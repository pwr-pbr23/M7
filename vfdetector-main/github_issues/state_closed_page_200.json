[{"number": 48697, "title": "\"libtensorflowlite_flex_jni.so\" crashes on x86 Android emulator", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@thaink could you take a look?", "I found information that tensorflow lite does not work on x86 emulators.  But I am running my model on a real device and it doesn't work on android 4.4.2.  Can you give an answer to which version of android tensorflow lite is stable?", "TensorFlow Lite and Select TF option both works on Android x86 emulators.\r\n\r\nWe recently have received the bug reports that the recent version (TF 2.5 or beyonds) of TensorFlow Lite's Select TF option won't work on Android 4.4.2 while the recent versions of TensorFlow Lite still works on Kitkat without any issues.\r\n\r\nIn your bug report, the issue is related to the Select TF option (which is also called as Flex) and this is aligned with our understanding.\r\n\r\nCould you try the TF 2.4.1 version on Android Kitkat? I believe at the TF 2.4.1 version, TensorFlow Lite + Select TF option will work on Android Kitkat.", "thanks for the answer, as soon as I try your solution to the problem, I will definitely report the results", "implementation \"org.tensorflow:tensorflow-lite:2.3.0\"\r\nupdated version to 2.4.1 and here's what happened\r\n\r\nCould not find org.tensorflow:tensorflow-lite:2.4.1.\r\n     Searched in the following locations:\r\n       - https://jcenter.bintray.com/org/tensorflow/tensorflow-lite/2.4.1/tensorflow-lite-2.4.1.pom\r\n       - https://maven.google.com/org/tensorflow/tensorflow-lite/2.4.1/tensorflow-lite-2.4.1.pom", "Instead of TF 2.4.1, could you try the TF 2.4.0 version? Looks like the TF pom distribution does not specify the minor version level.", "the app built with tensorflow version 2.4.0 but fails to start with the same error on android 4.4.2", "@sanyakuznezov Looks like the Select TF option has a compatibility issue with Android 4.4.2. Thanks for reporting the compatibility issue to us!", "@thaink could you take a look?", "I tried to run the application with TensorFlow 2.4.0 on the Pixel 3A emulator with API 25, but it does not work, this is what it says in Run:\r\n\r\n\r\n\r\nI/tflite: Initialized TensorFlow Lite runtime.\r\nW/DynamiteModule: Local module descriptor class for com.google.android.gms.measurement.dynamite not found.\r\nW/native: cpu_feature_guard.cc:36 The TensorFlow library was compiled to use SSE instructions, but these aren't available on your machine.\r\n    \r\n    --------- beginning of crash\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0xfffffff4 in tid 4888 (homok.sleepbaby)\r\nI/DynamiteModule: Considering local module com.google.android.gms.ads.dynamite:0 and remote module com.google.android.gms.ads.dynamite:21400\r\n    Selected remote version of com.google.android.gms.ads.dynamite, version >= 21400\r\n", "Let me give it a try.", "I am trying to run this example (https://github.com/tensorflow/examples) on Pixel 3A APi25 emulator. The application does not start.\r\n\r\n\r\n04/23 11:58:03: Launching 'app' on Pixel 3a XL API 25.\r\nApp restart successful without requiring a re-install.\r\n$ adb shell am start -n \"org.tensorflow.lite.examples.soundclassifier/org.tensorflow.lite.examples.soundclassifier.MainActivity\" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER\r\nConnected to process 4253 on device 'Pixel_3a_XL_API_25 [emulator-5554]'.\r\nCapturing and displaying logcat messages from application. This behavior can be disabled in the \"Logcat output\" section of the \"Debugger\" settings page.\r\nW/art: Before Android 4.1, method android.graphics.PorterDuffColorFilter androidx.vectordrawable.graphics.drawable.VectorDrawableCompat.updateTintFilter(android.graphics.PorterDuffColorFilter, android.content.res.ColorStateList, android.graphics.PorterDuff$Mode) would have incorrectly overridden the package-private method in android.graphics.drawable.Drawable\r\nI/art: Rejecting re-init on previously-failed class java.lang.Class<androidx.core.view.ViewCompat$2>: java.lang.NoClassDefFoundError: Failed resolution of: Landroid/view/View$OnUnhandledKeyEventListener;\r\n        at boolean androidx.core.view.ViewCompat.getFitsSystemWindows(android.view.View) (ViewCompat.java:2424)\r\n        at void androidx.coordinatorlayout.widget.CoordinatorLayout.setupForInsets() (CoordinatorLayout.java:3309)\r\n        at void androidx.coordinatorlayout.widget.CoordinatorLayout.<init>(android.content.Context, android.util.AttributeSet, int) (CoordinatorLayout.java:247)\r\n        at void androidx.coordinatorlayout.widget.CoordinatorLayout.<init>(android.content.Context, android.util.AttributeSet) (CoordinatorLayout.java:211)\r\n        at java.lang.Object java.lang.reflect.Constructor.newInstance0!(java.lang.Object[]) (Constructor.java:-2)\r\n        at java.lang.Object java.lang.reflect.Constructor.newInstance(java.lang.Object[]) (Constructor.java:430)\r\n        at android.view.View android.view.LayoutInflater.createView(java.lang.String, java.lang.String, android.util.AttributeSet) (LayoutInflater.java:645)\r\n        at android.view.View android.view.LayoutInflater.createViewFromTag(android.view.View, java.lang.String, android.content.Context, android.util.AttributeSet, boolean) (LayoutInflater.java:787)\r\n        at android.view.View android.view.LayoutInflater.createViewFromTag(android.view.View, java.lang.String, android.content.Context, android.util.AttributeSet) (LayoutInflater.java:727)\r\n        at android.view.View android.view.LayoutInflater.inflate(org.xmlpull.v1.XmlPullParser, android.view.ViewGroup, boolean) (LayoutInflater.java:495)\r\n        at android.view.View android.view.LayoutInflater.inflate(int, android.view.ViewGroup, boolean) (LayoutInflater.java:426)\r\n        at org.tensorflow.lite.examples.soundclassifier.databinding.ActivityMainBinding org.tensorflow.lite.examples.soundclassifier.databinding.ActivityMainBinding.inflate(android.view.LayoutInflater, android.view.ViewGroup, boolean) (ActivityMainBinding.java:70)\r\n        at org.tensorflow.lite.examples.soundclassifier.databinding.ActivityMainBinding org.tensorflow.lite.examples.soundclassifier.databinding.ActivityMainBinding.inflate(android.view.LayoutInflater) (ActivityMainBinding.java:64)\r\n        at void org.tensorflow.lite.examples.soundclassifier.MainActivity.onCreate(android.os.Bundle) (MainActivity.kt:38)\r\n        at void android.app.Activity.performCreate(android.os.Bundle) (Activity.java:6679)\r\n        at void android.app.Instrumentation.callActivityOnCreate(android.app.Activity, android.os.Bundle) (Instrumentation.java:1118)\r\n        at android.app.Activity android.app.ActivityThread.performLaunchActivity(android.app.ActivityThread$ActivityClientRecord, android.content.Intent) (ActivityThread.java:2618)\r\n        at void android.app.ActivityThread.handleLaunchActivity(android.app.ActivityThread$ActivityClientRecord, android.content.Intent, java.lang.String) (ActivityThread.java:2726)\r\n        at void android.app.ActivityThread.-wrap12(android.app.ActivityThread, android.app.ActivityThread$ActivityClientRecord, android.content.Intent, java.lang.String) (ActivityThread.java:-1)\r\nI/art:     at void android.app.ActivityThread$H.handleMessage(android.os.Message) (ActivityThread.java:1477)\r\n        at void android.os.Handler.dispatchMessage(android.os.Message) (Handler.java:102)\r\n        at void android.os.Looper.loop() (Looper.java:154)\r\n        at void android.app.ActivityThread.main(java.lang.String[]) (ActivityThread.java:6119)\r\n        at java.lang.Object java.lang.reflect.Method.invoke!(java.lang.Object, java.lang.Object[]) (Method.java:-2)\r\n        at void com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run() (ZygoteInit.java:886)\r\n        at void com.android.internal.os.ZygoteInit.main(java.lang.String[]) (ZygoteInit.java:776)\r\n    Caused by: java.lang.ClassNotFoundException: Didn't find class \"android.view.View$OnUnhandledKeyEventListener\" on path: DexPathList[[zip file \"/data/app/org.tensorflow.lite.examples.soundclassifier-1/base.apk\"],nativeLibraryDirectories=[/data/app/org.tensorflow.lite.examples.soundclassifier-1/lib/x86, /data/app/org.tensorflow.lite.examples.soundclassifier-1/base.apk!/lib/x86, /system/lib, /vendor/lib]]\r\n        at java.lang.Class dalvik.system.BaseDexClassLoader.findClass(java.lang.String) (BaseDexClassLoader.java:56)\r\n        at java.lang.Class java.lang.ClassLoader.loadClass(java.lang.String, boolean) (ClassLoader.java:380)\r\n        at java.lang.Class java.lang.ClassLoader.loadClass(java.lang.String) (ClassLoader.java:312)\r\n        at boolean androidx.core.view.ViewCompat.getFitsSystemWindows(android.view.View) (ViewCompat.java:2424)\r\n        at void androidx.coordinatorlayout.widget.CoordinatorLayout.setupForInsets() (CoordinatorLayout.java:3309)\r\n        at void androidx.coordinatorlayout.widget.CoordinatorLayout.<init>(android.content.Context, android.util.AttributeSet, int) (CoordinatorLayout.java:247)\r\n        at void androidx.coordinatorlayout.widget.CoordinatorLayout.<init>(android.content.Context, android.util.AttributeSet) (CoordinatorLayout.java:211)\r\n        at java.lang.Object java.lang.reflect.Constructor.newInstance0!(java.lang.Object[]) (Constructor.java:-2)\r\n        at java.lang.Object java.lang.reflect.Constructor.newInstance(java.lang.Object[]) (Constructor.java:430)\r\n        at android.view.View android.view.LayoutInflater.createView(java.lang.String, java.lang.String, android.util.AttributeSet) (LayoutInflater.java:645)\r\n        at android.view.View android.view.LayoutInflater.createViewFromTag(android.view.View, java.lang.String, android.content.Context, android.util.AttributeSet, boolean) (LayoutInflater.java:787)\r\n        at android.view.View android.view.LayoutInflater.createViewFromTag(android.view.View, java.lang.String, android.content.Context, android.util.AttributeSet) (LayoutInflater.java:727)\r\n        at android.view.View android.view.LayoutInflater.inflate(org.xmlpull.v1.XmlPullParser, android.view.ViewGroup, boolean) (LayoutInflater.java:495)\r\n        at android.view.View android.view.LayoutInflater.inflate(int, android.view.ViewGroup, boolean) (LayoutInflater.java:426)\r\n        at org.tensorflow.lite.examples.soundclassifier.databinding.ActivityMainBinding org.tensorflow.lite.examples.soundclassifier.databinding.ActivityMainBinding.inflate(android.view.LayoutInflater, android.view.ViewGroup, boolean) (ActivityMainBinding.java:70)\r\n        at org.tensorflow.lite.examples.soundclassifier.databinding.ActivityMainBinding org.tensorflow.lite.examples.soundclassifier.databinding.ActivityMainBinding.inflate(android.view.LayoutInflater) (ActivityMainBinding.java:64)\r\n        at void org.tensorflow.lite.examples.soundclassifier.MainActivity.onCreate(android.os.Bundle) (MainActivity.kt:38)\r\n        at void android.app.Activity.performCreate(android.os.Bundle) (Activity.java:6679)\r\n        at void android.app.Instrumentation.callActivityOnCreate(android.app.Activity, android.os.Bundle) (Instrumentation.java:1118)\r\n        at android.app.Activity android.app.ActivityThread.performLaunchActivity(android.app.ActivityThread$ActivityClientRecord, android.content.Intent) (ActivityThread.java:2618)\r\n        at void android.app.ActivityThread.handleLaunchActivity(android.app.ActivityThread$ActivityClientRecord, android.content.Intent, java.lang.String) (ActivityThread.java:2726)\r\n        at void android.app.ActivityThread.-wrap12(android.app.ActivityThread, android.app.ActivityThread$ActivityClientRecord, android.content.Intent, java.lang.String) (ActivityThread.java:-1)\r\n        at void android.app.ActivityThread$H.handleMessage(android.os.Message) (ActivityThread.java:1477)\r\n        at void android.os.Handler.dispatchMessage(android.os.Message) (Handler.java:102)\r\n        at void android.os.Looper.loop() (Looper.java:154)\r\n        at void android.app.ActivityThread.main(java.lang.String[]) (ActivityThread.java:6119)\r\n        at java.lang.Object java.lang.reflect.Method.invoke!(java.lang.Object, java.lang.Object[]) (Method.java:-2)\r\n        at void com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run() (ZygoteInit.java:886)\r\n        at void com.android.internal.os.ZygoteInit.main(java.lang.String[]) (ZygoteInit.java:776)\r\nI/ViewConfigCompat: Could not find method getScaledScrollFactor() on ViewConfiguration\r\nI/SoundClassifier: Done creating TFLite buffer from soundclassifier.tflite\r\nI/tflite: Initialized TensorFlow Lite runtime.\r\nW/native: cpu_feature_guard.cc:36 The TensorFlow library was compiled to use SSE instructions, but these aren't available on your machine.\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0xfffffff4 in tid 4253 (soundclassifier)\r\n\r\n", "as I understand it, you need to disable the instruction SSE. How to do it?", "From TensorFlow 2.4 versions, the Select TF binaries are built without the SSE support. Please make sure your TF dependency is at least TF 2.4. version for the x86 emulator.", "I am working with these dependencies: \r\n\r\nimplementation 'org.tensorflow:tensorflow-lite-support:0.1.0-rc1'\r\n    implementation \"org.tensorflow:tensorflow-lite:2.4.0\"\r\n    implementation 'org.tensorflow:tensorflow-lite-metadata:0.1.0-rc2'\r\n   implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:2.4.0'", "Could you also try the tf-nightly or tf 2.5.0? I think the fix isn't included in the TF 2.4.0. See also https://github.com/tensorflow/tensorflow/issues/38025", "Could not resolve all files for configuration ':app:debugRuntimeClasspath'.\r\n   > Could not find org.tensorflow:tensorflow-lite:2.5.0.\r\n     Searched in the following locations:\r\n       - https://jcenter.bintray.com/org/tensorflow/tensorflow-lite/2.5.0/tensorflow-lite-2.5.0.pom\r\n       - https://maven.google.com/org/tensorflow/tensorflow-lite/2.5.0/tensorflow-lite-2.5.0.pom\r\n       - file:/C:/Users/first/.m2/repository/org/tensorflow/tensorflow-lite/2.5.0/tensorflow-lite-2.5.0.pom\r\n       - file:/C:/Users/first/MyProgect/GoodSleep/app/libs/tensorflow-lite-2.5.0.jar\r\n       - file:/C:/Users/first/MyProgect/GoodSleep/app/libs/tensorflow-lite.jar", "Then please try out the tf-nightly version.", "the problem persists, perhaps this problem with sse only on emulators with x86. On a real device with android api 29, the application starts and works stably, but I have no opportunity to test the application on all real devices\r\n\r\nbuild.gradle:\r\n\r\n //tensorflow\r\n    implementation 'org.tensorflow:tensorflow-lite-support:0.1.0-rc1'\r\n    implementation \"org.tensorflow:tensorflow-lite:0.0.0-nightly\"\r\n    implementation 'org.tensorflow:tensorflow-lite-metadata:0.1.0-rc2'\r\n    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'\r\n   //\r\n  Run:\r\n\r\nI/tflite: Initialized TensorFlow Lite runtime.\r\nW/native: cpu_feature_guard.cc:36 The TensorFlow library was compiled to use SSE instructions, but these aren't available on your machine.\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0xfffffff4 in tid 12144 (homok.sleepbaby)\r\n", "@terryheo could you take a look?", "We used to fix this but it's happening again. Let me take a look.", "It turns out that you're using old version of nightly from jcenter.\r\nTFLite is switching to maven for hosting of those AARs.\r\nThe official guide will be updated soon.\r\nIn the mean time, you can use it as following.\r\n\r\nIn your Project build.gradle file, \r\n```\r\nallprojects {\r\n    repositories {\r\n        google()\r\n        jcenter()\r\n    }\r\n}\r\n```\r\nUpdate it as the following.\r\n```\r\nallprojects {\r\n    repositories {\r\n        google()\r\n        mavenCentral ()  // mavenCentral() is for versioned stable release\r\n        maven {          // This maven with url is for snapshot release (nightly)\r\n            name 'ossrh-snapshot'\r\n            url 'http://oss.sonatype.org/content/repositories/snapshots'\r\n        }\r\n    }\r\n} \r\n```\r\n\r\nAlso update build.gradle of your Module,\r\n```\r\n    implementation('org.tensorflow:tensorflow-lite:0.0.0-nightly') { changing = true }\r\n    implementation('org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly') { changing = true }\r\n```\r\nChange it to\r\n\r\n```\r\n    implementation('org.tensorflow:tensorflow-lite:0.0.0-nightly-SNAPSHOT') { changing = true }\r\n    implementation('org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly-SNAPSHOT') { changing = true }\r\n```\r\n\r\nAnd rebuild it. It will work well with x86 emulator.\r\n\r\n@xunkai55 just FYI,", "thanks, everything worked out, the application started on the emulator", "@sanyakuznezov \r\nPlease confirm if this is still an issue on latest version of tf.", "@sanyakuznezov, According to [this](https://github.com/tensorflow/tensorflow/issues/48697#issuecomment-826700267), your issue was resolved. Please feel free to close. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48697\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48697\">No</a>\n"]}, {"number": 48696, "title": "TFLM: Bump CMSIS version", "body": "The new version brings MVE support for SVDF and Fully Connected implementation is updated to reflect zero weight offset as per int8 spec.\r\nFix: https://github.com/tensorflow/tensorflow/issues/48695", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "Done"]}, {"number": 48695, "title": "Downloaded CMSIS version is a bit old", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source): 323d8b857216f20bf4266ea0a7876363d707aceb\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\nDownloaded CMSIS version is a bit old. It should be updated.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": []}, {"number": 48694, "title": "Import graph operation in C or C++", "body": "Hi all,\r\nI'm dealing with the following operations. I would like to export a graph from tensorflow python API to TF C API.  Based on TF 2, I'm using graph execution and @tf.function to build the graph with custom operation. Then I'm saving the graph using save_model. Next I would like to load this graph on C or C++ and run the graph to obtain the outputs. Which is the best procedure to do that at the moment?", "comments": ["@FGMphys ,\r\n\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48694\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48694\">No</a>\n"]}, {"number": 48693, "title": "How to build a dynamic library for ios tflite by cmake with Cross-compilation?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI have successfully built the ios static library with the comand \"bash tensorflow/lite/tools/make/download_dependencies.sh\". But I find the generated static lib is over 17Mb for each architecture. \r\n\r\nMeanwhile, I also try to use the command \"bazel build --config=ios_x86_64 -c op //tensorflow/lite/ios:TensorFlowLiteC_framework\" to genenrate a ios static lib (.framework), but it is bigger (>23Mb).\r\n\r\n In my opinion, the dynamic lib can be smaller than the static lib (17Mb). How can I obtain it?\r\n\r\n\r\n\r\n", "comments": ["@terryheo @yyoon  could you take a look?", "cc/ @thaink \r\n\r\nGenerally speaking, the size of the iOS static library built with bazel is big due to bitcode embedding. When it's linked to your final app after the app thinning is applied, the actual size increase caused by TFLite will be much smaller (around 3~4MB last time we checked a few months ago).\r\n\r\nA few additional notes:\r\n* The [iOS build script using Makefile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/make/build_ios_universal_lib.sh) has not been maintained for quite a long time, and the resulting library wouldn't necessarily work correctly.\r\n* You could try building a dynamic framework by adding a new `ios_framework` build target in the [iOS BUILD file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/ios/BUILD.apple). It would be similar to the static framework target, but you would need to additionally provide a `plist.info` file. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/ios/BUILD.apple for documentation.\r\n* When I tried building iOS lib with CMake, it didn't support cross compilation. It required me to use a Mac machine and the Xcode project generator. Even with these, I couldn't successfully build some dependencies such as XNNPack.\r\n\r\nLet me know if you have further questions.", "Right. I don't think you should care about .framework file size. Better to focus on the final app size increase.", "I see. Thanks! I find an alternative solution is that I can turn off the bitcode in bazel build.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48693\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48693\">No</a>\n", "@yyoon I find the official site (https://www.tensorflow.org/lite/guide/build_ios) is still asking users to use the command \"tensorflow/lite/tools/make/download_dependencies.sh\". It is better to update it. ", "@Mrlyk423 I don't see that instruction anywhere on the page you linked. Can you point to the exact location of it? Is it possible that you were somehow looking at an old version of that doc?", "@yyoon  Ohh, I see. I am looking at the version of \"Chinese\" of this page, the \"English\" version has been updated."]}, {"number": 48692, "title": "multi-output keras models change metric names when reloading", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.79\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n\r\nWhen reloading a multi-output model, the name of the output gets repeated  when calling `tf.keras.models.Model.evaluate`:\r\n\r\n```\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'2.4.1'\r\n\r\n>>> input_a = tf.keras.Input(shape=(1,))\r\n\r\n>>> ifoo = tf.keras.layers.Dense(1, name=\"foo\")(input_a)\r\n>>> ibar = tf.keras.layers.Dense(1, name=\"bar\")(input_a)\r\n\r\n>>> imodel = tf.keras.Model(input_a, {\"foo\": foo, \"bar\": bar})\r\n>>> imodel.compile(loss=\"mse\", optimizer=\"adam\", metrics={\"foo\": \"mae\", \"bar\": \"mae\"})\r\n>>> model.evaluate(tf.constant([[1]]), tf.constant([[1]]), return_dict=True)\r\n\r\n1/1 [==============================] - 0s 236ms/step - loss: 4.0179 - bar_loss: 3.9153 - foo_loss: 0.1026 - bar_mae: 1.9787 - foo_mae: 0.3203\r\n{'loss': 4.0179123878479,\r\n 'bar_loss': 3.915294885635376,\r\n 'foo_loss': 0.10261743515729904,\r\n 'bar_mae': 1.978710412979126,\r\n 'foo_mae': 0.320339560508728}\r\n\r\n>>> model.save(\"/tmp/model\")\r\n>>> model_relaoded = tf.keras.models.load_model(\"/tmp/model\")\r\n>>> model_relaoded.evaluate(tf.constant([[1]]), tf.constant([[1]]), return_dict=True)\r\n\r\n1/1 [==============================] - 0s 87ms/step - loss: 4.0179 - bar_loss: 3.9153 - foo_loss: 0.1026 - bar_bar_mae: 1.9787 - foo_foo_mae: 0.3203\r\n{'loss': 4.0179123878479,\r\n 'bar_loss': 3.915294885635376,\r\n 'foo_loss': 0.10261743515729904,\r\n 'bar_bar_mae': 1.978710412979126,\r\n 'foo_foo_mae': 0.320339560508728}\r\n```\r\n\r\n**Describe the expected behavior**\r\nI would expect the metrics' name to remain unchanged when reloading:\r\n\r\n```\r\n>>> model.save(\"/tmp/model\")\r\n>>> model_relaoded = tf.keras.models.load_model(\"/tmp/model\")\r\n>>> model_relaoded.evaluate(tf.constant([[1]]), tf.constant([[1]]), return_dict=True)\r\n\r\n1/1 [==============================] - 0s 87ms/step - loss: 4.0179 - bar_loss: 3.9153 - foo_loss: 0.1026 - bar_mae: 1.9787 - foo_mae: 0.3203\r\n{'loss': 4.0179123878479,\r\n 'bar_loss': 3.915294885635376,\r\n 'foo_loss': 0.10261743515729904,\r\n 'bar_mae': 1.978710412979126,\r\n 'foo_mae': 0.320339560508728}\r\n```\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nHere is a collab with the above code: https://colab.research.google.com/drive/1rm2d51gXw0ZvxIs63Qu5ACyRDK5OAgoM?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nNA\r\n\r\nPS: I have never contributed to TensorFlow but I would be glad to help resolve this issue.\r\n", "comments": ["@aredier \r\n I reproduced the code in tf-nightly it worked as you expected that the metrics' remain unchanged when reloading:\r\nCould you please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/c43c04782946b15d3faf7a9a671bde9d/-48692.ipynb) here.Thanks", "@UsharaniPagadala I can indeed reproduce on my machine with tf_nightly.\r\nTnanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48692\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48692\">No</a>\n"]}, {"number": 48691, "title": "Create sample", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F48691) for more info**.\n\n<!-- need_sender_cla -->", "Closing this PR, since no files changed.  thanks!\r\ncc @mihaimaruseac"]}, {"number": 48690, "title": "ValueError: Found two metrics with the same name: Dense_xx Accuracy. TensorFlow 2.4", "body": "**System information**\r\n- OS: Linux Ubuntu 20.04 as well as Windows 10\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.79\r\n- CUDA version: 11.2\r\n- GPU model and memory: RTX 3060\r\n\r\n**Issue**\r\nPreviously I upgraded my Tensorflow to 2.4.\r\nI got an error message like \"ValueError: Found two metrics with the same name: dense_xx_accuracy\". \r\nThen, I downgraded my TF to 2.1 and everything is working fine again.\r\n\r\n**Log**\r\n2021-04-22 14:36:23.743926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\nNt.2 Np.2 Nr.4 M.4 RIS.4\r\n2021-04-22 14:36:24.521915: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-04-22 14:36:24.522409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-04-22 14:36:24.526771: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2021-04-22 14:36:24.526787: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: user-system-sharing\r\n2021-04-22 14:36:24.526791: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: user-system-sharing\r\n2021-04-22 14:36:24.526838: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.67.0\r\n2021-04-22 14:36:24.526851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.67.0\r\n2021-04-22 14:36:24.526855: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.67.0\r\n2021-04-22 14:36:24.526974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-04-22 14:36:24.527331: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-04-22 14:36:24.605219: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\r\n2021-04-22 14:36:24.605238: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\r\n2021-04-22 14:36:24.607251: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\r\n2021-04-22 14:36:24.653744: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2021-04-22 14:36:24.654329: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2799925000 Hz\r\nEpoch 1/50\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/user/Documents/Python/RIS/RIS-DNN_Cosine_Training.py\", line 110, in <module>\r\n    model.fit(np.transpose(D),train_labels_app, validation_split=0.25, batch_size=512, epochs=50, callbacks=[callbacks_list, tensorboard], shuffle=True)\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\r\n    *args, **kwds))\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n\r\n  File \"/usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\n\r\nValueError: in user code:\r\n\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\r\n        outputs = model.train_step(data)\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:758 train_step\r\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state\r\n        self.build(y_pred, y_true)\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:329 build\r\n        self._set_metric_names()\r\n    /usr/local/anaconda3/envs/AI/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:349 _set_metric_names\r\n        m._name))\r\n\r\n    ValueError: Found two metrics with the same name: dense_3_accuracy", "comments": ["@hasanabs \r\nPlease share code such that we could replicate the error reported or a colab gist with the code and error.\r\n\r\nBased on the error logs, you may refer to this link an let us know: [link](https://stackoverflow.com/questions/62905851/valueerror-found-two-metrics-with-the-same-name-recall), \r\n", "> @hasanabs\r\n> Please share code such that we could replicate the error reported or a colab gist with the code and error.\r\n> \r\n> Based on the error logs, you may refer to this link and let us know: [link](https://stackoverflow.com/questions/62905851/valueerror-found-two-metrics-with-the-same-name-recall),\r\n\r\nYes this is my training file and its function\r\n[B-DNN_Training.py](https://github.com/hasanabs/B_DNN/blob/main/B-DNN_Training.py)\r\n[fungsi_dnn.py](https://github.com/hasanabs/B_DNN/blob/main/fungsi_dnn.py)", "I found the main problem, it turns out that in TF 2.4 there is a slight change in the way to call accuracy but for sparse_categorical_crossentropy\r\n\r\nThis is the change needed for solve this problem. First, delete the line I commented on, then define loss and matrices as in the green area\r\n![Screenshot from 2021-04-30 10-25-33](https://user-images.githubusercontent.com/26079804/116641799-0a717000-a9a0-11eb-83bc-0f63c3ddf07d.png)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48690\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48690\">No</a>\n"]}, {"number": 48689, "title": "Post training quantization conversion log show: Optimization loop failed: Cancelled: Operation was cancelled", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installation (pip package or built from source): pip package install in anaconda virtual env\r\n- TensorFlow library (version, if pip package or github SHA, if built from source):  tf-nightly 2.6.0.dev20210407\r\n\r\n### 2. Code\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef representative_dataset():\r\n    path = r'D:\\Development\\fruits_data\\images\\test'\r\n    image_dataset = tf.data.Dataset.list_files(path + '/*.png')\r\n    for i in range(15):\r\n        image = next(iter(image_dataset))\r\n        image = tf.io.read_file(image)\r\n        image = tf.io.decode_jpeg(image, channels=3)\r\n        image = tf.image.resize(image, [640, 640])\r\n        image = tf.cast(image / 255., tf.float32)\r\n        image = tf.expand_dims(image, 0)\r\n        yield [image]\r\n        \r\n#import trained model from mobilenet 640 v2 fpn\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('./exported_models/tflite/saved_model') #using tensorflow\r\n\r\n#quantize the model to int8 for export\r\nconverter.experimental_new_converter = True #required for using experimental target_spec flags.\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT] #Currently only DEFAULT is supported by TF2.4.X or tf-nightly.\r\nconverter.representative_dataset = representative_dataset\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n\r\nconverter.target_spec.supported_types = [tf.int8]\r\nconverter.inference_input_type = tf.int8 \r\n#converter.inference_output_type = tf.int8 \r\nconverter.allow_custom_ops = True \r\ntflite_int8_model = converter.convert()\r\n\r\n# Save the model.\r\nwith open('test_model.tflite', 'wb') as f:\r\n  f.write(tflite_int8_model)\r\n```\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\nConversion to TFLite is successful, but on the log states: `Optimization loop failed: Cancelled: Operation was cancelled`\r\nand during inferences the model was not able to be used. The conversion model used is the pre-trained `mobilenet 640 v2 fpn` model found in tf zoo for object detection. \r\n\r\n\r\n### 4. (optional) RNN conversion support\r\n~If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.~\r\n\r\n### 5. (optional) Any other info / logs\r\n\r\nTerminal log: \r\n\r\n```\r\nSkipping registering GPU devices...\r\n2021-04-22 12:08:07.890584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-04-22 12:08:07.890670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0\r\n2021-04-22 12:08:07.891405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N\r\n2021-04-22 12:08:09.301186: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:10.346812: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:11.392280: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:12.466013: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:13.526607: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:14.586672: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:15.633286: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:16.680019: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:17.754911: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:18.828891: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:19.905723: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:20.984154: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:22.027698: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n2021-04-22 12:08:23.097239: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\r\n```\r\n\r\n", "comments": ["@liufengdb could you triage this?", "Ethylbenzol@, can you use some random inputs in your representative_dataset method to verify that error is actually due to the use of tf.dataset (not really quantization).", ">  can you use some random inputs in your representative_dataset method to verify that error is actually due to the use of tf.dataset (not really quantization).\r\n\r\n'''\r\ndef representative_dataset():\r\n    for _ in range(100):\r\n      data = np.random.rand(1, 640, 640, 3)\r\n      yield [data.astype(np.float32)]\r\n''\r\nso i ran this dummy dataset and seem like there was no operation cancelled error thrown.\r\n\r\nCould this be related to a GPU error as running this on a venv with tensorflow 2.3 and cuda toolkit 10.2 i get a different error: `ValueError: Failed to parse the model: pybind11::init(): factory function returned nullptr.`\r\nThe venv which contains the tf-nightly version does not come with any cuda toolkit installed. ", "update to this issue:\r\nLooking at the logs during tflite inference for this model: \r\n```\r\n{'name': 'StatefulPartitionedCall:3', 'index': 382, 'shape': array([ 1, 10,  4]), 'shape_signature': array([ 1, 10,  4]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.006796886213123798, 60), 'quantization_parameters': {'scales': array([0.00679689], dtype=float32), 'zero_points': array([60]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\r\n{'name': 'StatefulPartitionedCall:2', 'index': 384, 'shape': array([ 1, 10]), 'shape_signature': array([ 1, 10]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.01568627543747425, 0), 'quantization_parameters': {'scales': array([0.01568628], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\r\n{'name': 'StatefulPartitionedCall:1', 'index': 386, 'shape': array([ 1, 10]), 'shape_signature': array([ 1, 10]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0035720604937523603, 0), 'quantization_parameters': {'scales': array([0.00357206], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\r\n{'name': 'StatefulPartitionedCall:0', 'index': 388, 'shape': array([1]), 'shape_signature': array([1]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.03921568766236305, 0), 'quantization_parameters': {'scales': array([0.03921569], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\r\nthis is the detection_boxes: [[ 71  86 216 204]\r\n [ 72  34 221 227]\r\n [166 200 191 208]\r\n [ 46   0 197 212]\r\n [ 95   2 245 209]\r\n [180  58 208  66]\r\n [156 191 201 211]\r\n [158 199 191 206]\r\n [ 91 203 113 207]\r\n [172  60 194  63]] and this is the detection_classes: and this is the detection_scores: [ 64  64 255  64  64 255 255   0 255 255] and this is the count: [236  28   5   5   5   5   3   3   2   2] \r\n```\r\n\r\nSeem like there the detection_classes are missing and the score make no sense. Are there anything else i could provide to troubleshoot this?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48689\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48689\">No</a>\n", "import numpy as np\r\nimport tensorflow as tf\r\n\r\nimage_data = tf.data.Dataset.list_files(\"./quant-images/*.jpg\")\r\nHEIGHT, WIDTH = 640, 640\r\n\r\ndef representative_dataset_gen():\r\n   for image_path in image_data:\r\n       img = tf.io.read_file(image_path)\r\n       img = tf.io.decode_image(img, channels=3)\r\n       img = tf.image.convert_image_dtype(img, tf.float32)\r\n       resized_img = tf.image.resize(img, (HEIGHT, WIDTH))\r\n       resized_img = resized_img[tf.newaxis, :]\r\n       yield [resized_img]\r\n\r\nmodel_path = './exported-models/ptag-detector-model/ssd_mobilenet_v2_fpnlite_640x640/saved_model'        \r\n\r\n#import trained model from mobilenet 640 v2 fpn\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_path) #using tensorflow\r\n\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\nconverter.quantized_input_stats = {\"normalized_input_image_tensor\": (128, 128)}\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ntflite_model_quant = converter.convert()\r\n\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\r\ninput_type = interpreter.get_input_details()[0]['dtype']\r\nprint('input: ', input_type)\r\noutput_type = interpreter.get_output_details()[0]['dtype']\r\nprint('output: ', output_type)\r\n\r\nwith open('detect_quant.tflite', 'wb') as f:\r\n  f.write(tflite_model_quant)\r\n\r\n\r\nThis code will get you full quantized tflite model"]}, {"number": 48688, "title": "[determinism] Add CPU-focused tests for fused softmax/cross-entropy ops", "body": "This current PR is a follow-up to PR [47925](https://github.com/tensorflow/tensorflow/pull/47925) (Add softmax/cross-entropy op exceptions for GPU determinism), and specifically to [this interaction](https://github.com/tensorflow/tensorflow/pull/47925#discussion_r599219389) between @sanjoy and myself.\r\n\r\nThis current PR adds determinism tests for the CPU implementations of `tf.softmax_cross_entropy_with_logits` and `tf.sparse_softmax_cross_entropy_with_logits`. When deterministic GPU implementations are added for these ops, the tests can be used to demonstrate, confirm, and ensure that the functionality is, and stays, deterministic.", "comments": []}, {"number": 48687, "title": "Update bot_config.yml", "body": "", "comments": []}, {"number": 48686, "title": "Update bot_config.yml", "body": "", "comments": []}, {"number": 48685, "title": "[Intel MKL] Fixing python version of IsMklEnabled() method", "body": "This PR changes IsMklEnabled() python method which used to consider build flag only to determine if Mkl is enabled. That caused some python tests to fail (like timeline_test) in single binary. Now it also checks the environment variable flag.", "comments": []}, {"number": 48684, "title": "Error:  tf.device does not support functions", "body": "Tensorflow crashes when following current guide.\r\n\r\n**System information**\r\nTensorflow Version: \r\nv2.4.0-49-g85c8b2a817f 2.4.1\r\n\r\n**Describe the current behavior**\r\nFollowing the [guide](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/replica_device_setter) on how to use `replica_device_setter`, the code crashes with the error: `RuntimeError: tf.device does not support functions.`\r\n\r\n\r\n**Describe the expected behavior**\r\nIt should not crash\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ncluster_spec = {\"ps\": [\"ps0:2222\"],\"worker\": [\"worker0:2222\", \"worker1:2222\"]}\r\nwith tf.device(tf.compat.v1.train.replica_device_setter(cluster=cluster_spec)):\r\n    pass\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n```\r\n...\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in device_v2(device_name)\r\n   5271   \"\"\"\r\n   5272   if callable(device_name):\r\n-> 5273     raise RuntimeError(\"tf.device does not support functions.\")\r\n   5274   return device(device_name)\r\n   5275 \r\n\r\nRuntimeError: tf.device does not support functions.\r\n```\r\n", "comments": ["@amahendrakar \r\n\r\nI reproduced the code in tf 2.5rc1 ,tf-nightly and tf2.4.1,but facing the same [error.](https://colab.research.google.com/gist/UsharaniPagadala/98d5766b0cb51c516dddf2c32f8ec1c9/-48684.ipynb) Could you please look at this issue .Thanks", "After digging though ops.py, I saw that I could call the old v1 method, and fixed the error by changing to\r\n```\r\nimport tensorflow as tf\r\ncluster_spec = {\"ps\": [\"ps0:2222\"],\"worker\": [\"worker0:2222\", \"worker1:2222\"]}\r\nwith tf.compat.v1.device(tf.compat.v1.train.replica_device_setter(cluster=cluster_spec)):\r\n    pass\r\n```\r\n\r\nSo I guess the guide needs to be updated or `device_v2()` to fall back on `device()` if a function is provided?", "As part of the migration to TF2, we explicitly disabled functions as input to tf.device. So we should just update the guide to call tf.compat.v1.device instead of tf.device. It'll be great if you wanted to contribute a PR with the documentation fix! ", "Since the above [PR](https://github.com/tensorflow/tensorflow/pull/52095) was merged. I am closing this issue. Please feel free to reopen the issue if you still have a concern. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48684\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48684\">No</a>\n"]}, {"number": 48683, "title": "Issues loading saved model  - TypeError: __init__() got an unexpected keyword argument 'name'", "body": "solved can be closed", "comments": ["Can you share a minimal standalone example that we could just `copy and run` to reproduce this (or a Colab)?\r\nThanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48683\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48683\">No</a>\n"]}, {"number": 48682, "title": "Fix sparkfun edge build for https://github.com/tensorflow/tflite-micro", "body": "For some unexplained reason, the sparkfun edge cflags includes -Werror for the (work in progress) standalone TFLM repo, but does not have the corresponding -Werror when we use TARGET=sparkfun_edge from the Tensorflow repo.\r\n\r\nWe will not attempt to root-cause this discrepancy. Instead, the current change fixes the sparkfun edge build in https://github.com/tensorflow/tflite-micro.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48681, "title": "[TF] Fix convert_variables_to_constants_v2 for DT_RESOURCE.", "body": "In GraphDef, a node with dtype DT_RESOURCE may not always represent a Var resource. Previously, when converting variables to constants, we always converted the val_tensor from a DT_RESOURCE to a numpy array and it crashes the TF runtime when\r\nthe resource is not a Var resource. \r\n\r\nThis PR avoids converting a val_tensor with dtype==resource to numpy array.\r\n\r\nThese github issues: https://github.com/tensorflow/tensorrt/issues/233 & https://github.com/tensorflow/tensorflow/issues/46254 explain why this bug is a problem for the savedModel utility convert_variables_to_constants_v2, it basically prevents TF-TRT from converting any NLP related models. \r\n\r\nThis simple PR addresses this important bug. Please let me know how I can help to get this merged\r\n\r\nGoogle Colab link to reproduce the issue from this bug: https://colab.research.google.com/drive/1_S37VihkTZ1B0HgjW8D7DMZcI8nwz2Bk\r\n\r\nCC1: @tfeher @MattConley @WhiteFangBuck @nluehr \r\nCC2: @pkanwar23 @sanjoy @bixia1", "comments": ["Fixed and merged in: 208becf33b18396969db3b7b4c7ccc46e37092bc"]}, {"number": 48680, "title": "ValueError: Shapes (8, 100) and (8, 1) are incompatible", "body": "![image](https://user-images.githubusercontent.com/53318795/115602332-7dffe700-a2e7-11eb-9f46-16b76d8bfdd5.png)\r\nMy model params is above. when i tried to get score metrics (Recall and Precision)  this error show up \r\n![image](https://user-images.githubusercontent.com/53318795/115603793-4134ef80-a2e9-11eb-92b4-ecd3323b8bd6.png)\r\nmodel.fit code is :\r\n![image](https://user-images.githubusercontent.com/53318795/115603861-56118300-a2e9-11eb-90d2-94e5c2b20b7b.png)\r\n\r\nHow can i solved this problem ? \r\n", "comments": ["@shbkukuk Could you please provide the code snippet/colab link so that it helps to figure out the error a bit faster.\r\n\r\nAlso, Please check the input size of  first layer whether you have defined properly or not and helps to resolve the error. Thanks!", "`IMG_SIZE = 100\r\n\r\nnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\r\nplt.imshow(new_array, cmap='gray')\r\n#plt.show()\r\n\r\n\r\ntraining_data = []\r\ndef create_training_data():\r\n    for category in CATEGORIES:\r\n        path = os.path.join(DATA,category)\r\n        class_num = CATEGORIES.index(category) #s\u0131n\u0131fland\u0131rma yap\u0131yoruz. 0=yang\u0131n,1=orman(yang\u0131ns\u0131z)\r\n        for img in os.listdir(path):  # her img array haline \u00e7evirme\r\n            try:\r\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)  # grile\u015ftirme de yap\u0131ld\u0131.\r\n                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\r\n                training_data.append([new_array,class_num])\r\n            except Exception as e:\r\n                pass\r\n\r\ncreate_training_data()\r\n\r\n#print(len(training_data))\r\n\r\nrandom.shuffle(training_data)\r\nX = []\r\ny = []\r\n\r\nfor features,label in training_data:\r\n    X.append(features)\r\n    y.append(label)\r\n\r\n\r\nX = np.array(X)\r\ny = np.array(y)\r\n\r\nprint(X.shape)\r\nprint(y.shape)\r\n\r\nX_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.2,random_state=426)\r\n\r\n\r\nfor dense_layer in dense_layers:\r\n    for layer_size in layer_sizes:\r\n        for multi_layer in multi_layers:\r\n            NAME = \"{}-Multilayer-{}-LayerSize-{}-dense-{}test-metrics\".format(multi_layer, layer_size, dense_layer, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n            print(NAME)\r\n\r\n            model = Sequential()\r\n            #ysa ilk katman\u0131(giri\u015f)\r\n            model.add(Dense(layer_size,input_shape=(X_train.shape[1:]),activation='relu')) #256 tane yapay sinir h\u00fccresi\r\n            #ysa ara katman\r\n        for l in dense_layers:\r\n            model.add(Dense(layer_size,activation='relu'))\r\n            #ysa gizli katman\r\n        for l in range(multi_layer-1):\r\n            model.add(Dense(layer_size,activation='relu'))\r\n            #ysa \u00e7\u0131k\u0131\u015f katman\u0131\r\n            model.add(Dense(1,activation='sigmoid'))\r\n            tensorboard = TensorBoard(log_dir=\"4820logs/21-04-21/{}\".format(NAME))\r\n\r\n            model.summary()\r\n\r\n            \r\n            model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\r\n                          optimizer='adam',\r\n                          metrics=['accuracy',\r\n                                   tf.keras.metrics.Recall(),\r\n                                   tf.keras.metrics.Precision()\r\n                                ])\r\n\r\n            model.fit(X_train,y_train,batch_size=8,\r\n                      epochs=50,verbose=2,\r\n                      validation_data=(X_test,y_test),\r\n                      callbacks=[tensorboard])\r\n            #print(\"{},{},{}\".format(str(pre),str(auc),str(rcll)))\r\n            s\u0131n\u0131f = X_test[2].reshape(IMG_SIZE, IMG_SIZE)\r\n            plt.imshow(s\u0131n\u0131f, cmap='gray')\r\n            plt.show()\r\n`\r\n@saikumarchalla  I can share with you part of code. i think its enough for help. Thank you for replies.", "@shbkukuk \r\nI ran the code shared and face a different error please find the [gist here [syntax issues]](https://colab.research.google.com/gist/Saduf2019/070d315489e20c3fe7f5b6260db062a0/untitled597.ipynb)\r\nPlease share code or colab gist such that we could see the error reported.\r\n\r\nwith respect to error reported, please refer to these links and let us know: [link](https://stackoverflow.com/questions/61550026/valueerror-shapes-none-1-and-none-3-are-incompatible),[link1](https://datascience.stackexchange.com/questions/73827/valueerror-shapes-are-incompatible-when-fitting-using-imagedatagenerator), [link2](https://www.kaggle.com/discussion/197993).", "@saikumarchalla  thank you for replies.I solved the problem. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48680\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48680\">No</a>\n", "@shbkukuk \r\nthank you for your update, glad the issue is resolved."]}, {"number": 48679, "title": "Add Vscode and Github Codespaces devcontainer", "body": "This will copy [our contributed TF devcontainer](https://github.com/microsoft/vscode-dev-containers/pull/381) to this repository to better collect users and Github Codespaces preview testers feedback before [Codespaces GA in Q3](https://github.com/github/roadmap/issues/55)\r\n\r\nFor more context see:\r\nhttps://github.com/microsoft/vscode-dev-containers/issues/713\r\nhttps://docs.github.com/en/github/developing-online-with-codespaces/configuring-codespaces-for-your-project\r\n\r\n/cc @Chuxel @chrmarti @jkeech if you have extra questions on devcontainer/Codespaces.", "comments": ["/cc @theadactyl @nikitamaia", "@gbaned does this look good to you technically? ", "Just a an operative note:\r\nTo make this concretely usable to an average user/contributor we need to control resources and compile time with our \"Contributor Simulator\" Action PR https://github.com/tensorflow/tensorflow/pull/48421", "@bhack Please add some kind of disclaimer to say that this is purely experimental and isn't officially supported.", "> @bhack Please add some kind of disclaimer to say that this is purely experimental and isn't officially supported.\n\nDo we already have a standard disclaimer like this somewhere? So I will just copy the same in the head here.", "How about adding a README.md in the .devcontainer directory with an explanation of what this is and how to maintain it, with a note like\r\n\r\n> This is a community-supported directory. Codespaces is not officially supported by the TensorFlow team. If you have any questions, ask @bhack.", "> How about adding a README.md in the .devcontainer directory with an explanation of what this is and how to maintain it, with a note like\r\n> \r\n> > This is a community-supported directory. Codespaces is not officially supported by the TensorFlow team. If you have any questions, as3k @bhack.\r\n\r\nWhat do you think about what we already have in Google Flax (as It Is a similar domain)? Do you think It could be ok? \r\n\r\nhttps://github.com/google/flax/tree/master/dev\r\n\r\nThen we could add the extra lines related to the community support.", "@angerson Done as in Google flax.\r\n\r\n@Chuxel Sorry but I moved this in a new `dev` directory as the root `.devcontainer` folder is in `.gitignore` now for user customizations. We could review this choice later, when you will have a solution for https://github.com/microsoft/vscode-remote-release/issues/3279. ", "Please use the standard `.devcontainer` directory instead, or `tensorflow/tools/vscode_devcontainer`.", "> Please use the standard `.devcontainer` directory instead, or `tensorflow/tools/vscode_devcontainer`.\r\n\r\nDone. \r\n", "Do you need anything else here?", "Gently ping.", "Weekly ping.", "@angerson Can you please review this PR ? Thanks!", "I'm rejecting this for now. I'm sorry for doing this so late in the review.\r\n\r\nI discussed this with my team. We can't put a \"this is unofficial\" consent form in between this and users, and TF would look bad if it doesn't work. For those kinds of changes, we have to go through a release process, and my team doesn't have the resources to do that right now.\r\n\r\nHowever, we're tracking this feature request to revisit when the team has more resources. (For anyone finding this later: please react with :rocket: if codespaces support would be a big help to you.)", "Thank you. \r\n\r\n> (For anyone finding this later: please react with rocket if codespaces support would be a big help to you.)\r\n\r\nI want just to explain that this PR is not only related to Github Codespaces but more in general to have a quick and reproducible TF dev environment ready for the users of one the most popular IDE (VSCode).\r\n\r\nI perfectly understand the lack of resources motivation but as I've already mentioned in a previous comment here I am sorry that a relatively small Google project in the same AI/ML domain but in the JAX ecosystem can maintain it:\r\nhttps://github.com/google/flax/tree/master/dev\r\n\r\nI would have been ready to maintain it, I hope you will re-evaluate it when you are organized to have a more distributed maintainership on the repository.\r\n", "It is GA now https://github.com/features/codespaces", "A this PR was closed II've added in  my branch `Dockerflie` two lines for the permission on the named volume\r\n```\r\nRUN mkdir -p /home/$USERNAME/.cache/bazel\r\nRUN chown -R $USER_UID:$USER_GID /home/$USERNAME/.cache/\r\n```"]}, {"number": 48678, "title": "Skipping timesteps with ConvLSTM2D layer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux RHEL 7.9\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.0.0 and 2.2.0\r\n- Python version: 3.6.13\r\n\r\n**Describe the current behavior**\r\nI am working with 2D data with a variable number of timesteps, so I padded my data with zeroes and use a masking layer with the ConvLSTM2D layer; however I get an error telling me my dimensions are mismatched (traceback below)\r\n\r\n**Describe the expected behavior**\r\nI would expect the ConvLSTM2D layer to correctly skip the timesteps that have a value of 0 like the regular LSTM layer does. \r\nNote that without the masking layer, the code below runs fine.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import Dense, Flatten, ConvLSTM2D, MaxPooling2D, Masking, Input\r\n\r\ninputs = Input(shape=(None,11,11,1)) \r\nmask = Masking(mask_value=0)(inputs)\r\nconv2d_1 = ConvLSTM2D(64, (3, 3), activation=\"relu\", padding=\"same\")(mask)\r\nmax_pool_1 = MaxPooling2D((2,2), padding=\"same\")(conv2d_1)\r\nflatten = Flatten()(max_pool_1)\r\nout = Dense(1, activation=\"sigmoid\")(flatten)\r\n\r\nx = np.random.rand(64, 300, 11, 11, 1)\r\ny = np.random.randint(2, size=(64,1))\r\n\r\nmodel = Model(inputs=inputs, outputs=out)\r\nmodel.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\r\nmodel.summary()\r\nmodel.fit(x, y, epochs=2, batch_size=16)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1610, in _create_c_op\r\n    c_op = c_api.TF_FinishOperation(op_desc)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Dimension 1 in both shapes must be equal, but are 11 and 121. Shapes are [?,11,11,64] and [?,121,121,64]. for 'Select' (op: 'Select') with input shapes: [?,121,121,64], [?,11,11,64], [?,11,11,64].\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"issue.py\", line 8, in <module>\r\n    conv2d_1 = ConvLSTM2D(64, (3, 3), activation=\"relu\", padding=\"same\")(mask)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional_recurrent.py\", line 299, in __call__\r\n    return super(ConvRNN2D, self).__call__(inputs, **kwargs)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent.py\", line 623, in __call__\r\n    return super(RNN, self).__call__(inputs, **kwargs)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 842, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional_recurrent.py\", line 939, in call\r\n    initial_state=initial_state)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional_recurrent.py\", line 393, in call\r\n    input_length=timesteps)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 4122, in rnn\r\n    **while_loop_kwargs)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 2675, in while_loop\r\n    back_prop=back_prop)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py\", line 198, in while_loop\r\n    add_control_dependencies=add_control_dependencies)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py\", line 176, in wrapped_body\r\n    outputs = body(*_pack_sequence_as(orig_loop_vars, args))\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 4099, in _step\r\n    tiled_mask_t, flat_output, flat_mask_output))\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 4098, in <genexpr>\r\n    array_ops.where(m, o, zo) for m, o, zo in zip(\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\", line 180, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\", line 3753, in where\r\n    return gen_math_ops.select(condition=condition, x=x, y=y, name=name)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 9441, in select\r\n    \"Select\", condition=condition, t=x, e=y, name=name)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 548, in create_op\r\n    compute_device)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3429, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1773, in __init__\r\n    control_input_ops)\r\n  File \"/home/mgeller/.conda/envs/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1613, in _create_c_op\r\n    raise ValueError(str(e))\r\nValueError: Dimension 1 in both shapes must be equal, but are 11 and 121. Shapes are [?,11,11,64] and [?,121,121,64]. for 'Select' (op: 'Select') with input shapes: [?,121,121,64], [?,11,11,64], [?,11,11,64].\r\n```", "comments": ["@maximgeller \r\n\r\nI reproduced the code shared on tf 2.4, tf 2.5rc0 and tf-nightly and didn't get any errors.please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/7c09134e95ca294cb93604be37547be3/-48678.ipynb) here.\r\nCould you please upgrade your tf version and let us know.Thanks\r\n\r\n", "> I reproduced the code shared on tf 2.4, tf 2.5rc0 and tf-nightly and didn't get any errors.please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/7c09134e95ca294cb93604be37547be3/-48678.ipynb) here.\r\n> Could you please upgrade your tf version and let us know.Thanks\r\n\r\nI was successfully able to run the code on the newer TensorFlow version @UsharaniPagadala. However, my project is dependent on the version I tested on, so is there any fix that could work for 2.0.0?\r\n", "update: I was able to run the code using TF 2.2.0 successfully, but I would really like to know if there could be a fix for r2.0", "@maximgeller \r\n\r\nPlease confirm if the issue still persist", "@UsharaniPagadala This is still an issue for me when using r2.0 as that is the version my project is dependent on", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@maximgeller \r\n\r\nCould you please reopen the issue with tf2.0 as it is fixed in tf2.2, and move this to closed status.Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48678\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48678\">No</a>\n"]}, {"number": 48677, "title": " Input and output tensor of .pb file", "body": "Hi,\r\n\r\nI have been trying to get the input and output tensor dtype for a pb model.\r\n```\r\n\r\ndef printTensors(pb_file):\r\n\r\ngraph = tf.Graph()\r\nwith tf.io.gfile.GFile(pb_file, \"rb\") as f:\r\n    graph_def = tf.compat.v1.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\ninput_tensor = graph_def.node[0]\r\noutput_tensor = graph_def.node[-1]\r\nprint(input_tensor.name)\r\nprint(output_tensor.name)\r\n```\r\n\r\nwhen I use the above code and compare against the output of summarize_graph utility there seems to be a mismatch. So my query is graph_def.node[0] is always input and graph_def.node[-1] is output ?\r\n\r\nCheers,\r\nPrabhakar", "comments": ["@prabhakarlad ,\r\n\r\nIn order to reproduce the issue reported here, could you please provide the Tensorflow version,complete code and the dataset you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 48676, "title": "can not install tensorflow", "body": "import tensorflow as tf\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\Home\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n\r\n  File \"<ipython-input-13-64156d691fe5>\", line 1, in <module>\r\n    import tensorflow as tf\r\n\r\n  File \"C:\\Users\\Home\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n\r\n  File \"C:\\Users\\Home\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n\r\n  File \"C:\\Users\\Home\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 114\r\n    def TFE_ContextOptionsSetAsync(arg1, async):\r\n                                             ^\r\nSyntaxError: invalid syntax", "comments": ["@ggproRIC  Could you please provide the  below information:\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nAlso, Please provide the exact sequence of commands that you have executed before running into the error. Thanks!\r\n\r\n", "@ggproRIC  Do  you have any update on this?", "> @ggproRIC Do you have any update on this?\r\n\r\nI solved it. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48676\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48676\">No</a>\n"]}, {"number": 48674, "title": "Update cmsis_nn readme", "body": "This PR updates the cmsis-nn README so that the instructions for compiling the person_detection example for disco_f746ng work.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48672, "title": "Efficient upsampling 3D Volume with linear interpolation options", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): tensorflow2.0\r\n- Are you willing to contribute it (Yes/No): No. I was trying to vectorize it, but I failed with out of GPU memory error. My GPU is tesla V100, memory 32G. Volume size = [128, 256, 256, 3] / want to upsampling it to [256, 256, 512, 3] by interpolation. \r\n\r\n**Describe the feature and the current behavior/state.**\r\nUpsample image by trilinear / cubic-spline interpolation\r\n\r\n**Will this change the current api? How?**\r\nNo\r\n\r\n**Who will benefit with this feature?**\r\nMost of people who are working with 3D data.  \r\n\r\n**Any Other info.**\r\nI will appreciate any efficient implementation advices for implementing it in a vectorized way. ", "comments": [">No. I was trying to vectorize it, but I failed with out of GPU memory error.\r\n\r\n@XXZhou25,\r\nCould you please provide a minimal code snippet of the use-case you are trying to implement, so that we can look into it. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 48670, "title": "SavedModel file does not exist at", "body": "Cannot load model whereas it does exist at the specified location.\r\n\r\nI'm using tf.keras.models.load_model(PATH_TO_FILE) to do so, like it's explained [here](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format), but it keeps on throwing:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Rasp\\project\\main.py\", line 37, in <module>\r\n    model = tf.keras.models.load_model(PATH_TO_FILE)\r\n  File \"C:\\Users\\me\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\", line 206, in load_model\r\n    return saved_model_load.load(filepath, compile, options)\r\n  File \"C:\\Users\\me\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py\", line 121, in load\r\n    meta_graph_def = loader_impl.parse_saved_model(path).meta_graphs[0]\r\n  File \"C:\\Users\\me\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 113, in parse_saved_model\r\n    raise IOError(\r\nOSError: SavedModel file does not exist at: C:\\Rasp\\experts_bit_r50x1_in21k_bird_1\\saved_model.pb\\{saved_model.pbtxt|saved_model.pb}\r\n\r\nI tried with some of the models [here](https://tfhub.dev/s?q=bird).", "comments": ["I needed to target to wrapping folder, not the file.", "@worknotalent Can you share the code? It will be helpful to see where the error is occurring.\r\nThanks", " Try using `hub.load()` to [load](https://www.tensorflow.org/hub/api_docs/python/hub/load) models from TF Hub.\r\nSee [gist](https://colab.research.google.com/gist/ymodak/304c5d8adad525a7da868cf5f61ce602/untitled17.ipynb) that explains the usage.", "@worknotalent ,\r\n\r\nPlease take a look at @[ymodak](https://github.com/tensorflow/tensorflow/issues/48670#issuecomment-824195656)   comment and let us know if you are still facing the same issue? Thanks!", "Sorry, I was just targetting the file instead of the containing folder, but anyways I discovered `hub.load()` and it works just fine, I'm just having a problem when I choose another model from the one used in the tutorial I followed:\r\n\r\n`Traceback (most recent call last):\r\n  File \"C:\\RealTimeObjectDetection\\h.py\", line 154, in <module>\r\n    run_detector(detector, downloaded_image_path)\r\n  File \"C:\\RealTimeObjectDetection\\h.py\", line 137, in run_detector\r\n    result = detector(converted_img)\r\n  File \"C:\\Users\\axelc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1711, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"C:\\Users\\axelc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py\", line 246, in _call_impl\r\n    return super(WrappedFunction, self)._call_impl(\r\n  File \"C:\\Users\\axelc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1729, in _call_impl\r\n    return self._call_with_flat_signature(args, kwargs, cancellation_manager)\r\n  File \"C:\\Users\\axelc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1778, in _call_with_flat_signature\r\n    return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n  File \"C:\\Users\\axelc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1960, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"C:\\Users\\axelc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 591, in call\r\n    outputs = execute.execute(\r\n  File \"C:\\Users\\axelc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  Matrix size-incompatible: In[0]: [1,239360], In[1]: [1280,965]\r\n         [[node Logits/BiasAdd (defined at Users\\axelc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\module_v2.py:106) ]] [Op:__inference_pruned_3535]\r\n\r\nFunction call stack:\r\npruned`\r\n\r\nThe problem doesn't occur while loading the model from the hub but when I pass it an image, I'm pretty sure it's because of the shape of the image.\r\n\r\nIs the wanted shape somewhere inside the loaded model?", "@worknotalent ,\r\n\r\nCould you please confirm if the issue is resolved. if yes, please feel free to move this issue to closed status and please submit a new issue from this [link](https://github.com/tensorflow/models/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48670\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48670\">No</a>\n"]}, {"number": 48669, "title": "TFLM: Add Ethos-U support to FVP target", "body": "* Update Arm Corstone-300, Ethos-U Driver and Ethos-U Core Platform\r\n  download versions.\r\n* Default model in network tester is converted for Ethos-U.\r\n* Use Ethosu-U in CI script for FVP target.\r\n\r\nThis is fixing: https://github.com/tensorflow/tensorflow/issues/48668\r\nProgress towards: https://github.com/tensorflow/tensorflow/issues/47070", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@advaitjain As discussed, we keep the default model in the network tester example, and just have it converted for the Ethos-U code path.", "Let's see if the import process passes this time. If not, it might be worth updating the PR to tip of tree."]}, {"number": 48668, "title": "Missing support for Ethos-U for FVP target", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source): d73d688687e48a29f06c84404f9817876e4b6325\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): FVP (cortex_m_corstone_300)\r\n\r\n**Describe the problem**\r\nFor the FVP (cortex_m_corstone_300) there is no support for Ethos-U. It is only possible to build the microlite lib with Ethos-U and with the FVP target one can build a binary but without Ethos-U enabled.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": []}, {"number": 48667, "title": "[mlir-hlo] Added RegionBranchOpInterfaces to lmhlo operations.", "body": "Added RegionBranchOpInterfaces to lmhlo operations that use regions.\r\nThis is needed, since the bufferization features in MLIR have to reason about the control flow within these operations.", "comments": ["@timshen91 Several analyses and runs within MLIR were designed with the `RegionBranchOpInterface` in mind. One of the underlying ideas was that any operation that has at least one region (excluding operations that do not return results) must implement this interface. If this invariant does not hold in general, some MLIR control-flow-based analyses cannot be successfully applied (including `BufferDeallocation`). This raises the question of whether this PR should also add \"proper\" implementations of `RegionBranchOpInterface` to the \"remaining\" operations....\r\n\r\nOn the one hand, one can argue that the implementation of `RegionBranchOpInterface` is generally not required for operations that have only a single region (as outlined above). On the other hand, it can be argued that a region attached to, say, the `Map` operation is called successively until each element is transformed from a high-level point of view in theory. This would form an implicit loop \"hidden\" within the operation. Alternatively, you can claim that this does not form a loop in general and should not be \"exposed to other transformations\". What do you think about this \ud83d\ude03 ?", "> This raises the question of whether this PR should also add \"proper\" implementations of `RegionBranchOpInterface` to the \"remaining\" operations....\r\n\r\nI guess it depends on what exactly `RegionBranchOpInterface` is used for. As @sherhut mentioned, it's modeled after classical conditionals and sequential loops, not parallel loops (e.g. Map) or associative folding (e.g. Reduce). I'm leaning towards delaying it until we have a concrete use case, but maybe you already have one?", "> > This raises the question of whether this PR should also add \"proper\" implementations of `RegionBranchOpInterface` to the \"remaining\" operations....\r\n> \r\n> I guess it depends on what exactly `RegionBranchOpInterface` is used for. As @sherhut mentioned, it's modeled after classical conditionals and sequential loops, not parallel loops (e.g. Map) or associative folding (e.g. Reduce). I'm leaning towards delaying it until we have a concrete use case, but maybe you already have one?\r\n\r\nUltimately all operations with a region need to implement this interface to model control flow. We can leave it out of this PR for now to unblock the work and make progress. But even then, if these operations appear in a program, we cannot guarantee correctness of the analysis because the regions have undefined control flow.", "Although these interfaces were originally developed to model classical control flow, we share @sherhut's point that each operation with a nested region must implement this interface. As @sherhut also mentioned, we cannot guarantee the correctness of various control flow-based analyses that could be applied to these operations.\r\n\r\nWhat we could do is omit these changes for now, as suggested. However, we should think about implementing this interface in a follow-up PR to avoid possible problems with control-flow-based transformations in the future.", "After a short offline discussion with @sherhut about different possibilities how to implement the `RegionBranchOpInterface`, we think that we first include interface implementations for the \"basic\" control-flow-dependent operations in the scope of this PR. Further extensions can be discussed in a separate issue \ud83e\udd13 "]}, {"number": 48666, "title": "Cadence HiFi 5 NN Library v1.5.0 integration", "body": "Integrate the HiFi 5 Neural Network Library v1.5.0\r\nUsed HiFi 5 NN Library kernel for fully_connected operator int8 variant.\r\n\r\nSigned-off-by: Anirban Mandal <amandal@cadence.com>\r\nSigned-off-by: Biswa Dhal <bdhal@cadence.com>\r\nSigned-off-by: Bhanu Prakash Bandaru Venkata <bhanup@cadence.com>\r\nSigned-off-by: Chaitanya Sanjay Muley <cmuley@cadence.com>\r\nSigned-off-by: Harinarayanan E V <hariev@cadence.com>\r\nSigned-off-by: Harshavardhan Ravindra Joshi <joshih@cadence.com>\r\nSigned-off-by: Prasad Nikam <pnikam@cadence.com>", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48665, "title": "Keras experimental preprocessing layers with random seed does not yield the same results after a few call", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tested on Linux Ubuntu 18.04 and Google Colab\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: Tested on Python 3.6.12 and Python 3.7.10\r\n- CUDA/cuDNN version: Tested on cuda 11.1 and cuda 11.2\r\n- GPU model and memory: gtx TITAN V / Tesla T4 (for colab)\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nCreating two sequential only with `tf.keras.layers.experimental.preprocessing.Random*` layers with the same seed start by producing the same output, but after a few calls they do not.\r\n\r\n- First few calls:\r\n![image](https://user-images.githubusercontent.com/25057256/115542065-28541c00-a2a0-11eb-8875-9f77248fca1d.png)\r\n- After multiple calls:\r\n![image](https://user-images.githubusercontent.com/25057256/115542168-4ae63500-a2a0-11eb-8d1a-9f3e87230895.png)\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect the layers to produce the same output every time.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nI have created a Colab Notebook to reproduce the bug. Please make sure that a gpu is enabled:\r\nhttps://colab.research.google.com/drive/1Hi98IwkW466ziXlXKKx9uoQwe4jSrUqC?usp=sharing\r\n\r\n**Other info / logs Include any logs or source code that would be helpful to**\r\n\r\nIt seems to work properly when not using a gpu intance on Google Colab.\r\nCloning the model (using `tf.keras.models.clone_model` or duplicating the model code produce the same bug.", "comments": ["@GuichardVictor \r\nI ran your code on latest version of tf [2.6.0-dev20210421], this seems to have been fixed, please refer to [the gist and confirm](https://colab.research.google.com/gist/Saduf2019/faf2b60aedbbc8cc391d94a458583619/untitled589.ipynb)", "@Saduf2019\n\nI can confirm that it is working properly on both my machine and Google colab with this tensorflow version installed.\n\nThanks! ", "@GuichardVictor \r\nThank you for your update, glad its working fine for you, kindly move this issue to closed status as it is resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48665\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48665\">No</a>\n"]}]