[{"number": 30516, "title": "[Intel MKL] Fix 4 autograph unit test failures (Intel MKL public ci: \u2026", "body": "\u2026https://tensorflow-ci.intel.com/job/tensorflow-mkl-linux-cpu/) by adding no_oss_py2 flag:\r\n\r\n//tensorflow/python/autograph/impl:api_py3_test\r\n//tensorflow/python/autograph/pyct/static_analysis:activity_py3_test\r\n//tensorflow/python/autograph/pyct/static_analysis:liveness_py3_test\r\n//tensorflow/python/autograph/pyct/static_analysis:reaching_definitions_py3_test\r\nWith this fix, PY3 w/ bazel is not affected. PY2 w/ bazel will filter\r\nthese unit tests out, therefore they no longer fail.", "comments": ["@penpornk Could you please help review this size:XS PR as well? Thanks!", "Thanks @penpornk for your review! Yes, let's wait for @gunan "]}, {"number": 30515, "title": "Convert Tensorflow Model to Tensorflow Lite Format Model", "body": "Convert Tensorflow Model to Tensorflow Lite Format [Conversion + Build]\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS High Sierra 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Anaconda Navigator\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.7.0\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: No \r\n\r\nI trained my custom model for tensorflow by following this tutorial\r\nhttps://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\r\nI made all the code work in macOS\r\nI got the output with python code.\r\n\r\nMy query here is \r\nI need to run my model in unity through TensorflowLite Plugin\r\nSo, I have to convert my tensorflow model to tensorflow lite format\r\nMy model's size is 55.5Mb \r\nI need help, How to convert my model to tensorflow lite model \r\n\r\n", "comments": ["This question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!"]}, {"number": 30514, "title": "Operators not supported by the standard TensorFlow Lite runtime", "body": "I tried a very small model that is as follows : \r\nmodel_input = Input(shape=(max_sequence_len,))\r\nX = Embedding(num_words, word_embedding_dimensions, weights = [embedding_matrix], trainable = False)(model_input)\r\nX = Flatten()(X)\r\nX = Dense(1, activation='sigmoid')(X)\r\nmodel = Model(inputs = model_input, outputs = X)\r\nmodel.summary()\r\n\r\nWhen converting my Keras model to tensorflow lite model I received message saying paste the following here - \r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CAST, FULLY_CONNECTED, LOGISTIC. Here is a list of operators for which you will need custom implementations: ResourceGather.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\udits\\Anaconda3\\Scripts\\toco_from_protos-script.py\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"C:\\Users\\udits\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 59, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Users\\udits\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\udits\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 33, in execute\r\n    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CAST, FULLY_CONNECTED, LOGISTIC. Here is a list of operators for which you will need custom implementations: ResourceGather.\r\n\r\n", "comments": ["@uditadhikari Please provide us the your tensorflow version. Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30513, "title": "TF2-gpu: tf.distribute cause crash when using RNN model,", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from  binary:\r\n- TensorFlow version (use command below): v1.12.1-5670-g718503b075 2.0.0-dev20190707\r\n- Python version: 3.6.4\r\n- CUDA/cuDNN version: CUDA-10.0/ Cudnn7.6.1\r\n- GPU model and memory: 3 Titan XP\r\n\r\ntf.distribute cause crash when using RNN model, work fine when using CNN.\r\n\r\n if  \"with mirrored_strategy.scope():\"  removed, The code below can work well.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntotal_data_size = 10000\r\nX = np.random.randint(100, size=(total_data_size, 100, 20)) / 100\r\nX = X.astype(np.float32)\r\nY = np.random.randint(2, size=(total_data_size)).astype(\r\n    np.int32)\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices((X, Y))\r\ndataset = dataset.batch(12)\r\n\r\nmirrored_strategy = tf.distribute.MirroredStrategy()\r\nwith mirrored_strategy.scope():\r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.LSTM(64),\r\n        tf.keras.layers.Dense(64, activation='relu'),\r\n        tf.keras.layers.Dense(3, activation='sigmoid')\r\n    ])\r\n    model.compile(loss='sparse_categorical_crossentropy',\r\n                  optimizer=tf.keras.optimizers.Adam(),\r\n                  metrics=['accuracy'])\r\n    model.fit(dataset)\r\n```\r\n\r\n**logs**\r\n\r\nApply a constraint manually following the optimizer update step.\r\n2019-07-09 12:01:15.720305: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] implementation_selector failed: Invalid argument: Invalid format of input node name: replica_1/sequential/lstm/StatefulPartitionedCall_replica_1/StatefulPartitionedCall_0 Expected: {forward_node_name}:{index}\r\n2019-07-09 12:01:16.056015: W tensorflow/core/grappler/optimizers/implementation_selector.cc:199] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_8517_9019' and '__inference___backward_standard_lstm_8517_9019_specialized_for_replica_2_StatefulPartitionedCall_at___inference_distributed_function_9976' both implement 'lstm_e2ea6704-e320-4be8-b8e0-8ad71afc296b' but their signatures do not match.\r\n2019-07-09 12:01:16.282647: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1558] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n2019-07-09 12:01:16.325991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-07-09 12:01:16.940501: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at partitioned_function_ops.cc:113 : Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:2 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\n2019-07-09 12:01:16.940501: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at partitioned_function_ops.cc:113 : Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:0 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\n2019-07-09 12:01:16.940560: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:0 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\n\t [[{{node sequential/lstm/StatefulPartitionedCall}}]]\r\n2019-07-09 12:01:16.940597: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:2 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\n\t [[{{node replica_2/sequential/lstm/StatefulPartitionedCall}}]]\r\n\t [[GroupCrossDeviceControlEdges_0/Adam/Adam/update_1_1/Const/_143]]\r\n2019-07-09 12:01:16.940632: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:2 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\n\t [[{{node replica_2/sequential/lstm/StatefulPartitionedCall}}]]\r\n\t [[metrics/accuracy/div_no_nan/ReadVariableOp_1/_110]]\r\n2019-07-09 12:01:16.940810: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:2 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\n\t [[{{node replica_2/sequential/lstm/StatefulPartitionedCall}}]]\r\n2019-07-09 12:01:16.943854: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at partitioned_function_ops.cc:113 : Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:1 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\nTraceback (most recent call last):\r\n  File \"test_run.py\", line 25, in <module>\r\n    model.fit(dataset)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 668, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 680, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 294, in model_iteration\r\n    batch_outs = f(actual_inputs)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py\", line 854, in execution_function\r\n    return [out.numpy() for out in distributed_function(input_fn)]\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 429, in __call__\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1662, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 635, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 733, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 459, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:0 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\n\t [[node sequential/lstm/StatefulPartitionedCall (defined at /usr/local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1654) ]]\r\n  (1) Invalid argument:  Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:2 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\n\t [[node replica_2/sequential/lstm/StatefulPartitionedCall (defined at /usr/local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1654) ]]\r\n0 successful operations.\r\n2 derived errors ignored. [Op:__inference_distributed_function_9976]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function\r\n\r\n", "comments": ["Note: this is being discussed in issue #29189.", "The distribution strategy with RNN issue should be resolved now in the latest nightly. Please try to test again. Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30513\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30513\">No</a>\n"]}, {"number": 30512, "title": "`tf.keras.layers.RNN` is very different from `tf.nn.dynamic_rnn`", "body": "In the documentation of [`tf.nn.dynamic_rnn`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn), it gives such a warning saying:\r\n\r\n> Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version. \r\n> Instructions for updating: Please use keras.layers.RNN(cell), which is equivalent to this API\r\n\r\nBUT when I checked [`tf.keras.layers.RNN(cell)`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN), I found an important feature of `tf.nn.dynamic_rnn` is lost, which enables users to deal with sequences of variable lengths.\r\n\r\n```\r\ntf.nn.dynamic_rnn(\r\n    cell,\r\n    inputs,\r\n    sequence_length=None,\r\n    initial_state=None,\r\n    dtype=None,\r\n    parallel_iterations=None,\r\n    swap_memory=False,\r\n    time_major=False,\r\n    scope=None\r\n)\r\n```\r\n\r\nHere `sequence_length` can be a tensor which indicating the length of the sequences. Let's see the API of `tf.keras.layers.RNN`:\r\n\r\n```\r\n__init__(\r\n    cell,\r\n    return_sequences=False,\r\n    return_state=False,\r\n    go_backwards=False,\r\n    stateful=False,\r\n    unroll=False,\r\n    time_major=False,\r\n    **kwargs\r\n)\r\n```\r\n\r\nThere is actually no such an argument. If I want to deal with variant-length sequences, I have to do a lot of work myself. So I still would like to use `tf.nn.dynamic_rnn` rather than `tf.keras.layers.RNN`.\r\n\r\n\r\nAfter all, I think as the arguments and funcationality is different, \r\n\r\n> keras.layers.RNN(cell), which is equivalent to this API\r\n\r\nis really a very big mistake. And please keep `tf.nn.dynamic_rnn` and remove it from deprecated functions.", "comments": ["There is an arg called `mask` in the `__call__` of `tf.keras.layers.RNN`, you can build a mask from `sequence_length `(use `tf.sequence_mask` to do so) and pass the mask to this arg. BTW, subclasses of `tf.keras.layers.RNN` like `tf.keras.layers.GRU` can work with GPU and cuda, but `tf.nn.dynamic_rnn` only works with CPU.", "how about the feature swap_memory? it seems that tf.keras.layers.RNN does not provide this flag"]}, {"number": 30511, "title": "Unsupported data type (DT_BOOL) given to Fill op with output", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 1.14.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n2019-07-09 11:44:07.354104: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2019-07-09 11:44:09.016434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:02:00.0\r\n2019-07-09 11:44:09.017804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:03:00.0\r\n2019-07-09 11:44:09.017884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.019209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:83:00.0\r\n2019-07-09 11:44:09.019280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.020624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:84:00.0\r\n2019-07-09 11:44:09.020953: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-07-09 11:44:09.023323: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-07-09 11:44:09.024759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-07-09 11:44:09.025100: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-07-09 11:44:09.027096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-07-09 11:44:09.028651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-07-09 11:44:09.033522: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-07-09 11:44:09.036355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.037640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.041685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.042985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.044219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3\r\n2019-07-09 11:44:09.341294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.351801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.353487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2295610 executing computations on platform CUDA. Devices:\r\n2019-07-09 11:44:09.353521: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX TITAN X, Compute Capability 5.2\r\n2019-07-09 11:44:09.353534: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX TITAN X, Compute Capability 5.2\r\n2019-07-09 11:44:09.353544: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): GeForce GTX TITAN X, Compute Capability 5.2\r\n2019-07-09 11:44:09.353554: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): GeForce GTX TITAN X, Compute Capability 5.2\r\n2019-07-09 11:44:09.357486: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499990000 Hz\r\n2019-07-09 11:44:09.358742: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49190f0 executing computations on platform Host. Devices:\r\n2019-07-09 11:44:09.358787: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-07-09 11:44:09.360901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:02:00.0\r\n2019-07-09 11:44:09.362217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:03:00.0\r\n2019-07-09 11:44:09.362286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.363528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:83:00.0\r\n2019-07-09 11:44:09.363597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.364844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:84:00.0\r\n2019-07-09 11:44:09.364909: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-07-09 11:44:09.364934: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-07-09 11:44:09.364955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-07-09 11:44:09.364977: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-07-09 11:44:09.364998: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-07-09 11:44:09.365019: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-07-09 11:44:09.365042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-07-09 11:44:09.367704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.368961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.372683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.373913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.375125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3\r\n2019-07-09 11:44:09.375170: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-07-09 11:44:09.380638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-09 11:44:09.380661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3\r\n2019-07-09 11:44:09.380672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N\r\n2019-07-09 11:44:09.380685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N\r\n2019-07-09 11:44:09.380695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y\r\n2019-07-09 11:44:09.380704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N\r\n2019-07-09 11:44:09.385795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.386981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.389401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11497 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:09.391171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11498 MB memory) -> physical GPU (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:09.392493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.393664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 11498 MB memory) -> physical GPU (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:09.394220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:09.395385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 11498 MB memory) -> physical GPU (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:84:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:11.354423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.356293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.358071: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 4\r\n2019-07-09 11:44:11.358226: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n2019-07-09 11:44:11.361961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:02:00.0\r\n2019-07-09 11:44:11.363679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:03:00.0\r\n2019-07-09 11:44:11.363774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.365461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:83:00.0\r\n2019-07-09 11:44:11.365554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.367225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:84:00.0\r\n2019-07-09 11:44:11.367299: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-07-09 11:44:11.367336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-07-09 11:44:11.367365: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-07-09 11:44:11.367392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-07-09 11:44:11.367420: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-07-09 11:44:11.367448: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-07-09 11:44:11.367477: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-07-09 11:44:11.370909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.372651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.377451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.379093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.380741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3\r\n2019-07-09 11:44:11.380985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-09 11:44:11.381010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3\r\n2019-07-09 11:44:11.381024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N\r\n2019-07-09 11:44:11.381041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N\r\n2019-07-09 11:44:11.381055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y\r\n2019-07-09 11:44:11.381068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N\r\n2019-07-09 11:44:11.387871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.389460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.392539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11497 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:11.394104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11498 MB memory) -> physical GPU (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:11.394198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.395746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 11498 MB memory) -> physical GPU (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:11.395841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:11.397369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 11498 MB memory) -> physical GPU (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:84:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:14.068140: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n2019-07-09 11:44:14.068230: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 2203 nodes (-39), 3277 edges (-74), time = 1373.11206ms.\r\n2019-07-09 11:44:14.068249: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 2203 nodes (0), 3277 edges (0), time = 725.973ms.\r\n2019-07-09 11:44:14.068300: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: layer_norm_compute_TsrF4cwFbXs\r\n2019-07-09 11:44:14.068329: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 17 nodes (0), 19 edges (0), time = 0.917ms.\r\n2019-07-09 11:44:14.068446: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 17 nodes (0), 19 edges (0), time = 0.531ms.\r\n2019-07-09 11:44:14.068463: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: layer_norm_compute_grad_ZL8R5wqcdys\r\n2019-07-09 11:44:14.068473: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 129 nodes (-1), 187 edges (-2), time = 11.934ms.\r\n2019-07-09 11:44:14.068482: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 129 nodes (0), 187 edges (0), time = 6.312ms.\r\nTraceback (most recent call last):\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/bin/tflite_convert\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/local/lib/python2.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 503, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/local/lib/python2.7/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/local/lib/python2.7/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/local/lib/python2.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 499, in run_main\r\n    _convert_tf1_model(tflite_flags)\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/local/lib/python2.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 193, in _convert_tf1_model\r\n    output_data = converter.convert()\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/local/lib/python2.7/site-packages/tensorflow/lite/python/lite.py\", line 898, in convert\r\n    **converter_kwargs)\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/local/lib/python2.7/site-packages/tensorflow/lite/python/convert.py\", line 404, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/home/hh1208-kang/venv_py2_tf1.13/local/lib/python2.7/site-packages/tensorflow/lite/python/convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-07-09 11:44:19.974693: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2019-07-09 11:44:20.292118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.295593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.306852: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f20b60 executing computations on platform CUDA. Devices:\r\n2019-07-09 11:44:20.306883: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX TITAN X, Compute Capability 5.2\r\n2019-07-09 11:44:20.306893: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX TITAN X, Compute Capability 5.2\r\n2019-07-09 11:44:20.306900: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): GeForce GTX TITAN X, Compute Capability 5.2\r\n2019-07-09 11:44:20.306911: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): GeForce GTX TITAN X, Compute Capability 5.2\r\n2019-07-09 11:44:20.311504: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499990000 Hz\r\n2019-07-09 11:44:20.312575: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b8d9fb0 executing computations on platform Host. Devices:\r\n2019-07-09 11:44:20.312601: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-07-09 11:44:20.314507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:02:00.0\r\n2019-07-09 11:44:20.315699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:03:00.0\r\n2019-07-09 11:44:20.315760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.316951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:83:00.0\r\n2019-07-09 11:44:20.317011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.318192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:84:00.0\r\n2019-07-09 11:44:20.318493: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-07-09 11:44:20.320081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-07-09 11:44:20.321322: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-07-09 11:44:20.321617: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-07-09 11:44:20.323431: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-07-09 11:44:20.324827: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-07-09 11:44:20.329388: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-07-09 11:44:20.331962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.333203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.336847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.338058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.340613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3\r\n2019-07-09 11:44:20.340677: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-07-09 11:44:20.345904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-09 11:44:20.345928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3\r\n2019-07-09 11:44:20.345939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N\r\n2019-07-09 11:44:20.345947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N\r\n2019-07-09 11:44:20.345954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y\r\n2019-07-09 11:44:20.345961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N\r\n2019-07-09 11:44:20.350971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.352193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.354601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11402 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:20.357821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11404 MB memory) -> physical GPU (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:20.358888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.361068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 11404 MB memory) -> physical GPU (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:20.362854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-07-09 11:44:20.365024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 11404 MB memory) -> physical GPU (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:84:00.0, compute capability: 5.2)\r\n2019-07-09 11:44:20.601403: I tensorflow/lite/toco/import_tensorflow.cc:2201] Found and inlined TensorFlow functions.\r\n2019-07-09 11:44:20.739944: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740059: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740088: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740111: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740134: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740159: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740182: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740205: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740228: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740250: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740272: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740313: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740336: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740359: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740382: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740404: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740427: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740450: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740472: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740495: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740518: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740540: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740562: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740586: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740609: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740631: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740653: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740676: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740699: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740723: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740746: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740769: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740793: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740815: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740838: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740861: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740884: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740908: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740931: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740954: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740976: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.740999: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741023: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741045: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741068: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741095: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741118: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741142: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741165: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741189: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741212: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741236: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741259: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741282: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741305: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741328: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741351: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741373: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741396: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741419: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741441: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741465: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741487: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741509: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741535: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741558: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741580: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741602: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741625: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741647: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741671: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741694: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741718: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741741: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741764: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741788: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741811: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741834: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741856: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741880: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741902: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741924: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741947: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741969: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.741992: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742015: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742037: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742060: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742082: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742105: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742126: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742148: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742171: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742193: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742216: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742238: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742261: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742284: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742307: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742330: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742353: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742376: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742398: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742421: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742444: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742465: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742487: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742510: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742532: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742556: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742579: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742603: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742626: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742649: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742673: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742696: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742719: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742742: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742764: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742787: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742808: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742832: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742855: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742878: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742901: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742924: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742946: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742968: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.742993: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743015: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743038: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743060: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743082: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743105: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743127: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743150: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743172: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743195: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743217: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743239: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743261: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743283: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743305: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743327: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743349: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743372: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743394: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743417: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743439: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743461: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743482: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743503: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743524: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743545: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743566: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743588: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743610: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743631: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743654: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743676: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743697: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743719: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743741: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743762: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743784: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743806: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743827: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743851: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743873: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743896: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743917: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743940: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743963: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.743985: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744006: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744028: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744048: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744069: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744090: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744112: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744133: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744154: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744175: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744197: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744218: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744240: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744261: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744288: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744313: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744334: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744356: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744378: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744399: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744421: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744708: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744744: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744788: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744811: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744837: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744873: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.744901: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-09 11:44:20.745001: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n2019-07-09 11:44:20.745064: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-07-09 11:44:20.745093: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-07-09 11:44:20.745119: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-07-09 11:44:20.887269: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: MatrixBandPart\r\n2019-07-09 11:44:20.892202: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: IsFinite\r\n2019-07-09 11:44:21.047492: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1559 operators, 2697 arrays (0 quantized)\r\n2019-07-09 11:44:21.127085: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1366 operators, 2311 arrays (0 quantized)\r\n2019-07-09 11:44:21.214208: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1366 operators, 2311 arrays (0 quantized)\r\n2019-07-09 11:44:21.217270: F **tensorflow/lite/toco/graph_transformations/resolve_constant_fill.cc:107] Unsupported data type given to Fill op with output \"zeros_2\"**\r\nAborted (core dumped)\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\nI cannot post the whole GraphDef but I think this part seems problem.\r\n\r\nnode {\r\n  name: \"zeros_2\"\r\n  op: \"Fill\"\r\n  input: \"zeros_2/packed\"\r\n  input: \"zeros_2/Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      **type: DT_BOOL**\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_output_shapes\"\r\n    value {\r\n      list {\r\n        shape {\r\n          dim {\r\n            size: -1\r\n          }\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"index_type\"\r\n    value {\r\n      type: DT_INT32\r\n    }\r\n  }\r\n}\r\n\r\n\r\n**Any other info / logs**\r\n\r\n\r\n'tflite_convert' complains about the data type 'DT_BOOL', while it dealt with 'DT_INT32', 'DT_FLOAT' in other Fill ops in different nodes.\r\n\r\nHow can I avoid this? I wonder if there exist a way that change the type, and is it safe or not.\r\n", "comments": ["I solved the problem by removing the related operation from the computing graph.\r\nThe operation is a part of the auto-regressive sequence decoding.\r\n\r\nThe operation is looked like following:\r\n...\r\nfinished_flags = tf.zeros([batch_size, beam_size], tf.bool)\r\n...\r\n\r\np.s. By removing the decoding part from my model, the message about Enter, LoopCond, Exit and IsFinite were removed from the tflite_convert output.\r\n\r\nHowever, MatrixBandPart op is still exist, so I'm working on it.\r\n\r\n2019-07-09 11:44:20.887269: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: MatrixBandPart"]}, {"number": 30510, "title": "Validate max_batch_size only in static mode", "body": "- Dynamic mode doesn't use max_batch_size at all. So we shouldn't validate it neither.\r\n- Do not change max_batch_size under the hood, let user make that change.\r\n- Log a message in case max_batch_size is larger than the batch size in the model to warn about performance impact.", "comments": ["@pooyadavoodi Did you get a chance to look on reviewer comments? Please let us know on the update. Thanks! "]}, {"number": 30509, "title": "Official windows pip package build settings could be better", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.7.0\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nThe build settings for the Tensorflow package produced and distributed via pip for windows aren't using the compiler flags that would result in optimal performance. I.e. the pip distributed package doesn't appear to use AVX2 instructions.\r\n\r\nGiven this, we suspect the package is also not built using LTCG, fp:fast, the new /Ob3 inlining, or the new exception handling /FH4 flags. A nice performance win (and binary size win in the case of /FH4) ought to come out of the small change of simply throwing the appropriate flags.\r\n\r\n\r\n**Any other info / logs**\r\nOutput from running Tensorflow models on MLPerf: \"Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\"", "comments": ["On all platforms, we aim to build packages that can run on the widest range of machines.\r\nTherefore, we intentionally only build with AVX support.\r\nTherefore, for performance we recommend building TF from sources."]}, {"number": 30508, "title": "add test value of test_default_value_saved_as_tuple and test_dtype_should_be_string_or_integer", "body": "", "comments": []}, {"number": 30507, "title": "Add NCCL check for XLA", "body": "Addresses issue #29886 by replacing the if_cuda checks with if_nccl, and exporting GOOGLE_NCCL similarly to GOOGLE_CUDA and GOOGLE_TENSORRT", "comments": ["Thanks for the review, just addressed the comment, let me know if I should do anything else.", "@sanjoy This LGTM, just wanted to bring this to your attention since you proposed the fix and may want to take a look yourself.", "Sounds good; does this look ready to merge in?", "Looks like an internal test is failing @aaroey is taking a look.", "@MattConley can you please resolve conflicts ?", "@rthadur Just addressed the conflict, thanks.\r\n@thomasjoerg Are we good to merge this in?", "Can one of the admins verify this patch?", "@MattConley sorry it did not merge last time , can you please resolve conflicts again so that we can import .", "I've implemented this slightly differently in commit 9b9bea65159eea4c8452d7f8b702b32dcb3cea8e. I'm closing this PR. Feel free to reopen if it doesn't work as expected."]}, {"number": 30506, "title": "[ROCm] Skipping subtests that check bit pattern result from zero division", "body": "ROCm platform currently does not produce the same (as CUDA platform) bit pattern result from zero division.\r\n\r\nThis commit skips subtests (within python unit-tests) that test this functionality. The \"skip\" is guarded by the call to \"is_built_with_rocm()\", and hence these unit-tests will not be affected in any way when running with TF which was not built with ROCm support (i.e. `--config=rocm`)\r\n\r\n-----------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n", "comments": []}, {"number": 30505, "title": "[ROCm] Skipping subtests that check support for int8x4 type (on the GPU)", "body": "ROCm platform currently does not support int8x4 type (on the GPU)\r\n\r\nThis commit skips subtests (within python unit-tests) that test this functionality. The \"skip\" is guarded by the call to \"is_built_with_rocm()\", and hence these unit-tests will not be affected in any way when running with TF which was not built with ROCm support (i.e. `--config=rocm`)\r\n\r\n---------------------------------\r\n\r\n@tatianashp @whchung @chsigg ", "comments": []}, {"number": 30504, "title": "[ROCm] Skipping subtests that check support for NAN propagation in the NN ops", "body": "ROCm platform currently does not support the NAN propagation in the NN ops\r\n\r\nThis commit skips subtests (within python unit-tests) that test this functionality. The \"skip\" is guarded by the call to \"is_built_with_rocm()\", and hence these unit-tests will not be affected in any way when running with TF which was not built with ROCm support (i.e. `--config=rocm`)\r\n\r\n---------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n\r\n--------------------------------------------\r\n\r\nupdating descriptions as per discussion with @whchung \r\n\r\nThe second commit in this PR contains a fix for what seems to be a string format specification bug, which results in the following error \r\n```\r\n--- Logging error ---                                                                                                                                                                                                                                                                                                                            \r\nTraceback (most recent call last):                                                                                                                                                                                                                                                                                                               \r\n  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit                                                                                                                                                                                                                                                                               \r\n    msg = self.format(record)                                                                                                                                                                                                                                                                                                                    \r\n  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format                                                                                                                                                                                                                                                                             \r\n    return fmt.format(record)                                                                                                                                                                                                                                                                                                                    \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/absl_py/absl/logging/__init__.py\", line 928, in format                    \r\n    return prefix + super(PythonFormatter, self).format(record)                                                                                                                                                                                                                                                                                  \r\n  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format                                                                                                                                                                                                                                                                             \r\n    record.message = record.getMessage()                                                                                                                                                                                                                                                                                                         \r\n  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage                                                                                                                                                                                                                                                                         \r\n    msg = msg % self.args                                                                                                                                                                                                                                                                                                                        \r\nTypeError: not all arguments converted during string formatting                                                                                                                                                                                                                                                                                  \r\nCall stack:                                                                                                                                                                                                                                                                                                                                      \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/pooling_ops_test.py\", line $\r\n    test.main()                                                                                                                                                                                                                                                                                                                                  \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/platform/test.py\", line 62, in main      \r\n    return _googletest.main(argv)                                                                                                                                                                                                                                                                                                                \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 65, in mai$\r\n    benchmark.benchmarks_main(true_main=main_wrapper)                                                                                                                                                                                                                                                                                            \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/platform/benchmark.py\", line 407, in ben$\r\n    true_main()                                                                                                                                                                                                                                                                                                                                  \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 64, in mai$\r\n    return app.run(main=g_main, argv=args)                                                                                                                                                                                                                                                                                                       \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 40, in run        \r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)                                                                                                                                                                                                                                                                         \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/absl_py/absl/app.py\", line 300, in run                                    \r\n    _run_main(main, args)                                                                                                                                                                                                                                                                                                                        \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/absl_py/absl/app.py\", line 251, in _run_main                              \r\n    sys.exit(main(argv))                                                                                                                                                                                                                                                                                                                         \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 55, in g_m$\r\n    absltest_main(argv=argv)                                                                                                                                                                                                                                                                                                                     \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/absl_py/absl/testing/absltest.py\", line 1855, in main                     \r\n    _run_in_app(run_tests, args, kwargs)                                                                                                                                                                                                                                                                                                         \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/absl_py/absl/testing/absltest.py\", line 1963, in _run_in_app              \r\n    function(argv, args, kwargs)                                                                                                                                                                                                                                                                                                                 \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/absl_py/absl/testing/absltest.py\", line 2230, in run_tests                \r\n    argv, args, kwargs, xml_reporter.TextAndXMLTestRunner)                                                                                                                                                                                                                                                                                       \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/absl_py/absl/testing/absltest.py\", line 2200, in _run_and_get_tests_resul$\r\n    test_program = unittest.TestProgram(*args, **kwargs)                                                                                                                                                                                                                                                                                         \r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 94, in __init__                                                                                                                                                                                                                                                                               \r\n    self.runTests()                                                                                                                                                                                                                                                                                                                              \r\n  File \"/usr/lib/python3.5/unittest/main.py\", line 255, in runTests                                                                                                                                                                                                                                                                              \r\n    self.result = testRunner.run(self.test)                                                                                                                                                                                                                                                                                                      \r\n  File \"/usr/lib/python3.5/unittest/runner.py\", line 176, in run                                                                                                                                                                                                                                                                                 \r\n    test(result)                                                                                                                                                                                                                                                                                                                                 \r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__                                                                                                                                                                                                                                                                              \r\n    return self.run(*args, **kwds)                                                                                                                                                                                                                                                                                                               \r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run                                                                                                                                                                                                                                                                                  \r\n    test(result)                                                                                                                                                                                                                                                                                                                                 \r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 84, in __call__                                                                                                                                                                                                                                                                              \r\n    return self.run(*args, **kwds)                                                                                                                                                                                                                                                                                                               \r\n  File \"/usr/lib/python3.5/unittest/suite.py\", line 122, in run                                                                                                                                                                                                                                                                                  \r\n    test(result)                                                                                                                                                                                                                                                                                                                                 \r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 648, in __call__                                                                                                                                                                                                                                                                              \r\n    return self.run(*args, **kwds)                                                                                                                                                                                                                                                                                                               \r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 600, in run                                                                                                                                                                                                                                                                                   \r\n    testMethod()                                                                                                                                                                                                                                                                                                                                 \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1189, in d$\r\n    return f(self, *args, **kwargs)                                                                                                                                                                                                                                                                                                              \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/pooling_ops_test.py\", line $\r\n    self._testAvgPoolGradValidPadding1_1(data_format, use_gpu)                                                                                                                                                                                                                                                                                   \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/pooling_ops_test.py\", line $\r\n    use_gpu=use_gpu)                                                                                                                                                                                                                                                                                                                             \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/pooling_ops_test.py\", line $\r\n    tf_logging.info(\"%s gradient error = \" % func_name, err)                                                                                                                                                                                                                                                                                     \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/org_tensorflow/tensorflow/python/platform/tf_logging.py\", line 156, in in$\r\n    get_logger().info(msg, *args, **kwargs)                                                                                                                                                                                                                                                                                                      \r\n  File \"/usr/lib/python3.5/logging/__init__.py\", line 1279, in info                                                                                                                                                                                                                                                                              \r\n    self._log(INFO, msg, args, **kwargs)                                                                                                                                                                                                                                                                                                         \r\n  File \"/usr/lib/python3.5/logging/__init__.py\", line 1415, in _log                                                                                                                                                                                                                                                                              \r\n    self.handle(record)                                                                                                                                                                                                                                                                                                                          \r\n  File \"/usr/lib/python3.5/logging/__init__.py\", line 1425, in handle                                                                                                                                                                                                                                                                            \r\n    self.callHandlers(record)                                                                                                                                                                                                                                                                                                                    \r\n  File \"/usr/lib/python3.5/logging/__init__.py\", line 1487, in callHandlers                                                                                                                                                                                                                                                                      \r\n    hdlr.handle(record)                                                                                                                                                                                                                                                                                                                          \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/absl_py/absl/logging/__init__.py\", line 891, in handle                    \r\n    return self._current_handler.handle(record)                                                                                                                                                                                                                                                                                                  \r\n  File \"/usr/lib/python3.5/logging/__init__.py\", line 855, in handle                                                                                                                                                                                                                                                                             \r\n    self.emit(record)                                                                                                                                                                                                                                                                                                                            \r\n  File \"/home/jenkins/workspace/tensorflow-upstream-csb-debug-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/pooling_ops_test_gpu.runfiles/absl_py/absl/logging/__init__.py\", line 829, in emit                      \r\n    super(PythonHandler, self).emit(record)                                                                                                                                                                                                                                                                                                      \r\nMessage: 'avg_pool gradient error = '                                                                                                                                                                                                                                                                                                            \r\nArguments: (9.5367431640625e-07,)    \r\n```\r\nThe above error does not seem to prevent the corresponding subtests from \"passing\", and hence fixing it is not a \"must\". Also this error does not seem to be ROCm specific...guessing it is an issue on other platforms too\r\n\r\n\r\n", "comments": []}, {"number": 30503, "title": " [ROCm] Skipping subtests that check support for complex datatype in BLAS calls", "body": "ROCm platform currently does not support complex datatype in BLAS calls\r\n\r\nThis commit skips subtests (within python unit-tests) that test this functionality. The \"skip\" is guarded by the call to \"is_built_with_rocm()\", and hence these unit-tests will not be affected in any way when running with TF which was not built with ROCm support (i.e. `--config=rocm`)\r\n\r\n----------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n\r\n", "comments": []}, {"number": 30502, "title": "[ROCm] Skipping subtests that check support for Pooling Ops with 3D tensors", "body": "ROCm platform currently does not support Pooling Ops with 3D Tensors\r\n\r\nThis commit skips subtests (within python unit-tests) that test this functionality. The \"skip\" is guarded by the call to \"is_built_with_rocm()\", and hence these unit-tests will not be affected in any way when running with TF which was not built with ROCm support (i.e. `--config=rocm`)\r\n\r\n-----------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg ", "comments": []}, {"number": 30501, "title": " the ipynb 'Get started with TensorFlow 2.0 for experts' exhausts RAM memory when it runs on GPU", "body": "When I run the notebook 'Get started with TensorFlow 2.0 for experts' using tensorflow GPU all RAM (12gb on Colab) gets consumed before training starts. If I run on colab without GPU it is slow but it runs to the end\r\n\r\n**System information**\r\nColab (but also debian linux 10)\r\n\r\n", "comments": ["I tried checking with colab link provided by you and observed it is not consuming more RAM memory. Can you please restart runtime in google colab and check if the issue still persists.", "That was my mistake. I did not notice I was running tensorflow 1.14 instead of tensorflow 2.0. Sorry "]}, {"number": 30500, "title": "[ROCm] Skipping subtests that check support for float64 type in the NN ops", "body": "\r\nROCm platform currently does not support the float64/double type in the NN ops\r\n\r\nThis commit skips subtests (within python unit-tests) that test this functionality. The \"skip\" is guarded by the call to \"is_built_with_rocm()\", and hence these unit-tests will not be affected in any way when running with TF which was not built with ROCm support (i.e. `--config=rocm`)\r\n\r\n---------------------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n", "comments": ["I looked at the CI failure logs, and they do not seem related to the changes in this PR.\r\n\r\nThe one failure in `Linux GPU` is in a test that was modified by this PR. However the changes in this PR should be a no-op for the CUDA / `Linux GPU` run, and hence it does not seem likely that the change in this PR is the cause for the failure. ", "@deven-amd here is the internal error : \r\n`InternalError: 2 root error(s) found.\r\n  (0) Internal: cuDNN Backward Data function launch failure : input shape([1,5,8,7,2]) filter shape([1,2,3,2,3])\r\n\t [[node gradients_5/conv_5_grad/Conv3DBackpropInputV2 (defined at /third_party/py/absl/third_party/unittest3_backport/case.py:162) ]]\r\n  (1) Internal: cuDNN Backward Data function launch failure : input shape([1,5,8,7,2]) filter shape([1,2,3,2,3])\r\n\t [[node gradients_5/conv_5_grad/Conv3DBackpropInputV2 (defined at /third_party/py/absl/third_party/unittest3_backport/case.py:162) ]]\r\n\t [[gradients_5/conv_5_grad/Conv3DBackpropInputV2/_19]]`", "@rthadur \r\n\r\nI saw the error in the invocation log, but cannot see how the change in this PR can cause it. \r\n\r\nFor the CUDA run, the only thing that will change with this PR is the ordering the dtypes in the list, it will go from `[dtypes.float64, dtypes.float32, dtypes.float16]` to `[dtypes.float32, dtypes.float16, dtypes.float64]`. The two are functionally equivalent and should not cause any failure (I would think)\r\n\r\nLet me push out a change that keeps the above mentioned ordering intact, and see it that fixes the error!\r\n\r\ndeven\r\n\r\n\r\n\r\n", "@whchung , please re-approve this to kick-off the CI runs. \r\nI need to figure out whether or not my last change fixes the failure in the `LInux GPU` CI run.\r\n\r\nThanks\r\ndeven", "@rthadur , the CI errors are gone :)", "@deven-amd thank you , @chsigg can you please review this again."]}, {"number": 30499, "title": "TOCO input_shape not working as expexted", "body": "Hello!\r\nI have converted deeplabv3 model to tflite using TOCO with following command.\r\n`toco --graph_def_file=\"/home/abdullah/frozen_inference_graph.pb\" --output_file=\"model1.tflite\" --output_format=\"TFLITE\" --input_arrays='sub_7' --output_arrays=\"ResizeBilinear_3\" --input_shape= 1,1024,1024,3\r\n`\r\nSo, tflite model should take (1, 1024, 1024, 3) input. But when I try to test this model on my laptop for testing using this code it gives output of dimensions mismatch and is still expecting input of (1, 513, 513, 3).\r\n\r\nHere is Inference code. \r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    from PIL import Image\r\n    import matplotlib.pyplot as plt\r\n\r\n    interpreter = tf.contrib.lite.Interpreter(model_path='/home/abdullah/Documents/Company Work/TFlite/model1.tflite')\r\n    interpreter.allocate_tensors()\r\n\r\n    input_details = interpreter.get_input_details()\r\n    output_details = interpreter.get_output_details()\r\n\r\n    quantization = None\r\n    using_type = input_details[0]['dtype']\r\n\r\n\r\n    size = 1024\r\n\r\n    image = Image.open('/home/abdullah/Pictures/xyz.jpg')\r\n    image = image.resize((size, size))\r\n\r\n    input_shape = input_details[0]['shape']\r\n    image = np.array(image)\r\n    image = image.reshape(1, size, size, 3)\r\n    image = image/127 -1\r\n    input_data = image.astype(using_type)\r\n\r\n    print(input_details)\r\n\r\n    interpreter.set_tensor(input_details[0]['index'], input_data)\r\n    interpreter.invoke()\r\n    output_data = interpreter.get_tensor(output_details[0]['index'])\r\n    output_data = output_data.reshape(size, size, 21)\r\n\r\n\r\n    labels = np.argmax(output_data, -1)\r\n    labels = labels.reshape(size, size)\r\n\r\n\r\n    plt.imshow(labels)\r\n    plt.show()\r\n    print(labels.shape)\r\n\r\n    print(labels)\r\n \r\nI am getting following error. \r\n\r\n`Traceback (most recent call last):\r\n  File \"infer.py\", line 36, in <module>\r\n    interpreter.set_tensor(input_details[0]['index'], input_data)\r\n  File \"/home/abdullah/anaconda3/envs/tflow/lib/python3.6/site-packages/tensorflow/contrib/lite/python/interpreter.py\", line 151, in set_tensor\r\n    self._interpreter.SetTensor(tensor_index, value)\r\n  File \"/home/abdullah/anaconda3/envs/tflow/lib/python3.6/site-packages/tensorflow/contrib/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 133, in SetTensor\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_SetTensor(self, i, value)\r\nValueError: Cannot set tensor: Dimension mismatch\r\n`\r\n\r\nBut when I set size=513 it works like charm. \r\nMoreover, when I print **input_details = interpreter.get_input_details()**\r\nIt prints  \r\n`[{'name': 'sub_7', 'index': 283, 'shape': array([  1, 513, 513,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\r\n`\r\n\r\nKindly tell me how should I solve this.\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution : Ubuntu 18.04):\r\n- TensorFlow installed from : Pip install tensorflow\r\n- TensorFlow version : 1.10.1\r\n- Python version: Python 3.6.8\r\n- Bazel version : NA\r\n- GCC/Compiler version : NA\r\n- CUDA/cuDNN version : 10.0/7.4 \r\n- GPU model and memory: Gtx 1060 and 16 gb RAM\r\n\r\n\r\n", "comments": ["The tflite graph would expect the same input shape as the tf graph. If you want it to be able to take a larger image, you can try:\r\n\r\ninterpreter.resize_tensor_input(self, input_index, tensor_size)\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python/interpreter.py#L406\r\n\r\nRemember to call interpreter.allocate_tensors() afterwards, since you need to allocate more memory.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30499\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30499\">No</a>\n"]}, {"number": 30498, "title": "No `output_shape` after tf.keras layer/model build() and call. Is it intended?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary.\r\n- TensorFlow version (use command below): `2.0.0-beta1` and `tf_nightly_gpu_2.0_preview-2.0.0.dev20190708`\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: CUDA 10.0\r\n- GPU model and memory: without and with GPU (P100)\r\n\r\n**Describe the current behavior**\r\n\r\nHi, all. When I tried to use `model.summary()`, the output shapes were printed as **multiple**. After few tries, I realized that the `output_shape` of keras layers/models are not determined even after the layer/model was built and called. Here are short examples.\r\n\r\n1. Keras layer\r\n```\r\nimport tensorflow as tf\r\n\r\ndense = tf.keras.layers.Dense(2)\r\ndense.build(input_shape=3)\r\n\r\ninput_tensor = tf.ones((5, 3), tf.float32)\r\noutput_tensor = dense(input_tensor)\r\n\r\n# The line below raises \"AttributeError: The layer has never been called and thus has no defined output shape.\"\r\nprint(dense.output_shape)\r\n```\r\n\r\n2. Keras model\r\n```\r\nimport tensorflow as tf\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Dense(2),\r\n    tf.keras.layers.ReLU(),\r\n    tf.keras.layers.Dense(4),\r\n])\r\n\r\nmodel.build(input_shape=(None, 3))\r\n\r\ninput_tensor = tf.ones((5, 3), tf.float32)\r\noutput_tensor = model(input_tensor)\r\n\r\n# The line below raises \"AttributeError: The layer has never been called and thus has no defined output shape.\"\r\nprint(model.output_shape)\r\n```\r\n\r\n**Describe the expected behavior**\r\nI think keras layer/model should have `output_shape`, but they aren't. Please see if it's intended. I've just started to migrate from TF 1.x to TF 2.0 and to use keras APIs, so I might be wrong when using keras API.\r\n\r\n**Code to reproduce the issue**\r\nDescribed above.\r\n\r\n**Other info / logs**\r\n", "comments": ["I am able to reproduce the issue on Colab with tensorflow 2.0.0.beta1 and tf_nightly_gpu_2.0_preview-2.0.0.dev20190708. ", "@dalgu90 `output_shape` is not supported in eager. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/base_layer.py#L1493", "@pavithrasv Oh I see. Then the issue here is the wrong type and description of the exception raised.", "I'm closing this issue since it's the desired behavior. Hope the error message will be corrected in the future.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30498\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30498\">No</a>\n"]}, {"number": 30497, "title": "[ROCm] Skipping subtests that check support for the Cholesky and QR ops", "body": "ROCm platform currently does not support the Cholesky and QR ops (on the GPU)\r\n\r\nThis commit skip subtests (within python unit-tests) that test this functionality. \r\n\r\nThe \"skip\" is guarded by the call to \"is_built_with_rocm()\", and hence these unit-tests will not be affected in any way when running with TF which was not built with ROCm support (i.e. `--config=rocm`)\r\n\r\n----------------------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n", "comments": []}, {"number": 30496, "title": "[ROCm] Skipping subtests that check GPU stream tracing/profiling.", "body": "ROCm platform currently does not support the ability to do GPU stream level tracing / profiling.\r\n\r\nThis commit skip subtests (within python unit-tests) that test this functionality. The \"skip\" is guarded by the call to \"is_built_with_rocm()\", and hence these unit-tests will not be affected in any way when running with TF which was not built with ROCm support (i.e. `--config=rocm`)\r\n\r\n--------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n", "comments": []}, {"number": 30495, "title": "/etc/bash.bashrc leads to scp fail", "body": "I tried to copy my model files to a remote docker container using scp, but the ASCII welcome painting and warning sentences, i.e., the logo of \"tensorflow\" and \"WARNING: You are running this container as root ...... \", cause a transfer failure. As `scp` uses `ssh` as the backend, it will fail if you print something when init an interactive shell.\r\n", "comments": ["Can you post the error message and the command you used?\r\n\r\nAfaik, motd doesn't interfere with scp.", "> Can you post the error message and the command you used?\r\n> \r\n> Afaik, motd doesn't interfere with scp.\r\n\r\nI have fixed this problem by removing the `cat` command in /etc/bash.bashrc. The image tag I am using is `tensorflow:1.14.0-gpu-py3`. I know that `motd` does not affect the scp transfer, but the `cat` and `echo` command in /etc/bash.bashrc cause the transfer to fail. I think this is a potential problem for the users who are not familiar with linux. Thanks, close ~\r\n\r\n"]}, {"number": 30494, "title": "Null Pointer Bug for InferenceContext* in Linux", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution: Linux CentOS 7 \r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\nWhen adding a custom op in C++, the shape function passes a NULL InferenceContext pointer.\r\n\r\n**Describe the expected behavior**\r\nThe pointer should not be NULL. (I have also tested it on Mac OS, and it works fine. But on Linux, it gives a null pointer.)\r\n\r\n**Code to reproduce the issue**\r\nThis code (as a file `zero_out.cc`) is taken directly from `https://www.tensorflow.org/guide/extend/op`.\r\n```\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/shape_inference.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n#include <iostream>\r\n\r\nusing namespace tensorflow;\r\nusing shape_inference::InferenceContext;\r\n\r\nREGISTER_OP(\"ZeroOut\")\r\n    .Input(\"to_zero: int32\")\r\n    .Output(\"zeroed: int32\")\r\n    .SetShapeFn([](InferenceContext* c) {\r\n      std::cout << \"c address: \" << c << std::endl;\r\n      c->set_output(0, c->input(0));\r\n      return Status::OK();\r\n    });\r\n\r\nclass ZeroOutOp : public OpKernel {\r\n public:\r\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n      // Just leave it empty\r\n  }\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(\r\n    Name(\"ZeroOut\")\r\n    .Device(DEVICE_CPU),\r\n    ZeroOutOp);\r\n\r\n```\r\nCompile the op with the commands:\r\n```\r\nTF_CFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_compile_flags()))') )\r\nTF_LFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_link_flags()))') )\r\ng++ -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC ${TF_CFLAGS[@]} ${TF_LFLAGS[@]} -O2\r\n```\r\nRun the op:\r\n```\r\nimport tensorflow as tf\r\nzero_out_module = tf.load_op_library('./zero_out.so')\r\nwith tf.Session(''):\r\n  zero_out_module.zero_out([[1, 2], [3, 4]]).eval()\r\n```\r\nThis prints the following:\r\n```\r\nc address: 0\r\nSegmentation fault\r\n```\r\n", "comments": ["@acs6610987 I can exactly reproduce your issue with pip install tensorflow==1.14.0\r\n\r\nHowever if I build tf 1.14 from source code: the out put c address(point) is not **NULL**:\r\n```\r\nc address: 0x360e850\r\n```\r\nBut  I got different error message:\r\n```\r\ntensorflow.python.framework.errors_impl.InternalError: Missing 0-th output from {{node ZeroOut}}\r\n```\r\nI believe the empty **Compute** function which casues my error message.\r\n\r\n\r\nDoes anyone know the build commands with the version I installed with _pip install tensorflow==1.14.0_?\r\n\r\n", "I got NULL pointer too as the address of InferenceContext*. Downgraded to 1.13.0 and it work now.", "This problem might come from the difference of compilers. In #31335, it is recommended that using the docker container provided in [custom-op](https://github.com/tensorflow/custom-op) to resolve this problem.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30494\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30494\">No</a>\n"]}, {"number": 30493, "title": "[Feature] To support casting float32 to int32 in HEX format", "body": "**System information**\r\n- TensorFlow version (you are using):\r\n    1.13.x\r\n- Are you willing to contribute it (Yes/No):\r\n    Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI want something like `int32_tensor = tf.float_to_hexint(fp32_tensor)` which allows me to get the hex value representation and can be used to further compute with bit-wise operators.\r\n\r\n**Will this change the current api? How?**\r\nNo, just extend a new op to handle it.\r\n\r\n**Who will benefit with this feature?**\r\nAny requirement that is needed to edit the bit value for a float32-type tensor.\r\n\r\n**Any Other info.**\r\nNo.", "comments": ["Hi ghostplant, by HEX do you mean the raw bits of a float32? If you want to learn how to add an new op and contribute, you can read https://www.tensorflow.org/guide/extend/op and https://github.com/tensorflow/tensorflow/commit/688e638da7ebe1f805107f56946ef400ffd89112 as an example.", "@wangpengmit Yes, it is something to make `int int_val = *(int*)&float_val;`\r\nI am using old version TF1.14 which is not suitable to upgrade to 2.0 for other unstable purpose, so I'm afraid I cannot establish full developing environment for latest Tensorflow 2.0 and managing test requirement for all combinations, like GPU, CPU, TF2.0, TF1.14, Windows, Linux, ..", "I see. I'll add the op.", "@wangpengmit Great, thanks! And `float float_val = *(float*)&int_val;` is needed as well, since the value should be turned back after some int-level / bit-wise operation.", "@wangpengmit I'm not sure whether you adding this op will support 2.0 only, or supporting 1.14 as well?", "An ordinary op like this will work for all versions.", "@alextp do you know of any existing ops for this? And if not, do you think they should be added as custom ops (https://github.com/tensorflow/community/pull/126/files) or to the core?", "I think you're talking about tf.bitcast https://www.tensorflow.org/api_docs/python/tf/bitcast", "Hi,\r\nIt appears this functionality is still not present, or am I confused. The desired type would be equivalent to https://docs.python.org/3/library/functions.html#hex, int should be convertible to hex string and back. "]}, {"number": 30492, "title": "Custom OP Documentation: `-D_GLIBCXX_USE_CXX11_ABI=0` not required anymore?", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/extend/op#compile_the_op_using_your_system_compiler_tensorflow_binary_installation\r\n(Last Note of the paragraph).\r\n\r\n## Description of issue (what needs changing):\r\nThe documentation states that customs ops for the binary pip packages should be compiled with `-D_GLIBCXX_USE_CXX11_ABI=0`. For me this actually had to be removed (python 3.7, tensorflow-gpu==1.14.0  from pip), so I guess tf-1.14 is now built with `gcc > 4`?\r\nIf someone can confirm, I could open a PR :)\r\n\r\n\r\n", "comments": ["@PhilJd,\r\n\r\nThe link that has been provided is broken and here is the [new link](https://www.tensorflow.org/guide/create_op#compile_the_op_using_your_system_compiler_tensorflow_binary_installation) for creating OP and the documentation states that, `If you compile your op library with gcc>=5, add -D_GLIBCXX_USE_CXX11_ABI=0 to the command line to make the library compatible with the older abi`. Do you think still this is an issue? ", "Hi,\r\nI have no idea, I haven't compiled a custom op for TF in a long tim - I also don't remember in which setup this was so I don't have a way to reproduce anymore. Should we close this as obsolete and if someone still runs into this issue they could reopen?\r\n\r\n", "@PhilJd,\r\n\r\nThanks for the confirmation. I am closing this issue and they can create a new one/reopen if there are any further questions.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30492\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30492\">No</a>\n"]}, {"number": 30491, "title": "padding parameter of conv2d layer is not saved correctly with dilation > 1", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\ntf.layers.conv2d(padding='same') is saved as padding is VALID.\r\n\r\n**Describe the expected behavior**\r\ntf.layers.conv2d(padding='same') is saved as padding is SAME.\r\n\r\n**Code to reproduce the issue**\r\ni use the below code to generate .pb file, the key is that padding parameter is same, and dilation_rate is 2.\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nx = tf.placeholder(tf.float32, shape=[1, None, None, 1])\r\nconv = tf.layers.conv2d(x, 64, 5, activation=tf.nn.tanh, padding='same', dilation_rate=(2, 2), kernel_initializer=tf.keras.initializers.he_normal())\r\ny = tf.identity(conv, name='y')\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, ['y'])\r\n    tf.train.write_graph(output_graph_def, '.', 'same.pb', as_text=False)\r\n```\r\n\r\nI use the following code to load and check the .pb file, but the padding parameter is not same, but VALID.\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nwith open('same.pb', 'rb') as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n    nodes = graph_def.node\r\n    for node in nodes:\r\n        if node.op == 'Conv2D':\r\n            print(node.attr['padding'].s)\r\n```", "comments": ["I have tried on colab with TF version 1.13.1 and was able to reproduce the issue.Thanks!", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "thanks, i'll try 2.x later.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30491\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30491\">No</a>\n"]}, {"number": 30490, "title": "core dumped when convert to tflite", "body": "Hi.\r\nAfter too debuging,i tried to convert tflite model!but i get error.\r\nmy code is:\r\n\r\n\r\ntflite_convert --graph_def_file=ssdlite_mobilenet_v2_coco_2018_05_09/frozen_inference_graph.pb --input_arrays=image_tensor --input_shapes=1,300,300,3 --output_arrays=concat --output_file=mobilenetv2_ssdlite.tflite\r\n\r\n\r\n\r\n\r\nmy error is:\r\n\r\n\r\n2019-07-08 15:20:45.599944: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-07-08 15:20:45.623407: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192955000 Hz\r\n2019-07-08 15:20:45.623793: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3096840 executing computations on platform Host. Devices:\r\n2019-07-08 15:20:45.623816: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-07-08 15:20:46.856808: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-07-08 15:20:46.856973: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-07-08 15:20:48.347129: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n2019-07-08 15:20:48.347173: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 6099 nodes (-30), 10134 edges (-41), time = 1151.25806ms.\r\n2019-07-08 15:20:48.347178: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 6099 nodes (0), 10134 edges (0), time = 197.626ms.\r\nTraceback (most recent call last):\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/bin/tflite_convert\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 503, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 499, in run_main\r\n    _convert_tf1_model(tflite_flags)\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 193, in _convert_tf1_model\r\n    output_data = converter.convert()\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 987, in convert\r\n    **converter_kwargs)\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 411, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-07-08 15:20:49.738690: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.738758: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.738807: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.738820: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.738828: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.738835: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.738842: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.738848: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.738856: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.738867: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.738873: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.738879: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.738887: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.738893: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.738899: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.738908: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.738914: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.738923: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-07-08 15:20:49.738935: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n2019-07-08 15:20:49.738943: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.738959: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-07-08 15:20:49.738968: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-07-08 15:20:49.738977: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n2019-07-08 15:20:49.738985: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n2019-07-08 15:20:49.738992: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-07-08 15:20:49.739018: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-07-08 15:20:49.739031: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n2019-07-08 15:20:49.739040: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n2019-07-08 15:20:49.739067: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-07-08 15:20:49.740378: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.740392: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740402: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.740409: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740418: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.740425: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740433: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.740440: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740448: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.740455: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740463: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.740469: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740477: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.740484: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740492: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-07-08 15:20:49.740498: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740505: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740519: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740526: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740533: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740539: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740546: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-07-08 15:20:49.740554: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740561: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740568: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-07-08 15:20:49.740577: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740585: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740591: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740600: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740606: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740613: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740621: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740627: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740633: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740640: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740646: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740653: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740660: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740666: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-07-08 15:20:49.740674: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-07-08 15:20:49.740684: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740693: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740707: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n2019-07-08 15:20:49.740716: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.740749: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-07-08 15:20:49.740758: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-07-08 15:20:49.740766: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-07-08 15:20:49.743703: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-07-08 15:20:49.743720: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-07-08 15:20:49.743729: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-07-08 15:20:49.748554: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748585: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748594: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748602: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748611: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748619: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748626: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748634: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748642: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748650: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748658: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748668: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748676: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748684: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748692: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748700: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748708: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748716: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748724: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748732: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748740: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748748: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748756: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748764: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748772: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748780: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748787: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748796: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748803: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748811: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748819: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748827: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748835: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748843: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748851: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748860: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748868: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748876: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748884: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748892: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748900: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748908: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748917: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748925: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748932: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748940: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748948: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748956: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748964: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748972: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748980: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748988: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.748996: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749004: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749012: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749020: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749028: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749036: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749044: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749052: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749060: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749068: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749076: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749084: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749093: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749101: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749109: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749117: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749125: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749133: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749141: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749149: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749157: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749165: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749173: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749181: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749189: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749197: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749205: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749213: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749222: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749230: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749238: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749246: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749254: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749262: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749270: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749278: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749286: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749294: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-07-08 15:20:49.749805: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n2019-07-08 15:20:49.749895: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-07-08 15:20:49.750159: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-07-08 15:20:49.750170: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-07-08 15:20:49.750179: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-07-08 15:20:50.198559: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4312 operators, 7090 arrays (0 quantized)\r\n2019-07-08 15:20:50.433191: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 475 operators, 732 arrays (0 quantized)\r\n2019-07-08 15:20:50.452701: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 475 operators, 732 arrays (0 quantized)\r\n2019-07-08 15:20:50.469125: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 139 operators, 344 arrays (0 quantized)\r\n2019-07-08 15:20:50.472201: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 139 operators, 344 arrays (0 quantized)\r\n2019-07-08 15:20:50.474837: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 139 operators, 344 arrays (0 quantized)\r\n2019-07-08 15:20:50.481901: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 1080128 bytes, theoretical optimal value: 1080128 bytes.\r\n2019-07-08 15:20:50.482406: F tensorflow/lite/toco/tooling_util.cc:2275] Check failed: array.data_type == array.final_data_type Array \"image_tensor\" has mis-matching actual and final data types (data_type=uint8, final_data_type=float).\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fcb303a1740 (most recent call first):\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/absl/app.py\", line 251 in _run_main\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/absl/app.py\", line 300 in run\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n  File \"/home/davari/virtualenvironments/detection_on_mobile/bin/toco_from_protos\", line 10 in <module>\r\nAborted (core dumped", "comments": ["I've got same issue.\r\nEDIT: looks like You used export_inference_graph.py to create pb, but you should use export_tflite_ssd_graph.py instead.", "@Davari393 Please provide us the Tensorflow version. Thanks!", "@AlexZot Were you able to resolve this issue? Thanks!", " @gadagashwini Yes, using export_tflite_ssd_graph.py helped me with same error (Check failed: array.data_type == array.final_data_type Array....)\r\n", "@AlexZot Thanks for suggestion. \r\n@Davari393 Can you try @AlexZot's solution and let us know is this still an issue.Thanks!  ", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "> Hi.\r\n> After too debuging,i tried to convert tflite model!but i get error.\r\n> my code is:\r\n> \r\n> tflite_convert --graph_def_file=ssdlite_mobilenet_v2_coco_2018_05_09/frozen_inference_graph.pb --input_arrays=image_tensor --input_shapes=1,300,300,3 --output_arrays=concat --output_file=mobilenetv2_ssdlite.tflite\r\n> \r\n> my error is:\r\n> \r\n> 2019-07-08 15:20:45.599944: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n> 2019-07-08 15:20:45.623407: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192955000 Hz\r\n> 2019-07-08 15:20:45.623793: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3096840 executing computations on platform Host. Devices:\r\n> 2019-07-08 15:20:45.623816: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): ,\r\n> 2019-07-08 15:20:46.856808: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n> 2019-07-08 15:20:46.856973: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n> 2019-07-08 15:20:48.347129: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n> 2019-07-08 15:20:48.347173: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718] constant folding: Graph size after: 6099 nodes (-30), 10134 edges (-41), time = 1151.25806ms.\r\n> 2019-07-08 15:20:48.347178: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718] constant folding: Graph size after: 6099 nodes (0), 10134 edges (0), time = 197.626ms.\r\n> Traceback (most recent call last):\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/bin/tflite_convert\", line 10, in\r\n> sys.exit(main())\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 503, in main\r\n> app.run(main=run_main, argv=sys.argv[:1])\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n> _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n> _run_main(main, args)\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n> sys.exit(main(argv))\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 499, in run_main\r\n> _convert_tf1_model(tflite_flags)\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 193, in _convert_tf1_model\r\n> output_data = converter.convert()\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 987, in convert\r\n> **converter_kwargs)\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 411, in toco_convert_impl\r\n> input_data.SerializeToString())\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 172, in toco_convert_protos\r\n> \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n> tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n> 2019-07-08 15:20:49.738690: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.738758: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.738807: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.738820: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.738828: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.738835: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.738842: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.738848: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.738856: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.738867: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.738873: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.738879: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.738887: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.738893: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.738899: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.738908: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.738914: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.738923: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-07-08 15:20:49.738935: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n> 2019-07-08 15:20:49.738943: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.738959: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-07-08 15:20:49.738968: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-07-08 15:20:49.738977: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-07-08 15:20:49.738985: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-07-08 15:20:49.738992: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-07-08 15:20:49.739018: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-07-08 15:20:49.739031: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-07-08 15:20:49.739040: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-07-08 15:20:49.739067: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-07-08 15:20:49.740378: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.740392: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740402: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.740409: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740418: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.740425: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740433: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.740440: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740448: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.740455: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740463: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.740469: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740477: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.740484: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740492: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-07-08 15:20:49.740498: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740505: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740519: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740526: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740533: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740539: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740546: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-07-08 15:20:49.740554: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740561: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740568: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-07-08 15:20:49.740577: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740585: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740591: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740600: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740606: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740613: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740621: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740627: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740633: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740640: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740646: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740653: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740660: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740666: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-07-08 15:20:49.740674: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-07-08 15:20:49.740684: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740693: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740707: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n> 2019-07-08 15:20:49.740716: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.740749: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-07-08 15:20:49.740758: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-07-08 15:20:49.740766: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-07-08 15:20:49.743703: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-07-08 15:20:49.743720: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-07-08 15:20:49.743729: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-07-08 15:20:49.748554: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748585: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748594: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748602: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748611: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748619: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748626: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748634: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748642: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748650: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748658: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748668: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748676: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748684: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748692: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748700: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748708: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748716: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748724: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748732: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748740: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748748: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748756: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748764: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748772: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748780: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748787: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748796: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748803: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748811: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748819: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748827: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748835: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748843: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748851: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748860: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748868: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748876: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748884: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748892: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748900: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748908: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748917: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748925: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748932: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748940: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748948: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748956: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748964: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748972: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748980: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748988: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.748996: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749004: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749012: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749020: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749028: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749036: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749044: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749052: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749060: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749068: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749076: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749084: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749093: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749101: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749109: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749117: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749125: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749133: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749141: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749149: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749157: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749165: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749173: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749181: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749189: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749197: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749205: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749213: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749222: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749230: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749238: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749246: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749254: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749262: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749270: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749278: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749286: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749294: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n> 2019-07-08 15:20:49.749805: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n> 2019-07-08 15:20:49.749895: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-07-08 15:20:49.750159: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-07-08 15:20:49.750170: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-07-08 15:20:49.750179: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-07-08 15:20:50.198559: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4312 operators, 7090 arrays (0 quantized)\r\n> 2019-07-08 15:20:50.433191: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 475 operators, 732 arrays (0 quantized)\r\n> 2019-07-08 15:20:50.452701: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 475 operators, 732 arrays (0 quantized)\r\n> 2019-07-08 15:20:50.469125: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 139 operators, 344 arrays (0 quantized)\r\n> 2019-07-08 15:20:50.472201: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 139 operators, 344 arrays (0 quantized)\r\n> 2019-07-08 15:20:50.474837: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 139 operators, 344 arrays (0 quantized)\r\n> 2019-07-08 15:20:50.481901: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 1080128 bytes, theoretical optimal value: 1080128 bytes.\r\n> 2019-07-08 15:20:50.482406: F tensorflow/lite/toco/tooling_util.cc:2275] Check failed: array.data_type == array.final_data_type Array \"image_tensor\" has mis-matching actual and final data types (data_type=uint8, final_data_type=float).\r\n> Fatal Python error: Aborted\r\n> \r\n> Current thread 0x00007fcb303a1740 (most recent call first):\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/absl/app.py\", line 251 in _run_main\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/absl/app.py\", line 300 in run\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n> File \"/home/davari/virtualenvironments/detection_on_mobile/bin/toco_from_protos\", line 10 in\r\n> Aborted (core dumped\r\n\r\n\r\n\r\nsame error, anyone solved?", "Not resolved", "@angyee and @Nitin-Qwinix,\r\nCan you please post a new issue by providing the information asked by the template?\r\nThe reason for this is we can focus on your specific configuration and problem since the root cause can be unrelated even though the error messages are similar. Thanks!", "@gadagashwini Error: core dumped when convert to tflite. when i checked input_array and output_array type is uint8 & float32 respectively. I tried lot of methods to change array type but couldn't get any solution..... \r\n\r\n\r\n\r\n", "The same here.\r\n\r\nI run the following code: \r\n\r\nimport tensorflow as tf\r\n\r\nsaved_model_dir = \"./saved_model\"\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\ntflite_model = converter.convert()\r\n\r\nTensorflow version 1.14.0\r\n\r\nAnd I got the error:\r\n\r\n2020-02-12 14:18:28.766546: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-02-12 14:18:28.805016: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-02-12 14:18:28.805163: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-02-12 14:18:28.805231: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-02-12 14:18:28.805281: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-02-12 14:18:28.805588: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-02-12 14:18:28.805654: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-02-12 14:18:28.805701: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-02-12 14:18:28.805747: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-02-12 14:18:28.806731: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n2020-02-12 14:18:28.859097: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 900 operators, 1701 arrays (0 quantized)\r\n2020-02-12 14:18:28.938939: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 889 operators, 1645 arrays (0 quantized)\r\n2020-02-12 14:18:29.032120: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 889 operators, 1645 arrays (0 quantized)\r\n2020-02-12 14:18:29.316379: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 494 operators, 992 arrays (0 quantized)\r\n2020-02-12 14:18:29.357290: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 493 operators, 990 arrays (0 quantized)\r\n2020-02-12 14:18:29.398222: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 492 operators, 989 arrays (0 quantized)\r\n2020-02-12 14:18:29.442322: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 4: 491 operators, 987 arrays (0 quantized)\r\n2020-02-12 14:18:29.482266: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 491 operators, 987 arrays (0 quantized)\r\n2020-02-12 14:18:29.510318: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 491 operators, 987 arrays (0 quantized)\r\n2020-02-12 14:18:29.573114: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 79380480 bytes, theoretical optimal value: 50135040 bytes.\r\n2020-02-12 14:18:29.581069: F tensorflow/lite/toco/tooling_util.cc:2258] Check failed: array.data_type == array.final_data_type Array \"image_tensor\" has mis-matching actual and final data types (data_type=uint8, final_data_type=float).\r\nFatal Python error: Aborted", "Same issue with tf 1.15", "You can follow my given link to resolve this issue-\r\n\r\nhttps://www.youtube.com/watch?v=3TLxQIRj3yg&t=1s", "> You can follow my given link to resolve this issue-\r\n> \r\n> https://www.youtube.com/watch?v=3TLxQIRj3yg&t=1s\r\n\r\nThis has nothing to do with TensorFlow lite, but is just advertisement for a project called Tensorlite (https://github.com/justdvnsh/tensorlite), which features code stolen from my TensorSlow project (https://github.com/danielsabinasz/TensorSlow)", "I create tflite model use input_data = tf.placeholder(dtype=tf.uint8, shape=[160, 160], name=\"input_data\") also failed. But if I replace tf.uint8 to tf.float32 or tf.int32, it will be ok. I see some tflite model use tf.uint8. I do not know how to solve the problem."]}, {"number": 30489, "title": "core dumped when convert to tflite", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["duplicate #30490"]}, {"number": 30488, "title": "libtensorflow_framework.so issue", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I git cloned it from https://github.com/smallcorgi/Faster-RCNN_TF.git\r\n- OS Platform and Distribution: ubuntu 18.04\r\n- TensorFlow installed from: pip install\r\n- TensorFlow version: used both 1.14.0rc and 1.14.0(gpu)\r\n- Python version: 2.7\r\n- GCC/Compiler version: 7.4\r\n- CUDA/cuDNN version: 10.0 \r\n- GPU model and memory: GV 100\r\n\r\nMy script file is demo.py. \r\n\r\nHere's the back trace\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"./tools/demo.py\", line 11, in <module>\r\n    from networks.factory import get_network\r\n  File \"/home/tFaster-RCNN_TF/tools/../lib/networks/__init__.py\", line 8, in <module>\r\n    from .VGGnet_train import VGGnet_train\r\n  File \"/home/Faster-RCNN_TF/tools/../lib/networks/VGGnet_train.py\", line 2, in <module>\r\n    from networks.network import Network\r\n  File \"/home/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 3, in <module>\r\n    import roi_pooling_layer.roi_pooling_op as roi_pool_op\r\n  File \"/homeFaster-RCNN_TF/tools/../lib/roi_pooling_layer/roi_pooling_op.py\", line 5, in <module>\r\n    _roi_pooling_module = tf.load_op_library(filename)\r\n  File \"/home/.local/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py\", line 61, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so: cannot open shared object file: No such file or directory\r\n```\r\nI checked that libtensorflow_framework.so is in ```python2.7/site-packages/tensorflow/ ```but somehow my program doesn't seem to be able to find it. The path for the tensorflow library is set as ```$TF_LIB = /home/.local/lib/python2.7/site-packages/tensorflow```\r\n\r\nI did run into some solutions but coudn't find one with tf version 1.14.0.\r\n\r\nPlease help. \r\n\r\nThanks in advance.", "comments": ["Hi @yunoJ,\r\ndoes it work if you specify the full path in `library_name`? Otherwise you might be able to fix this by adding the directory of your libtensorflow_framwork to your `LD_LIBRARY_PATH`.", "Thank you @PhilJd,\r\nAppending the LD_LIBRARY_PATH worked for me. Well, for the libtensorflow_framework.so at least. I guess I should just keep adding directories for every .so file I use. ", "Please,let me know if we can close this issue since it looks to be fixed. Thanks!", "Oh, the problem is fixed. I will close the issue, thanks!", "can you specify where to append i faced the same issue with python 3.6 tensorflow", "You need to run the command\r\n```\r\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:\"path/to/your/libtensorflow\"\r\n```", "Thanks but after trying it i amgetting error undefined symbol: _ZTVN10tensorflow14kernel_factory17OpKernelRegistrar18PtrOpKernelFactoryE", "When people (like myself) come from python to java world, everything is strange! here is how I solved my problem regarding all linking errors:\r\nI assumed you already have simple hello Tensorflow project, explained [here](https://www.tensorflow.org/install/lang_java)\r\n\r\nFirst:\r\n1. [Download](https://www.tensorflow.org/install/lang_java#download) and copy tensorflow JNI files to :/usr/lib/tensorflow \r\n2. [Download](https://www.tensorflow.org/install/lang_java#download) and copy desired version of tensorflow Lib jar file to: /usr/lib/tensorflow \r\n#### Compile with java\r\n3. Compile java file\r\n```bash\r\njavac -cp /usr/lib/tensorflow/libtensorflow-1.14.0.jar HelloTensorFlow.java\r\n```\r\n4. run java file:\r\n```bash\r\njava -cp /usr/lib/tensorflow/libtensorflow-1.14.0.jar:. -Djava.library.path=/usr/lib/tensorflow/ HelloTensorFlow\r\n```\r\n\r\n#### MAVEN\r\n1. First we should export LD_LIBRARY_PATH:\r\n```bash\r\nexport LD_LIBRARY_PATH=/usr/lib/tensorflow\r\n```\r\n2. Then run maven build command:\r\n```bash\r\nmvn -q compile exec:java\r\n```\r\n\r\nI hope it helps you", "Hi, Sorry for commenting on the closed issue. I tried to append the libtensorflow path, but again getting the same error. How can I know the correct path of libtensorflow.", "@chanchalIITP , run this to get the path of your libtensorflow:\r\n`find . -name libtensorflow_framework.so2`", "@chanchalIITP : Are you able to solve the error? I am also facing the same issue. Kindly help.", "@AASHISHAG, find . -name libtensorflow_framework.so2 works for finding the path of .so file. In my case, actually the .so file is not generated. It generally happens if the tensorflow and gcc is not compatible. \r\nConcluding: I am also not able to solve it. You may check the compatibility of CUDA, Tensorflow, and gcc.", "> @chanchalIITP , run this to get the path of your libtensorflow:\r\n> `find . -name libtensorflow_framework.so2`\r\n\r\nThe above mis-spells the file name.  Try:\r\n`find . -name libtensorflow_framework.so.2`", "i hope the problem is with the tensorflow version so try to change the versionand reinstall the tensorflow version\r\n"]}, {"number": 30487, "title": "How to reuse conv layers with keras", "body": "my data shape is [91,109,91,27] and I unstack the one data to 27 data which shape is [91,109,91,1],\r\n\r\nI want to use the convnet to extract the feature. But here is loop my Net 27 times. So how could I reuse the Network for just one time?\r\n\r\nDescription of the problem in the code comment\r\n```python\r\nx_in = Input(shape=shape) # my data shape is [91,109,91,27]\r\n\r\nx = Lambda(self.unstack)(x_in) # there I unstack the data to 27 datas shape is [91,109,91]\r\n\r\nt_list = []\r\nfor i in range(len(x)): # loop 27 times\r\n   x_expand = Lambda(self.expand)(x[i])  # change the data shape to [91,109,91,1]\r\n\r\n   feature = self.cnn_block(x_expand)# here is my Net with 3 convs --->\r\n# I build a convnet here, and I want to reuse the network, but here it is looping 27 times. so is there a way to reuse the cnn_block in keras?\r\n\r\n   x_out = Lambda(self.expand)(feture)\r\n   t_list.append(x_out)\r\n\r\nx = Concatenate(axis=-1)(t_list)\r\n\r\n```", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n"]}]