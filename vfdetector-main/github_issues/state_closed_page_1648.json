[{"number": 3467, "title": "Docker Image with Python 3?", "body": "This is more a feature request.  Any chance we can get support for this?\n", "comments": ["Just to gather more info, are you using the images from docker hub or gcr.io?\n", "gcr.io I'm also not a docker guru; I'm just trying to get tensor flow operational on my windows machine and have to deal with all sorts of crazy data that comes in; so python 3.5 is nice.  I am trying to use this not only for tensorflow but get a data set in, do my munging with it, then feed it into tensor flow.  \n", "+1, would love if it included ipython3 too.\nCurrently using gcr.io, but could use any source really.\n", "For those willing to look out of gcr.io, there is a Docker image in Docker Hub packing Python 3 Tensorflow (0.10.0rc0 at the time of writing) with IPython notebook installed, pretty much like the supported ones:\nhttps://hub.docker.com/r/erroneousboat/tensorflow-python3-jupyter/\n_Edit:_ Also, it is Debian Jessie (8.5), not Ubuntu 14.04\n", "It would be great to sync docker images from gcr.io to docker hub because gcr.io is always blocked in China.\r\n\r\n[erroneousboat/tensorflow-python3-jupyter](https://hub.docker.com/r/erroneousboat/tensorflow-python3-jupyter/) is good enough for someone who want to run TensorFlow and Python 3. BTW, installing TensorFlow and building another docker image are not that hard. Just modify the Dockerfile if you want another operation system or dependencies.", "@tobegit3hub The latest releases are indeed synced to docker hub. So are the nightly builds:\r\nhttps://hub.docker.com/r/tensorflow/tensorflow/tags/\r\nAre those working for you?", "Thanks @caisq and I have test the python3 docker image. It works like a charm with Python 3.4.3 and latest TensorFlow. You can run by `docker run -i -t  tensorflow/tensorflow:nightly-py3 bash`.\r\n\r\n![screen shot 2016-12-02 at 09 17 53](https://cloud.githubusercontent.com/assets/2715000/20819590/49d6ed22-b870-11e6-9b20-4c30572a1224.png)\r\n\r\nBut the binary `python` doesn't exist. It would be better to link `python3` to `python`.", "@tobegit3hub Good point. I'll incorporate your feedback. I'm working on a pull request to finalize the python3 docker builds: https://github.com/tensorflow/tensorflow/pull/6030\r\n\r\nOnce the PR is submitted, py3 images will be pushed to docker hub nightly. Release py3 images will be pushed starting from the next release.", "Fixed by https://github.com/tensorflow/tensorflow/pull/6030\r\nPython-3 docker images are now available in nightly builds, via Docker Hub.\r\nSee: https://hub.docker.com/r/tensorflow/tensorflow/tags/\r\n\r\npy3 tags include:\r\nnightly-py3\r\nnightly-devel-py3\r\nnightly-gpu-py3\r\nnightly-devel-gpu-py3\r\n\r\npy3 images will also be made available in the next release. They will be pushed to gcr.io and Docker Hub along with the existing non-py3 tags."]}, {"number": 3466, "title": "Fix a typo in input_producer documentation", "body": "Just what it says on the tin..\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3465, "title": "Add bazel version to issue template", "body": "", "comments": []}, {"number": 3464, "title": "Extract the element from the output list of tf.py_func when length 1", "body": "`tf.py_func` could extract the element from the list when the length is 1.\n\nIn this example:\n\n```\ndef func(x):\n    return 2*x\n\nx = tf.constant(1.)\nres = tf.py_func(func, [x], [tf.float32])\n```\n\n`res` is a list containing 1 Tensor. This can be confusing, because users expect to get only one tensor as output.\n\n`tf.cond` handles this case well:\n\n> **Returns:**\n> Tensors returned by the call to either fn1 or fn2. If the callables return a singleton list, the element is extracted from the list.\n", "comments": ["Maybe it could be \n\n```\ntf.py_func(func, [x], [tf.float32]) -> returns list of tf.float32\ntf.py_func(func, [x], tf.float32) -> returns single tf.float32\n```\n\nThis is similar to `session.run` which returns either list of numpy arrays or single numpy array depending on whether input is a list\n", "That would work for me.\n", "We are unlikely to work on this soon, so marking as contributions welcome.  IMO @yaroslavvb's suggested behavior is saner than checking for the length of the result list.\n", "dbs\n", "op's attr can't be {type, list(type)}, so I suggest add a boolean to distinguish.\n", "@concretevitamin since attr can't be set as {type, list(type)}, if it's set as list(type), then this op will always return [...] instead of ... , I want to make C++ api and python api same as each other, I need help.\n", "I think #3744 closes this one.\n"]}, {"number": 3463, "title": "Dev request -- LSTM RNN", "body": "I previously [posted](https://github.com/tensorflow/tensorflow/issues/3278) about processing 3D data in an LSTM network with Tensorflow. It turns out Grid LSTM networks are what would work best. Already applied in contrib gridd_rnn.py. [This](http://arxiv.org/abs/1507.01526) paper (Grid LSTM) outlines Grid LSTM, but they also mentioned something I found to be a great idea.\n\nI don't believe there is a way for Tensorflow to currently support this natively. \n\nThe idea goes, in between each LSTM RNN step, instead of simply passing outputs to the next step, outputs are first passed through a single layer MLP. In other words there is a `tf.matmul` in between each step.\n\nWhat do you think? It seems like a simple enough feature to implement in the `RNN` initialization. \n", "comments": ["I believe this is partially done in the LSTMCell, if you use proj_size > 0.\n", "I don't see a `proj_size` in the BasicLSTMCell args\n", "It's not in BasicLSTMCell.  It's in LSTMCell.\n\nOn Fri, Jul 22, 2016 at 5:15 PM, Kendall Weihe notifications@github.com\nwrote:\n\n> I don't see a proj_size in the BasicLSTMCell args\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3463#issuecomment-234685933,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtimybAmP4YDWGc2WHfhrjk_rU58-0Fks5qYV0rgaJpZM4JS6SN\n> .\n", "Closing since this seems resolved.\n", "@ebrevdo It seems that `proj_size` has been removed. \r\n\r\nIf I understand this correctly, then we just apply a `Dense` layer to the RNN/LSTM output in order to project the particular output down to a desired dimension.\r\n\r\nSo doing this (note I am using `tf.compat.v1.nn.rnn_cell.LSTMCell` here):\r\n\r\n```python\r\noutputs = layers.RNN(\r\n    tf.compat.v1.nn.rnn_cell.LSTMCell(\r\n        layer_size,\r\n        num_proj=proj_size\r\n    ),\r\n    return_sequences=True\r\n)(inputs)\r\n```\r\n\r\nShould be similar to this:\r\n\r\n```python\r\nx = layers.RNN(\r\n    layers.LSTMCell(layer_size),\r\n    return_sequences=True\r\n)(inputs)\r\n\r\noutputs = layers.Dense(proj_size)(x)\r\n```\r\n\r\nIs this correct? I am not sure - mainly because the number of parameters is different: 31,520 vs 23,296 but that might be due to some implementation/optimization details?\r\n\r\nHere's a complete example:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.python.keras import Model\r\n\r\n\r\ndef get_model(inputs, layer_size, proj_size):\r\n\r\n    x = layers.RNN(\r\n        layers.LSTMCell(layer_size),\r\n        return_sequences=True\r\n    )(inputs)\r\n\r\n    outputs = layers.Dense(proj_size)(x)\r\n\r\n    return Model(\r\n        inputs=[inputs],\r\n        outputs=[outputs],\r\n        name='model'\r\n    )\r\n\r\n\r\ndef get_compat_model(inputs, layer_size, proj_size):\r\n\r\n    outputs = layers.RNN(\r\n        tf.compat.v1.nn.rnn_cell.LSTMCell(\r\n            layer_size,\r\n            num_proj=proj_size\r\n        ),\r\n        return_sequences=True\r\n    )(inputs)\r\n\r\n    return Model(\r\n        inputs=[inputs],\r\n        outputs=[outputs],\r\n        name='compat_model'\r\n    )\r\n\r\n\r\ndef main():\r\n    layer_size, proj_size = 64, 32\r\n    inputs = layers.Input(shape=(100, 50))\r\n\r\n    model = get_model(inputs, layer_size, proj_size)\r\n    compat_model = get_compat_model(inputs, layer_size, proj_size)\r\n\r\n    model.summary()\r\n    compat_model.summary()\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n*Output:*\r\n\r\n```\r\nModel: \"model\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         [(None, 100, 50)]         0         \r\n_________________________________________________________________\r\nrnn (RNN)                    (None, 100, 64)           29440     \r\n_________________________________________________________________\r\ndense (Dense)                (None, 100, 32)           2080      \r\n=================================================================\r\nTotal params: 31,520\r\nTrainable params: 31,520\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nModel: \"compat_model\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         [(None, 100, 50)]         0         \r\n_________________________________________________________________\r\nrnn_1 (RNN)                  (None, 100, 32)           23296     \r\n=================================================================\r\nTotal params: 23,296\r\nTrainable params: 23,296\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```", "There are a couple of reasons why you may be getting different numbers of\nparameters.  First of, iirc the projection layer doesn't have a bias term,\nso you may need to disable bias in your Dense layer.  Second, there may be\nsome differences in the LSTM layer.\n\nAnother thing to consider is that the layers may have different\ninitializers; so you may have to add some manual initializer calls to the\nkeras LSTMCell constructor to ensure consistent initialization.\n\nFinally, looks like *in your case* the set of variables created by the\nLSTMCells are different:\n\nHere's how I inspect the variables created by the cells:\n\n```python\nz = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(3), return_sequences=True)\nv = tf.keras.layers.RNN(tf.compat.v1.nn.rnn_cell.LSTMCell(3))\nz.build((3, 4, 5))\nv.build((3, 4, 5))\n\nIn [18]: [(x.name, x.shape) for x in z.variables]\nOut[18]:\n[('lstm_cell/kernel:0', TensorShape([5, 12])),\n ('lstm_cell/recurrent_kernel:0', TensorShape([3, 12])),\n ('lstm_cell/bias:0', TensorShape([12]))]\n\nIn [22]: [(x.name, x.shape) for x in v.variables]\nOut[22]:\n[('lstm_cell_1/kernel:0', TensorShape([8, 12])),\n ('lstm_cell_1/bias:0', TensorShape([12]))]\n```\n\nIn my case, the sizes are the same (just split up into different shapes);\nbut in your case they may be different - you want to investigate that the\nsame way.\n\n\nOn Wed, Jul 8, 2020 at 7:48 AM Stefan Falk <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> It seems that proj_size has been\n> removed.\n>\n> If I understand this correctly, then we just apply a Dense layer to the\n> RNN/LSTM output in order to project the particular output down to a desired\n> dimension.\n>\n> So doing this (note I am using tf.compat.v1.nn.rnn_cell.LSTMCell here):\n>\n> outputs = layers.RNN(\n>     tf.compat.v1.nn.rnn_cell.LSTMCell(\n>         layer_size,\n>         num_proj=proj_size\n>     ),\n>     return_sequences=True\n> )(inputs)\n>\n> Should be similar to this:\n>\n> x = layers.RNN(\n>     layers.LSTMCell(layer_size),\n>     return_sequences=True\n> )(inputs)\n> outputs = layers.Dense(proj_size)(x)\n>\n> Is this correct?\n>\n> Here's a complete example:\n>\n> import tensorflow as tffrom tensorflow.keras import layersfrom tensorflow.python.keras import Model\n>\n> def get_model(inputs, layer_size, proj_size):\n>\n>     x = layers.RNN(\n>         layers.LSTMCell(layer_size),\n>         return_sequences=True\n>     )(inputs)\n>\n>     outputs = layers.Dense(proj_size)(x)\n>\n>     return Model(\n>         inputs=[inputs],\n>         outputs=[outputs],\n>         name='model'\n>     )\n>\n> def get_compat_model(inputs, layer_size, proj_size):\n>\n>     outputs = layers.RNN(\n>         tf.compat.v1.nn.rnn_cell.LSTMCell(\n>             layer_size,\n>             num_proj=proj_size\n>         ),\n>         return_sequences=True\n>     )(inputs)\n>\n>     return Model(\n>         inputs=[inputs],\n>         outputs=[outputs],\n>         name='compat_model'\n>     )\n>\n> def main():\n>     layer_size, proj_size = 64, 32\n>     inputs = layers.Input(shape=(100, 50))\n>\n>     model = get_model(inputs, layer_size, proj_size)\n>     compat_model = get_compat_model(inputs, layer_size, proj_size)\n>\n>     model.summary()\n>     compat_model.summary()\n>\n> if __name__ == '__main__':\n>     main()\n>\n> *Output:*\n>\n> Model: \"model\"\n> _________________________________________________________________\n> Layer (type)                 Output Shape              Param #\n> =================================================================\n> input_1 (InputLayer)         [(None, 100, 50)]         0\n> _________________________________________________________________\n> rnn (RNN)                    (None, 100, 64)           29440\n> _________________________________________________________________\n> dense (Dense)                (None, 100, 32)           2080\n> =================================================================\n> Total params: 31,520\n> Trainable params: 31,520\n> Non-trainable params: 0\n> _________________________________________________________________\n> Model: \"compat_model\"\n> _________________________________________________________________\n> Layer (type)                 Output Shape              Param #\n> =================================================================\n> input_1 (InputLayer)         [(None, 100, 50)]         0\n> _________________________________________________________________\n> rnn_1 (RNN)                  (None, 100, 32)           23296\n> =================================================================\n> Total params: 23,296\n> Trainable params: 23,296\n> Non-trainable params: 0\n> _________________________________________________________________\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/3463#issuecomment-655566693>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AANWFGZPUIVBLH4EKEIGDLDR2SBLRANCNFSM4CKLUSGQ>\n> .\n>\n", "@ebrevdo Okay, I see. Thank you for the example.\r\n\r\nI can see that running the following gives the same number of trainable parameters:\r\n\r\n```python\r\ni = tf.keras.layers.Input(shape=(4, 8))\r\nv2 = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(3), return_sequences=True)(i)\r\nModel(inputs=[i], outputs=[v2], name='v2').summary()\r\n\r\ni = tf.keras.layers.Input(shape=(4, 8))\r\nv2 = tf.keras.layers.RNN(tf.compat.v1.nn.rnn_cell.LSTMCell(3), return_sequences=True)(i)\r\nModel(inputs=[i], outputs=[v2], name='compat').summary()\r\n```\r\n\r\nOutput:\r\n\r\n```\r\nModel: \"v2\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         [(None, 4, 8)]            0         \r\n_________________________________________________________________\r\nrnn (RNN)                    (None, 4, 3)              144       \r\n=================================================================\r\nTotal params: 144\r\nTrainable params: 144\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n\r\nModel: \"compat\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_2 (InputLayer)         [(None, 4, 8)]            0         \r\n_________________________________________________________________\r\nrnn_1 (RNN)                  (None, 4, 3)              144       \r\n=================================================================\r\nTotal params: 144\r\nTrainable params: 144\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```\r\n\r\nBut what I do not understand is the `num_proj` argument in the `compat` cell. How can I reproduce (notice `num_proj`) with `tf.keras.layers.LSTMCell`?:\r\n\r\n```python\r\ni = tf.keras.layers.Input(shape=(4, 8))\r\nv2 = tf.keras.layers.RNN(tf.compat.v1.nn.rnn_cell.LSTMCell(3, num_proj=2), return_sequences=True)(i)\r\nModel(inputs=[i], outputs=[v2], name='compat').summary()\r\n```", "Looking carefully at the code, it seems like this functionality is not\nsupported by the keras LSTMCell.  Projection is applied\n<https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/ops/rnn_cell_impl.py#L1061>\nto the h (m) state that gets passed to the next frame.  You would need to\ncreate your own wrapper RNNCell that has this behavior, and wrap the keras\nLSTMCell in it.\n\nOn Thu, Jul 9, 2020 at 6:05 AM Stefan Falk <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> Okay, I see. Thank you for the\n> example.\n>\n> I can see that running the following gives the same number of trainable\n> parameters:\n>\n> i = tf.keras.layers.Input(shape=(4, 8))v2 = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(3), return_sequences=True)(i)Model(inputs=[i], outputs=[v2], name='v2').summary()\n> i = tf.keras.layers.Input(shape=(4, 8))v2 = tf.keras.layers.RNN(tf.compat.v1.nn.rnn_cell.LSTMCell(3), return_sequences=True)(i)Model(inputs=[i], outputs=[v2], name='compat').summary()\n>\n> Output:\n>\n> Model: \"v2\"\n> _________________________________________________________________\n> Layer (type)                 Output Shape              Param #\n> =================================================================\n> input_1 (InputLayer)         [(None, 4, 8)]            0\n> _________________________________________________________________\n> rnn (RNN)                    (None, 4, 3)              144\n> =================================================================\n> Total params: 144\n> Trainable params: 144\n> Non-trainable params: 0\n> _________________________________________________________________\n>\n> Model: \"compat\"\n> _________________________________________________________________\n> Layer (type)                 Output Shape              Param #\n> =================================================================\n> input_2 (InputLayer)         [(None, 4, 8)]            0\n> _________________________________________________________________\n> rnn_1 (RNN)                  (None, 4, 3)              144\n> =================================================================\n> Total params: 144\n> Trainable params: 144\n> Non-trainable params: 0\n> _________________________________________________________________\n>\n> But what I do not understand is the num_proj argument in the compat cell.\n> How can I reproduce (notice num_proj) with tf.keras.layers.LSTMCell?:\n>\n> i = tf.keras.layers.Input(shape=(4, 8))v2 = tf.keras.layers.RNN(tf.compat.v1.nn.rnn_cell.LSTMCell(3, num_proj=2), return_sequences=True)(i)Model(inputs=[i], outputs=[v2], name='compat').summary()\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/3463#issuecomment-656115292>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AANWFG3QHO3TPQF34O63U7TR2W6DLANCNFSM4CKLUSGQ>\n> .\n>\n", "@ebrevdo Ah, I see. I think now it's clear why the code I posted at first was using `tf.compat.v1.nn.rnn_cell.LSTMCell` instead of the TF 2.0 version of it. Interesting that this parameter has been dropped. \r\n\r\nThank you for your support \ud83d\udc4d "]}, {"number": 3462, "title": "Correction in Dequantize comments", "body": "A small correction in Dequantize Comments\n", "comments": ["Can one of the admins verify this patch?\n", "I signed it!\n", "Thanks!\n"]}, {"number": 3461, "title": "Corrected a typo in Dequantize comments", "body": "Given dequantize pseudocode is same as quantization. Corrected that\n\n`range_scale = number_of_steps / range` --> `range_scale = range / number_of_steps`\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 3460, "title": "Exponential Moving Average of trained variables in tf.contrib.learn.estimators.estimator", "body": "Hi,\n\nAs mentioned in the cifar10 tutorial, it is often useful to use an exponential moving average of the trained variables at prediction time.\n\nFrom my understanding, in it's current form, the class BaseEstimator does not allow to do so. \n\nThe _infer_model method of BaseEstimator would need to create a saver object that restores the averaged version of the trained variables, and the saver object would then need to be cascaded into graph_actions.infer and ultimately down to graph_actions.run_feeds.\n\nWhilst overriding a class method is not a big deal, I was wondering if there was a neat way of achieving the end goal without having to refactor the graph_actions.\n\nBest Regards,\n\nMarco\n", "comments": ["@martinwicke Can you comment please?\n", "I think if you simply add the moving averages to the graph and explicitly\nadd their output to the VARIABLES collection they will be saved and you can\nuse them in the inference graph.\n\nThis is assuming you use the Estimator class. There should be no need to\noverride anything.\nOn Mon, Aug 15, 2016 at 16:37 Daniel W Mane notifications@github.com\nwrote:\n\n> @martinwicke https://github.com/martinwicke Can you comment please?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3460#issuecomment-239960552,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_XL8t3C19ix8K12DAO0Uz5Ip8oOUks5qgPgbgaJpZM4JSlat\n> .\n", "@martinwicke, is the gist close to what you had in mind?\n[Estimator and moving average of trained variables](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c)\n\nA few points worth mentioning:\n- There  is no need to explicitly add the shadow variables to the VARIABLES collection. [This is automatically done.](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L31)\n-  [At inference time](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L37) I assign the value of the shadow variables to the graph variables using [tf.assign](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L16)\n- With [tf.control_dependencies and tf.identity](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L39) I can enforce the output of the linear layer to depend on the assign operation\n\nThanks\n\nMarco\n", "That looks right to me. Nicely done.\n\nOn Wed, Sep 7, 2016 at 3:28 AM, marcoadurno notifications@github.com\nwrote:\n\n> @martinwicke https://github.com/martinwicke, is the gist close to what\n> you had in mind?\n> Estimator and moving average of trained variables\n> https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c\n> \n> A few points worth mentioning:\n> \n>    -\n> \n>    There is no need to explicitly add the shadow variables to the\n>    VARIABLES collection. This is automatically done.\n>    https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L31\n>    -\n> \n>    At inference time\n>    https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L37\n>    I assign the value of the shadow variables to the graph variables using\n>    tf.assign\n>    https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L16\n>    -\n> \n>    With tf.control_dependencies and tf.identity\n>    https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L39\n>    I can enforce the output of the linear layer to depend on the assign\n>    operation\n> \n> Thanks\n> \n> Marco\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3460#issuecomment-245239464,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_QmiaysDxARg7UDhZ1naQAKLvNxBks5qnpHMgaJpZM4JSlat\n> .\n", "Thanks for the hint. I'll close the issue as the API already supports the requested functionality. \n", "@marcoadurno \r\nAlthough things have been going on for a long time, there is still something to explain.\r\n\r\n**The restoring operation should be executed only once, and before any inference.**\r\n\r\nIn your code this operation will be executed every time `_infer()` is invoked, and if there are multiple layers (for example, your model has 3 dense layers), you can't restore the variables from the very beginning, you can only restore them after all layers (thus all variables) have been created. but when the variables are created, they have been calculated at least once, so the first batch will get the wrong result.\r\n\r\nThe way to solve this problem is restoring the variables in other place.\r\n\r\n1. In the training phase, create ema instance and track moving averages:\r\n    ```python\r\n    def track_params_averages():\r\n        \"\"\"\r\n        Track the moving averages of parameters.\r\n        Must be invoked after `infer()` and before `train()`.\r\n\r\n        :return:\r\n                ema:                    `tf.train.ExponentialMovingAverage`\r\n                params_averages_op:     operator that tracking averages\r\n        \"\"\"\r\n        ema = tf.train.ExponentialMovingAverage(FLAGS.params_moving_average_decay)\r\n        params = tf.trainable_variables()\r\n        params_averages_op = ema.apply(params)\r\n        return ema, params_averages_op\r\n\r\n\r\n    def model_fn_train(features, labels, params):\r\n        model = Model(params)\r\n        logits = model.infer(features)\r\n\r\n        _, params_averages_op = track_params_averages()\r\n\r\n        ....\r\n\r\n        # Note that the UPDATE_OPS must be executed before applying gradients,\r\n        # and tracking variables averages must be done after applying gradients.\r\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n        with tf.control_dependencies(update_ops):\r\n            gradients = opt.compute_gradients(total_loss)\r\n            apply_gradients_op = opt.apply_gradients(gradients, global_step=global_step)\r\n\r\n        with tf.control_dependencies([apply_gradients_op]):\r\n            params_averages_op = tf.group(params_averages_op)\r\n\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\r\n    ```\r\n\r\n1. In the evaluation phase, create a SessionRunHook to restore the averages:\r\n     ```python\r\n    class RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n        \"\"\"\r\n        Replace parameters with their moving averages.\r\n        This operation should be executed only once, and before any inference.\r\n        \"\"\"\r\n        def __init__(self, ema):\r\n            \"\"\"\r\n            :param ema:         tf.train.ExponentialMovingAverage\r\n            \"\"\"\r\n            super(RestoreParametersAverageValues, self).__init__()\r\n            self._ema = ema\r\n            self._restore_ops = None\r\n\r\n        def begin(self):\r\n            \"\"\" Create restoring operations before the graph been finalized. \"\"\"\r\n            ema_variables = tf.moving_average_variables()\r\n            self._restore_ops = [tf.assign(x, self._ema.average(x)) for x in ema_variables]\r\n\r\n        def after_create_session(self, session, coord):\r\n            \"\"\" Restore the parameters right after the session been created. \"\"\"\r\n            session.run(self._restore_ops)\r\n\r\n\r\n    def model_fn_eval(features, labels, params):\r\n        model = Model(params)\r\n        logits = model.infer(features)\r\n\r\n        ema, _ = track_params_averages()\r\n\r\n        ...\r\n\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=tf.estimator.ModeKeys.PREDICT,\r\n            predictions={...},\r\n            prediction_hooks=[RestoreParametersAverageValues(ema)],\r\n        )\r\n    ```", "> @martinwicke, is the gist close to what you had in mind?\r\n> [Estimator and moving average of trained variables](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c)\r\n> \r\n> A few points worth mentioning:\r\n> \r\n> * There  is no need to explicitly add the shadow variables to the VARIABLES collection. [This is automatically done.](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L31)\r\n> * [At inference time](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L37) I assign the value of the shadow variables to the graph variables using [tf.assign](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L16)\r\n> * With [tf.control_dependencies and tf.identity](https://gist.github.com/marcoadurno/1359e49e50a9237b68181a29d104af8c#file-estimator_ema-py-L39) I can enforce the output of the linear layer to depend on the assign operation\r\n> \r\n> Thanks\r\n> \r\n> Marco\r\n\r\nwhat if you want to continue training the model after the model evaluation? ", "> @marcoadurno\r\n> Although things have been going on for a long time, there is still something to explain.\r\n> \r\n> **The restoring operation should be executed only once, and before any inference.**\r\n> \r\n> In your code this operation will be executed every time `_infer()` is invoked, and if there are multiple layers (for example, your model has 3 dense layers), you can't restore the variables from the very beginning, you can only restore them after all layers (thus all variables) have been created. but when the variables are created, they have been calculated at least once, so the first batch will get the wrong result.\r\n> \r\n> The way to solve this problem is restoring the variables in other place.\r\n> \r\n> 1. In the training phase, create ema instance and track moving averages:\r\n>    ```python\r\n>    def track_params_averages():\r\n>        \"\"\"\r\n>        Track the moving averages of parameters.\r\n>        Must be invoked after `infer()` and before `train()`.\r\n>    \r\n>        :return:\r\n>                ema:                    `tf.train.ExponentialMovingAverage`\r\n>                params_averages_op:     operator that tracking averages\r\n>        \"\"\"\r\n>        ema = tf.train.ExponentialMovingAverage(FLAGS.params_moving_average_decay)\r\n>        params = tf.trainable_variables()\r\n>        params_averages_op = ema.apply(params)\r\n>        return ema, params_averages_op\r\n>    \r\n>    \r\n>    def model_fn_train(features, labels, params):\r\n>        model = Model(params)\r\n>        logits = model.infer(features)\r\n>    \r\n>        _, params_averages_op = track_params_averages()\r\n>    \r\n>        ....\r\n>    \r\n>        # Note that the UPDATE_OPS must be executed before applying gradients,\r\n>        # and tracking variables averages must be done after applying gradients.\r\n>        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n>        with tf.control_dependencies(update_ops):\r\n>            gradients = opt.compute_gradients(total_loss)\r\n>            apply_gradients_op = opt.apply_gradients(gradients, global_step=global_step)\r\n>    \r\n>        with tf.control_dependencies([apply_gradients_op]):\r\n>            params_averages_op = tf.group(params_averages_op)\r\n>    \r\n>        return tf.estimator.EstimatorSpec(\r\n>            mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\r\n>    ```\r\n> 2. In the evaluation phase, create a SessionRunHook to restore the averages:\r\n>    ```python\r\n>    class RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n>       \"\"\"\r\n>       Replace parameters with their moving averages.\r\n>       This operation should be executed only once, and before any inference.\r\n>       \"\"\"\r\n>       def __init__(self, ema):\r\n>           \"\"\"\r\n>           :param ema:         tf.train.ExponentialMovingAverage\r\n>           \"\"\"\r\n>           super(RestoreParametersAverageValues, self).__init__()\r\n>           self._ema = ema\r\n>           self._restore_ops = None\r\n>    \r\n>       def begin(self):\r\n>           \"\"\" Create restoring operations before the graph been finalized. \"\"\"\r\n>           ema_variables = tf.moving_average_variables()\r\n>           self._restore_ops = [tf.assign(x, self._ema.average(x)) for x in ema_variables]\r\n>    \r\n>       def after_create_session(self, session, coord):\r\n>           \"\"\" Restore the parameters right after the session been created. \"\"\"\r\n>           session.run(self._restore_ops)\r\n>    \r\n>    \r\n>    def model_fn_eval(features, labels, params):\r\n>       model = Model(params)\r\n>       logits = model.infer(features)\r\n>    \r\n>       ema, _ = track_params_averages()\r\n>    \r\n>       ...\r\n>    \r\n>       return tf.estimator.EstimatorSpec(\r\n>           mode=tf.estimator.ModeKeys.PREDICT,\r\n>           predictions={...},\r\n>           prediction_hooks=[RestoreParametersAverageValues(ema)],\r\n>       )\r\n>    ```\r\n\r\nwhat is `train_op ` here?", "> @marcoadurno\r\n> Although things have been going on for a long time, there is still something to explain.\r\n> \r\n> **The restoring operation should be executed only once, and before any inference.**\r\n> \r\n> In your code this operation will be executed every time `_infer()` is invoked, and if there are multiple layers (for example, your model has 3 dense layers), you can't restore the variables from the very beginning, you can only restore them after all layers (thus all variables) have been created. but when the variables are created, they have been calculated at least once, so the first batch will get the wrong result.\r\n> \r\n> The way to solve this problem is restoring the variables in other place.\r\n> \r\n> 1. In the training phase, create ema instance and track moving averages:\r\n>    ```python\r\n>    def track_params_averages():\r\n>        \"\"\"\r\n>        Track the moving averages of parameters.\r\n>        Must be invoked after `infer()` and before `train()`.\r\n>    \r\n>        :return:\r\n>                ema:                    `tf.train.ExponentialMovingAverage`\r\n>                params_averages_op:     operator that tracking averages\r\n>        \"\"\"\r\n>        ema = tf.train.ExponentialMovingAverage(FLAGS.params_moving_average_decay)\r\n>        params = tf.trainable_variables()\r\n>        params_averages_op = ema.apply(params)\r\n>        return ema, params_averages_op\r\n>    \r\n>    \r\n>    def model_fn_train(features, labels, params):\r\n>        model = Model(params)\r\n>        logits = model.infer(features)\r\n>    \r\n>        _, params_averages_op = track_params_averages()\r\n>    \r\n>        ....\r\n>    \r\n>        # Note that the UPDATE_OPS must be executed before applying gradients,\r\n>        # and tracking variables averages must be done after applying gradients.\r\n>        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n>        with tf.control_dependencies(update_ops):\r\n>            gradients = opt.compute_gradients(total_loss)\r\n>            apply_gradients_op = opt.apply_gradients(gradients, global_step=global_step)\r\n>    \r\n>        with tf.control_dependencies([apply_gradients_op]):\r\n>            params_averages_op = tf.group(params_averages_op)\r\n>    \r\n>        return tf.estimator.EstimatorSpec(\r\n>            mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\r\n>    ```\r\n> 2. In the evaluation phase, create a SessionRunHook to restore the averages:\r\n>    ```python\r\n>    class RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n>       \"\"\"\r\n>       Replace parameters with their moving averages.\r\n>       This operation should be executed only once, and before any inference.\r\n>       \"\"\"\r\n>       def __init__(self, ema):\r\n>           \"\"\"\r\n>           :param ema:         tf.train.ExponentialMovingAverage\r\n>           \"\"\"\r\n>           super(RestoreParametersAverageValues, self).__init__()\r\n>           self._ema = ema\r\n>           self._restore_ops = None\r\n>    \r\n>       def begin(self):\r\n>           \"\"\" Create restoring operations before the graph been finalized. \"\"\"\r\n>           ema_variables = tf.moving_average_variables()\r\n>           self._restore_ops = [tf.assign(x, self._ema.average(x)) for x in ema_variables]\r\n>    \r\n>       def after_create_session(self, session, coord):\r\n>           \"\"\" Restore the parameters right after the session been created. \"\"\"\r\n>           session.run(self._restore_ops)\r\n>    \r\n>    \r\n>    def model_fn_eval(features, labels, params):\r\n>       model = Model(params)\r\n>       logits = model.infer(features)\r\n>    \r\n>       ema, _ = track_params_averages()\r\n>    \r\n>       ...\r\n>    \r\n>       return tf.estimator.EstimatorSpec(\r\n>           mode=tf.estimator.ModeKeys.PREDICT,\r\n>           predictions={...},\r\n>           prediction_hooks=[RestoreParametersAverageValues(ema)],\r\n>       )\r\n>    ```\r\n\r\n```python\r\nclass RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n          def __init__(self, restore_weight_backups, assign_dep ):\r\n              '''\r\n              with tf.variable_scope('BackupVariables'):\r\n                  backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\r\n                                                initializer=var.initialized_value())\r\n                                for var in model_vars]\r\n\r\n              save_weight_backups = tf.group(*(tf.assign(bck, var.read_value())\r\n                                              for var, bck in zip(model_vars, backup_vars)))\r\n              restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value())\r\n                                              for var, bck in zip(model_vars, backup_vars)))\r\n                                              \r\n              with tf.control_dependencies( [ save_weight_backups ] ):\r\n                assign_dep = tf.group(*[tf.assign(x, ema.average(x)) for x in model_vars])\r\n                \r\n              '''\r\n              super(RestoreParametersAverageValues, self).__init__()\r\n              self._assign_dep = assign_dep # assign ema var to var\r\n              self._restore_weight_backups = restore_weight_backups # restore weight back\r\n\r\n          def after_create_session(self, session, coord):\r\n              \"\"\" Restore the parameters right before run. \"\"\"\r\n              session.run(self._assign_dep)\r\n\r\n          def end(self, session):\r\n               session.run(self._restore_weight_backups)\r\n```\r\n\r\nI was wondering, will this work? I am kinda confused", "> > @marcoadurno\r\n> > Although things have been going on for a long time, there is still something to explain.\r\n> > **The restoring operation should be executed only once, and before any inference.**\r\n> > In your code this operation will be executed every time `_infer()` is invoked, and if there are multiple layers (for example, your model has 3 dense layers), you can't restore the variables from the very beginning, you can only restore them after all layers (thus all variables) have been created. but when the variables are created, they have been calculated at least once, so the first batch will get the wrong result.\r\n> > The way to solve this problem is restoring the variables in other place.\r\n> > \r\n> > 1. In the training phase, create ema instance and track moving averages:\r\n> >    ```python\r\n> >    def track_params_averages():\r\n> >        \"\"\"\r\n> >        Track the moving averages of parameters.\r\n> >        Must be invoked after `infer()` and before `train()`.\r\n> >    \r\n> >        :return:\r\n> >                ema:                    `tf.train.ExponentialMovingAverage`\r\n> >                params_averages_op:     operator that tracking averages\r\n> >        \"\"\"\r\n> >        ema = tf.train.ExponentialMovingAverage(FLAGS.params_moving_average_decay)\r\n> >        params = tf.trainable_variables()\r\n> >        params_averages_op = ema.apply(params)\r\n> >        return ema, params_averages_op\r\n> >    \r\n> >    \r\n> >    def model_fn_train(features, labels, params):\r\n> >        model = Model(params)\r\n> >        logits = model.infer(features)\r\n> >    \r\n> >        _, params_averages_op = track_params_averages()\r\n> >    \r\n> >        ....\r\n> >    \r\n> >        # Note that the UPDATE_OPS must be executed before applying gradients,\r\n> >        # and tracking variables averages must be done after applying gradients.\r\n> >        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n> >        with tf.control_dependencies(update_ops):\r\n> >            gradients = opt.compute_gradients(total_loss)\r\n> >            apply_gradients_op = opt.apply_gradients(gradients, global_step=global_step)\r\n> >    \r\n> >        with tf.control_dependencies([apply_gradients_op]):\r\n> >            params_averages_op = tf.group(params_averages_op)\r\n> >    \r\n> >        return tf.estimator.EstimatorSpec(\r\n> >            mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\r\n> >    ```\r\n> > 2. In the evaluation phase, create a SessionRunHook to restore the averages:\r\n> >    ```python\r\n> >    class RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n> >       \"\"\"\r\n> >       Replace parameters with their moving averages.\r\n> >       This operation should be executed only once, and before any inference.\r\n> >       \"\"\"\r\n> >       def __init__(self, ema):\r\n> >           \"\"\"\r\n> >           :param ema:         tf.train.ExponentialMovingAverage\r\n> >           \"\"\"\r\n> >           super(RestoreParametersAverageValues, self).__init__()\r\n> >           self._ema = ema\r\n> >           self._restore_ops = None\r\n> >    \r\n> >       def begin(self):\r\n> >           \"\"\" Create restoring operations before the graph been finalized. \"\"\"\r\n> >           ema_variables = tf.moving_average_variables()\r\n> >           self._restore_ops = [tf.assign(x, self._ema.average(x)) for x in ema_variables]\r\n> >    \r\n> >       def after_create_session(self, session, coord):\r\n> >           \"\"\" Restore the parameters right after the session been created. \"\"\"\r\n> >           session.run(self._restore_ops)\r\n> >    \r\n> >    \r\n> >    def model_fn_eval(features, labels, params):\r\n> >       model = Model(params)\r\n> >       logits = model.infer(features)\r\n> >    \r\n> >       ema, _ = track_params_averages()\r\n> >    \r\n> >       ...\r\n> >    \r\n> >       return tf.estimator.EstimatorSpec(\r\n> >           mode=tf.estimator.ModeKeys.PREDICT,\r\n> >           predictions={...},\r\n> >           prediction_hooks=[RestoreParametersAverageValues(ema)],\r\n> >       )\r\n> >    ```\r\n> \r\n> what is `train_op ` here?\r\n\r\nIt doesn't matter, right?\r\nDue to the confidentiality agreement, I can't upload the full project, the following is the newest version of model_fn_train() and model_fn_eval():\r\n\r\n```python\r\ndef model_fn_train(features, labels, params):\r\n    \"\"\"\r\n    All tensors must be created in the model_fn / input_fn function,\r\n    otherwise tf.estimator.Estimator will throw an exception.\r\n    \"\"\"\r\n    device_name = '/{}:{}'.format(DEVICE_CPU, DEVICE_ID_DEFAULT) if params.force_cpu else None\r\n    with tf.device(device_name):\r\n        model = Model(params)\r\n\r\n        global_step = tf.train.get_or_create_global_step()\r\n\r\n        logits = model.infer(features, mode=tf.estimator.ModeKeys.TRAIN)\r\n\r\n        _, params_averages_op = model.track_params_averages()\r\n\r\n        loss = model.get_loss(logits, labels)\r\n\r\n        train_op = model.train(loss, global_step, params_averages_op)\r\n\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=train_op)\r\n\r\ndef model_fn_eval(features, labels, params):\r\n    \"\"\"\r\n    All tensors must be created in the model_fn / input_fn function,\r\n    otherwise tf.estimator.Estimator will throw an exception.\r\n    \"\"\"\r\n    features_and_labels = features\r\n    features = features_and_labels['images']\r\n    labels = features_and_labels['labels']\r\n\r\n    device_name = '/{}:{}'.format(DEVICE_CPU, DEVICE_ID_DEFAULT) if params.force_cpu else None\r\n    with tf.device(device_name):\r\n        model = Model(params)\r\n\r\n        logits = model.infer(features, mode=tf.estimator.ModeKeys.PREDICT)\r\n\r\n        ema, _ = model.track_params_averages()\r\n\r\n        predicted_prob = model.predict(logits)\r\n\r\n        predictions = {\r\n            'predicted_prob': predicted_prob,\r\n            'labels': labels,\r\n        }\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=tf.estimator.ModeKeys.PREDICT,\r\n            predictions=predictions,\r\n            prediction_hooks=[RestoreParametersAverageValues(ema)],\r\n        )\r\n```", "> ```python\r\n> after_create_session\r\n> ```\r\n\r\nThanks for the explaning, But what if you want to restore the variable to the original variable to continue training? ", "> ```python\r\n> class RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n>           def __init__(self, restore_weight_backups, assign_dep ):\r\n>               '''\r\n>               with tf.variable_scope('BackupVariables'):\r\n>                   backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\r\n>                                                 initializer=var.initialized_value())\r\n>                                 for var in model_vars]\r\n> \r\n>               save_weight_backups = tf.group(*(tf.assign(bck, var.read_value())\r\n>                                               for var, bck in zip(model_vars, backup_vars)))\r\n>               restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value())\r\n>                                               for var, bck in zip(model_vars, backup_vars)))\r\n>                                               \r\n>               with tf.control_dependencies( [ save_weight_backups ] ):\r\n>                 assign_dep = tf.group(*[tf.assign(x, ema.average(x)) for x in model_vars])\r\n>                 \r\n>               '''\r\n>               super(RestoreParametersAverageValues, self).__init__()\r\n>               self._assign_dep = assign_dep # assign ema var to var\r\n>               self._restore_weight_backups = restore_weight_backups # restore weight back\r\n> \r\n>           def after_create_session(self, session, coord):\r\n>               \"\"\" Restore the parameters right before run. \"\"\"\r\n>               session.run(self._assign_dep)\r\n> \r\n>           def end(self, session):\r\n>                session.run(self._restore_weight_backups)\r\n> ```\r\n> \r\n> I was wondering, will this work? I am kinda confused\r\n> \r\n> Thanks for the explaning, But what if you want to restore the variable to the original variable to continue training?\r\n\r\nYou don't need to save and restore the variables manually, 'tf.estimator.Estimator' will save and restore all the parameters automatically for you.\r\n\r\n```python\r\ndef train():\r\n    config = tf.ConfigProto()\r\n    config.intra_op_parallelism_threads = FLAGS.cpu_threads\r\n    config.inter_op_parallelism_threads = FLAGS.cpu_threads\r\n    config.gpu_options.allow_growth = True\r\n    config.log_device_placement = FLAGS.log_device_placement\r\n\r\n    estimator = tf.estimator.Estimator(\r\n        model_fn=model_fn_train,\r\n        model_dir=FLAGS.train_dir,\r\n        config=tf.estimator.RunConfig(\r\n            tf_random_seed=FLAGS.random_seed,\r\n            log_step_count_steps=FLAGS.log_frequency,\r\n            save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\r\n            session_config=config,\r\n        ),\r\n        params=FLAGS,\r\n    )\r\n\r\n    input_fn, iterator_initializer_hook = get_input(flags=FLAGS, mode=tf.estimator.ModeKeys.TRAIN)\r\n\r\n    logging_hook = tf.train.LoggingTensorHook(tensors={\r\n        'cross_entropy': 'loss/softmax_cross_entropy_loss/value',\r\n    }, every_n_iter=FLAGS.log_frequency)\r\n    hooks = [\r\n        iterator_initializer_hook,\r\n        logging_hook,\r\n    ]\r\n    if FLAGS.debug:\r\n        hooks.append(tf_debug.LocalCLIDebugHook())\r\n\r\n    estimator.train(input_fn=input_fn, steps=FLAGS.max_steps, hooks=hooks)\r\n```\r\n\r\nAll you need is replacing the parameters with their moving averages.", "> ```python\r\n> > ```python\r\n> > class RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n> >           def __init__(self, restore_weight_backups, assign_dep ):\r\n> >               '''\r\n> >               with tf.variable_scope('BackupVariables'):\r\n> >                   backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\r\n> >                                                 initializer=var.initialized_value())\r\n> >                                 for var in model_vars]\r\n> > \r\n> >               save_weight_backups = tf.group(*(tf.assign(bck, var.read_value())\r\n> >                                               for var, bck in zip(model_vars, backup_vars)))\r\n> >               restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value())\r\n> >                                               for var, bck in zip(model_vars, backup_vars)))\r\n> >                                               \r\n> >               with tf.control_dependencies( [ save_weight_backups ] ):\r\n> >                 assign_dep = tf.group(*[tf.assign(x, ema.average(x)) for x in model_vars])\r\n> >                 \r\n> >               '''\r\n> >               super(RestoreParametersAverageValues, self).__init__()\r\n> >               self._assign_dep = assign_dep # assign ema var to var\r\n> >               self._restore_weight_backups = restore_weight_backups # restore weight back\r\n> > \r\n> >           def after_create_session(self, session, coord):\r\n> >               \"\"\" Restore the parameters right before run. \"\"\"\r\n> >               session.run(self._assign_dep)\r\n> > \r\n> >           def end(self, session):\r\n> >                session.run(self._restore_weight_backups)\r\n> > ```\r\n> > \r\n> > \r\n> > I was wondering, will this work? I am kinda confused\r\n> > Thanks for the explaning, But what if you want to restore the variable to the original variable to continue training?\r\n> \r\n> \r\n> You don't need to save and restore the variables manually, 'tf.estimator.Estimator' will save and restore all the parameters automatically for you.\r\n> ```python\r\n> def train():\r\n>     config = tf.ConfigProto()\r\n>     config.intra_op_parallelism_threads = FLAGS.cpu_threads\r\n>     config.inter_op_parallelism_threads = FLAGS.cpu_threads\r\n>     config.gpu_options.allow_growth = True\r\n>     config.log_device_placement = FLAGS.log_device_placement\r\n> \r\n>     estimator = tf.estimator.Estimator(\r\n>         model_fn=model_fn_train,\r\n>         model_dir=FLAGS.train_dir,\r\n>         config=tf.estimator.RunConfig(\r\n>             tf_random_seed=FLAGS.random_seed,\r\n>             log_step_count_steps=FLAGS.log_frequency,\r\n>             save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\r\n>             session_config=config,\r\n>         ),\r\n>         params=FLAGS,\r\n>     )\r\n> \r\n>     input_fn, iterator_initializer_hook = get_input(flags=FLAGS, mode=tf.estimator.ModeKeys.TRAIN)\r\n> \r\n>     logging_hook = tf.train.LoggingTensorHook(tensors={\r\n>         'cross_entropy': 'loss/softmax_cross_entropy_loss/value',\r\n>     }, every_n_iter=FLAGS.log_frequency)\r\n>     hooks = [\r\n>         iterator_initializer_hook,\r\n>         logging_hook,\r\n>     ]\r\n>     if FLAGS.debug:\r\n>         hooks.append(tf_debug.LocalCLIDebugHook())\r\n> \r\n>     estimator.train(input_fn=input_fn, steps=FLAGS.max_steps, hooks=hooks)\r\n> ```\r\n> \r\n> \r\n> All you need is replacing the parameters with their moving averages.\r\n> ```\r\n\r\nThanks! what is `\r\nget_input` ?  I mean during  the online training, how do you restore the var back to original variable and continue training? Because we want to do evaluation during training.", "> > ```python\r\n> > > ```python\r\n> > > class RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n> > >           def __init__(self, restore_weight_backups, assign_dep ):\r\n> > >               '''\r\n> > >               with tf.variable_scope('BackupVariables'):\r\n> > >                   backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\r\n> > >                                                 initializer=var.initialized_value())\r\n> > >                                 for var in model_vars]\r\n> > > \r\n> > >               save_weight_backups = tf.group(*(tf.assign(bck, var.read_value())\r\n> > >                                               for var, bck in zip(model_vars, backup_vars)))\r\n> > >               restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value())\r\n> > >                                               for var, bck in zip(model_vars, backup_vars)))\r\n> > >                                               \r\n> > >               with tf.control_dependencies( [ save_weight_backups ] ):\r\n> > >                 assign_dep = tf.group(*[tf.assign(x, ema.average(x)) for x in model_vars])\r\n> > >                 \r\n> > >               '''\r\n> > >               super(RestoreParametersAverageValues, self).__init__()\r\n> > >               self._assign_dep = assign_dep # assign ema var to var\r\n> > >               self._restore_weight_backups = restore_weight_backups # restore weight back\r\n> > > \r\n> > >           def after_create_session(self, session, coord):\r\n> > >               \"\"\" Restore the parameters right before run. \"\"\"\r\n> > >               session.run(self._assign_dep)\r\n> > > \r\n> > >           def end(self, session):\r\n> > >                session.run(self._restore_weight_backups)\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > I was wondering, will this work? I am kinda confused\r\n> > > Thanks for the explaning, But what if you want to restore the variable to the original variable to continue training?\r\n> > \r\n> > \r\n> > You don't need to save and restore the variables manually, 'tf.estimator.Estimator' will save and restore all the parameters automatically for you.\r\n> > ```python\r\n> > def train():\r\n> >     config = tf.ConfigProto()\r\n> >     config.intra_op_parallelism_threads = FLAGS.cpu_threads\r\n> >     config.inter_op_parallelism_threads = FLAGS.cpu_threads\r\n> >     config.gpu_options.allow_growth = True\r\n> >     config.log_device_placement = FLAGS.log_device_placement\r\n> > \r\n> >     estimator = tf.estimator.Estimator(\r\n> >         model_fn=model_fn_train,\r\n> >         model_dir=FLAGS.train_dir,\r\n> >         config=tf.estimator.RunConfig(\r\n> >             tf_random_seed=FLAGS.random_seed,\r\n> >             log_step_count_steps=FLAGS.log_frequency,\r\n> >             save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\r\n> >             session_config=config,\r\n> >         ),\r\n> >         params=FLAGS,\r\n> >     )\r\n> > \r\n> >     input_fn, iterator_initializer_hook = get_input(flags=FLAGS, mode=tf.estimator.ModeKeys.TRAIN)\r\n> > \r\n> >     logging_hook = tf.train.LoggingTensorHook(tensors={\r\n> >         'cross_entropy': 'loss/softmax_cross_entropy_loss/value',\r\n> >     }, every_n_iter=FLAGS.log_frequency)\r\n> >     hooks = [\r\n> >         iterator_initializer_hook,\r\n> >         logging_hook,\r\n> >     ]\r\n> >     if FLAGS.debug:\r\n> >         hooks.append(tf_debug.LocalCLIDebugHook())\r\n> > \r\n> >     estimator.train(input_fn=input_fn, steps=FLAGS.max_steps, hooks=hooks)\r\n> > ```\r\n> > \r\n> > \r\n> > All you need is replacing the parameters with their moving averages.\r\n> \r\n> Thanks! what is ` get_input` ? I mean during the online training, how do you restore the var back to original variable and continue training? Because we want to do evaluation during training.\r\n\r\n`tf.estimator.Estimator` will do this for you, of course you can evaluate the model during training.\r\nUse different processes to train and evaluate the model. Every time you evaluate the model, create a new instance of `tf.estimator.Estimator`, then it will use the newest value of moving averages of the parameters. \r\nMaybe you need to read the reference of this class.", "> ```python\r\n> > > ```python\r\n> > > > ```python\r\n> > > > class RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n> > > >           def __init__(self, restore_weight_backups, assign_dep ):\r\n> > > >               '''\r\n> > > >               with tf.variable_scope('BackupVariables'):\r\n> > > >                   backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\r\n> > > >                                                 initializer=var.initialized_value())\r\n> > > >                                 for var in model_vars]\r\n> > > > \r\n> > > >               save_weight_backups = tf.group(*(tf.assign(bck, var.read_value())\r\n> > > >                                               for var, bck in zip(model_vars, backup_vars)))\r\n> > > >               restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value())\r\n> > > >                                               for var, bck in zip(model_vars, backup_vars)))\r\n> > > >                                               \r\n> > > >               with tf.control_dependencies( [ save_weight_backups ] ):\r\n> > > >                 assign_dep = tf.group(*[tf.assign(x, ema.average(x)) for x in model_vars])\r\n> > > >                 \r\n> > > >               '''\r\n> > > >               super(RestoreParametersAverageValues, self).__init__()\r\n> > > >               self._assign_dep = assign_dep # assign ema var to var\r\n> > > >               self._restore_weight_backups = restore_weight_backups # restore weight back\r\n> > > > \r\n> > > >           def after_create_session(self, session, coord):\r\n> > > >               \"\"\" Restore the parameters right before run. \"\"\"\r\n> > > >               session.run(self._assign_dep)\r\n> > > > \r\n> > > >           def end(self, session):\r\n> > > >                session.run(self._restore_weight_backups)\r\n> > > > ```\r\n> > > > \r\n> > > > \r\n> > > > I was wondering, will this work? I am kinda confused\r\n> > > > Thanks for the explaning, But what if you want to restore the variable to the original variable to continue training?\r\n> > > \r\n> > > \r\n> > > You don't need to save and restore the variables manually, 'tf.estimator.Estimator' will save and restore all the parameters automatically for you.\r\n> > > ```python\r\n> > > def train():\r\n> > >     config = tf.ConfigProto()\r\n> > >     config.intra_op_parallelism_threads = FLAGS.cpu_threads\r\n> > >     config.inter_op_parallelism_threads = FLAGS.cpu_threads\r\n> > >     config.gpu_options.allow_growth = True\r\n> > >     config.log_device_placement = FLAGS.log_device_placement\r\n> > > \r\n> > >     estimator = tf.estimator.Estimator(\r\n> > >         model_fn=model_fn_train,\r\n> > >         model_dir=FLAGS.train_dir,\r\n> > >         config=tf.estimator.RunConfig(\r\n> > >             tf_random_seed=FLAGS.random_seed,\r\n> > >             log_step_count_steps=FLAGS.log_frequency,\r\n> > >             save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\r\n> > >             session_config=config,\r\n> > >         ),\r\n> > >         params=FLAGS,\r\n> > >     )\r\n> > > \r\n> > >     input_fn, iterator_initializer_hook = get_input(flags=FLAGS, mode=tf.estimator.ModeKeys.TRAIN)\r\n> > > \r\n> > >     logging_hook = tf.train.LoggingTensorHook(tensors={\r\n> > >         'cross_entropy': 'loss/softmax_cross_entropy_loss/value',\r\n> > >     }, every_n_iter=FLAGS.log_frequency)\r\n> > >     hooks = [\r\n> > >         iterator_initializer_hook,\r\n> > >         logging_hook,\r\n> > >     ]\r\n> > >     if FLAGS.debug:\r\n> > >         hooks.append(tf_debug.LocalCLIDebugHook())\r\n> > > \r\n> > >     estimator.train(input_fn=input_fn, steps=FLAGS.max_steps, hooks=hooks)\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > All you need is replacing the parameters with their moving averages.\r\n> > \r\n> > \r\n> > Thanks! what is ` get_input` ? I mean during the online training, how do you restore the var back to original variable and continue training? Because we want to do evaluation during training.\r\n> \r\n> \r\n> `tf.estimator.Estimator` will do this for you, of course you can evaluate the model during training.\r\n> Use different processes to train and evaluate the model. Every time you evaluate the model, create a new instance of `tf.estimator.Estimator`, then it will use the newest value of moving averages of the parameters.\r\n> Maybe you need to read the reference of this class.\r\n> ```\r\n\r\nThanks for the explanation. So basically all I need is the following? \r\n```python\r\n     if mode != tf.estimator.ModeKeys.TRAIN:\r\n          assign_eval_op_list = [tf.assign(x, ema.average(x)) for x in model_vars]\r\n          assign_eval_op_list.append( tf.assign(eval_flag[0], 1) )\r\n          assign_eval_op = tf.group( *assign_eval_op_list )\r\n          # # we use ema variable for testing \r\n          with tf.control_dependencies([assign_eval_op]):\r\n            output = tf.identity(output)\r\n            loss   = tf.identity(loss)\r\n\r\n```", "> > ```python\r\n> > > > ```python\r\n> > > > > ```python\r\n> > > > > class RestoreParametersAverageValues(tf.train.SessionRunHook):\r\n> > > > >           def __init__(self, restore_weight_backups, assign_dep ):\r\n> > > > >               '''\r\n> > > > >               with tf.variable_scope('BackupVariables'):\r\n> > > > >                   backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\r\n> > > > >                                                 initializer=var.initialized_value())\r\n> > > > >                                 for var in model_vars]\r\n> > > > > \r\n> > > > >               save_weight_backups = tf.group(*(tf.assign(bck, var.read_value())\r\n> > > > >                                               for var, bck in zip(model_vars, backup_vars)))\r\n> > > > >               restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value())\r\n> > > > >                                               for var, bck in zip(model_vars, backup_vars)))\r\n> > > > >                                               \r\n> > > > >               with tf.control_dependencies( [ save_weight_backups ] ):\r\n> > > > >                 assign_dep = tf.group(*[tf.assign(x, ema.average(x)) for x in model_vars])\r\n> > > > >                 \r\n> > > > >               '''\r\n> > > > >               super(RestoreParametersAverageValues, self).__init__()\r\n> > > > >               self._assign_dep = assign_dep # assign ema var to var\r\n> > > > >               self._restore_weight_backups = restore_weight_backups # restore weight back\r\n> > > > > \r\n> > > > >           def after_create_session(self, session, coord):\r\n> > > > >               \"\"\" Restore the parameters right before run. \"\"\"\r\n> > > > >               session.run(self._assign_dep)\r\n> > > > > \r\n> > > > >           def end(self, session):\r\n> > > > >                session.run(self._restore_weight_backups)\r\n> > > > > ```\r\n> > > > > \r\n> > > > > \r\n> > > > > I was wondering, will this work? I am kinda confused\r\n> > > > > Thanks for the explaning, But what if you want to restore the variable to the original variable to continue training?\r\n> > > > \r\n> > > > \r\n> > > > You don't need to save and restore the variables manually, 'tf.estimator.Estimator' will save and restore all the parameters automatically for you.\r\n> > > > ```python\r\n> > > > def train():\r\n> > > >     config = tf.ConfigProto()\r\n> > > >     config.intra_op_parallelism_threads = FLAGS.cpu_threads\r\n> > > >     config.inter_op_parallelism_threads = FLAGS.cpu_threads\r\n> > > >     config.gpu_options.allow_growth = True\r\n> > > >     config.log_device_placement = FLAGS.log_device_placement\r\n> > > > \r\n> > > >     estimator = tf.estimator.Estimator(\r\n> > > >         model_fn=model_fn_train,\r\n> > > >         model_dir=FLAGS.train_dir,\r\n> > > >         config=tf.estimator.RunConfig(\r\n> > > >             tf_random_seed=FLAGS.random_seed,\r\n> > > >             log_step_count_steps=FLAGS.log_frequency,\r\n> > > >             save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\r\n> > > >             session_config=config,\r\n> > > >         ),\r\n> > > >         params=FLAGS,\r\n> > > >     )\r\n> > > > \r\n> > > >     input_fn, iterator_initializer_hook = get_input(flags=FLAGS, mode=tf.estimator.ModeKeys.TRAIN)\r\n> > > > \r\n> > > >     logging_hook = tf.train.LoggingTensorHook(tensors={\r\n> > > >         'cross_entropy': 'loss/softmax_cross_entropy_loss/value',\r\n> > > >     }, every_n_iter=FLAGS.log_frequency)\r\n> > > >     hooks = [\r\n> > > >         iterator_initializer_hook,\r\n> > > >         logging_hook,\r\n> > > >     ]\r\n> > > >     if FLAGS.debug:\r\n> > > >         hooks.append(tf_debug.LocalCLIDebugHook())\r\n> > > > \r\n> > > >     estimator.train(input_fn=input_fn, steps=FLAGS.max_steps, hooks=hooks)\r\n> > > > ```\r\n> > > > \r\n> > > > \r\n> > > > All you need is replacing the parameters with their moving averages.\r\n> > > \r\n> > > \r\n> > > Thanks! what is ` get_input` ? I mean during the online training, how do you restore the var back to original variable and continue training? Because we want to do evaluation during training.\r\n> > \r\n> > \r\n> > `tf.estimator.Estimator` will do this for you, of course you can evaluate the model during training.\r\n> > Use different processes to train and evaluate the model. Every time you evaluate the model, create a new instance of `tf.estimator.Estimator`, then it will use the newest value of moving averages of the parameters.\r\n> > Maybe you need to read the reference of this class.\r\n> > ```\r\n> \r\n> Thanks for the explanation. So basically all I need is the following?\r\n> \r\n> ```python\r\n>      if mode != tf.estimator.ModeKeys.TRAIN:\r\n>           assign_eval_op_list = [tf.assign(x, ema.average(x)) for x in model_vars]\r\n>           assign_eval_op_list.append( tf.assign(eval_flag[0], 1) )\r\n>           assign_eval_op = tf.group( *assign_eval_op_list )\r\n>           # # we use ema variable for testing \r\n>           with tf.control_dependencies([assign_eval_op]):\r\n>             output = tf.identity(output)\r\n>             loss   = tf.identity(loss)\r\n> ```\r\n\r\nAs mentioned above, please make sure you won't fall into this pit:\r\n\r\n> **The restoring operation should be executed only once, and before any inference.**\r\n\r\n> In your code this operation will be executed every time `_infer()` is invoked, and if there are multiple layers (for example, your model has 3 dense layers), you can't restore the variables from the very beginning, you can only restore them after all layers (thus all variables) have been created. but when the variables are created, they have been calculated at least once, so the first batch will get the wrong result."]}, {"number": 3459, "title": "tf.cond blocks forever when one branch calls tf.random_crop trough tf.map_fn", "body": "I'm running tensorflow 0.9.0 on Python 3.5.2 using CUDA 7.5 on CentOS 7, and I keep running into very weird behaviour: tf.cond seems to stall forever when the non-active branch calls tf.random_crop. I've reduced my code to the following minimal example:\n\n```\nimport numpy as np\nimport tensorflow as tf\n\nIMG_WIDTH = 32\nIMG_HEIGHT = 32\nIMG_CHANNELS = 3\n\ndef distort_image(image):\n    # this should crop the whole image, i.e. do nothing!\n    return tf.random_crop(image, [IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n\nxx = np.random.normal(size=(4, IMG_HEIGHT, IMG_WIDTH, 3)).astype(np.float32)\n\ntf.reset_default_graph()\nx = tf.placeholder(tf.float32, shape=(None, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\nis_training = tf.placeholder(tf.bool)\nxp = tf.cond(is_training,  \n        lambda: tf.map_fn(distort_image, x, back_prop=False),  \n        lambda: tf.identity(x))  \n\ninit = tf.initialize_all_variables()\nwith tf.Session() as sess:\n    sess.run(init)\n    p = sess.run(xp, feed_dict={x: xx, is_training: False})\n```\n\nThe weird thing is that if `is_training` is set to True, the function runs through without problems. I.e., when you actually call the `tf.map_fn` branch, everything works out fine.\n", "comments": ["So, I played around with this a bit more: the behaviour is a bit different on CPU and on GPU.  On the CPU, the above code runs though just fine. For what it's worth, I'm using a TitanX using Cuda 7.5.\n", "It would be helpful if you could run the code in gdb and provide a gist with the full backtrace (\"thread apply all bt\").\n\nyou may need to run \"gdb --args python ./path/to/your/python/script\"\n", "For what it's worth, if I explicitly place `xp` on the CPU using a `device_scope`, I don't run into any issues. As far as I'm concerned, my issue is solved and this can be closed. \n", "@yuanbyu you have a change that probably fixes this, yes?\n", "Yes. It is CL/129785041 that you reviewed.  -Yuan\n\nOn Wed, Aug 10, 2016 at 9:22 AM, ebrevdo notifications@github.com wrote:\n\n> @yuanbyu https://github.com/yuanbyu you have a change that probably\n> fixes this, yes?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3459#issuecomment-238920817,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ACO993xsJR7iucLu13CJ0kn5aEyYwP-5ks5qefrGgaJpZM4JSiQc\n> .\n", "Thomas, can you confirm this bug is fixed?\n\nOn Wed, Aug 10, 2016 at 10:06 AM, Yuan Yu notifications@github.com wrote:\n\n> Yes. It is CL/129785041 that you reviewed. -Yuan\n> \n> On Wed, Aug 10, 2016 at 9:22 AM, ebrevdo notifications@github.com wrote:\n> \n> > @yuanbyu https://github.com/yuanbyu you have a change that probably\n> > fixes this, yes?\n> > \n> > \u2014\n> > You are receiving this because you were mentioned.\n> > Reply to this email directly, view it on GitHub\n> > <https://github.com/tensorflow/tensorflow/issues/\n> > 3459#issuecomment-238920817>,\n> > or mute the thread\n> > <https://github.com/notifications/unsubscribe-auth/\n> > ACO993xsJR7iucLu13CJ0kn5aEyYwP-5ks5qefrGgaJpZM4JSiQc>\n> > \n> > .\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3459#issuecomment-238933946,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim0IS4vKaibQh3PwhUW8Gn2uVRR4lks5qegT-gaJpZM4JSiQc\n> .\n", "Hi! Unfortunately I don't have the time to compile my own TF version right now, so I'll have to wait for the next RC-release to test this. \n", "You can download a nightly wheel.  See the readme.md on\ngithub/tensorflow/tensorflow.\n\nOn Aug 11, 2016 1:11 AM, \"Thomas Unterthiner\" notifications@github.com\nwrote:\n\n> Hi! Unfortunately I don't have the time to compile my own TF version right\n> now, so I'll have to wait for the next RC-release to test this.\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3459#issuecomment-239098202,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim5kFfllhwUnwO2QrOsIS-0nk4uOYks5qetk6gaJpZM4JSiQc\n> .\n", "Please close the issue once you see that it's been solved in the nightlies.\n", "This should have fixed at HEAD.  Please verify.\n", "I can confirm that the behavior seems fixed with the current nightlies\n"]}, {"number": 3458, "title": "fix sync update in distributed mnist demo", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@caisq could you take a look?\n", "Looking\n", "Can one of the admins verify this patch?\n", "Adding @jmchen-g \n", "https://github.com/tensorflow/tensorflow/issues/3457 provided more information\n", "@caisq / @jmchen-g should we go ahead to merge this?\n", "This fix is not right. The chief queue runner can only run by the chief. This seems to expose a bug somewhere but we have not figured it yet. We are in the middle of changing the sync_rep_optimizer so will come back to this after that change.\n", "Any updates on the sync mode?\n", "@jmchen-g any updates on this?\n", "Most of the updates are implemented internally and after they are verified, we will push it outside. That will take some time though. We can close this PR for now as the fix is not a real fix but happens to get around some issues in the current implementation. The new implementation should be more robust and easier to debug.\n", "hi @jmchen-g any updates on this? please :)", "@caisq, any update on this please?\n\nOn Thu, Jul 6, 2017 at 12:22 PM, Renato Marroquin <notifications@github.com>\nwrote:\n\n> hi @jmchen-g <https://github.com/jmchen-g> any updates on this?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/3458#issuecomment-313493621>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/APD49u1OCLjX_k7VO3cUzt-YTckqhiXLks5sLTP8gaJpZM4JSh4c>\n> .\n>\n"]}, {"number": 3457, "title": "Problem in distributed tensorflow demo?", "body": "### Environment info\n\nOperating System:\nKubernetes (using the 0.8.0 server image)\n\nInstalled version of CUDA and cuDNN: \nNo\n\nWhen I start the [mnist_replica demo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py), it stuck after `prepare_or_wait_for_session`\n\nBut if I run `start_queue_runners` for both chief worker and all other workers, it runs successfully. (By removing `and is_chief` part [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L224) and [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L193))\n\nIs this a bug in the demo?\n", "comments": ["made a pr https://github.com/tensorflow/tensorflow/pull/3458 to fix this\n", "Update\uff1a If I start workers this way:\n\n```\n  if FLAGS.job_name == 'ps':\n    server.join()\n  else:\n   # Do training\n```\n\nInstead of connecting to worker each time:\n\n```\nsess = sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url)\n```\n\nI can successfully run the code. Any explanation about this?\n", "Way to repeat the problem:\nOn my own laptop run the following three cmd:\n\n```\npython mnist_replica.py --worker_grpc_url=\"grpc://43.254.53.118:30001\" --worker_index=0 --sync_replicas\npython mnist_replica.py --worker_grpc_url=\"grpc://43.254.53.118:30002\" --worker_index=1 --sync_replicas\npython mnist_replica.py --worker_grpc_url=\"grpc://43.254.53.118:30003\" --worker_index=2 --sync_replicas\n```\n\nThe log for worker1 is:\n\n```\nWorker GRPC URL: grpc://43.254.53.118:30001\nWorker index = 0\nNumber of workers = 3\nWorker 0: Initializing session...\nWorker 0: Session initialization complete.\nStarting chief queue runner and running init_tokens_op\nTraining begins @ 1469418277.317969\n1469418277.659315: Worker 0: training step 1 done (global step: 0)\n1469418277.961008: Worker 0: training step 2 done (global step: 0)\n1469418278.261021: Worker 0: training step 3 done (global step: 0)\n1469418292.345302: Worker 0: training step 4 done (global step: 0)\n```\n\nThe log for worker2 is:\n\n```\nWorker GRPC URL: grpc://43.254.53.118:30002\nWorker index = 1\nNumber of workers = 3\nWorker 1: Waiting for session to be initialized...\nWorker 1: Session initialization complete.\nTraining begins @ 1469418290.118592\n1469418292.332708: Worker 1: training step 1 done (global step: 0)\n1469418292.865696: Worker 1: training step 2 done (global step: 1)\n```\n\nAnd log for worker 3 is:\n\n```\nWorker GRPC URL: grpc://43.254.53.118:30003\nWorker index = 2\nNumber of workers = 3\nWorker 2: Waiting for session to be initialized...\nWorker 2: Session initialization complete.\nTraining begins @ 1469418298.766421\n```\n\nThey stuck there forever. I'm keeping the server alive so that anybody should be able to repeat this problem. The mnist_replica.py is [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py) and I also updated the file:\n[mnist_replica.py.txt](https://github.com/tensorflow/tensorflow/files/380746/mnist_replica.py.txt)\n", " @perhapszzy \nHave you solved the problem? I'm trying the distributed mnist demo, and I'm facing the same problem!\nThe tutorial of distributed tensorflow is really awful and hard-to-use\n", "I can start the demo by applying this pr:\nhttps://github.com/tensorflow/tensorflow/pull/3458\n\nbut I haven't figured out why.\n", "The --sync-replicas mode is not fully supported yet (see the obscurely located line at: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/scripts/dist_mnist_test.sh#L69). If you remove that flag, it should work under the asynchronous mode.\n", "Is synchronous model not supported in general or just this demo doesn't support it? I did found it work when start individual works this way:\n\n```\n  if FLAGS.job_name == 'ps':\n    server.join()\n  else:\n   # Do training\n```\n\nAnd it also runs by applying that pr. (not sure if it works expectedly).\n", "Closing this as per @jmchen-g comment on the PR. Let us know if it's still not fixed."]}, {"number": 3456, "title": "Fix CUDA capability version logic in ci_parameterized_build.sh for non-Docker cases", "body": "Fix CUDA capability version logic in ci_parameterized_build.sh for non-Docker cases\n\nAllows proper specification of TF_CUDA_COMPUTE_CAPABILITIES for nightly Mac GPU builds, e.g., export TF_CUDA_COMPUTE_CAPABILITIES=\"3.0,3.5,5.2\"\n\nTested:\nopensource build.\nExperimental Linux GPU PIP build: http://ci.tensorflow.org/job/experimental-cais-new-gpu/45/console (Jenkins login required)\nExperimental Mac GPU PIP build: http://ci.tensorflow.org/job/experimental-cais-tensorflow-mac/44/console (Jenkins login required)\n", "comments": ["Ready to merge.\n"]}, {"number": 3455, "title": "Feature Request: support sparse tensor in conv2d operator", "body": "It looks like TF doesn't support conv2d as another thread mentioned (https://github.com/tensorflow/tensorflow/issues/1604). This is critical for us since we are implementing CDSSM (from microsoft https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/www2014_cdssm_p07.pdf). Miscrosoft's library supports it and the training speed is dramatically faster than using TF. So we strongly feel this feature is important. \n", "comments": ["Is this different from #1604 ?\n", "It is essentially the same. But that was  not reported as a feature request. I am shouting out officially to request it. :) \n", "I will retitle that one.\n", "That works too. Thanks!\n"]}, {"number": 3454, "title": "Fixed regex for extracting Eigen version on iOS", "body": "", "comments": []}, {"number": 3453, "title": "Saver (sharded) ignores number of checkpoints to keep", "body": "`tf.train.Saver()` has a default limit of 5 most recent checkpoints to keep (`max_to_keep=5`). When I use a Saver with `sharded=True` option, only one machine performs this check and keeps ALL the checkpoints without removing any of them.\n### Environment info\n\nOperating System: Ubuntu 14.04 LTS\nBuilt from source; commit hash: aa2cacd6627ffb296bedc910c957a0fd4a2f957f\n### Steps to reproduce\n- Init a sharded saver and pass it to the Supervisor for distributed training and auto-model saving after every `save_model_secs`.\n\n```\nsaver = tf.train.Saver(sharded=True)\nsv = tf.train.Supervisor(is_chief=is_chief,\n                                 logdir=FLAGS.train_dir,\n                                 init_op=init_op,\n                                 summary_op=None,\n                                 global_step=global_step,\n                                 saver=saver,\n                                 save_model_secs=FLAGS.save_interval_secs)\n```\n- Start two workers and one ps on machine 0. Start two more workers and one ps on machine 1.\n- The saver keeps the 5 most recent sharded checkpoints on machine 0 (where the chief worker also runs). But machine 1 keeps all sharded checkpoints from beginning.\n", "comments": ["I can't immediately tell why, looking at the code.  Call stack: `Saver.save()` calls `_MaybeDeleteOldCheckpoints()`, which will inspect `max_to_keep`.  \n\nCould you add some debug logging to both these methods, and relaunch on the two machines?  \n", "Can you please guide on how to add the debug logging?\n", "`print(\"in save()\")` and `print(\"in _MaybeDeleteOldCheckpoints()\")`?  Your goal is to figure out if these two functions are actually called?\n", "Automatically closing due to lack of recent activity. Please reopen if further information becomes available.\n"]}, {"number": 3452, "title": "Update download_dependencies.sh for changed Eigen config", "body": "The `download_dependencies.sh` in `contrib/make` also needs to be updated to work with the Eigen config changes from #3288.\nThanks to @apcode for pointing this out!\n", "comments": ["Can one of the admins verify this patch?\n", "Is #3428 sufficient?\n", "Oh, I missed #3428. It looks sufficient.\nI'll close this one, then.\n"]}, {"number": 3451, "title": "retrain.py validation and testing evaluation seems incorrect", "body": "While retrain new final layer is added which has name defined by FLAGS.final_tensor_name. Strangely while evaluating against ground truths instead of using final_tensor_name or final_matmul it still uses output of ''validation_bottlenecks'. \n\nvalidation_accuracy = sess.run(\n          evaluation_step,\n          feed_dict={bottleneck_input: validation_bottlenecks,\n                     ground_truth_input: validation_ground_truth})\n", "comments": ["@maciekcc: can you take a look? Thanks.\n", "Closing due to inactivity. Feel free to open a new github issue if the problem still persists in recent versions."]}, {"number": 3450, "title": "Update link in linear tutorial", "body": "The link to the wide_n_deep tutorial doesn't work.\nShould it link to the one above?\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "This will be fixed in the next release (soon!), closing this. Thanks!\n"]}, {"number": 3449, "title": "IPython Notebook kernel dies when importing tensorflow", "body": "### Environment info\n\nOperating System: nvidia-docker (Docker version 1.11.2, build b9f10c9)\nTensorflow version 0.8.0\n### Steps to reproduce\n1. Run ipyhton notebook from nvidia-docker\n2. import tensorflow\n3. Kernel dies with Kernel Restarting dialog and message \"The kernel appears to have died. It will restart automatically\"\n4. importing numpy package before importing tensorflow solves the issue.\n", "comments": ["There was a similar crash fixed in 0.9\nhttps://github.com/tensorflow/tensorflow/pull/2173#event-646602065\n", "@shekkizh can you test against 0.8.0, as @yaroslavvb mentioned (thanks!)?\n", "Closing issue since the problem is reported to be fixed in 0.9. Thanks @yaroslavvb @concretevitamin \n", "i was having the same problem, but i cant solved it by importing numpy package before tensorflow", "i am having same problem in my desktop even when i import numpy before importing tensorflow", "I am having same problem in my desktop, 'import numpy before importing tensorflow 'it doesn't work.", "same problem here, both in python2.7 and python3.5. crash happens even if imported in a normal python shell (no jupyter).\r\n\r\nmy problem was that my processor was too old. installing tensorflow 1.5.0 solved the problem. Another solution would be to build from source..."]}, {"number": 3448, "title": "Fix segfault in MacOS when GPU is not available", "body": "Fixes #3435 \n", "comments": ["Can one of the admins verify this patch?\n", "Looks good, thanks!  (Btw, it's SIGSEGV (signal segmentation violation), not SEG or SERV :)\n\nWe don't yet have a Mac OS X GPU testing setup, but I'll test anyway.\n\n@tensorflow-jenkins test this please\n", "Changed the link to point to Apple (although it's extra long).\n\nAlso tried their official recipe of falling back to `CFStringGetCString` but get a Segmentation fault inside `CFStringGetCString`, and I guess it's not that important to get the actual driver version\n", "Woot!  Thanks!\n\n@tensorflow-jenkins test this please\n", "should I squash?\n", "We can squash when merging, so no need.\n"]}, {"number": 3447, "title": "minor typo fix.", "body": "This just fixes a minor typo in a comment. \n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3446, "title": "iOS example with Image Retraining model always gives the same prediction", "body": "## Environment info\n\nRunning on: iOS 9.1\nBuilding on OS X El Capitan version 10.11, Xcode version 7.3.1\nTensorFlow release 0.9\n## Steps to reproduce\n\nFollow the contrib/makefile/README to install the tensorflow iOS core lib\nCreate my own model with the Image Retraining tutorial\nRun the iOS example, same error as #2883 is logged.\nAfter fixing errors as suggested same prediction is always given. \nLogs or other output that would be helpful\n\n```\n2016-07-21 18:20:06.582 tf_ios_makefile_example[949:323060] Unable to simultaneously satisfy constraints.\n    Probably at least one of the constraints in the following list is one you don't want. \n    Try this: \n        (1) look at each constraint and try to figure out which you don't expect; \n        (2) find the code that added the unwanted constraint or constraints and fix it. \n(\n    \"<NSLayoutConstraint:0x17594000 V:|-(20)-[UIInputSetContainerView:0x176b59d0]   (Names: '|':UITextEffectsWindow:0x17597ab0 )>\",\n    \"<NSLayoutConstraint:0x17593e30 'UIInputWindowController-top' V:|-(0)-[UIInputSetContainerView:0x176b59d0]   (Names: '|':UITextEffectsWindow:0x17597ab0 )>\"\n)\n\nWill attempt to recover by breaking constraint \n<NSLayoutConstraint:0x17594000 V:|-(20)-[UIInputSetContainerView:0x176b59d0]   (Names: '|':UITextEffectsWindow:0x17597ab0 )>\n\nMake a symbolic breakpoint at UIViewAlertForUnsatisfiableConstraints to catch this in the debugger.\nThe methods in the UIConstraintBasedLayoutDebugging category on UIView listed in <UIKit/UIView.h> may also be helpful.\n2016-07-21 18:20:08.017 tf_ios_makefile_example[949:323060] 1\n2016-07-21 18:20:16.855 tf_ios_makefile_example[949:323060] Image path: /var/mobile/Containers/Data/Application/3AEB6ED8-B068-45FA-85D3-36FCFFA21DD1/Documents/photos/image.jpg\nI ../tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:302] Session created.\nI ../tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:305] Graph created.\nI ../tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:310] Creating session.\nW tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n2016-07-21 18:20:25.542 tf_ios_makefile_example[949:323060] Received memory warning.\n2016-07-21 18:20:25.653 tf_ios_makefile_example[949:323060] Received memory warning.\n2016-07-21 18:20:38.698 tf_ios_makefile_example[949:323060] Received memory warning.\nI ../tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:410] Predictions: 259 4.32 n01342269  moneran, moneron\n10 3.69 n00141669   check-in\n800 3.67 n01601410  great bowerbird, Chlamydera nuchalis\n552 3.59 n01531811  redpoll, Carduelis flammea\n0 3.58 n00004475    organism, being\n```\n## Related to\n#2883 I encountered the same error related to DecodeJpeg and then followed the fixes suggested there, but I get the same prediction no matter what I point the camera at. Similarly if i work with the \"simple\" project and change the photo being identified I still get the same prediction that in the log output above\n", "comments": ["I've got an example of how to successfully load and run a retrained model here:\nhttps://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/\n\nI'm going to close this bug, since I believe it's fixed now, please reopen if you're still hitting problems.\n"]}, {"number": 3445, "title": "Where to download updated apks from the jenkin builds", "body": "where to get the artifacts from daily builds?\nhttp://ci.tensorflow.org/job/tensorflow-master-android/\n", "comments": ["It's in our README: https://github.com/tensorflow/tensorflow#installation.\n"]}, {"number": 3444, "title": "Is it possible to import the project int android Studio and compile using NDK?", "body": "I was trying to import the project into android studio and work on it.\nGetting lot of compilation issues on jni compilation.\nIs it possible to do that?\nAny constraints we have ?\n", "comments": ["Hi, I've just given this a whirl and managed to successfully open the Android Tensorflow Demo under Android Studio and build it from there. You'll still need Bazel for building the native libs, but you'll be able to get full Java support through Android Studio.\n\nSome of these steps are shared with\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md, so feel free to skip if you've already done them.\n\n**Instructions:**\nDownload and install bazel 0.3.0 for your system: https://github.com/bazelbuild/bazel/releases\n\nDownload Android NDK r11c and unzip it somewhere:\n- osx: https://dl.google.com/android/repository/android-ndk-r11c-darwin-x86_64.zip\n- linux: http://dl.google.com/android/repository/android-ndk-r11c-linux-x86_64.zip\n\n**Clone repo:**\n\n```\ngit clone --recursive https://github.com/tensorflow/tensorflow/\ncd tensorflow\n```\n\nNow edit `WORKSPACE` to point to your NDK (the SDK should be unnecessary, since only AS will be using it, not Bazel).\n\n**Install Assets for Demo:**\n\n```\nwget https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip -O /tmp/inception5h.zip\nunzip /tmp/inception5h.zip -d tensorflow/examples/android/assets/\n```\n\n**Build native libs:**\n\n```\nCPU=armeabi-v7a\nbazel build //tensorflow/examples/android:tensorflow_native_libs --crosstool_top=//external:android/crosstool --cpu=$CPU --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\n\nNATIVE_FOLDER=tensorflow/examples/android/libs/$CPU\nmkdir -p $NATIVE_FOLDER\ncp bazel-bin/tensorflow/examples/android/libtensorflow_demo.so $NATIVE_FOLDER \n```\n\n**Set up the Android Studio project:**\n- Select \"Open an existing Android Studio project\" (it's not, but don't worry about that)\n- It will detect an AndroidManifest.xml, and ask you to configure. Do so.\n- Open \"File/Project Structure\"\n  - click \"Modules\"\n    - select the \"android\" module (not the \"Android\" below it)\n      - On the \"Sources\" tab, make sure that res is a resource directory, and src is a source directory.\n      - On the \"Paths\" tab, make sure that the paths are set to a directory you want to output to.\n\n**Build the APK**\nUnder Build, click \"Generate Signed APK\"\n\nWith any luck, this should create a working APK! **You'll need to re-run the \"Build Native Libs\" instructions any time you modify .cc or .h files**, but you should be able to edit the Java code as you normally would for any other Android project.\n\nIn the future we may better support Android Studio with cmake support, so that some of these steps would be unnecessary.\n", "Just to followup on this, there is now a build.gradle for the Android demo that will automate most of this if you just add the tensorflow/examples/android dir as an existing AS project. You'll still need to have Bazel installed, though.\n", "Error on Sync build.gradle\n\n`Error:(72, 0) Could not get unknown property 'assembleDebug' for root project 'android' of type org.gradle.api.Project.`\n\nWorks fine when I comment the line `assembleDebug.dependsOn copyNativeLibs`\n", "@riless Seems to be a change/bug in Gradle 2.2: https://code.google.com/p/android/issues/detail?id=219732\n\nA workaround may be to rewrite it as:\n\n```\ntasks.whenTaskAdded { task ->\n    if (task.name == 'assembleDebug') {\n        task.dependsOn 'copyNativelibs'\n    }\n}\n```\n", "`copyNativeLibs` (with capital L)\n", "Can anyone guide me? I want to take the scoreView result as recog.getTitle() in a texview.\r\n\r\n@andrewharp ", "@codeloverr It sounds like you just want to call view.setText(recog.getTitle()). But please direct general Android programming questions to StackOverflow, you'll find better support for that there."]}, {"number": 3443, "title": "step_stats.pb.h and types.pb.h missing", "body": "These two files are missing in the repo.\ncore/framework/step_stats.pb.h\ncore/framework/types.pb.h\n\nCompilation of tensorflow_jni.cc is failing due to this.\nIs it due to any issue?\n", "comments": ["@vishnudevk , Can I know how is the issue resolved ?"]}, {"number": 3442, "title": "Error malloc(): memory corruption", "body": "Hi All\n### Environment info\n\nOS: Linux raspberrypi 4.4.11-v7+ #888 SMP Mon May 23 20:10:33 BST 2016 armv7l GNU/Linux\nDevice: Raspberry PI 3\n\nInstalled version of CUDA and cuDNN: N/A\n\nTensorflow installed from source: \ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow\ncommit c5983f87f0402f2cb8c627807917ebdf8e4d4bb6\n### Steps to reproduce\n1.   `make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\" CXX=g++-4.8`\n2. `sudo apt-get install -y libjpeg-dev`\n3. make -f tensorflow/contrib/pi_examples/label_image/Makefile\n   returns:\n\n```\nI tensorflow/contrib/pi_examples/label_image/label_image.cc:142] Loaded JPEG: 512x600x3\n*** Error in `tensorflow/contrib/pi_examples/label_image/gen/bin/label_image': malloc(): memory corruption: 0x00e94520 ***\nAborted\n\n```\n\nI've tried also\n`tensorflow/contrib/pi_examples/label_image/gen/bin/label_image --image=tensorflow/tensorflow/contrib/pi_examples/label_image/data/grace_hopper.jpg\n`\nIs there a way to understand which line of code caused the memory corruption?\nHow can I increase the debug level?\n\nThanks\nGiovanni\n", "comments": ["Sorry you're hitting problems, and that it's taken us so long to dig into this one! I've just grabbed the latest source code and wasn't able to reproduce this on my Raspberry Pi 3. I've had multiple reports of the same problem though, so there must be something different between my environment and yours.\n\nTo help debug, I've attached a zip of the label_image executable produced by my build. If you get a chance, I'd love to know if it works on your system or fails with the same error. If it works, then there's something different about the compilation process. If it fails, that means there's a problem with the system libraries:\n\n[label_image.zip](https://github.com/tensorflow/tensorflow/files/417317/label_image.zip)\n\nI would also be interested in getting a call stack to show what functions are causing the immediate error. Can you try running this command to load your crashing executable into the gdb debugged?\n\n```\ngdb tensorflow/contrib/pi_examples/label_image/gen/bin/label_image\n```\n\nIf you type `r` to run the program once the prompt appears, you should see a call stack once it crashes. If you don't, try the command `bt` at the prompt. Once you have that, could you paste it back here?\n\nI've also updated the build files and docs a little bit based on my latest run-through, adding in zlib and cleaning up some of the compilation directions in PR #3809.\n", "Pete - I had the same issue.  Your binary actually works for me.\n\nWhen I run my binary, here is the backtrace I get\n\n`#0  0x76a51f70 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56\n#1  0x76a53324 in __GI_abort () at abort.c:89\n#2  0x76a8d954 in __libc_message (do_abort=<optimized out>, fmt=0x76b43830 \"*** Error in '%s': %s: 0x%s ***\\n\")\n    at ../sysdeps/posix/libc_fatal.c:175\n#3  0x76a93b80 in malloc_printerr (action=1, str=0x76b43cfc \"malloc(): memory corruption\", ptr=<optimized out>)\n    at malloc.c:4996\n#4  0x76a95cd4 in _int_malloc (av=av@entry=0x76b614d4 <main_arena>, bytes=bytes@entry=280) at malloc.c:3447\n#5  0x76a97e18 in __GI___libc_malloc (bytes=280) at malloc.c:2891\n#6  0x76f13328 in operator new(unsigned int) () from /usr/lib/arm-linux-gnueabihf/libstdc++.so.6\n#7  0x00288078 in tensorflow::{lambda(tensorflow::OpKernelConstruction*)#1}::_FUN ()\n#8  0x0016f6d8 in tensorflow::CreateOpKernel(tensorflow::DeviceType, tensorflow::DeviceBase*, tensorflow::Allocator*, tensorflow::FunctionLibraryRuntime*, tensorflow::NodeDef const&, int, tensorflow::OpKernel**) ()\n#9  0x000fd4d0 in tensorflow::CreateNonCachedKernel(tensorflow::Device*, tensorflow::FunctionLibraryRuntime*, tensorflow::NodeDef const&, int, tensorflow::OpKernel**) ()\n#10 0x001101c0 in tensorflow::FunctionLibraryRuntimeImpl::CreateKernel(tensorflow::NodeDef const&, tensorflow::OpKernel**)\n    ()\n#11 0x00119d94 in std::_Function_handler<tensorflow::Status (tensorflow::NodeDef const&, tensorflow::OpKernel**), tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::thread::ThreadPool*, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*)::{lambda(tensorflow::NodeDef const&, tensorflow::OpKernel**)#1}>::_M_invoke(std::_Any_data const&, tensorflow::NodeDef const&, tensorflow::OpKernel**) ()\n#12 0x001040b0 in tensorflow::(anonymous namespace)::ExecutorImpl::Initialize() ()\n#13 0x00104708 in tensorflow::NewLocalExecutor(tensorflow::LocalExecutorParams const&, tensorflow::Graph const*, tensorflow::Executor**) ()\n#14 0x0011dc88 in tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::thread::ThreadPool*, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) ()\n#15 0x00aa9060 in ?? ()`\n", "Hi, I have the samemalloc(): memory corruption issue (build 94493ec) on RPI raspbian\ngdb says: \n56 ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory\n", "I\u00b4ve seen multiple reports of this, but haven\u00b4t been able to reproduce this, so I bought several clean Pi 3s with Jessie SD cards to experiment with. On my first one, I\u00b4m still not seeing the issue, so I suspect there\u015b something I\u00b4m missing with my approach. To narrow it down, here are my complete steps copied from my bash history:\n\n``` bash\nmkdir ~/projects\n cd ~/projects/\n git clone https://github.com/tensorflow/tensorflow\n  cd tensorflow/\n  tensorflow/contrib/makefile/download_dependencies.sh\n  sudo apt-get install autoconf automake libtool\n  cd tensorflow/contrib/makefile/downloads/protobuf/\n  ./autogen.sh\n  ./configure\n  make\n  sudo make install\n  sudo ldconfig\n  cd ../../../../..\n  sudo apt-get install -y gcc-4.8 g++-4.8\n  make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\" CXX=g++-4.8\n  sudo apt-get install -y libjpeg-dev\n  make -f tensorflow/contrib/pi_examples/label_image/Makefile\n  curl https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015_stripped.zip -o /tmp/inception_dec_2015_stripped.zip\n   unzip /tmp/inception_dec_2015_stripped.zip -d tensorflow/contrib/pi_examples/label_image/data/\n   tensorflow/contrib/pi_examples/label_image/gen/bin/label_image\n```\n\nThis runs as expected, and produces military uniform as the top result, with no malloc error.\n\nThe outpout of `uname -a` is `Linux raspberrypi 4.1.19-v7+ #858 SMP Tue Mar 15 15:56:00 GMT 2016 armv7l GNU/Linux`. \n\nCan someone who\u00b4s seeing this issue give my steps above a try and let me know if they see the error still?\n", "Hi,\n\nI've run into the same problem!\n\n**My gdb output after running once on the gdb is:**\n\n\"(gdb) r\nStarting program: /home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/bin/label_image \n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/arm-linux-gnueabihf/libthread_db.so.1\".\nW tensorflow/core/platform/profile_utils/cpu_utils.cc:73] Failed to get CPU frequency: 0 Hz\n[New Thread 0x70f53420 (LWP 5310)]\n[New Thread 0x70753420 (LWP 5311)]\n[New Thread 0x6ff53420 (LWP 5312)]\n[New Thread 0x6f753420 (LWP 5313)]\n[New Thread 0x6ef53420 (LWP 5314)]\n[New Thread 0x6e753420 (LWP 5315)]\n[New Thread 0x6df53420 (LWP 5316)]\n[New Thread 0x6d753420 (LWP 5317)]\nI tensorflow/contrib/pi_examples/label_image/label_image.cc:142] Loaded JPEG: 512x600x3\n[New Thread 0x6cc8c420 (LWP 5318)]\n**\\* Error in `/home/pi/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/bin/label_image': malloc(): memory corruption: 0x00b11f58 ***\n\nProgram received signal SIGABRT, Aborted.\n0x76a50f70 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56\n56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.\n(gdb) \n\"\n\n**And the backtrace I get is:**\n\n\"(gdb) bt\n#0  0x76a50f70 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56\n#1  0x76a52324 in __GI_abort () at abort.c:89\n#2  0x76a8c954 in __libc_message (do_abort=<optimized out>, fmt=0x76b42bc0 \"**\\* Error in `%s': %s: 0x%s **_\\n\") at ../sysdeps/posix/libc_fatal.c:175\n#3  0x76a92b80 in malloc_printerr (action=1, str=0x76b4308c \"malloc(): memory corruption\", ptr=<optimized out>) at malloc.c:4996\n#4  0x76a94cd4 in _int_malloc (av=av@entry=0x76b604d4 <main_arena>, bytes=bytes@entry=280) at malloc.c:3447\n#5  0x76a96e18 in __GI___libc_malloc (bytes=280) at malloc.c:2891\n#6  0x76f12328 in operator new(unsigned int) () from /usr/lib/arm-linux-gnueabihf/libstdc++.so.6\n#7  0x002b3680 in tensorflow::{lambda(tensorflow::OpKernelConstruction_)#1}::_FUN ()\n#8  0x0017a64c in tensorflow::CreateOpKernel(tensorflow::DeviceType, tensorflow::DeviceBase_, tensorflow::Allocator_, tensorflow::FunctionLibraryRuntime*, tensorflow::NodeDef const&, int, tensorflow::OpKernel**) ()\n#9  0x000fe3ac in tensorflow::CreateNonCachedKernel(tensorflow::Device_, tensorflow::FunctionLibraryRuntime_, tensorflow::NodeDef const&, int, tensorflow::OpKernel**) ()\n#10 0x00117f04 in tensorflow::FunctionLibraryRuntimeImpl::CreateKernel(tensorflow::NodeDef const&, tensorflow::OpKernel**) ()\n#11 0x00120cdc in std::_Function_handler<tensorflow::Status (tensorflow::NodeDef const&, tensorflow::OpKernel**), tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::thread::ThreadPool*, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlicestd::string, tensorflow::gtl::ArraySlicestd::string, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*)::{lambda(tensorflow::NodeDef const&, tensorflow::OpKernel**)#1}>::_M_invoke(std::_Any_data const&, tensorflow::NodeDef const&, tensorflow::OpKernel**) ()\n#12 0x00104e50 in tensorflow::(anonymous namespace)::ExecutorImpl::Initialize() ()\n#13 0x001054a8 in tensorflow::NewLocalExecutor(tensorflow::LocalExecutorParams const&, tensorflow::Graph const*, tensorflow::Executor**) ()\n#14 0x00124e30 in tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::thread::ThreadPool_, tensorflow::gtl::ArraySlicestd::string, tensorflow::gtl::ArraySlicestd::string, tensorflow::gtl::ArraySlicestd::string, tensorflow::DirectSession::ExecutorsAndKeys__, tensorflow::DirectSession::RunStateArgs_) ()\n#15 0x00b50e80 in ?? ()\nBacktrace stopped: previous frame identical to this frame (corrupt stack?)\n(gdb) \n\"\n\n**My system is a Raspberry Pi 2:**\n\n\"$ uname -a\nLinux raspberrypi 3.18.16-v7+ #795 SMP PREEMPT Wed Jun 17 13:24:01 BST 2015 armv7l GNU/Linux\"\n\n**My command history is:**\n\n\"1992  ./tensorflow/contrib/makefile/download_dependencies.sh\n 1993  wget https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\n 1994  sudo apt-get install autoconf automake libtool\n 1995  cd tensorflow/contrib/makefile/downloads/protobuf/\n 1996  ./autogen.sh\n 1997  ./configure\n 1998  make\n 1999  sudo reboot\n 2000  cd tensorflow/contrib/makefile/downloads/protobuf/\n 2001  cd tensorflow/\n 2002  cd tensorflow/contrib/makefile/downloads/protobuf/\n 2003  sudo make install\n 2004  sudo ldconfig\n 2005  cd ../../../../..\n 2006  make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI  OPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\"\n 2007  sudo apt-get install -y gcc-4.8 g++-4.8\n 2008  make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\" CXX=g++-4.8\n 2009  sudo apt-get install -y libjpeg-dev\n 2010  curl https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015_stripped.zip -o /tmp/inception_dec_2015_stripped.zip\n 2011  unzip /tmp/inception_dec_2015_stripped.zip -d tensorflow/contrib/pi_examples/label_image/data/\n 2012  make -f tensorflow/contrib/pi_examples/label_image/Makefile\n 2013  ./tensorflow/contrib/pi_examples/label_image/gen/bin/label_image\n 2014  tensorflow/contrib/pi_examples/label_image/gen/bin/label_image\n\"\n\n**Could the problem be related to trying the 2006 command and after failing the 2008 command without doing a \"make clean\" in between?**\n", "So git clone or git clone --recurse-submodules does not matter?\n", "Hi again!\n\nPete, I used your commands starting the whole thing fresh and it worked!\n\nSo, the only difference between your commands and the ones in the documentation is that in your commands you use directly the \"CXX=g++-4.8\" in\nmake -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\" CXX=g++-4.8\nbut in the documentation the user first fails in the same command because of  gcc 4.9 and the tries again adding the CXX=g++-4.8.\n\nWithout being 100% sure, I think that this causes the memory corruption issue, because this is the only thing I did differently compared to your command listing.\n", "Thanks for the update, that is promising! I am following your original steps here on my Pi, without a `make clean` between the gcc 4.9 and 4.8 builds. If that reproduces the issue, then I will update the documentation to start with version 4.8, rather than having it be an option, and also mention that if you do switch compilers it's necessary to clean. If there's a straightforward way to enforce that in a script, I'll put that in too.\n", "I was able to reproduce the malloc errors using your steps @pmousoul, so it does look like the lack of a clean is the issue. I'm double-checking that by building it again after a clean, but I've updated the docs in PR #4327 to use gcc version 4.8 by default, and hopefully avoid misleading directions. Thanks for everyone's help tracking this down, I'm cautiously optimistic that this is the root cause, but confirmations that other people are now able to successfully build using the updated instructions would be very welcome!\n", "I've confirmed that adding a 'make clean' in between the gcc version switch in @pmousoul's steps fixes the issue, so I believe that's strong evidence that we've tracked down the cause of this issue.\n", "Hi,\n\nI can confirm it too, using Pete's commands list, the malloc error disappeared from all my pieces of code calling session->Run(...)\n\nGood work !\n\n---\n\nFrom: Pete Warden notifications@github.com\nSent: Sunday, September 11, 2016 10:56:27 PM\nTo: tensorflow/tensorflow\nCc: MATTHIEU BOUJONNIER; Comment\nSubject: Re: [tensorflow/tensorflow] Error malloc(): memory corruption (#3442)\n\nI've confirmed that adding a 'make clean' in between the gcc version switch in @pmousoulhttps://github.com/pmousoul's steps fixes the issue, so I believe that's strong evidence that we've tracked down the cause of this issue.\n\n## \n\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHubhttps://github.com/tensorflow/tensorflow/issues/3442#issuecomment-246232432, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ARdojsIAB9Jg6gc2-zXd8w90HfcIokzmks5qpL9bgaJpZM4JR1XX.\n\n---\n\nThis message was scanned by Exchange Online Protection Services.\n\n---\n", "These are good news - well done to everybody!\nThank you Pete for the great work!\n", "Great! PR #4327 has been merged with the docs update, so I'm going to go ahead and close this bug. I appreciate all the help tracking this down.\n"]}, {"number": 3441, "title": "Documentation for 'Adding a new op'", "body": "This is a feature request. Currently, I find the documentation for 'Adding an Op' quite minimal. There are a few important questions that remain unanswered:\n- How should one use multithreaded CPU code in an operation? Can we use OpenMP? How many threads should an op use? It is hard to find this in the implementations of existing ops, because they are all based on _Eigen_.\n- How should a GPU version of the op be written? Should it be a cuda kernel, or the code spawning cuda kernels? Maybe there could be a simple example for both CPU and GPU code not using Eigen.\n", "comments": ["Can I use C++ threads in the CPU implementation of an op? And how should I choose the number of threads to use?\n", "I'm also interested in using CPU threads in an op. Did you ever figure it out @tvogels?", "No, sorry, I left it single threaded ", "@tvogels No problem, thanks anyway", "In random_op.cc, there is an example of a multi-threaded op in the CPUDevice FillPhiloxRandom: \r\n  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/random_op.cc#L164\r\nIt uses the Shard function declared in work_sharder.h to split work across multiple threads.\r\n", "Brilliant thank you very much! That's my weekend sorted :)\n________________________________________\nFrom: cwhipkey [notifications@github.com]\nSent: 28 April 2017 18:07\nTo: tensorflow/tensorflow\nCc: Samuel Relton; Comment\nSubject: Re: [tensorflow/tensorflow] Documentation for 'Adding a new op' (#3441)\n\nIn random_op.cc, there is an example of a multi-threaded op in the CPUDevice FillPhiloxRandom:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/random_op.cc#L164\nIt uses the Shard function declared in work_sharder.h to split work across multiple threads.\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/3441#issuecomment-298053170>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AGGqhRE7FMMsNC4logvNJgk-Wd1DAonNks5r0hzIgaJpZM4JRwQR>.\n\n", "Some documentation has been added, and should be available when documentation is next rebuilt."]}, {"number": 3440, "title": "How to modify the seq2seq cost function for padded vectors?", "body": "Tensorflow supports dynamic length sequence by use of the parameter: `sequence_length` while constructing the RNN layer, wherein the model does not learn the sequence after the sequence size = 'sequence_length' i.e, returns zero vector.\n\nHowever, how can the cost function at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L890 be modified to encounter the masked sequences, so that cost and perplexity are calculated only on the actual sequences rather than whole padded sequence? \n\n```\ndef sequence_loss_by_example(logits, targets, weights, average_across_timesteps=True,  softmax_loss_function=None, name=None):\n\n    if len(targets) != len(logits) or len(weights) != len(logits):\n        raise ValueError(\"Lengths of logits, weights, and targets must be the same \"\n                         \"%d, %d, %d.\" % (len(logits), len(weights), len(targets)))\n      with ops.op_scope(logits + targets + weights, name,\n                        \"sequence_loss_by_example\"):\n        log_perp_list = []\n        for logit, target, weight in zip(logits, targets, weights):\n          if softmax_loss_function is None:\n            # TODO(irving,ebrevdo): This reshape is needed because\n            # sequence_loss_by_example is called with scalars sometimes, which\n            # violates our general scalar strictness policy.\n            target = array_ops.reshape(target, [-1])\n            crossent = nn_ops.sparse_softmax_cross_entropy_with_logits(\n                logit, target)\n          else:\n            crossent = softmax_loss_function(logit, target)\n          log_perp_list.append(crossent * weight)\n        log_perps = math_ops.add_n(log_perp_list)\n        if average_across_timesteps:\n          total_size = math_ops.add_n(weights)\n          total_size += 1e-12  # Just to avoid division by 0 for all-0 weights.\n          log_perps /= total_size\n    return log_perps\n```\n", "comments": ["Please redirect to StackOverflow for questions like this.  Thanks!\n"]}, {"number": 3439, "title": "\"tensorflow: Input iterator is exhausted\" when passing numpy arrays in validation monitor", "body": "I'm not sure if this is a bug or whether I just don't understand the usage of monitors (in which case I apologize for posting here). I'm trying to use a validation monitor by passing my validation set as numpy array.\n\n```\nval_monitor = learn.monitors.ValidationMonitor(X_val, Y_val, every_n_steps=100)\nreg.fit(X_train, Y_train, steps=1000, batch_size=200, monitors=[val_monitor])\n```\n\n(X_val and Y_val are numpy arrays)\n\nThe code runs but only the first validation step is done properly, then I get the following message in the logs:\n`INFO:tensorflow:Input iterator is exhausted.`\n\nAny help is welcome!\n", "comments": ["Assigning @martinwicke to redirect to tf.learn folks.\n", "That's a harmless info message emitted when eval hits the end of the eval data. You say only the first eval step is done properly -- what happens instead?\n", "The evaluation always returns the same value even if training is actually\ngoing fine. I probably just don't understand how to use this properly. What\nshould be the function call so that it runs the evaluation on the whole\nvalidation set every time? Thanks for your help!\nOn Fri, 22 Jul 2016 at 18:02, Martin Wicke notifications@github.com wrote:\n\n> That's a harmless info message emitted when eval hits the end of the eval\n> data. You say only the first eval step is done properly -- what happens\n> instead?\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3439#issuecomment-234583966,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAl3ErZv_NIEGVH0NpuHpLyYYDUdhS2dks5qYOmXgaJpZM4JRn43\n> .\n", "I've also posted to StackOverFlow with some example code to reproduce the problem:\nhttp://stackoverflow.com/questions/38500570/how-to-input-data-in-a-tensorflow-learn-validation-monitor\n", "I've been able to solve the problem by adding `config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1)` to the Estimator call:\n\n```\nreg = learn.Estimator(model_fn=my_model,\n                      model_dir=model_dir,\n                      config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1)) \n```\n\nCan someone clarify for me what is happening here and how this helped?\nThanks,\nDavid\n", "This happened because evaluation works off of the last checkpoint. Checkpoints are by default saved every 10 minutes (the defaults are good for long-running jobs, not so good for toy examples).\n\nSo if you evaluate more than every 10 minutes, you'll get no results or identical results to last time.\n\nPassing the config allows you to override the checkpointing interval, now you write a checkpoint every second (which may now be slowing you down), but you can be pretty sure that your evals are up to date.\n\nI'll close this, there's no bug here (although better documentation would be good).\n", "@martinwicke Thanks for the explanation. I'm frequently running relatively small models for which I like doing early stopping on the validation set. What is the best practice to do this without having to write checkpoints every second? This might be more of a feature request, but would it be possible to set checkpoint intervals as a number of steps rather than time? Or to write a checkpoint before an evaluation automatically?\n", "Both these options are good feature requests. For larger datasets this\nmostly doesn't matter, but for smaller ones, steps-based checkpointing\nwould certainly be convenient.\nOn Thu, Jul 28, 2016 at 04:17 David Bikard notifications@github.com wrote:\n\n> @martinwicke https://github.com/martinwicke Thanks for the explanation.\n> I'm frequently running relatively small models for which I like doing early\n> stopping on the validation set. What is the best practice to do this\n> without having to write checkpoints every second? This might be more of a\n> feature request, but would be possible to set checkpoint intervals as a\n> number of steps rather than time? Or to write a checkpoint before an\n> evaluation automatically?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> \n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3439#issuecomment-235867280,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_e1knILeblZ9ppopR0ZVYEVUgT9rks5qaI_VgaJpZM4JRn43\n> .\n"]}, {"number": 3438, "title": "Discussion: A possible Profiling method for TensorFlow", "body": "Goals:\n1. Get the timing run on CPU & GPU.\n2. Get the timing for each OP (run on GPU or CPU) or a serial of OPs.\n\nIdentify the performance bottlenecks to do the optimization.\n\nI just review some code for TF, and I find it should be possible to add some profiling code in tensorflow/core or tensorflow/stream_executor.\n\nHow about the idea? Any comments?\n", "comments": ["Take a look at #1824?  The StepStats and timeline functionalities that we open-sourced a while ago should address these two goals.\n\nFeel free to re-open if there's something missing.\n"]}]