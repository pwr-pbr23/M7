[{"number": 13747, "title": "Fix typos", "body": "This PR fixes some typos: `a a`, `for for`, `tranpose`, `from from`, and `to to`.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 13746, "title": "GraphDef ParseFromString error", "body": "I load a `graph.pb` saved by `tf.train.write_graph(sess.graph.as_graph_def(), FLAGS.model_dir, 'graph.pb', as_text=False)` via blow code. But an error occur. Why?\r\n\r\n```\r\ngraph_def = graph_pb2.GraphDef()\r\nwith tf.gfile.GFile('./graph.pb', 'rb') as f:\r\n    graph_def.ParseFromString(f.read())\r\n```\r\n\r\n```\r\nFile \"../../python/graph_test.py\", line 53, in freeze_graph\r\n    graph_def.ParseFromString(f.read())\r\n  File \"/Users/anaconda/lib/python3.6/site-packages/google/protobuf/message.py\", line 185, in ParseFromString\r\n    self.MergeFromString(serialized)\r\n  File \"/Users/anaconda/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\", line 1069, in MergeFromString\r\n    if self._InternalParse(serialized, 0, length) != length:\r\n  File \"/Users/anaconda/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\", line 1095, in InternalParse\r\n    new_pos = local_SkipField(buffer, new_pos, end, tag_bytes)\r\n  File \"/Users/anaconda/lib/python3.6/site-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\r\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\r\n  File \"/Users/anaconda/lib/python3.6/site-packages/google/protobuf/internal/decoder.py\", line 820, in _RaiseInvalidWireType\r\n    raise _DecodeError('Tag had invalid wire type.')\r\ngoogle.protobuf.message.DecodeError: Tag had invalid wire type.\r\n```", "comments": ["How did you solve this issue? I am having the same issue at the moment.", "@formath Were you able to solve this issue?", "Could you provide a solution? I'm having this error."]}, {"number": 13745, "title": "tf.contrib.data.Dataset  does not handle well with last  elements with is fewer than batch size", "body": "tf.contrib.data.Dataset  does not handle well with last  elements with is fewer than batch size.\r\n\r\nMaybe batch_size = 10, but last batch has 9 elements.", "comments": ["When this is that case `dataset.batch(10)` will give you zero or more batches of 10 elements, followed by a single batch of 9 elements. If you don't want the smaller batch, you can use `dataset.apply(tf.contrib.data.batch_and_drop_remainder(10))`. \r\n\r\nWhat would you recommend instead?", "I think which may have a param for dataset.batch()  which like allow_smaller_final_batch of tf.train.batch().\r\n\r\nAnd tf.contrib.data.batch_and_drop_remainder is interface use dataset.batch() which i want dataset.padded_batch()", "If you're using `Dataset.padded_batch()`, you can compose it with a `Dataset.filter()` to exclude smaller batches. For example, if your dataset has three components in each element `(x, y, z)`:\r\n\r\n```python\r\ndataset = dataset.padded_batch(batch_size, ...).filter(lambda x, y, z: tf.equal(tf.shape(x), batch_size))\r\n```", "@mrry Thanks, it's work.", "What if I want to extend final batch to 10 elements from 9 by extending one element from existing 9 ?", "@chenghuige You can handle that by adding a `Dataset.map()` that uses `tf.pad()` to pad each batch up to 10 elements.", "@mrry can you give an example of extending one element from existing 9? What if my input tensor has a shape of [batch_size,10,3]?\r\nThank you.", "I have met the same problem, that is what i tried:\r\ndataset = dataset.padded_batch(....., drop_reminder = True) \r\ndataset = dataset.repeat()\r\nand it works for me. Good luck", "`tf.contrib.data.batch_and_drop_remainder()` is DEPRECATED\r\n\r\nUse `tf.data.Dataset.batch(..., drop_remainder=True)` INSTEAD\r\n\r\nSource: [Tensorflow Docs](https://www.tensorflow.org/api_docs/python/tf/contrib/data/batch_and_drop_remainder)", "As @mrry said, I needed to do the following (considering the shape of the labels) in order to work:\r\n```\r\ndataset = dataset.batch(batch_size).filter(lambda features, labels: tf.equal(tf.shape(labels)[0], batch_size))\r\n```", "> I have met the same problem, that is what i tried:\r\n> dataset = dataset.padded_batch(....., drop_reminder = True)\r\n> dataset = dataset.repeat()\r\n> and it works for me. Good luck\r\n\r\nThanks, this works", "It's year 2020 now and I faced the same issue. It was hard to understand because there were many loose parts. For instance, we have 4 TF records and I was loading them, preprocessing because we had issues with some labels, converting to tf.data.Dataset, concatenating them and saving the shards with the new `save` function from TF2.3.0rc2. So, got really lost in the code and forgot to look at the batch. The issue was also only happening when I was adding the augmentation, after loading the Datasets before training.\r\n\r\nTook me sometime to remember that the augmentation was batching it and having some remaining data that was not inline with the expected shapes. So, the `padded_patch(ds, drop_remainder=True).repeat()` fixed it. \ud83d\udc4d "]}, {"number": 13744, "title": "TensorFlow: lack of repeatability in tf.estimator.DNNClassifier", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\ncustom code: no, it is the one in https://www.tensorflow.org/get_started/estimator\r\nsystem: Apple\r\nOS: Mac OsX 10.13\r\nTensorFlow version: 1.3.0\r\nPython version: 3.6.3\r\nGPU model: AMD FirePro D700 (actually, two such GPUs)\r\n\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nDear all,\r\n\r\nI wish to use TensorFlow to perform classification on medical datasets.\r\nTo do this, I am using exactly the same code as that proposed in https://www.tensorflow.org/get_started/estimator, the only difference being that I face medical datasets rather than the Iris database. So, it is not custom code.\r\n\r\nI do need help about the following problem: if I run the same code on the same data with the same parameters for the network configuration (number of layers, number of neurons in each layer, and so on) , the results are different. I mean, I run the same code ten times, and I obtain ten different values for the accuracy. These values are even largely different, as they range from 73% up to 83%.\r\nThis means that the subjects considered suffering from a given disease vary from a run to another. Differently said, once set a network structure, there are several subjects who are considered either healthy or sick depending on the run only.\r\nAs you can imagine, this lack of repeatability makes that code useless from both scientific and medical viewpoints: another user, running the same configuration over the same data set, would find a different model and different results, so would cure different subjects. \r\nI have noticed that for the Iris database the problem seems not to take place, and accuracy is always 0.9666. This depends on the problem being very easy (linearly separable for all but one items, and very small data set). \r\n\r\nI have carried out a search on the internet, and I have found several other people who have noted the same problem. As for the possible solutions, I have read several as well, I have implemented them all, with no result.\r\n\r\nHere I add a short list of some suggested remedies that failed in my case:\r\n\r\nos.environ['PYTHONHASHSEED'] = '0'\r\nnp.random.seed(0)\r\ntf.set_random_seed(0)\r\nrn.seed(0)\r\ntf.reset_default_graph()\r\n\r\nsession_conf = tf.ConfigProto(\r\n    intra_op_parallelism_threads=1,\r\n    inter_op_parallelism_threads=1\r\n)\r\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\r\n\r\nIs there any chance to fix this problem? It is a pity that such an excellent tool, as TensorFlow is, cannot guarantee repeatibility.\r\n\r\nI am using TensorFlow 1.3.0, Python 3.6.3, and an Apple with Mac OsX 10.13.\r\n\r\nThank you very much!\r\n\r\nBest regards\r\n\r\nIvanoe De Falco\r\n\r\n\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nSource code is in:\r\nhttps://www.tensorflow.org/get_started/estimator\r\n", "comments": ["Do you shuffle input data? ", "Dear facaiy,\r\nthank you very much for your fast reply!\r\nActually, yesterday evening I noticed the same issue, so I set shuffle=False, and performed several tests.\r\nNow all the runs yield the same result, so your idea is good and very helpful for my goal, thank you!\r\nActually, generally speaking, setting shuffle=False is just a way to get around the real problem, because the problem still exists: even if one sets all the random seeds fixed, the shuffling still produces different results. \r\nI feel there should be an easy way to declare whether or not a DNN run should be based on a fixed seed so as to make it repeatable. This would be, I believe, a great improvement in the ease of use of TensorFlow, and I hope you good guys will work on it.\r\nBy now, thanks a lot for your cooperation!\r\nIvan\r\n", "Hi, @IvanDeFalco . If I understand you correctly, you want a global seed setter for random, like `numpy.random.seed(0)`, right?\r\n\r\nSounds reasonable, however, it goes beyond my scope and perhaps is difficult to implement. Let's wait for response from official tensorflowers.", "yes @facaiy it is exactly what I am looking for.\r\nLet's hope somebody will start working on this.\r\nAgain, thanks :)", "Perhaps it is nearly impossible for multiple thread or distributed environment. ", "Just to double check - you're running this on the CPU? Or using OpenCL on the AMD GPUs?", "Dear  **@ekelsen** currently the program is running on the CPU.", "@mrry do you know if there's a way to deterministically seed shuffled input data? ", "@skyewm: Yes, the `Dataset.shuffle()` transformation will pick up the graph seed, if one is specified (or you can pass an explicit seed as an optional argument).", "@IvanDeFalco, does this suggestion resolve your issue.\r\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Closing this due to lack of activity.", "Without `tf.set_random_seed`, running multiple training in the same `model_dir` cause a fake accuracy improvement. But with `tf.set_random_seed`, it's fine. Why is this related with `tf.set_random_seed`?\r\n\r\nHere is the question I asked on SO: [python - Weird accuracy improvement by multiple small epochs training - Stack Overflow](https://stackoverflow.com/questions/51629819/weird-accuracy-improvement-by-multiple-small-epochs-training)\r\n\r\nThanks."]}, {"number": 13743, "title": "Propagate -DPCRE_STATIC from pcre.BUILD to swig.BUILD", "body": "pcre_internal.h uses this macro to determine the content of PCRE_EXP_DECL. So, in order to keep consistent, every file who includes pcre_internal.h  directly or indirectly should also have this macro defined.\r\n\r\nThis pull request is for fix a build error on Windows:\r\n<hr/>\r\nERROR: C:/os/t/external/swig/BUILD.bazel:5:1: Linking of rule '@swig//:swig' failed (Exit 1120): link.exe failed: error executing command                          <br/>\r\nmisc.o : error LNK2019: unresolved external symbol __imp_pcre_compile referenced in function Swig_string_regex <br/>                      \r\nnaming.o : error LNK2001: unresolved external symbol __imp_pcre_compile                       \r\nmisc.o : error LNK2019: unresolved external symbol __imp_pcre_exec referenced in function Swig_string_regex   <br/>                    \r\nnaming.o : error LNK2001: unresolved external symbol __imp_pcre_exec        <br/>               \r\nmisc.o : error LNK2019: unresolved external symbol __imp_pcre_version referenced in function Swig_pcre_version                       <br/>\r\nmisc.o : error LNK2001: unresolved external symbol __imp_pcre_free            <br/>           \r\nnaming.o : error LNK2001: unresolved external symbol __imp_pcre_free           <br/>            \r\nbazel-out/host/bin/external/swig/swig.exe : fatal error LNK1120: 4 unresolved externals    <br/>                   \r\n<hr/>\r\n", "comments": ["Can one of the admins verify this patch?", "Ping for @jart.\r\n\r\nI'm a little worried about this because using 'defines' propagates these defines to all libraries that depend on on this.  Given that these defines are very generic sounding, it's likely to cause conflicts in the future.  I don't have a good suggestion on how to deal with this though.", "Hi @vrv Currently, pcre is private to swig, not visible to the others. ", "If `PCRE_STATIC` is the only one that needs to be propagated, then why not have that be the only one listed under `defines` and have the rest remain copts?", "Hi @jart  If you search \u201cHAVE_\u201d in pcre_internal.h, there are a lot of occurrences.", "@snnn The public headers don't appear to include the internal header. Only the .c. files do. So those defines should never be needed by downstream rules. Therefore it should be sufficient to say:\r\n\r\n```py\r\n    defs = [\"PCRE_STATIC=1\"],\r\n    copts = [\r\n        \"-DHAVE_BCOPY=1\",\r\n        \"-DHAVE_INTTYPES_H=1\",\r\n        \"-DHAVE_MEMMOVE=1\",\r\n        \"-DHAVE_STDINT_H=1\",\r\n        \"-DHAVE_STRERROR=1\",\r\n        \"-DHAVE_SYS_STAT_H=1\",\r\n        \"-DHAVE_SYS_TYPES_H=1\",\r\n        \"-DHAVE_UNISTD_H=1\",\r\n        \"-DLINK_SIZE=2\",\r\n        \"-DMATCH_LIMIT=10000000\",\r\n        \"-DMATCH_LIMIT_RECURSION=1000\",\r\n        \"-DMAX_NAME_COUNT=10000\",\r\n        \"-DMAX_NAME_SIZE=32\",\r\n        \"-DNEWLINE=10\",\r\n        \"-DNO_RECURSE\",\r\n        \"-DPARENS_NEST_LIMIT=50\",\r\n        \"-DPOSIX_MALLOC_THRESHOLD=10\",\r\n        \"-DSTDC_HEADERS=1\",\r\n        \"-DSUPPORT_UCP\",\r\n        \"-DSUPPORT_UTF\",\r\n    ],\r\n```\r\n\r\nYou're correct in what you said earlier, that this wouldn't be an issue due to the visibility restriction. To offer more context on why this is worth doing, simply for its own sake, consider https://github.com/tensorflow/tensorflow/commit/d88cccebc7f61078d775d26f4714a06bc4002fcf. We actually got in trouble a few days ago because we were using a overly broad viral define. It ended up colliding with the codebase of a random team at Google.\r\n", "Hi @jart \r\n\r\nThanks for pointing it out.  I'll update this PR according to your suggestion.\r\n", "Thank you. Please ping when it's ready for approval.", "Let's hold on this PR until https://github.com/bazelbuild/bazel/issues/3949 is fixed. Otherwise, I'm not able to test it.", "Please do it.", "Jenkins test this please. ", "Jenkins, test this please."]}, {"number": 13742, "title": "libtensorflow_cc.so need to work on single (but not specific) core. (feature request)", "body": "I use self builded libtensorflow_cc.so shared library in my c++ model \"player\" program. I builded *.so for cpu-only usage. But by default in runtime it uses all cores. But I want to use only one core.\r\nIf i run my program through taskset, for example, I can use specific mask:\r\n$taskset -c 0 ./my_program param1 param2\r\nAnd it will perfectly work, but only on 0-th core of my cpu. And if I run several parallel programs with theese parameters all of them will work on 0-th core, while another cores are free.\r\nI need that for my service, for several parallel program works on different cores.\r\nHow can I build libtensorflow_cc.so WITHOUT multi-threading? Or maybe how can I configure it for single-core (but I repeat, not specific core)?\r\nThank you.", "comments": ["You can control the number of threads in SessionConfig by setting inter and intra op parallelism.\r\n\r\nIn general questions like this should be asked on StackOverflow."]}, {"number": 13741, "title": "Decoding and resizing image is giving unknown tensor shape", "body": "I'm trying to load two images, one is .png and another is .jpg, to tensorflow and resize them to 100x100 pixel size using `tf.image.pad_to_bounding_box`, so that they will be of same size and can be used for training. Here's my code:\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\ndef decode(image_data):\r\n    return tf.image.decode_image(image_data, channels=3)\r\n\r\ndef adjust_paddig(image_tensor):\r\n    return tf.image.pad_to_bounding_box(image_tensor, offset_height=0, offset_width=0, target_height=100, target_width=100)\r\n\r\ndef load(images_paths):\r\n    filename_queue = tf.train.string_input_producer(images_paths)\r\n    reader = tf.WholeFileReader()\r\n    _, image_file = reader.read(filename_queue)\r\n    image_tensor = decode(image_file)\r\n    padded_image_tensor = adjust_paddig(image_tensor)\r\n    return padded_image_tensor\r\n\r\nif __name__ == '__main__':\r\n    IMAGES_PATH = [\"images/1.png\",\"images/2.jpg\"] # Both image are of different shape\r\n    class_images_tensor = load(IMAGES_PATH)\r\n    print(class_images_tensor.shape)\r\n```\r\n\r\nBut some how the resized image size is not proper. It's displaying height and width but not depth(I mean channels).\r\n\r\n`Output: (100,100,?) #height, width are 100, but depth is '?'`\r\n\r\nand Surprisingly, It's giving same output for invalid paths also.\r\n\r\n`Eg: IMAGES_PATH = ['images/']  `\r\n\r\nWhat Am I doing wrong? Please help.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13739, "title": "Add freeze_graph to CONSOLE_SCRIPTS.", "body": "Make freeze_graph accessible from command line from pip package.\r\n", "comments": []}, {"number": 13738, "title": ".", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 13737, "title": "tfdbg release notes in r1.4", "body": "", "comments": []}, {"number": 13736, "title": "tfdbg: add persistent config (cherry-pick to r1.4)", "body": "* Add two persistent UI configurations backed by a file at ~/.tfdbg_config by default.\r\n  * graph_recursion_depth, which controls the recursive output of li/lo commands.\r\n  * mouse_mode, which controls the mouse state of the CursesUI.\r\n* Add `config` command to set and inspect the persistent configuration. E.g.,\r\n  * config show\r\n  * config set graph_recursion_depth 3\r\n  * config set mouse_mode False\r\n\r\nFixes: #13449\r\nPiperOrigin-RevId: 172270804", "comments": ["The new cherrypick policy is we only accept critical bugfixes or documentation updates into the release.\r\nAs the issue looks like a feature request, I will close the PR.\r\nWe can discuss internally whether to have this cherrypick, if you think we definitely need it, let's start an email thread."]}, {"number": 13735, "title": "Branch 172270804", "body": "", "comments": []}, {"number": 13734, "title": "Fix build error with boringssl", "body": "This fix tries to fix build error with boringssl on `Ubuntu 16.04`, `gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)`, and `bazel` `0.6.1`:\r\n\r\n```sh\r\n  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-march=native' -MD -MF bazel-out/local-opt/bin/external/curl/_objs/curl/external/curl/lib/curl_multibyte.pic.d -fPIC -iquote external/curl -iquote bazel-out/local-opt/genfiles/external/curl -iquote external/zlib_archive -iquote bazel-out/local-opt/genfiles/external/zlib_archive -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/boringssl -iquote bazel-out/local-opt/genfiles/external/boringssl -isystem external/curl/include -isystem bazel-out/local-opt/genfiles/external/curl/include -isystem external/zlib_archive -isystem bazel-out/local-opt/genfiles/external/zlib_archive -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/boringssl/src/include -isystem bazel-out/local-opt/genfiles/external/boringssl/src/include -Iexternal/curl/lib -D_GNU_SOURCE -DHAVE_CONFIG_H -DCURL_DISABLE_FTP -DCURL_DISABLE_NTLM -DHAVE_LIBZ -DHAVE_ZLIB_H -Wno-string-plus-int '-DCURL_MAX_WRITE_SIZE=65536' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/curl/lib/curl_multibyte.c -o bazel-out/local-opt/bin/external/curl/_objs/curl/external/curl/lib/curl_multibyte.pic.o)\r\nERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/external/boringssl/BUILD:128:1: C++ compilation of rule '@boringssl//:ssl' failed (Exit 1)\r\nexternal/boringssl/src/ssl/t1_lib.cc: In function 'int bssl::ssl_ext_key_share_parse_clienthello(bssl::SSL_HANDSHAKE*, bool*, bssl::Array<unsigned char>*, uint8_t*, CBS*)':\r\nexternal/boringssl/src/ssl/t1_lib.cc:2189:7: error: 'peer_key.cbs_st::len' may be used uninitialized in this function [-Werror=maybe-uninitialized]\r\n   CBS peer_key;\r\n           ^\r\nexternal/boringssl/src/ssl/t1_lib.cc:2189:7: error: 'peer_key.cbs_st::data' may be used uninitialized in this function [-Werror=maybe-uninitialized]\r\ncc1plus: all warnings being treated as errors\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 107.966s, Critical Path: 18.12s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nThis fix is related to PR #13638\r\n\r\nThis fix fixes #13733.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "/cc @gunan @caisq @tjingrant\r\n\r\nThe issue seems to appear on Ubuntu 16.04 only.", "Jenkins, test this please.", "@gunan The Jenkins build error seems to be that clang is not happy with `-Wno-maybe-uninitialized`. \r\n\r\nI have changed the `-Wno-maybe-uninitialized`to `-Wno-uninitialized`. I think that should address the clang error.\r\n\r\n(My dev machine is Ubuntu 16.04 + GCC so didn't notice that before).", "@tensorflow-jenkins test this please", "(This should be fixed on BoringSSL master as of Monday.\r\nhttps://boringssl.googlesource.com/boringssl/+/619c8cec8391068e483747cfce354a8d756e77ac )", "Thanks @davidben for the fix!", "Created a PR #13798 to bring  BoringSSL up to date."]}, {"number": 13733, "title": "Build error with boringssl ", "body": "With the most recent master bazel build fails with `Ubuntu 16.04`, `gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)`, and `bazel` `0.6.1`.\r\n\r\n```sh\r\n  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-march=native' -MD -MF bazel-out/local-opt/bin/external/curl/_objs/curl/external/curl/lib/curl_multibyte.pic.d -fPIC -iquote external/curl -iquote bazel-out/local-opt/genfiles/external/curl -iquote external/zlib_archive -iquote bazel-out/local-opt/genfiles/external/zlib_archive -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/boringssl -iquote bazel-out/local-opt/genfiles/external/boringssl -isystem external/curl/include -isystem bazel-out/local-opt/genfiles/external/curl/include -isystem external/zlib_archive -isystem bazel-out/local-opt/genfiles/external/zlib_archive -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/boringssl/src/include -isystem bazel-out/local-opt/genfiles/external/boringssl/src/include -Iexternal/curl/lib -D_GNU_SOURCE -DHAVE_CONFIG_H -DCURL_DISABLE_FTP -DCURL_DISABLE_NTLM -DHAVE_LIBZ -DHAVE_ZLIB_H -Wno-string-plus-int '-DCURL_MAX_WRITE_SIZE=65536' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/curl/lib/curl_multibyte.c -o bazel-out/local-opt/bin/external/curl/_objs/curl/external/curl/lib/curl_multibyte.pic.o)\r\nERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/external/boringssl/BUILD:128:1: C++ compilation of rule '@boringssl//:ssl' failed (Exit 1)\r\nexternal/boringssl/src/ssl/t1_lib.cc: In function 'int bssl::ssl_ext_key_share_parse_clienthello(bssl::SSL_HANDSHAKE*, bool*, bssl::Array<unsigned char>*, uint8_t*, CBS*)':\r\nexternal/boringssl/src/ssl/t1_lib.cc:2189:7: error: 'peer_key.cbs_st::len' may be used uninitialized in this function [-Werror=maybe-uninitialized]\r\n   CBS peer_key;\r\n       ^\r\nexternal/boringssl/src/ssl/t1_lib.cc:2189:7: error: 'peer_key.cbs_st::data' may be used uninitialized in this function [-Werror=maybe-uninitialized]\r\ncc1plus: all warnings being treated as errors\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 107.966s, Critical Path: 18.12s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nI think the issue is caused by the recent changes of the patch in boringssl with in PR #13638.", "comments": []}, {"number": 13732, "title": "Update CUB to 1.7.4", "body": "Was working on #13731 and noticed that the CUB version is 1.7.3.\r\n\r\nThis fix updates CUB to 1.7.4 which consists of bug fixes in radix sort.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Thanks @mrry @caisq. I have updated the PR with the CMAKE file changes. I don't have a Windows dev machine readily available though I tested with CMAKE Linux build and it works.\r\n\r\nPlease take a look and let me know if there are any issues.", "@tensorflow-jenkins test this please"]}, {"number": 13731, "title": "Add GPU and CPU implementation of `tf.histogram_fixed_width`.", "body": "This fix adds the GPU and CPU implementation of `tf.histogram_fixed_width`.\r\n\r\nThe previous implementation was done in python. This fix adds C++ kernel for GPU and CPU.\r\n\r\nThe GPU version uses `CUB`'s API `cub::DeviceHistogram::HistogramRange`. The `range` is  constructed from the upper/lower limit and step size. (`HistogramEven` could not be used directly as the edge case is different).\r\n\r\nThe CPU version uses a transform to map the input into the bucket index, then did a bin count.\r\n\r\nNote the output type of int64 on GPU is not supported yet as atomicAdd has no int64 at the moment.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Thanks @rmlarsen for the review \ud83d\udc4d . The PR has been updated. Please take a look and let me know if there are any issues.", "@tensorflow-jenkins test this please", "The only failed test is on Mac OS X of `//tensorflow/contrib/distributions/poisson_lognormal_test`. I would assume this is unrelated?", "@yongtang Yes, the failing test appears to be unrelated. Merging. Thanks for your contribution!", "I think the \"poisson_lognormal_test\" is broken due to this change.\r\n```\r\nTypeError: Expected int for argument 'nbins' not <tf.Tensor 'histogram/ToInt32:0' shape=() dtype=int32>.\r\n```\r\n\r\nhttps://source.cloud.google.com/results/invocation/28566b59-d961-458c-8978-b16dc248782f/%2F%2Ftensorflow%2Fcontrib%2Fdistributions:poisson_lognormal_test?page=log\r\n\r\nI now also see these failures in our continuous builds. Could you take a look?\r\n\r\n@vrv @hpucha looking at the state of things in the morning, we may want to revert this change temporarily to unblock everyone else.", "@gunan Sorry for the breaks. I have created a PR #13776 that revert the change.\r\n\r\nI will take a look at the failing test shortly.", "Think I know where the issue is. Before this PR, the `tf.histogram_fixed_width` is only available in Python (no C++ for CPU or GPU). The python version of `tf.histogram_fixed_width` has a default value of `nbins=100`.\r\n\r\nThis PR tries to preserve the `nbins=100` to keep API backward-compatibility. As a result this PR uses attribute instead of `input` tensor to carry nbins. (You could specify default value `=100` with attribute).\r\n\r\nBut that somehow breaks the test utility code in `tensorflow/contrib/distributions/python/ops/test_util.py` where a tensor is passed in `nbins`.\r\n\r\nThe fix might be quite tricky. Need to preserve api compatibility and also pass a tensor. Let me think if there is a way to fix the issue without breaking one way or another.\r\n\r\nThe  PR #13776 is the revert. It could be merged first for a quick solution.", "Think I could hide the `HistogramFixedWidth` in `hidden_ops.txt` and add wrapper, so that both api compatibility and test utility in contrib could be preserved. Will create the PR shortly."]}, {"number": 13730, "title": "freeze  model graph failure", "body": "I can generate the pbtxt,but freeze  model graph failure\r\nI use tensorflow1.2\r\n\r\nFile \"/Users/gouwei/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph\", line 178, in <module>\r\n    Main()\r\n  File \"/Users/gouwei/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph\", line 117, in Main\r\n    module_space = FindModuleSpace()\r\n  File \"/Users/gouwei/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph\", line 91, in FindModuleSpace\r\n    sys.argv[0])\r\nAssertionError: Cannot find .runfiles directory for /Users/gouwei/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph\r\nTraceback (most recent call last):\r\n  File \"/Users/gouwei/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph\", line 178, in <module>\r\n    Main()\r\n  File \"/Users/gouwei/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph\", line 117, in Main\r\n    module_space = FindModuleSpace()\r\n  File \"/Users/gouwei/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph\", line 91, in FindModuleSpace\r\n    sys.argv[0])\r\nAssertionError: Cannot find .runfiles directory for /Users/gouwei/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph", "comments": ["by the ways ,I use MAC 10.12.6", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13729, "title": "android:tensorflow_demo build error - external/fft2d/fft/fftsg.c:641:10: fatal error: 'math.h' file not found", "body": "Hi\r\n\r\nI succeeded build and install TensorFlow from sources with the link below.\r\nhttps://www.tensorflow.org/install/install_sources\r\n\r\nBut, I could not build 'android: tensorflow_demo' under the guidance of the link below.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\r\n> bazel build -c opt //tensorflow/examples/android:tensorflow_demo\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: none\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.11.6\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:\r\ntf.VERSION = 1.4.0-rc0\r\ntf.GIT_VERSION = b'v1.3.0-rc1-3399-g7cdd26f'\r\ntf.COMPILER_VERSION = b'v1.3.0-rc1-3399-g7cdd26f'\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: Build label: 0.6.1-homebrew\r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: none\r\n- **Exact command to reproduce**: \r\nbazel build -c opt //tensorflow/examples/android:tensorflow_demo\r\n\r\n### Describe the problem\r\nI could not build 'android: tensorflow_demo' under the guidance of the link below.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\r\nbazel build -c opt //tensorflow/examples/android:tensorflow_demo\r\n\r\nMy System OSX system has 'math.h' header in /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/usr/include/math.h folder.\r\n\r\nAnd I can check fftsg.o, fftsg.d file below path.\r\nbazel-out/host/bin/external/fft2d/_objs/fft2d/external/fft2d/fft/\r\n\r\nAnd fftsg.d have math.h path.\r\n\r\nvi fftsg.d\r\nbazel-out/host/bin/external/fft2d/_objs/fft2d/external/fft2d/fft/fftsg.o: \\\r\n  external/fft2d/fft/fftsg.c \\\r\n  /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/usr/include/math.h \\\r\n  /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/usr/include/sys/cdefs.h \\\r\n  /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/usr/include/sys/_symbol_aliasing.h \\\r\n  /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/usr/include/sys/_posix_availability.h \\\r\n  /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/usr/include/Availability.h \\\r\n  /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/usr/include/AvailabilityInternal.h\r\n\r\nBy the way, why do errors occur when building tensorflow_demo?\r\n\r\n### Source code / logs\r\nERROR: /private/var/tmp/_bazel_leebongjun/3584e4473c72a5166d05587429923d11/external/fft2d/BUILD.bazel:21:1: C++ compilation of rule '@fft2d//:fft2d' failed (Exit 1).\r\nexternal/fft2d/fft/fftsg.c:641:10: fatal error: 'math.h' file not found\r\n#include <math.h>\r\n         ^~~~~~~~\r\n1 error generated.\r\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2.271s, Critical Path: 0.39s", "comments": ["It looks like there's something wrong in your toolchain. Did you follow the instructions for Mac?\r\n\r\n/CC: @mhyttsten ", "I used the ndk-bundle (v16), which was downloaded via the sdk manager of the Android studio. This version seems to be a compatibility issue.\r\n\r\nSo I used the standalone Android NDK 14b as a [guide](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md).\r\n\r\n> The Android NDK is required to build the native (C/C++) TensorFlow code. The current recommended version is 14b, which may be found here.\r\n\r\nThen build succeeded.\r\n\r\nIncidentally, it only builds in Python2. In Python3, the build did not complete because of an execution error in resource_extractor.py.\r\n\r\nAnyway, this is a problem with Android NDK version compatibility.  I will close Issue.", "@bbongcol @drpngx I'm having a similar issue when building `android:libtensorflow_inference.so`: I can compile fine with NDK r14b and r15c, but not r16b (with the same '@fft2d//:fft2d' error) should I reopen this as a new issue? Or is there something basic I'm missing and this is a mistake on my side?", "tensorflow still relies on GCC i think, since ndk-r15 GCC is no longer supported.", "I get this error \r\n\r\n```\r\nvagrant@vagrant:~/tensorflow$ ../.bazel/bin/bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" //tensorflow/contrib/android:libtensorflow_inference.so --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures\r\nWARNING: /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:batch_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_volume_patch.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:padding_fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_base.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:typed_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nINFO: Analysed target //tensorflow/contrib/android:libtensorflow_inference.so (29 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/fft2d/BUILD.bazel:21:1: C++ compilation of rule '@fft2d//:fft2d' failed (Exit 1): false failed: error executing command \r\n  (cd /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PWD=/proc/self/cwd \\\r\n  /bin/false -MD -MF bazel-out/armeabi-v7a-opt/bin/external/fft2d/_objs/fft2d/external/fft2d/fft/fftsg.pic.d -fPIC -iquote external/fft2d -iquote bazel-out/armeabi-v7a-opt/genfiles/external/fft2d -iquote external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/genfiles/external/bazel_tools -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -c external/fft2d/fft/fftsg.c -o bazel-out/armeabi-v7a-opt/bin/external/fft2d/_objs/fft2d/external/fft2d/fft/fftsg.pic.o)\r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\nINFO: Elapsed time: 211.430s, Critical Path: 13.76s\r\nINFO: 190 processes, local.\r\nFAILED: Build did NOT complete successfully\r\n```"]}, {"number": 13728, "title": "Disable the newly failing windows GPU tests.", "body": "", "comments": ["Jenkins, test this please."]}, {"number": 13727, "title": "AddSign and PowerSign optimizers for contrib.opt", "body": "Added optimizers with update rules from https://arxiv.org/pdf/1709.07417.pdf", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "Thanks @kdubovikov for this PR, and for your interest in the paper!\r\n\r\nIt's worth noting that Irwan (the paper author) is already mostly done with a change to add these optimizers to GitHub.  I would be happy to take this change, but it is complicated due to the fact that most of our supported optimizers require C++ fused implementations for speed and distributed training reasons.\r\n\r\nGiven that this work is almost done, would you be okay if we closed this PR in favor of the C++ version that is coming soon?", "Hi! Great news! I thought to develop C++ code later, but it\u2019s clear that the author of the paper will manage this perfectly. Hope I\u2019ll implement something more useful further along", "Great, I'll close it for now, but if we can't get the C++ changes in by the end of the month, I'll reopen."]}, {"number": 13726, "title": "Error while installing Tensorflow on Mac via terminal", "body": "I am trying to install Tensorflow on my mac via the terminal using the tutorial and commands that are provided by the official website linked below.\r\n\r\nhttps://www.tensorflow.org/versions/r0.12/get_started/os_setup#pip_installation\r\n\r\nHowever when running the pip install tensorflow & the pip install tensorflow-gpu command i get the same error (picture is attached).\r\n\r\n\r\n<img width=\"820\" alt=\"screen shot 2017-10-14 at 11 24 00 pm\" src=\"https://user-images.githubusercontent.com/5986856/31581317-ca2a4126-b136-11e7-81a8-462276e4bff3.png\">\r\n<img width=\"1182\" alt=\"screen shot 2017-10-14 at 11 23 41 pm\" src=\"https://user-images.githubusercontent.com/5986856/31581318-ca348d52-b136-11e7-884b-9fa95fe7a25a.png\">\r\n\r\nI am not sure why this error is occurring. Any help that can be provided would be appreciated. \r\n", "comments": ["You probably need `sudo`?\r\nIt is likely that you will run into more issues, as we saw some changes into numpy has broken some old versions of TF.\r\n\r\nOn MacOS, we recommend using a CPU version, or you can always use a GPU supported TF through cloud instances that have GPUs.", "Simply execute the following command:\r\n\r\npython3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py3-none-any.whl"]}, {"number": 13725, "title": " Build tensorflow 1.0.1 for bug on jetson TX2", "body": "Hi,\r\nBuild tensorflow 1.0.1 for bug on jetson TX2\r\n$ ./cloneTensorFlow.sh$ \r\n$./setTensorFlowEV.sh\r\n$ ./buildTensorFlow.sh\r\n\r\n\r\nERROR: /home/nvidia/tensorflow/tensorflow/core/kernels/BUILD:685:1: output 'tensorflow/core/kernels/_objs/tile_ops_gpu/tensorflow/core/kernels/tile_ops_gpu.cu.pic.o' was not created.\r\nERROR: /home/nvidia/tensorflow/tensorflow/core/kernels/BUILD:685:1: not all outputs were created or valid.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 3022.881s, Critical Path: 2684.15s\r\n\r\nThank you for your help", "comments": ["bazel build -c opt --jobs 1 --local_resources 2048,0.5,1.0 --verbose_failures --config=cuda //tensorflow/tools/pip_package:build_pip_package", "Can you paste more logs to pastebin?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 13724, "title": "Fixed incorrect `hooks` doc in `EvalSpec`", "body": "", "comments": ["Thanks!"]}, {"number": 13723, "title": "Feature request: bitwise operations on boolean tensors", "body": "Currently, bitwise operations such as OR, AND only take integers.\r\nIt would be nice to be able to feed boolean tensors, e.g. `tf.zeros(4, dtype=tf.bool)` or to be able to bitcast an axis of a boolean tensor to an int.  ", "comments": ["Perhaps tf.cast could be useful. ", "Only much later do I realize that `logical_or` etc. does exactly what I'm asking for; hopefully these operations are as fast as their bitwise equivalents."]}, {"number": 13722, "title": "Fix cmake build with `Dtensorflow_BUILD_ALL_KERNELS=OFF` error", "body": "This fix tries to address the issue raised in #11975 where cmake with `Dtensorflow_BUILD_ALL_KERNELS=OFF` will throw out an error:\r\n```\r\n[ 93%] Building CXX object CMakeFiles/tf_tools_transform_graph_lib.dir/workspace/tensorflow/tools/graph_transforms/freeze_requantization_ranges.cc.o\r\nCMakeFiles/tf_core_cpu.dir/workspace/tensorflow/core/grappler/costs/measuring_cost_estimator.cc.o: In function `tensorflow::grappler::MeasuringCostEstimator::MeasuringCostEstimator(tensorflow::grappler::Cluster*, int, int)':\r\nmeasuring_cost_estimator.cc:(.text+0x18c): undefined reference to `tensorflow::SanitizeThreadSuffix(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)'\r\ncollect2: error: ld returned 1 exit status\r\nmake[2]: *** [benchmark_model] Error 1\r\nCMakeFiles/benchmark_model.dir/build.make:949: recipe for target 'benchmark_model' failed\r\nmake[1]: *** [CMakeFiles/benchmark_model.dir/all] Error 2\r\nCMakeFiles/Makefile2:6884: recipe for target 'CMakeFiles/benchmark_model.dir/all' failed\r\nmake[1]: *** Waiting for unfinished jobs....\r\n```\r\n\r\nThe issue is casued by `ops_util.cc` which is needed even if all kernels are OFF.\r\n\r\nThis fix fixes the issue with cmake file update.\r\n\r\nThis fix fixes #11975.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@yongtang It is still not working. When running `tf_tutorials_example_trainer.exe` it crashes with\r\n\r\n    F E:\\tensorflow\\cc\\tutorials\\example_trainer.cc:109] Non-OK-status: session->Create(def) status: Invalid argument: No OpKernel was registered to support Op 'Cast' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\r\n      <no registered kernels>\r\n\r\n             [[Node: Cast = Cast[DstT=DT_FLOAT, SrcT=DT_INT32, _device=\"/cpu:0\"](Const)]]\r\n\r\n@mrry could the issue be reopened please?"]}, {"number": 13721, "title": "Update documentation for uint16 support in `tf.resize_...` ops", "body": "This fix tries to address the different between the registered kernels and the documentation differnet for `uint16` support of:\r\n`tf.resize_area`\r\n`tf.resize_bicubic`\r\n`tf.resize_bilinear`\r\n`tf.resize_nearest_neighbor`\r\n\r\nThough `uint16` is supported in the kernel, it is not documented in `image_ops.cc`. Unit test cases are also missing for `uint16` and `float16`.\r\n\r\nThis fix added the missing entries in tests and docs.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 13720, "title": "Add nth_element op", "body": "This PR tries to settle the issue #13360 and add `NthElement` op in kernel and `tf.nn.nth_element` wrapper for python.\r\n\r\nAs in `std::nth_element`, this op finds values of the n-th order statistic for the last dmension, which the n-th order statistic is equal to its n-th smallest value. Median is not a reduce(fold) operation technically, this op could be a effective foundation of building `reduce_median` or other quantile function.\r\n\r\nThis PR support CPU device only. The internal implementation is based on [std::nth_element](http://www.cplusplus.com/reference/algorithm/nth_element/), which has fast average performance of `O(n)` and may has worst average performance of `O(n)` by introselect in some implementations like GCC 4.7 according to this [blog](https://stackoverflow.com/questions/11068429/nth-element-implementations-complexities), I believe it's efficient enough in most of case. And I enhance it in batch mode by multi-thread.\r\n\r\nI also add the unit tests both in `core/ops/nn_ops_test.cc` and `python/kernel_tests/nth_element_op_test.py`, and register the gradient op accordingly. The reason why I choose putting it in `nn` module is that I noticed `tf.nn.top_k` which has the similar function did the same.\r\n\r\nFurthermore, I'm glad to contribute `reduce_median` based on this op in the future. If there is anything I need to modify, please let me know. Thank you for your review.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "I encounter a failure test in Ubuntu Python2 Internal CI Build above, which is\r\n```\r\nIf this test fails, it means a change has been made to the public API. Backwards\r\nincompatible changes are not allowed. You can run the test as follows to update\r\ntest goldens and package them with your change.\r\n\r\n    $ bazel build tensorflow/tools/api/tests:api_compatibility_test\r\n    $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\r\n          --update_goldens True\r\n\r\nYou will need an API approval to make changes to the public TensorFlow API. This\r\nincludes additions to the API.\r\n\r\nERROR:tensorflow:1 differences found between API and golden.\r\nERROR:tensorflow:Issue 1\t: Change detected in python object: tensorflow.nn.\r\nF.\r\n```\r\nI've run the command above in my computer, but nothing changed locally. So what should I do for this test failure, please?", "No, leave the implementation there and just put a pointer to it in contrib.\n\nOn Mon, Oct 16, 2017 at 7:15 PM, jinze1994 <notifications@github.com> wrote:\n\n> *@jinze1994* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/python/ops/nn.py\n> <https://github.com/tensorflow/tensorflow/pull/13720#discussion_r145013188>\n> :\n>\n> > @@ -88,6 +88,7 @@\n>  @@ctc_beam_search_decoder\n>  @@top_k\n>  @@in_top_k\n> +@@nth_element\n>\n> Sure, so should I delete the file of tensorflow/python/ops/nth_\n> element_op.py and other relative modifies, build a new directory of\n> contrib/nth_element/ and move those modifies to contrib/nth_element/?\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/13720#discussion_r145013188>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxWMzh2rWnNz8a_BVfuHLWiQGFtwVks5stA3YgaJpZM4P5c37>\n> .\n>\n\n\n\n-- \n - Alex\n", "@alextp OK, I've made some changes according to your comments, is that right?", "Jenkins, test this please.", "Why the `TF Test Suite` is still pending? Is something wrong?", "@tensorflow-jenkins test this please", "@alextp \r\nI couldn't find this API in tensorflow [online documents](https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/nn) of master branch. So may I ask that when I can see this API in official website? Until release next version?", "When the next version gets released, yes.\n\nTo use it before then you should use one of our nightly builds.\n\nOn Fri, Oct 20, 2017 at 7:58 AM, Jinze Bai <notifications@github.com> wrote:\n\n> @alextp <https://github.com/alextp>\n> I couldn't find this API in tensorflow online documents\n> <https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/nn>\n> of master branch. So may I ask that when I can see this API in official\n> website? Until release next version?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/13720#issuecomment-338230414>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxViQXMb7azoqKK1LV2n6Xh6aPNxzks5suLT9gaJpZM4P5c37>\n> .\n>\n\n\n\n-- \n - Alex\n"]}, {"number": 13719, "title": "Support reversing bool sequence.", "body": "This PR tries to fix issue [#13717](https://github.com/tensorflow/tensorflow/issues/13717).", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@ebrevdo \r\nI had made some changes according to your comments.", "@tensorflow-jenkins test this please"]}, {"number": 13718, "title": "fatal error: third_party/eigen3/Eigen/Core: No such file or directory", "body": "Hi,\r\nI have followed below mentioned steps on my raspberry PI device to enable tensorflow support, but stuck with this issue when executed \"**make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=\"-Os\" CXX=g++-4.8** \" command -\r\n\r\nError description - \r\n\r\n```\r\n fatal error: third_party/eigen3/Eigen/Core: No such file or directory\r\n #include \"third_party/eigen3/Eigen/Core\"                                         ^\r\ncompilation terminated.\r\ntensorflow/contrib/makefile/Makefile:617: recipe for target '/home/pi/tensorflow                                                                                                             /contrib/makefile/gen/host_obj/tensorflow/core/platform/denormal.o' failed\r\nmake: *** [/home/pi/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/pla                                                                                                             tform/denormal.o] Error 1\r\n```\r\n\r\nSteps executed on raspberry pi; steps a to k are successful, getting error at step l- \r\na) tensorflow/contrib/makefile/download_dependencies.sh\r\nb) sudo apt-get install -y autoconf automake libtool gcc-4.8 g++-4.8\r\nc ) cd tensorflow/contrib/makefile/downloads/protobuf/\r\nd) ./autogen.sh\r\ne) ./configure\r\nf) make\r\ng) sudo make install\r\nh) sudo ldconfig  # refresh shared library cache\r\ni) cd ../../../../..\r\nj) export HOST_NSYNC_LIB=`tensorflow/contrib/makefile/compile_nsync.sh`\r\nk) export TARGET_NSYNC_LIB=\"$HOST_NSYNC_LIB\"\r\n**l) make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=\"-Os\" CXX=g++-4.8**\r\n\r\nNot sure, what am i missing? Please provide suggestions to resolve this issue. Thanks!\r\n\r\nThanks\r\nAmit Srivastava\r\n", "comments": ["@petewarden Can you comment on this raspberry PI issue?", "@amit-sri24 I would have expected Eigen to have been imported as part of the TF distribution. Nevertheless, can you try downloading/installing it separately, and seeing if that resolves the issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Downloading the files separately should resolve this issue, closing this now.", "I have the same issue. Where I can download files separately?", "@RealBerd I think you can download files from the [repo](https://gitlab.com/libeigen/eigen)"]}, {"number": 13717, "title": "`tf.reverse_sequence` does not support bool sequence", "body": "It seems that `tf.reverse_sequence` can not reverse bool sequence. ", "comments": ["As #13719 is merged I think this issue could be closed.\r\n\r\nYou could also specify in then PR with things like `This PR fixes #13717.` Then when the PR is merged the associated issue will be closed automatically.", "@yongtang \r\nThanks!"]}]