[{"number": 39365, "title": "interpreter.allocate_tensors() Failing for MNIST model with LocallyConnected2D layer", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **macOS 10.15.4**\r\n- TensorFlow installed from (source or binary): **from pip**\r\n- TensorFlow version (or GitHub SHA if from source): **2.2.0-rc4**\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n[colab.research.google.com](https://colab.research.google.com/drive/1GFvL0LrCYEwsLVBxjxF3hVeraGDZgJ41?usp=sharing) **_WORKS FINE ON COLAB BUT BREAKS ON MY MACHINE_**\r\n\r\n```\r\ndef convert_keras_to_tflite_and_verify(keras_model):\r\n  converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\r\n  tflite_model = converter.convert()\r\n  interpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n  interpreter.allocate_tensors()  # ERRORS OUT\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n2020-05-09 22:05:21.516092: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-05-09 22:05:21.516150: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-05-09 22:05:21.580927: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\r\n2020-05-09 22:05:21.580949: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-05-09 22:05:21.580954: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-05-09 22:05:23.603879: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-05-09 22:05:23.603950: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-05-09 22:05:23.856983: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\r\n2020-05-09 22:05:23.857001: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 3693 nodes (-25), 4297 edges (-25), time = 124.184ms.\r\n2020-05-09 22:05:23.857005: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 3693 nodes (0), 4297 edges (0), time = 67.772ms.\r\nAllocating tensors\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 122, in <module>\r\n    convert_keras_to_tflite_and_verify(mnist_model)\r\n  File \"main.py\", line 68, in convert_keras_to_tflite_and_verify\r\n    interpreter.allocate_tensors()\r\n  File \"/Users/xx/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py\", line 242, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\n  File \"/Users/xx/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 110, in AllocateTensors\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\nRuntimeError: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (1331 != 121)Node number 3040 (RESHAPE) failed to prepare.\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\nThe model can be found here [colab.research.google.com](https://colab.research.google.com/drive/1GFvL0LrCYEwsLVBxjxF3hVeraGDZgJ41?usp=sharing)\r\n\r\n**Failure details**\r\nThe `interpreter.allocate_tensors()` method works fine on the colab notebook but fails for me locally on my machine for the exact same model\r\n\r\nBackground - I am trying to add a basic attention branch to a CNN model from https://keras.io/examples/mnist_cnn/. \r\nReplacing the `LocallyConnected2D` layer from the attention branch with `Conv2D` makes everything work fine.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@i2infinity \r\nAs reported it works fine on calab, please find [gist here](https://colab.sandbox.google.com/gist/Saduf2019/a5ea2d4458d4da4ef64c5b3f4c8f5f60/untitled178.ipynb)\r\nCould you please try the same on virtual environment and let us know. ", "Also to add, @i2infinity, I tried your code using  Tensorflow version 2.2.0-dev20200508 (pip install tf-nightly==2.2.0.dev20200508) and it works, but using tensorflow-2.2.0 has the error you mentioned. I think the tensorflow version installed in the colab must be higher. Try upgrading tensorflow to the nightly version and see if it works for you.", "@i2infinity \r\nPlease update as per above comment", "Hi @Saduf2019 @daverim - I will try this within the next couple of days and get back. Thanks for the suggestions", "I think it is ok to close this one out as you have a fix that works on your end. I can re-open if needed"]}, {"number": 39363, "title": "bazel build; encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swif", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from: source\r\n- TensorFlow version: 1.14.0\r\n- Python version:3.7.7\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version: 0.24.1\r\n- trying to build tensorflow cpu not gpu \r\n\r\nI followed the intructions and based my versions found here: https://www.tensorflow.org/install/source#tested_build_configurations\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen i run the command\r\n``` bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package ``` it gives the following error: \r\n\r\n```\r\nStarting local Bazel server and connecting to it...\r\nERROR: error loading package '': Encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swift': java.io.IOException: Error downloading [https://github.com/bazelbuild/rules_swift/releases/download/0.9.0/rules_swift.0.9.0.tar.gz] to /home/domingo_cm/.cache/bazel/_bazel_domingo_cm/f08b2f8b39197d5a57f7b557c17f0caf/external/build_bazel_rules_swift/rules_swift.0.9.0.tar.gz: Unknown host: github.com\r\nERROR: error loading package '': Encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swift': java.io.IOException: Error downloading [https://github.com/bazelbuild/rules_swift/releases/download/0.9.0/rules_swift.0.9.0.tar.gz] to /home/domingo_cm/.cache/bazel/_bazel_domingo_cm/f08b2f8b39197d5a57f7b557c17f0caf/external/build_bazel_rules_swift/rules_swift.0.9.0.tar.gz: Unknown host: github.com\r\nINFO: Elapsed time: 14.145s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1. git clone https://github.com/tensorflow/tensorflow.git\r\n2. cd tensorflow\r\n3. git checkout r1.14\r\n4. ./configure\r\n5. (assuing bazel is installed ) bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nI am running under a corporate proxy network if it gives any importance\r\nAlso, git version is 2.17.1 (latest in Ubuntu 18.04)\r\n", "comments": ["@louiselumapas, \r\nCould you please check if you are able to build the package with the proxy disabled. Thanks!", "I am running under a company corporate proxy and i don\u2019t think i can disable it anytime and i\u2019m not allowed. Isn\u2019t there a workaround in building by surpassing the proxy?", "Since you are using `conda` for installing TF please post this issue on [ContinuumIO\r\n/anaconda-issues.](https://github.com/ContinuumIO/anaconda-issues/issues) for official support.\r\nApologies for redirecting.\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39363\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39363\">No</a>\n"]}, {"number": 39362, "title": "Example create_sine_model.ipynb disappreared ", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): all\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source):  I921176f6a8dc4c76bd45e6a508548d3b1936f89d\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): all\r\n\r\n**Describe the problem**\r\nThe create_sine_model.ipynb was deleted from the examples. \r\nThere is afaik no new place mentioned, where it can be found.\r\nIt is btw the introductory example in Pete Wardens TinyML book. \r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nIch checked the github location which is suggested in the book and could't find the example. By searching the last commit, I noticed that it was deleted recently.\r\n", "comments": ["You may refer this [notebook link](https://github.com/tensorflow/tensorflow/blob/453399f82c212a676b9510b3dc214c7f86e06d7c/tensorflow/lite/micro/examples/hello_world/create_sine_model.ipynb) however its not on master.", "Well, in principal yes, but then \"Open in Colab\" is somehow redirected to the master branch and says the following:\r\n<img width=\"861\" alt=\"grafik\" src=\"https://user-images.githubusercontent.com/10559666/82063230-84471580-96cb-11ea-92fa-0790eff65d57.png\">\r\nHence, in practice I cannot use the version in some other branch.\r\n\r\nAnd furthermore, the **introductory code sample** for a book **dedicated to the topic TensorFlow fpr uC** was deleted  from the master branch. I am not sure if this was intended.\r\n\r\nI don't see a reason why this notebook had to be deleted, where it can be found in a subale variant, and furthermore there was also no comment explaining this.\r\n", "Tagging in @petewarden and @dansitu -- would it be possible to add the `create_sine_model.ipynb` example back into the `hello_world` directory?", "Thanks @dynamicwebpaige, and sorry about this @quirli! I'm not sure why/how this was deleted, but we'll make sure it is added back ASAP.", "Update: Looks like it was moved into this subfolder:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world/train", "Ah, ok, thanks! I didn't see that one.\r\nI will close this one, however, some sort of note will probably be nice for future users.", "Thanks for reporting, agreed that we should redirect folks somehow!", "I'm on Chapter 3 and I can't find the sine example for notebooks. \r\n", " @dynamicwebpaige, ^^", "@mazurick It was moved into this subdirectory:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world/train", "The file is not there either must of moved again", "All of the TensorFlow Lite for Microcontrollers files got moved to a new, separate repository, so you can find the file here:\r\n\r\nhttps://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/create_sine_model.ipynb\r\n\r\nWarmly,\r\nDan"]}, {"number": 39361, "title": "Issue with Python3.8 and Ubuntu 20.04", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Ubuntu 20.04 arm64\r\n- TensorFlow installed from (source or binary): https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_aarch64.whl\r\n- Tensorflow version (commit SHA if source): 2.1.0\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33, etc.): Raspberry Pi 3\r\n\r\n**Describe the problem**\r\nPlease make support for Python 3.8 on Ubuntu 20.04 with Raspberry Pi 3 arm64. I try to install TF Lite with Python 3.8, but it isn't a good version of TF Lite and I read that the TF 2.2.0 works with Python 3.8, but this version I cannot find on the page: https://www.tensorflow.org/lite/guide/python. Thanks.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\npip3 install https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_aarch64.whl\r\n\r\n", "comments": ["Can I build my own python 'whl' file?\r\n\r\nHere are instructions only for the C++ static library: https://www.tensorflow.org/lite/guide/build_arm64.\r\nWhere are build instructions for Python language (tflite_runtime)?", "This might help you: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package", "It looks like the tflite_runtime for AARCH64 on python 3.8 and linux is now available on https://www.tensorflow.org/lite/guide/python per  4a96705. Is this what you were looking for?\r\n\r\nhttps://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp38-cp38-linux_aarch64.whl", "It's working perfectly. I tested it on a new Raspberry Pi 4 with Ubuntu 20.04 arm64.\r\n\r\nHere is the result:\r\n<img width=\"870\" alt=\"Sni\u0301mka obrazovky 2020-10-16 o 21 22 09\" src=\"https://user-images.githubusercontent.com/16693449/96300428-ce735080-0ff5-11eb-9011-5a303d5c97ad.png\">\r\n"]}, {"number": 39360, "title": "[Docs] Inconsistencies with Keras Applications preprocess_input", "body": "The latest [keras.io](https://keras.io) website includes a whole bunch of great examples and tutorials that could help users get started with deep learning, transfer learning and combines all the goodness that comes in around with the TF 2.x support for keras.\r\n\r\n1. https://keras.io/guides/transfer_learning/\r\n2. https://www.tensorflow.org/tutorials/images/transfer_learning\r\n\r\n## Description of documentation issue:\r\nOne of the major setbacks that I observed was brought in by the transfer learning examples portraying use of data augmentation involving the newly added `Resize()` and `Rescaling()` (rescaling the data from a range of 0-255 to 0.0-1.0, specific case for Xception in [1.](https://keras.io/guides/transfer_learning/) and -1.0-+1.0, specific case for MobileNetV2 in [2.](https://www.tensorflow.org/tutorials/images/transfer_learning)) layers from `tf.keras.layers.experimental` as per the latest keras RFC on Preprocessing Layers API. This is indeed a well planned transition and beneficial for users to switch to tf.data API instead of the `keras.preprocessing.image.ImageDataGenerator` in favour of performance and reducing training bottlenecks.\r\n\r\nA majority of the users still are using the ImageDataGenerator class with pre-trained models from keras-applications instead of the new `tf.keras.preprocessing.image_dataset_from_directory` or tf.data API(s) directly. Most likely, with the use of the `preprocessing_function` argument to ImageDataGenerator objects.\r\n\r\neg.\r\n```python3\r\nfrom tensorflow.keras.preprocessing import image\r\nfrom tensorflow.keras.applications.resnet_50 import preprocess_input\r\ndatagen = image.ImageDataGenerator(preprocessing_function=preprocess_input)\r\n```\r\n\r\nThe new documentation encourages use of tf.data API(s) exclusively which lacks consistency with this type of legacy image preprocessing used. As a result of various pre-trained models of keras_applications being ported from a variety of frameworks apart from TensorFlow, each specific keras_applications model requires it's own way of preprocessing images. The currently available ones being: \r\nhttps://github.com/tensorflow/tensorflow/blob/de5b0cfd434c7a9f848ab100b70a6be16e48280b/tensorflow/python/keras/applications/imagenet_utils.py#L72-L83\r\nThis makes it necessary for each of the pre-trained ConvNet(s) that form of a part of the keras_applications repo, be documented relating to which pre-trained model requires which type of preprocessing whatsoever and specifically how the same can be achieved using the newer Preprocessing Layers API or directly by chaining it with `ds.map()`.\r\n\r\nA workaround in this regard would be to:\r\n- update the newly created [keras-io repo](https://github.com/keras-team/keras-io) to document preprocessing method for each pre-trained model. [*please mention in comments if a corresponding Issue has to be filed in that repo*]\r\n- introduce changes to `tf.keras` and the `tf.keras.layers.experimental.preprocessing` for creating new classes that can help serve this goal\r\n- adding some documentation in place to explicitly specify use of respective `preprocess_input` with `ds.map`\r\n\r\n/cc: @fchollet Is there any RFC in this regard proposed by the TensorFlow community to unify legacy preprocess_input functions with the newer Preprocessing Layers API?", "comments": ["Hi,\r\n\r\nAny updates on this thread?\r\n\r\n/cc: @tanzhenyu Can we look into this?", "> Hi,\r\n> \r\n> Any updates on this thread?\r\n> \r\n> /cc: @tanzhenyu Can we look into this?\r\n\r\nI think this is already fixed", "Okay okay. \r\n"]}, {"number": 39359, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "Using TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"G:\\Final year project\\python\\Emotion-recognition-master\\train_emotion_classifier.py\", line 5, in <module>\r\n    from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>> \r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@mallikarjunsomanni \r\nWhat is the version of the tensorflow.\r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.[See hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the latest [microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.\r\nPlease, refer similar issue #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\nJust to sample over 100 similar issues: #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\n\r\nPlease make sure you do a search in the future.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39359\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39359\">No</a>\n"]}, {"number": 39358, "title": "The trainable_variables of the subclass of tf.keras.Model is empty.", "body": "class MaskMean(tf.keras.layers.Layer):\r\n    def __init__(self, trainable=True):\r\n        super(MaskMean, self).__init__()\r\n        self.dropout = tf.keras.layers.Dropout(0.1, trainable=trainable)\r\n\r\nclass Predict(tf.keras.layers.Layer):\r\n    def __init__(self, trainable=True):\r\n        super(Predict, self).__init__()\r\n        self.dense_layer = tf.keras.layers.Dense(512, activation='relu', name=\"full connection\", trainable=trainable)\r\n        self.predict = tf.keras.layers.Dense(1, name=\"prediction\", trainable=trainable)\r\n\r\nclass Regulation(tf.keras.Model):\r\n    def __init__(self, trainable=True):\r\n        super(Regulation, self).__init__()\r\n        # self.embedding = TFBertModel.from_pretrained(r'E:\\googleCloudDisk\\model\\Bert\\cased\\base')\r\n        # self.dropout = tf.keras.layers.Dropout(0.1, name='dropout')\r\n        # self.inmediate = tf.keras.layers.Dense(512, name=\"full connection\")\r\n        # self.predict = tf.keras.layers.Dense(1, name=\"prediction\")\r\n        self.mask_mean_layer = MaskMean(trainable=trainable)\r\n        self.predict = Predict(trainable=trainable)\r\n\r\nRmodel = Regulation(trainable=True)\r\n\r\nBut the Rmodel.trainable_variables() is empty.\r\nHow to define a subclass model of tf.keras.Model to make its' variables can be trainable and could return by Rmodel.trainable_variables()?", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version?.\r\n\r\nRequest you to share colab link or simple standalone code with proper indentation to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "I have solved this issue, thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39358\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39358\">No</a>\n", "How did you fix this issue?", "one batch data for the subclass and then the trainable variables will be got\u53d1\u81ea\u6211\u7684\u534e\u4e3a\u624b\u673a-------- \u539f\u59cb\u90ae\u4ef6 --------\u53d1\u4ef6\u4eba\uff1a Vignesh Ram Somnath <notifications@github.com>\u65e5\u671f\uff1a 2020\u5e746\u670821\u65e5\u5468\u65e5 17:21\u6536\u4ef6\u4eba\uff1a tensorflow/tensorflow <tensorflow@noreply.github.com>\u6284\u9001\uff1a over-shine <Chengwei_works@163.com>, State change <state_change@noreply.github.com>\u4e3b    \u9898\uff1a Re: [tensorflow/tensorflow] The trainable_variables of the subclass of tf.keras.Model is empty. (#39358)\r\nHow did you fix this issue?\r\n\r\n\u2014You are receiving this because you modified the open/close state.Reply to this email directly, view it on GitHub, or unsubscribe."]}, {"number": 39357, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "I'm trying work with MINIST dataset with tensorflow\r\nbut it keep failed to load about the DLL file\r\n\r\n**System information**\r\n- WINDOWS 10\r\n- TensorFlow installed : Anaconda (by Prompt)\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.8.2\r\n- Installed using virtualenv? pip? conda?: Prompt pip\r\n- GPU model and memory: NVIDIA GTX950 4G\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nI've tried uninstall and reinstall all the pip, tensorflow, pillow\r\nwith different kinds of CMD / Conda / Prompt\r\nand it just didn't work and really can't figure out wheres the problem.\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@senkoraku552,\r\nPython 3.8 does not support Tensorflow v2.1, I'd request you to try installing TensorFlow v2.2 using the below command\r\n`pip install tensorflow==2.2.0`\r\n\r\nAlso regarding the ImportError, please check [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) from a similar issue and let us know if it helps. Thanks!", "> @senkoraku552,\r\n> Python 3.8 does not support Tensorflow v2.1, I'd request you to try installing TensorFlow v2.2 using the below command\r\n> `pip install tensorflow==2.2.0`\r\n> \r\n> Also regarding the ImportError, please check [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) from a similar issue and let us know if it helps. Thanks!\r\n\r\nThanks! I was never though about the patch thing, I'm gonna try this now!", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\nJust to sample over 100 similar issues: #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\n\r\nPlease make sure you do a search in the future.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39357\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39357\">No</a>\n"]}, {"number": 39356, "title": "Update version numbers for TensorFlow 2.0.2", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 0 -> 0\nPatch: 1 -> 2\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.0.1\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/python/tpu/profiler/capture_tpu_profile.py:93:2.0.1\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.0.1\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/python/tpu/profiler/capture_tpu_profile.py:93:2.0.1\n```", "comments": []}, {"number": 39355, "title": "Update release notes for TensorFlow 2.0.2", "body": "This PR is intentionally incomplete. One of the Release Owners for 2.0.2\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 39354, "title": "Update version numbers for TensorFlow 2.1.1", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 1 -> 1\nPatch: 0 -> 1\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.1.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/tools/pip_package/setup.py:64:2.1.0\ntensorflow/tools/pip_package/setup.py:65:2.1.0\ntensorflow/tools/pip_package/setup.py:99:2.1.0\ntensorflow/lite/toco/tflite/op_version_test.cc:148:2.1.0\ntensorflow/lite/toco/tflite/op_version.cc:77:2.1.0\ntensorflow/lite/toco/tflite/op_version.cc:85:2.1.0\ntensorflow/lite/toco/tflite/op_version.cc:148:2.1.0\ntensorflow/lite/toco/tflite/op_version.cc:208:2.1.0\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.1.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/tools/pip_package/setup.py:64:2.1.0\ntensorflow/tools/pip_package/setup.py:65:2.1.0\ntensorflow/tools/pip_package/setup.py:99:2.1.0\ntensorflow/lite/toco/tflite/op_version_test.cc:148:2.1.0\ntensorflow/lite/toco/tflite/op_version.cc:77:2.1.0\ntensorflow/lite/toco/tflite/op_version.cc:85:2.1.0\ntensorflow/lite/toco/tflite/op_version.cc:148:2.1.0\ntensorflow/lite/toco/tflite/op_version.cc:208:2.1.0\n```", "comments": []}, {"number": 39353, "title": "Update release notes for TensorFlow 2.1.1", "body": "This PR is intentionally incomplete. One of the Release Owners for 2.1.1\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 39352, "title": "Update version numbers for TensorFlow 1.15.3", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 1 -> 1\nMinor: 15 -> 15\nPatch: 2 -> 3\n\nNo lingering old version strings \"1.15.2\" found in source directory \n\"tensorflow/\". Good.\nNo lingering old version strings \"1.15.2\" found in source directory \n\"tensorflow/\". Good.\n```", "comments": []}, {"number": 39351, "title": "tf.strings.join not allowed in graph", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 19.10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.2\r\n- Python version:3.7.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nWhen writing a function that is mapped on a `tf.data.Dataset`, using `tf.strings.join()` yields the following error\r\n```\r\nOperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\r\n```\r\nEven when using the `@tf.function`\r\n\r\n**Describe the expected behavior**\r\nShould work when calling the `@tf.function` decorator\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\n@tf.function\r\ndef process_path(path):\r\n    path = tf.strings.split(path, \"_\")[:3]\r\n    path = tf.strings.join(path, \"_\")\r\n    return path\r\n\r\npath_ds = tf.data.Dataset.list_files(...)\r\npath_ds = path_ds.map(process_path)\r\n```\r\n", "comments": ["@khazit `tf.strings.join` expect a list as input, so it should be `tf.strings.join([path, \"_\"])`.\r\n\r\nI will close this issue, but feel free to reopen if you encounter any other issues.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39351\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39351\">No</a>\n", "@yongtang Thanks for the quick answer but it still doesn't work properly. \r\n\r\nThis `tf.strings.join([path, \"_\"])` gives the following \r\n`[b'data/cityscapes/train/darmstadt_' b'000035_' b'000019_']` \r\n\r\nMy idea was to join every element of the tensor using the \"_\" separator into a single string. So I'm expecting this `b'data/cityscapes/train/darmstadt_000035_000019'` as an output", "@khazit Ah in that case, you need to convert path into lists before the join through tf.unstack:\r\n```\r\n@tf.function(autograph=False)\r\ndef process_path(path):\r\n    path = tf.strings.split(path, \"_\")[:3]\r\n    path = tf.unstack(path, num=3)\r\n    path = tf.strings.join(path, \"_\")\r\n    return path\r\n```\r\n\r\n`num=3` is needed as otherwise tf.unstack will not be able to infer the number of output and join will not work. So `num=3` has to be passed in.\r\n", "Great ! Thank you\r\nI'm closing this issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39351\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39351\">No</a>\n", "@yongtang Is there any way to not manually input the number of outputs, i.e. not have to set num=3.  I am trying to do this in a for loop where there are different sizes. "]}, {"number": 39350, "title": "Update release notes for TensorFlow 2.1.1", "body": "This PR is intentionally incomplete. One of the Release Owners for 2.1.1\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 39349, "title": "Update release notes for TensorFlow 1.15.3", "body": "This PR is intentionally incomplete. One of the Release Owners for 1.15.3\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 39348, "title": "Update release notes for TensorFlow 1.15.3", "body": "This PR is intentionally incomplete. One of the Release Owners for 1.15.3\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 39347, "title": "I used from keras_applications.inception_v3 import InceptionV3 but it showed the following error.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39347\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39347\">No</a>\n"]}, {"number": 39346, "title": "Cannot import EfficientNetB0 from tensorflow.keras.applications", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 (docker container)\r\n- TensorFlow installed from (source or binary): binary (using pip) \r\n- TensorFlow version (use command below):  v2.2.0-rc4-8-g2b96f3662b 2.2.0 (I installed version 2.2.0 from pypi)\r\n- Python version: 3.7.7\r\n\r\n**Describe the current behavior**\r\nI cannot import EfficientNetB0 from tensorflow.keras.applications\r\nWhen listing the module, using `print(dir(tensorflow.keras.applications))`, I can see other applications (like MobileNetV2, ...), but not efficient net or dense net\r\n This is weird, since here (https://github.com/tensorflow/tensorflow/tree/v2.2.0/tensorflow/python/keras/applications) it's present.\r\n\r\n\r\n**Describe the expected behavior**\r\n`from tensorflow.keras.applications import EfficientNetB0` should work\r\n\r\n", "comments": ["@Hartorn,\r\nAs per the [documentation for EfficientNetB0](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0). The API is available only in TF-nightly. \r\n\r\nI was able to import EfficientNetB0 without any issues using TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/a977106b48183824373ed2fef510b47c/39346-tf-nightly.ipynb). Thanks!", "Oh sry, did not see this.\nThanks for the answer "]}, {"number": 39345, "title": "Failed to import tensorflow with Winpython64-3.7.7.0 (Windows 10)", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Just tried to import tensorflow\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\nWinpython64-3.7.7.0\r\n- **TensorFlow version (use command below)**:\r\ntensorflow_cpu 2.1.0\r\n- **Python version**:\r\nWinpython64-3.7.7.0\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\nCoral Edge TPU\r\n- **Exact command to reproduce**:\r\n\r\nimport tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\r\n\r\n\r\n\r\n\r\n### Describe the problem\r\nFailed to import tensorflow (see logs)\r\n\r\n### Source code / logs\r\nimport tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\ptpython\\repl.py\", line 148, in _execute\r\n    code = compile_with_flags(line, \"eval\")\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\ptpython\\repl.py\", line 135, in compile_with_flags\r\n    dont_inherit=True,\r\n  File \"<stdin>\", line 1\r\n    import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\r\n         ^\r\nSyntaxError: invalid syntax\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nTraceback (most recent call last):\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\ptpython\\repl.py\", line 148, in _execute\r\n    code = compile_with_flags(line, \"eval\")\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\ptpython\\repl.py\", line 135, in compile_with_flags\r\n    dont_inherit=True,\r\n  File \"<stdin>\", line 1\r\n    import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\r\n         ^\r\nSyntaxError: invalid syntax\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"E:\\Software\\Coral\\WPy64-3770\\python-3.7.7.amd64\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@MartinBathmann  \r\nWhat is the version of the tensorflow.\r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the latest microsoft visual c++ redistributable from [here.](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\n.Also, please follow the instructions from to install from[ Tensorflow website.\r\n](https://www.tensorflow.org/install/source_windows)\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.\r\nPlease, refer similar issue #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "my cpu does not support AVX. Thank you for the hint! I've found a conda version of tensorflow for my cpu. Now import works!", "@MartinBathmann\r\nGlad to help, moving this to closed status as its resolved."]}, {"number": 39344, "title": "Gradient of outputs with respect to inputs inside a custom loss function", "body": "I want to write a custom loss function for a Multilayer Perceptron network in Keras. The loss has two components: first is the regular 'mse' and the second is element wise gradients of output with respect to input features. Let x be the input with 2 features (size: number of samples X 2) and y the output with single output (size: number of samples X 1). I am denoting derivative of each output sample with first feature of each sample as `$\\frac{dy[:]}{dx[:,0]}$`\r\n\r\nSimilarly, I want to compute the following expression inside the loss function:\r\n\r\n`$$r[:] = y[:] \\frac{dy[:]}{dx[:,0]} - x[:,1] \\frac{d^2y[:]}{dx[:,0]^2}$$`\r\n\r\nand take the mean square of the r vector. The total loss being the sum of the regular 'mse' and mean square of r vector.\r\n\r\nThis is a minimal, reproducible example of the code I tried:\r\n```\r\ndef custom_loss_envelop(model_inputs, model_outputs):\r\n    def custom_loss(y_true,y_pred):\r\n        mse_loss = keras.losses.mean_squared_error(y_true, y_pred)\r\n        print()\r\n        print(model_inputs); print()\r\n        print(model_outputs); print()\r\n        dy_dx = keras.backend.gradients(model_outputs, tf.gather(model_inputs, [0], axis=1))\r\n        print(dy_dx); print()\r\n        d2y_dx2 = keras.backend.gradients(dy_dx, tf.gather(model_inputs, [0], axis=1))\r\n        print(d2y_dx2); print()\r\n\r\n        r = tf.multiply(model_outputs, tf.gather(dy_dx, [0], axis=1)) - tf.multiply(tf.gather(model_inputs, [1], axis=1), tf.gather(d2y_dx2, [0], axis=1)) # y*dy_dx[0] - x[1]*d2y_dx[0]2\r\n\r\n        r = keras.backend.mean(keras.backend.square(r))\r\n        loss = mse_loss + r\r\n        return loss\r\n    return custom_loss\r\n\r\nnx=100;\r\ninputs_train=np.random.uniform(0,1,(nx,2)); outputs_train=np.random.uniform(0,1,(nx,1))\r\ninputs_val=np.random.uniform(0,1,(int(nx/2),2)); outputs_val=np.random.uniform(0,1,(int(nx/2),1))\r\nn_hidden_units=50; l2_reg_lambda=0; learning_rate=0.001; dropout_factor=0.0; epochs=3\r\n\r\nmodel = keras.Sequential();\r\nmodel.add(keras.layers.Dense(n_hidden_units, activation='relu', input_shape=(inputs_train.shape[1],), kernel_regularizer=keras.regularizers.l2(l2_reg_lambda))); #first hidden layer\r\nmodel.add(keras.layers.Dropout(dropout_factor)); model.add(keras.layers.BatchNormalization())\r\nmodel.add(keras.layers.Dense(n_hidden_units, activation='relu', kernel_regularizer = keras.regularizers.l2(l2_reg_lambda)));\r\nmodel.add(keras.layers.Dropout(dropout_factor)); model.add(keras.layers.BatchNormalization())\r\nmodel.add(keras.layers.Dense(n_hidden_units, activation='relu', kernel_regularizer = keras.regularizers.l2(l2_reg_lambda)));\r\nmodel.add(keras.layers.Dropout(dropout_factor)); model.add(keras.layers.BatchNormalization())\r\nmodel.add(keras.layers.Dense(outputs_train.shape[1], activation='linear'));\r\noptimizer1 = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\r\n\r\nmodel.compile(loss=custom_loss_envelop(model.inputs, model.outputs), optimizer=optimizer1, metrics=['mse'])\r\n\r\nmodel.fit(inputs_train, outputs_train, batch_size=100, epochs=epochs, shuffle=True, validation_data=(inputs_val,outputs_val), verbose=1)\r\n```\r\n\r\nHere, I have generated training and validation samples randomly. I am getting the tensor shapes as follows: model_inputs: `[<tf.Tensor 'dense_input:0' shape=(None, 2) dtype=float32>]`, model_outputs: `[<tf.Tensor 'dense_3/Identity:0' shape=(None, 1) dtype=float32>]` and dy_dx: `[None]`. The first 2 are as expected but the derivative should also be of shape `(None, 1)` which it is not. Hence, I get `AttributeError: 'NoneType' object has no attribute 'op'` error in the line `d2y_dx2 = keras.backend.gradients(dy_dx, tf.gather(model_inputs, [0], axis=1))`\r\n\r\nAny help is appreciated either to fix this issue or with alternate solution.", "comments": ["I have tried in colab with TF 2.2-rc4 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/02487344c5e408d7f44a841096dd3f2c/untitled874.ipynb).Thanks!", "Thanks @shahaneshantanu . There is likely an issue in the custom code above. You can review the [guide](https://keras.io/guides/customizing_what_happens_in_fit/) on overriding train_step for some help, and also reach out on Stack Overflow, where there is a larger community to help you debug. If there is a concrete bug that you find, please file a new issue describing it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39344\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39344\">No</a>\n", "@shahaneshantanu  - have you solved this problem?"]}, {"number": 39343, "title": "Is it normal that every worker print the same loss and metric values when using multiworker distributed stragety?", "body": "**Descriptions**\r\n\r\nI've created a Keras model, and trained it with multiworker distributed strategy using `tf2.2.0`.\r\n\r\nThe training data I used is dataset gengerated from numpy array. And according to the [shard policy](https://www.tensorflow.org/api_docs/python/tf/data/experimental/DistributeOptions), the dataset will be auto sharded by `DATA policy`. That is to say every worker will handle different portion of the whole dataset.\r\n\r\nAfter training, I notice that all the workers print the same loss and metric values just like they all trained with the identical data. But according to my knowledge, if every worker train with different data, the loss and metric values of them should be different. Is it because the shard policy didn't take effect?\r\n\r\nI also know that multi-worker uses all-reduce communication method to keep variables in sync. So, the values printed are calculated after all-reduce? This could explain the same values maybe.\r\n\r\n**Questions:**\r\n\r\n1. Is this normal? And why?\r\n2. How to check(or make sure) that different workers use different data portion for training(or the shard policy take effect)?\r\n3. Are the values printed for all workers after all-reduce operation or just for that single worker?\r\n4. When will all-reduce execute, on every batch end or epoch end?\r\n5. When I use just numpy array for training, does the shard policy work? Or every worker will use the whole data for its training?\r\n6. In general, dataset for every worker's fit method is same. When different, training will success as well, does shard policy work at this time?\r\n\r\n**Code snippets:**\r\n\r\n```python\r\nclass ThreeLayerMLP(keras.Model):\r\n    def __init__(self, name=None):\r\n        super().__init__(name=name)\r\n        self.dense_1 = layers.Dense(64, activation='relu', name='dense_1')\r\n        self.dense_2 = layers.Dense(64, activation='relu', name='dense_2')\r\n        self.pred_layer = layers.Dense(10, name='predictions')\r\n\r\n    def call(self, inputs):\r\n        x = self.dense_1(inputs)\r\n        x = self.dense_2(x)\r\n        return self.pred_layer(x)\r\n\r\n\r\ndef main(argv):\r\n    del argv  # Unused args\r\n    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n    BATCH_SIZE_PER_REPLICA = 64\r\n    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n    print('Number of devices: %d' % strategy.num_replicas_in_sync)\r\n\r\n    with strategy.scope():\r\n        model = model = ThreeLayerMLP(name='3_layer_mlp')\r\n        model.compile(\r\n            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n            optimizer=keras.optimizers.RMSprop())\r\n\r\n    log_dir = FLAGS.logs\r\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\r\n                                                          histogram_freq=1,\r\n                                                          update_freq='batch')\r\n\r\n    np.random.seed(0)\r\n    x_train, y_train = (np.random.random(\r\n        (60000, 784)), np.random.randint(10, size=(60000, 1)))\r\n    x_test, y_test = (np.random.random(\r\n        (10000, 784)), np.random.randint(10, size=(10000, 1)))\r\n\r\n    # options = tf.data.Options()\r\n    # options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\r\n    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n    train_dataset = train_dataset.shuffle(1024).batch(BATCH_SIZE)\r\n\r\n\r\n    model.fit(\r\n        train_dataset,\r\n        epochs=5,\r\n        steps_per_epoch=10,\r\n        callbacks=tensorboard_callback)\r\n\r\n    model_dir = FLAGS.logs + '/models/' + str(task_index)\r\n    model.save(model_dir)\r\n\r\n\r\nif __name__ == '__main__':\r\n    app.run(main)\r\n```\r\n\r\nI'm cofused by these questions for long time. I will appreciate your help very much.\r\n\r\nThanks~", "comments": ["This is expected. The metric values would be allreduced in `fit` method. By default, `MultiWorkerMirroredStrategy` will shard your data across workers. You can use `auto_shard_policy` to turn off that behavior."]}, {"number": 39342, "title": "<Bug> while fit the tensor flow mode", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\nhttps://colab.research.google.com/drive/1Okqfq5UXFttj_atsmVqwooDwVibLtriq?usp=sharing\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@vishnoiprem \r\nIt looks like you haven't filled the  template while you created this issue, please share the tensorflow version as well.\r\nPlease provide with indented and correct syntax stand alone code such that we could replicate the issue faced, please share error logs for us to analyse\r\n ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39342\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39342\">No</a>\n", "closing since no information was provided"]}, {"number": 39341, "title": "sparse_categorical_crossentropy metrics bug?", "body": "**System information**\r\n- Have I written custom code : No\r\n- OS Platform and Distribution: macOS 10.15.4 (Reproduce on Colab)\r\n- TensorFlow installed from (source or binary): from pip \r\n- TensorFlow version (use command below): tensorflow==2.2.0\r\n- Python version: python 3.7.3 \r\n\r\nTensorFlow version : v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n**Describe the current behavior**\r\nTrying to train with below code , however it shows ValueError.\r\n```\r\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])\r\n\r\nmodel.fit(train_ds, epochs=100, validation_data=valid_ds, steps_per_epoch=100, use_multiprocessing=False)\r\n```\r\nshow below errors\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-33-1c452d509fd9> in <module>()\r\n----> 1 model.fit(train_ds, epochs=100, validation_data=valid_ds, steps_per_epoch=100, use_multiprocessing=False)\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nValueError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\r\n        outputs = self.distribute_strategy.run(\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:543 train_step  **\r\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:391 update_state\r\n        self._build(y_pred, y_true)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:322 _build\r\n        self._metrics, y_true, y_pred)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1118 map_structure_up_to\r\n        **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1214 map_structure_with_tuple_paths_up_to\r\n        *flat_value_lists)]\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1213 <listcomp>\r\n        results = [func(*args, **kwargs) for args in zip(flat_path_list,\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1116 <lambda>\r\n        lambda _, *values: func(*values),  # Discards the path arg.\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:421 _get_metric_objects\r\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:421 <listcomp>\r\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:442 _get_metric_object\r\n        y_t_rank = len(y_t.shape.as_list())\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1173 as_list\r\n        raise ValueError(\"as_list() is not defined on an unknown TensorShape.\")\r\n\r\n    ValueError: as_list() is not defined on an unknown TensorShape.\r\n```\r\n**Describe the expected behavior**\r\nExpect the model start training.\r\n```\r\nEpoch 1/100\r\n100/100 [==============================] - 22s 223ms/step - loss: 0.4050 - sparse_categorical_accuracy: 0.8918 - val_loss: 0.1670 - val_sparse_categorical_accuracy: 0.9400\r\nEpoch 2/100\r\n 30/100 [========>.....................] - ETA: 13s - loss: 0.4082 - sparse_categorical_accuracy: 0.8763\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n**Reproducible Colab**\r\nhttps://drive.google.com/open?id=1VjmF4OlPddPVbDG0iMNYg4lWjuis9H5f\r\n\r\n\r\n**Other info / logs**\r\n\r\nAlthough the bugs above, i can train by changing the metrics from the code \r\n[\"accuracy\"] to [tf.keras.metrics.SparseCategoricalAccuracy()]\r\n\r\n\r\n", "comments": ["I have tried in colab with TF version 2.2-rc4 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/8bf4f2ed3baa4c83063fd32403536d45/untitled873.ipynb).Thanks!", "You can workaround it by changing the metrics argument to `metrics = ['sparse_categorical_accuracy']`.", "@bjourne This is a known issue. We will track the progress with [this issue](https://github.com/tensorflow/tensorflow/issues/42045). You and @bjourne already mentioned workaround. \r\n\r\nAs [mentioned](https://github.com/tensorflow/tensorflow/issues/42045#issuecomment-674232499) by @k-w-w \r\n\r\n> This is a bug with using the sparse categorical accuracy. For now, please compile the model with metrics='sparse_categorical_accuracy' instead of just 'accuracy'.\r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/b3efcbc1851512aa644e0ecce6cdccf0/untitled873.ipynb) is the gist for a reference. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I am closing this issue as you know the workaround. We will track this bug in [this issue](https://github.com/tensorflow/tensorflow/issues/42045).\r\n\r\nI will also comment when the bug will get corrected. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39341\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39341\">No</a>\n", "This is resolved in recent tf-nightly. Please feel free to reopen if you notice the issue.\r\nThis is available in stable TF2.4 in the near future. Thanks!"]}, {"number": 39340, "title": "TF 2.2.0 fails to build (Ubuntu Linux): \"this rule is missing dependency declarations\"", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0 (2b96f3662b)\r\n- Python version: Python 3.8.2\r\n- Installed using virtualenv? pip? conda?: -\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): GCC 9.3.0 (Ubuntu 9.3.0-10ubuntu2)\r\n- CUDA/cuDNN version: CUDA 10.2 / cuDNN 7.6.5 (but seems irrelevant for this issue)\r\n- GPU model and memory: N/A\r\n\r\n**Describe the problem**\r\nTensorFlow 2.2.0 fails to build from source, complaining about \"missing dependency declarations\".\r\nThe precise error differs somewhat, depending on whether CUDA support is activated in the `configure` script.\r\n\r\nWhen not activating CUDA, the following error occurs:\r\n\r\n```\r\nERROR: /home/michael/devel/tensorflow/tensorflow/python/BUILD:797:1: undeclared inclusion(s) in rule '//tensorflow/python:_pywrap_checkpoint_reader.so':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/util/py_checkpoint_reader_wrapper.cc':\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_endian.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/utils.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_math.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /home/michael/devel/tensorflow/tensorflow/python/tools/BUILD:82:1 undeclared inclusion(s) in rule '//tensorflow/python:_pywrap_checkpoint_reader.so':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/util/py_checkpoint_reader_wrapper.cc':\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_endian.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/utils.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_math.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\n```\r\n\r\nWith CUDA support activated, the same type of failure occurs, but at a different stage:\r\n\r\n```\r\n  ERROR: /home/michael/devel/tensorflow/tensorflow/python/BUILD:606:1: undeclared inclusion(s) in rule '//tensorflow/python:_pywrap_tf_session.so':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/client/tf_session_wrapper.cc':\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_endian.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/utils.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_math.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/michael/devel/tensorflow/tensorflow/python/tools/BUILD:225:1 undeclared inclusion(s) in rule '//tensorflow/python:_pywrap_tf_session.so':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/client/tf_session_wrapper.cc':\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_endian.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/utils.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_math.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/bin/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nGiven a working Bazel installation (2.0.0), the following commands lead to the error:\r\n\r\n```\r\ncd ~/devel/tensorflow\r\ngit clean -fxd\r\ngit checkout v2.2.0\r\n\r\npython3 -m venv ~/.virtualenvs/tf_dev\r\nsource ~/.virtualenvs/tf_dev/bin/activate\r\npip install -U pip six numpy wheel setuptools mock 'future>=0.17.1'\r\npip install -U keras_applications --no-deps\r\npip install -U keras_preprocessing --no-deps\r\n\r\n./configure\r\n# (see below for output)\r\n\r\nbazel build --config=opt -c opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nOutput from `configure` (in the CUDA support case; default options were used, except for CUDA support):\r\n```\r\n  (tf_dev) michael@the-beast \u279c  ~/devel/tensorflow git:(2b96f3662b) ./configure                                                                                        \r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nYou have bazel 2.0.0 installed.\r\nPlease specify the location of python. [Default is /home/michael/.virtualenvs/tf_dev/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /home/michael/.virtualenvs/tf_dev/lib/python3.8/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/michael/.virtualenvs/tf_dev/lib/python3.8/site-packages]\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.2 in:\r\n    /usr/local/cuda/lib64\r\n    /usr/local/cuda/include\r\nFound cuDNN 7 in:\r\n    /usr/local/cuda/lib64\r\n    /usr/local/cuda/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 5.2,5.2]: 5.2\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: \r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nI can attach a fuill build log, if necessary. Due to the asynchronous build nature, it might be hard to interpret, though. The above error messages are the only obvious notices w.r.t. the problem at hand.", "comments": ["If you upgraded GCC or ubuntu, you have to run \"bazel clean --expunge\" Then retry building tf from the beginning.\r\nIs it possible you cloned TF, built before, then updated your system?", "Also, in your virtualenvironment, is numpy installed?", "> Is it possible you cloned TF, built before, then updated your system?\r\n\r\nYes, that was the case. I did a new install of Ubuntu 20.04, porting my `/home` directory. A `bazel clean --expunge` helped, in addition to the `git clean -fxd; git checkout v2.2.0` I had already done. The behavior of Bazel never ceases to amaze me.\r\n\r\nEverything works now given the above configuration. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39340\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39340\">No</a>\n"]}, {"number": 39339, "title": "AutoGraph and tf.function are not working for TPU: Resubmitting this issue, because no reply so far for previous thread.", "body": "It seems that TPU only supports keras fit() function, but unable to use functions from tf.function and autographs.\r\n\r\nTensorflow version 2.1\r\npython version 3.6\r\n\r\nIssue can be reproduced in colab.\r\n\r\nHere's the link to gist.\r\nhttps://gist.github.com/saahiluppal/0bf79c27a15eaf6a72b25322eae6b6aa\r\n\r\nThanks.", "comments": ["I am able to replicate the code shared, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/2b84b4a389373be779f5d0658e4620db/untitled177.ipynb). Thanks!", "When using TPUStrategy, or any distribution strategy without keras model.fit, you need to use a few more strategy methods to distribute your computation. You can see a tutorial here: https://www.tensorflow.org/tutorials/distribute/custom_training\r\n\r\nJust replace `MirroredStrategy` in that tutorial with `TPUStrategy` (keep the initialization etc associated w TPUStrategy). The rest of the code should work as-is. ", "This helped me. \r\nThanks. "]}, {"number": 39338, "title": "TypeError: 'DatasetV1Adapter' object is not subscriptable", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow version (use command below):1.15.0 (I have to use tf 1.x rather than tf 2.x)\r\n- Python version: python3.7\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Nvidia 8G\r\n**Error**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/frank/PycharmProjects/reconstruction_NN/my_test.py\", line 77, in <module>\r\n    train_script(model,example,opt)\r\n  File \"/home/frank/PycharmProjects/reconstruction_NN/my_test.py\", line 54, in train_script\r\n    output = model(example['my_x'])\r\nTypeError: 'DatasetV1Adapter' object is not subscriptable\r\n```\r\n\r\n**Full Code**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Lambda, Conv2D, Reshape, MaxPool2D, Average, Dropout, Concatenate, \\\r\n    Add, Maximum, Layer, Activation, Conv1D, TimeDistributed, GlobalAvgPool2D\r\nimport numpy as np\r\ntf.compat.v1.enable_eager_execution()\r\nprint(tf.__version__)\r\nprint(tf.executing_eagerly())\r\n\r\n\r\nclass Test(tf.keras.Model):\r\n    def __init__(self,attention_sz,dropout_rt, name=None):\r\n        super(Test, self).__init__(name=name)\r\n        # here we define the layer:\r\n        self.fc = Dense(attention_sz,input_dim = attention_sz ,activation='relu')\r\n        self.fc2 = Dense(attention_sz, activation='relu')\r\n        self.fc3 = Dense(1, activation='sigmoid')\r\n\r\n        self.dp = Dropout(dropout_rt,input_shape=(attention_sz,))\r\n        self.dp2 = Dropout(dropout_rt,input_shape=(attention_sz,))\r\n\r\n\r\n    def call(self, inp):\r\n        # here we get the segmentation and pose\r\n        with tf.device('/gpu:0'):\r\n            print(\"~~~~~~~~~~~\")\r\n            x = self.fc(inp)\r\n            print(x.shape)\r\n            z = self.dp(x)\r\n            print(z.shape)\r\n            x = self.fc2(z)\r\n            print(x.shape)\r\n            z = self.dp2(x)\r\n            print(z.shape)\r\n            y = self.fc3(z)\r\n            print(y.shape)\r\n        return y # here z is the weight.\r\n\r\n\r\n    # here we overwrite the method.\r\n    def save(self, checkpoint_path):\r\n        print(\"Saving model...\")\r\n        self.save_weights(checkpoint_path)\r\n        print(\"Model saved\")\r\n    def load(self, checkpoint_path):\r\n        print(\"Loading model checkpoint {} ...\\n\".format(checkpoint_path))\r\n        self.load_weights(checkpoint_path)\r\n        print(\"Model loaded\")\r\n\r\ncheckpoint_path = \"saved_model/\"\r\n\r\n\r\ndef train_script(model, example, optimizer):\r\n    with tf.GradientTape() as tape:\r\n        output = model(example['my_x'])\r\n        loss = tf.reduce_mean(tf.abs(output - example['my_y']))\r\n    variables = model.trainable_variables\r\n    gradients = tape.gradient(loss, variables)\r\n    optimizer.apply_gradients(zip(gradients, variables))\r\n    return loss\r\n\r\nif __name__ == '__main__':\r\n    model = Test(1024, 0.05)\r\n\r\n    x = np.round(np.random.normal(1.75, 0.2, size=(10000, 1024)), 2)\r\n    x2 = np.round(np.random.normal(100.75, 0.2, size=(10000, 1024)), 2)\r\n    labels = np.zeros((10000, 1))\r\n    labels2 = np.ones((10000, 1))\r\n    x_t = np.row_stack((x, x2))\r\n    labels = np.row_stack((labels, labels2))\r\n    x_t = tf.convert_to_tensor(x_t)\r\n    labels = tf.convert_to_tensor(labels)\r\n\r\n    example = tf.data.Dataset.from_tensor_slices(\r\n        dict(my_x=x_t, my_y=labels)).repeat().batch(2)\r\n\r\n    opt = tf.keras.optimizers.Adam(0.1)\r\n    train_script(model,example,opt)\r\n\r\n```", "comments": ["Please note that eager mode is enabled.\r\n```\r\ntf.compat.v1.enable_eager_execution()\r\nprint(tf.__version__)\r\nprint(tf.executing_eagerly())\r\n```", "I have tried in colab with TF version 1.15 and was able to reproduce the issue.However i tried with TF version 2.2-rc4 and was seeing different error message.(`TypeError: 'BatchDataset' object is not subscriptable`).Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/d9cdedde6cfd26f7d33c545550077064/untitled872.ipynb).Thanks!", "@Frank-Dz Your code snippet fails irrespective of eager execution enabled/disabled in TF 1.15\r\nHowever you should try passing example object as iterable as suggested by the error message.\r\nYou can achieve this by setting:\r\n```python\r\ndef train_script(model, example, optimizer):\r\n    with tf.GradientTape() as tape:\r\n        example = list(example.as_numpy_iterator()) # add this line\r\n        output = model(example['my_x'])\r\n        loss = tf.reduce_mean(tf.abs(output - example['my_y']))\r\n       ... \r\n```\r\nSee https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#from_tensor_slices", "Thanks! Well solved!\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39338\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39338\">No</a>\n"]}, {"number": 39337, "title": "Memory alignment of C + + member variables", "body": "I'm using tensorflow for image recognition\u3002Now it's been crashing\r\nThe logs are as follows\uff1a\r\n *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r\n2020-05-09 15:50:16.279 8343-8343/? A/DEBUG: Build fingerprint: 'Android/msm8953_32/msm8953_32:7.1.2/N2G47H/howard04261732:user/test-keys'\r\n2020-05-09 15:50:16.279 8343-8343/? A/DEBUG: Revision: '0'\r\n2020-05-09 15:50:16.279 8343-8343/? A/DEBUG: ABI: 'arm'\r\n2020-05-09 15:50:16.279 8343-8343/? A/DEBUG: pid: 8134, tid: 8134, name: recycling  >>> recycling <<<\r\n2020-05-09 15:50:16.279 8343-8343/? A/DEBUG: signal 7 (SIGBUS), code 1 (BUS_ADRALN), fault addr 0x8baaf4bd\r\n2020-05-09 15:50:16.279 8343-8343/? A/DEBUG:     r0 be9f370c  r1 be9f370c  r2 00024bfc  r3 00000000\r\n2020-05-09 15:50:16.280 8343-8343/? A/DEBUG:     r4 00000000  r5 00000000  r6 8b493000  r7 be9f36b0\r\n2020-05-09 15:50:16.280 8343-8343/? A/DEBUG:     r8 a1837010  r9 00000000  sl 00000000  fp 00024c00\r\n2020-05-09 15:50:16.280 8343-8343/? A/DEBUG:     ip 8baaf4bd  sp be9f3644  lr 00093000  pc 8e9bc67e  cpsr 600d0030\r\n2020-05-09 15:50:16.282 8343-8343/? A/DEBUG: backtrace:\r\n2020-05-09 15:50:16.282 8343-8343/? A/DEBUG:     #00 pc 0008167e  /data/app/com.pekon.recycling-1/lib/arm/libtensorflowlite_jni.so\r\n2020-05-09 15:50:16.282 8343-8343/? A/DEBUG:     #01 pc 000838cb  /data/app/com.pekon.recycling-1/lib/arm/libtensorflowlite_jni.so\r\n2020-05-09 15:50:16.282 8343-8343/? A/DEBUG:     #02 pc 000801c3  /data/app/com.pekon.recycling-1/lib/arm/libtensorflowlite_jni.so\r\n2020-05-09 15:50:16.282 8343-8343/? A/DEBUG:     #03 pc 000f7a39  /data/app/com.pekon.recycling-1/lib/arm/libtensorflowlite_jni.so\r\n2020-05-09 15:50:16.282 8343-8343/? A/DEBUG:     #04 pc 000f9fc7  /data/app/com.pekon.recycling-1/lib/arm/libtensorflowlite_jni.so\r\n2020-05-09 15:50:16.282 8343-8343/? A/DEBUG:     #05 pc 00007be3  /data/app/com.pekon.recycling-1/lib/arm/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+26)\r\n2020-05-09 15:50:16.282 8343-8343/? A/DEBUG:     #06 pc 00a253f3  /data/app/com.pekon.recycling-1/oat/arm/base.odex (offset 0x9d1000)", "comments": ["@SenShan,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39336, "title": "Distributed Training on multiple nodes - process gets stuck after initializing grpc channel", "body": "**System information**\r\n- TF v.2.1\r\n- Linux-based HPC\r\n- Snakemake workflow manager\r\n- Slurm as scheduler\r\n- TensorFlow installed from (source or binary): virtual conda environment\r\n- Python version: 3.7.6\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GeForce GTX 980 computeCapability: 5.2,  coreClock: 1.2405GHz coreCount: 16 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 208.91GiB/s\r\n\r\n\r\n**Describe the current behavior**\r\nHi there,  \r\nMy aim is to train a neural net on multiple nodes and GPUs on a HPC. Therefore, I am using TF's `MultiWorkerMirroredStrategy` and the `SlurmClusterResolver` to get the configuration of my nodes and to set the TF_CONFIG variable.  \r\n  \r\nHowever, when trying to connect to the cluster using:  \r\n```\r\ntf.config.experimental_connect_to_cluster(resolver,\r\n                                            job_name = 'worker',\r\n                                            task_index = cfg['task']['index'],\r\n                                            protocol = 'grpc')\r\n```  \r\nthe process gets stuck (please see the log below).  \r\nWhen I `ssh` into the nodes I see my processes there but they are all sleeping. GPUs aren't used either.  \r\n  \r\nHas anyone experience with this kind of setup and can provide help?  \r\n  \r\nIf I don't use the `experimental_connect_to_cluster` every node is executing the job independently, instead of working together.  \r\nI know that TF_CONFIG should be set before calling the `MultiWorkerMirroredStrategy` but this caused a `RunTimeError`.  \r\nI also played around with the position of GPU initialization in the code - this doesn't seem to have an effect.  \r\n  \r\nNote that I am using the most recent version of the `SlurmClusterResolver`, I basically copied the script from the GitHub and call it using `slurm_cluster_resolver.SlurmClusterResolver`\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.keras.backend.clear_session()\r\n# print all tensor allocations\r\ntf.debugging.set_log_device_placement(True)\r\ntf.random.set_seed(42)\r\n\r\n# instantiate strategy at program startup to prevent RuntimeError\r\nprint(\"-------------------------------------------------------------------------\")\r\n\r\nprint(\"DEFINE DISTRIBUTED TRAINING STRATEGY\")\r\n# only RING communication uses grpc protocols\r\n\r\nmultiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(communication=tf.distribute.experimental.CollectiveCommunication.NCCL)\r\n\r\n\r\nimport os\r\nimport sys\r\nimport json\r\nimport gc\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n\r\n\r\nprint(\"-------------------------------------------------------------------------\")\r\n\r\nprint('CLUSTER CONFIGURATION')\r\n\r\ndef set_tf_config(resolver, environment=None):\r\n    \"\"\"Set the TF_CONFIG env variable from the given cluster resolver\"\"\"\r\n    cfg = {\r\n        'cluster': resolver.cluster_spec().as_dict(),\r\n        'task': {\r\n            'type': resolver.get_task_info()[0],\r\n            'index': resolver.get_task_info()[1],\r\n        },\r\n        'rpc_layer': resolver.rpc_layer,\r\n    }\r\n    if environment:\r\n        cfg['environment'] = environment\r\n    os.environ['TF_CONFIG'] = json.dumps(cfg)\r\n\r\n    return cfg\r\n\r\n\r\n# there must be one GPU for every task\r\nresolver = slurm_cluster_resolver.SlurmClusterResolver(port_base = 11214, gpus_per_task=1, tasks_per_node=2)\r\n\r\nprint(\"-------------------------------------------------------------------------\")\r\n\r\ncfg = set_tf_config(resolver)\r\ntf.print(cfg)\r\nprint(cfg)\r\n\r\n\r\nprint('CONNECT TO CLUSTER')\r\n\r\ntf.config.experimental_connect_to_cluster(resolver,\r\n                                            job_name = 'worker',\r\n                                            task_index = cfg['task']['index'],\r\n                                            protocol = 'grpc')\r\n\r\nprint(\"-------------------------------------------------------------------------\")\r\n\r\n# doesn't matter if at the beginning or not\r\nprint(\"GPU CONFIGURATION\")\r\n# allow memory growth\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\n\r\nprint('INITIALIZE GPUs')\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\n\r\nif gpus:\r\n    tf.config.experimental.set_visible_devices(gpus, 'GPU')\r\n    print(gpus)\r\n\r\nprint(\"-------------------------------------------------------------------------\")\r\n\r\n\r\n\r\n```\r\n**Other info / logs**\r\n```\r\n2020-05-09 08:40:42.220277: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op StringFormat in device /job:localhost/replica:0/task:0/device:CPU:0\r\n2020-05-09 08:40:42.220277: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op StringFormat in device /job:localhost/replica:0/task:0/device:CPU:0\r\n2020-05-09 08:40:42.220607: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op PrintV2 in device /job:localhost/replica:0/task:0/device:CPU:0\r\n2020-05-09 08:40:42.220639: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op PrintV2 in device /job:localhost/replica:0/task:0/device:CPU:0\r\n{'cluster': {'worker': ['dge10:11214',\r\n                'dge10:11215',\r\n                'dge12:11214',\r\n                'dge12:11215',\r\n                'dge13:11214',\r\n                'dge13:11215',\r\n                'dge14:11214',\r\n                'dge14:11215',\r\n                'dge15:11214',\r\n                'dge15:11215',\r\n                'dge9:11214',\r\n                'dge9:11215']},\r\n'rpc_layer': 'grpc',\r\n'task': {'index': 5, 'type': 'worker'}}\r\n{'cluster': {'worker': ['dge10:11214',\r\n                'dge10:11215',\r\n                'dge12:11214',\r\n                'dge12:11215',\r\n                'dge13:11214',\r\n                'dge13:11215',\r\n                'dge14:11214',\r\n                'dge14:11215',\r\n                'dge15:11214',\r\n                'dge15:11215',\r\n                'dge9:11214',\r\n                'dge9:11215']},\r\n'rpc_layer': 'grpc',\r\n'task': {'index': 4, 'type': 'worker'}}\r\n2020-05-09 08:40:42.223059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-05-09 08:40:42.223095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-05-09 08:40:42.223113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]\r\n2020-05-09 08:40:42.223157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]\r\n2020-05-09 08:40:42.226758: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> dge10:11214, 1 -> dge10:11215, 2 -> dge12:11214, 3 -> dge12:11215, 4 -> localhost:11214, 5 -> dge13:11215, 6 -> dge14:11214, 7 -> dge14:11215, 8 -> dge15:11214, 9 -> dge15:11215, 10 -> dge9:11214, 11 -> dge9:11215}\r\n2020-05-09 08:40:42.226828: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> dge10:11214, 1 -> dge10:11215, 2 -> dge12:11214, 3 -> dge12:11215, 4 -> dge13:11214, 5 -> localhost:11215, 6 -> dge14:11214, 7 -> dge14:11215, 8 -> dge15:11214, 9 -> dge15:11215, 10 -> dge9:11214, 11 -> dge9:11215}\r\n```\r\n", "comments": ["@hroetsc \r\nI ran the code shared above but face a different error, please refer to this [gist here](https://colab.sandbox.google.com/gist/Saduf2019/2ec7fc4324cb2118d6aa2c4be1f92e3d/untitled176.ipynb) for the same.", "instead of `slurm_cluster_resolver.SlurmClusterResolver()` you could just run `tf.distribute.cluster_resolver.SlurmClusterResolver()` or take the most recent version from the GitHub, copy it into you directory and name it `slurm_cluster_resolver.py`\r\n", "`experimental_connect_to_cluster ` is not necessary for `MultiWorkerMirroredStrategy`. What are the issues to set TF_CONFIG?", "manually set TF_CONFIG variables were not maintained when i logged out of the node... Since the cluster is very large it is also very inconvenient to set them manually", "`MultiWorkerMirroredStrategy` also accepts `ClusterResolver` as input. You can pass your resolver into it instead of using experimental_connect_to_cluster. Note the `ClusterResolver` passed in must have `task_type` and `task_index` set.", "i ended up getting a `RunTimeError` when calling the `MultiWorkerMirroredStrategy` after the `ClusterResolver`", "Did you do something with your cluster_resolver? Maybe you triggered something that initialized some global state. Note you should never call `experimental_connect_to_cluster` for `MultiWorkerMirroredStrategy`.\r\n\r\nCould you show us the code how you construct your cluster_resolver and how you pass it to `MultiWorkerMirroredStrategy`?", "i solved the problem - using Horovod with Tensorflow instead of Tensorflow's dirstributed training. But thank you for your help!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39336\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39336\">No</a>\n"]}, {"number": 39335, "title": "[Intel MKL] Enable DepthwiseConv2D bfloat16 fusions", "body": "", "comments": ["@CuiYifeng  Can you please check @penpornk's comments and keep us posted. Thanks!", "@gbaned @penpornk Yes, of course. I will let you know when we have a conclusion, thanks!", "@penpornk @gbaned Can we merge this PR first and factor this common macro in another PR later?"]}]