[{"number": 30058, "title": "Correct the size of downsampledFrame", "body": "Both frameWidth and frameHeight should be considered when determining the size of downsampledFrame.\r\nThe previous code only used frameWidth, potentially causing an illegal memory access.", "comments": ["@andrewharp Hi Andrew, could you please spare some time and check if my modification is correct?", "Hi @gbaned @andrewharp,\r\nI submitted this patch because the previous code makes an invalid memory access in my application based on the TensorFlow tracker. I found that the problem was due to wrong size allocation of buffer in this file of TesnsorFlow. The previous code calculates the size of buffer using frameWidth * frameWidth, but it should be frameWidth * frameHeight. After changing according to the submitted patches, all illegal memory access issues were resolved even when I used various video resolutions. Therefore, please check my patch again."]}, {"number": 30057, "title": "tensorflow docker images with python3.6 as default version", "body": "Since many repo using python 3.6 as default version, so recommend using python3.6 as default version for tensorflow docker images.\r\n", "comments": ["On this page: https://hub.docker.com/r/tensorflow/tensorflow/ it states:\r\n\r\n> Images built after May 20 2019 (TF nightly, plus TF versions 1.14 and onward) are based on Ubuntu 18.04. Earlier images are based on Ubuntu 16.04.\r\n\r\nPython 3.6 is the default for Ubuntu 18.04, so while the web page doesn't clearly state it. Starting from TF 1.14 the `-py3` docker containers will have python 3.6 as the default.\r\n\r\n\r\n```\r\n$ docker run --rm tensorflow/tensorflow:1.14.0-py3 python --version\r\nPython 3.6.8\r\n```\r\n\r\nFYI @angersson - if you want to consider updating the doc for that. [The section that says python 3.5 is now wrong.]\r\n\r\n", "Thanks @wdirons! I've updated the page to be more clear.\r\n\r\n@zh794390558, @wdirons is correct -- recently built `py3` images (1.14+ and `nightly` images) include Python 3.6 thanks to Ubuntu 18."]}, {"number": 30056, "title": "multi-gpu training: tf.compat.v1.scatter_sub() operation throws exception", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n    - Extended from the stock example\r\n    - https://www.tensorflow.org/beta/tutorials/distribute/keras\r\n    - Working example is attached to this bug report\r\n- OS Platform and Distribution\r\n    - Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n    - No\r\n- TensorFlow installed from (source or binary):\r\n    - Binary\r\n- TensorFlow version (use command below):\r\n    - 2.0.0-beta1\r\n- Python version:\r\n    - Python 3.5.2\r\n- Bazel version (if compiling from source):\r\n    - N/A (0.23.2)\r\n- GCC/Compiler version (if compiling from source):\r\n    - N/A (5.4.0 20160609)\r\n- CUDA/cuDNN version:\r\n    - 10.0.130/7.4.1\r\n- GPU model and memory:\r\n    - 4x Titan Xp (12Gb) (Standalong, no SLI connections)\r\n\r\n**Describe the current behavior**\r\n```\r\ntf.compat.v1.scatter_sub does not support multi-gpu training.\r\n\r\n    AttributeError: 'Tensor' object has no attribute '_lazy_read'\r\n\r\n    is thrown in the tf.compat.v1.scatter_sub() operation.\r\n\r\nThere is no equivalent scatter_* operations in tf.compat.v2 module.\r\n```\r\n\r\n**Describe the expected behavior**\r\ntf.compat.v1.scatter_sub or equivalent scatter_* operations should support multi-gpu training.\r\n\r\n\r\n**Code to reproduce the issue**\r\n1. The script attached is used to train a model using multiple GPUs.\r\n  * The code is modified from the stock example for quick experiment.\r\n    * https://www.tensorflow.org/beta/tutorials/distribute/keras\r\n\r\n**Other info / logs**\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0622 23:56:34.418763 140543953778432 cross_device_ops.py:1164] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:1,/job:localhost/replica:0/task:0/device:GPU:0\r\nNumber of devices: 2\r\nTraceback (most recent call last):\r\n  File \"center_loss_mnist.py\", line 326, in <module>\r\n    run(0.0001)\r\n  File \"center_loss_mnist.py\", line 259, in run\r\n    final_output, side_output = my_model(main_input, aux_input)\r\n  File \"center_loss_mnist.py\", line 119, in my_model\r\n    side = CenterLossLayer(alpha=0.5, name='centerlosslayer')([x, labels])\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 662, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 169, in wrapper\r\n    raise e.ag_error_metadata.to_exception(type(e))\r\nAttributeError: in converted code:\r\n\r\n    center_loss_mnist.py:179 call  *\r\n        new_centers = tf.compat.v1.scatter_sub(self.centers, x[1], delta_centers)\r\n    /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py:535 scatter_sub\r\n        return ref._lazy_read(gen_resource_variable_ops.resource_scatter_sub(  # pylint: disable=protected-access\r\n    /usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/values.py:381 __getattr__\r\n        return getattr(self.get(), name)\r\n\r\n    AttributeError: 'Tensor' object has no attribute '_lazy_read'\r\n```\r\n\r\n** Run the script using the following command\r\n```\r\nexport CUDA_VISIBLE_DEVICES=\"0\"\r\npython3 center_loss_mnist.py\r\n```\r\n\r\n** Save the following script as \"center_loss_mnist.py\"\r\n\r\n```python\r\n\r\nfrom datetime import datetime\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras import initializers\r\nfrom tensorflow.keras import losses\r\nfrom tensorflow.keras import optimizers\r\nfrom tensorflow.keras.callbacks import TensorBoard\r\nfrom tensorflow.keras.datasets import mnist\r\nfrom tensorflow.keras.layers import Activation\r\nfrom tensorflow.keras.layers import BatchNormalization\r\nfrom tensorflow.keras.layers import Conv2D\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.layers import Dropout\r\nfrom tensorflow.keras.layers import Flatten\r\nfrom tensorflow.keras.layers import Input\r\nfrom tensorflow.keras.layers import Layer\r\nfrom tensorflow.keras.layers import MaxPool2D\r\nfrom tensorflow.keras.layers import PReLU\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.regularizers import l2\r\nimport math\r\nimport numpy as np\r\nimport os\r\nimport shutil\r\nimport tensorflow as tf\r\n\r\n### parameters\r\nbatch_size = 64\r\nepochs = 10\r\nweight_decay = 0.0005\r\n\r\ndef init_gpus(soft_device_placement=True, log_device_placement=False, create_virtual_devices=False, memory_limit=4096):\r\n\r\n    tf.config.set_soft_device_placement(soft_device_placement)    \r\n    tf.debugging.set_log_device_placement(log_device_placement)\r\n\r\n    gpus = tf.config.experimental.list_physical_devices('GPU')\r\n    if gpus:\r\n        # If there is only one GPU, create two logical virtual devices for developing\r\n        # on a machine with only one GPU installed\r\n        try:\r\n            # Create 2 virtual GPUs on each physical GPU with the given memory_limit GPU memory\r\n            if create_virtual_devices and len(gpus) == 1:\r\n                tf.config.experimental.set_virtual_device_configuration(\r\n                    gpus[0],\r\n                    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096),\r\n                     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]\r\n                )\r\n\r\n            else:\r\n                # Currently, memory growth needs to be the same across GPUs\r\n                for gpu in gpus:\r\n                    tf.config.experimental.set_memory_growth(gpu, True)\r\n\r\n        except RuntimeError as e:\r\n            # Memory growth must be set before GPUs have been initialized\r\n            print(e)\r\n\r\n        # print out physical and logical GPUs\r\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n\r\n    else:\r\n        print(\"No visible GPU is detected...\")\r\n\r\ndef prelu(x, name='default'):\r\n    if name == 'default':\r\n        return PReLU(alpha_initializer=initializers.Constant(value=0.25))(x)\r\n    else:\r\n        return PReLU(alpha_initializer=initializers.Constant(value=0.25), name=name)(x)\r\n\r\ndef center_loss(y_true, y_pred):\r\n    \"\"\"Center loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\"\r\n       (http://ydwen.github.io/papers/WenECCV16.pdf)\r\n       Lc = 1/2 sum(|| xi - ci||)\r\n    \"\"\"\r\n    return 0.5 * K.sum(y_pred, axis=0)\r\n\r\n### model\r\ndef my_model(x, labels):\r\n    # x = BatchNormalization()(x)\r\n    #\r\n    x = Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)\r\n    x = BatchNormalization()(x)\r\n    x = prelu(x)\r\n\r\n    x = Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)\r\n    x = BatchNormalization()(x)\r\n    x = prelu(x)\r\n\r\n    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\r\n    #\r\n    x = Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)\r\n    x = BatchNormalization()(x)\r\n    x = prelu(x)\r\n\r\n    x = Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)\r\n    x = BatchNormalization()(x)\r\n    x = prelu(x)\r\n\r\n    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\r\n    #\r\n    x = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)\r\n    x = BatchNormalization()(x)\r\n    x = prelu(x)\r\n\r\n    x = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)\r\n    x = BatchNormalization()(x)\r\n    x = prelu(x)\r\n\r\n    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\r\n    x = Dropout(0.25)(x)\r\n    #\r\n    x = Flatten()(x)\r\n    x = Dense(2, kernel_regularizer=l2(weight_decay))(x)\r\n    x = prelu(x, name='side_out')\r\n    #\r\n    main = Dense(10, activation='softmax', name='main_out', kernel_regularizer=l2(weight_decay))(x)\r\n    side = CenterLossLayer(alpha=0.5, name='centerlosslayer')([x, labels])\r\n    return main, side\r\n\r\n# Function for decaying the learning rate.\r\n# You can define any decay function you need.\r\ndef lr_schedule(epoch):\r\n    if epoch <= 5:\r\n        learning_rate = 1e-3\r\n\r\n    elif epoch <= 10:\r\n        learning_rate = 1e-4\r\n\r\n    else:\r\n        learning_rate = 1e-5\r\n\r\n    tf.summary.scalar('learning_rate', data=learning_rate, step=epoch)\r\n    return learning_rate\r\n\r\nclass CenterLossLayer(Layer):\r\n\r\n    def __init__(self, alpha=0.5, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.alpha = alpha\r\n\r\n    def build(self, input_shape):\r\n        self.centers = self.add_weight(\r\n            name='centers',\r\n            shape=(10, 2),\r\n            initializer='uniform',\r\n            trainable=False\r\n        )\r\n\r\n        super().build(input_shape)\r\n\r\n    def call(self, x):\r\n        \"\"\"This is where the layer's logic lives.\r\n        Arguments:\r\n            inputs: Input tensor, or list/tuple of input tensors.\r\n            **kwargs: Additional keyword arguments.\r\n        Returns:\r\n            A tensor or list/tuple of tensors.\r\n        \"\"\"\r\n        features = x[0]\r\n        labels = K.reshape(x[1], [-1])\r\n\r\n        # get the tensor as specified in the label\r\n        # the centers might repeate depending on the label index\r\n        centers_batch = K.gather(self.centers, labels)\r\n\r\n        unique_label, unique_idx, unique_count = tf.unique_with_counts(labels)\r\n        appear_times = K.gather(unique_count, unique_idx)\r\n        appear_times = K.reshape(appear_times, [-1, 1])\r\n        #\r\n        # center_loss_alfa default 0.5\r\n        delta_centers = centers_batch - features\r\n        delta_centers = delta_centers / tf.cast((1 + appear_times), tf.float32)\r\n        delta_centers = self.alpha * delta_centers\r\n\r\n        # scatter_sub does not support multi-gpu training, there is no equivalent operation \r\n        new_centers = tf.compat.v1.scatter_sub(self.centers, x[1], delta_centers)\r\n\r\n        self.add_update((self.centers, new_centers), x)\r\n        self.result = K.sum(K.square(features - centers_batch), axis=1, keepdims=True)\r\n        return self.result\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return K.int_shape(self.result)\r\n\r\ndef empty_dir(folder):\r\n    \"\"\"\r\n    Empty a folder recursively.\r\n    \"\"\"\r\n    for file in os.listdir(folder):\r\n        file_path = os.path.join(folder, file)\r\n        if os.path.isfile(file_path):\r\n            print(\"Remove file: {}\".format(file_path))\r\n            os.remove(file_path)\r\n        else:\r\n            empty_dir(file_path)\r\n            print(\"Remove folder: {}\".format(file_path))\r\n            os.rmdir(file_path)\r\n\r\ndef build_empty_dir(folder, root_dir=os.getcwd()):\r\n    base_dir = os.path.join(root_dir, folder)\r\n    os.makedirs(base_dir, exist_ok=True)\r\n    empty_dir(os.path.join(root_dir, folder))\r\n\r\n    return base_dir\r\n\r\n\"\"\"\r\nunset CUDA_VISIBLE_DEVICES\r\n\r\nexport CUDA_VISIBLE_DEVICES=\"0\"\r\npython3 center_loss_mnist.py\r\n\"\"\"\r\n\r\n### run model\r\ndef run(lambda_centerloss):\r\n\r\n    init_gpus(\r\n        log_device_placement=False,\r\n        create_virtual_devices=True\r\n    )\r\n    \r\n    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())\r\n    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\r\n    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce())\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\r\n\r\n    ### get data\r\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n    # normalize to 0..1\r\n    x_train, x_test = x_train/255, x_test/255\r\n    x_train = np.float32(x_train);\r\n    x_test  = np.float32(x_test)\r\n\r\n    y_train = np.int32(y_train)\r\n    y_test = np.int32(y_test)\r\n\r\n    # reshape to matrix\r\n    x_train = x_train.reshape((-1, 28, 28, 1))\r\n    x_test = x_test.reshape((-1, 28, 28, 1))\r\n\r\n    ### compile\r\n    main_input = Input((28, 28, 1))\r\n    aux_input = Input((), dtype='int32')\r\n\r\n    # Training using Multi-GPUs\r\n    # \r\n    # tf.compat.v1.scatter_sub does not support multi-gpus training\r\n    # with strategy.scope():\r\n    #\r\n    # The following exception with be thrown.\r\n    #\r\n    # AttributeError: 'Tensor' object has no attribute '_lazy_read'\r\n\r\n    # comment out the following line for the training to run successfully\r\n    with strategy.scope():\r\n        final_output, side_output = my_model(main_input, aux_input)\r\n        model = Model(inputs=[main_input, aux_input], outputs=[final_output, side_output])\r\n        model.compile(\r\n            optimizer='adam',\r\n            loss=[losses.sparse_categorical_crossentropy, center_loss],\r\n            metrics=['accuracy'],\r\n            loss_weights=[1, lambda_centerloss]\r\n        )\r\n        model.summary()\r\n\r\n    ### create the log directory\r\n    log_dir = '/tmp/logs/' + datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')\r\n    build_empty_dir(log_dir)\r\n\r\n    # Initialize the file_writer for logging summary\r\n    # create the file_writer to save events for Tensorboard\r\n    summary_log_dir = log_dir + '/train'\r\n    file_writer = tf.summary.create_file_writer(summary_log_dir)\r\n    file_writer.set_as_default()    \r\n\r\n    tb_callback = TensorBoard(log_dir=log_dir)\r\n\r\n    # https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LearningRateScheduler\r\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\r\n\r\n    ### fit\r\n    dummy1 = np.zeros((x_train.shape[0], 1), dtype=int)\r\n    dummy2 = np.zeros((x_test.shape [0], 1), dtype=int)\r\n\r\n    #\r\n    print('model.input[0].shape = ', model.input[0].shape)\r\n    print('model.get_layer(\\'side_out\\').output.shape = ', model.get_layer('side_out').output.shape)\r\n    #\r\n    model.fit(\r\n        [x_train, y_train],     # inputs =[main_input, aux_input]\r\n        [y_train, dummy1 ],     # outputs=[final_output, side_output]\r\n        batch_size=batch_size,\r\n        epochs=epochs,\r\n        verbose=1,\r\n        validation_data=([x_test, y_test], [y_test, dummy2]),\r\n        callbacks=[tb_callback, lr_callback]\r\n    )\r\n    # validation\r\n    reduced_model = Model(inputs=model.input[0], outputs=model.get_layer('main_out').output)\r\n    reduced_model.compile(\r\n        loss='sparse_categorical_crossentropy',\r\n        optimizer=tf.keras.optimizers.Adam(),\r\n        metrics=['accuracy']\r\n    )\r\n    # evaluate\r\n    eval_loss, eval_acc = reduced_model.evaluate(\r\n        x=x_test,\r\n        y=y_test,\r\n        batch_size=batch_size\r\n    )\r\n    print('\\nEval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\r\n    ### run training and val sets\r\n    reduced_model = Model(inputs=model.input[0], outputs=model.get_layer('side_out').output)\r\n\r\n    feats = reduced_model.predict(x_train)\r\n\r\n    ### done\r\n    K.clear_session()\r\n    return\r\n\r\n###\r\nif __name__ == '__main__':\r\n    run(0.0001)\r\n\r\n```", "comments": ["The script will run successfully without using the \"with stragety.scopt():\" with the following changes:\r\n\r\nChange from:\r\n```\r\n    with strategy.scope():\r\n        final_output, side_output = my_model(main_input, aux_input)\r\n        model = Model(inputs=[main_input, aux_input], outputs=[final_output, side_output])\r\n        model.compile(\r\n            optimizer='adam',\r\n            loss=[losses.sparse_categorical_crossentropy, center_loss],\r\n            metrics=['accuracy'],\r\n            loss_weights=[1, lambda_centerloss]\r\n        )\r\n        model.summary()\r\n```\r\nTo: \r\n```\r\n    # with strategy.scope():\r\n    final_output, side_output = my_model(main_input, aux_input)\r\n    model = Model(inputs=[main_input, aux_input], outputs=[final_output, side_output])\r\n    model.compile(\r\n        optimizer='adam',\r\n        loss=[losses.sparse_categorical_crossentropy, center_loss],\r\n        metrics=['accuracy'],\r\n        loss_weights=[1, lambda_centerloss]\r\n    )\r\n    model.summary()\r\n```", "I have reproduced the issue in Colab using TF-GPU 2.0.0-beta1.Thanks!", "FYI The same issue is present in tensorflow 1.14 as well. It comes from the usage of scatter_sub in multi-gpu MirroredStrategy.\r\n\r\nWhile you guys fix the issue is there a workaround for this that we can use ?\r\n\r\nThanks", "Is there a chance to resolve this in final release of 1.15 ? ", "This issue is still there, and will not be fixed in 1.15 since that has already been cut. One person had started working on it, but the fix got delayed due to some other issues.\r\nYou can try 2 workarounds:\r\n- if the tensors you're trying to subtract are not too big, you can try to convert them to dense and just subtract regularly using assign_sub etc. This may have some performance implications\r\n- You can implement this yourself using merge_call/reduce/update, something like this (this is exactly how we are going to implement this within mirrored variable as well)\r\n\r\n```\r\ndef dist_scatter_sub(v, *args, **kwargs):\r\n  def merge_fn(strategy, value, *other_args, **other_kwargs):\r\n          agg_val = strategy.extended.reduce_to(distribute.ReduceOp.SUM, value, v)\r\n          fn = lambda var, *a, **kw: var.scatter_sub(*a, **kw)\r\n          return strategy.extended.update(\r\n              v, f, args=(agg_val,) + other_args, kwargs=other_kwargs)\r\n\r\n  return tf.distribute.get_replica_context().merge_call(merge_fn, args=args, kwargs=kwargs)\r\n\r\ndist_scatter_sub(v, delta)\r\n```\r\n\r\n\r\n\r\n\r\n\r\n", "This issue should have been fixed in tf 2.2. You can just call the \"scatter_*\" method on the variable. tf.compat.v1.scatter_sub wouldn't work though.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30056\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30056\">No</a>\n"]}, {"number": 30055, "title": "Fix warning in sparse.from_dense caused by where", "body": "While running tf.sparse.from_dense the following warning surface:\r\n```\r\n$ python\r\nPython 2.7.15+ (default, Nov 27 2018, 23:36:35)\r\n[GCC 7.3.0] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import numpy as np\r\n>>> import tensorflow as tf\r\n>>> tf.sparse.from_dense(np.array([[.1, .3, .5, .9]]))\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0623 02:24:12.467936 140242193565504 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/sparse_ops.py:108: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\n<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f8ca17ade90>\r\n```\r\n\r\nThis fix fixes the warning.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 30054, "title": "Correct doc of LSTMBlockFusedCell", "body": "The second return value of `LSTMBlockFusedCell`'s `_call_cell` function is a `LSTMStateTuple` that represents the final hidden state and final output, not a 3D tensor.", "comments": ["Hey @sijunhe, thanks for the PR! \r\n\r\n@ebrevdo do you know if that's the intended behavior? I expected the return value to be 3D for both outputs and states.", "Can one of the admins verify this patch?", "closing this PR as contrib folder will be depricated in 2.0, thank you.\r\nCC @mihaimaruseac"]}, {"number": 30053, "title": "Fix dimension check for tf.keras.losses.BinaryCrossentropy", "body": "This fix tries to address the issue raised in #30040 where tf.keras.losses.BinaryCrossentropy does not check the dimension match:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ny_true = np.array([[1.], [1.], [1.], [0.], [1.], [0.], [0.], [1.], [1.], [0.]]).astype(np.float32)\r\ny_pred = np.array([[0.], [0.], [0.], [1.], [1.], [0.], [0.], [1.], [0.], [1.]]).astype(np.float32)\r\nbce = tf.keras.losses.BinaryCrossentropy()\r\nprint(bce(np.squeeze(y_true), y_pred).numpy()) # should fail\r\n```\r\nThe reason was that broadcasting was applied directly.\r\nThis fix adds dimension check to throw an error if there is a mismatch.\r\n\r\nThis fix fixes #30040.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@pavithrasv The PR has been updated with comments addressed. Please take a look and let me know if there are other issues.", "Merging of the PR failed because https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/distribute/distribute_strategy_test.py fails. Stacktrace of the failure:\r\n\r\n```\r\nERROR: test_fit_with_dictionary_in_the_dataset_b135161171_test_cloning_True_distribution_OneDeviceGPU_mode_graph (__main__.TestDistributionStrategyWithDatasets)\r\ntest_fit_with_dictionary_in_the_dataset_b135161171_test_cloning_True_distribution_OneDeviceGPU_mode_graph (__main__.TestDistributionStrategyWithDatasets)\r\ntest_fit_with_dictionary_in_the_dataset_b135161171_test_cloning_True_distribution_OneDeviceGPU_mode_graph(cloning=True, distribution=OneDeviceGPU, mode='graph')\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/absl_py/absl/testing/parameterized.py\", line 262, in bound_param_test\r\n    test_method(self, **testcase_params)\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/distribute/test_combinations.py\", line 314, in decorated\r\n    execute_test_method()\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/distribute/test_combinations.py\", line 297, in execute_test_method\r\n    test_method(**kwargs_to_pass)\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/keras/distribute/distribute_strategy_test.py\", line 854, in test_fit_with_dictionary_in_the_dataset_b135161171\r\n    my_loss = loss_lambda([predict, input_lbl, input_weight])\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/keras/engine/base_layer.py\", line 716, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/keras/layers/core.py\", line 789, in call\r\n    return self.function(inputs, **arguments)\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/keras/distribute/distribute_strategy_test.py\", line 853, in <lambda>\r\n    lambda x: custom_loss(*x), name='my_loss')\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/keras/distribute/distribute_strategy_test.py\", line 843, in custom_loss\r\n    bce = keras.losses.binary_crossentropy(label, predict)\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/keras/losses.py\", line 985, in binary_crossentropy\r\n    K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/keras/backend.py\", line 4332, in binary_crossentropy\r\n    target.get_shape().assert_is_compatible_with(output.get_shape())\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/distribute_strategy_test_gpu.runfiles/org_tensorflow/tensorflow/python/framework/tensor_shape.py\", line 1120, in assert_is_compatible_with\r\n    raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\nValueError: Shapes (None, 64, 64, 1) and (None, 64, 64, 2) are incompatible\r\n\r\n```", "Thanks @pavithrasv for the review. The PR has been updated with failing test fixed.", "This PR was reverted because of more test failures in tensorflow-estimator repository."]}, {"number": 30052, "title": "ValueError: Arguments and signature arguments do not match -- when using dataset api, keras functional api and checkpoints callback (tf2.0)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): GIT_VERSION='v1.12.1-4759-g9856697d8b' TF_VERSION='2.0.0-dev20190622'\r\n- Python version: 3.6.4\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nCalling the ```fit``` function on a Keras model, when specifying a Dataset and a ```ModelCheckpoint``` callback, will crash after the first epoch with this error:\r\n```ValueError: Arguments and signature arguments do not match```.\r\nThe error happens only when specifying both the training Dataset and validation Dataset.\r\nThe error happens because of the checkpoint callback.\r\n\r\n**Describe the expected behavior**\r\nThe model should not crash, continue training and successfully save the checkpoints.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\n\r\nimport tensorflow as tf\r\n\r\n# model architecture\r\ninputs = tf.keras.Input(shape=(784,), name='flattened_image')\r\nx = tf.keras.layers.Dense(64, activation='relu')(inputs)\r\nx = tf.keras.layers.Dense(64, activation='relu')(x)\r\noutputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs, name='error_showcase')\r\n\r\n# loading mnist data\r\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\nx_train = x_train.reshape(60000, 784).astype('float32') / 255\r\nx_test = x_test.reshape(10000, 784).astype('float32') / 255\r\n\r\n# create the training dataset\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n# shuffle, batch and prefetch\r\ntrain_dataset = train_dataset.shuffle(buffer_size=1024).batch(64).prefetch(1024)\r\n# create the validation dataset.\r\nval_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\r\n# shuffle, batch and prefetch\r\nval_dataset = val_dataset.batch(64).prefetch(1024)\r\n\r\n# compile the model\r\nmodel.compile(\r\n    loss='sparse_categorical_crossentropy',\r\n    optimizer='rmsprop',\r\n    metrics=['accuracy']\r\n)\r\n\r\n# defining checkpoint callback\r\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n    './checkpoints/',\r\n    monitor='val_accuracy',\r\n    verbose=1,\r\n    save_best_only=True,\r\n    mode='max'\r\n)\r\n\r\n# fit the model\r\nhistory = model.fit(\r\n    train_dataset,\r\n    validation_data=val_dataset,\r\n    epochs=5,\r\n    callbacks=[checkpoint_callback],\r\n)\r\n\r\nprint('\\nhistory dict:', history.history)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n2019-06-22 18:30:17.760500: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-06-22 18:30:17.777440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d2bb0de30 executing computations on platform Host. Devices:\r\n2019-06-22 18:30:17.777463: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\nEpoch 1/5\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0622 18:30:18.333158 140736272085888 deprecation.py:323] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW0622 18:30:18.374418 140736272085888 deprecation.py:323] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:460: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nApply a constraint manually following the optimizer update step.\r\n2019-06-22 18:30:18.583083: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n911/938 [============================>.] - ETA: 0s - loss: 0.3021 - accuracy: 0.9133  \r\nEpoch 00001: val_accuracy improved from -inf to 0.94660, saving model to ./checkpoints/\r\n2019-06-22 18:30:20.643797: W tensorflow/python/util/util.cc:268] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nW0622 18:30:20.653870 140736272085888 deprecation.py:506] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1775: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n938/938 [==============================] - 2s 3ms/step - loss: 0.2972 - accuracy: 0.9147 - val_loss: 0.1739 - val_accuracy: 0.9466\r\nEpoch 2/5\r\nTraceback (most recent call last):\r\n  File \"error_showcase_ckpt.py\", line 46, in <module>\r\n    callbacks=[checkpoint_callback],\r\n  File \"/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 669, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 695, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 265, in model_iteration\r\n    batch_outs = batch_function(*batch_data)\r\n  File \"/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 939, in train_on_batch\r\n    outputs = self.train_function(ins)  # pylint: disable=not-callable\r\n  File \"/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 3483, in __call__\r\n    outputs = self._graph_fn(*converted_inputs)\r\n  File \"/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 583, in __call__\r\n    return self._call_flat(args, self.captured_inputs)\r\n  File \"/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 685, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 436, in call\r\n    (len(args), len(list(self.signature.input_arg))))\r\nValueError: Arguments and signature arguments do not match: 19 20 \r\n```\r\n", "comments": ["I get the same issue.", "I tried on colab with Tensorflow 2.0.0-dev20190623. I am able to reproduce the issue. Thanks!", "get the same issue, without specifying a ModelCheckpoint callback\r\n\r\n`\r\nTraceback (most recent call last):\r\n  File \"/home/deeplearning/.vscode/extensions/ms-python.python-2019.6.22090/pythonFiles/ptvsd_launcher.py\", line 43, in <module>\r\n    main(ptvsdArgs)\r\n  File \"/home/deeplearning/.vscode/extensions/ms-python.python-2019.6.22090/pythonFiles/lib/python/ptvsd/__main__.py\", line 434, in main\r\n    run()\r\n  File \"/home/deeplearning/.vscode/extensions/ms-python.python-2019.6.22090/pythonFiles/lib/python/ptvsd/__main__.py\", line 312, in run_file\r\n    runpy.run_path(target, run_name='__main__')\r\n  File \"/usr/local/lib/python3.6/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"/usr/local/lib/python3.6/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/deeplearning/work/Deeplearning/TensorFlow/DeepWritingID/DeepHWS_online_2/run.py\", line 62, in <module>\r\n    sys.exit(main())\r\n  File \"/home/deeplearning/work/Deeplearning/TensorFlow/DeepWritingID/DeepHWS_online_2/run.py\", line 56, in main\r\n    train_model.fit(next(it), batch_size=params.batch_size, epochs=3)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 643, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 664, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 383, in model_iteration\r\n    batch_outs = f(ins_batch)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3510, in __call__\r\n    outputs = self._graph_fn(*converted_inputs)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 572, in __call__\r\n    return self._call_flat(args)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 671, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 427, in call\r\n    (len(args), len(list(self.signature.input_arg))))\r\nValueError: Arguments and signature arguments do not match: 97 98 \r\n`", "I get the same issue when I use the \"callback\" parameter:\r\n```python\r\ncheckpointer = keras.callbacks.ModelCheckpoint(\"./models/\")\r\nmodel.fit(train_ds, steps_per_epoch=train_steps_per_epoch, epochs=EPOCH, validation_steps=val_steps_per_epoch,\r\n              validation_data=val_ds, callbacks=[checkpointer])\r\nresult = model.evaluate(val_ds)\r\n```\r\n\r\nGet error when start training 2 epoch.\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/aaron/Workspace/tf2.0_sample/main.py\", line 35, in <module>\r\n    validation_data=val_ds, callbacks=[checkpointer])\r\n  File \"/home/aaron/Soft/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 643, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/aaron/Soft/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 694, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/home/aaron/Soft/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 264, in model_iteration\r\n    batch_outs = batch_function(*batch_data)\r\n  File \"/home/aaron/Soft/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 918, in train_on_batch\r\n    outputs = self.train_function(ins)  # pylint: disable=not-callable\r\n  File \"/home/aaron/Soft/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\", line 3510, in __call__\r\n    outputs = self._graph_fn(*converted_inputs)\r\n  File \"/home/aaron/Soft/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 572, in __call__\r\n    return self._call_flat(args)\r\n  File \"/home/aaron/Soft/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 671, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"/home/aaron/Soft/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 427, in call\r\n    (len(args), len(list(self.signature.input_arg))))\r\nValueError: Arguments and signature arguments do not match: 40 41\r\n```", "Hi @mahzoon, I got the same error as yours. But it only happens when I set `save_weights_only=False` in the checkpoint callback. If and only if I set `save_weights_only=True`, it will work as usual.\r\n\r\nAlso, I'm confused by this warning \"W tensorflow/python/util/util.cc:280] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\" It didn't show up after I set `save_weights_only=True`. ", "@rchao -- can you take a look? There seems to be some delta in the inputs as created and as we try to do them.\r\n\r\n(Can we improve the error message while fixing this? We should be able to print out what the mismatch is in that error message.)", "@mahzoon thanks for reporting the issue - we were able to repro and found that the mismatched argument is keras_learning_phase. We're actively working on training loop refactoring which will resolve the issue. Will post back here once we get more updates. ", "In jupyter notebook I noticed that if I don't have any metric, it works after the first fail. Just fyi, in case it helps", "> Hi @mahzoon, I got the same error as yours. But it only happens when I set `save_weights_only=False` in the checkpoint callback. If and only if I set `save_weights_only=True`, it will work as usual.\r\n> \r\n> Also, I'm confused by this warning \"W tensorflow/python/util/util.cc:280] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\" It didn't show up after I set `save_weights_only=True`.\r\n\r\nI got the same issue like @zihaozhihao , setting 'save_weights_only=False' would cause the problem.", "same issue here, running on rc0", "I also hit this issue in my personal project :) ", "TF_VERSION='v2.0.0-rc2-26-g64c3d38'\r\nPython version: 3.5.3\r\nI am not sure if it is the same bug, but it states:\r\nValueError: Arguments and signature arguments do not match: 1229 1230 \r\nIt occurs on model.fit_generator at the beginning  of the training. But if I use fit_generator with class_weights argument, the error would prompt on the end of the epoch and seems to be related to validation dataset evaluation:\r\nValueError: You must feed a value for placeholder Tensor(\"block1c_bn/block1c_bn_trainable:0\", dtype=bool)\r\n If using without validation_data argument the model works fine. Setting 'save_weights_only=True' doesn't help.\r\n\r\nThe workaround is to train 1 epoch without validation data, save the model, load afterwards. After this manipulation train can be done as usual.\r\n", "I am currently dealing with the same problem here when using keras backend during the learning phase. I wondered if any solution has been found yet? :)", "This is fixed with latest `tf-nightly` build '2.1.0-dev20200109'\r\nSee [gist](https://colab.sandbox.google.com/gist/ymodak/2e7ca2c039dd0c97a683d4132bb3465a/github_30052ipynb.ipynb)\r\nFeel free to reopen if still have problems. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30052\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30052\">No</a>\n", "tried tf-nightly build '2.1.0-dev20200109' and the lastest TensorFlow-GPU also\r\nKeras 2.3.1\r\n\r\nproblem not resolved when doing predict or predict_on_batch from model loaded from a file.\r\n> ValueError: Arguments and signature arguments do not match. got: 92, expected: 93 \r\n\r\ncan someone confirm this? or my problem could be unrelated.", "> tried tf-nightly build '2.1.0-dev20200109' and the lastest TensorFlow-GPU also\r\n> Keras 2.3.1\r\n> \r\n> problem not resolved when doing predict or predict_on_batch from model loaded from a file.\r\n> \r\n> > ValueError: Arguments and signature arguments do not match. got: 92, expected: 93\r\n> \r\n> can someone confirm this? or my problem could be unrelated.\r\n\r\nI got similar issue, I was using \r\n`K.function(input, output, updates)`", " I'm having same issue with `tensorflow-gpu: '2.1.0'.` and `python: 3.6.9 ` Any updates ?\r\n`ValueError: Arguments and signature arguments do not match. got: 37, expected: 39`", "> I'm having same issue with `tensorflow-gpu: '2.1.0'.` and `python: 3.6.9 ` Any updates ?\r\n> `ValueError: Arguments and signature arguments do not match. got: 37, expected: 39`\r\n\r\nThe problem solved after replacing import keras by import tensorflow.keras and making the necessary modifications"]}, {"number": 30051, "title": "Convert input to tensor in `tf.math.angle`", "body": "This is a fix following https://github.com/tensorflow/tensorflow/pull/30049#issuecomment-504692831\r\n\r\nSee also #30049 and #30029", "comments": []}, {"number": 30050, "title": "Composing layers using functools in TF 2.0 gives error", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **YES**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **CentOS 7**\r\n- TensorFlow installed from (source or binary): **SOURCE**\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: 10.0/7.4\r\n- GPU model and memory: Nvidia V100 (32 GB)\r\n\r\n\r\n**Describe the current behavior**\r\nDuring eager execution, python lists are wrapped by TF 2.0 as `<class 'tensorflow.python.training.tracking.data_structures.ListWrapper'>`\r\nI see a weird issue with this data structure when using function composition to build a custom keras layer. The code for the layer is as follows. When called, it gives the error as ` TypeError: reduce() arg 2 must support iteration`. I have checked that the second argument to `reduce()` is indeed a generic iterable with an `__iter__` method. \r\n\r\nIs using function compositions using `functools` package an issue in TF2.0 ?\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nimport functools\r\nfrom collections.abc import Iterable\r\n\r\n\r\n# TODO Check for correctness of the model implementation\r\nclass Unit3D(tf.keras.layers.Layer):\r\n    def __init__(self, output_channels,\r\n                 kernel_shape=(1, 1, 1),\r\n                 stride=(1, 1, 1),\r\n                 activation_fn='relu',\r\n                 use_batch_norm=True,\r\n                 use_bias=False,\r\n                 is_training=False,\r\n                 name='unit_3d'):\r\n        super(Unit3D, self).__init__(name=name)\r\n        self._output_channels = output_channels\r\n        self._kernel_shape = kernel_shape\r\n        self._stride = stride\r\n        self._activation = activation_fn\r\n        self._use_batch_norm = use_batch_norm\r\n        self._use_bias = use_bias\r\n        self._is_training = is_training\r\n        self._pipeline = []\r\n        self._pipeline.append(tf.keras.layers.Conv3D(\r\n            filters=self._output_channels,\r\n            kernel_size=self._kernel_shape,\r\n            strides=self._stride,\r\n            padding='same',\r\n            use_bias=self._use_bias,\r\n            data_format='channels_first'\r\n        )\r\n        )\r\n        if self._use_batch_norm:\r\n            bn = tf.keras.layers.BatchNormalization(\r\n                axis=1,\r\n                fused=False,\r\n            )\r\n            bn = functools.partial(bn, training=self._is_training)\r\n            self._pipeline.append(bn)\r\n\r\n        if self._activation is not None:\r\n            self._pipeline.append(tf.keras.layers.Activation(\r\n                activation=self._activation\r\n            )\r\n            )\r\n\r\n        print(isinstance(self._pipeline, Iterable))\r\n        print(type(self._pipeline))\r\n        self._pipeline = lambda x: functools.reduce(lambda f, g: g(f), self._pipeline, x)\r\n\r\n    def call(self, input):\r\n        return self._pipeline(input)\r\n```\r\n\r\n**Describe the expected behavior** \r\nFunction composition should be working properly.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport tensorflow as tf\r\nfrom nets.i3d import Unit3D\r\n\r\nmodel = Unit3D(output_channels=64, kernel_shape=[7,7,7],\r\n               is_training=True)\r\n\r\ninput = tf.keras.backend.random_uniform(shape=(1,3,64,224,224),\r\n                                        dtype=tf.float32)\r\noutput = model(input)\r\n\r\n```\r\n**Other info / logs**\r\n```\r\n2019-06-22 22:09:52.578799: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n<class 'tensorflow.python.training.tracking.data_structures._ListWrapper'>\r\nTraceback (most recent call last):\r\n  File \"/Users/meetukme/PycharmProjects/KineticsNet/main.py\", line 7, in <module>\r\n    out = net(input)\r\n  File \"/Users/meetukme/anaconda3/envs/slim2.0/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 660, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/Users/meetukme/PycharmProjects/KineticsNet/nets/i3d.py\", line 52, in call\r\n    return self._pipeline(input)\r\n  File \"/Users/meetukme/PycharmProjects/KineticsNet/nets/i3d.py\", line 47, in <lambda>\r\n    a = lambda x : functools.reduce(lambda f, g: g(f), self._pipeline, x)\r\nTypeError: reduce() arg 2 must support iteration\r\n\r\nProcess finished with exit code 1\r\n```\r\n", "comments": ["It looks like nets.i3d is not defined in Unit3D class.Please, help us to provide complete code snippet to reproduce the issue.Thanks.\r\n\r\n\r\n", "@ravikyram \r\nThe model definition can be stored in a file i3d.py and then the code will be \r\n\r\n```\r\nimport tensorflow as tf\r\nfrom i3d import Unit3D\r\n\r\nmodel = Unit3D(output_channels=64, kernel_shape=[7,7,7],\r\n               is_training=True)\r\n\r\ninput = tf.keras.backend.random_uniform(shape=(1,3,64,224,224),\r\n                                        dtype=tf.float32)\r\noutput = model(input)\r\n\r\n```\r\n\r\nHope that clarifies.", "I am able to reproduce the issue in Tensorflow  2.0.0-beta1 version. Thanks!        ", "Anything on this one ?", "The issue is not a bug. For details please see [this](https://stackoverflow.com/questions/56717031/composition-of-lambda-functions-in-tensorflow-2-0/56837574#56837574)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30050\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30050\">No</a>\n"]}, {"number": 30049, "title": "Fix issue of tf.math.real with numeric input", "body": "This fix tries to address the issue raised in #30029 where numeric input does not work with tf.math.real:\r\n```\r\n>>> import tensorflow as tf\r\n>>> tf.math.real(1.)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/util/dispatch.py\", line 180, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/math_ops.py\", line 525, in real\r\n    if input.dtype.is_complex:\r\nAttributeError: 'float' object has no attribute 'dtype'\r\n```\r\n\r\nThe reason was that unlike other functions in math_ops.py, tf.math.real does not try to call ops.convert_to_tensor before processing.\r\nThis fix fixes the issue.\r\n\r\nThis fix fixes #30029.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["`tf.math.angle` also misses the conversion.", "I made #30051 to fix `tf.math.angle`", "Changes submitted internally , waiting for auto merge."]}, {"number": 30048, "title": "Add Raises in the docstring of tf.histogram_fixed_width_bins", "body": "This fix adds exception conditions for tf.histogram_fixed_width_bins in the docstring.\r\n\r\nThis fix fixes #29279.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 30047, "title": "How much memory is required to build tensorflow from sources?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 VM\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: latest\r\n- Python version: 2.7.12\r\n- Installed using virtualenv? pip? conda?: No\r\n- Bazel version (if compiling from source): 0.21\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: ROCm 2.5\r\n- GPU model and memory: ROCm gfx803 gfx900\r\n\r\n\r\n\r\n**Describe the problem**\r\nBuilding tensorflow fails running out of memory LLVM compile stage. Tried VM with\r\n4GB and 8GB, still fails to complete compilation of tensorflow - runs out of memory.\r\nWhat is the memory requirement for building tensorflow?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbuild_rocm script of r1.3-rocm release\r\n./configure (configure for ROCm)\r\nbazel build --config=rocm --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nLLVM Out of Memory\r\nis the error message", "comments": ["You can try using flags in Bazel to limit amount of memory usage:\r\n\r\n* `--ram_utilization_factor 30`\r\n* `--host_jvm_args=-Xmx1g --host_jvm_args=-Xms512m`\r\n* limit number of concurrent jobs `--jobs=2`\r\n\r\nYou can tweak these numbers as you need. I got good success with only `--jobs=2` in a very constrained environment back in October.", "@srinivirt Did you get a chance to look into the comment given by @mihaimaruseac .Thanks.", "Are the --host_jvm_args supported in bazel 0.21, the version that I'm using for ROCm tensorflow build?\r\nIt emitted Unrecognized option ERROR.\r\nTrying with --jobs=2 and ram_utilization_factor", "With bazel jobs=1, the hcc opt core dumps, outof memory again. Here's the log message:\r\n\r\ncd ... execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/bin:/usr/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=1 \\\r\n  external/local_config_rocm/crosstool/clang/bin/crosstool_wrapper_driver_rocm -shared -o bazel-out/k8-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so '-Wl,-rpath,$ORIGIN/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Urocm_S_Srocm_Chiprand___Uexternal_Slocal_Uconfig_Urocm_Srocm_Srocm_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Urocm_S_Srocm_Crocfft___Uexternal_Slocal_Uconfig_Urocm_Srocm_Srocm_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Urocm_S_Srocm_Crocblas___Uexternal_Slocal_Uconfig_Urocm_Srocm_Srocm_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Urocm_S_Srocm_Cmiopen___Uexternal_Slocal_Uconfig_Urocm_Srocm_Srocm_Slib' -Lbazel-out/k8-opt/bin/_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow -Lbazel-out/k8-opt/bin/_solib_local/_U@local_Uconfig_Urocm_S_Srocm_Chiprand___Uexternal_Slocal_Uconfig_Urocm_Srocm_Srocm_Slib -Lbazel-out/k8-opt/bin/_solib_local/_U@local_Uconfig_Urocm_S_Srocm_Crocfft___Uexternal_Slocal_Uconfig_Urocm_Srocm_Srocm_Slib -Lbazel-out/k8-opt/bin/_solib_local/_U@local_Uconfig_Urocm_S_Srocm_Crocblas___Uexternal_Slocal_Uconfig_Urocm_Srocm_Srocm_Slib -Lbazel-out/k8-opt/bin/_solib_local/_U@local_Uconfig_Urocm_S_Srocm_Cmiopen___Uexternal_Slocal_Uconfig_Urocm_Srocm_Srocm_Slib -Wl,--version-script bazel-out/k8-opt/bin/tensorflow/python/pywrap_tensorflow_internal_versionscript.lds '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..' -Wl,-soname,_pywrap_tensorflow_internal.so -Wl,-z,muldefs -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -Wl,-no-as-needed -B/opt/rocm/hcc/compiler/bin -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/k8-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params)\r\nINFO: From Linking tensorflow/python/_pywrap_tensorflow_internal.so:\r\nLLVM ERROR: out of memory\r\nLLVM ERROR: out of memory\r\nLLVM ERROR: out of memory\r\nStack dump:\r\n0.\tProgram arguments: /opt/rocm/hcc/bin/opt -O3 -mtriple amdgcn-amd-amdhsa -mcpu=gfx803 -load /opt/rocm/hcc/bin/../lib/LLVMSelectAcceleratorCode.so -load /opt/rocm/hcc/bin/../lib/LLVMPromotePointerKernArgsToGlobal.so -select-accelerator-code -sac-enable-function-calls=0 -promote-pointer-kernargs-to-global -infer-address-spaces -verify -o /tmp/tmp.CBSxylGc5B/kernel-gfx803.hsaco.opt.bc \r\n1.\tStack dump:\r\n0.\tProgram arguments: /opt/rocm/hcc/bin/opt -O3 -mtriple amdgcn-amd-amdhsa -mcpu=gfx900 -load /opt/rocm/hcc/bin/../lib/LLVMSelectAcceleratorCode.so -load /opt/rocm/hcc/bin/../lib/LLVMPromotePointerKernArgsToGlobal.so -select-accelerator-code -sac-enable-function-calls=0 -promote-pointer-kernargs-to-global -infer-address-spaces -verify -o /tmp/tmp.CBSxylGc5B/kernel-gfx900.hsaco.opt.bc \r\n1.\tStack dump:\r\n0.\tProgram arguments: /opt/rocm/hcc/bin/opt -O3 -mtriple amdgcn-amd-amdhsa -mcpu=gfx906 -load /opt/rocm/hcc/bin/../lib/LLVMSelectAcceleratorCode.so -load /opt/rocm/hcc/bin/../lib/LLVMPromotePointerKernArgsToGlobal.so -select-accelerator-code -sac-enable-function-calls=0 -promote-pointer-kernargs-to-global -infer-address-spaces -verify -o /tmp/tmp.CBSxylGc5B/kernel-gfx906.hsaco.opt.bc \r\n1.\tRunning pass 'Running pass 'Running pass 'Interprocedural Sparse Conditional Constant Propagation' on module '<stdin>'.\r\nInterprocedural Sparse Conditional Constant Propagation' on module '<stdin>'.\r\nInterprocedural Sparse Conditional Constant Propagation' on module '<stdin>'.\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm3sys15PrintStackTraceERNS_11raw_ostreamE+0x2a)[0x17e69fa]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm3sys15PrintStackTraceERNS_11raw_ostreamE+0x2a)[0x17e69fa]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm3sys17RunSignalHandlersEv+0x4c)[0x17e48cc]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm3sys17RunSignalHandlersEv+0x4c)[0x17e48cc]\r\n/opt/rocm/hcc/bin/opt[0x17e4a37]\r\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7fd026058390]\r\n/lib/x86_64-linux-gnu/libc.so.6(gsignal+0x38)[0x7fd024dca428]\r\n/lib/x86_64-linux-gnu/libc.so.6(abort+0x16a)[0x7fd024dcc02a]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm22report_bad_alloc_errorEPKcb+0x154)[0x1783db4]\r\n/opt/rocm/hcc/bin/opt[0x17e4a37]\r\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7fc9dc340390]\r\n/lib/x86_64-linux-gnu/libc.so.6(gsignal+0x38)[0x7fc9db0b2428]\r\n/lib/x86_64-linux-gnu/libc.so.6(abort+0x16a)[0x7fc9db0b402a]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm22report_bad_alloc_errorEPKcb+0x154)[0x1783db4]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm3sys15PrintStackTraceERNS_11raw_ostreamE+0x2a)[0x17e69fa]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm3sys17RunSignalHandlersEv+0x4c)[0x17e48cc]\r\n/opt/rocm/hcc/bin/opt[0x17e4a37]\r\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7f497ef12390]\r\n/lib/x86_64-linux-gnu/libc.so.6(gsignal+0x38)[0x7f497dc84428]\r\n/lib/x86_64-linux-gnu/libc.so.6(abort+0x16a)[0x7f497dc8602a]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm22report_bad_alloc_errorEPKcb+0x154)[0x1783db4]\r\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6(_Znwm+0x2c)[0x7fc9db9f3e8c]\r\n/opt/rocm/hcc/bin/opt[0x16bf7b7]\r\n/opt/rocm/hcc/bin/opt[0x16bfcba]\r\n/opt/rocm/hcc/bin/opt[0x16c1319]\r\n/opt/rocm/hcc/bin/opt[0x16c4445]\r\n/opt/rocm/hcc/bin/opt[0x16c5620]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm9runIPSCCPERNS_6ModuleERKNS_10DataLayoutEPKNS_17TargetLibraryInfoENS_12function_refIFNS_20AnalysisResultsForFnERNS_8FunctionEEEE+0x66b)[0x16c61cb]\r\n/opt/rocm/hcc/bin/opt[0x131b6ca]\r\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6(_Znwm+0x2c)[0x7fd02570be8c]\r\n/opt/rocm/hcc/bin/opt[0x16bf7b7]\r\n/opt/rocm/hcc/bin/opt[0x16bfcba]\r\n/opt/rocm/hcc/bin/opt[0x16bfd10]\r\n/opt/rocm/hcc/bin/opt[0x16c3726]\r\n/opt/rocm/hcc/bin/opt[0x16c4416]\r\n/opt/rocm/hcc/bin/opt[0x16c5620]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm9runIPSCCPERNS_6ModuleERKNS_10DataLayoutEPKNS_17TargetLibraryInfoENS_12function_refIFNS_20AnalysisResultsForFnERNS_8FunctionEEEE+0x66b)[0x16c61cb]\r\n/opt/rocm/hcc/bin/opt[0x131b6ca]\r\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6(_Znwm+0x2c)[0x7f497e5c5e8c]\r\n/opt/rocm/hcc/bin/opt[0x16bf7b7]\r\n/opt/rocm/hcc/bin/opt[0x16bfcba]\r\n/opt/rocm/hcc/bin/opt[0x16bfd10]\r\n/opt/rocm/hcc/bin/opt[0x16c3726]\r\n/opt/rocm/hcc/bin/opt[0x16c4416]\r\n/opt/rocm/hcc/bin/opt[0x16c5620]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm9runIPSCCPERNS_6ModuleERKNS_10DataLayoutEPKNS_17TargetLibraryInfoENS_12function_refIFNS_20AnalysisResultsForFnERNS_8FunctionEEEE+0x66b)[0x16c61cb]\r\n/opt/rocm/hcc/bin/opt[0x131b6ca]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm6legacy15PassManagerImpl3runERNS_6ModuleE+0x34b)[0x120016b]\r\n/opt/rocm/hcc/bin/opt(main+0x222f)[0x6abd6f]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7fc9db09d830]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm6legacy15PassManagerImpl3runERNS_6ModuleE+0x34b)[0x120016b]\r\n/opt/rocm/hcc/bin/opt(main+0x222f)[0x6abd6f]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7fd024db5830]\r\n/opt/rocm/hcc/bin/opt(_ZN4llvm6legacy15PassManagerImpl3runERNS_6ModuleE+0x34b)[0x120016b]\r\n/opt/rocm/hcc/bin/opt(main+0x222f)[0x6abd6f]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f497dc6f830]\r\n/opt/rocm/hcc/bin/opt(_start+0x29)[0x7129b9]\r\n/opt/rocm/hcc/bin/opt(_start+0x29)[0x7129b9]\r\n/opt/rocm/hcc/bin/opt(_start+0x29)[0x7129b9]\r\n/opt/rocm/hcc/bin/clamp-device: line 206: 22160 Aborted                 (core dumped) $OPT ${KMOPTOPT} -mtriple amdgcn-amd-amdhsa -mcpu=$AMDGPU_TARGET -load $LIB/LLVMSelectAcceleratorCode.so -load $LIB/LLVMPromotePointerKernArgsToGlobal.so -select-accelerator-code -sac-enable-function-calls=$AMDGPU_FUNC_CALLS -promote-pointer-kernargs-to-global -infer-address-spaces -verify -o $2.opt.bc < $2.linked.bc\r\n/opt/rocm/hcc/bin/clamp-device: line 206: 22161 Aborted                 (core dumped) $OPT ${KMOPTOPT} -mtriple amdgcn-amd-amdhsa -mcpu=$AMDGPU_TARGET -load $LIB/LLVMSelectAcceleratorCode.so -load $LIB/LLVMPromotePointerKernArgsToGlobal.so -select-accelerator-code -sac-enable-function-calls=$AMDGPU_FUNC_CALLS -promote-pointer-kernargs-to-global -infer-address-spaces -verify -o $2.opt.bc < $2.linked.bc\r\n/opt/rocm/hcc/bin/clamp-device: line 206: 22162 Aborted                 (core dumped) $OPT ${KMOPTOPT} -mtriple amdgcn-amd-amdhsa -mcpu=$AMDGPU_TARGET -load $LIB/LLVMSelectAcceleratorCode.so -load $LIB/LLVMPromotePointerKernArgsToGlobal.so -select-accelerator-code -sac-enable-function-calls=$AMDGPU_FUNC_CALLS -promote-pointer-kernargs-to-global -infer-address-spaces -verify -o $2.opt.bc < $2.linked.bc\r\nhcc: error: linker command failed with exit code 170 (use -v to see invocation)\r\n", "Normally we use instances with at least 16GB of RAM.", "Also see this comment:\r\n\r\n> Building TensorFlow from source can use a lot of RAM. If your system is memory-constrained, limit Bazel's RAM usage with: --local_ram_resources=2048.\r\n\r\nfrom: https://www.tensorflow.org/install/source", "@srinivirt Can we close this issue since the query is been answered. But please let me know if I'm mistaken.Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "I had the same issues and it finally worked. The root of my problem was that I was trying to build on a 16g laptop.\r\n\r\nFor people not used to build tensorflow: if you're trying to only execute a simple python unit test like with this command:\r\n\r\n`bazel test tensorflow/python/keras:losses_test`\r\n\r\nIf you see bazel busy compiling C++ code for a very long time: this is normal. It's dependencies that must be built.\r\nOnce built, the python tests you asked for will be the only thing that will be done and will be fast.\r\n\r\nStill, if you're limited in RAM, you may have plenty of C++ compiler crashes due to memory alloc problems. Or your system might be thrashing so watch the use of memory to avoid your system being out of control.\r\n\r\nPlay with flags to adjust memory and CPU usage like this:\r\n\r\n`bazel test --local_ram_resources=9216 --jobs=5 --verbose_failures tensorflow/python/keras:losses_test`\r\n\r\nRetry if it failed or wrap this command in a loop in a bash script.\r\n\r\nYou should see output like this:\r\n```\r\n[816 / 1,594] Compiling tensorflow/core/kernels/pad_op.cc; 171s local ... (5 actions running)\r\n[833 / 1,594] Compiling tensorflow/core/kernels/pad_op.cc; 197s local ... (5 actions running)\r\n[837 / 1,594] Compiling tensorflow/core/kernels/pad_op.cc; 228s local ... (5 actions running)\r\n[1,101 / 1,594] Compiling tensorflow/core/kernels/pad_op.cc; 263s local ... (5 actions running)\r\n[1,208 / 1,594] Compiling tensorflow/core/kernels/tile_functor_cpu.cc; 304s local ... (5 actions running)\r\n[1,322 / 1,594] Compiling tensorflow/core/kernels/conv_grad_filter_ops.cc; 324s local ... (5 actions running)\r\n[1,691 / 1,729] Compiling tensorflow/core/kernels/conv_grad_filter_ops.cc; 377s local ... (4 actions running)\r\n[1,723 / 1,747] Compiling tensorflow/core/kernels/conv_ops_fused_float.cc; 418s local ... (3 actions running)\r\n```\r\n\r\nIt'll make progress on each pass and eventually, it succeeded for me.\r\n\r\nAt the very end:\r\n```\r\nTarget //tensorflow/python/keras:losses_test up-to-date:\r\n  bazel-bin/tensorflow/python/keras/losses_test\r\nINFO: Elapsed time: 0.634s, Critical Path: 0.00s\r\nINFO: 0 processes.\r\nINFO: Build completed successfully, 1 total action\r\n//tensorflow/python/keras:losses_test                           (cached) PASSED in 17.6s\r\n```\r\n\r\nBut if your system has more RAM, I assume it'll be much smoother.\r\n\r\nMy config:\r\n```\r\nUbuntu 18.04.3 LTS\r\nPython 3.6.9\r\nbazel version: bazel 1.1.0. This respects the boundaries between _TF_MIN_BAZEL_VERSION and _TF_MAX_BAZEL_VERSION in configure.py\r\ngcc --version: gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n```\r\n"]}, {"number": 30046, "title": "input_fn recall hook for estimator api", "body": "**System information**\r\n- TensorFlow version (you are using): 1.10 < 2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently estimators are trained using either:\r\n\r\n```python\r\nestimator.train(...)\r\nestimator.train_and_evaluate(...)    # internally calls self.train\r\n```\r\n\r\nFollowing the `tf.estimator.Estiamtor` [source code](https://github.com/tensorflow/estimator/blob/33e13754b0deebe7cc5006c49c53d246b6ff1dec/tensorflow_estimator/python/estimator/estimator.py) we see that `.train` calls `_train_model` that calls `_train_model_default`\r\n\r\n[Line 1183](https://github.com/tensorflow/estimator/blob/33e13754b0deebe7cc5006c49c53d246b6ff1dec/tensorflow_estimator/python/estimator/estimator.py#L1183) has:\r\n\r\n```python\r\n# ...\r\nfeatures, labels, input_hooks = (self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\r\n# ...\r\n```\r\n\r\nprior to calling `_train_with_estimator_spec`\r\n\r\nwith the features and labels from the `tf.data.Dataset` returned by the `input_fn` wrapped into an `EstimatorSpec`. \r\n\r\nSo it seems that per epoch / per batch updates to the `tf.data.Dataset` is not possible without very careful construction of the dataset.\r\n\r\nIt would be nice to be able to have the `input_fn` have the ability to be recalled and possibly updated depending on estimator stated (e.g. depending on `step`)\r\n\r\n\r\n**Will this change the current api? How?**\r\n\r\nIt _shouldn't_ change the current estimator api.\r\nIt may add some extra interfaces to the api (e.g. a decorator for the `input_fn` that passes `_step`, `_recall_on_batch`)\r\n\r\n**Who will benefit with this feature?**\r\n\r\nUsers with data that requires run-time generation / variation \r\n\r\n\r\n**Any Other info.**\r\n\r\ne.g. this kind of logic should be possible\r\n```python\r\ndef input_fn(..., _step, _epoch):\r\n\r\n    if _step > n:\r\n        return tf.data.Dataset(...)\r\n    return tf.data.Dataset(...)\r\n```\r\n\r\n", "comments": ["@SumNeuron,\r\nSorry for the delayed response. In the **`Tensorflow Version 2.x`**, since we use [TF Keras](https://www.tensorflow.org/api_docs/python/tf/keras/) and [tf.data](https://www.tensorflow.org/guide/data) predominantly and don't use [Estimators](https://www.tensorflow.org/guide/estimator) much, can you please let us know if this Feature is still relevant? \r\n\r\nThanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 30045, "title": "ParseSequenceExample should return Ragged Tensor or have an option for this", "body": "**System information**\r\n- TensorFlow version (you are using): 1.14r\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nRight now, ParseSequenceExample returns sparse tensors. Instead, it should return Ragged tensors. This causes issues with our molecular dynamics project because padded tensors contain zeros which are misinterpreted as extra atoms in simulation. As a workaround we have to make lists of tensors, which interrupts training. Will try another approach by mapping twice\r\n\r\nSequence Examples are suited to make Ragged tensors because they both address the same variable-length issue\r\n\r\n**Will this change the current api? How?**\r\ndataset = tf.data.TFRecordDataset(files)\r\ndataset = dataset.batch(batch_size=BATCH_SIZE)\r\ndataset = dataset.map(parse_function) \r\n```\r\ndef parse_function(batch):\r\n    ... define batch features ...\r\n    return parse_sequence_example(batch, ragged=True, context_features=context_features, sequence_features=sequence_features)\r\n```\r\n**Who will benefit with this feature?**\r\npeople who don't want to pause training to postprocess data coming out of TFRecordDataset \r\n\r\n**Any Other info.**\r\nit would be nice to return a tuple of ragged tensors for each sequence feature. context features can remain as tensors\r\n\r\nHappy to try workarounds but it's hard to share our code as it requires making a special proteins dataset of TFRecords", "comments": ["Ugh, not sure how to accomplish this! How do you parse tfrecords of sequence examples into Ragged Tensors or just lists/tuples of tensors? It works only with batch_size 1, higher batch sizes try to concat the tensors and fail. \r\n\r\nthe `for item in dataset` pattern is cool but not sure how to get multiple elements if we can't use Dataset.batch\r\n\r\ni guess we could just append to a list until the list is full and then train and empty the list. but that doesn't seem like real batch training. Keras models don't support ragged tensors either, which is a bummer, because it's a great idea for NLP and unstructured data", "* We are planning to add RaggedTensor support to ParseSequenceExample.  In the mean-time, you may be able to use the following:\r\n\r\n```\r\ndataset = dataset.map(tf.RaggedTensor.from_sparse)\r\n```\r\n\r\n* We are actively working on adding support for RaggedTensor to Keras.", "Thank you @edloper! I was also thinking windows might help", "@bionicles,\r\nSorry for the delayed response. The documentation of [ParseSequenceExampleV2](https://www.tensorflow.org/api_docs/cc/struct/tensorflow/ops/parse-sequence-example-v2/attrs) and [tf.io.parse_single_sequence_example](https://www.tensorflow.org/api_docs/python/tf/io/parse_single_sequence_example) shows the support of **`Ragged Tensor`**. \r\n\r\nCan you please let us know if that is what you are looking for? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 30044, "title": "weight NCHW2NHWC", "body": "Hi\uff0cI know that if I want to change the tensor from NCHW to NHWC is simply use transpos((0,2,3,1)) will,but my question is what if I want to change the weight of network trained using NCHW to NHWC,is using  transpos((0,2,3,1)) on the the weight will work too?I just want to know.Thanks if anyone can help\uff01", "comments": ["It is weird that I use this code:\r\n```\r\nimport tensorflow as tf\r\n\r\ninput_x = tf.constant([\r\n\t[\r\n\t\t[[0.0, 1.0, 2.0],[1.0,1.0,0.0],[1.0,1.0,2.0],[2.0,2.0,0.0],[2.0,0.0,2.0]],\r\n\t\t[[0.0,0.0,0.0],[1.0,2.0,0.0],[1.0,1.0,1.0],[0.0,1.0,2.0],[0.0,2.0,1.0]],\r\n\t\t[[1.0,1.0,1.0],[1.0,2.0,0.0],[0.0,0.0,2.0],[1.0,0.0,2.0],[0.0,2.0,1.0]],\r\n\t\t[[1.0,0.0,2.0],[0.0,2.0,0.0],[1.0,1.0,2.0],[1.0,2.0,0.0],[1.0,1.0,0.0]],\r\n\t\t[[0.0,2.0,0.0],[2.0,0.0,0.0],[0.0,1.0,1.0],[1.0,2.0,1.0],[0.0,0.0,2.0]],\r\n\t],\r\n])\r\nfilters = tf.constant([\r\n\t[\r\n\t\t[[1.0,-1.0,0.0],[1.0,0.0,1.0],[-1.0,-1.0,0.0]],\r\n\t\t[[-1.0,0.0,1.0],[0.0,0.0,0.0],[1.0,-1.0,1.0]],\r\n\t\t[[-1.0,1.0,0.0],[-1.0,-1.0,-1.0],[0.0,0.0,1.0]],\r\n\t],\r\n])\r\nbias = tf.constant(1.0,shape=[1])\r\n\r\nfilterinput = tf.reshape(filters, [3, 3, 3, 1])  \r\nprint('input_x shape',input_x.shape)\r\nprint('filterinput shape',filterinput.shape)\r\nres = tf.nn.conv2d(input_x, filterinput, strides=[1,2,2,1], padding='SAME')#+bias\r\n\r\nsess = tf.Session()\r\nprint(\"result shape:\", res.shape)\r\nprint(sess.run(res[:,:,:,0]))\r\n```\r\nget a result:\r\n```input_x shape (1, 5, 5, 3)\r\nfilterinput shape (3, 3, 3, 1)\r\nresult shape: (1, 3, 3, 1)\r\n[[[ 0. -1. -4.]\r\n  [-7.  0.  0.]\r\n  [ 3. -4.  0.]]]\r\n```\r\nand I transpose the input to NCHW,and weight from RSCK to KCRS(R:kernel h,S:kernel w,C:in channels,K:out channels):\r\n```\r\nimport tensorflow as tf\r\nimport os\r\n#os.environ['CUDA_VISIBLE_DEVICES']='-1'\r\ninput_x = tf.constant([\r\n\t[\r\n\t\t[[0.0, 1.0, 2.0],[1.0,1.0,0.0],[1.0,1.0,2.0],[2.0,2.0,0.0],[2.0,0.0,2.0]],\r\n\t\t[[0.0,0.0,0.0],[1.0,2.0,0.0],[1.0,1.0,1.0],[0.0,1.0,2.0],[0.0,2.0,1.0]],\r\n\t\t[[1.0,1.0,1.0],[1.0,2.0,0.0],[0.0,0.0,2.0],[1.0,0.0,2.0],[0.0,2.0,1.0]],\r\n\t\t[[1.0,0.0,2.0],[0.0,2.0,0.0],[1.0,1.0,2.0],[1.0,2.0,0.0],[1.0,1.0,0.0]],\r\n\t\t[[0.0,2.0,0.0],[2.0,0.0,0.0],[0.0,1.0,1.0],[1.0,2.0,1.0],[0.0,0.0,2.0]],\r\n\t],\r\n])\r\nfilters = tf.constant([\r\n\t[\r\n\t\t[[1.0,-1.0,0.0],[1.0,0.0,1.0],[-1.0,-1.0,0.0]],\r\n\t\t[[-1.0,0.0,1.0],[0.0,0.0,0.0],[1.0,-1.0,1.0]],\r\n\t\t[[-1.0,1.0,0.0],[-1.0,-1.0,-1.0],[0.0,0.0,1.0]],\r\n\t],\r\n])\r\nbias = tf.constant(1.0,shape=[1])\r\n\r\nfilterinput = tf.reshape(filters, [3, 3, 3, 1])\r\nprint('input_x shape',input_x.shape)\r\nprint('filterinput shape',filterinput.shape)\r\ninput_x = tf.transpose(input_x,perm=(0,3,1,2))\r\nfilterinput = tf.transpose(filterinput,perm=(2,3,1,0))\r\nprint('input_x transpose shape',input_x.shape)\r\nprint('filterinput transpose shape',filterinput.shape)\r\nres = tf.nn.conv2d(input_x, filterinput,data_format='NCHW',strides=[1,1,2,2], padding='SAME')#+bias\r\nres = tf.transpose(res,perm=(0,3,2,1))\r\n#res = tf.reduce_sum(res, 3, keep_dims=True)\r\nsess = tf.Session()\r\nprint(\"result shape:\", res.shape)\r\nprint(sess.run(res[:,:,:,:]))\r\n```\r\n\r\nand I get this:\r\n\r\n```input_x shape (1, 5, 5, 3)\r\nfilterinput shape (3, 3, 3, 1)\r\ninput_x transpose shape (1, 3, 5, 5)\r\nfilterinput transpose shape (3, 1, 3, 3)\r\nresult shape: (1, 3, 3, 3)\r\n[[[[-2. -2. -1.]\r\n   [-2.  2.  2.]\r\n   [-1.  1. -3.]]\r\n\r\n  [[-2.  0.  0.]\r\n   [ 0.  1. -1.]\r\n   [-1.  0. -3.]]\r\n\r\n  [[-2. -1.  1.]\r\n   [ 1.  1. -5.]\r\n   [ 0. -3. -2.]]]]\r\n```\r\nI same inputs and kernels,the dfierent is NCHW and NHWC,the output shape and result is different.why?????\r\nmy tf version is 1.12.0,python 3.6"]}, {"number": 30043, "title": "fix metal build", "body": "there is no message(). use error_message() instead", "comments": ["@impjdi Could you review this?"]}, {"number": 30042, "title": "Installation documentation and mac wheels", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/pip\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThere are no binary wheels for tensorflow 1.14 for mac (should be [here](https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.14.0-py3-none-any.whl)) and the documentation page still points to 1.13.\r\n\r\nIs 1.14 still considered unstable? Was the wheel generation and documentation update simply forgotten? Or is it normal that it takes a couple of days after the release?\r\n", "comments": ["Any update on when the wheels will appear on the googleapis storage? They exist on pypi?", "Seems there was a bug in the release process pipeline.\r\n\r\nWe'll (try to) solve this issue this week, sorry about this.", "Added @av8ramit too. I wonder if there's a desync between our upload scripts.", "Taking a look now.", "It appears the 1.14 build upload was not completed. Can you try again now please?", "Yes, the downloads work now! The [documentation](https://www.tensorflow.org/install/pip) still points to 1.13 though.", "I think @lamberta can fix the documentation link, assigning to him", "Site updated: https://www.tensorflow.org/install/pip#package-location", "Thank you!"]}, {"number": 30041, "title": "The api 'tf.data.experimental.CsvDataset' performs very slow in test.", "body": "**System info.**\r\n - cuda: 10.1\r\n - python: 3.6.6\r\n - tensorflow: 1.13.1\r\n - gpu: Quadro P5000\r\n\r\n**Test Data.**\r\nCsv dataset with 430 columns (all in floats), the first 429 columns as features and the last column as labels. There are totally 1928 classes and 57909 instances. \r\n\r\n**Problem.**\r\nI test the speed of the csv readers, api ```tf.data.experimental.CsvDataset``` and the common method ```tf.placeholder()```. Here is the code:\r\n\r\nwith ```tf.data.experimental.CsvDataset```:\r\n```\r\ndef parse_data(x, n_classes):\r\n    x = tf.convert_to_tensor(x)\r\n    return x[:-1], tf.one_hot(indices=tf.cast(x[-1], tf.int32), depth=n_classes)\r\n\r\nif __name__=='__main__':\r\n    dataset_train = tf.data.experimental.CsvDataset('/home/david/Dataset/timit/test.csv', [tf.float32] * 430,\r\n                                                    header=False,\r\n                                                    field_delim=' ')\r\n    dataset_train = dataset_train.map(lambda *x_: parse_data(x_, 1928))\r\n    dataset_train = dataset_train.batch(128)\r\n    dataset_train = dataset_train.prefetch(1)\r\n    iterator = dataset_train.make_initializable_iterator()\r\n\r\n    x_in, y = iterator.get_next()\r\n\r\n    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x_in)\r\n    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)\r\n    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)\r\n    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)\r\n    logits = tf.layers.Dense(units=1928, activation=None)(x)\r\n\r\n    loss = tf.losses.softmax_cross_entropy(y, logits)\r\n    optimizer = tf.train.AdamOptimizer()\r\n    optimizer.minimize(loss)\r\n\r\n    sess = tf.Session()\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(iterator.initializer)\r\n    running_loss = 0.0\r\n    time_last = time.time()\r\n    epoch = 0\r\n    i = 0\r\n    while True:\r\n        try:\r\n            running_loss += sess.run(loss)  # , feed_dict={x: data, y: labels})\r\n            if (i + 1) % 5 == 0:\r\n                print('\\r[epoch: %2d, batch: %5d, time: %5f] loss: %.3f' % (\r\n                    epoch + 1, i + 1, time.time() - time_last, running_loss / i), end=' ')\r\n                time_last = time.time()\r\n            i += 1\r\n        except tf.errors.OutOfRangeError:\r\n            pass\r\n```\r\n\r\nwith ```tf.placeholder```:\r\n```\r\nif __name__ == '__main__':\r\n    x_in = tf.placeholder(shape=[128, 429], dtype=tf.float32)\r\n    y_in = tf.placeholder(shape=[128], dtype=tf.int32)\r\n    y = tf.one_hot(y_in, depth=1928)\r\n\r\n    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x_in)\r\n    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)\r\n    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)\r\n    x = tf.layers.Dense(units=1024, activation=tf.nn.relu)(x)\r\n    logits = tf.layers.Dense(units=1928, activation=None)(x)\r\n\r\n    loss = tf.losses.softmax_cross_entropy(y, logits)\r\n    optimizer = tf.train.AdamOptimizer()\r\n    optimizer.minimize(loss)\r\n\r\n    sess = tf.Session()\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    w = pd.read_csv('/home/david/Dataset/timit/test.csv', header=None, delim_whitespace=True).values\r\n\r\n    for epoch in range(23):\r\n        running_loss = 0.0\r\n        time_last = time.time()\r\n        i = 0\r\n        indexes = np.random.permutation(w.shape[0])\r\n        w_ = w[indexes, :]\r\n        while True:\r\n            if i * 128 + 128 > w.shape[0]:\r\n                break\r\n            running_loss += sess.run(loss,\r\n                                     feed_dict={x_in: w_[i * 128:i * 128 + 128, :-1],\r\n                                                y_in: w_[i * 128:i * 128 + 128, -1]})\r\n            if (i + 1) % 5 == 0:\r\n                print('\\r[epoch: %2d, batch: %5d, time: %5f] loss: %.3f' % (\r\n                    epoch + 1, i + 1, time.time() - time_last, running_loss / i), end=' ')\r\n                time_last = time.time()\r\n            i += 1\r\n```\r\n\r\n**Result (Time for training five batches).**\r\n - ```tf.placeholder``` method: 0.013263s\r\n - ```tf.data.experimental.CsvDataset``` method: 1.382647s\r\n\r\n**Problem.**\r\n - Api ```tf.data.experimental.CsvDataset``` is so slow in the above test. I guess it is partly because that ```tf.data.experimental.CsvDataset``` do io operations before each batch to extract data from csv file. Is this ture, or there are other reasons?\r\n\r\n - However, it is too slow comparing to ```tf.placeholder```. Is there any chance for improvement? How can I set the ```tf.data.experimental.CsvDataset ```api to load all csv data at the very beginning?\r\n\r\n - Or can I say that ```tf.data.experimental.CsvDataset``` is implemented only for the csv dataset that is too big to store in the memory? Because the time cost seems like intolerable.\r\n\r\n", "comments": ["Can you please help us with test.csv to reproduce the issue.Thanks.", "Sure, the ```test.csv``` can be downloaded [here](https://drive.google.com/file/d/1Lo0CULsDWt8qoFzFlq6FzCNb-Rt9bp9P/view?usp=sharing), but I think there is nothing special for this dataset. ", "All in all this isn't really surprising. There's a reason people don't use CSVs for high performance pipelines. That said, there are couple adjustments to make the comparison more apples to apples:\r\n\r\n1) Drop the network and just run through the dataset in isolation. (Since that's all we're interested in.)\r\n2) **Time the Pandas load**. This is the big one. Loading the CSV is by far the most expensive part of both pipelines, so it should be timed in both.\r\n3) Run for more than 5 steps. You generally need to run for a few dozen to reasonably amortize and startup costs. \r\n\r\nWhen you correct for those factors the delta drops from ~100x to ~3.5x:\r\nhttps://colab.sandbox.google.com/gist/robieta/8ac90d720108666ddd58cff9f1d2a88c/csv_profile.ipynb\r\n\r\nTaking a step back, however, the truth is that if you want a very high performance pipeline on data that doesn't fit into memory tf.data offers a variety of solutions. (TFRecordDataset for parallel reads of TFRecords, FixedLengthRecordDataset if you just want to dump the raw NumPy buffer and then decode it, etc.) Ultimately an appropriately chosen binary format will always outperform a text based format; it's just that for a lot of applications CSV happens to be fast enough.", "> All in all this isn't really surprising. There's a reason people don't use CSVs for high performance pipelines. That said, there are couple adjustments to make the comparison more apples to apples:\r\n> \r\n> 1. Drop the network and just run through the dataset in isolation. (Since that's all we're interested in.)\r\n> 2. **Time the Pandas load**. This is the big one. Loading the CSV is by far the most expensive part of both pipelines, so it should be timed in both.\r\n> 3. Run for more than 5 steps. You generally need to run for a few dozen to reasonably amortize and startup costs.\r\n> \r\n> When you correct for those factors the delta drops from ~100x to ~3.5x:\r\n> https://colab.sandbox.google.com/gist/robieta/8ac90d720108666ddd58cff9f1d2a88c/csv_profile.ipynb\r\n> \r\n> Taking a step back, however, the truth is that if you want a very high performance pipeline on data that doesn't fit into memory tf.data offers a variety of solutions. (TFRecordDataset for parallel reads of TFRecords, FixedLengthRecordDataset if you just want to dump the raw NumPy buffer and then decode it, etc.) Ultimately an appropriately chosen binary format will always outperform a text based format; it's just that for a lot of applications CSV happens to be fast enough.\r\n\r\nI really want to use TFRecord but TFRecordWriter is superslow.\r\nI already check that Example.SerializeToString() is the cause.\r\nIn my case in took 15secs to process 50000 records and I have 220,000,000 .......that's 5 days!!\r\nI mean I prepare that 220m rows with C# in 15mimutes by Parallel.ForEach.\r\nIt would be nice if they can explain how to construct this TFRecord in binary stucture so that we can use any tool or language we want,data preparation shouldn't be tie with Tensorflow", "For advice on optimizing a particular implementation, I would suggest you consult [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since there a larger community that reads questions there. Github issues are more narrowly scoped to bugs and, in this case, feature requests. However I'll let @rachellim have the final word on that front. (I just happened to be passing through.)\r\n", "Thanks @robieta ! Looking at this [old github issue](https://github.com/tensorflow/tensorflow/issues/4467), the poor performance of the `SerializeToString` has been noticed before. Can you check what implementation of `protobuf` is being used, @Pearseak ?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30041\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30041\">No</a>\n"]}, {"number": 30040, "title": "Dimensions check in BinaryCrossEntropy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary):Binary\r\n- TensorFlow version (use command below):2.0.0-beta1\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nSuppose we build a model for binary classification problem and we want to use `BinaryCrossEntropy` loss provided in `tf.keras.losses`. Here is an example:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ny_true = np.array([[1.], [1.], [1.], [0.], [1.], [0.], [0.], [1.], [1.], [0.]]).astype(np.float32)\r\ny_pred = np.array([[0.], [0.], [0.], [1.], [1.], [0.], [0.], [1.], [0.], [1.]]).astype(np.float32)\r\n\r\nprint(y_true.shape, y_pred.shape) # prints (10, 1) (10, 1)\r\n\r\n# loss function\r\nbce = tf.keras.losses.BinaryCrossentropy()\r\n\r\n# Case1:\r\nprint(bce(y_true, y_pred).numpy())  # prints 9.23662 correctly\r\n\r\n# Case2:\r\nprint(bce(np.squeeze(y_true), y_pred).numpy()) # prints 8.006299\r\n```\r\n\r\n**Describe the expected behavior**\r\nWhen the `dimensions` of `y_true` and `y_pred` are different, in that case the loss function should raise an error for `dimension` mismatch or the model will fail **silently** and no one would be ab;e to debug it until unless they are aware of this behavior \r\n\r\n**Code to reproduce the issue**\r\nCheck above \r\n\r\n", "comments": ["Added a PR #30053 for the shape check.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30040\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30040\">No</a>\n"]}, {"number": 30039, "title": "Tensorflow per_process_gpu_memory_fraction used more memory than specified", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch linux 5.1.12\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): [Arch Linux repository](https://www.archlinux.org/packages/community/x86_64/python-tensorflow-cuda/) \r\n- TensorFlow version (use command below): 1.14.0-rc1\r\n- Python version: 3.7.3 \r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.1.168\r\n- GPU model and memory: Quadro M2200, 4043 MB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nTensorflow allocates more memory than specified. When running multiple processes sharing the same GPU can cause one process to have out of memory exception. For example, I specified it to use no more than 50% of GPU memory. However, it actually allocates ~52% memory as in the screenshot.\r\n\r\n![image](https://user-images.githubusercontent.com/11804383/59959367-68051d80-94e8-11e9-9e95-688f66049599.png)\r\n\r\n**Describe the expected behavior**\r\nI would expect it to allocate no more than 50% memory. In my case, it would be <=2021.5 MB.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\r\n\r\nwith tf.compat.v1.Session(\r\n        config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\r\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\n    c = tf.matmul(a, b)\r\n    while True:\r\n        sess.run(c)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Can confirm this issue, on a system with NVIDIA 2080 Ti it behaves the following way:\r\nwith per_process_gpu_memory_fraction=0.2 it allocates 2457 MiB / 10989 MiB (as shown in nvidia-smi), which is obviously greater than expected (0.2 * 10989 = 2198 MiB)\r\n\r\nWith per_process_gpu_memory_fraction=0.1 it allocates 1357 MiB / 10989 MiB, which is greater than 0.1 * 10989 = 1099 MiB expected.", "Hi @zli117, I think this is expected. per_process_gpu_memory_fraction specifies the amount of memory that TF will be used to allocate input/output tensors of the graph and temporary buffers for intermediate results. This doesn't include memory that is needed to initialize CUDA/cuDNN and other GPU libraries.\r\n\r\nI'm closing this, feel free to reopen if there are further questions."]}, {"number": 30038, "title": "Generated a .tflite file with 0kb", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 1.14.0. also tried with 1.12 and 1.13\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: Using CPU\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nGenerated a sample.tflite file with 0kb\r\n\r\n**Describe the expected behavior**\r\nShould generate a good .tflite file\r\n\r\n**Code to reproduce the issue**\r\nbazel run -c opt tensorflow/lite/toco:toco -- --input_file=C:/tensorflow1/models/research/object_detection/sample_tflite_graph.pb --output_file=C:/tensorflow1/models/research/object_detection/sample_detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_values=128 --change_concat_input_ranges=false --default_ranges_min=0 --default_ranges_max=6 --allow_custom_ops \r\n\r\n\r\n**Other info / logs**\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Options provided by the client:\r\n  Inherited 'build' options: --python_path=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe\r\nINFO: Reading rc options for 'run' from c:\\tensorflow1\\models\\research\\object_detection\\tensorflow\\.bazelrc:\r\n  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include\r\nINFO: Reading rc options for 'run' from c:\\tensorflow1\\models\\research\\object_detection\\tensorflow\\.tf_configure.bazelrc:\r\n  Inherited 'build' options: --action_env PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe --action_env PYTHON_LIB_PATH=C:/tensorflow1/models/research/slim --python_path=C:/ProgramData/Anaconda3/envs/tensorflow1/python.exe --config monolithic --copt=-w --host_copt=-w --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --verbose_failures --distinct_host_configuration=false --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:monolithic in file c:\\tensorflow1\\models\\research\\object_detection\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Analyzed target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nTarget //tensorflow/lite/toco:toco up-to-date:\r\n  bazel-bin/tensorflow/lite/toco/toco.exe\r\nINFO: Elapsed time: 3.214s, Critical Path: 0.01s\r\nINFO: 0 processes.\r\nINFO: Build completed successfully, 1 total action\r\nINFO: Running command line: bazel-bin/tensorflow/lite/toco/toco.exe '--input_file=C:/tensorflow1/models/research/object_detection/sample_tflite_graph.pb' '--output_file=C:/tensorflow1/models/research/object_detection/sample_detect.tflite' '--input_shapes=1,300,300,3' '--input_arrays=normalized_input_image_tensor' '--output_arrays='\\''TFLite_Detection_PostProcess'\\'','\\''TFLite_Detection_PostProcess:1'\\'','\\''TFLite_Detection_PostProcess:2'\\'','\\''TFLite_Detection_PostProcess:3'\\''' '--inference_type=QUANTIZED_UINT8' '--mean_values=128' '--std_values=128' '--change_concat_input_ranges=false' '-INFO: Build completed successfully, 1 total action\r\n2019-06-22 00:08:48.443379: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TFLite_Detection_PostProcess\r\n2019-06-22 00:08:48.469603: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TFLite_Detection_PostProcess\r\n2019-06-22 00:08:48.563540: F tensorflow/lite/toco/tooling_util.cc:918] Check failed: GetOpWithOutput(model, output_array) Specified output array \"'TFLite_Detection_PostProcess'\" is not produced by any op in this graph. Is it a typo? This should not happen. If you trigger this error please send a bug report (with code to reporduce this error), to the TensorFlow Lite team.\r\n", "comments": ["it may be output node is wrong, you can add one output nde  in net ,  @devidipak ", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30038\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30038\">No</a>\n"]}, {"number": 30037, "title": "InvalidArgumentError (see above for traceback): Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero", "body": "python 3.6\r\nUbuntu 16.04.6 LTS\r\ntensorflow '1.13.1'\r\n```\r\nfeat_width = 2048\r\ngpu_num = 8\r\n\r\ndef create_cnn_model(feat_width, data_format='channels_last'):\r\n   model = tf.keras.Sequential()\r\n   model.add(\r\n      tf.keras.layers.Conv2D(\r\n        filters = 32,\r\n        kernel_size  = (1,2),\r\n        strides = (1,2),\r\n        data_format = data_format,\r\n        padding = 'same',\r\n        activation='relu',\r\n        input_shape = (2,feat_width,1)))\r\n    model.add(\r\n      tf.keras.layers.Conv2D(\r\n        filters = 10,\r\n        kernel_size  = (2,2),\r\n        data_format = data_format,\r\n        padding = 'same',\r\n        activation = 'relu'))\r\n    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 1), data_format=data_format))\r\n    model.add(tf.keras.layers.Flatten(data_format=data_format))\r\n    model.add(tf.keras.layers.Dense(units=10, activation='relu'))\r\n    model.add(tf.keras.layers.Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\r\n    return model\r\n\r\ndef serving_input_fn():\r\n        \"\"\"Build the serving inputs.\"\"\"\r\n        inputs = {}\r\n        inputs[keras_model.input_names[0]] = tf.placeholder(shape=(None, 2,feat_width,1), dtype=tf.float32)\r\n\r\n        return tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)\r\n\r\nstrategy = tf.contrib.distribute.MirroredStrategy(num_gpus=gpu_num)\r\nestimator_config = tf.estimator.RunConfig(\r\n        model_dir='../../model',\r\n        tf_random_seed=0,\r\n        save_summary_steps=256,\r\n        save_checkpoints_steps=10000,\r\n        train_distribute=strategy,\r\n        keep_checkpoint_max=64,\r\n        log_step_count_steps=256)\r\n\r\nkeras_model = create_cnn_model(feat_width)\r\nkeras_model = tf.keras.utils.multi_gpu_model(keras_model, gpus=gpu_num)\r\nkeras_model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\r\nestimator = tf.keras.estimator.model_to_estimator(keras_model=keras_model,config=estimator_config)\r\ntf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n```\r\n\r\nusing\r\n```\r\n tf.contrib.predictor.from_saved_model(export_dir)\r\n```\r\nto do inference:\r\n```\r\npredictor =  tf.contrib.predictor.from_saved_model(export_dir=export_dir)\r\nfeed_tensor = list(predictor.feed_tensors.keys())[0]\r\nfetch_tensor = list(predictor.fetch_tensors.keys())[0]\r\nfeat = np.random.rand(2*feat_width)\r\nfeat = np.reshape(feat,[ 2, feat_width, 1])\r\nY = predictor({feed_tensor: [feat]})\r\nr = Y[fetch_tensor]\r\n```\r\nfails for multi gpu with error\r\n```\r\nInvalidArgumentError (see above for traceback): Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\r\n\t [[node sequential_1/flatten/Reshape ]]\r\n\t [[node dense_2_1/concat ]]\r\n```\r\nif I don't use multi gpu the inference code works.\r\n", "comments": ["maybe it is related to these bugs https://github.com/keras-team/keras/issues/11806 and https://github.com/keras-team/keras/issues/12694", "@alexmil2019 Please provide us the complete code to reproduce the issue. Thanks!", "I have already attached the complete code for reproducing the bug.", "I am running into the same problem. \r\nI have a custom callback that tries to run a model inference at the end of each epoch for visualization purposes. \r\nWhen I run on a single GPU the inference succeeds, when I use multiple gpus I receive:\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\r\n\t [[{{node replica_0/model_1/reshape_1/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](replica_0/model_1/permute_1/transpose, replica_0/model_1/reshape_1/Reshape/shape)]]\r\n\t [[{{node replica_1/model_1/permute_2/transpose/_1481}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:1\", send_device_incarnation=1, tensor_name=\"edge_1709_replica_1/model_1/permute_2/transpose\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```", "@alexmil2019 I tried reproducing the issue but It looks some entities are not defined like `strategy`. Please help us reproduce the issue. Thanks!", "I added definition for strategy.", "@alexmil2019 You don't need to use multi_gpu_model since you are also using MirroredStrategy. Can you try using MirroredStrategy with native Keras APIs to train your model synchronously on multiple GPUs?\r\nHere is a tutorial that demonstrates how you can use tf.distribute APIs: https://www.tensorflow.org/beta/tutorials/distribute/keras\r\n\r\nWould this work for your use case?", "Closing this bug for now. Please reopen if you run into issues when using MirroredStrategy.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30037\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30037\">No</a>\n", "\u6211\u662f\u5728bert\u7684\u6a21\u578b\u8bad\u7ec3\u5b8c\u4e4b\u540e\u9884\u6d4b\u65f6\u5019\u9047\u5230\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u7528\u7684\u662fkeras_bert\uff0c\u6211\u662f\u8fd9\u6837\u89e3\u51b3\u7684\r\nword2vec, segment = tokenizer.encode(sen)\r\nword2vec = np.expand_dims(word2vec, axis=0)\r\n\u4e5f\u5c31\u662f\u8bf4\u7ed9\u751f\u6210\u7684index\u6dfb\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u8fd9\u4e00\u7ef4\u5ea6\u5728\u5145\u5f53batch"]}, {"number": 30036, "title": "Can TensorFlow's \"predict\" be used in C++?", "body": "I am very new to TensorFlow and this may be a silly question, and I hope this is the right place to ask it. I have been searching for a rnn-library that I can use with C++ and was hoping TensorFlow could work for me. What I am wondering about is:\r\n\r\n**Can I train and save a keras model in python, and then load the model by using C++, and then use the loaded model to do predictions (in C++)?**\r\n\r\nI just wanted to make sure, or figure out, if this is possible before I started working on, and learn more about TensorFlow, or if I should keep looking for other C++ libraries.", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there and provide solution to such issues better and faster. meanwhile you can also have a look on this [link](http://bitbionic.com/2017/08/18/run-your-keras-models-in-c-tensorflow/) for reference. This might help you. Thanks!\r\n", "Thanks for the reply. I understand, I will ask this question (and similar ones in the future) at StackOverflow instead, since it's not a bug or feature request. Thanks again! ", "Are you satisfied with the resolution of your issue?<br> [Yes](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30036)<br> [No](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30036)\r\n"]}, {"number": 30035, "title": "TF 2.0 tensor.numpy() inside of map() functions", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0.0b1\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, there is no way to get a numpy array from a tensor during graph execution, even if it is well defined. Specifically I am working with a funciton to map to a dataset, where I would like to get the np array from the tensor, however with eager execution disabled (due to static graph execution) it is not possible. There does not appear to be a workaround because the normal workaround in static cases is the py_func() function but that can only return tensors, defeating the purpose in this case.\r\n\r\n**Will this change the current api? How?**\r\nNo significant changes beyond adding a method that would allow for numpy arrays to be returned during a map function. It would likely have to be specific because there are a number of times that one could improperly use this outside of a use case like dataset.map\r\n\r\n**Who will benefit with this feature?**\r\ndevelopers working with custom datasets which require custom mapped functions to interact with other libraries that expect numpy arrays. Definitely a larger number of the research community could make use of this than hobbyist to be sure.\r\n\r\n**Any Other info.**\r\n", "comments": ["Could you please provide an example that illustrates the use case that you would like to support? Thanks.", "Sure, I am looking at some image preprocessing techniques, ideally getting the advantage of preprocessing rather than using the ImageDataGenerator option. In order to do this many libraries would require the numpy array data rather than a tensor. A similar desire, although in a purely TF implementation, was mentioned in this thread: https://twitter.com/pmdanton/status/1144388777235947520. ", "IIUC, [numpy_function](https://www.tensorflow.org/api_docs/python/tf/numpy_function) used within `tf.data.Dataset.map` should address your use case.", "That solves the problem for me, thank you!"]}, {"number": 30034, "title": "bazel 0.26.1 git rules break on Windows", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (build 18912.1001)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nThe default git worker rules from bazel 0.26.1 actually assume bash.  However, Windows 10 with WSL will provide a bash that is a redirection to the default WSL installation.  This is both difficult to track down as well as behaves incorrectly when trying to build TensorFlow for Windows.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n`bazel --config=opt --config=v2 build //tensorflow:...`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["CC: @saeta ", "BTW, it seems that bazel 0.27.0 rewrote the git rules to avoid the inline generated bash script.  This should help, though it seems that the current version for bazel for TensorFlow is 0.26.1.  I'm unfortunately, not familiar enough with bazel to figure out how to override the rules with the one from 0.27.0", "Not sure at all, but it might make more sense to figure out how to upgrade the version of Bazel TensorFlow uses directly to 0.27.0 instead, unless there's something else that's blocking... (Guesses: CI infra, maybe?) ", "Hmm, is there an easy way to check if the infra will support the bump?", "Hmm, not sure. Maybe @gunan might know?", "There is work in progress to upgrade bazel but it is going to take some time as it is currently blocked on another infrastructure release task", "I think this upgrade is complete, I forgot to update this issue when we fixed the problem. Closing.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30034\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30034\">No</a>\n"]}, {"number": 30033, "title": "Update install_python3.6_pip_packages.sh to use apt.", "body": "Now python3.6 can be installed from apt and it will be installed with\r\nall submodules.\r\n\r\nIf we're compiling Python from source, during compilation we get:\r\n\r\n```\r\nThe necessary bits to build these optional modules were not found:\r\n_bz2                  _dbm                  _gdbm\r\n_lzma                 _sqlite3              _tkinter\r\nreadline\r\n```\r\n\r\nwhich then results in\r\n\r\n```\r\n==================== Test output for //bazel_pip/tensorflow/contrib/summary:summary_ops_test:\r\nRunning test /tmpfs/src/github/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_kbuilder/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/bazel_pip/tensorflow/contrib/summary/summary_ops_test.runfiles/org_tensorflow/bazel_pip/tensorflow/contrib/summary/summary_ops_test  on GPU 0\r\nTraceback (most recent call last):\r\n  File \"/tmpfs/src/github/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_kbuilder/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/bazel_pip/tensorflow/contrib/summary/summary_ops_test.runfiles/org_tensorflow/bazel_pip/tensorflow/contrib/summary/summary_ops_test.py\", line 23, in <module>\r\n    import sqlite3\r\n  File \"/usr/local/lib/python3.6/sqlite3/__init__.py\", line 23, in <module>\r\n    from sqlite3.dbapi2 import *\r\n  File \"/usr/local/lib/python3.6/sqlite3/dbapi2.py\", line 27, in <module>\r\n    from _sqlite3 import *\r\nModuleNotFoundError: No module named '_sqlite3'\r\n================================================================================\r\n```\r\n\r\nand similar failures which then block releasing patch version.", "comments": []}, {"number": 30032, "title": "build: introduce `configure.cmd`", "body": "This adds a batch file to invoke the python configure script on Windows.\r\nThis mirrors the script for Linux and macOS (`configure`).  This is\r\nneeded since Windows does not support shebangs, and will not invoke the\r\npython script as a result without the explicit interpreter.", "comments": ["CC: @saeta @bgogul "]}, {"number": 30031, "title": "Update ModelCheckpoint callback in callbacks.py", "body": "See #29958 : Suggested improvements:\r\n\r\n* _Clarified and expanded the ModelCheckpoint callback description_:\r\n`ModelCheckpoint` does not just \"save after each epoch\" - it can be customized.\r\n\r\n* _Add a ModelCheckpoint example_:\r\nAn example showing how to save checkpoints with weights only after 1 epoch and load weights for a new model with `tf.train.latest_checkpoint`. Used the following tutorial as a reference: _Save and Restore Models_ [r1.14](https://www.tensorflow.org/tutorials/keras/save_and_restore_models) and [r2.0](https://www.tensorflow.org/beta/tutorials/keras/save_and_restore_models)\r\n\r\nAny questions, suggestions, fixes, clarifications welcome!", "comments": ["@rthadur Hi, just checking if this is still alright. Thanks a million", "> Thanks for the request!\r\n\r\nRevised, thank you @rchao \ud83d\udc4d", "Can one of the admins verify this patch?", "@8bitmp3 Could you please check build failures and resolve the conflicts? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on."]}, {"number": 30030, "title": "[ROCm] Fix for the broken `--config=rocm` build", "body": "The `--config=rocm` build was broken by the following commit\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/3e3b915613637e5fae14dafe2de6b8525c866242\r\n\r\nThe above commit contains update for CUDA implementation of GPU stream executor code, but not for the corresponding ROCm implementation. This commit adds in the missing ROCm piece.\r\n\r\n-----------------------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n", "comments": []}, {"number": 30029, "title": "Autoconversion to Tensor in functions", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 19.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary, pip\r\n- TensorFlow version (use command below):1.14.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\ncalling certain functions with non-Tensors (but convertible to) fails, since the object is not converted to a tensor. The function actually only expect Tensors.\r\n\r\ne.g. `tf.math.real(1.0)` fails because `1.` has no attribute dtype (which it will only have after the conversion to a tensor).\r\n\r\n**Describe the expected behavior**\r\n(My understanding goes that:) functions that take Tensors, such as `tf.math.real`, can also take anything that can be converted to a Tensor, such as Python floats or objects with a registered conversion function. Namely,\r\n```\r\ntf.math.real(tf.convert_to_tensor(something))\r\ntf.math.real(something)\r\n```\r\nare _equivalent_.\r\n\r\nI would expect `tf.math.real(1.)` to return the real part of the tensor `tf.convert_to_tensor(1.)`.\r\n\r\nThis causes a big problem with the (actual beautiful!) registration of conversion functions. The code contains only a minimal example.\r\n\r\nAm I mistaken with the expected behavior? And if so, this may could be made clear in the docs, that _only_ Tensors are taken vs Tensor-like objects. E.g. the docs of `tf.math.round` and `tf.math.real` leave no clue in which to use tensors and in which Tensor-like objects.\r\n\r\n**Code to reproduce the issue**\r\nshort version\r\n```\r\nreal_python = tf.math.real(1.)  # <- fails\r\n```\r\nbut of course also fails for any custom defined Tensor-like object\r\n```\r\nfrom tensorflow.python import ops\r\n\r\nclass MyTensor():\r\n    def _dense_var_to_tensor(self, dtype, name, as_ref):\r\n        return tf.constant(42, dtype=dtype)\r\n\r\n\r\ndef _dense_var_to_tensor(var, dtype=None, name=None, as_ref=False):\r\n    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)\r\n\r\n\r\nops.register_tensor_conversion_function(MyTensor, _dense_var_to_tensor)\r\n\r\nmy_t1 = MyTensor()\r\nt1 = tf.convert_to_tensor(my_t1)  # <- works\r\nsquare = tf.math.round(my_t1)  # <- works\r\nreal_python = tf.math.real(1.)  # <- fails\r\nreal = tf.math.real(my_t1)  # <- fails\r\n```\r\n\r\n", "comments": ["Added a PR #30049 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30029\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30029\">No</a>\n"]}]