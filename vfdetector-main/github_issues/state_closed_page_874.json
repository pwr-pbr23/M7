[{"number": 27274, "title": "Integration of CMSIS-NN API to TFLu", "body": "This is a first step towards integrating CMSIS-NN optimized kernel implementations into TFLu.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27274) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!\r\n", "I added my work email.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27274) for more info**.\n\n<!-- ok -->", "Sounds good! ", "@freddan80 please resolve conflicts", "I will fix it", "Reverted back to original change. No need to review this", "Ready for review"]}, {"number": 27273, "title": "TF Lite zeros_like_test death test case added", "body": "Unsupported validation test case added for zeros_like operator", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27273) for more info**.\n\n<!-- need_author_consent -->", "Corrupt PR is replaced with #27372"]}, {"number": 27272, "title": "ImportError: Missing module: '_pywrap_tensorflow_internal' [Win10][tf-cpu]", "body": "**System information**\r\n- **Top-level directory**: C:\\Users\\user\\Documents\\GitHub\\pysc2-examples\r\n- **OS Platform and Distribution**: Windows 10\r\n- **TensorFlow installed from**: pip\r\n- **TensorFlow version installed** (as of publising the issue): tensorflow-cpu 1.12.0\r\n- **Python version**: 3.6.3\r\n- **Installed using virtualenv? pip? conda?**: Using pip\r\n- **Bazel version**: Not used (it doesn't seem to be required?)\r\n- **GCC/Compiler version (if compiling from source)**: Not used (it doesn't seem to be required?)\r\n- **CUDA/cuDNN version**: Not used (it doesn't seem to be required?)\r\n- **GPU model and memory**: Intel Graphics HD 4000, 4GB RAM\r\n- **CPU model**: Intel Core i3-3217U\r\n\r\nAfter successfully installing tensorflow and the aforementioned project, after running the aforementioned command, this stacked trace is put out:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train_mineral_shards.py\", line 5, in <module>\r\n    from baselines import deepq\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\baselines\\deepq\\__init__.py\", line 1, in <module>\r\n    from baselines.deepq import models  # noqa\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\baselines\\deepq\\models.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\nA similar stack trace appears when Tensorflow is imported on python, even when *the current directory is different from where I installed the project*:\r\n\r\n```\r\nC:\\> python\r\nPython 3.6.3 (v3.6.3:2c5fed8, Oct  3 2017, 17:26:49) [MSC v.1900 32 bit (Intel)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\nSimilar issues have been published, though there is no simple solution to this problem, and all workarounds seem to be outdated, one way or another.\r\n\r\nOne of the most notable differences from other similar issues, though,  is that **I don't have a problem with the DLL file**, as I have the latest Microsoft Visual C++ [2015 and 2017] Redistributable [x64 and x86]. I have tried to follow the stack trace to where it triggers, and it's this `Path Error` that is being triggered inside `pywrap_tensorflow_internal.py`. I have tried to inspect the **apparently not missing** `_pywrap_tensorflow_internal.so` to no avail.", "comments": ["@ThGkasios Could you uninstall python and tensorflow from the system, restart computer, and follow steps 3,4, and 5 from [here](https://github.com/jvishnuvardhan/Installing-TensorFlow-GPU-on-Windows-10-TF1.12). Then, Open a command prompt and type \"pip install tensorflow==1.12.0\". This should install tensorflow. Please let me know how it progresses. Thanks!", "Hello, and thank you for the response!\r\n\r\nSince publishing this issue, I have **updated my python 3.6 to specifically 3.6.8 64-bit**, installed **all of Microsoft Visual C++ [2015/2017] Redistributable [x64/x86]**, and for good measure, downloaded Visual Studio 2017.\r\n\r\nFor a bit, I had shelved my project (that required 3.6) to have a look on 3.7, and I 've just reverted back.\r\n\r\nAfter running everything as administrator and a couple restarts, tensorflow is imported successfully on my system when I call it on the python IDLE terminal.\r\n\r\nMany thanks for the guide!\r\n\r\nOn the same note, I'd like to know whether Bazel is required to run tensorflow projects. It seems madatory, but is nowhere to be found as a prerequisite", "@ThGkasios Good to know that the instructions helped you. \r\nIf you want to build TensorFlow from source, then you need Bazel. Otherwise, you don't need Bazel. I don't have Bazel on my system as I installed TF using binaries. \r\nPlease close the issue if there is no issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27272\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27272\">No</a>\n"]}, {"number": 27271, "title": "[XLA] Add a SliceDelaying pass which delaying the spliting-slice", "body": "In Hlo DAG, the parameters sometimes split to many tensors to do the same operations. Delaying the tensor split until the same operation is done will make the DAG simpler and code generation more efficient.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27271) for more info**.\n\n<!-- need_sender_cla -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n>  **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\r\n> \r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> ##### Corporate signers\r\n> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\r\n> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n>  **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27271) for more info**.\r\n\r\nI signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27271) for more info**.\n\n<!-- ok -->", "@jlebar \r\nHi Justin,\r\n\r\nWish this could be a starting point to push more of our code back to community.\r\n\r\nThanks.", "Before Pass:\r\n![image](https://user-images.githubusercontent.com/41858707/55217047-686b8080-5239-11e9-9ddc-43aec85e7b56.png)\r\n\r\nAfter Pass:\r\n![image](https://user-images.githubusercontent.com/41858707/55217110-94870180-5239-11e9-80fb-e0a4760f2ad0.png)\r\n\r\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27271) for more info**.\n\n<!-- need_author_cla -->", "> We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors. If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)? If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\r\n> In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\r\n> \r\n>  **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27271) for more info**.\r\n\r\nI signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27271) for more info**.\n\n<!-- ok -->", "Hi Justin,  thanks for your suggestions.\r\n\r\nThis is our algorithm. \r\nFirstly, the instructions are traversed in post order. It is guarantee the operands of the instruction will be traverse before the instruction. \r\nThen, we choose the instructions (the selected instruction) whose operands are all slice instructions, and reserve the operands of the slices in a vector(<vector>operands). these operands of slices are the true operands of the selected instruction. It is implemented in function GetTrueOperands.\r\nAnd then, we find the peers of the instruction. Here, peers are the instructions which have the same true operands in the same order as the selected instruction. Additionally, the peer's operands should slice from the same location in the output tensor of true operands. The selected instruction and its peers are keep in a vector(<vector>users). It is implemented in function GetTrueUsers.\r\nThen, We calculate the cost of slice-delaying in function ShouldReplace. If the total of slice elements are not less than the elements of the true operand, slice-delaying should be implemented for this operation.\r\nAt last, the implement of the slice-delaying on the selected instruction and its peers is in function GenerateNewOp.\r\n\r\nAdditionally, we collected the dead instructions which generated in this pass, and keep them in a set(<set> removed_). These dead instructions' operands are kept in another set(<set> slices_), because these slices instruction may be dead instruction too.\r\nIn order to reduce the redundant visits to the peers, we also use a set(<set> visited_)  to record the visited instructions, and skip them in later traverse.\r\n\r\nPlease let me know if you have any questions.", "@jlebar \r\n\r\nHi justin,\r\n\r\nSorry for a little bit delay. We have made refinement of this PR and please take another round of review.\r\n\r\nThanks.", "@jlebar\r\nIt is right.\r\nActually, situation 2 \"adjacent slice\" is a special case. We just consider the total elements in the slice instructions which could be moved \"down\". If the total elements are more than the elements in the original operation, there must be redundant work, and vice versa.\r\nAs you said, it will simplify the graph that the slice instructions are moved \"down\", even no matter what kind of slice(split-slice, stride-slice or others). Eventually, the simpler graph will be transformed to fewer kernels on GPU backend, or simpler loops on CPU backend. \r\n\r\nIt could simplify the graph that any kind of slice is moved \"down\", but what kind of slice instruction could be move \"down\"? The op's operands, which are sliced from the same range of \"true operands\"! So, it need to check every operand's slice_starts, slice_limits and slice_strides.", "@bixia1 volunteered to help out with this review as well.", "Aah, that's silly of me.  Thanks.\n\nOn Tue, Apr 23, 2019 at 6:30 PM Xinan Jiang(\u59dc\u66e6\u6960) <notifications@github.com>\nwrote:\n\n> *@xinan-jiang* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/compiler/xla/service/slice_delaying_test.cc\n> <https://github.com/tensorflow/tensorflow/pull/27271#discussion_r277926532>\n> :\n>\n> > +      s01 = f32[6,8] slice(f32[8,8] p0), slice={[2:8], [0:8]}\n> +      s10 = f32[2,8] slice(f32[8,8] p1), slice={[0:2], [0:8]}\n> +      s11 = f32[6,8] slice(f32[8,8] p1), slice={[2:8], [0:8]}\n> +      add0 = f32[2,8] add(f32[2,8] s00, f32[2,8] s10)\n> +      add1 = f32[6,8] add(f32[6,8] s01, f32[6,8] s11)\n> +      ROOT tuple = (f32[2,8], f32[6,8]) tuple(add0, add1)\n> +    }\n> +  )\";\n> +  TF_ASSERT_OK_AND_ASSIGN(auto module,\n> +                          ParseAndReturnVerifiedModule(kModuleStr));\n> +  EXPECT_EQ(9, module->entry_computation()->instruction_count());\n> +  SliceDelaying slice_delaying;\n> +  TF_ASSERT_OK_AND_ASSIGN(bool result,\n> +                          RunHloPass(&slice_delaying, module.get()));\n> +  EXPECT_TRUE(result);\n> +  EXPECT_EQ(6, module->entry_computation()->instruction_count());\n>\n> slices are different, but adds are the same.\n> the add is generated here only once:\n> auto new_user = computation->AddInstruction(\n> users[0]->CloneWithNewOperands(shape, operands));\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/27271#discussion_r277926532>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABEZBZ64GWEA44TJTCBNPLPR6ZZ3ANCNFSM4HCGP6ZQ>\n> .\n>\n", "Bixia, Thanks for your quick review.\r\n\r\nternary operators UT is really a good idea. It makes this pass more general. Thanks!\r\n"]}, {"number": 27270, "title": "[TF 2.0] two issues on v2 ctc_loss", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.5.2\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Tesla V100, 32Gb\r\n\r\n\r\n**Describe the current behavior**\r\n Hi, I'am working on a project and trying to migrate my code to use tf 2.0 preview, and discovered two issues using `ctc_loss`. One is about a missing keyword argument from v2, and the other is about weird behavior of gradient using v1. \r\n\r\n Current version of `tf.nn.ctc_loss` raises an exception when it encounters outputs longer than label, saying that `ignore_longer_outputs_than_inputs` flag should be used to turn this exception into a warning. However, I noticed that this keyword argument was deleted from new version.\r\n \r\nHence I just decided to go back to v1 but another issue came out, which is model being trained to predict blank tokens only, just after one iteration. I'm aware that this could have happened due to other parts of my code, but I'm reporting this after several tests on that.   \r\n\r\n**Describe the expected behavior** \r\n The `ignore_longer_outputs_than_inputs` keyword should be added to the new `ctc_loss`, or set True by default. \r\n\r\n\r\n**Code to reproduce the issue**\r\nI will provide code later in the comment\r\n\r\n**Other info / logs**\r\n```\r\n2019-03-29 13:38:40.841685: W tensorflow/core/framework/op_kernel.cc:1431] OP_REQUIRES failed at ctc_loss_op.cc:168 : Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n2019-03-29 13:38:40.841912: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n         [[Adam/group_deps/_1107]]\r\n2019-03-29 13:38:40.841981: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n         [[Adam/update_2_1/AssignAddVariableOp/_1091]]\r\n2019-03-29 13:38:40.842035: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Adam/update_2_1/Const/_1063]]\r\n2019-03-29 13:38:40.842177: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n         [[Adam/group_deps/_1103]]\r\n2019-03-29 13:38:40.848029: E tensorflow/core/common_runtime/process_function_library_runtime.cc:764] Component function execution failed: Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Adam/update_2_1/Const/_1063]]\r\n2019-03-29 13:38:40.848362: E tensorflow/core/common_runtime/process_function_library_runtime.cc:764] Component function execution failed: Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n         [[Adam/group_deps/_1107]]\r\n2019-03-29 13:38:40.850240: E tensorflow/core/common_runtime/process_function_library_runtime.cc:764] Component function execution failed: Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n         [[Adam/group_deps/_1103]]\r\n2019-03-29 13:38:40.852283: E tensorflow/core/common_runtime/process_function_library_runtime.cc:764] Component function execution failed: Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n         [[Adam/update_2_1/AssignAddVariableOp/_1091]]\r\n2019-03-29 13:38:40.867602: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n2019-03-29 13:38:40.881608: E tensorflow/core/common_runtime/process_function_library_runtime.cc:764] Component function execution failed: Invalid argument: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 196, in <module>\r\n    exp_fn = main(args, CONFIG)\r\n  File \"train.py\", line 120, in main\r\n    distributed_train()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/def_function.py\", line 414, in __call__\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\", line 1288, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\", line 574, in _filtered_call\r\n    (t for t in nest.flatten((args, kwargs))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\", line 627, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\", line 415, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Not enough time for target transition sequence (required: 49, available: 48)32You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\r\n         [[{{node replica_2/CTCLoss}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Adam/update_2_1/Const/_1063]] [Op:__inference_distributed_train_49990]\r\n```", "comments": [" loss, _ = gen_ctc_ops.ctc_loss(\r\n      inputs,\r\n      labels.indices,\r\n      labels.values,\r\n      sequence_length,\r\n      preprocess_collapse_repeated=preprocess_collapse_repeated,\r\n      ctc_merge_repeated=ctc_merge_repeated,\r\nignore_longer_outputs_than_inputs=ignore_longer_outputs_than_inputs)\r\n\r\nyou want this to be :\r\n\r\n loss, _ = gen_ctc_ops.ctc_loss(\r\n      inputs,\r\n      labels.indices,\r\n      labels.values,\r\n      sequence_length,\r\n      preprocess_collapse_repeated=preprocess_collapse_repeated,\r\n      ctc_merge_repeated=ctc_merge_repeated,\r\nignore_longer_outputs_than_inputs=True)", "I think that will work for my case but will make `ignore_longer_outputs_than_inputs=False` not working in v1 ctc loss. \r\n", "@SunQpark This is a stale issue. Can you try recent TF version (`TF2.0.0rc2` or `tf-nightly-2.0-preview`) and let us know if the issue still persists. If the issue is there, could you please share a small standalone code to reproduce the issue? If this was resolved, please close the issue. Thanks!", "`ignore_longer_outputs_than_inputs` is still not there, but this could be considered as a reasonable decision. For the second point, model could be trained properly with ctc loss in recent `TF2.0.0rc2` version.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27270\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27270\">No</a>\n"]}, {"number": 27269, "title": "[doc] broken link in tf.logging", "body": "\r\n**System information**\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/logging\r\n\r\n\r\n**Describe the documentation issue**\r\n> Defined in **tensorflow/_api/v1/logging/ _ _ init _ _.py**.\r\n\r\nThe link for _ _ init _ _.py is broken: https://www.tensorflow.org/code/stable/tensorflow/_api/v1/logging/__init__.py\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/logging", "comments": ["what is its original link\r\n", "@shashvatshahi1998 \r\n\r\nyou can click the links of other functions in the same page and you'll find the expected link.\r\nThen a pullrequest.", "So we have to just put the correct link for tf.logging in tensorflow guide, thats the only issue???", "There is a file for changing links and I am not getting the link of that sheet where we can edit the link which is on the guide page of tf.logging", "Actually tf.logging is removed in new version of TF that is 2.0.0 so that's why the link their is of no use as tensorflow is focussing to change complete documentation for TF2.0. You can also refer to issue #26662", "@csukuangfj   Thanks for bringing this to our notice. We will take a look and resolve it. Thanks!", "For me, except __init__.py link (https://www.tensorflow.org/code/stable/tensorflow/_api/v1/logging/__init__.py) everything else is working. Thanks!", "Faced no logging module in tensorflow 2.0, which is obvious. Any update on this? \r\nAnd if logging is not available in tensorflow 2.0 what is the alternative for logging, pure python logging? ", "> pure python logging?\r\n\r\nI think that's it, or absl_py logging?"]}, {"number": 27268, "title": "if I use feature_column.embedding_column, how to get embedding variables?", "body": "```\r\nuid = fc.categorical_column_with_hash_bucket(\"uid\", 10000, dtype=tf.int64)\r\nitem_id = fc.categorical_column_with_hash_bucket(\"item_id\", 10000, dtype=tf.int64)\r\nuid_embed = fc.embedding_column(uid, 64)\r\nitem_id_embed = fc.embedding_column(item_id, 64)\r\n```\r\nI want to extract the embedding matrix for other task, how to implement this idea?", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Any idea on this problem? Is it solved"]}, {"number": 27267, "title": "TensorFlow 1.x to TensorFlow 2.x", "body": "tf.contrib.training.HParams is TensorFlow 1.x\r\nHow can I use tf.contrib.training.HParams in 2.x?", "comments": ["import tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\n\r\nThis is the way in which you can use this function in tensorflow 2.x.", "WOW, Thank you!!", "Is `tf.contrib.training.HParams` getting removed from tf 2.0 completely? Is there an alternative in 2.0?", "@shafi-dayatar \r\n\r\n```\r\n    hparams = tf.contrib.training.HParams(\r\nAttributeError: module 'tensorflow.compat.v1' has no attribute 'contrib'\r\n```", "Yes I need help with this aswell\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\ndoesnt work for me", "same here tf.disable_v2_behavior() is not working ? "]}, {"number": 27265, "title": "Download Images fail: Get curl: (23) Failed writing body (0 != 2696)", "body": "<em>Tried to follow the tutorial: TensorFlow For Poets, but failed to download images on the second step\r\n</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: Not related\r\n- Doc Link: https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#2\r\n\r\n\r\n**Describe the documentation issue**\r\nI used the command copied from tensor document: [TensorFlow For Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#2)\r\n\r\nThe commond is `curl http://download.tensorflow.org/example_images/flower_photos.tgz | tar xz -C tf_files`\r\nThen I got curl: (23) Failed writing body (0 != 2696)\r\n", "comments": ["Found the cause: Personal Hotspot doesn't support such a large amount of images downloading."]}, {"number": 27264, "title": "[Intel MKL] Enable FusedBatchNormV2 and its grad operator via MKL-DNN\u2026", "body": "\u2026 API\r\n\r\nThis PR enables FusedBatchNormV2 and its grad operator with MKL-DNN API.\r\nIt makes necessary changes in the layout pass to rewrite original\r\nFusedBatchNormV2 (and grad) into MKL-equivalent operator (and grad).", "comments": ["@penpornk Thanks for review. Yes, the only difference is in types. Pls check the definition below.\r\n\r\n```\r\nREGISTER_OP(\"FusedBatchNorm\")\r\n    .Input(\"x: T\")\r\n    .Input(\"scale: T\")\r\n    .Input(\"offset: T\")\r\n    .Input(\"mean: T\")\r\n    .Input(\"variance: T\")\r\n    .Output(\"y: T\")\r\n    .Output(\"batch_mean: T\")\r\n    .Output(\"batch_variance: T\")\r\n    .Output(\"reserve_space_1: T\")\r\n    .Output(\"reserve_space_2: T\")\r\n    .Attr(\"T: {float}\")\r\n    .Attr(\"epsilon: float = 0.0001\")\r\n    .Attr(GetConvnetDataFormatAttrString())\r\n    .Attr(\"is_training: bool = true\")\r\n    .SetShapeFn(shape_inference::FusedBatchNormShape);\r\n```\r\n\r\n```\r\nREGISTER_OP(\"FusedBatchNormV2\")\r\n    .Input(\"x: T\")\r\n    .Input(\"scale: U\")\r\n    .Input(\"offset: U\")\r\n    .Input(\"mean: U\")\r\n    .Input(\"variance: U\")\r\n    .Output(\"y: T\")\r\n    .Output(\"batch_mean: U\")\r\n    .Output(\"batch_variance: U\")\r\n    .Output(\"reserve_space_1: U\")\r\n    .Output(\"reserve_space_2: U\")\r\n    .Attr(\"T: {half, bfloat16, float}\")\r\n    .Attr(\"U: {float}\")\r\n    .Attr(\"epsilon: float = 0.0001\")\r\n    .Attr(GetConvnetDataFormatAttrString())\r\n    .Attr(\"is_training: bool = true\")\r\n    .SetShapeFn(shape_inference::FusedBatchNormShape);\r\n```"]}, {"number": 27263, "title": "[Intel MKL] Fix int8 convolution accuracy and add back mkl_conv_ops_test", "body": "", "comments": ["closing temporarily."]}, {"number": 27262, "title": "How to get Gather instead of GatherV2 in GraphDef?", "body": "Tried to use \"tf.gather\", each time when I export GraphDef, just saw op GatherV2, so how could I get Gather in graphdef?", "comments": ["code snippet:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nindices = tf.constant([0, 1, 1])\r\nx = tf.constant([[1, 2, 3],\r\n                 [4, 5, 6],\r\n                 [7, 8, 9]])\r\n\r\nresult = tf.gather(x, indices, axis=1)\r\n\r\nwith tf.Session() as sess:\r\n    out = sess.run(result)\r\n    print(out)\r\n    print(sess.graph_def)\r\n```", "Seems if using old tf version like 1.5, Gather will be used instead for same graph definition. Does that mean Gather is never used in TF new versons like 1.9+?", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "posted it is stackoverflow - https://stackoverflow.com/questions/55484373/how-to-get-gather-in-graphdef", "@yongwww Thank you very much.", "reopen it since nobody responds to the question on stackoverflow. ", "if we can not find the Gather anymore, it should be removed", "Same questions for Zeros, Ones, ZerosLike, OnesLike", "TensorFlow at one point changed to emit GatherV2 in GraphDef instead of Gather, because GatherV2 has correct shape inference, and changing the shape inference behavior of Gather could have broken existing graphs.\r\n\r\nIn general the set of ops emitted by TensorFlow for a given set of python API calls is not fixed, and can change from version to version.\r\n\r\nIf you rely on downstream processing of TensorFlow ops I recommend you use our [compat module](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/compat/compat.py) to run nightly tests against future versions of TensorFlow's graph emitting code."]}, {"number": 27261, "title": "OOM error", "body": "```\r\n2019-03-28 20:17:05.067925: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[612,612,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 \r\nby allocator cpu\r\nTraceback (most recent call last):\r\n  File \"/home/models/TF-2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/home/models/TF-2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/models/TF-2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[427,640,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\r\n         [[{{node rgb_to_grayscale/convert_image/Cast}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[{{node superpoint/IteratorGetNext}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[{{node superpoint/vgg/conv1_1/bn/beta/read}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"experiment.py\", line 148, in <module>\r\n    args.func(config, output_dir, args)\r\n  File \"experiment.py\", line 86, in _cli_train\r\n    train(config, config['train_iter'], output_dir)\r\n  File \"experiment.py\", line 27, in train\r\n    keep_checkpoints=config.get('keep_checkpoints', 1))\r\n  File \"/home/models/codes/SuperPoint/superpoint/models/base_model.py\", line 313, in train\r\n    options=options, run_metadata=run_metadata)\r\n  File \"/home/models/TF-2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/home/models/TF-2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/models/TF-2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/home/models/TF-2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[427,640,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\r\n         [[{{node rgb_to_grayscale/convert_image/Cast}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node superpoint/IteratorGetNext (defined at /home/models/codes/SuperPoint/superpoint/models/base_model.py:260) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n```\r\n\r\nTF version: 1.13.1\r\ncudnn: 7\r\ncuda: 10.0\r\n\r\nQuestion: I do not understand what is meaning of it. Is GPU memory exhausted. Which is api by which I can change policy of cacheing etc.", "comments": ["Hello, some points for your issue:\r\nFirst of all, please use the issue templates\r\nSecond, you're using a CPU to train not a GPU as this line states ```/job:localhost/replica:0/task:0/device:CPU:0```\r\n\r\nIf you want to use the GPU install tensorflow-gpu by running \r\n`pip uninstall tensorflow & pip install tensorflow-gpu`\r\n\r\nThe problem seems to be that your ram is getting filled, you can reduce the batch size so the data will fit into your RAM.", "Please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md). Could you update them if they are relevant in your case, or leave them as N/A? Along with the template, please provide as many details as possible to find the root cause of the issue. It would be great if you can provide a small code to reproduce the error. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "let me point out the detail code ....\nthe policy I adapted for memory allocation during training was using CPU\nmemory for augmented data to appear in ram and batches come in GPU memory\nsequentially.\nhttps://github.com/Exception4U/SuperPoint/blob/491189c96c9561c1829eeeb45890a70436ae2d49/superpoint/datasets/base_dataset.py#L109\nit seems to me that even if the ram is getting filled Virtual memory could\nbe used. which is not observed.\n\n--\nTushar\n\n\n\nOn Sat, Apr 20, 2019 at 6:23 PM Alfred Sorten Wolf <notifications@github.com>\nwrote:\n\n> It has been 14 days with no activity and the awaiting response label was\n> assigned. Is this still an issue?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/27261#issuecomment-485112389>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABKAWVIN2MEQTG3VM2IMMT3PRMG3ZANCNFSM4HCERFWQ>\n> .\n>\n", "@Exception4U \r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!"]}, {"number": 27260, "title": "tensorflow.keras model.fit_generator not working with use multiprocessing", "body": "I am using Ubuntu 18 with conda and python 3.6 with tf 1.20 GPU over a gtx 1070 and 2080ti\r\n\r\nWhen I am using this code \r\n\r\n    model.fit_generator(i, epochs=1, workers=16,\r\n                            use_multiprocessing=False, max_queue_size=16,\r\n                            verbose=1)\r\n\r\nIt works fine\r\n\r\nWhen I change use_multiprocessing to True, and run, it does nothing, the cpu is not utilized by python at all, and nothing shows on the monitor. It used to work fine in the past. \r\n\r\nWhat am I missing here? ", "comments": ["@thebeancounter Since you mentioned that ```use_multiprocessing``` was working for you in the past. So did you recently updated your configuration or updated the code that caused change in the behavior? Can you please add a little bit context here? Thanks!", "@ymodak \r\nI am afraid I do not have the record of the working code and system settings and was not able to reproduce a working environment.", "Okay. I see you have mentioned that you are using TF 1.20. Is there a possibility for you to switch to latest version of TF and try again?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I was getting an error trying to use fit_generator and one of the strategies in tf.distribute.Strategy and came across this thread.  So it looks like use_multiprocessing as well as any tf strategies that use multiple workers/GPUs does not work with fit_generator.\r\n\r\nWhat would be the best solution here?  Do I have to change my generator to a tf.Dataset object?", "@thebeancounter have you solved this problem?", "I am facing the same issue here, was using tf.keras use_multiprocessing=True in my fit_generator function without any issues, came back few month later and now nothing runs, exactly as @thebeancounter mentioned. only difference is that I used to use TF 1.12 together with Cuda9.2 and also the corresponding drivers. Now I have only updated TF to 1.14 together with Cuda10.1, nothing else has changed."]}, {"number": 27259, "title": "r1.13 multi-gpu towering fails due to DeviceSpec parsing during model creation", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): This is a custom written yolov3 model written primarily with the tf.layers api which is soon to deprecated. \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 & Power9\r\n- TensorFlow installed from (source or binary): compiled from r1.13 source branch and Conda tensorflow-gpu package from https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 0.18.1\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: Cuda 10.0 CuDNN 7.5 NCCL 2.4\r\n- GPU model and memory: GT 1080 Ti 12GB and V100 16GB\r\n\r\n**Describe the current behavior**\r\nUnder Tensorflow r1.13 my single node multi-gpu training code produces a \r\n```\r\nsplits = [x.split(\":\") for x in spec.split(\"/\")]\r\nAttributeError: 'DeviceSpec' object has no attribute 'split'\r\n```\r\n\r\nError when constructing the model, before a single forward pass has happened.\r\n\r\nThe towering code I am using is based on the cifar10_multi_gpu_train.py example:\r\nhttps://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py\r\n\r\n**Describe the expected behavior**\r\nMy codebase works correctly on Tensroflow r1.12\r\n\r\nGiven the error and my reading of the tensorflow source code throwing the error, my best guess is some op is missing/has a malformed device_spec, or a deivce_spec object is being passed into the `DeviceSpec().parse_from_string(spec)` function. \r\n\r\nThe layer that seems to be generating this (see trace below) is \r\n```\r\ntf.layers.conv2d_transpose\r\n``` \r\n\r\nI am using several: `tf.device('/cpu:0')` and `tf.device('/gpu:#')` statements to control the placement of ops within different towers onto specific devices. and the problematic `tf.layers.conv2d_transpose` is happening once per tower under a \r\n```with tf.device('/gpu:#'):``` However, if this error were tied to my mishandling of those control statements the many layers of the model that get added before `tf.layers.conv2d_transpose` would have caused an error. \r\n\r\nThese issues in the past seem somewhat relevant, but they all refer to much older source code for tensorflow, and this is a change since r1.12. So I am not putting much stock in any of the discussion from these issues:\r\n- https://github.com/keras-team/keras/issues/10008\r\n- https://github.com/keras-team/keras/issues/10490\r\n\r\nDoes anyone have any pointers where I could look for solutions? My entire codebase will be shifting to tf2.0 api once thats out of alpha. However, it is my understanding that model data parallel training is not fully operational at this time for custom models (non tf.keras.models.Sequential models).\r\n\r\n**Other info / logs**\r\n```\r\nCreating model\r\nBuilding model towers\r\n  tower 0\r\n    building feature map\r\nshutdown complete\r\n  File \"train_yolo.py\", line 348, in <module>\r\n    train_model()\r\n  File \"train_yolo.py\", line 169, in train_model\r\n    train_op, all_loss_total_op, all_loss_xy_op, all_loss_wh_op, all_loss_objectness_op, all_loss_class_op, ops_per_gpu, train_init_op, test_init_op, is_training_placeholder = yolov3.build_towered_model(train_reader, test_reader, GPU_IDS, LEARNING_RATE)\r\n  File \"/fs/wrk/mmajursk/yolov3/src/yolov3.py\", line 562, in build_towered_model\r\n    outputs, total_loss_op, loss_xy_op, loss_wh_op, loss_objectness_op, loss_class_op = tower_loss(image_batch, label_batch, is_training_placeholder)\r\n  File \"/fs/wrk/mmajursk/yolov3/src/yolov3.py\", line 464, in tower_loss\r\n    pred_feature_map, outputs = add_inference_ops(images, is_training=is_training)\r\n  File \"/fs/wrk/mmajursk/yolov3/src/yolov3.py\", line 446, in add_inference_ops\r\n    pred_feature_map = build_feature_maps(images, is_training=is_training)\r\n  File \"/fs/wrk/mmajursk/yolov3/src/yolov3.py\", line 211, in build_feature_maps\r\n    inputs = upsample_2x(inputs)\r\n  File \"/fs/wrk/mmajursk/yolov3/src/yolov3.py\", line 168, in upsample_2x\r\n    trainable=False)  \r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 1279, in conv2d_transpose\r\n    return layer.apply(inputs)\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 832, in call\r\n    dilation_rate=self.dilation_rate)\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 4267, in conv2d_transpose\r\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format, force_transpose)\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 4082, in _preprocess_conv2d_input\r\n    if not _has_nchw_support() or force_transpose:\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 592, in _has_nchw_support\r\n    explicitly_on_cpu = _is_current_explicit_device('CPU')\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 561, in _is_current_explicit_device\r\n    device = _get_current_tf_device()\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 541, in _get_current_tf_device\r\n    graph._apply_device_functions(op)\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4246, in _apply_device_functions\r\n    op._set_device(device_spec.function(op))\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/device.py\", line 314, in _device_function\r\n    current_device = DeviceSpec.from_string(node_def.device or \"\")\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/device.py\", line 232, in from_string\r\n    return DeviceSpec().parse_from_string(spec)\r\n  File \"/home/mmajursk/.conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/device.py\", line 150, in parse_from_string\r\n    splits = [x.split(\":\") for x in spec.split(\"/\")]\r\nAttributeError: 'DeviceSpec' object has no attribute 'split'\r\n```\r\n\r\nThanks for any help/insights you can provide.\r\n~Michael\r\n", "comments": ["This issue has the same cause as #25946: TF1.13 switch the implementation of `tf.layers.conv2d_transpose` to Keras and the new implementation interacts with devices in a wrong way.\r\n\r\nNow I have moved my code to use my own implementation of conv2d_transpose instead while waiting for responses.", "@ppwwyyxx Would you be willing to share your conv2d_transpose code?", "https://github.com/tensorpack/tensorpack/blob/d48cce3aa399db11a4e6fc35a5a896c96a92b641/tensorpack/models/conv2d.py#L205\nIt has quite some dependencies, though", "Probably should have commented here, but alas: \r\nI did a bit of digging and working in https://github.com/tensorflow/tensorflow/pull/23197 including a minimal working example of sorts.", "I believe that this is coming from the fact that `_TfDeviceCaptureOp` is capturing the device as a DeviceSpec, whereas tf Operations capture it as a string. I'm currently working on a cleanup in the device code, and I'll make sure that this gets remedied in that refactor.", "Can you check whether this has been resolved? (You will need a recent tensorflow; for instance building from head or using the latest `tf-nightly-gpu`)", "I was unable to compile from the latest master branch. I got a nccl compile error. The error persisted when I tried to turn on nccl support in the bazel build.\r\n\r\n```\r\nERROR: /home/mmajursk/.cache/bazel/_bazel_mmajursk/6141fa2ddcb6e0f90a8f011edd6ceac9/external/nccl_archive/BUILD.bazel:67:1: error while parsing .d file: /home/mmajursk/.cache/bazel/_bazel_mmajursk/6141fa2ddcb6e0f90a8f011edd6ceac9/execroot/org_tensorflow/bazel-out/host/bin/external/nccl_archive/_objs/device_lib/max_all_reduce.cu.pic.d (No such file or directory)\r\nIn file included from <command-line>:0:0:\r\n/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h:83:10: fatal error: crt/host_config.h: No such file or directory\r\n #include \"crt/host_config.h\"\r\n          ^~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 4.786s, Critical Path: 0.57s\r\nINFO: 29 processes: 29 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nMoving on, I was able to successfully install tf-nightly-gpu into a brand new python venv.\r\n\r\nRunning the same code that generated the original error now results in a different error.\r\n\r\n```\r\nRunning Network\r\n---- Epoch: 0 ----\r\ninitializing training data iterator\r\n   iterator init complete\r\nTraining:\r\nshutdown complete\r\nTraceback (most recent call last):\r\n  File \"/home/mmajursk/envs/tfn/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1339, in _do_call\r\n    return fn(*args)\r\n  File \"/home/mmajursk/envs/tfn/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1324, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/mmajursk/envs/tfn/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1412, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InternalError: No unary variant device copy function found for direction: 1 and Variant type_index: tensorflow::data::(anonymous namespace)::DatasetVariantWrapper\r\n\t [[{{node n/_3}}]]\r\n\t [[tower_0/IteratorGetNext]]\r\n\t [[all_loss_wh/_49]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train_yolo.py\", line 353, in <module>\r\n    train_model()\r\n  File \"train_yolo.py\", line 227, in train_model\r\n    _, loss_total, loss_xy, loss_wh, loss_objectness, loss_class = sess.run([train_op, all_loss_total_op, all_loss_xy_op, all_loss_wh_op, all_loss_objectness_op, all_loss_class_op], feed_dict={is_training_placeholder: True})\r\n  File \"/home/mmajursk/envs/tfn/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 933, in run\r\n    run_metadata_ptr)\r\n  File \"/home/mmajursk/envs/tfn/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1156, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/mmajursk/envs/tfn/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1333, in _do_run\r\n    run_metadata)\r\n  File \"/home/mmajursk/envs/tfn/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1353, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: No unary variant device copy function found for direction: 1 and Variant type_index: tensorflow::data::(anonymous namespace)::DatasetVariantWrapper\r\n\t [[{{node n/_3}}]]\r\n\t [[tower_0/IteratorGetNext]]\r\n\t [[all_loss_wh/_49]]\r\n```\r\n\r\nSince this error is coming from the Dataset api, I think it has to do with API changes breaking my I/O pipeline. So I am cautiously optimistic that the underlying bug is fixed. Unlike before, my training script is able to fully construct the towered network. Previously the error occured during model construction, well before any data was fed into the network. This new error occurs when my first batch of data is being handed to the network, indicating that the model was able to be successfully constructed. \r\n\r\nI don't have time right now to dig into fixing my new error, but I will try to update this post next week if I can work around the new Dataset error.\r\n\r\nThank you\r\n", "@mmajurski Thank you for posting your issue. May I ask if you were able to solve the last error you posted? I am having the same issue.", "I have not been able to solve the error, just work around it. \r\n\r\nMy solution: stick to TF 1.12, and make the jump to TF 2.0.\r\n\r\nI tried a couple of times to see if the bug was fixed in TF, but each time it was still present. I think I tested 2 versions of TF 1.13.", "Thank you @mmajurski. I tested it on TF 1.14 and still no luck on GPU.\r\n\r\nIf it helps, I was able to get my code running on Google's TPU machines. I am not sure if it applies to you, but if you are interested, Google Colab allows you to run your code on a TPU for free. \r\n\r\nhttps://colab.research.google.com/notebooks/tpu.ipynb\r\n\r\nThe instructions are a bit incorrect. You have to click \"Runtime\" -> \"Change runtime type\" and change \"Hardware Accelerator\" to \"TPU\".\r\n\r\nI wish you the best with your app!", "@mmajurski, hi! Could you please provide the workaround?", "@BEEugene My workaround was to never upgrade tensorflow beyond 1.12.\r\n\r\nI also moved to TF2.0 which has an entirely different parallelization mechanism with distribution strategies.", "open  /tensorflow/python/framework/device.py\r\n\r\nchange line314  `current_device = DeviceSpec.from_string(node_def.device or \"\")` to \r\n`current_device = node_def.device if isinstance(node_def.device, DeviceSpec) else DeviceSpec.from_string(node_def.device or \"\")`\r\n", "> open /tensorflow/python/framework/device.py\r\n> \r\n> change line314 `current_device = DeviceSpec.from_string(node_def.device or \"\")` to\r\n> `current_device = node_def.device if isinstance(node_def.device, DeviceSpec) else DeviceSpec.from_string(node_def.device or \"\")`\r\n\r\nThis is the same solution that worked for me https://github.com/tensorflow/tensorflow/pull/23197#issuecomment-478297037", "@mmajurski,\r\n Can we close this issue as it is resolved by using **`Tensorflow Version 2.x`**, as per [this comment](https://github.com/tensorflow/tensorflow/issues/27259#issuecomment-525301138) and as per [this comment](https://github.com/tensorflow/tensorflow/issues/27259#issuecomment-570552675)?", "This issue can absolutely be closed. It was obsoleted with the full transition to Tensorflow 2.x.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27259\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27259\">No</a>\n"]}, {"number": 27258, "title": "Tests for FlatMapDatasetOp", "body": "This PR adds the test for `FlatMapDatasetOp`.\r\n\r\ncc: @jsimsa ", "comments": []}, {"number": 27257, "title": "Fix typo in comment.", "body": "Fix typo \"apecified\" --> \"specified\".", "comments": ["From the Ubuntu Sanity log:\r\n\r\nRuntimeError: The following files are missing load(\"//tensorflow:tensorflow.bzl\", \"py_test\").\r\nThis load statement is needed because otherwise pip tests will try to use their dependencies, which are not visible to them.:\r\n tensorflow/contrib/input_pipeline/BUILD\r\ntensorflow/contrib/periodic_resample/BUILD\r\n\r\nI don't think that's due to my comment change. What do I do now?"]}, {"number": 27256, "title": "Fixed small markdown typos", "body": "Small typos were causing incorrect formatting here:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy", "comments": ["Hey @rthadur can you please give some info about why all the checks are failing and  preventing the merge.", "@Andr0id100 i believe your changes are pushed to r1.13 , so it is failing. do you intend to push your changes to r1.13 or master ?", "It was intended for r1.13.", "Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 27255, "title": "Issues with @tf.function and abstracted classes", "body": "**System information**\r\n- Have I written custom code: YES\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- Mobile device: NO\r\n- TensorFlow installed from (source or binary): PyPI\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.6.4\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nWhen using `@tf.function` on a function that involves abstract classes (e.g. for instance layers or other NN abstractions) Tensorflow fails with the error:\r\n```\r\n2019-03-28 19:44:23.869165: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-03-28 19:44:23.901972: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2693750000 Hz\r\n2019-03-28 19:44:23.902265: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x555bfd2f8e40 executing computations on platform Host. Devices:\r\n2019-03-28 19:44:23.902288: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>\r\nTraceback (most recent call last):\r\n  File \"/home/alex/work/python/simple-kf/tf_git/example.py\", line 87, in <module>\r\n    main()\r\n  File \"/home/alex/work/python/simple-kf/tf_git/example.py\", line 81, in main\r\n    loss = train_one_step(params, data)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 426, in __call__\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 370, in _initialize\r\n    *args, **kwds))\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1313, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1580, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1512, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 694, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 317, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 686, in wrapper\r\n    ), args, kwargs)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 392, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n  File \"/tmp/tmpc8qghhfj.py\", line 6, in tf__train_one_step\r\n    logits, extra = ag__.converted_call(model, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (variables, batch), {'return_inputs': False, 'return_outputs': False})\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 392, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n  File \"/tmp/tmp2wyz0_pd.py\", line 5, in tf____call__\r\n    result, extra = ag__.converted_call('__call__', super(ParametricFunction, self), ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (params, inputs), dict(kwargs, **{'return_inputs': return_inputs, 'return_outputs': return_outputs}))\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 392, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n  File \"/tmp/tmpn16v62zu.py\", line 6, in tf____call__\r\n    retval_ = ag__.converted_call('call', self, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_2, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (params, inputs), dict(kwargs, **{'return_inputs': return_inputs, 'return_outputs': return_outputs}))\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 392, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n  File \"/tmp/tmp43quxi5v.py\", line 3, in tf__call\r\n    raise ag__.converted_call(NotImplementedError, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_2, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_3, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), ('call not implemented for {}.'.format(self.__dict__),), {})\r\nNotImplementedError: call not implemented for {'_name': None, 'initializers': None, 'out_dim': 784}.\r\n```\r\n\r\n**Describe the expected behaviour**\r\nTo work as though if it was run without `@tf.function` (e.g. in Eager Mode).\r\n\r\n**Code to reproduce the issue**\r\n```\r\nfrom abc import abstractmethod\r\nimport tensorflow as tf\r\nimport logging\r\n\r\n\r\nclass Function(object):\r\n    def __init__(self, name=None):\r\n        self._name = name\r\n\r\n    def call(self, params, inputs, **kwargs):\r\n        raise NotImplementedError(\"call not implemented for {}.\".format(self.__dict__))\r\n\r\n    def __call__(self, params, inputs, return_inputs=False, return_outputs=False, **kwargs):\r\n        return self.call(params, inputs,\r\n                         return_inputs=return_inputs,\r\n                         return_outputs=return_outputs,\r\n                         **kwargs)\r\n\r\n\r\ndef expand_bias_to(bias, shape):\r\n    return tf.reshape(bias, [1] * (len(shape) - len(bias.shape)) + bias.shape.as_list())\r\n\r\n\r\ndef call_or_get(maybe_callable, *args, **kwargs):\r\n    if callable(maybe_callable):\r\n        return maybe_callable(*args, **kwargs)\r\n    else:\r\n        return maybe_callable\r\n\r\n\r\nclass ParametricFunction(Function):\r\n    def __init__(self, initializers, name=None):\r\n        super(ParametricFunction, self).__init__(name=name)\r\n        self.initializers = initializers\r\n\r\n    def __call__(self, params, inputs, return_inputs=False, return_outputs=False, **kwargs):\r\n        result, extra = super(ParametricFunction, self). \\\r\n            __call__(params, inputs,\r\n                     return_inputs=return_inputs,\r\n                     return_outputs=return_outputs,\r\n                     **kwargs)\r\n        return result, extra\r\n\r\n    @abstractmethod\r\n    def call(self, params, inputs, **kwargs):\r\n        raise NotImplementedError()\r\n\r\n\r\nclass Affine(ParametricFunction):\r\n    def __init__(self, out_dim,\r\n                 name=None):\r\n        super(Affine, self).__init__(initializers=None, name=name)\r\n        self.out_dim = out_dim\r\n\r\n    def call(self, params, inputs, **kwargs):\r\n        if len(params) == 2:\r\n            w, b = params\r\n            b = expand_bias_to(b, inputs.shape)\r\n        else:\r\n            w, b = params[0], 0\r\n        return tf.matmul(inputs, w) + b, None\r\n\r\n\r\n# !!! IF THIS IS COMMENTED OUT IT WORKS !!!\r\n@tf.function\r\ndef train_one_step(variables, batch):\r\n    model = Affine(784)\r\n    logits, extra = model(variables, batch, return_inputs=False, return_outputs=False)\r\n    loss_value = tf.reduce_mean(logits ** 2)\r\n    return loss_value\r\n\r\n\r\ndef main():\r\n    batch_size = 100\r\n    tf.get_logger().setLevel(logging.WARNING)\r\n    params = (tf.Variable(initial_value=tf.random.normal([784, 784]), name=\"W\"),\r\n              tf.Variable(initial_value=tf.zeros([784]), name=\"b\"))\r\n    data = tf.random.normal([batch_size, 784])\r\n\r\n    for epoch in range(10):\r\n        loss = train_one_step(params, data)\r\n        epoch += 1\r\n        print(\"Epoch {}, loss: {:0.3f}\".format(epoch, loss))\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n**Other info / logs**\r\nThis seems to stem somehow from the inheritance of abstract methods.\r\n", "comments": ["It seems that the error stems from the using calls of the type:\r\n```\r\ndef method(self, ...):\r\n    super(Class, self).method()\r\n```", "I can confirm that error trace with TF2.0.0-alpha0. When I ran with tf-nightly, the error is as follows. \r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-2-f79db8f201dc> in <module>()\r\n     84 \r\n     85 if __name__ == '__main__':\r\n---> 86     main()\r\n\r\n<ipython-input-2-f79db8f201dc> in main()\r\n     80         loss = train_one_step(params, data)\r\n     81         epoch += 1\r\n---> 82         print(\"Epoch {}, loss: {:0.3f}\".format(epoch, loss))\r\n     83 \r\n     84 \r\n\r\nTypeError: unsupported format string passed to Tensor.__format__", "I just ran this in a colab with version 2.0.0-dev20190405 and it runs without an error, so I think this has been fixed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27255\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27255\">No</a>\n"]}, {"number": 27254, "title": "Update tf.shape_v2", "body": "Provides explanation to display in https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/shape", "comments": []}, {"number": 27253, "title": "[CUDA] \u2019tensorflow/core/kernels:cwise_op_gpu\u2019 is not Clang-compatible", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: f09580c8362385f934e7d8321353de06512d92be in master (Date:  Thu Mar 28 02:02:36 2019 -0700)\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: not yet installed\r\n- Bazel version (if compiling from source): 0.24.0\r\n- GCC/Compiler version (if compiling from source): clang r348507-1\r\n- CUDA/cuDNN version: CUDA 10.0, cuDNN 7.5.0\r\n- GPU model and memory: not likely related to the issue\r\n\r\n\r\n\r\n**Describe the problem**\r\nA build process fails every time at the same point '//tensorflow/core/kernels:cwise_op_gpu'.  I suspect the file \"cwise_ops_gpu_common.cu.h\" and/or the related .h file(s) might have an inconsistency.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n## How to reproduce the issue\r\n\r\n**First, change all ${TF_*_VERSION}, ${*_PATH} according to your environment.**\r\n\r\n```console\r\n# Preparation\r\nsudo apt install -y bazel_0.24.0-linux-x86_64.deb\r\nsudo apt install -y apt-utils wget pkg-config ca-certificates apt-transport-https gnupg2 curl liblapack-dev libeigen3-dev git-core subversion automake zlib1g-dev unzip python zip libflann-dev libvtk6-dev cmake libboost-filesystem-dev libboost-date-time-dev libboost-thread-dev libboost-iostreams-dev libboost-system-dev libproj-dev python3-numpy software-properties-common curl libtool\r\nsudo apt-get install /tmp/nv-tensorrt-repo-ubuntu1604-cuda10.0-trt5.0.2.6-ga-20181009_1-1_amd64.deb && \\\r\nsudo apt-key add /var/nv-tensorrt-repo-cuda10.0-trt5.0.2.6-ga-20181009/7fa2af80.pub\r\nsudo apt update && sudo apt install -y tensorrt libnccl2 libnccl-dev\r\n\r\n# Fit these envs\r\n  export PYTHON_BIN_PATH=/usr/bin/python3\r\n  export PYTHON_LIB_PATH=/usr/local/lib/python3.6/dist-packages\r\n  export CUDA_TOOLKIT_PATH=/usr/local/cuda\r\n  export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu\r\n  export TENSORRT_INSTALL_PATH=/usr/lib/x86_64-linux-gnu\r\n  export NCCL_INSTALL_PATH=/usr/lib/x86_64-linux-gnu\r\n\r\n  export TF_NEED_ROCM=0\r\n  export TF_NEED_CUDA=1\r\n  export TF_CUDA_VERSION=\"$($CUDA_TOOLKIT_PATH/bin/nvcc --version | sed -n 's/^.*release \\(.*\\),.*/\\1/p')\"\r\n  export TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n  export TF_CUDNN_VERSION=7.5.0\r\n  export TF_NEED_TENSORRT=1\r\n  export TF_TENSORRT_VERSION=5.0.2\r\n  export TF_NCCL_VERSION=2.4.2\r\n\r\n  export TF_CUDA_CLANG=1\r\n  export TF_DOWNLOAD_CLANG=1\r\n\r\n  export TF_NEED_HDFS=1\r\n  export TF_NEED_OPENCL=0\r\n  export TF_NEED_JEMALLOC=1\r\n  export TF_ENABLE_XLA=1\r\n  export TF_NEED_VERBS=0\r\n  export TF_NEED_MKL=0\r\n  export TF_DOWNLOAD_MKL=0\r\n  export TF_NEED_AWS=0\r\n  export TF_NEED_MPI=0\r\n  export TF_NEED_GDR=0\r\n  export TF_NEED_S3=0\r\n  export TF_NEED_OPENCL_SYCL=0\r\n  export TF_SET_ANDROID_WORKSPACE=0\r\n  export TF_NEED_COMPUTECPP=0\r\n  export TF_NEED_KAFKA=0\r\n\r\n  export CC_OPT_FLAGS=\"-O3 -march=native\"\r\n\r\n  export C_INCLUDE_PATH=/usr/include/python3.6m\r\n  export CPLUS_INCLUDE_PATH=/usr/include/python3.6m\r\n\r\n# Clone\r\n  git clone https://github.com/tensorflow/tensorflow.git --depth 1\r\n  cd tensorflow/\r\n  ./configure\r\n\r\n\r\n  time bazel build -c opt --distinct_host_configuration=false --copt=-march=native --copt=-O3 --verbose_failures //tensorflow/core/kernels:cwise_op_gpu\r\n\r\n```\r\n\r\nThen, Clang and Bazel will exit with an error log like below.\r\n\r\n```\r\nIn file included from tensorflow/core/kernels/cwise_op_gpu_xdivy.cu.cc:18:\r\nIn file included from ./tensorflow/core/kernels/cwise_ops_gpu_common.cu.h:27:\r\nIn file included from ./tensorflow/core/framework/tensor_types.h:19:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14:\r\nIn file included from external/eigen_archive/Eigen/Core:150:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/GenericPacketMath.h:211:51: error: invalid operands to binary expression ('const float4' and 'const float4')\r\npxor(const Packet& a, const Packet& b) { return a ^ b; }\r\n                                                ~ ^ ~\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/GenericPacketMath.h:258:33: note: in instantiation of function template specialization 'Eigen::internal::pxor<float4>' requested here\r\npzero(const Packet& a) { return pxor(a,a); }\r\n                                ^\r\n./tensorflow/core/kernels/cwise_ops.h:624:20: note: in instantiation of function template specialization 'Eigen::internal::pzero<float4>' requested here\r\n    Packet zeros = pzero(x);\r\n                   ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorEvaluator.h:520:22: note: in instantiation of function template specialization 'Eigen::internal::xdivy_op<float>::packetOp<float4>' requested here\r\n    return m_functor.packetOp(m_leftImpl.template packet<LoadMode>(index), m_rightImpl.template packet<LoadMode>(index));\r\n                     ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:159:75: note: in instantiation of function template specialization 'Eigen::TensorEvaluator<const Eigen::TensorCwiseBinaryOp<Eigen::internal::xdivy_op<float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long>, 16, MakePointer> >, Eigen::GpuDevice>::packet<16>' requested here\r\n    m_leftImpl.template writePacket<LhsStoreMode>(i, m_rightImpl.template packet<RhsLoadMode>(i));\r\n                                                                          ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:350:12: note: in instantiation of member function 'Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorCwiseBinaryOp<Eigen::internal::xdivy_op<float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long>, 16, MakePointer> > >, Eigen::GpuDevice>::evalPacket' requested here\r\n      eval.evalPacket(i);\r\n           ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:367:63: note: in instantiation of member function 'Eigen::internal::EigenMetaKernelEval<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorCwiseBinaryOp<Eigen::internal::xdivy_op<float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long>, 16, MakePointer> > >, Eigen::GpuDevice>, long, true>::run' requested here\r\n  EigenMetaKernelEval<Evaluator, StorageIndex, vectorizable>::run(eval, first_index, size, step_size);\r\n                                                              ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:386:10: note: in instantiation of function template specialization 'Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorCwiseBinaryOp<Eigen::internal::xdivy_op<float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long>, 16, MakePointer> > >, Eigen::GpuDevice>, long>' requested here\r\n        (EigenMetaKernel<TensorEvaluator<Expression, GpuDevice>, StorageIndex>),\r\n         ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:59: note: in instantiation of member function 'Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorCwiseBinaryOp<Eigen::internal::xdivy_op<float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long>, 16, MakePointer> > >, Eigen::GpuDevice, true, false>::run' requested here\r\n      internal::TensorExecutor<const Assign, DeviceType>::run(assign, m_device);\r\n                                                          ^\r\n./tensorflow/core/kernels/cwise_ops_gpu_common.cu.h:54:28: note: in instantiation of function template specialization 'Eigen::TensorDevice<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, MakePointer>, Eigen::GpuDevice>::operator=<Eigen::TensorCwiseBinaryOp<Eigen::internal::xdivy_op<float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, int>, 16, MakePointer>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long>, 16, MakePointer> > >' requested here\r\n    To32Bit(out).device(d) =\r\n                           ^\r\n```\r\n\r\n\r\n**Any other info / logs**\r\n- *#26159 may be related to this issue. Please check it out as well.*\r\n- *This is a full version of the error log. Just for your information.*\r\n-- [full-error.log](https://github.com/tensorflow/tensorflow/files/3019127/full-error.log)\r\n- Workaround : ~Now I'm trying nvcc to reproduce the problem.~  With nvcc, build succeeded. ", "comments": ["Looks like one of the reasons behind the issue is Clang\u2019s template deduction. The way to avoid it is \r\n- making it compatible with Clang\r\n- giving up on Clang", "Now I found a solution. See https://github.com/tensorflow/tensorflow/pull/27348", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27253\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27253\">No</a>\n"]}, {"number": 27252, "title": "tensorflow won't compile", "body": "\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: only import tensorflow\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no\r\n- **TensorFlow installed from (source or binary)**: pip \r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: 3.7.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:  cuda 10.1, cudnn v.7.5\r\n- **GPU model and memory**: gtx 1070\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n```\r\n\r\n## and this is the error\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kevol\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["duplicate #26364 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27252\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27252\">No</a>\n"]}, {"number": 27251, "title": "Update tf.math.logical_xor", "body": "Provide description and example for tf.math.logical_xor.", "comments": ["@lamberta Can you please review this."]}, {"number": 27250, "title": "helper_functions.inc (Google howto fail)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): VMware Ubuntu 18.04.2\r\n- TensorFlow installed from (source or binary): according to howto (see description of problem)\r\n- TensorFlow version: according to howto (see description of problem)\r\n- Python version: latest\r\n- Installed using virtualenv? pip? conda?: according to howto (see description of problem)\r\n- Bazel version (if compiling from source): not installed\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: VMware\r\n\r\n\r\n**Describe the problem**\r\n\r\nludwig1@ubuntu:~/dev$ make -f tensorflow/tensorflow/lite/experimental/micro/tools/make/Makefile test\r\ntensorflow/tensorflow/lite/experimental/micro/tools/make/Makefile:5: tensorflow/lite/experimental/micro/tools/make/helper_functions.inc: No such file or directory\r\n/bin/sh: 1: [[: not found\r\nmake: *** No rule to make target 'tensorflow/lite/experimental/micro/tools/make/helper_functions.inc'.  Stop.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nFollowing howto: https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#2\r\n\r\nUsed command: \"make -f tensorflow/lite/experimental/micro/tools/make/Makefile test\"\r\n\r\n**Any other info / logs**\r\nNA\r\n", "comments": ["I believe you need to `cd tensorflow`, after the `git clone` so your in the correct directory when the command is run.\r\n\r\ni.e. it should be  `make -f tensorflow/lite/experimental/micro/tools/make/Makefile test`\r\nand not `make -f tensorflow/tensorflow/lite/experimental/micro/tools/make/Makefile test`\r\n\r\nThe 2nd command tells me your in the wrong directory.", "It works, thanks! Ticket can be closed.", "Closing since its resolved. Thanks!"]}, {"number": 27249, "title": "importError: cannot import name 'bitwise'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nimport tensorflow as tf\r\n\r\ngives me this error:\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-12-fe025adf6030> in <module>()\r\n      1 # Import TensorFlow\r\n----> 2 import tensorflow as tf\r\n      3 \r\n      4 # Define a and b as placeholders\r\n      5 a = tf.placeholder(dtype=tf.int8)\r\n\r\n/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py in <module>()\r\n     38 \r\n     39 from tensorflow import app\r\n---> 40 from tensorflow import bitwise\r\n     41 from tensorflow import compat\r\n     42 from tensorflow import data\r\n\r\nImportError: cannot import name 'bitwise'\r\n\r\n\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Solved issue by pip install --upgrade tensorflow"]}, {"number": 27248, "title": "How to transfer a ckpt file to the code?", "body": "I have a demand that need to transfer the ckpt.meta file to the code. Don't use the \"import_meta_graph\". I means that if we know the input_tensor name and logit name, how we get the subgraph of this and transfer the graph to \"inference\" code.", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 27247, "title": "Feedback limitation in a documentation web page ", "body": "Hello tf developers team. \r\n\r\nI'm coming to this page: https://www.tensorflow.org/api_docs/python/tf/bitwise, and I see no indication whether this is implemented on GPU or CPU only. Will tf help me for my project or not? I find this information page extremely unhelpful for my purpose. As the overview should state clearly when to use the library and when not (I need only bitwise operations). \r\n\r\nI left a feedback on your page giving two stars - but I can't write a string for you. How would you know what to fix if everyone are just saying the document is bad, and can't explain why and what they're missing? \r\n", "comments": ["Thanks for the feedback ... it seems you found the place to enter it :)\r\n\r\nI would suggest starting with the [guides and tutorials](https://www.tensorflow.org/overview) to get started. Perhaps check out the beginner eager tutorial notebooks to look at GPU placement. Colab provides a option to toggle the between CPU and GPU (and TPU!). The API reference is a mixed bag since there are about ~5000 pages of them. But the docstrings are open source so contributions welcome.\r\n\r\nStars are used more for a signal. There are no plans to add a more featureful feedback widget."]}, {"number": 27246, "title": "Build Issue on windows - cd command does not change drive without /d flag", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Windows 10:\r\n- TensorFlow installed from (source or binary): building\r\n- TensorFlow version: Master\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):23.0\r\n- GCC/Compiler version (if compiling from source):VS2015\r\n- CUDA/cuDNN version:7.1\r\n- GPU model and memory:GTX970\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nWhen building with bazel the it fails with the following \r\n\r\n`ERROR: D:/phil/python/tensorflow/tensorflow/core/BUILD:2676:1: Executing genrule //tensorflow/core:version_info_gen failed (Exit 1): bash.exe failed: error executing command\r\n  cd C:/users/username/_bazel_username/frxyltss/execroot/org_tensorflow\r\n\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n\r\n   <more set parameters>\r\n\r\n  C:/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt/bin/tensorflow/tools/git/gen_git_source.exe --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref \"bazel-out/x64_windows-opt/genfiles/tensorflow/core/util/version_info.cc\" --git_tag_override=${GIT_TAG_OVERRIDE:-}\r\n\r\nExecution platform: @bazel_tools//platforms:host_platform\r\n\r\nD:\\Phil\\Virtual Environments\\tensorflow_compilation\\Scripts\\python.exe: can't find '__main__' module in 'C:\\\\users\\\\yvann'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build`\r\n\r\nThe cause of this is that the tensorflow source directory is on the D drive, but the temporary files are created in the windows user directory that is on the C drive. On windows the cd command does not change drive by default. Thus the line \r\n`cd C:/users/username/_bazel_username/frxyltss/execroot/org_tensorflow`\r\nwill not change the directory if the current working directory is on the D drive. This can be fixed by making the above line cd /d <path> which will then change drive. Alternatively you can insert cd D:\r\nThis command appears to be autogenerated but i cannot easily see how to change it.\r\n", "comments": ["Thanks for the reporting, this is a Bazel issue. \r\nI created a Bazel issue at https://github.com/bazelbuild/bazel/issues/7904", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27246\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27246\">No</a>\n", "As explained in https://github.com/bazelbuild/bazel/issues/7904\r\n> What \"bazel build -s\" prints is decorational.\r\nBazel doesn't actually shell out to cmd.exe (or Bash, or cd) to change the directory.\r\n\r\nSo Bazel didn't actually run any cd command, so the build error is caused by some other problem, probably in some TF script.", "Where does `C:\\users\\yvann` come from?", "@phil20686,\r\n\r\nWe are checking to see if you still need help on this issue. We recommend that you upgrade to `2.6` which is latest stable version of TF and let us know if the issue still persists in newer versions. You can use this [guide](https://www.tensorflow.org/install/source_windows) as a reference while building TF for windows.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27246\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27246\">No</a>\n"]}, {"number": 27245, "title": "tf.data input pipeline got strange bug with tensorflow-gpu", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- Mobile device if the issue happens on mobile device: Dell Precision Tower 7910\r\n- TensorFlow installed from (source or binary): tensorflow-gpu 1.12.0\r\n- TensorFlow version (use command below): tensorflow-gpu 1.12.0\r\n- Installed from: conda\r\n- Python version: python 3.6\r\n- GCC/Compiler version (if compiling from source): 6.5.0\r\n- CUDA/cuDNN version: 9.2 but nvcc 7.5\r\n- GPU model and memory:Quadro M4000\r\n\r\n\r\n**Describe the current behavior**\r\nThe following code worked fine with tensorflow-cpu 1.12.0 but not with the gpu version.\r\nI got error:\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: transpose expects a vector of size 5. But input(1) is a vector of size 4\r\n\t [[{{node gradients/Conv1/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](IteratorGetNext/_19, PermConstNHWCToNCHW-LayoutOptimizer)]]\r\n\t [[{{node mean_squared_error/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_2/_37}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_63_me...t/Switch_2\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```\r\nHere's the traceback:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n>     return fn(*args)\r\n>   File \"/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n>     options, feed_dict, fetch_list, target_list, run_metadata)\r\n>   File \"/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n>     run_metadata)\r\n\r\nAnother thread on parallel threw:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"20190328_.py\", line 52, in <module>    sess.run([train_op])\r\n>   File \"/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n>     run_metadata_ptr)\r\n>   File \"/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n>     feed_dict_tensor, options, run_metadata)\r\n>   File \"/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n>   File \"/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n>     raise type(e)(node_def, op, message)\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport h5py\r\nimport threading\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# make some random img data\r\nfor i in range(100):\r\n    with h5py.File('./test_{}.h5'.format(i), 'w') as f:\r\n        f.create_dataset('X', shape=(1000, 100, 100), dtype='float32', data=np.random.rand(10**7).reshape(1000, 100, 100))\r\n        f.create_dataset('y', shape=(1000, 100, 100), dtype='float32', data=np.random.rand(10**7).reshape(1000, 100, 100))\r\n        print(threading.get_ident())\r\n\r\n# params\r\nnum_cores = 3\r\nshuffle_size = 1\r\nbatch_size = 1\r\n\r\n# read .h5 file\r\ndef parse_file(f):\r\n    print(f.decode('utf-8'))\r\n    with h5py.File(f.decode(\"utf-8\"), 'r') as fi:\r\n        X = fi['X'][:].reshape(1000, 100, 100, 1)\r\n        y = fi['y'][:].reshape(1000, 100, 100, 1)\r\n        print(threading.get_ident())  # to see the thread id\r\n        return X, y\r\n\r\n# py_func wrapper\r\ndef parse_file_tf(filename):\r\n    return tf.py_func(parse_file, [filename], [tf.float32, tf.float32])\r\n\r\n# input pipeline\r\nfiles = tf.data.Dataset.list_files('./test_*.h5')\r\ndataset = files.map(parse_file_tf, num_parallel_calls=num_cores)\r\ndataset = dataset.batch(batch_size).shuffle(shuffle_size).prefetch(10)\r\nit = dataset.make_initializable_iterator()\r\niter_init_op = it.initializer\r\nX_it, y_it = it.get_next()\r\n\r\n# simplest model\r\nwith tf.name_scope(\"Conv1\"):\r\n    W = tf.get_variable(\"W\", shape=[3, 3, 1, 1],\r\n                         initializer=tf.contrib.layers.xavier_initializer())\r\n    b = tf.get_variable(\"b\", shape=[1], initializer=tf.contrib.layers.xavier_initializer())\r\n    layer1 = tf.nn.conv2d(X_it, W, strides=[1, 1, 1, 1], padding='SAME') + b\r\n    out = tf.nn.relu(layer1)\r\n\r\nloss = tf.reduce_mean(tf.losses.mean_squared_error(labels=y_it, predictions=out))\r\ntrain_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\r\n\r\n# session\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nsess.run(iter_init_op)\r\nsess.run([train_op])\r\nsess.close()\r\n```\r\nThanks for your help\r\n", "comments": ["Can you please update your code and change the argument  to ```data_format=\"NCHW\"``` given in ```tf.nn.conv2d``` function? By default it is set to ```\"NHWC\"```", "@ymodak Thank you for your reply. I think the problem comes from the convention or mechanism of tf.data.  My case is that one batch contains one sample of multiple images. You can understand like 1000 color channels. Consequently my CNN see one batch of one image of dimension rank-4 (1000, 100, 100, 1) instead of 1000 batches of images of dimension rank-3 (100, 100, 1). I did try to reshape the image to (1, 100, 100, 1000) but it seems that tensorflow supports maximum 4 channels. I got around this programming issue by separating each channel as one image and load them in a batch (like tradition). However, physically it doesn't make any sense since channels will be passed by same convolution kernels.", "> @ymodak Thank you for your reply. I think the problem comes from the convention or mechanism of tf.data. My case is that one batch contains one sample of multiple images. You can understand like 1000 color channels. Consequently my CNN see one batch of one image of dimension rank-4 (1000, 100, 100, 1) instead of 1000 batches of images of dimension rank-3 (100, 100, 1). I did try to reshape the image to (1, 100, 100, 1000) but it seems that tensorflow supports maximum 4 channels. I got around this programming issue by separating each channel as one image and load them in a batch (like tradition). However, physically it doesn't make any sense since channels will be passed by same convolution kernels.\r\n\r\nGood morning @ZeliangSu   I think my problem is in the same line. After checking in [ StackOverflow](https://stackoverflow.com/questions/55375435/cannot-add-tensor-to-the-batch-number-of-elements-does-not-match/56002510#56002510) I cannot solve the error displayed below:\r\n```\r\nmer_summary, self.global_step, lr])\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [400,400,1], [batch]: [400,400,3]\r\n\t [[node IteratorGetNext (defined at run_model.py:254) ]]\r\n\r\nCaused by op 'IteratorGetNext'\r\n```\r\nWhenever the numbers of iteration were 90 it was working properly, since I changed the dataset with 6480 iterations the input tensor does not match the batch size. Actually, my input size is [400, 400, 3] and the target [400, 400, 3], the prediction size is [400,400,1]. To compute the loss function I use tf.image.rgb_to_grayscale().\r\n\r\n Here the definition of my dataset:\r\n\r\n```\r\n# Training\r\ntrain_list = data_cache['train_paths']\r\ntrain_list = np.array(train_list)\r\ntrain_data = tf.data.Dataset.from_tensor_slices((train_list[:,0],train_list[:,1]))\r\ntrain_data = train_data.shuffle(1000)\r\ntrain_data = train_data.map(self.load_train_edge, num_parallel_calls=4)\r\ntrain_data = train_data.batch(self.bs)\r\ntrain_data = train_data.prefetch(self.bs)\r\ntrain_iter = train_data.make_initializable_iterator()\r\ntrain_img,train_targ = train_iter.get_next()\r\n# train_iter_init_op = train_iter.initializer\r\n# Validation\r\nval_list = data_cache['val_paths']\r\nval_list = np.array(val_list)\r\nval_data = tf.data.Dataset.from_tensor_slices((val_list[:,0],val_list[:,1]))\r\nval_data  = val_data.map(self.load_train_edge, num_parallel_calls=4)\r\nval_data = val_data.batch(self.bs)\r\nval_iter = val_data.make_initializable_iterator()\r\nval_img, val_targ = val_iter.get_next()\r\n```\r\n\r\nThe function in **map** is:\r\n\r\n```\r\n    def load(self,image_file):\r\n        input_img = tf.io.read_file(image_file[0])\r\n        input_img = tf.image.decode_jpeg(input_img)\r\n\r\n        real_img = tf.io.read_file(image_file[1])\r\n        real_img=tf.image.decode_png(real_img)\r\n        real_img = tf.cast(real_img, tf.float32)\r\n        input_img = tf.cast(input_img, tf.float32)\r\n        return input_img, real_img\r\n\r\n    def random_crop_edge(self,input_img,real_img):\r\n        if np.random.random() > 0.5:\r\n            stacked_img = tf.stack([input_img, real_img], axis=0)\r\n            cropped_img = tf.image.random_crop(stacked_img, size=[2, self.img_height, self.img_height, 3])\r\n            input_img, real_img = cropped_img[0], cropped_img[1]\r\n        else:\r\n            input_img = tf.image.resize(input_img, size=[self.img_height, self.img_width],\r\n                                        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR, align_corners=True)\r\n            real_img = tf.image.resize(real_img, size=[self.img_height, self.img_width],\r\n                                       method=tf.image.ResizeMethod.NEAREST_NEIGHBOR, align_corners=True)\r\n            input_img = tf.reshape(input_img, [self.img_height, self.img_width, 3])\r\n            real_img = tf.reshape(real_img, [self.img_height, self.img_width, 3])\r\n        return input_img, real_img\r\n\r\n    def load_train_edge(self,input_paths, target_path):\r\n        input_img, real_img = self.load([input_paths, target_path])\r\n        input_img, real_img = self.random_crop_edge(input_img, real_img)\r\n        return input_img, real_img\r\n```\r\n\r\n**System information**\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes a little bit\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n\r\nTensorFlow installed from (source or binary): binary\r\n\r\nTensorFlow version (use command below): 1.13.1\r\n\r\nPython version: 3.7\r\n\r\nBazel version (if compiling from source):\r\n\r\nGCC/Compiler version (if compiling from source):\r\n\r\nCUDA/cuDNN version: 10.0 \r\n\r\nGPU model and memory: GeForce GTX TITAN X\r\n\r\nCPU Make & Model: Intel(R) Xeon(R) CPU E5-1620 v3\r\n\r\nData Drive: Seagate ATA Disk  931GiB (1TB)\r\n\r\nDid you solve your problem? please help me :'( @ymodak @ZeliangSu @jsimsa ", "The error you are seeing suggests that you are trying to create a batch of tensors that have incompatible shapes (both `[400, 400, 3]` and `[400, 400, 1]`).\r\n\r\nYou should be able to identify the mismatch by printing the shapes of the elements in your input pipeline:\r\n\r\n```\r\ntrain_list = data_cache['train_paths']\r\ntrain_list = np.array(train_list)\r\ntrain_data = tf.data.Dataset.from_tensor_slices((train_list[:,0],train_list[:,1]))\r\ntrain_data = train_data.map(self.load_train_edge, num_parallel_calls=4)\r\ntrain_iter = train_data.make_initializable_iterator()\r\nget_next = train_iter.get_next()\r\n\r\nwith tf.Session() as sess:\r\n  print(sess.run(train_iter.initializer))\r\n  while True:\r\n    try:\r\n      image, target = sess.run(get_next)\r\n      print(image.shape, target.shape)\r\n    except errors.OutOfRangeError:\r\n      pass\r\n```", "> The error you are seeing suggests that you are trying to create a batch of tensors that have incompatible shapes (both `[400, 400, 3]` and `[400, 400, 1]`).\r\n> \r\n> You should be able to identify the mismatch by printing the shapes of the elements in your input pipeline:\r\n> \r\n> ```\r\n> train_list = data_cache['train_paths']\r\n> train_list = np.array(train_list)\r\n> train_data = tf.data.Dataset.from_tensor_slices((train_list[:,0],train_list[:,1]))\r\n> train_data = train_data.map(self.load_train_edge, num_parallel_calls=4)\r\n> train_iter = train_data.make_initializable_iterator()\r\n> get_next = train_iter.get_next()\r\n> \r\n> with tf.Session() as sess:\r\n>   print(sess.run(train_iter.initializer))\r\n>   while True:\r\n>     try:\r\n>       image, target = sess.run(get_next)\r\n>       print(image.shape, target.shape)\r\n>     except errors.OutOfRangeError:\r\n>       pass\r\n> ```\r\n\r\nI will try that way but before this, I have printed the size of every single input and target, and all of them matched.\r\n\r\nThanks \r\nXavier\r\n", "> \r\n> \r\n> The error you are seeing suggests that you are trying to create a batch of tensors that have incompatible shapes (both `[400, 400, 3]` and `[400, 400, 1]`).\r\n> \r\n> You should be able to identify the mismatch by printing the shapes of the elements in your input pipeline:\r\n> \r\n> ```\r\n> train_list = data_cache['train_paths']\r\n> train_list = np.array(train_list)\r\n> train_data = tf.data.Dataset.from_tensor_slices((train_list[:,0],train_list[:,1]))\r\n> train_data = train_data.map(self.load_train_edge, num_parallel_calls=4)\r\n> train_iter = train_data.make_initializable_iterator()\r\n> get_next = train_iter.get_next()\r\n> \r\n> with tf.Session() as sess:\r\n>   print(sess.run(train_iter.initializer))\r\n>   while True:\r\n>     try:\r\n>       image, target = sess.run(get_next)\r\n>       print(image.shape, target.shape)\r\n>     except errors.OutOfRangeError:\r\n>       pass\r\n> ```\r\n\r\nCan you tell me how to load my tfrecord? The code before train_list = data_cache['train_paths'] is missing. I have the same problem.", "@ZeliangSu,\r\nSorry for the delayed response. Can you please let us know if your issue is resolved as per [jsimsa's comment](https://github.com/tensorflow/tensorflow/issues/27245#issuecomment-489726216). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27245\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27245\">No</a>\n", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. "]}, {"number": 27244, "title": "TensorFlow estimator train_and_evaluate loss is None model does not train when reading data from s3 ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nAnaconda\r\n- TensorFlow version (use command below):\r\n1.12\r\n- Python version:\r\nPython 3.6.8 :: Anaconda, Inc.\r\n\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\ni have build tensorflow distribution code using estimator api.And it worked well when reading data from local using train_and_evaluate.But if data is located in s3,it just checkpoints at step 0, the loss being None and moves to the evaluate phase. I'm not sure why this is happening, and any suggestions about what to look for would be great \r\n**Describe the expected behavior**\r\nit should training normally when reading data from s3\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\ntrain_input = lambda: fetch_train_data(FLAGS.train_data, FLAGS.train_epoch,batch_size=FLAGS.train_batch_size,is_eval=False,shuffle=True)\r\n    eval_input  = lambda: fetch_eval_data (FLAGS.eval_data,  FLAGS.eval_epoch, batch_size=FLAGS.eval_batch_size, is_eval=True, shuffle=True)\r\n\r\n    train_spec = tf.estimator.TrainSpec(train_input,max_steps=9223372036854775807)\r\n    eval_spec = tf.estimator.EvalSpec(eval_input,steps=1)\r\n    tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\r\n```\r\n```\r\ndef fetch_train_data(filename, epochs=1, batch_size=256,is_eval=False,shuffle=False):\r\n    print (\"fetch_train_data\");\r\n    blocks = get_blocks()\r\n    #files = __list_files(filename)\r\n\r\n    def chunks(arr, m):\r\n      n = int(math.floor(len(arr) / float(m)))\r\n      return [arr[i:i + n] for i in range(0, len(arr), n)]\r\n    print (\"is_eval is %d\"%(is_eval))\r\n    data_file = tf_record_pattern(filename, is_eval)\r\n    #random.shuffle(data_file)\r\n    num_shards = FLAGS.gpu_nums\r\n    if FLAGS.gpu_nums!=0 and not is_eval:\r\n        data_file = chunks(data_file, num_shards)\r\n\r\n    for file in data_file:\r\n        print (file)\r\n\r\n    sys.stdout.flush()\r\n    ds = [[] for i in range(num_shards)]\r\n    feature_shards = [[] for i in range(num_shards)]\r\n    label_shards = [[] for i in range(num_shards)]\r\n    for i in range(num_shards):\r\n      if not is_eval:\r\n        ds[i] = tf.data.TFRecordDataset.list_files(data_file[i])\r\n        ds[i] = ds[i].interleave(lambda filename: tf.data.TFRecordDataset(filename, buffer_size = 20*1024*1024), cycle_length = 20)\r\n      else:\r\n        ds[i] = tf.data.TFRecordDataset(data_file[i], buffer_size = 20*1024*1024)\r\n      ds[i] = ds[i].prefetch(buffer_size=batch_size)\r\n      if shuffle:\r\n          ds[i] = ds[i].shuffle(buffer_size = 10000)\r\n      if FLAGS.sync == 0:\r\n        ds[i] = ds[i].repeat(epochs)\r\n      else:\r\n        ds[i] = ds[i].repeat()\r\n\r\n      ds[i] = ds[i].batch(batch_size).map(__parse_ins(blocks), num_parallel_calls = 20)\r\n      ds[i] = ds[i].prefetch(FLAGS.gpu_nums)\r\n      feature_shards[i], label_shards[i] = ds[i].make_one_shot_iterator().get_next()\r\n    return feature_shards, label_shards\r\n\r\n```\r\n\r\n", "comments": ["who can help to fix it?", "@yongtang Could you please take a look at this issue? Thanks!", "I have a similar situation. Unable to train an image classification model while streaming image data from S3.", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Please follow the suggestion from jvishnuvardhan@. Will close this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27244\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27244\">No</a>\n"]}]