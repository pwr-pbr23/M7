[{"number": 7326, "title": "Can't find rt.jar when installing tensorflow on Mac OS", "body": "Hi,\r\n\r\nI downloaded and installed jdk 8 on my mac os. But there was no classes.jar or rt.jar shipped with the installation. When I tried to install tensorflow afterwards, I got a could not find rt.jar error. How should I fix this ?", "comments": ["Since TensorFlow doesn't use any Java, are you referring to a problem with Bazel?  You could also the Bazel folk, but I expect the problem is better suited for StackOverflow.  Wherever you ask it, please post complete error messages."]}, {"number": 7325, "title": "Clarify import_graph_def() places Ops into current default graph def", "body": "Small documentation tweak for `import_graph_def`, stemming from #7240. The documentation current says that the `GraphDef` is imported into \"the graph\". This change adds clarity as to which graph receives the imported operations.\r\n\r\nCC: @martinwicke ", "comments": ["Can one of the admins verify this patch?", "Los dos!", "Jenkins, test this please.", "Thanks!"]}, {"number": 7324, "title": " Auto-Configuration Error: Invalid compute capability: \"6.0\"", "body": "```\r\nExtracting Bazel installation...\r\n.\r\nINFO: Starting clean.\r\nINFO: Output base moved to /home/chaimb/.cache/bazel/_bazel_chaimb/acf2af86672e1552dfd6edd47d54a950_tmp_31124 for deletion\r\nWARNING: Output base '/home/chaimb/.cache/bazel/_bazel_chaimb/acf2af86672e1552dfd6edd47d54a950' is on NFS. This may lead to surprising failures and undetermined behavior.\r\n............\r\nERROR: package contains errors: tensorflow/stream_executor.\r\nERROR: error loading package 'tensorflow/stream_executor': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"/home/chaimb/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 824\r\n                _create_cuda_repository(repository_ctx)\r\n        File \"/home/chaimb/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 736, in _create_cuda_repository\r\n                _get_cuda_config(repository_ctx)\r\n        File \"/home/chaimb/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 590, in _get_cuda_config\r\n                struct(cuda_toolkit_path = cuda_toolkit..., <5 more arguments>)\r\n        File \"/home/chaimb/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 595, in struct\r\n                _compute_capabilities(repository_ctx)\r\n        File \"/home/chaimb/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 337, in _compute_capabilities\r\n                auto_configure_fail(\"Invalid compute capability: %s\"...)\r\n        File \"/home/chaimb/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 93, in auto_configure_fail\r\n                fail(\"\r\n%sAuto-Configuration Error:%s ...))\r\n\r\nAuto-Configuration Error: Invalid compute capability: \"6.0\"\r\n.\r\n```\r\nWorks with default compute capability.\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttps://github.com/tensorflow/tensorflow/issues/4105\r\n### Environment info\r\nOperating System:\r\nUbuntu 16.04\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\nCUDA 8.0\r\n```\r\n-rw-r--r-- 1 root root    558720 Sep 15 02:02 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root        16 Sep 15 02:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root        19 Sep 15 02:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root    415432 Sep 15 02:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root    775162 Sep 15 02:02 /usr/local/cuda/lib64/libcudart_static.a\r\n-rw-r--r-- 1 root root 105920110 Feb  7 10:47 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n`eb225d71b394c24f49a2e07f685be94d4ab7496f`\r\n2. The output of `bazel version`\r\n```\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n\r\n```\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nIt crashes directly after I pick `configure` options\r\n\r\n", "comments": ["@zheng-xq Should 6 be supported?", "6.0, 6.1 is Pascal TitanX, P100 cards. I routinely enter those in configure (5 days ago when I tried last it worked)", "According to https://github.com/tensorflow/tensorflow/issues/6914, you guys are already building with 6.0", "@jart Any ideas for this cuda/bazel issue?", "Maybe it's too early for me, but how is it possible for this condition to fail for the input \"6.0\"? Unless that's some kind of unicode dot, I don't understand how this is possible.\r\n\r\n```python\r\n    parts = capability.split(\".\")\r\n    if len(parts) != 2 or not parts[0].isdigit() or not parts[1].isdigit():\r\n      auto_configure_fail(\"Invalid compute capability: %s\" % capability)\r\n```", "Oh I see, somehow that value is getting quoted. Looking into this further\u2026", "@jart Did your search come up with anything?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Closing due to inactivity. If this is still an issue, let me know and I'll reopen."]}, {"number": 7323, "title": "convert_variables_to_constants doesn't preserve output shape", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n``` sh\r\n$ ls -l /usr/local/cuda-8.0/lib64/libcud*\r\n-rw-r--r-- 1 root root   558720 Sep 30 15:48 /usr/local/cuda-8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Sep 30 15:48 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Sep 30 15:48 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x 1 root root   415432 Sep 30 15:48 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 Sep 30 15:48 /usr/local/cuda-8.0/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Sep 30 15:50 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Sep 30 15:50 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxr-xr-x 1 root root 79337624 Sep 30 15:50 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 Sep 30 15:50 /usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\nTensorflow Version: '0.12.1-3-g45ab528-dirty'\r\nBazel Version: 0.4.4\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n``` python\r\n#!/usr/bin/python3\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import graph_util\r\nimport difflib\r\n\r\ngraph_1 = tf.Graph()\r\nwith graph_1.as_default():\r\n    input_batch = tf.placeholder(shape=(None, 100), dtype=tf.float32, name=\"Placeholder\")\r\n\r\ngraph_1_pb = graph_1.as_graph_def(add_shapes=True)\r\nsession = tf.Session(graph=graph_1)\r\ngraph_2_pb = graph_util.convert_variables_to_constants(session, session.graph.as_graph_def(), [\"Placeholder\"])\r\n\r\nprint(\"\\n\".join(difflib.unified_diff(str(graph_1_pb).split(\"\\n\"), str(graph_2_pb).split(\"\\n\"))))\r\n```\r\nI expected it will return no diff or have a little diff, but it has noticeable diffs.\r\n\r\n```\r\n--- \r\n\r\n+++ \r\n\r\n@@ -1,21 +1,6 @@\r\n\r\n node {\r\n   name: \"Placeholder\"\r\n   op: \"Placeholder\"\r\n-  attr {\r\n-    key: \"_output_shapes\"\r\n-    value {\r\n-      list {\r\n-        shape {\r\n-          dim {\r\n-            size: -1\r\n-          }\r\n-          dim {\r\n-            size: 100\r\n-          }\r\n-        }\r\n-      }\r\n-    }\r\n-  }\r\n   attr {\r\n     key: \"dtype\"\r\n     value {\r\n@@ -30,7 +15,4 @@\r\n\r\n     }\r\n   }\r\n }\r\n-versions {\r\n-  producer: 17\r\n-}\r\n```\r\nPreserving `_output_shapes attribute` is somewhat important for me, so we have `add_shapes=True` on `tf.Graph.as_graph_def` function.\r\n\r\nseems like other [graph utils](https://github.com/tensorflow/tensorflow/blob/a0d784bdd31b27e013a7eac58a86ba62e86db299/tensorflow/python/tools/strip_unused_lib.py#L64)  copying `_output_shapes` attributes. \r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": []}, {"number": 7322, "title": "How to uninstall tensorflow?", "body": "Help I want to reinstall tensorflow, from GPU to CPU, because, just installed tensorflow not work correctly.\r\nI test my installation, from documentation of tensorflow.org,\r\nthen it gives back that error:\r\n\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, TensorFlow!')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'constant'\r\n\r\n\r\nSO SHOULD I REINSTALL TENSORFLOW?\r\nbefore I installed by pip, but it did not work then I use virtualen, also did not work, then by using anaconda. something worked, but I stack in testing installation. Help me!", "comments": ["@gunan Heads up: this is the second recent bug I've seen where someone somehow got an empty installation of TensorFlow (no `tf.constant` here, no `tf.Variable` for https://github.com/tensorflow/tensorflow/issues/7285).  This one is anaconda; not sure about the other one yet.\r\n\r\n@danchokobo We don't support Anaconda, so if you installed it through that you should look at Anaconda docs to know how to uninstall.", "Ah, didn't notice you were the same person from https://github.com/tensorflow/tensorflow/issues/7285.  I believe you installed through Anaconda, so you should look at the Anaconda docs for how to uninstall.", "I installed tensorflow through pip for python on windows 10\r\ncmd-> pip3 install --upgrade tensorflow\r\nIt said \"successfully installed tensorflow\" but when I typed \" import tensorflow as tf\", it gave me a huge error saying \"DLL load failed\" and \"no module named _pywrap_tensorflow_internal\" and \"failed to load the native tensorflow runtime\", in the end.\r\nI uninstalled through pip -> pip uninstall tensorflow in command prompt and reinstalled but I'm getting the same error. Please help.", "Do the following:\r\n\r\n`conda update libgcc`\r\n\r\nbut this will require downgrading \"due to dependency conflicts\" next time you update anaconda.\r\n\r\nOR\r\n you can mask the anaconda libstdc++ so that your system's libstdc++ is used\r\n```\r\ncd ~/TO-YOUR-ANACONDA-FOLDER/lib\r\nmv libstdc++.so libstdc++.so.bkp\r\nmv libstdc++.so.6 libstdc++.so.6.bkp\r\n```\r\nFurther optionally create a softlink inside the anaconda lib directly\r\n\r\n`ln -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6 libstdc++.so.6`\r\n"]}, {"number": 7321, "title": "Tensorflow retrained model compression fails with error: terminate called after throwing an instance of 'std::bad_alloc'\u00a0\u00a0 what():\u00a0 std::bad_alloc Aborted (core dumped) ", "body": "I am doing a college project on tensorflow. I have successfully retrained using rerain.py file, to use that model in android program. I was trying to compress the model using commands in the following\r\nlink: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size\r\n\r\nBut it is getting terminated throwing the below error:\r\nERROR:   terminate called after throwing an instance of 'std::bad_alloc'\u00a0\u00a0 what():\u00a0 std::bad_alloc Aborted (core dumped) \r\n\r\nI am working on  an Ubuntu 14.04 machine with 4GB RAM.\r\n\r\nPlease help.\r\n\r\nThanks,\r\nBruczzz", "comments": ["It sounds like you ran out of memory.  However, it's impossible for us to help with the level of detail you given.  For example, what command did you run that ran out of memory?", "I am referring the \"Shrinking File Size\" section given at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size\r\n\r\nThe command that failed was:\r\n\r\n<code>\r\nbazel build tensorflow/tools/graph_transforms:transform_graph\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=tensorflow_inception_graph.pb \\\r\n--out_graph=optimized_inception_graph.pb \\\r\n--inputs='Mul:0' \\\r\n--outputs='final_result:0' \\\r\n--transforms='\\\r\nround_weights(num_steps=256) \\\r\n'\r\n</code>\r\n", "@Bruczzz What version of TensorFlow are you using?  A request for this was in the instructions that you deleted when creating the issue.\r\n\r\n@petewarden What would `transform_graph` be doing that consumes a bunch of memory?  Are there huge constants in these graphs?", "Apologies, this is a known bug with the command line parser. If you remove the '\\' and newlines in the transform script it should work. I have a fix pending, I'm hoping to get it in soon.", "Thanks a lot @petewarden  and @girving. Now I am able to compress my retrained model successfully. ", "If you look at the Slim library, there's a pretrained Inception v1 model that only has seven million parameters and so shrinks down to 7MB. You might want to try fine-tuning that.\r\nhttps://github.com/tensorflow/models/blob/master/slim/README.md#Pretrained", "Thanks you so much @petewarden for your information and time.\r\n\r\nI tried fine tuning on V3 model using flower data as provided on tensorflow page, it is generating again a check point. Got stuck there with no clue of converting check point to .pb file. So that it can be compressed and used in android application.\r\n\r\nI have tried  compression of  inception v3 model using quantization in two ways, but i feel quantizied model is getting corrupted or on classification something going wrong and producing incorrect results. Raised issue on that : https://github.com/tensorflow/tensorflow/issues/7523\r\nPlease assist me.\r\nThanks ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "I am runnning into the same error with the following code. As I am quite new to tensor flow I am trying to understand what is actually causing the abort\r\n\r\n[paint2.txt](https://github.com/tensorflow/tensorflow/files/1199967/paint2.txt)\r\nI am sorry if it is a known bug. I am using python 3 tensorflow with pip install, GPU still not working. ", "Hi, I encountered the same problem when working on Ubuntu 16.04 virtual machine with 1GB memory. I trained a neural network with weights of 84MB in total. Is it possible that the model ended up so huge to take up all memory?", "Hi,i have the same issue after running 4 epoch,and i have tested in other machin,but problem exists.\r\nI use tensorflow 1.3,ubuntu 16.04,gtx 1080 gpu ,system ram=128\r\nand i am working on shared server with 3 gpus\r\nthis is my trainig code:\r\n\r\n\r\n\r\n\r\n[github.txt](https://github.com/tensorflow/tensorflow/files/1502929/github.txt)\r\n\r\n\r\n "]}, {"number": 7320, "title": "Tensorflow freezes for a small model in Windows 10", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n--> I have not been able to find any related information. I did post a SO thread (http://stackoverflow.com/questions/41889147/tensorflow-execution-freezes-for-a-small-cnn), and got the suggestion that I may have encountered a bug.\r\n\r\n### Environment info\r\nOperating System: \r\n--> Windows 10 home edition\r\n\r\nInstalled version of CUDA and cuDNN: \r\n--> None. Was using the CPU version.\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: \r\n--> https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.1-cp35-cp35m-win_amd64.whl\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n--> 0.12.1\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n--> Attached as \"Issue_example_code.txt\"\r\nA brief explanation of the issue: \r\nTraining freezes as I slightly increase the model size. For the attached code, using 50, 50 for the two fully-connected layers would work, but going slightly larger, e.g., to 100, 50, would result in execution freezing after model initialization or a few rounds of training. It does not seem to be constrained by memory, since when the freeze occurs the Python process takes around 50MB of memory (as observed from task manager), while when the training runs (for smaller sizes) it takes GB range of memory.\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n--> None, as I was unable to find related info by searching and I myself does not understand the possible cause of this issue.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\n[Issue_example_code.txt](https://github.com/tensorflow/tensorflow/files/756669/Issue_example_code.txt)\r\n\r\n", "comments": ["Can you get us a stack trace from where it freezes?  This isn't enough information to guess at a cause.  A Python stack trace would be a starting point; just hit ctrl-c or whatever the windows equivalent is.", "@girving Actually the ctrl-c doesn't work in this case: the console/execution simply stays frozen. I had to forcibly close the console or kill the process to terminate the execution.\r\n\r\nIs there another good way to gather more info?", "The ideal would be to run it through a debugger.  You could also try adding print statements until you localize it, but it'll be hard to get below the Python level with those.\r\n\r\n@mrry Do you have suggestions for Windows debugging?", "I've mainly used Visual Studio for debugging on Windows. The free Community edition should be able to attach to your frozen process and gather a stack trace.", "I have stepped through my code in the IDLE debugger and gotten the following stack trace:\r\n\r\n'__main__'.<module>(), line 87:_, l1, l2, predictions = session.run([optimizer, loss, loss_reg, train_prediction], feed_dict=feed_dict)\r\n'tensorflow.python.client.session'.run(), line 766: run_metadata_ptr)\r\n'tensorflow.python.client.session'._run(), line 964: feed_dict_string, options, run_metadata)\r\n'tensorflow.python.client.session'._do_run(), line 1014: target_list, options, run_metadata)\r\n'tensorflow.python.client.session'._do_call(), line 1021: return fn(*args)\r\n'tensorflow.python.client.session'._run_fn(), line 1003: status, run_metadata)\r\n\r\nThe execution then freezes at line 1001 when I tried to step into tf_session.TF_Run(...) there. Should I go deeper?", "@pengd49 Yes, unfortunately `TF_Run` is where everything happens, so it isn't specific enough yet.", "@girving If I understand it correctly, the TF_Run is ultimately defined in the file _pywrap_tensorflow.pyd, right? \r\n\r\nI'm sorry I am inexperienced in debugging a pyd file. From what I found online, it seems I will need to try to compile and generate a version of the pyd with debug flag in order to debug it?", "@pengd49 `TF_Run` is where essentially everything happens.  All it means is that the error is somewhere in C++ code.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 7319, "title": "can any body write one simple seq2seq model with attention ,the example given by tensorflow.org is too hard to understand!", "body": "can any body write one simple seq2seq model with attention ,the example given by tensorflow.org is too hard to understand!\r\n", "comments": ["Questions about the model should be asked on StackOverflow."]}, {"number": 7318, "title": "Make CNN input float32", "body": "Fixes #6342, fixes #6647.", "comments": ["jenkins, test this please.\r\n"]}, {"number": 7317, "title": "Tensorboard fails to load with latest install from source.", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttps://github.com/tensorflow/tensorflow/issues/1421\r\nhttps://github.com/tensorflow/tensorflow/issues/4596\r\nhttps://github.com/tensorflow/tensorflow/issues/1076\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\n-rw-r--r-- 1 root root   560184 Jul 23  2016 libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Jul 23  2016 libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Jul 23  2016 libcudart.so.8.0 -> libcudart.so.8.0.27\r\n-rwxr-xr-x 1 root root   394472 Jul 23  2016 libcudart.so.8.0.27\r\n-rw-r--r-- 1 root root   737516 Jul 23  2016 libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Jul 24  2016 libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Jul 24  2016 libcudnn.so.5 -> libcudnn.so.5.0.5\r\n-rwxr-xr-x 1 root root 78065952 Apr 22  2016 libcudnn.so.5.0.5\r\n-rw-r--r-- 1 root root 68709594 Apr 22  2016 libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\ncommit hash: eb225d71b394c24f49a2e07f685be94d4ab7496f\r\nbazel version\r\n```\r\nBuild label: 0.4.3\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Dec 22 12:31:25 2016 (1482409885)\r\nBuild timestamp: 1482409885\r\nBuild timestamp as int: 1482409885\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\nChrome dev tools shows that tensorboard is failing to load because of missing polymer.html\r\n```\r\nGET http://0.0.0.0:6006/polymer/polymer.html 404 (NOT FOUND)\r\n...Lots of other errors because Polymer is undefined...\r\n```\r\n", "comments": ["@dandelionmane Suggestions?  That doesn't look like the best URL.", "On it.", "This has now been fixed."]}, {"number": 7316, "title": "Explicit device does not work with saved GraphDef?", "body": "### explicit device seems not work with a saved GragphDef\r\nI try https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py\r\nand want to use gpu to classify an image.\r\n\r\nI change the create-graph code\r\n```\r\n  with tf.device(\"/gpu:0\"):\r\n    with tf.gfile.FastGFile(os.path.join(\r\n      FLAGS.model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\r\n      graph_def = tf.GraphDef()\r\n      graph_def.ParseFromString(f.read())\r\n      _ = tf.import_graph_def(graph_def, name='')\r\n\r\n  with tf.Session(config=tf.ConfigProto(\r\n      allow_soft_placement=True, log_device_placement=True)) as sess:\r\n```\r\nbut from logs all operations are done on cpu not gpu.\r\n\r\nIs there anyone to help me use gpu with classify_image.py\r\n### Environment info\r\nOperating System: Ubuntu 14.04 LTS, tensorflow 0.12.1\r\nCUDA: 7.5.18 \r\ncuDNN: v5.1\r\ninstalled via `sudo pip install tensorflow --upgrade`\r\n\r\n### Logs\r\n```\r\nconv_2/batchnorm/gamma: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv_2/batchnorm/gamma: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv_2/batchnorm/beta: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv_2/batchnorm/beta: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv_2/conv2d_params: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv_2/conv2d_params: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv_1/batchnorm/moving_variance: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv_1/batchnorm/moving_variance: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv_1/batchnorm/moving_mean: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv_1/batchnorm/moving_mean: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv_1/batchnorm/gamma: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv_1/batchnorm/gamma: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv_1/batchnorm/beta: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv_1/batchnorm/beta: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv_1/conv2d_params: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv_1/conv2d_params: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv/batchnorm/moving_variance: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv/batchnorm/moving_variance: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv/batchnorm/moving_mean: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv/batchnorm/moving_mean: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv/batchnorm/gamma: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv/batchnorm/gamma: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv/batchnorm/beta: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv/batchnorm/beta: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nconv/conv2d_params: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] conv/conv2d_params: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nMul/y: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] Mul/y: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nSub/y: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] Sub/y: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nResizeBilinear/size: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] ResizeBilinear/size: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nExpandDims/dim: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:827] ExpandDims/dim: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nDecodeJpeg/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n```", "comments": ["Sorry, it's a stupid question..\r\nI install tensorflow via `sudo pip install tensorflow --upgrade`, which does not support GPU.\r\nIt works fine with `sudo pip install tensorflow-gpu --upgrade`.\r\nThis issue can be closed."]}, {"number": 7315, "title": "Cherry-picks to bring tensorflow/compiler up-to-date with master in r1.0 branch.", "body": "This contains cherry-picks to bring all files under tensorflow/compiler in the r1.0 branch up-to-date with master.\r\n\r\nThis was accomplished by determining a a sequence of commits in oldest-to-newest order that could cleanly be cherry-picked.  This is represented by everything except the last 2 commits.\r\n\r\nThe second-to-last commit was manually merged, reverting unrelated tensorboard files.\r\n\r\nThe last commit was manually created, reverting files in directories other than tensorflow/compiler.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "The failing test is just flaky. After we revert the last commit, I can retest and merge this right away.\r\n", "OK, I've reverted the \"last commit\", so the innocuous files outside of tensorflow/compiler are also part of this PR.  My next message will either be idiotic or brilliant...", "Jenkins, test this please.", "Jenkins, test this please.", "http://ci.tensorflow.org/job/tensorflow-pull-requests-xla/1/\r\nRunning XLA tests on the PR to make sure its alive.", "Mac tests flaked.\r\nJenkins, test this please."]}, {"number": 7314, "title": "slice_input_producer does not return a queue", "body": "`tf.train.slice_input_producer` does not return a queue for each slice. This means the outputs cannot be used with the BaseReader api. Shouldn't this be consistent with the other `*_input_producer` methods like `string_input_producer`?\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttp://stackoverflow.com/questions/34340489/tensorflow-read-images-with-labels\r\n\r\n### Environment info\r\nOperating System:\r\nUbuntu 14.04\r\n\r\n### Installed version of CUDA and cuDNN: \r\nCuda 8.0.44\r\nCudnn 5.1.5\r\n\r\n### Tensorflow Version:\r\n0.12.1\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n```python\r\nimage_files = glob(...)\r\nlabel_files = [s.replace('image.jpg', 'labels.jpg') for s in image_files]\r\n# Create a queue where the elements are pairs (image, label)\r\nimage_queue, label_queue = tf.train.slice_input_producer([image_files, label_files])\r\nimages, labels = [], []\r\nfor _ in num_threads:\r\n    # Create two readers for each thread - one for the image and one for the label\r\n    image_reader, label_reader = tf.SomeReader(), tf.SomeReader()\r\n    # Read the image and label pair\r\n    _, image_op = image_reader.read(image_queue)\r\n    _, label_op = label_reader.read(label_queue)\r\n    images.append(image_op)\r\n    labels.append(label_op)\r\n```\r\n## Error\r\n```python\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py\", line 265, in read\r\n  return gen_io_ops._reader_read(self._reader_ref, queue_ref, name=name)\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 213, in _reader_read\r\n  queue_handle=queue_handle, name=name)\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 613, in apply_op\r\n  (input_name, op_type_name))\r\nTypeError: Input 'queue_handle' of 'ReaderRead' Op requires l-value input\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\nUsing two `string_input_producers` with the same random seed\r\n", "comments": ["Seems like an odd one out since other input producers give queues. cc @josh11b who added this code\r\n\r\n```\r\nwith ops.name_scope(name, \"input_producer\", tensor_list):\r\n    tensor_list = ops.convert_n_to_tensor_or_indexed_slices(tensor_list)\r\n    if not tensor_list:\r\n      raise ValueError(\r\n          \"Expected at least one tensor in slice_input_producer().\")\r\n    range_size = array_ops.shape(tensor_list[0])[0]\r\n    # TODO(josh11b): Add an assertion that the first dimension of\r\n    # everything in TensorList matches. Maybe just check the inferred shapes?\r\n    queue = range_input_producer(range_size, num_epochs=num_epochs,\r\n                                 shuffle=shuffle, seed=seed, capacity=capacity,\r\n                                 shared_name=shared_name)\r\n    index = queue.dequeue()\r\n    output = [array_ops.gather(t, index) for t in tensor_list]\r\n    return output\r\n```", "It may have an unfortunate name, but exists to provide an alternative to using a Reader in the case when all your data is in memory.  Enqueuing its output would just add overhead in its designed use case (see https://www.tensorflow.org/how_tos/reading_data/#preloaded_data ).  If you really need the output of this in a queue, you can create a queue, enqueue the output of slice_input_producer, and add that enqueue to a QueueRunner.  The functions in that file are intended to cover common use cases but there is no reason you need to be limited by them.", "For anyone interested in @josh11b 's solution, this worked for me (although I'm not sure if there is a better way). This is really helpful when your data and labels are in separate files.\r\n\r\n```python\r\nfrom tensorflow.python.training import queue_runner\r\n\r\ndef wrap_with_queue(tensor, dtypes=tf.string):\r\n    queue = tf.FIFOQueue(1, dtypes=dtypes)\r\n    enqueue_op = queue.enqueue(tensor)\r\n    queue_runner.add_queue_runner(queue_runner.QueueRunner(queue, [enqueue_op]))\r\n    return queue\r\n\r\nimage_files = glob(...)\r\nlabel_files = [s.replace('image.jpg', 'labels.jpg') for s in image_files]\r\n# Create a queue where the elements are pairs (image, label)\r\nimage_file_op, label_file_op = tf.train.slice_input_producer([image_files, label_files])\r\nimage_queue = wrap_with_queue(image_file_op)\r\nlabel_queue = wrap_with_queue(label_file_op)\r\n\r\nimages, labels = [], []\r\nfor _ in num_threads:\r\n    # Create two readers for each thread - one for the image and one for the label\r\n    image_reader, label_reader = tf.SomeReader(), tf.SomeReader()\r\n    # Read the image and label pair\r\n    _, image_op = image_reader.read(image_queue)\r\n    _, label_op = label_reader.read(label_queue)\r\n    images.append(image_op)\r\n    labels.append(label_op)\r\n\r\nsess = tf.Session()\r\ntf.train.start_queue_runners(sess=sess)\r\n```", "Be careful with \"images_queue, labels_queue\" construction. If they go into `train_op`, and you run this op in parallel (ie, from different Python threads), then your images and labels can go out of sync because your second run dequeues can \"wedge in\" between the first run's image_op dequeue and label_op dequeue. This is a natural consequence of `.run` calls not being atomic. More details in http://stackoverflow.com/questions/41920371/tensorflow-multi-threaded-queuerunner", "Given @josh11b 's response, it seems there are compelling reasons to break with the pattern here"]}, {"number": 7313, "title": "AttributeError: module 'tensorflow.contrib.learn' has no attribute 'SKCompat'", "body": "Hi,\r\n\r\nI cannon import SKCompat. Running 0.12.head on osx. Any ideas?", "comments": ["Resolved with upgrade to 1.0.0-rc1"]}, {"number": 7312, "title": "incorrect usage of num_gpus & num_workers in mnist_replica.py", "body": "[mnist_replica.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L126) has the following code. \r\n```\r\n if FLAGS.num_gpus < num_workers:\r\n    raise ValueError(\"number of gpus is less than number of workers\")\r\n```\r\nThis will work fine in a single worker setup with one or more GPUs. However, it will throw error if the number of workers is greater than the number of GPUs available in each worker. For example, using 2 workers each with 1 GPU will trigger this error.\r\n\r\nIt looks like this if-block can be removed. If that is an acceptable change, I can send a PR for that.", "comments": ["What would the extra worker use for compute?", "I am not sure what you mean by \"extra worker\". I am assuming that I can use any number of workers to run this example. I tried running it with 2 workers each with 1 GPU and got this error. Is that not a valid setup to run mnist_replica.py?", "I'm not familiar with this code, but I'm assuming that check is because it's inefficient to use more workers than GPUs, because each worker uses one GPU for compute.  Each worker does some compute, and in GPU mode this compute takes place on a GPU.", "In my case, I would like to use 2 GPU. However the workers I have in Cloud have only 1 GPU each. So, I had to use 2 workers to employ 2 GPUs for my job. I understand that getting a bigger VM with more GPU is more efficient and would not result in this error but the configuration I am using sounds like a valid one and I find this error unnecessarily restrictive.", "@skaarthik Ah, sorry for my confusion.  @mrry Does this check look wrong to you?  I tried finding who added it in the history, but failed.", "It looks wrong to me, but I think it might have a weird sense where it's used for multi-GPU in a single machine, but not multi-machine multi-GPU. @caisq wrote that code, so he can confirm.", "Sorry this fell through the cracks.  If you're still interested, @skaarthik, we'd be happy to accept a PR.", "Great. I will send a PR.", "Now that the PR is merged, can I close this issue?"]}, {"number": 7311, "title": "tfrecords giving parsing error when saved examples are too big", "body": "\r\nWhen I try to save a example to a tfrecord that is too large a parsing error occurs. I need to save a large sequence of float valued images (states of a fluid flow simulation) and when the states and sequences get too large a parsing error occurs.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI think that this might be the same error and problem that other people are getting when saving long sequences to tfrecords like seen here https://github.com/tensorflow/tensorflow/issues/5234 and https://github.com/OliviaMG/xiaomeng/issues/1. While both of these threads found solutions the underlining problem does not seem to be found.\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nUbuntu 16.04\r\nCUDA 8.0\r\nCUDNN 5.1\r\nTensorFlow 0.12.1\r\n\r\n### If possible, provide a minimal reproducible example\r\n\r\nRunning this minimal script will cause the error. Lowering the ```SIZE_RECORD``` value will cause the script to run with out error.\r\n\r\n```\r\nfrom tqdm import tqdm\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# this will kill it\r\nSIZE_RECORD=20000000\r\n# this will run just fine\r\n# SIZE_RECORD=2000000\r\n\r\nwriter = tf.python_io.TFRecordWriter(\"test.tfrecords\")\r\n# iterate over 10 times\r\n# wrap with tqdm for a progress bar\r\nfor example_idx in tqdm(xrange(2)):\r\n    features = np.zeros((SIZE_RECORD))\r\n\r\n    # construct the Example proto boject\r\n    example = tf.train.Example(\r\n        # Example contains a Features proto object\r\n        features=tf.train.Features(\r\n          # Features contains a map of string to Feature proto objects\r\n          feature={\r\n            # A Feature contains one of either a int64_list,\r\n            # float_list, or bytes_list\r\n            'image': tf.train.Feature(\r\n                float_list=tf.train.FloatList(value=features.astype(\"float\"))),\r\n    }))\r\n    # use the proto object to serialize the example to a string\r\n    serialized = example.SerializeToString()\r\n    # write the serialized object to disk\r\n    writer.write(serialized)\r\nwriter.close()\r\n\r\ndef read_and_decode_single_example(filename):\r\n    # first construct a queue containing a list of filenames.\r\n    # this lets a user split up there dataset in multiple files to keep\r\n    # size down\r\n    filename_queue = tf.train.string_input_producer([filename],\r\n                                                    num_epochs=None)\r\n    # Unlike the TFRecordWriter, the TFRecordReader is symbolic\r\n    reader = tf.TFRecordReader()\r\n    # One can read a single serialized example from a filename\r\n    # serialized_example is a Tensor of type string.\r\n    _, serialized_example = reader.read(filename_queue)\r\n    # The serialized example is converted back to actual values.\r\n    # One needs to describe the format of the objects to be returned\r\n    features = tf.parse_single_example(\r\n        serialized_example,\r\n        features={\r\n            # We know the length of both fields. If not the\r\n            # tf.VarLenFeature could be used\r\n            'image': tf.FixedLenFeature([SIZE_RECORD], tf.float32)\r\n        })\r\n    # now return the converted data\r\n    image = features['image']\r\n    return image\r\n\r\n# get single examples\r\nimage = read_and_decode_single_example(\"test.tfrecords\")\r\n# groups examples into batches randomly\r\nimages_batch = tf.train.shuffle_batch(\r\n    [image], batch_size=1,\r\n    capacity=3,\r\n    min_after_dequeue=2)\r\n\r\n# simple model\r\nw = tf.get_variable(\"w1\", [SIZE_RECORD, 1])\r\ny_pred = tf.matmul(images_batch, w)\r\nloss = tf.nn.l2_loss(y_pred - 1.0)\r\n\r\n# for monitoring\r\nloss_mean = tf.reduce_mean(loss)\r\n\r\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\r\n\r\nsess = tf.Session()\r\ninit = tf.initialize_all_variables()\r\nsess.run(init)\r\ntf.train.start_queue_runners(sess=sess)\r\n\r\n_, loss_val = sess.run([train_op, loss_mean])\r\nprint loss_val\r\nprint(\"worked!!!\")\r\n````\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nI have tried saving the example in a variety of different ways including converting it to a string and breaking up the vector into multiple features.\r\n\r\n### Logs or other output that would be helpful\r\n\r\nThis is the output when the tfrecord is too big\r\n\r\nW tensorflow/core/framework/op_kernel.cc:975] Invalid argument: Could not parse example input, value: '\r\n\ufffd\ufffd\ufffd&\r\n\ufffd\ufffd\ufffd&\r\nimage\u0012\ufffd\ufffd\ufffd&\u0012\ufffd\ufffd\ufffd&\r\n\ufffd\ufffd\ufffd&\r\nERROR:tensorflow:Exception in QueueRunner: 'utf8' codec can't decode byte 0x9b in position 40: invalid start byte\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 234, in _run\r\n    sess.run(enqueue_op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1021, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1003, in _run_fn\r\n    status, run_metadata)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 468, in raise_exception_on_not_ok_status\r\n    compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/compat.py\", line 84, in as_text\r\n    return bytes_or_text.decode(encoding)\r\n  File \"/usr/lib/python2.7/encodings/utf_8.py\", line 16, in decode\r\n    return codecs.utf_8_decode(input, errors, True)\r\nUnicodeDecodeError: 'utf8' codec can't decode byte 0x9b in position 40: invalid start byte\r\n\r\n\r\nThank!!!", "comments": ["@ebrevdo I'm suspicious that this is a TFRecord problem, since the sizes don't approach INT_MAX.  The next likely candidate is the example parsing code.  Thoughts?", "I have the same issue when writing large float lists to the tfrecords file. 64 MB seems to be the limit.", "@jonasrauber Ah, right.  Protobufs are limited to 64 MB outside of Google for some unfathomable reason.  @martinwicke Was there a hack to increase this?", "Using the other protobuf library as mentioned here doesn't help: https://github.com/tensorflow/tensorflow/issues/5676", "I am having a similar problem when trying to read my Example protocol bufffer in batches. I have also tried the other protobuf library, but that did not help. ", "Same issue for me. Increasing size of protobufs would be great :)", "Facing the same issue working with high-resolution images. Anyone find a hack around this?", "Looks like installing Tensorflow 1.1.0-rc0 solved the issue for me.", "I can also confirm that using Tensorflow 1.1.0 solved the problem for us.", "Same here :D\n\nOn Apr 24, 2017 4:33 PM, \"Elmer Garduno\" <notifications@github.com> wrote:\n\n> I can also confirm that using Tensorflow 1.1.0 solved the problem for us.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7311#issuecomment-296828348>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEv26DKUPuzl_kTfBrjuYtZKn7gvPlCwks5rzRU1gaJpZM4L4-up>\n> .\n>\n", "Thank you for checking back. I will close this issue as resolved in 1.1."]}, {"number": 7310, "title": "change tf.contrib.learn.datasets.load_dataset('boston') to sklearn.da\u2026", "body": "change tf.contrib.learn.datasets.load_dataset('boston') to sklearn.datasets.load_boston()\r\n\r\nchange tf.contrib.learn.datasets.load_dataset('iris') to sklearn.datasets.load_iris()\r\n\r\nbecause when run examples/learn/iris.py and examples/learn/boston.py  with python35, errors like followings occurs:\r\nUnicodeEncodeError: 'utf-16-le' codec can't encode character '\\udcds' in position 166: surrogates not allowed\r\nso it's better to change sklearn's method.\r\n", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "Jenkins, test this please.", "@hevensun: Can you check that the email address you used to sign the CLA matches the email address you used to author the change ? Our bot can't find a CLA for you.", "Why are you changing this?", "We should fix any issues instead of not using it. @ilblackdragon @martinwicke are we planning to keep sklearn compatibility such as using SKCompat in the long term?", "Yes, we want to keep SKCompat.\r\n\r\nFixing it would be good. It would be nice to be able to use these datasets with the sklearn dependency.", "@benoitsteiner I signed the CLA using google account hevensun@gmail.com with github account hevensun@126.com", "@martinwicke what can I have to do to fix this jenkins's failure? I just change boston and iris data load method to fix the exception I met,  I didn't change anything about this slim module, and I can pass this test with my python3.5. \r\n//tensorflow/contrib/slim/python/slim/data:dataset_data_provider_test    FAILED in 2.8s\r\n  **/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-py3-opt/testlogs/tensorflow/contrib/slim/python/slim/data/dataset_data_provider_test/test.log**\r\n\r\nExecuted 888 out of 888 tests: 887 tests pass and 1 fails locally.", "The test failure is not your fault.", "@hevensun you need to set your git commit email to match the one you signed the CLA with -- currently it is different.\r\n\r\n@martinwicke can you give approval if this LG to you?", "@vrv  @benoitsteiner  sorry to commit the branch with another account songgang@chinamobile.com, now I have changed the CLA to match the songgang's account. ", "it looks like the CLA is still not signed: I checked under that email and it doesn't look registered.  Can you try to redo the PR from scratch with the right git commit email ?  Thanks!!", "@vrv  @benoitsteiner  @martinwicke  as vrv suggested, I redo the PR #7512"]}, {"number": 7309, "title": "Include build fixes, and a filesystem fix for r1.0.", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.\r\n", "Also watching tf windows build:\r\nhttp://ci.tensorflow.org/job/tf-pr-win-bzl/11/"]}, {"number": 7308, "title": "Small inaccuracy in Mandelbrot tutorial", "body": "Just noticed a small inaccuracy in  [the Mandelbrot tutorial](https://www.tensorflow.org/tutorials/mandelbrot/):\r\n\r\nThere is a snippet like this:\r\n\r\n```\r\n# Use NumPy to create a 2D array of complex numbers on [-2,2]x[-2,2]\r\nY, X = np.mgrid[-1.3:1.3:0.005, -2:1:0.005]\r\n```\r\n\r\nIn the comment there is an area [-2,2]x[-2,2], but in the code itself it looks more like [-2.1]x[-1.3,1,3].\r\nNothing important but still slightly confusing :)\r\n\r\n", "comments": ["Thank you for the report! Was updating that tutorial anyway. I'll probably just take that bit out of the comment unless you have an objection.", "Another comment is puzzling for a novice that wants to know more:\r\n```\r\n# Note: We keep computing zs after they diverge! This\r\n#       is very wasteful! There are better, if a little\r\n#       less simple, ways to do this.\r\n```\r\nIs there some tutorial or a more specific reference how do it better?", "Interesting question. I'm guessing it involves partitioning the space to avoid iterating in the parts of the image which have provably diverged (imaginary part greater than 2). The Wikipedia article is actually quite good there.\r\n\r\nMaybe we could do some sort of SparseTensor followup which gets a speedup.", "Hi Allen, I wonder if you could help me with a problem I'm having with the Mandelbrot tuorial.  When the final statement is executed I get:\r\n\r\n>>> DisplayFractal(ns.eval())\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"<stdin>\", line 12, in DisplayFractal\r\n  File \"PIL/Image.py\", line 1439, in save\r\n    save_handler(self, fp, filename)\r\n  File \"PIL/JpegImagePlugin.py\", line 471, in _save\r\n    ImageFile._save(im, fp, [(\"jpeg\", (0,0)+im.size, 0, rawmode)])\r\n  File \"PIL/ImageFile.py\", line 476, in _save\r\n    fh = fp.fileno()\r\nio.UnsupportedOperation: fileno\r\n>>> \r\n\r\nLooking around it seems there might be some problem with IPython redirecting io streams but i don't know what I can do about it.  Thanks.", "It works for me in IPython.\\_\\_version\\_\\_ ==  '5.1.0' (python 3.4.3).\r\n\r\nMaybe try saving the image instead of displaying it by replacing:\r\n```\r\n  f = BytesIO()\r\n  PIL.Image.fromarray(a).save(f, fmt)\r\n  display(Image(data=f.getvalue()))\r\n```\r\nWith:\r\n```\r\n  PIL.Image.fromarray(a).save(\"/tmp/mandelbrot.jpg\")\r\n```", "Thanks, maybe I need to upgrade/install more software. Now I'm getting that encoder jpeg no available.", "If I decided to upgrade to python3 would I need to uninstall tensorflow before re-installing?", "Probably want to move these questions to StackOverflow. I don't think the Python version matters; it's probably IPython.", "Hmm, my IPython version is 5.4.1.  Maybe the tutorial should be upgraded to work with this version, which is probably the latest, at least for my ios.", "I've upgraded my IPython to 5.4.1 and switched to Python 2.7.6 and it works for me either way (saving to a file or as written in the tutorial) on Linux.\r\n\r\nBy \"for my ios\", do you mean you're on a Mac? That would in fact be a bug if there's a platform dependency. If so please open a new bug. We may just need to switch it to matplotlib or something. Bonus points if you follow up with a pull request which makes the tutorial work cross-platform."]}, {"number": 7307, "title": "Branch 146699987", "body": "", "comments": ["@tensorflow-jenkins test this please"]}, {"number": 7306, "title": "OutOfRangeError/Early EOF on file read in Windows Server 2012", "body": "Hi folks,\r\n\r\nI am finding that tensorflow code snippets which ran on Windows 10 are failing on Windows Server 2012/NTFS. In particular, anytime I try to load a file (with `tf.gfile.Open`, `tf.gfile.FastGFile`, or `tf.contrib.slim.assign_from_checkpoint_fn`), I encounter an \"out of range\" error.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI found [Git issue #6791 (Contrib support for Windows) ](https://github.com/tensorflow/tensorflow/issues/6791) where it was suggested that the fault lies with contrib packages. However, the code sample I provide below displays the problem without using any contrib imports.\r\n\r\n### Environment info\r\nOperating System: Windows Server 2012 R2\r\n\r\nInstalled version of CUDA and cuDNN: N/A\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: [tensorflow-0.12.1-cp35-cp35m-win_amd64.whl](https://pypi.python.org/packages/64/a3/0054a3329579de44d557f491adbcaf8127809a7992bc46af80f0a589e29b/tensorflow-0.12.1-cp35-cp35m-win_amd64.whl)\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`. **0.12.1**\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n```\r\nwith tf.Graph().as_default():\r\n        with tf.Session('') as sess:\r\n                image_data = tf.gfile.FastGFile(filepath_to_image, 'r').read()\r\n---------------------------------------------------------------------------\r\nOutOfRangeError                           Traceback (most recent call last)\r\n<ipython-input-11-a7847d42df75> in <module>()\r\n      1 with tf.Graph().as_default():\r\n      2     with tf.Session('') as sess:\r\n----> 3         image_data = tf.gfile.FastGFile(training_filenames[0], 'r').read()\r\nC:\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in read(self, n)\r\n    110       else:\r\n    111         length = n\r\n--> 112       return pywrap_tensorflow.ReadFromStream(self._read_buf, length, status)\r\n    113 \r\n    114   def seek(self, position):\r\nC:\\Anaconda\\envs\\py35\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n     64         if type is None:\r\n     65             try:\r\n---> 66                 next(self.gen)\r\n     67             except StopIteration:\r\n     68                 return\r\nC:\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py in raise_exception_on_not_ok_status()\r\n    467           None, None,\r\n    468           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 469           pywrap_tensorflow.TF_GetCode(status))\r\n    470   finally:\r\n    471     pywrap_tensorflow.TF_DeleteStatus(status)\r\nOutOfRangeError: reached end of file\r\n```\r\n\r\nA similar error is encountered when reading a text file, and a more complicated DataLossError occurs when trying to load a model from a checkpoint (but the trace includes references to \"out of range\" errors, so I assume the same underlying problem is responsible).\r\n\r\nThe same code snippet gives no error and returns the image byte data when run on the same version of Tensorflow on Windows 10 (also NTFS).\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nI can workaround this problem for images and text files by using native Python to read the files. However, I really need to use tensorflow built-ins to e.g. read a trained model from a checkpoint.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\nSee above for output of MWE.\r\n\r\nThanks very much for your help!", "comments": ["@mrry Do we support Windows Server 2012/NTFS?", "I doubt the issue is related to a specific release of Windows, but it could be a bug in the `file_io.py` library, which AFAIK doesn't distinguish between text and binary files (modes \"r\" versus \"rb\"), and I think this can invalidate file length checks.\r\n\r\n@rohan100jain Can you take a look at this?\r\n@mawah Can you share a minimal text file that reproduces this problem on Windows?", "Sure thing @mrry -- the following generates a text file and shows the error thrown:\r\n```\r\nimport tensorflow as tf\r\n\r\nwith open('labels.txt', 'w') as f:\r\n    f.write('0:0\\n1:1\\n')\r\n    \r\nwith tf.gfile.Open('labels.txt', 'r') as f:\r\n    lines = f.read()\r\n---------------------------------------------------------------------------\r\nOutOfRangeError                           Traceback (most recent call last)\r\n<ipython-input-2-3660054b17bb> in <module>()\r\n      5 \r\n      6 with tf.gfile.Open('labels.txt', 'r') as f:\r\n----> 7     lines = f.read()\r\n\r\nC:\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in read(self, n)\r\n    110       else:\r\n    111         length = n\r\n--> 112       return pywrap_tensorflow.ReadFromStream(self._read_buf, length, status)\r\n    113 \r\n    114   def seek(self, position):\r\n\r\nC:\\Anaconda\\envs\\py35\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n     64         if type is None:\r\n     65             try:\r\n---> 66                 next(self.gen)\r\n     67             except StopIteration:\r\n     68                 return\r\n\r\nC:\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py in raise_exception_on_not_ok_status()\r\n    467           None, None,\r\n    468           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 469           pywrap_tensorflow.TF_GetCode(status))\r\n    470   finally:\r\n    471     pywrap_tensorflow.TF_DeleteStatus(status)\r\n\r\nOutOfRangeError: reached end of file\r\n```\r\nEdit to clarify: this throws an error on my Windows Server 2012 (Azure N-series GPU) VM, but not on my local Windows 10 computer.", "Did you manage to resolve this issue? I am facing the same problem on Windows Server 2012. ", "Sorry @chadland, no progress yet. Not sure if @rohan100jain or @mrry need more information to repro the problem?", "Thanks for letting me know @mawah ", "Unfortunately I don't have easy access to a Windows Server 2012 box, so I haven't been able to reproduce the problem you are seeing. There is no obvious platform dependence in the `file_io` library that would explain different behavior on Windows Server 2012 and Windows 10.\r\n\r\n@rohan100jain, since you wrote that library, can you suggest what steps could be useful to debug this further?\r\n\r\n@mawah, based on my high-level understanding of the file system code, the problem stems from a mismatch between the length of the file (as reported by [`file_io.stat()`](https://github.com/tensorflow/tensorflow/blob/1bbb52426bd4f8046400731100b11e9ca767d303/tensorflow/python/lib/io/file_io.py#L470)) and the number of bytes that can be read from the file. When I ran your program, `labels.txt` is 10 bytes on disk (presumably because the `\\n` becomes `\\r\\n`), and the string read back in has length 10 (and contains the added `\\r` characters). Since you have access to both platforms, can you try to identify where the mismatch creeps in?", "Thanks @mrry,\r\n\r\nI also get a length of \"10\" using `file_io.stat()` on both Windows 10 and Windows Server 2012 with the code snippet below:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.lib.io.file_io import stat\r\nwith open('labels.txt', 'w') as f:\r\n    f.write('0:0\\n1:1\\n')\r\nstat('labels.txt').length\r\n```\r\nEvidently the problem lies elsewhere. I'm not sure where to find the definition of `pywrap_tensorflow`, which I would have examined next...thought it would be defined under the `[site-packages]\\tensorflow\\python` directory, but I'm having trouble locating it.", "Thanks for checking that. Does the file also have size 10 if you `dir` it at the command prompt?\r\n\r\nCan you also try printing each individual character of that file, using code like the following:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nwith tf.gfile.Open('labels.txt', 'r') as f:\r\n    print(f.tell())  # I'd expect this to print zero, but who knows?\r\n    for _ in range(10):\r\n        print(f.read(n=1))\r\n```\r\n\r\nI'd expect this to crash with an error when it eventually goes beyond the end of the file, but it would be interesting to learn where this happens....", "Thanks again @mrry. This certainly cleared up something for me. The following fails (regardless of whether the filepath is relative or absolute, and I did double-check that the file is still present):\r\n```\r\nimport tensorflow as tf\r\nwith tf.gfile.Open('labels.txt', 'r') as f:\r\n    print(type(f))\r\n    print(f.tell())\r\n---------------------------------------------------------------------------\r\n<class 'tensorflow.python.platform.gfile.GFile'>\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-6-f2213a8e47cc> in <module>()\r\n      3 \r\n      4 with tf.gfile.Open('labels.txt', 'r') as f:\r\n----> 5     print(f.tell())\r\n\r\nC:\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in tell(self)\r\n    140       raise errors.PermissionDeniedError(None, None,\r\n    141                                          \"File isn't open for reading\")\r\n--> 142     return self._read_buf.Tell()\r\n    143 \r\n    144   def __enter__(self):\r\n\r\nAttributeError: 'NoneType' object has no attribute 'Tell'\r\n```\r\n...which fully explains the origin of the OutOfRangeError on attempting to read from the file. (Unsurprisingly, I got that error again if I simply tried to read from `f` one character at a time.)\r\n\r\nAny idea why `tf.gfile.Open()` would return an object of class `tensorflow.python.platform.gfile.GFile` and `_read_check_passed` set to true, but still have `_read_buf=None`?", "Okay so one bug clearly is that the tell() method (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/lib/io/file_io.py#L147) needs to do a _preread_check() and not just check for _read_check_passed. That should fix the problem with Tell().\r\n\r\nIt should look like...\r\n\r\ndef tell(self):\r\n    \"\"\"Returns the current position in the file.\"\"\"\r\n    self._preread_check()\r\n    return self._read_buf.Tell()\r\n\r\nI'll send out that fix.\r\n\r\nThis still doesn't solve the problem that you experienced earlier (I think).. I agree with @mrry that the file sizes somehow are the culprit...\r\n\r\nFYI the pywrap_tensorflow method comes from file_io.i (SWIG wrapping the c++ interface).\r\n\r\nThe C++ implementation is in core/platform/env.cc core/platform/file_system.cc. Hopefully this might help you debug more if you want to dig into it further. \r\n\r\nWhen you read it one byte at a time.. where did it crash? ", "Hi @rohan100jain and @mrry ,\r\nI added a call to `f._preread_check()`. Even so, looks like the `for` loop crashes while trying to read the first byte:\r\n```\r\nimport tensorflow as tf\r\nwith tf.gfile.Open('labels.txt', 'r') as f:\r\n    f._preread_check()\r\n    print('Result of f.tell(): {}'.format(f.tell()))\r\n    for _ in range(10):\r\n        print(f.read(n=1))\r\n```\r\nOutput:\r\n```\r\nResult of f.tell(): 0\r\n---------------------------------------------------------------------------\r\nOutOfRangeError                           Traceback (most recent call last)\r\n<ipython-input-15-ae33091a7083> in <module>()\r\n      5     print('Result of f.tell(): {}'.format(f.tell()))\r\n      6     for _ in range(10):\r\n----> 7         print(f.read(n=1))\r\n\r\nC:\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in read(self, n)\r\n    110       else:\r\n    111         length = n\r\n--> 112       return pywrap_tensorflow.ReadFromStream(self._read_buf, length, status)\r\n    113 \r\n    114   def seek(self, position):\r\n\r\nC:\\Anaconda\\envs\\py35\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n     64         if type is None:\r\n     65             try:\r\n---> 66                 next(self.gen)\r\n     67             except StopIteration:\r\n     68                 return\r\n\r\nC:\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py in raise_exception_on_not_ok_status()\r\n    467           None, None,\r\n    468           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 469           pywrap_tensorflow.TF_GetCode(status))\r\n    470   finally:\r\n    471     pywrap_tensorflow.TF_DeleteStatus(status)\r\n\r\nOutOfRangeError: reached end of file\r\n```", "The same error occurs in window 7 64bit. \r\n\r\nOutput:\r\n    mnist = input_data.read_data_sets(\"./MNIST_DATA\", one_hot=True)\r\n  File \"C:\\Users\\LEE\\Documents\\Visual Studio 2015\\Projects\\PythonApplication1\\deepLearning\\input_data.py\", line 196, in read_data_sets\r\n    train_images = extract_images(local_file)\r\n  File \"C:\\Users\\LEE\\Documents\\Visual Studio 2015\\Projects\\PythonApplication1\\deepLearning\\input_data.py\", line 64, in extract_images\r\n    buf = bytestream.read(rows * cols * num_images)\r\n  File \"H:\\Util\\Anaconda3\\lib\\gzip.py\", line 274, in read\r\n    return self._buffer.read(size)\r\n  File \"H:\\Util\\Anaconda3\\lib\\_compression.py\", line 68, in readinto\r\n    data = self.read(len(byte_view))\r\n  File \"H:\\Util\\Anaconda3\\lib\\gzip.py\", line 467, in read\r\n    buf = self._fp.read(io.DEFAULT_BUFFER_SIZE)\r\n  File \"H:\\Util\\Anaconda3\\lib\\gzip.py\", line 82, in read\r\n    return self.file.read(size)\r\n  File \"H:\\Util\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 112, in read\r\n    return pywrap_tensorflow.ReadFromStream(self._read_buf, length, status)\r\n  File \"H:\\Util\\Anaconda3\\lib\\contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"H:\\Util\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 469, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: reached end of file", "@mrry and @rohan100jain, if limited access to a Windows environment prevents you from investigating this, I could set up a low-performance Azure VM with my monthly personal MSDN credits. (Couldn't run it all month, but certainly long enough for you to have a look.) You can reach me at mawah at microsoft if interested.", "I remember seeing above gzip trace above back in October and there was some discussion about eof semantic in ReadFromStream(). Just tried my old test app again and it fails, but seem to work linux. I can debug this a little ... might take a day or 2 before I get to it,", "spend some time on this: \r\n@smartdolphin I can reproduce the same exception on 0.12.1 but on 1.0 this is gone.  Could you update to 1.0 (pip install --upgrade tensorflow) and see if this works for you?\r\n@mawah, I can't reproduce your problem. I'll send you some email if we can debug this in your setup. ", "Hi folks, the error was resolved by upgrading to Tensorflow 1.0.0 (which has been released in the meantime). Closing this issue.", "***Do we have a solution/work-around in Windows 10?***\r\n\r\nIssue still exists in Windows 10, Tensorflow 1.0.1 (GPU)\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-6-415a7deab32c> in <module>()\r\n      1 with tf.gfile.GFile(\"train.x.txt\", \"r\") as f:\r\n----> 2     print(f.tell())  # I'd expect this to print zero, but who knows?\r\n      3     for _ in range(10):\r\n      4         print(f.read(n=1))\r\n\r\nc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in tell(self)\r\n    140       raise errors.PermissionDeniedError(None, None,\r\n    141                                          \"File isn't open for reading\")\r\n--> 142     return self._read_buf.Tell()\r\n    143 \r\n    144   def __enter__(self):\r\n\r\nAttributeError: 'NoneType' object has no attribute 'Tell'", "@oldmonk101 This bug (`tell()` raising an `AttributeError` if called before `read()` or `write()`) was present in all versions of TensorFlow up to 1.0.1, but is fixed in 1.1. Upgrading to the 1.1 release candidate or nightly version will fix the problem.", "Tried Tensorflow 1.1.0-rc0 - f.tell() is giving right result (0). f.size() is still throwing OutOfRangeError"]}, {"number": 7305, "title": "Added Python Pandas to Docker Images", "body": "For more info/discussion: #7304", "comments": ["Can one of the admins verify this patch?", "@thesuperzapper FYI, the changes should take effect at the next nightly docker build and push."]}, {"number": 7304, "title": "Python Pandas in Docker Images", "body": "### Feature\r\n\r\nWhat are everyone's opinions on including Python Pandas in the [Docker images](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker)?\r\n\r\n### Reason\r\n\r\nTF.Lean is commonly used with Pandas for data ingestion, (And [in many](https://www.tensorflow.org/tutorials/wide/) of the [examples](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/text_classification.py)). The Docker implementation is a noob-friendly way to install TensorFlow, and given this, is likely to be used with TF.Learn.\r\n\r\n### Pull Request\r\nIf we decide to implement this, here's a Pull Request: #7305 ", "comments": ["@caisq Preferences?", "@thesuperzapper @girving I agree that pandas is a frequently used package for TF Docker image users. According to my analysis, this leads to an increase in the docker image size by a modest 18 MB. So I will approve this PR. Thank you for sending the PR."]}, {"number": 7303, "title": "Creating cyclic graphs with the C API", "body": "I'm trying to use the C API to create a cyclic graph that corresponds to a while loop with `merge` and `switch` operations. \r\n\r\nIt doesn't seem possible though, since `TF_AddInput` requires a `TF_Operation` pointer, which in turn can only come from `TF_FinishOperation`, which expects all the inputs of the `TF_OperationDescription` to be filled in.  How can you create cyclic graph by creating nodes one at a time, if to create each node, all its input must already be created?\r\n\r\nJust wanted to check I'm not missing anything. Thanks!", "comments": ["I believe you need to have all inputs ready in the C API for now. @yuanbyu can give suggestions on the while loop construction. Thanks.", "Great. It also occurs to me that I could perhaps just construct the appropriate `GraphDef` proto for my cyclical graph and then use `TF_ImportGraphDef`. ", "Support for creating while loops from the C API is in progress (@skye), but is not there yet.\r\n\r\nIn the mean time, yes, you can still create the graph in python and then importing it using `TF_ImportGraphDef`", "Closed now by https://github.com/tensorflow/tensorflow/commit/661058e52460b36417573e2c5a73de9a8b9e5edb?", "Yes, thanks!"]}, {"number": 7302, "title": "Weird grouping of tf.layers ops in TensorBoard graph visualization", "body": "This doesn't always happen, but sometimes when stacking multiple tf.layers, variables get placed in previous layers' graphical boxes. Setting variable_scope prevents this, but it's still a bit confusing as to why this is happening. It could have something to do with how tf.layers decide on a scope name automatically.\r\n\r\nAn example on TensorFlow 1.0.0-rc0 (but I think this also happens on the current PyPI release):\r\n![image](https://cloud.githubusercontent.com/assets/1595907/22663580/686737ee-ecad-11e6-8044-5e09749378cc.png)\r\n\r\n```python\r\nx = tf.layers.conv2d(x, ...)\r\nx = tf.layers.conv2d(x, ...)\r\nx = tf.layers.conv2d(x, ...)\r\n```\r\n\r\nAs it's hard to reproduce, I think it could be related to having multiple runs in the same TensorBoard, and some kind of namespace collision happening.", "comments": ["@dandelionmane Can you comment?", "Reassigning to @dsmilkov and @chihuahua for graph visualizer expertise. \r\n\r\n@carlthome, please post a full reproduction, including code that generates a bad graph, and the .pbtxt (or event files) that will repro", "Indeed, a full repro would be useful. That being said, I think I might've just repro-ed this case (except with a 1D convolution lol).\r\n\r\nIn the diagram below, is what you mean that the `kernel` and `bias` Variables within the conv1d_2 box really belong to conv1d_3? And that the `kernel` and `bias` Variables within the conv1d_1 box really belong to conv1d_2?\r\n\r\n![pbcpih3hgdx](https://cloud.githubusercontent.com/assets/4221553/23194401/bce29ff0-f862-11e6-85e9-4849bdce9713.png)\r\n\r\nIf so, this looks like a tflearn or TF convolution op scoping-related bug. I'll do a little research on that.", "Sorry for not being able to provide a concrete example of how to reproduce the problem. I've been unable to precisely track it down in my experiments. Good to hear you're on it, @chihuahua!\r\n\r\n> In the diagram below, is what you mean that the kernel and bias Variables within the conv1d_2 box really belong to conv1d_3? And that the kernel and bias Variables within the conv1d_1 box really belong to conv1d_2?\r\n\r\nYes, exactly.", "Giving each `tf.layers.conv2d` an explicit name makes the graph look as expected, so I guess there's something wonky with how names are generated to avoid variable reuse?", "This is still an issue in 1.1rc2.", "We really appreciate this issue report, however I'm going to close it out due to inactivity. We're still open to solving this issue, but we need a simple way to reproduce it. If anyone in the community can help us out on that end, please file an issue against our new GitHub repository. Be sure to reference this issue. https://github.com/tensorflow/tensorboard/issues/new", "Indeed, I can't reproduce the issue. It seems fixed for `tf.contrib.layers.convolution2d`.\r\n\r\n![2hrmeqxceix](https://user-images.githubusercontent.com/4221553/27247319-4691cfca-52ac-11e7-8690-dae5ec118089.png)\r\n\r\n"]}, {"number": 7301, "title": "Bump the protobuf version to 3.2.0", "body": "Removes the 64 MB default limit.", "comments": ["This is great!\r\nWe still need to build and upload our own protobuf packages for cpp implementations right?", "Yep, after this is submitted, I plan to:\r\n\r\n- Build protobuf 3.2.0 and upload it\r\n- Update the documentation to point to the new versions on the website\r\n- Update the version we depend on in the pip package for TF 1.1."]}, {"number": 7300, "title": "API documentation \"Core graph data structures\"", "body": "A few things are wrong in the documentation around [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/framework.md#tfgraphadd_to_collectionname-value-graphadd_to_collection](url).\r\n\r\n* Near the end of tf.Graph.name_scope, the line about ValueError is incomplete.\r\n* The paragraph at the very end of tf.Graph.name_scope should be in tf.Graph.add_to_collection.\r\n* Both tf.Graph.add_to_collection and tf.Graph.add_to_collections (plural) exist.", "comments": ["The link you posted is broken.", "Sorry. Please use https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/framework.md then scroll down to the end of tf.Graph.name_scope .", "@mrry Looks like you changed the documention in cl/126447618 to the rules are the", "I'm submitting a fix for the broken docstring in `tf.Graph.name_scope()`.\r\n\r\nThe bad formatting between `tf.Graph.name_scope()` and the paragraph describing collections is (I believe) a function of the doc generator, which @josh11b touched last and will be best placed to fix.\r\n\r\nI don't know what the problem is about having `tf.Graph.add_to_collection()` and `tf.Graph.add_to_collections()`, other than it seems a bit redundant. Regardless, we're stuck with supporting both of those methods because of the 1.0 API freeze.", "I'm closing this, as the formatting and paragraph whatnot is fixed on this new page:  https://www.tensorflow.org/api_docs/python/tf/Graph#name_scope\r\nPlease re-open or re-file if I'm missing something."]}, {"number": 7299, "title": "Merge r1.0 branch to master", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->"]}, {"number": 7298, "title": "Branch 146677928", "body": "", "comments": ["Hmm, were there some manual edits done in this change? It's missing `tensorflow/go/op/wrappers.go` which was added in cl/146572093.\r\n\r\nThat file shows up when I run movechanges.py manually, so I don't think it's part of the script. @asimshankar fyi"]}, {"number": 7297, "title": "Slow GPU performance", "body": "Fresh installed on Azure Linux VM with Nvidia Tesla M60 which has 2x8 GB Ram and dual GPU but program prints only one GPU and 8 GB ram as available. Result is worse than GTX 1080.\r\n\r\nI can't find specific information for Tesla M60. Is there any trick for dual core GPU's ? \r\n\r\n \r\n\r\n\r\n", "comments": ["1. You can't match fp32 performance of a good gaming card with current cloud compute offering. M60 is rated for peak 3.8 TFlops per core, whereas 1080 is is 8.4 TFlops. Also, M60 is an older Pascal architecture, so it's peak flops are harder to achieve.\r\n2. They may be physically attached, but from software standpoint, each GPU chip is a separate device. Do any other tools see both GPUs? Can you rule out driver issues? Our system people had some difficulty getting multi-GPU setups to work on Azure although I don't have details handy.\r\n3. TensorFlow networks usually only utilize 1 GPU, you need a special architecture that will use more than one. Cifar multi-GPU example is one such -- https://www.tensorflow.org/tutorials/deep_cnn/#training_a_model_using_multiple_gpu_cards", "Thank you for detailed information. \r\n\r\nOutput when I run code : \r\n\r\nFound device 0 with properties: \r\nname: Tesla M60\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.1775\r\npciBusID 85bb:00:00.0\r\nTotal memory: 7.93GiB\r\nFree memory: 7.86GiB\r\n\r\nAlso output from nvidia-smi \r\n\r\n![screen shot 2017-02-07 at 04 43 07](https://cloud.githubusercontent.com/assets/6421164/22674263/a9c7937a-ece7-11e6-9f0d-197c9c4cf63e.png)\r\n\r\nI work with neural style transfer between two images which takes minutes (almost same with my local gtx 970 ) and I'm not satisfied because I want to return result with REST Api and minutes are so long in this case. \r\n\r\nI will check  Cifar multi-GPU example definitely. Thanks again.\r\n\r\n"]}]