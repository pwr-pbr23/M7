[{"number": 14699, "title": "A very strange bug with tf.cond, update_ops and global_step", "body": "I'm using tf.Estimator with custom model_fn. When training, the estimator usually outputs log like:\r\n\r\nINFO:tensorflow:loss = 1109.14, step = 1\r\nINFO:tensorflow:loss = 937.876, step = 101 (6.245 sec)\r\nINFO:tensorflow:loss = 632.192, step = 201 (6.195 sec)\r\n\r\nBy default, the printed steps should be 1, 101, 201... However, when I use the following function (which is simplified to reproduce the bug) in any place of the model:\r\n\r\n```\r\ndef my_op(inputs, name=None):\r\n  with tf.variable_scope(name, default_name='my_scope', reuse=False):\r\n    count = tf.get_variable('count', shape=[],\r\n      initializer=tf.zeros_initializer(), trainable=False)\r\n\r\n    def myfunc1():\r\n      return 1\r\n\r\n    def myfunc2():\r\n      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, count.assign_add(10.0))\r\n      return 1\r\n\r\n    tf.cond(tf.less(1, 2), myfunc1, myfunc2)\r\n    return inputs\r\n\r\n```\r\n\r\nThe log becomes something like:\r\n\r\nINFO:tensorflow:loss = 1130.58, step = 0\r\nINFO:tensorflow:loss = 940.298, step = 0 (6.352 sec)\r\n\r\nThe global step is always 0. After some tests, I found that the global step is not updated if myfunc2 is not executed. For example, if I write\r\n`    tf.cond(tf.less(count, 2), myfunc1, myfunc2)`\r\nthen the global step is always 1.\r\n\r\nI suspect that this is caused by the tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, ...) in myfunc2, in which my intend is to update a variable when some condition holds. Maybe op created inside tf.cond can not be used as a dependency outside, but no error message is reported.\r\n\r\nIf I cannot add ops to UPDATE_OPS inside tf.cond, does this imply that stateful operations (like tf.layers.batch_normalization) can not be used inside tf.cond? So I cannot dynamically choose a network module from a set of network modules to execute if the network modules use any stateful operations like tf.layers.batch_normalization?\r\n\r\nmy tensorflow version: ('v1.4.0-rc0-10-g756a7fc', '1.4.0-rc1')", "comments": ["@skye might have some ideas behind the interaction between `tf.cond` and the global step.", "I was unable to reproduce this bug given the information provided. The following script runs as expected (running release v1.3.0). \r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef my_op(inputs, name=None):\r\n  with tf.variable_scope(name, default_name='my_scope', reuse=False):\r\n    count = tf.get_variable('count', shape=[],\r\n      initializer=tf.zeros_initializer(), trainable=False)\r\n\r\n    def myfunc1():\r\n      return 1\r\n\r\n    def myfunc2():\r\n      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, count.assign_add(10.0))\r\n      return 1\r\n\r\n    tf.cond(tf.less(count, 2), myfunc1, myfunc2)\r\n    return inputs\r\n\r\nglobal_step = tf.get_variable('global_step', [],\r\n  initializer=tf.zeros_initializer(), trainable=False, dtype=tf.int32)\r\na = tf.placeholder(tf.float32, [None, 5])\r\nb = tf.placeholder(tf.float32, [None, 3])\r\na_out = tf.layers.dense(my_op(a, 'somewhere'), 3)\r\n\r\nloss = tf.losses.mean_squared_error(b, a_out)\r\nopt = tf.train.AdamOptimizer(learning_rate=1e-2)\r\n\r\ntrain_op = opt.minimize(loss, global_step)\r\n\r\nwith tf.Session() as sess:\r\n  sess.run(tf.global_variables_initializer())\r\n\r\n  print(sess.run(global_step)) # prints 0\r\n  sess.run(train_op, { a: [[0.1, 0.2, 0.3, 0.4, 0.5]], b: [[1., 2., 3.]] })\r\n  print(sess.run(global_step)) # prints 1\r\n  sess.run(train_op, { a: [[0.1, 0.2, 0.3, 0.4, 0.5]], b: [[1., 2., 3.]] })\r\n  print(sess.run(global_step)) # prints 2\r\n  sess.run(train_op, { a: np.empty(shape=[0,5]), b: np.empty(shape=[0,3]) })\r\n  print(sess.run(global_step)) # prints 3\r\n```\r\n\r\nAs does changing the `tf.less(count, 2)` to `tf.less(1,2)`.\r\nAs does using `a` directly in the `tf.layers.dense`, but still calling `my_op(a, 'somewhere')` elsewhere.\r\nAs does using a different `Optimizer`.\r\n\r\nSo there's another piece to this puzzle; there's something else going on to cause the issue.\r\n  ", "I figured out the missing ingredient to reproduce the bug: you need to put your `opt.minimize` inside a `with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS))`\r\n\r\nTurns out this is a rather dangerous bug: Adding an operation to a collection inside a function used in a `tf.cond` **silently** prevents any operations that use that collection as a control dependency, regardless of whether that `tf.cond` is ever used.\r\n\r\nSo, it's not just the global_step; it's everything! Here's the minimal code I put together to highlight the bug in action.\r\n\r\n``` python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nflag = tf.placeholder(tf.bool, [])\r\nglobal_step = tf.train.get_or_create_global_step()\r\n\r\n# Include breaking code, putting a no_op inside a cond,\r\n# which isn't even used anywhere, and shouldn't impact anything else\r\ndef myfunc():\r\n  tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, tf.no_op())\r\n  return 1\r\ntf.cond(flag, myfunc, lambda: 1)\r\n\r\n# Make our ad hoc model\r\na = tf.placeholder(tf.float32, [None, 5])\r\nb = tf.placeholder(tf.float32, [None, 3])\r\na_out = tf.layers.dense(a, 3)\r\ngraph = tf.get_default_graph()\r\nbias = graph.get_tensor_by_name('dense/bias:0')\r\nweights = graph.get_tensor_by_name('dense/kernel:0')\r\n\r\n# Define our train_op\r\nloss = tf.losses.mean_squared_error(b, a_out)\r\nopt = tf.train.GradientDescentOptimizer(learning_rate=1e-2)\r\nwith tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\r\n  train_op = opt.minimize(loss, global_step)\r\n\r\n# Test everything\r\nwith tf.Session() as sess:\r\n  sess.run(tf.global_variables_initializer())\r\n\r\n  print('BEFORE ANYTHING IS RUN')\r\n  print(sess.run(global_step))\r\n  print(sess.run(bias))\r\n  print(sess.run(weights))\r\n  sess.run(train_op, { a: [[0.1, 0.2, 0.3, 0.4, 0.5]], b: [[1., 2., 3.]], flag: False })\r\n  print('AFTER FIRST RUN:  we do not follow the path with the update op added')\r\n  print(sess.run(global_step))\r\n  print(sess.run(bias))\r\n  print(sess.run(weights))\r\n  sess.run(train_op, { a: [[0.1, 0.2, 0.3, 0.4, 0.5]], b: [[1., 2., 3.]], flag: True })\r\n  print('AFTER SECOND RUN: we follow the path with the update op added')\r\n  print(sess.run(global_step))\r\n  print(sess.run(bias))\r\n  print(sess.run(weights))\r\n```\r\n\r\nRunning the above code gives\r\n\r\n```\r\nBEFORE ANYTHING IS RUN\r\n0\r\n[ 0.  0.  0.]\r\n[[-0.37039062 -0.37549886  0.73892838]\r\n [-0.20615649  0.03782606  0.50503689]\r\n [-0.43216512  0.73242658  0.42330664]\r\n [ 0.11180687  0.07816333 -0.02583456]\r\n [ 0.15668219  0.58735186  0.83961934]]\r\nAFTER FIRST RUN:  we do not follow the path with the update op added\r\n0\r\n[ 0.  0.  0.]\r\n[[-0.37039062 -0.37549886  0.73892838]\r\n [-0.20615649  0.03782606  0.50503689]\r\n [-0.43216512  0.73242658  0.42330664]\r\n [ 0.11180687  0.07816333 -0.02583456]\r\n [ 0.15668219  0.58735186  0.83961934]]\r\nAFTER SECOND RUN: we follow the path with the update op added\r\n1\r\n[ 0.00723237  0.0099021   0.01525755]\r\n[[-0.36966738 -0.37450865  0.74045414]\r\n [-0.20471002  0.03980648  0.50808841]\r\n [-0.42999542  0.73539722  0.42788389]\r\n [ 0.11469982  0.08212417 -0.01973154]\r\n [ 0.16029838  0.59230292  0.84724814]]\r\n```\r\n\r\nI looked around for other people experiencing problems with adding ops to the UPDATE_OPS collection inside a `tf.cond` and couldn't find anything. The fact that it completely halts training despite not being a required node for the `train_op` and without any errors means that you could silently break your whole training with just those few lines.", "@Multihuntr thank you for digging into this! I have a large backlog of issues to diagnose so I can't look into a potential fix for this right now, so for now it's probably best to avoid adding to collections inside a cond.", "I've played around with it a little more, and it turns out that this issue only occurs when the operation is actually created inside the cond. So this will work fine:\r\n\r\n```python\r\na_no_op = tf.no_op()\r\ndef myfunc():\r\n  tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, a_no_op)\r\n  return 1\r\ntf.cond(tf.less(2,1), myfunc, lambda: 1)\r\n```\r\n\r\nBut this will break everything:\r\n\r\n```python\r\ndef myfunc():\r\n  tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, tf.no_op())\r\n  return 1\r\ntf.cond(tf.less(2,1), myfunc, lambda: 1)\r\n```\r\n\r\nThis is because the operations defined outside the `myfunc` are always executed, regardless of the result of the condition. So, you CAN use batch norm with conditionals, you just have to define the branch containing the batch norm outside the `tf.cond`. However this means that that branch will always execute. This is definitely a workaround that will only work in some cases (e.g. it does not solve the OP's problem, as the assignment operation should only be executed once).\r\n\r\nI'll definitely avoid this, but the biggest problem I can see is that it's silent and extremely easy to accidentally cause (using batch norm in a conditional is perfectly reasonable). I wonder how many people have been stung by this and not even known that it was a bug within tensorflow itself.\r\n\r\nIs there some way we can make this bug more visible? Hotfix the docs for tf.cond or something?", "A better solution for using batch norm inside a conditional: [`tf.contrib.layers.batch_normalization`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm) allows you to set `updates_collections=None` to force the updates to happen before you get the batch norms output (and thus not adding them to UPDATE_OPS).\r\n\r\nHowever [`tf.layers.batch_normalization`](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization) doesn't seem to have this option.\r\n\r\nIf you use Sonnet, then when constructing the batch norm module, you can use `update_ops_collection=None` ([source](https://github.com/deepmind/sonnet/blob/master/sonnet/python/modules/batch_norm.py#L172)).", "Ah, that's actually a fairly general workaround. Instead of adding ops to the UPDATE_OPS, you enforce that it must be completed before getting the output of your branch in the `tf.cond`.\r\n\r\nSo the workaround to the OPs problem is to rewrite their `myfunc2` as follows:\r\n\r\n```python\r\n  def myfunc2():\r\n      with tf.control_dependencies([count.assign_add(10.0)]):\r\n        return 1\r\n```\r\n\r\nP.S. Sorry for triple post", "The similar issue has appeared several times in #18795, #14809. I think it's a good feature to add an extra option to `layers.batch_normalization`, similar to that of `contrib.batch_norm`.", "I have a similar issue with using the optimizer and tf.cond. Here is the simplified code:\r\n\r\n    def optimize(loss):\r\n    \r\n        with tf.name_scope('Optimizer'):\r\n            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    \r\n            with tf.control_dependencies(update_ops):\r\n                optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n                    def prev_grads_are_None():\r\n            \r\n                        # This will compute the local gradient given the loss function (taking into account all trainable variables)\r\n                        train_step = optimizer.minimize(loss)\r\n                        grads_wrt_initial_state = tf.gradients(loss, initial_state, grad_ys=None)\r\n            \r\n                        return train_step, grads_wrt_initial_state\r\n        \r\n                train_step, grads_wrt_initial_state = tf.cond(this_is_last_batch, prev_grads_are_None, prev_grads_are_None)\r\n                return train_step, grads_wrt_initial_state\r\n\r\nSo when running the code in Jupyter Notebook, the kernel shows busy, but nothing seems to continue running. Please note that I am training a 2 layer GRU.", "This is a stale issue. Please check the issue with latest TensorFlow. If the issue still persists in the newer version of TF, please feel free to reopen it by providing details about the issue and a standalone code to reproduce the issue. Thanks!", "I ran my test code again using the `tensorflow/tensorflow:1.13.2-gpu-py3` docker image. This issue still exists in the latest version of Tensorflow. For ease of explanation, here is a minimum example that you can copy-paste into the python interpreter (the same as my test code above):\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nflag = tf.placeholder(tf.bool, [])\r\nglobal_step = tf.train.get_or_create_global_step()\r\n\r\n# Include breaking code, putting a no_op inside a cond,\r\n# which isn't even used anywhere, and shouldn't impact anything else\r\ndef myfunc():\r\n  tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, tf.no_op())\r\n  return 1\r\n\r\n  \r\ntf.cond(flag, myfunc, lambda: 1)\r\n\r\n# Make our ad hoc model\r\na = tf.placeholder(tf.float32, [None, 5])\r\nb = tf.placeholder(tf.float32, [None, 3])\r\na_out = tf.layers.dense(a, 3)\r\ngraph = tf.get_default_graph()\r\nbias = graph.get_tensor_by_name('dense/bias:0')\r\nweights = graph.get_tensor_by_name('dense/kernel:0')\r\n\r\n# Define our train_op\r\nloss = tf.losses.mean_squared_error(b, a_out)\r\nopt = tf.train.GradientDescentOptimizer(learning_rate=1e-2)\r\nwith tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\r\n  train_op = opt.minimize(loss, global_step)\r\n\r\n\r\n# Test everything\r\nwith tf.Session() as sess:\r\n  sess.run(tf.global_variables_initializer())\r\n  print('BEFORE ANYTHING IS RUN')\r\n  print(sess.run(global_step))\r\n  print(sess.run(bias))\r\n  print(sess.run(weights))\r\n  sess.run(train_op, { a: [[0.1, 0.2, 0.3, 0.4, 0.5]], b: [[1., 2., 3.]], flag: False })\r\n  print('AFTER FIRST RUN:  we do not follow the path with the update op added')\r\n  print(sess.run(global_step))\r\n  print(sess.run(bias))\r\n  print(sess.run(weights))\r\n  sess.run(train_op, { a: [[0.1, 0.2, 0.3, 0.4, 0.5]], b: [[1., 2., 3.]], flag: True })\r\n  print('AFTER SECOND RUN: we follow the path with the update op added')\r\n  print(sess.run(global_step))\r\n  print(sess.run(bias))\r\n  print(sess.run(weights))\r\n```\r\n\r\nWhich gives you this result:\r\n\r\n```\r\nBEFORE ANYTHING IS RUN\r\n0\r\n[0. 0. 0.]\r\n[[ 0.3860709   0.45507103 -0.1816141 ]\r\n [-0.00840878  0.7818753  -0.605694  ]\r\n [-0.04105538 -0.03619885 -0.10100174]\r\n [ 0.8570104   0.44614607  0.7425906 ]\r\n [ 0.7079007   0.8293366  -0.6455219 ]]\r\nAFTER FIRST RUN:  we do not follow the path with the update op added\r\n0\r\n[0. 0. 0.]\r\n[[ 0.3860709   0.45507103 -0.1816141 ]\r\n [-0.00840878  0.7818753  -0.605694  ]\r\n [-0.04105538 -0.03619885 -0.10100174]\r\n [ 0.8570104   0.44614607  0.7425906 ]\r\n [ 0.7079007   0.8293366  -0.6455219 ]]\r\nAFTER SECOND RUN: we follow the path with the update op added\r\n1\r\n[0.00185758 0.00810567 0.02130217]\r\n[[ 0.38625666  0.4558816  -0.17948389]\r\n [-0.00803727  0.78349644 -0.6014336 ]\r\n [-0.04049811 -0.03376715 -0.09461109]\r\n [ 0.85775346  0.44938833  0.75111145]\r\n [ 0.70882946  0.8333894  -0.63487077]]\r\n```\r\n\r\ni.e. When the `sess.run` does not execute the `tf.no_op`, the `opt.minimize` operation silently fails to run.\r\n\r\nI do not have authority to re-open this issue."]}, {"number": 14698, "title": "MemoryError from tensorflow.contrib.learning.datasets in Python3", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.5.3\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: python -c \"import tensorflow as tf; tf.contrib.learn.datasets.load_dataset('dbpedia', size='full')\"\r\n\r\n\r\n\r\n### Describe the problem\r\nThe command results in an MemoryError, even though the dataset easily fits into my memory (64GB), and also works with Python 2. \r\n\r\n### Source code / logs\r\nHere is the traceback:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/james/python3.5-ve/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py\", line 71, in load_dataset\r\n    return DATASETS[name](size, test_with_fake_data)\r\n  File \"/home/james/python3.5-ve/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py\", line 65, in load_dbpedia\r\n    train_path, target_dtype=np.int32, features_dtype=np.str, target_column=0)\r\n  File \"/home/james/python3.5-ve/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 72, in load_csv_without_header\r\n    data = np.array(data)\r\nMemoryError\r\n\r\n", "comments": ["Any update on this?", "I think we'd need a bit more info about the code you're using.", "I just tried with 1.4.0, I cannot reproduce this. I'll close, please reopen if you have more information.", "Please use the below files to recreate the issue. Use following command(copy rnn_tc.txt as rnn_tc.py first). python3 tensorflow version is 1.3.0:\r\n\r\n$python3 rnn_tc.py\r\n\r\nWe got following messages:\r\n\r\n$ python3 rnn_tc.py > tc.log4\r\nTraceback (most recent call last):\r\n  File \"rnn_tc.py\", line 62, in <module>\r\n    'dbpedia', size='big')\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py\", line 71, in load_dataset\r\n    return DATASETS[name](size, test_with_fake_data)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py\", line 65, in load_dbpedia\r\n    train_path, target_dtype=np.int32, features_dtype=np.str, target_column=0)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 72, in load_csv_without_header\r\n    data = np.array(data)\r\n**MemoryError**\r\n\r\n\r\n[rnn_tc.txt](https://github.com/tensorflow/tensorflow/files/1535219/rnn_tc.txt)\r\n\r\n\r\n\r\n\r\n", "Since you're running an old version of TensorFlow, this may be fixed in 1.4. Can you check whether this is fixed in 1.4? It works fine for me, but I am using Py2. That's the only difference I can think of. How much memory is in the machine you're using?", "Oh wait, you said that. Sorry. I take that back. Let me test again with Py3.", "I just tried with TF 1.4 and Py 3.6.3, and I don't see this failure.", "Did you get the error (using rnn_tc.txt)  with TF 1.3 and Py3 and did not get that error with TF 1.4 and Py 3.6.3 ?? Is this what you are saying?", "I did not get the error (using your repro `python -c \"import tensorflow as tf; tf.contrib.learn.datasets.load_dataset('dbpedia', size='full')\"`) in TensorFlow 1.4, Python 3.6.3. \r\n\r\nI did not test on 1.3 -- we wouldn't backport a fix like this anyway.", "I just did a fresh install of python 3.6.3 and tensorflow, and the issue is still present. For example:\r\n\r\n(python-3.6.3-ve) ___$ python -V\r\nPython 3.6.3\r\n(python-3.6.3-ve) ___$ python -c 'import tensorflow as tf; print(tf.__version__)'\r\n/home/james/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\r\n  return f(*args, **kwds)\r\n1.4.1\r\n\r\nNow, running python3 rnn_tc.py gives the error as above.\r\n\r\nPlease re-open this issue.\r\n\r\n\r\n", "Does `python -c \"import tensorflow as tf; tf.contrib.learn.datasets.load_dataset('dbpedia', size='full')\"` trigger the problem for you?", "Yes, as before:\r\n\r\n`(python-3.6.3-ve) ___$ python -c \"import tensorflow as tf; tf.contrib.learn.datasets.load_dataset('dbpedia', size='full')\"`\r\n\r\n/home/james/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\r\n  return f(*args, **kwds)\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/james/.pyenv/versions/3.6.3/envs/python-3.6.3-ve/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py\", line 71, in load_dataset\r\n    return DATASETS[name](size, test_with_fake_data)\r\n  File \"/home/james/.pyenv/versions/3.6.3/envs/python-3.6.3-ve/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py\", line 65, in load_dbpedia\r\n    train_path, target_dtype=np.int32, features_dtype=np.str, target_column=0)\r\n  File \"/home/james/.pyenv/versions/3.6.3/envs/python-3.6.3-ve/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 72, in load_csv_without_header\r\n    data = np.array(data)\r\nMemoryError\r\n", "What sort of machine are you running this on? Can you check \r\n\r\n`time --verbose python -c \"import tensorflow as tf; tf.contrib.learn.datasets.load_dataset('dbpedia', size='full')\"`?\r\n\r\nI'd like to understand why I cannot reproduce this. ", "It is a System 76 laptop: \r\n\r\n`(python-3.6.3-ve) ___$ uname -a` \r\ngives\r\n`Linux james-Bonobo-WS 4.10.0-42-generic #46-Ubuntu SMP Mon Dec 4 14:38:01 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`\r\n\r\nAnd: \r\n\r\n    (python-3.6.3-ve) ___$ /usr/bin/time --verbose python -c \"import tensorflow as tf; tf.contrib.learn.datasets.load_dataset('dbpedia', size='full')\" \r\n    /home/james/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\r\n      return f(*args, **kwds)\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/home/james/.pyenv/versions/3.6.3/envs/python-3.6.3-ve/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py\", line 71, in load_dataset\r\n        return DATASETS[name](size, test_with_fake_data)\r\n      File \"/home/james/.pyenv/versions/3.6.3/envs/python-3.6.3-ve/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py\", line 65, in load_dbpedia\r\n    train_path, target_dtype=np.int32, features_dtype=np.str, target_column=0)\r\n      File \"/home/james/.pyenv/versions/3.6.3/envs/python-3.6.3-ve/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 72, in load_csv_without_header\r\n    data = np.array(data)\r\n    MemoryError\r\n    Command exited with non-zero status 1\r\n\tCommand being timed: \"python -c import tensorflow as tf; tf.contrib.learn.datasets.load_dataset('dbpedia', size='full')\"\r\n\tUser time (seconds): 9.28\r\n\tSystem time (seconds): 0.80\r\n\tPercent of CPU this job got: 103%\r\n\tElapsed (wall clock) time (h:mm:ss or m:ss): 0:09.71\r\n\tAverage shared text size (kbytes): 0\r\n\tAverage unshared data size (kbytes): 0\r\n\tAverage stack size (kbytes): 0\r\n\tAverage total size (kbytes): 0\r\n\tMaximum resident set size (kbytes): 1554848\r\n\tAverage resident set size (kbytes): 0\r\n\tMajor (requiring I/O) page faults: 0\r\n\tMinor (reclaiming a frame) page faults: 398832\r\n\tVoluntary context switches: 83\r\n\tInvoluntary context switches: 106919\r\n\tSwaps: 0\r\n\tFile system inputs: 0\r\n\tFile system outputs: 0\r\n\tSocket messages sent: 0\r\n\tSocket messages received: 0\r\n\tSignals delivered: 0\r\n\tPage size (bytes): 4096\r\n\tExit status: 1\r\n\r\n", "I'm on a Mac, and I get \"7516360704  maximum resident set size\" (~7.5G), which is way more than your 1.5G. I agree that is a lot. There are probably a few unnecessary copies in there. \r\n\r\nWe'll gladly take fixes that reduce the memory consumption. \r\n \r\n", "OK, but the 1.5G maximum resident set size still does not explain the `MemoryError` since this happens when there is > 10G of unused memory. Also the error only occurs with python3 and not python2.\r\n\r\nYes, the dataset should be way smaller than a G, but I haven't had a chance to look into fixing it.", "If somebody sill have the issue\r\nhttps://stackoverflow.com/a/49824034/604530"]}, {"number": 14697, "title": "tf.train.Scaffold does't accept global_step, and therefore only one checkpoint (0) is saved", "body": "Disclaimer: Issue #10661 might be related. \r\n\r\nWhen I create a Scaffold object and attempt to use it in a MonitoredTrainingSession, there is no ability to specify the global step.  As a consequence (I think), only one checkpoint is created, labeled \"model.ckpt-0\". \r\n\r\nAs I understand it, the code below (taken from a custom class I've written...hence the `self`s) should save a new checkpoint every 10 seconds, but only actually creates a single checkpoint at the start of training, and then never again.\r\n\r\n    self.GLOBAL_STEP = tf.train.get_or_create_global_step()\r\n    self.init_op = tf.global_variables_initializer()       \r\n    self.Saver = tf.train.Saver()\r\n\r\n    self.Scaffold = tf.train.Scaffold( init_op=self.init_op,\r\n                                       saver=self.Saver\r\n                                   #   global_step=self.GLOBAL_STEP  \r\n                                           )\r\n\r\n    self.sess = tf.train.MonitoredTrainingSession( master='',\r\n                                                   is_chief=True,\r\n                                                   scaffold = self.Scaffold,\r\n                                                   checkpoint_dir='./chkpt/',\r\n                                                   save_checkpoint_secs=10,\r\n                                                       )\r\n\r\nIf I uncomment the `global_step=...` line above, I get an error (as expected) since `Scaffold.__init__()` doesn't take a global_step argument, however shouldn't it?", "comments": ["Yup, I think this is the same issue as #10661.  Closing this out, and pinging the other one."]}, {"number": 14696, "title": "[CMake] Don't build tests for RE2", "body": "Issue #14691 shows a build error on Windows in the RE2 tests. Since we do not run these tests, and they seem to be causing problems on some platforms, do not build them as part of the TensorFlow build.", "comments": []}, {"number": 14695, "title": "Update CONTRIBUTING.md", "body": "Add Objective-C Style guide to list.", "comments": ["Can one of the admins verify this patch?", "Yes, we've got Objective C demos for iOS.\n\nOn Thu, Nov 23, 2017 at 5:31 PM, Martin Wicke <notifications@github.com>\nwrote:\n\n> *@martinwicke* commented on this pull request.\n>\n> Does have any objective-C code in the TensorFlow repo?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/14695#pullrequestreview-78816178>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AATiyU9hUUo7rkK6SW86FgG_achxaDxPks5s5hxzgaJpZM4QjLr7>\n> .\n>\n"]}, {"number": 14694, "title": "added my name as a contributors", "body": "", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "This list is auto generated from the list of commits we receive during each release.\r\nPlease do not hand edit it.\r\n\r\nWe will make sure to add your name if we receive commits from your github account.\r\n"]}, {"number": 14693, "title": "Why did you call BasicLSTMCell a cell and not a layer?", "body": "`BasicLSTMCell` is actually a layer (as for a layer in MLPs) of LSTM units. Each of these LSTM units contains a cell. Each cell of an LSTM unit contains a **scalar value** for the CEC and a **scalar** representing the previous state.\r\n\r\nPeople are usually first introduced to MLPs or feed-forward (and fully connected) neural networks, before being introduced to RNNs and, in particular, LSTMs. \r\n\r\nWhy would you call `BasicLSTMCell` a **cell**, if it can be thought more intuitively (at least for me) as a layer of LSTM units (as I describe them above) containing just one scalar-based cell? Wouldn't it be less ambiguous to call a `BasicLSTMCell` `BasicLSTMLayer`???\r\n\r\nMoreover, the first parameter to `BasicLSTMCell`'s `__init__` method is `num_units`, i.e. the number of LSTM units, i.e. the number of LSTM cells and gates (if we have 3 gates for every LSTM unit, then the total number of gates in one layer of LSTMs is 3 * `num_units`). \r\n\r\nIt almost seems that you created TF to make it as confusing as possible to make it seem hard. It also almost seems that the person who wrote the name of the class `BasicLSTMCell` is a different person of the person who wrote its `__init__` method. What's going on??? A little bit of consistency, for once, no???\r\n\r\nA similar argument can be said for `MultiRNNCell`, which, a lot more intuitively, can be thought as a sequence of layers.\r\n\r\n### Request\r\n\r\nChange classes such as `BasicLSTMCell` and `MultiRNNCell` to have more descriptive names of what they actually are in future versions of TF. Then change the corresponding documentation to be more compliant with these changes.", "comments": ["We work hard on building clean and consistent interfaces, but the truth is that the field moves quickly, and the description and terms used when an idea first breaks out aren't always the same as the best way to teach things turns out a few years later. And we also have a responsibility to our users to maintain some backwards compatibility with the older (and probably uglier) interfaces. I think in practice we can add new, cleaner interfaces, but it's a slower process to deprecate and remove the older, uglier ones. \r\n\r\nI think @ebrevdo wrote the code in question (both the class and its __init__ method). He might be able to comment on future, cleaner interfaces.", "Nomenclature varies between different researchers.  It's unfortunate that the naming doesn't match standard notation taught by NN courses, but this interface is locked for backwards compatibility until at least tf 2.0 due to our API guarantees.  You may have an easier time with the naming in the Keras API.  Will add this request to the internal list of possible breaking changes for future versions.  Closing.", "@ebrevdo Yes, nomenclature varies, but I am more concerned about **consistency** within the same class, module and possibly library. \r\n\r\nThe \"cell\" `BasicLSTMCell` contains a method called `__init__` whose first parameter is `num_units`, which is vaguely [documented](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell) as\r\n\r\n> The number of units in the LSTM cell.\r\n\r\nNumber of units??? Which units??? A cell has units???\r\n\r\nAt least, meanwhile, you should change the documentation to make it more understandable!!", "Would you like to submit a PR to help improve the documentation?  I'm happy\nto review.\n\nOn Sun, Nov 19, 2017 at 6:03 AM, Nelson Brochado <notifications@github.com>\nwrote:\n\n> @ebrevdo <https://github.com/ebrevdo> Yes, nomenclature varies, but I am\n> more concerned about consistency within the same class, module and possibly\n> library.\n>\n> The \"cell\" BasicLSTMCell contains a method called __init__ whose first\n> parameter is num_units, which is vaguely documented\n> <https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell>\n> as\n>\n> The number of units in the LSTM cell.\n>\n> Number of units??? Which units??? A cell has units???\n>\n> At least, meanwhile, you should change the documentation to make it more\n> understandable!!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14693#issuecomment-345519132>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimxO70QZgMLDIemq8Iluxxjsz1heVks5s4DUogaJpZM4QjErd>\n> .\n>\n"]}, {"number": 14692, "title": "Does 'distributed tensorflow' support Keras training?", "body": "[distributed tensorflow in the official site](https://www.tensorflow.org/deploy/distributed)\r\n\r\nInstread of tensorflow model,  is Keras model and training possible?\r\n\r\n If I put the Keras model and training, is it working??\r\n![image](https://user-images.githubusercontent.com/9244296/32982719-3394322e-cccc-11e7-9b58-ea5f326e63ff.png)\r\nI want to know if distributed tensorflow support keras model too.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "`tf.keras.Model.fit` does not support distributed yet, if that is what you're asking.\r\nHowever, you can convert a Keras model to an `Estimator` using [`tf.keras.estimator.model_to_estimator`](https://www.tensorflow.org/programmers_guide/estimators#creating_estimators_from_keras_models) and use that for distributed training.\r\n\r\nSee also: https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate and https://cloud.google.com/blog/big-data/2018/02/easy-distributed-training-with-tensorflow-using-tfestimatortrain-and-evaluate-on-cloud-ml-engine\r\n\r\nHope that helps.", "@asimshankar Is there any plan to make tf.keras.Model.fit support distribution training? Or users should keep using tf.keras.estimator.model_to_estimator"]}, {"number": 14691, "title": "compile failed for tf-gpu 1.4, cuda 9, cudnn 7, vc 2017, windows 10.", "body": "I would greatly appreciate if anyone could help me out with compiling.\r\nI followed #5600 and #13962 in compiling the wheel, however when building i got into 6 types of in total 90 errors. Respectively c2070, c2059, c2064, c2001, c1057, c2146.\r\n\r\nMy build command was:\r\n`cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\r\n-DSWIG_EXECUTABLE=C:/swigwin-3.0.12/swig.exe ^\r\n-DPYTHON_EXECUTABLE=python.exe ^\r\n-DPYTHON_LIBRARIES=C:/ProgramData/Anaconda3/libs/python36_lib ^\r\n-DPYTHON_INCLUDE_DIR=C:/ProgramData/Anaconda3/Include ^\r\n-DNUMPY_INCLUDE_DIR=C:/ProgramData/Anaconda3/lib/site-packages/numpy/core/include ^\r\n-Dtensorflow_ENABLE_GPU=ON ^\r\n-DCUDNN_HOME=\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\" ^\r\n-Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX `\r\n\r\nEverything looks good until the compiler_arch_native_support failed.\r\nIt manage to configure the build so I continue with: \r\nMSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj \r\n\r\nThe last 9999 line of the failed log is here. \r\n[tf-compile-build-error-log.txt](https://github.com/tensorflow/tensorflow/files/1484750/tf-compile-build-error-log.txt)\r\n\r\nWarmest Regards,\r\nColman", "comments": ["@colmantse It looks like something is failing in the RE2 build, apparently in test code. Since we don't need that code, I've created PR #14696 to disable it. Could you please try patching it in (or making the one-line change to `tensorflow/contrib/cmake/external/re2.cmake`) and let us know if that fixes things?", "Hi, thanks for the advice. I have implemented the change and the error reduced from 90 to 1 as follow:\r\n\r\n```\r\n\"D:\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\r\n\"D:\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.vcxproj\" (default target) (3) ->\r\n\"D:\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\" (default target) (133) ->\r\n(CustomBuild target) ->\r\n  C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets(17\r\n1,5): error MSB6006: \"cmd.exe\" exited with code 1. [D:\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_k\r\nernels.vcxproj]\r\n\r\n    2615 Warning(s)\r\n    1 Error(s)\r\n\r\nTime Elapsed 01:25:40.39\r\n```\r\n\r\nI googled and it seems this is a path problem, i rebuild the config using this but the problem persist. \r\n`cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\r\n-DSWIG_EXECUTABLE=\"C:/swigwin-3.0.12/swig.exe\" ^\r\n-DPYTHON_EXECUTABLE=\"C:/ProgramData/Anaconda3/python.exe\" ^\r\n-DPYTHON_LIBRARIES=\"C:/ProgramData/Anaconda3/libs/python36.lib\" ^\r\n-DPYTHON_INCLUDE_DIR=\"C:/ProgramData/Anaconda3/Include\" ^\r\n-DNUMPY_INCLUDE_DIR=\"C:/ProgramData/Anaconda3/lib/site-packages/numpy/core/include\" ^\r\n-Dtensorflow_ENABLE_GPU=ON ^\r\n-DCUDNN_HOME=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0\" ^\r\n-Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX`\r\n\r\nhere is the last 9999 of the new error log.\r\n[tf-compile-build-error-log.txt](https://github.com/tensorflow/tensorflow/files/1485313/tf-compile-build-error-log.txt)\r\n", "I figure this might be vc 2017 cuda 9 problem, i switched back to vc 2015 and cuda 8 and finally successfully compile it and get it installed. It will still be great if the issue with vc 2017/cuda9 could be resolved tho. Thank you very much for your help.", "There are a lot of warnings about code page issues. For example:\r\n\r\n>  C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\include\\cuda_runtime.h : warning C4819: The file contains a character that cannot be represented in the current code page (950). Save the file in Unicode format to prevent data loss (compiling source file D:\\projects\\tensorflow\\tensorflow\\core\\kernels\\slice_op.cc) [D:\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_kernels.vcxproj]\r\n\r\nI'm not sure how the system code page interacts with the Visual C++ compiler&mdash;and there's no indication in the error message about exactly what character is causing problems&mdash;but it seems like it might be necessary to change your system settings to get this to build cleanly.", "thanks for the direction, may you clarify a little bit more on changing system settings? I am not very sure where should I be looking at. Also, is compiler_arch_native_support failed an issue? I noticed after the upgrade from tf 1.3 to 1.4, my gpu utility (2 1080 ti) drop from 90% to 30 %, efficiency decreased as well by more than 3 quarters. This is why I try to build from source ( I previously use pip install tensorflow_gpu --upgrade). I notice my pc support AVX2 but I am not sure how to compile arch:AVX/AVX2 together, but nevertheless, the new build does not yield any performance gain. CPU remains excessively high in usage (abnormally) and gpu outrageously low utility. I am pretty desperate now, would be great to have your advice.", "Additionally I am not able to compile with AVX2, despite when running tf 1.4 installed from pip, it says my pc supports so and would benefit from compiling with it. Below is the log, building was successful, but compiling yield below. Would be great if someone could help.\r\n[compile AXV2 error.txt](https://github.com/tensorflow/tensorflow/files/1499033/compile.AXV2.error.txt)\r\n\r\nP.S. i tried switching to chcp 65001 but the warning persists.. It seems that changing code page at cmd does not has an effect, cmd still compiles with cp 950", "FYI I've been able to compile everything (without testing python bindings, and using AVX, not AVX2), see #14801. However I've discovered that despite everything ran fine, the VS2017 (until 15.4) distribution introduced a bug in the /WHOLEARCHIVE trick resulting in unfilled factories (session, device...) [as mentioned in](https://developercommunity.visualstudio.com/content/problem/132766/wholearchive-linker-flag-is-dysfunctional-since-15.html). Therefore I am stuck using vs2017 for linking my application with TF. @aluo-x", "thank you for the pointer!", "If you are seeing a failure similar to this one:\r\nhttp://ci.tensorflow.org/job/tf-master-win-gpu-cmake/\r\n\r\nThis looks like an nvcc bug, and it is reported to NVIDIA. We are waiting for their investigation", "thank you! however, I could not see the fail build log from your page. There seems a lot of experiment has been going on tho. Good to know!", "@gunan Any updates on this? Can we link to an nvidia page / thread / developer to help triage this issue?", "https://bitbucket.org/eigen/eigen/pull-requests/351/win-nvcc/diff\r\nOnce the above change is merged, I will bump TF eigen dependency, and we should be all fixed.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Forgot to update, but TF master now builds with cuda9.0 and cudnn 7 without any problems.\r\nWe will not backport the fix to 1.4, as there were quite a bunch of fixes since 1.4 to fix the build for cuda9.", "@gunan with cuda 9.0 & cudnn 7, I'm still seeing the error as of commit https://github.com/tensorflow/tensorflow/commit/25d275280dfb163674f81c7681c2c1d34545a155 . \r\n\r\nI used\r\n```\r\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\r\n-DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12/swig.exe ^\r\n-DPYTHON_EXECUTABLE=C:\\Users\\csemp\\AppData\\Local\\Programs\\Python\\Python35\\python.exe ^\r\n-DPYTHON_LIBRARIES=C:\\Users\\csemp\\AppData\\Local\\Programs\\Python\\Python35\\libs\\python35.lib ^\r\n-Dtensorflow_ENABLE_GPU=ON ^\r\n-DCUDNN_HOME=\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\" ^\r\n-Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX ^\r\n-Dtensorflow_BUILD_CC_EXAMPLE=OFF\r\n```\r\n\r\nAdditionally, I found the original error earlier in the logs. It's\r\n```\r\n 133>CustomBuild: (TargetId:8893)\r\n                     CMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:222 (message): (TaskId:3323)\r\n                       Error generating (TaskId:3323)\r\n                       C:/Users/csemp/dev/tensorflowbuild/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj (TaskId:3323)\r\n                      (TaskId:3323)\r\n                      (TaskId:3323)\r\n```\r\n\r\nI'm using MSBuild 15.5.180.51428, the one with Visual Studio 2017\r\n\r\n", "1.4 does not have the fixed version of eigen. You have to use master, or 1.5\r\n\r\nCorrection, I misread your message. It is possible there is another breakage now in master. Will take a look.", "@gunan https://github.com/tensorflow/tensorflow/commit/25d275280dfb163674f81c7681c2c1d34545a155 was from master as of yesterday", "http://ci.tensorflow.org/job/tf-master-win-gpu-cmake/\r\nLooks like our continuous build is healthy. But our build uses VS 2015,  and we do not set SIMD options.\r\nSo these may be the cause of the failure you are seeing.\r\n\r\nThe error message above is helpful, but still does not capture what compiler emits for that build target. Is it possible for you to file a new issue, and maybe share the full build output through pastebin?", "I have tried VS 2017 multiple time but failed to build so i did it with visual studio 2015. Hope we can build it using Visual Studio 2017 later soon. I have created a tutorial for building tensorflow on windows 10 using cmake and visual studio 2015 update 3 on my blog here http://www.python36.com/install-tensorflow-gpu-windows . Thanks @gunan for helping with great deep learning library. ", "@arunmandal53 \r\nJust change CUDA host compiler to v140 by the following CMake option (you can also find it in cmak-gui by checking \"Advanced\"):\r\n```\r\n-DCUDA_HOST_COMPILER=\"C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe\r\n```\r\nNonCUDA code can still be compiled by v141 in VS 2017.\r\nIt seems that v141 and nvcc is incompatible.\r\n\r\nReference: https://medium.com/@shiweili/building-tensorflow-c-shared-library-on-windows-e79c90e23e6e\r\n", "@chaosink thank you. I will test it."]}, {"number": 14690, "title": "Added a check for a macro to specify that an ARM device is not mobile", "body": "I've copied the existing mechanism for Raspberry Pi to allow other ARM platforms to be designated as not a mobile platform and thus get the full feature set.", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@petewarden mind taking a look? Thanks!"]}, {"number": 14689, "title": "Couldn't find field google.protobuf.EnumDescriptorProto.EnumReservedRange.start", "body": "Im trying to run the following code \r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(\"Hello TensorFlow version\", tf.__Version__)\r\n```\r\n\r\n\r\nIt is firing the following error \r\n\r\n> Users/anaconda/envs/cnn/bin/python /Users/Downloads/rude-carnie/version.py\r\n> Traceback (most recent call last):\r\n>   File \"/Users/Downloads/rude-carnie/version.py\", line 1, in <module>\r\n>     import tensorflow as tf\r\n>   File \"/Users/anaconda/envs/cnn/lib/python3.6/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n>     from tensorflow.python import *\r\n>   File \"/Users/anaconda/envs/cnn/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\r\n>     from tensorflow.core.framework.graph_pb2 import *\r\n>   File \"/Users/anaconda/envs/cnn/lib/python3.6/site-packages/tensorflow/core/framework/graph_pb2.py\", line 10, in <module>\r\n>     from google.protobuf import descriptor_pb2\r\n>   File \"/Users/anaconda/envs/cnn/lib/python3.6/site-packages/google/protobuf/descriptor_pb2.py\", line 735, in <module>\r\n>     options=None, file=DESCRIPTOR),\r\n>   File \"/Users/anaconda/envs/cnn/lib/python3.6/site-packages/google/protobuf/descriptor.py\", line 501, in __new__\r\n>     return _message.default_pool.FindFieldByName(full_name)\r\n> KeyError: \"Couldn't find field google.protobuf.EnumDescriptorProto.EnumReservedRange.start\"", "comments": ["I'm having the same problem.", "Maybe you've tried tf-nightly or something? Anyway, try reinstalling the protobuf version that TensorFlow 1.4 wants by running:\r\n\r\n```sh\r\npip uninstall protobuf\r\npip install tensorflow\r\npython -c \"import tensorflow\"\r\n```", "No, your answer is incorrect. Tensorflow 1.4 uninstalls protobuf and reinstalls it so I think we need to dig deeper into this.", "Do you have multiple installs of protobuf in the same Python environment?", "On my mac it all works like a charm including eager execution with nightly build update. It's just on my Ubuntu GPU box , its dying :/\r\n\r\nI'll see if downgrading to 3.4.0 gives some positive results.", "OK, here is the solution -- funny but worked for me \ud83d\udc6f\u200d\u2642\ufe0f \r\n\r\nI uninstalled protobuf 3.5.0.post1, which comes with TF 1.4.1 distro, installed 3.4.0 release and then installed 3.5.0.post1.\r\n\r\n```shell\r\ndeeplearn@Ubuntu-1604-xenial-64-minimal:~$ pip install protobuf==3.4.0\r\nRequirement already satisfied: protobuf==3.4.0 in ./anaconda3/lib/python3.6/site-packages\r\nRequirement already satisfied: setuptools in ./anaconda3/lib/python3.6/site-packages (from protobuf==3.4.0)\r\nRequirement already satisfied: six>=1.9 in ./anaconda3/lib/python3.6/site-packages (from protobuf==3.4.0)\r\ndeeplearn@Ubuntu-1604-xenial-64-minimal:~$ pip install protobuf==3.5.0.post1\r\nCollecting protobuf==3.5.0.post1\r\n  Using cached protobuf-3.5.0.post1-py2.py3-none-any.whl\r\nRequirement already satisfied: six>=1.9 in ./anaconda3/lib/python3.6/site-packages (from protobuf==3.5.0.post1)\r\nRequirement already satisfied: setuptools in ./anaconda3/lib/python3.6/site-packages (from protobuf==3.5.0.post1)\r\nInstalling collected packages: protobuf\r\n  Found existing installation: protobuf 3.4.0\r\n    Uninstalling protobuf-3.4.0:\r\n      Successfully uninstalled protobuf-3.4.0\r\nSuccessfully installed protobuf-3.5.0.post1\r\ndeeplearn@Ubuntu-1604-xenial-64-minimal:~$ \r\n```\r\nas a result, this baby's working :)\r\n\r\n\r\n![screen shot 2017-11-23 at 23 42 32](https://user-images.githubusercontent.com/7202199/33189951-1876c274-d0a8-11e7-899a-1341f32edd05.png)\r\n", "I run into the same problem, and your solution works for me.", "Glad to hear \ud83d\ude03", "check if your `protobuf` are installed  deplicately like: \r\n\r\n*  sudo apt-get install python3-protobuf  `or` python-protobuf \r\n*  pip install protobuf  `or`  pip3 install protobuf \r\n\r\nIf both installed, uninstall one of them \r\n", "I tried all... i tried reinstalling protobuf, tensorflow but still the same issue :(", "Thanks @TarrySingh Your solution worked for me", "Thank you @TarrySingh. Your solution works like charm ^_^", "In my case `protobuf` from `conda-forge` was the reason for the error. I removed it via `conda remove protobuf` and reinstalled protobuf via pip.", "Awesome to hear that \ud83d\udc4c\r\n\r\n@zumbalambo \u2014 you need to share your error. ", "@TarrySingh your solution worked for me as well!", "Thanks @TarrySingh, pip install protobuf==3.4.0 solved the problem!", "@TarrySingh didn't immediately help but upgrading all pip packages did:\r\n\r\n`pip3 freeze --local | grep -v '^\\-e' | cut -d = -f 1  | xargs -n1 pip3 install -U`\r\n\r\nHope it helps.", "came with the same issue, I solved it with these commands:\r\n```\r\nconda remove protobuf\r\npip install tensorflow=1.4.0\r\npip install protobuf==3.4.0\r\npip install protobuf==3.5.0.post1\r\npython -c \"import tensorflow\"\r\n```\r\nthanks @gokceneraslan and @TarrySingh", "In my case tf 1.4.1 works only with protobuf 3.4.0:\r\n\r\n```\r\npython -c \"import tensorflow as tf; print(tf.__version__); import google.protobuf as pb; print(pb.__version__)\"\r\n1.4.1\r\n3.4.0\r\n```\r\n\r\nUpgrading protobuf to 3.5.x results in `KeyError: \"Couldn't find field google.protobuf.EnumDescriptorProto.EnumReservedRange.start\"`", "I find this solution really helpful:\r\n1. uninstall all the protobuf on your machine (both from anaconda and pip)\r\n`pip uninstall protobuf`\r\n`conda remove protobuf`\r\nyou may try them twice to make sure all the version of protobuf have been removed\r\n2. install protobuf using pip:\r\n`pip install protobuf==3.5.0.post1`", "1\u3001remove all the protobuf, by pip list, conda list and so on\r\n2\u3001install a new one", "@TarrySingh thanks \u5927\u50bb\u732b\uff0c\u4f60\u771f\u68d2\ud83d\udc4d"]}, {"number": 14688, "title": "how to build tensorflow lite into a static c++ library using android ndk", "body": "I want to write some c++ test binary using tensorflow lite.\r\nfrom the README.md I can only see how to build the demo app.\r\nCould you please tell me how to build tensorflow lite into a static library using android ndk?", "comments": ["I recently managed to do this myself for armeabi-v7a. Here is what I had to do:\r\n\r\n- Download Android NDK\r\n- Set the environment variable, e.g:  export NDK_ROOT=~/AndroidNDK/android-ndk-r14b/\r\n- I had to compile the static library libcpufeatures.a in android-ndk-r14b/sources/android/cpufeatures\r\n- From the tensorflow directory run `make` -f tensorflow/contrib/lite/Makefile TARGET=ANDROID ANDROID_ARCH=armeabi-v7a`\r\n\r\nI made some other changes and added a file: \r\nhttps://gist.github.com/shaurya0/eac838b390df3461b972e966b015a3a2\r\n", "@andrehentz could you please take a look.", "@shaurya0  \r\nI tried with your method, I can successfully build the libtensorflow-lite.a.\r\nBut when I link libtensorflow-lite.a with my test binary, a lot of errors\r\n\r\n\r\n[armeabi-v7a] Executable     : test_tflite\r\njni/libtensorflow-lite.a(register.o):register.cc:function tflite::ops::builtin::BuiltinOpResolver::FindOp(char const*) const: error: undefined reference to 'std::_Hash_bytes(void const*, unsigned int, unsigned int)'\r\njni/libtensorflow-lite.a(register.o):register.cc:function tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver(): error: undefined reference to 'std::__detail::_Prime_rehash_policy::_M_next_bkt(unsigned int) const'\r\njni/libtensorflow-lite.a(register.o):register.cc:function tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver(): error: undefined reference to 'std::__detail::_Prime_rehash_policy::_M_next_bkt(unsigned int) const'\r\njni/libtensorflow-lite.a(register.o):register.cc:function tflite::ops::builtin::BuiltinOpResolver::AddCustom(char const*, TfLiteRegistration*): error: undefined reference to 'std::_Hash_bytes(void const*, unsigned int, unsigned int)'\r\njni/libtensorflow-lite.a(register.o):register.cc:function std::_Hashtable<tflite::BuiltinOperator, std::pair<tflite::BuiltinOperator const, TfLiteRegistration*>, std::allocator<std::pair<tflite::BuiltinOperator const, TfLiteRegistration*> >, std::__detail::_Select1st, std::equal_to<tflite::BuiltinOperator>, tflite::ops::builtin::BuiltinOpResolver::BuiltinOperatorHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned int, unsigned int, std::__detail::_Hash_node<std::pair<tflite::BuiltinOperator const, TfLiteRegistration*>, true>*): error: undefined reference to 'std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned int, unsigned int, unsigned int) const'\r\njni/libtensorflow-lite.a(register.o):register.cc:function std::_Hashtable<std::string, std::pair<std::string const, TfLiteRegistration*>, std::allocator<std::pair<std::string const, TfLiteRegistration*> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned int, unsigned int, std::__detail::_Hash_node<std::pair<std::string const, TfLiteRegistration*>, true>*): error: undefined reference to 'std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned int, unsigned int, unsigned int) const'\r\njni/libtensorflow-lite.a(svdf.o):svdf.cc:function _GLOBAL__sub_I_svdf.cc: error: undefined reference to 'std::ios_base::Init::Init()'\r\njni/libtensorflow-lite.a(svdf.o):svdf.cc:function _GLOBAL__sub_I_svdf.cc: error: undefined reference to 'std::ios_base::Init::~Init()'\r\njni/libtensorflow-lite.a(nnapi_delegate.o):nnapi_delegate.cc:function tflite::addTensorOperands(tflite::Interpreter*, ANeuralNetworksModel*): error: undefined reference to '__dynamic_cast'\r\njni/libtensorflow-lite.a(simple_memory_arena.o):simple_memory_arena.cc:function tflite::SimpleMemoryArena::Allocate(TfLiteContext*, unsigned int, unsigned int, tflite::ArenaAlloc*): error: undefined reference to 'std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)'\r\njni/libtensorflow-lite.a(simple_memory_arena.o):simple_memory_arena.cc:function tflite::SimpleMemoryArena::Deallocate(TfLiteContext*, tflite::ArenaAlloc const&): error: undefined reference to 'std::__detail::_List_node_base::_M_unhook()'\r\njni/libtensorflow-lite.a(embedding_lookup.o):embedding_lookup.cc:function _GLOBAL__sub_I_embedding_lookup.cc: error: undefined reference to 'std::ios_base::Init::Init()'\r\njni/libtensorflow-lite.a(embedding_lookup.o):embedding_lookup.cc:function _GLOBAL__sub_I_embedding_lookup.cc: error: undefined reference to 'std::ios_base::Init::~Init()'\r\njni/libtensorflow-lite.a(hashtable_lookup.o):hashtable_lookup.cc:function _GLOBAL__sub_I_hashtable_lookup.cc: error: undefined reference to 'std::ios_base::Init::Init()'\r\njni/libtensorflow-lite.a(hashtable_lookup.o):hashtable_lookup.cc:function _GLOBAL__sub_I_hashtable_lookup.cc: error: undefined reference to 'std::ios_base::Init::~Init()'\r\njni/libtensorflow-lite.a(lstm.o):lstm.cc:function _GLOBAL__sub_I_lstm.cc: error: undefined reference to 'std::ios_base::Init::Init()'\r\njni/libtensorflow-lite.a(lstm.o):lstm.cc:function _GLOBAL__sub_I_lstm.cc: error: undefined reference to 'std::ios_base::Init::~Init()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::Barrier::Notify() [clone .part.60]: error: undefined reference to 'std::condition_variable::notify_all()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::Barrier::Notify() [clone .part.60]: error: undefined reference to 'std::condition_variable::notify_all()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function tflite::multithreaded_ops::GetThreadPoolDevice(): error: undefined reference to 'std::condition_variable::condition_variable()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function tflite::multithreaded_ops::GetThreadPoolDevice(): error: undefined reference to 'std::condition_variable::condition_variable()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function tflite::multithreaded_ops::GetThreadPoolDevice(): error: undefined reference to 'std::condition_variable::~condition_variable()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function tflite::multithreaded_ops::GetThreadPoolDevice(): error: undefined reference to 'std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>)'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function tflite::multithreaded_ops::GetThreadPoolDevice(): error: undefined reference to 'std::condition_variable::~condition_variable()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function std::_Function_handler<void (int, int), EigenForTFLite::ThreadPoolDevice::parallelFor(int, EigenForTFLite::TensorOpCost const&, std::function<int (int)>, std::function<void (int, int)>) const::{lambda(int, int)#1}>::_M_invoke(std::_Any_data const&, int, int): error: undefined reference to 'std::condition_variable::notify_all()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function std::_Function_handler<void (int, int), EigenForTFLite::ThreadPoolDevice::parallelFor(int, EigenForTFLite::TensorOpCost const&, std::function<int (int)>, std::function<void (int, int)>) const::{lambda(int, int)#1}>::_M_invoke(std::_Any_data const&, int, int): error: undefined reference to 'std::condition_variable::notify_all()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::EventCount::Unpark(EigenForTFLite::EventCount::Waiter*) [clone .isra.58]: error: undefined reference to 'std::condition_variable::notify_one()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::NonBlockingThreadPoolTempl<EigenForTFLite::StlThreadEnvironment>::~NonBlockingThreadPoolTempl(): error: undefined reference to 'std::thread::join()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::NonBlockingThreadPoolTempl<EigenForTFLite::StlThreadEnvironment>::~NonBlockingThreadPoolTempl(): error: undefined reference to 'std::condition_variable::~condition_variable()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::Barrier::Wait(): error: undefined reference to 'std::condition_variable::wait(std::unique_lock<std::mutex>&)'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::ThreadPoolDevice::parallelFor(int, EigenForTFLite::TensorOpCost const&, std::function<int (int)>, std::function<void (int, int)>) const: error: undefined reference to 'std::condition_variable::condition_variable()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::ThreadPoolDevice::parallelFor(int, EigenForTFLite::TensorOpCost const&, std::function<int (int)>, std::function<void (int, int)>) const: error: undefined reference to 'std::condition_variable::~condition_variable()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::NonBlockingThreadPoolTempl<EigenForTFLite::StlThreadEnvironment>::WaitForWork(EigenForTFLite::EventCount::Waiter*, EigenForTFLite::StlThreadEnvironment::Task*): error: undefined reference to 'std::condition_variable::wait(std::unique_lock<std::mutex>&)'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function EigenForTFLite::NonBlockingThreadPoolTempl<EigenForTFLite::StlThreadEnvironment>::WorkerLoop(int): error: undefined reference to 'std::_Hash_bytes(void const*, unsigned int, unsigned int)'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:function void EigenForTFLite::TensorEvaluator<EigenForTFLite::TensorContractionOp<std::array<EigenForTFLite::IndexPair<int>, 1u> const, EigenForTFLite::TensorMap<EigenForTFLite::Tensor<float const, 2, 1, int>, 16, EigenForTFLite::MakePointer> const, EigenForTFLite::TensorMap<EigenForTFLite::Tensor<float const, 2, 1, int>, 16, EigenForTFLite::MakePointer> const> const, EigenForTFLite::ThreadPoolDevice>::evalProduct<true, true, false, 0>(float*) const: error: undefined reference to 'std::condition_variable::condition_variable()'\r\njni/libtensorflow-lite.a(conv.o):conv.cc:typeinfo for int (int): error: undefined reference to 'vtable for __cxxabiv1::__function_type_info'\r\n", "I've been able to build a binary that links to libtensorflow-lite.a within the tensorflow lite source tree and outside of it. Judging by the linker errors it looks like the problem is with how you are linking libstdc++. ", "jus want to ask : can libtensorflow-lite.a do predictions only on android phones ? \r\n                          and is this lib much more smaller ?", "Can you please share the steps to build tflite static binary for android C++ ", "I tried to follow the mentioned steps but I am getting an error:\r\n\r\n> fatal error: tensorflow/core/lib/core/error_codes.pb.h: No such file or directory\r\n\r\nI think this is a file generated by Bazel, is it required? These are the steps I followed, I am new to TFLite, so probably I am missing something.\r\n\r\n1. Clone repository \r\n2. Set NDK_ROOT\r\n3. Download dependencies: `tensorflow/contrib/lite/download_dependencies.sh`\r\n4. Make from TensorFlow directory: `make -f tensorflow/contrib/lite/Makefile TARGET=ANDROID ANDROID_ARCH=armeabi-v7a`\r\n", "Bazel should not be required and your are not missing anything :) Unfortunately we introduced a dependency to benchmark_model which isn't easily resolved with Make. The fix is https://github.com/tensorflow/tensorflow/pull/19019\r\n\r\n\r\n", "I want to write a c++ code to run tensorflow models on android and ios. bothe of them support c++ API so I want a single file. tflite ot .pb file. can anybody help?", "@kargarisaac did you figure it out? What steps did you take?", "@kargarisaac Just to clarify: do you want a single .tflite file that can be interpreted both on android and ios? That should be possible. What's not working for you? Could you open a separate issue to track that?", "@andrehentz Do you have any C++ examples of Tensorflow Lite and Android NDK?\r\nI'm looking for more information that can help me develop an Android App using the NDK.\r\nI'm also really looking for how you access the .tflite file path so you can build the flat buffer model in C++.\r\nI know this is an off topic ask- no direct message feature though...", "The [api doc](https://www.tensorflow.org/lite/apis) describes how to write your C++ program to access a .tflite file and run inference. On android you will most likely need to interface with Java, which you can do via our own JNI code. If you prefer, TF Lite provides Java APIs too.", "@jefhai  @andrehentz \r\nSorry for late response. No I couldn't do that. I used the freezed .pb file for android and converted it to use it in coreml for ios. "]}, {"number": 14687, "title": "Update AUTHORS", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->"]}, {"number": 14686, "title": "i'm a newcomer , and met the following problem!!", "body": "i install tensorflow following the guide explanation in \r\n**www.tensorflow.org/install/install_windows**\r\n### System information\r\n- **OS Platform and Distribution:win10\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below): i use the following command: pip3 install --upgrade tensorflow-gpu\r\n- **Python version:3.5.2 \r\n- **CUDA/cuDNN version**:cuda 8.0 /cudnn 8.0\r\n- **GPU model and memory:GTX1070 8g\r\ni download the source successfully and when i enter the following short program inside the python interactive shell:   import tensorflow as tf\r\nit goes wrong:\r\nTraceback (most recent call last):\r\n  File \"E:\\SoftWare\\Python\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 87, in preload_check\r\n    ctypes.WinDLL(build_info.cudnn_dll_name)\r\n  File \"E:\\SoftWare\\Python\\lib\\ctypes\\__init__.py\", line 347, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] Could not find the specified module\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"E:\\SoftWare\\Python\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"E:\\SoftWare\\Python\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"E:\\SoftWare\\Python\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"E:\\SoftWare\\Python\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 97, in preload_check\r\n    % (build_info.cudnn_dll_name, build_info.cudnn_version_number))\r\nImportError: Could not find 'cudnn64_6.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Note that installing cuDNN is a separate step from installing CUDA, and this DLL is often found in a different directory from the CUDA DLLs. You may install the necessary DLL by downloading cuDNN 6 from this URL: https://developer.nvidia.com/cudnn\r\n\r\n\r\nin my file sys ,the dll file's name is cudnn64_5.dll\r\nand following is my path:\r\n![image](https://user-images.githubusercontent.com/33776263/32978257-56054f12-cc79-11e7-838e-a10a1b138b07.png)\r\n(i can find my msvcp140.dll)\r\nplease help ,thx", "comments": ["As the document says, you should use cuDNN v6.1.\r\nAnd GitHub issue is used to report bugs or  feature requests. You should go to Stack Overflow for help and support", "@qmick ok! uh i'm sorry that i asked question here. but thanks for your help,i\u2018ve solved the problem!"]}, {"number": 14685, "title": "Fix pip package tests.", "body": "They depend on a testonly package, so they break pip test runs for\r\nnightly and releases.", "comments": ["Done. I merged test_internal library into test_util, removed testonly and the tests should now pass on the installed pip package."]}, {"number": 14684, "title": "Does SavedModelBuilder save checkpoints ?", "body": "Does SavedModelBuilder.save() create checkpoint files ? The documentation says this is a wrapper for Saver but doesn't mention checkpoints. It looks like this function doesn't create checkpoints.   \r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.1\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "This is still an issue", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "It's packaging checkpoints inside. You should use the same interface to load the models.\r\n\r\nI'm closing this. Feel free to ask the question on stackoverflow if you have trouble with the docs."]}, {"number": 14683, "title": "Cannot convert a string input to combination of tensors as defined in the Input function", "body": "While working on the tensor flow java api, I trained a model in python and saved it using the code below -\r\n\r\nThere are two problems I'm facing now while making predictions in Python and Java as below - \r\n\r\n1. Making predictions in Python\r\n2.  Making prediction in Java with input as string \r\n3.  How to convert data to complex input types like CrossColumn tensors, bucketized tensors, embedding tensors etc in Java\r\n\r\n**_1] Making predictions in Python -_** \r\n\r\nGist for training code can be found at - https://gist.github.com/gaganmalhotra/8c40e7650f27cf3f894bad092fbe01ab\r\n\r\nWhile loading the model using the Predictor and making predictions as : \r\n\r\n```\r\n# Preparing the single test dataframe to be used for prediction\r\ninput_single_predict = df_test[2:3] #this is just a single row from the test dataframe I'm using to test for prediction\r\n\r\nK_CATEGORICAL_COLUMNS = [\"gender\", \"native_country\", \"education\", \"occupation\", \"workclass\", \"marital_status\", \"race\"]\r\n\r\ndef predict_ip_fn(df):\r\n  categorical_cols = {k: tf.SparseTensor(\r\n      indices=[[i, 0] for i in range(df[k].size)],\r\n      values=df[k].values,\r\n      dense_shape=[df[k].size, 1])\r\n                      for k in K_CATEGORICAL_COLUMNS}\r\n  return categorical_cols\r\n\r\ndict_predict = predict_ip_fn(input_single_predict)\r\n\r\n# Loading the model from disk\r\nfrom tensorflow.contrib import predictor\r\nexport_dir = \"/Users/Documents/SampleTF_projects/temp/1510957027\"\r\npredict_fn = predictor.from_saved_model(export_dir, signature_def_key=None)\r\n\r\npredictions = predict_fn(dict_predict) . #<<<<<< ****** Error is caused here ******\r\nprint(predictions['probabilities'])\r\n\r\n```\r\n**But it leads to the error as below -** \r\n`\r\nValueError: Got unexpected keys in input_dict: set(['workclass', 'gender', 'marital_status', 'race', 'native_country', 'education', 'occupation'])\r\n`\r\n\r\n**Just to cross verify with the model features, you can find the feature columns used in the model as below -** \r\n\r\n```\r\nLinearClassifier(params = {\r\n\t'gradient_clip_norm': None,\r\n\t'head': < tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x121e5a310 > ,\r\n\t'joint_weights': False,\r\n\t'optimizer': None,\r\n\t'feature_columns': [_SparseColumn(column_name = 'gender', is_integerized = False, bucket_size = None, lookup_config = _SparseIdLookupConfig(vocabulary_file = None, keys = ('Female', 'Male'), num_oov_buckets = 0, vocab_size = 2, default_value = -1), combiner = 'sum', dtype = tf.string), \r\n  _SparseColumn(column_name = 'native_country', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string),\r\n  _SparseColumn(column_name = 'education', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string), \r\n  _SparseColumn(column_name = 'occupation', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string), \r\n  _SparseColumn(column_name = 'workclass', is_integerized = False, bucket_size = 100, lookup_config = None, combiner = 'sum', dtype = tf.string), \r\n  _SparseColumn(column_name = 'marital_status', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string), \r\n  _SparseColumn(column_name = 'race', is_integerized = False, bucket_size = 1000, lookup_config = None, combiner = 'sum', dtype = tf.string)]\r\n})\r\n```\r\n\r\n**_2] Making predictions in Java_** \r\n\r\nBelow is the java code for making the predictions from the loaded model:\r\n```\r\n\r\npublic static void main(String[] args) throws UnsupportedEncodingException {\r\nTensorFlow.loadLibrary(\"/Users/gagandeep.malhotra/Documents/gcTensorFlowPredictIncome/census_keras/lib/python2.7/site-packages/tensorflow/contrib/layers/python/ops/_sparse_feature_cross_op.so\");\r\n\t\t\r\n\t\t  try (SavedModelBundle b = SavedModelBundle.load(\"/Users/Documents/SampleTF_projects/temp/1510957027/\", \"serve\")) {\r\n\r\n\t          \r\n\t          /**\r\n\t\t\t * \r\n\t\t\t * The given SavedModel SignatureDef contains the following input(s):\r\n\t\t\t * inputs['inputs'] tensor_info: dtype: DT_STRING shape: (-1) name:\r\n\t\t\t * input_example_tensor:0 The given SavedModel SignatureDef contains the\r\n\t\t\t * following output(s): outputs['classes'] tensor_info: dtype: DT_STRING shape:\r\n\t\t\t * (-1, -1) name:\r\n\t\t\t * linear/binary_logistic_head/_classification_output_alternatives/classes_tensor:0\r\n\t\t\t * outputs['scores'] tensor_info: dtype: DT_FLOAT shape: (-1, 2) name:\r\n\t\t\t * linear/binary_logistic_head/predictions/probabilities:0 Method name is:\r\n\t\t\t * tensorflow/serving/classify\r\n\t\t\t * \r\n\t\t\t * \r\n\t\t\t */\r\n\t\t\tString[] inputs = new String[] { \"HS-grad\", \"Male\", \"Divorced\", \"United-States\", \"Handlers-cleaners\",\r\n\t\t\t\t\t\"White\", \"Private\" };\r\n\r\n\t\t\tbyte[][][] stringMatrix = new byte[7][1][];\r\n\t\t\tfor (int i = 0; i < 7; ++i) {\r\n\t\t\t\tstringMatrix[i][0] = String.format(inputs[i]).getBytes(\"UTF-8\");\r\n\t\t\t}\r\n\r\n\t\t\tTensor<String> t = Tensors.create(stringMatrix);\r\n\r\n\t\t\tSession sess = b.session();\r\n\r\n\t\t\tfinal String xName = \"input_example_tensor:0\";\r\n\t\t\tfinal String scoresName = \"linear/binary_logistic_head/predictions/probabilities:0\";\r\n\t\t\tList<Tensor<?>> outputs = s.runner().feed(xName, t).fetch(scoresName).run();\r\n\r\n\t\t\tfloat[][] classes = new float[2][2];\r\n\t\t\toutputs.get(0).copyTo(classes);\r\n\r\n\t      }\r\n\t\t  \r\n```\r\n\r\n**_3] How to create a Complex Input data types in JAVA_**\r\n\r\nIn python, we can create different input tensors like CrossedColumn, Bucketized etc , Is there a way that we can convert similarly in Java as we dont have estimators or contrib libraries present in JAVA API.\r\n\r\n\r\nIf anyone you could help or guide in the right direction.. @eggie5 @asimshankar @ry", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14682, "title": "MKL: Adding MKL-DNN Reshape op", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please.", "@tensorflow-jenkins test this please.", "What is the Ubuntu CC test that is preventing this PR from merging? It appears to be a Google Internal check. AFAICT none of these errors are related to the changes in this PR. Please merge.", "Jenkins, test this please."]}, {"number": 14681, "title": "MKL: Adding MKL-DNN AddN op", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please.", "What is the Ubuntu CC test that is preventing this PR from merging? It appears to be a Google Internal check. AFAICT none of these errors are related to the changes in this PR. Please merge.", "All required checks are passing. Please merge.", "Jenkins, test this please."]}, {"number": 14680, "title": "MKL: Adding MKL-DNN Identity op", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please.", "What is the Ubuntu CC test that is preventing this PR from merging? It appears to be a Google Internal check. AFAICT none of these errors are related to the changes in this PR. Please merge.", "Ubuntu CC runs the tests on our new test infra. I will need them to pass before I can make sure our releases wont be negatively affected.\r\nI will try to watch these builds and get the change merged.", "@gunan Anything we can do on our side to make your life easier with all these MKL PRs?", "Not really, we had a few bugs in the CI stack that made tests fail for unrelated reasons.  This week they are under control, so the merge is much better than it was last week."]}, {"number": 14679, "title": "MKL: Adding MKL-DNN pooling ops", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for the PRs @mahmoud-abuzaina!\r\n@andydavis1 I just assigned a bunch of the MKL PRs to you for review as it looks like you have been reviewing them :) Feel free to re-assign if needed. Thank you!", "@tensorflow-jenkins test this please.", "What is the Ubuntu CC test that is preventing this PR from merging? It appears to be a Google Internal check. AFAICT none of these errors are related to the changes in this PR. Please merge.", "Jenkins, test this please."]}, {"number": 14678, "title": "Fix shape inference for bitwise ops with broadcasting", "body": "This fix tries to address the issue raised in #14646 where shape inference for bitwise ops is incorrect with broadcasting.\r\nAs was specified in #14646, in the following\r\n```\r\n>>> import tensorflow as tf\r\n>>> tf.bitwise.bitwise_and(tf.zeros([3,1], dtype=tf.int32), tf.zeros([1,3], dtype=tf.int32))\r\n<tf.Tensor 'BitwiseAnd:0' shape=(3, 1) dtype=int32>\r\n```\r\nthe result shape should be (3, 3), not (3, 1).\r\n\r\nThis fix fixes the issue by changing\r\n`.SetShapeFn(shape_inference::UnchangedShape)`\r\nto\r\n`.SetShapeFn(shape_inference::BroadcastBinaryOpShapeFn)`\r\n\r\nAdditional test cases have been added.\r\n\r\nThis fix fixes #14646.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@facaiy any comment?", "@facaiy updated to add additional assert for shape function. Please take a look.", "@yongtang Thank you. "]}, {"number": 14677, "title": "Avoid using illegal characters in checkpoint file names in normalizat\u2026", "body": "\u2026ion_test.", "comments": ["Ping!"]}, {"number": 14676, "title": "XLA operation semantics documentation BatchNormTrain error", "body": "Hey! I think there are a few errors in the documentation for the XLA BatchNormTrain operation in https://www.tensorflow.org/performance/xla/operation_semantics#batchnormgrad.\r\n\r\nThe gradient of the scaling factor `gamma` should be\r\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\nabla&space;\\gamma&space;=&space;\\text{sum}\\Big(&space;\\nabla&space;y&space;*&space;\\frac{(&space;x&space;-&space;\\mu&space;)}{&space;\\sqrt{\\sigma^2&space;&plus;&space;\\epsilon}}&space;\\Big)\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\nabla&space;\\gamma&space;=&space;\\text{sum}\\Big(&space;\\nabla&space;y&space;*&space;\\frac{(&space;x&space;-&space;\\mu&space;)}{&space;\\sqrt{\\sigma^2&space;&plus;&space;\\epsilon}}&space;\\Big)\" title=\"\\nabla \\gamma = \\text{sum}\\Big( \\nabla y * \\frac{( x - \\mu )}{ \\sqrt{\\sigma^2 + \\epsilon}} \\Big)\" /></a>\r\ninstead of \r\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\nabla&space;\\gamma&space;=&space;\\text{sum}\\Big(&space;\\nabla&space;y&space;*&space;(&space;x&space;-&space;\\mu&space;)&space;*&space;\\sqrt{\\sigma^2&space;&plus;&space;\\epsilon}&space;\\Big)\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\nabla&space;\\gamma&space;=&space;\\text{sum}\\Big(&space;\\nabla&space;y&space;*&space;(&space;x&space;-&space;\\mu&space;)&space;*&space;\\sqrt{\\sigma^2&space;&plus;&space;\\epsilon}&space;\\Big)\" title=\"\\nabla \\gamma = \\text{sum}\\Big( \\nabla y * ( x - \\mu ) * \\sqrt{\\sigma^2 + \\epsilon} \\Big)\" /></a>\r\n\r\nMoreover, the gradient for the input tensor is also not correct. It should instead read something like this:\r\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\Big(&space;\\nabla&space;y&space;-&space;\\frac{\\hat{x}&space;\\times&space;\\nabla&space;\\gamma&space;&plus;&space;\\nabla&space;\\beta}{m&space;w&space;h}\\Big)&space;\\times&space;\\frac{\\gamma}{\\sqrt{\\sigma^2&space;&plus;&space;\\epsilon}}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\Big(&space;\\nabla&space;y&space;-&space;\\frac{\\hat{x}&space;\\times&space;\\nabla&space;\\gamma&space;&plus;&space;\\nabla&space;\\beta}{m&space;w&space;h}\\Big)&space;\\times&space;\\frac{\\gamma}{\\sqrt{\\sigma^2&space;&plus;&space;\\epsilon}}\" title=\"\\Big( \\nabla y - \\frac{\\hat{x} \\times \\nabla \\gamma + \\nabla \\beta}{m w h}\\Big) \\times \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}}\" /></a>\r\n\r\nWhere the products and summations are done in a \"broadcasted\" manner when shapes don't match and <a href=\"https://www.codecogs.com/eqnedit.php?latex=\\hat{x}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\hat{x}\" title=\"\\hat{x}\" /></a> is the whitened input tensor. That is:\r\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\hat{x}&space;=&space;\\frac{x&space;-&space;\\mu}{\\sqrt{\\sigma^2&space;&plus;&space;\\epsilon}}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\hat{x}&space;=&space;\\frac{x&space;-&space;\\mu}{\\sqrt{\\sigma^2&space;&plus;&space;\\epsilon}}\" title=\"\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\" /></a>\r\n\r\n\r\nThere also seem to be a typo in the table explaining the output of this XLA node. The second row should say `grad_offset` in the first column, `ComputationalDataHandle` in the second column, and the semantics column should say something like `gradient with respect to input offset`.\r\n\r\n \r\nFinally, it may be good if it could be specified that the summation used for the gradients of the scaling and offset tensors is performed over all dimensions that were used to compute the different statistics during normalization.", "comments": ["Just saw this. Good catches, thanks! We did notice the mistakes in the formula when we were testing the implementation, but haven't got a chance to fix the doc. Will work on a fix. ", "Great! Let me know if I can help somehow. Thanks!", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @yunxing: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @yunxing: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @yunxing: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Ahh this is has already been fixed a while ago, I forgot to close this."]}, {"number": 14674, "title": "Fix parameter pack expansion in ptr_util.", "body": "", "comments": ["Let's check if the XLA tests pass."]}, {"number": 14673, "title": "Fixed bug in code within programmer's guide markdown docs for Variabl\u2026", "body": "\u2026es. Had a call to {tensor}.run() method, but Tensor instances have no run() method, switched to eval() instead.", "comments": ["Can one of the admins verify this patch?", "Thanks guys. @GreggHelt2 could you resolve the conflicts?"]}, {"number": 14672, "title": "Compilation Flags", "body": "Can someone please explain the flags that can be enabled when compiling TensorFlow from source? I don't seem to understand the functionality of most of them and they are not documented.\r\n", "comments": ["where could you find the detail list of them? i only see those in the window compiling instruction ~", "@colmantse I am not sure I understood what you mean exactly, but this is the list I am referring to:\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: \r\nGoogle Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: \r\nHadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: \r\nAmazon S3 File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: \r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: \r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL support? [y/N]: \r\nNo OpenCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: \r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: \r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nI understand Hadoop, XLA, CUDA, OpenCL and MPI however, I do not understand what the rest does", "Sorry, I think right you pretty much have to know what you're doing. Usually you should keep with the default unless you know what you are doing.\r\n\r\n@MarkDaoust maybe there is something I am missing?", "A quick search seems to indicate that the other options,  GDR and VERBS are for these two contrib packages:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/verbs\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/gdr\r\n\r\nMaybe we should link to these on the install/sources page? @RainbowZephyr, it could be relatively straight forward, care to send a PR?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly."]}, {"number": 14671, "title": "Added mode to input_fn argument", "body": "And modified existing tests to include the mode argument. \r\n\r\n(deleted previous PR because I accidentally pulled a bunch of other commits into the branch)", "comments": ["@tensorflow-jenkins test this please", "Jenkins, test this please.", "Seems like an unrelated failure.\r\n```\r\n[ RUN      ] NaryGradTest.Select\r\ntensorflow/cc/gradients/math_grad_test.cc:699: Failure\r\nExpected: (max_error) < (1e-3), actual: 0.170095 vs 0.001\r\n[  FAILED  ] NaryGradTest.Select (7 ms)\r\n```", "Jenkins, test this please.", "@tensorflow-jenkins test this please", "Not sure what happened to the Linux XLA log.\r\n\r\nJenkins, test this please.", "@gunan any idea what happened to the Linux XLA test? I ran kokoro and Jenkins again and it's still 404.", "Ignoring Jenkins build Linux XLA that is now in kokoro."]}, {"number": 14670, "title": "Tensorflow Lite toco conversion error on SSD fails", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOSX 10.12.6\r\n- **TensorFlow installed from (source or binary)**: source \r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.7.0-homebrew\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.38)\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: see below\r\n\r\n### Describe the problem\r\nI'm trying to convert a model from the object-detection framework to a tflite file. Here's the command I run:\r\n\r\n bazel run --config=opt tensorflow/contrib/lite/toco:toco -- \\\r\n                                                         --input_file=(path)/models/research/object_detection/output_inference_graph/frozen_inference_graph.pb \\\r\n                                                         --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\r\n                                                         --output_file=(pwd)/mobilenet_v1_1.0_224.lite --inference_type=FLOAT \\\r\n                                                         --input_type=FLOAT --input_arrays=image_tensor \\\r\n                                                         --output_arrays=detection_boxes --input_shapes=1,320,320,3\r\n\r\nhere's the output:\r\n\r\n...\r\n2017-11-17 22:02:12.888007: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: TensorArrayGatherV3\r\n2017-11-17 22:02:12.888037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice\r\n2017-11-17 22:02:12.888065: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: StridedSlice\r\n2017-11-17 22:02:12.888077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: LogicalAnd\r\n2017-11-17 22:02:12.888123: F tensorflow/contrib/lite/toco/import_tensorflow.cc:281] Check failed: GetInputsCount(node, model->flags.drop_control_dependency()) == 2 (3 vs. 2)\r\n\r\nI freezed the model using the python script from the object detection framework:\r\n\r\npython export_inference_graph.py  --input_type image_tensor --pipeline_config_path samples/configs/ssd_mobilenet_v1_coco.config  --trained_checkpoint_prefix ../../../ssd_mobilenet_v1_coco_11_06_2017/model.ckpt  --output_directory output_inference_graph --input_shape 1,320,320,3\r\n\r\nAny idea why the conversion fails?\r\nThanks for any help!", "comments": ["We haven't worked on or tested this model yet. In particular, that model uses several operations that are not supported in tflite like striced slice, logical and etc. (the error message says this). It is possible (with some work to extend tflite operations to support this model) by providing custom operations that implement these ops, but this is not straightforward to do yet. You can also specify --drop_control_dependencies to get past this point, but it will likely fail elsewhere. Let us know if you have any more progress.", "@aselle  Thanks for the hint, added --drop_control_dependency=true  to the toco call, but -as you predicted-  it now fails with:\r\n\r\n...\r\n2017-11-18 13:21:54.634779: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: Pack\r\n2017-11-18 13:21:54.634800: I tensorflow/contrib/lite/toco/import_tensorflow.cc:937] Converting unsupported operation: Where\r\n2017-11-18 13:21:54.634826: F tensorflow/contrib/lite/toco/import_tensorflow.cc:1042] Check failed: tf_src_dtype == DT_UINT8 || tf_src_dtype == DT_INT32 || tf_src_dtype == DT_FLOAT\r\n\r\nDoes this mean that the model uses a type (somewhere?) which is not UINT8 INT32 or FLOAT?\r\n\r\nThanks!", "@dhelleberg \r\nAs per the documentation of [export_inference_graph.py](https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py) under [object_detection,](https://github.com/tensorflow/models/tree/master/research/object_detection) the model is exported with input as image_tensors which is basically a uint8 4-D tensor of shape [None, None, None, 3].\r\nIt's UINT8 but there's some difference which I don't understand yet.\r\nFYI.. I'm getting the same error. Looking forward to get updates from Tensorflow soon.", "It looks like multiple things are happening. You still have operations we don't support (Pack, Where). We are working to add more ops. If you're inclined you can provide your own implementations of these as custom ops.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "OS: Ubuntu 16.04.3\r\nCUDA: 9.0\r\nAnaconda: 5.0.1\r\nPython: 3.6.2\r\nTensorflow: Build from source of today: December 28, 2017 .\r\nbazel: 0.9.0\r\n\r\nMy command to build Tensorflow: `bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n>                        ^\r\n> **ERROR**: /home/longer/Downloads/deeplearning/tensorflow/tensorflow/contrib/lite/toco/BUILD:328:1: Linking of rule '//tensorflow/contrib/lite/toco:toco' failed (Exit 1)\r\n> /usr/bin/ld: warning: libcublas.so.9.0, needed by bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n> /usr/bin/ld: warning: libcudnn.so.7, needed by bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n> /usr/bin/ld: warning: libcufft.so.9.0, needed by bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n> /usr/bin/ld: warning: libcurand.so.9.0, needed by bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGemmEx@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreate@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreatePoolingDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateConvolutionDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBiasActivationForward@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecD2Z@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotg_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyConvolutionDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecR2C@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyrk_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetVersion@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetWorkArea@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher2k_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecC2C@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetStream@libcurand.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetPseudoRandomGeneratorSeed@libcurand.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2D@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStpsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDznrm2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyFilterDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdscal_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIzamax_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgeru_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandDestroyGenerator@libcurand.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStpmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIsamax_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan1d@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelForward@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateRNNDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyRNNDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardData@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateFilterDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelBackward@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScopy_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScnrm2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan3d@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSnrm2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmEx@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyLRNDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroy@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotg_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetStream_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSswap_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDropoutGetStatesSize@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardWorkspaceSize@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotmg_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetActivationDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIsamin_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetPoolingNdDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNWorkspaceSize@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetStream@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCrotg_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardAlgorithm@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSdot_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardBias@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsscal_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrsm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyr2k_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrot_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSaxpy_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateUniformDouble@libcurand.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensorNdDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateUniform@libcurand.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2k_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDnrm2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrsm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnAddTensor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrmm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyActivationDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgeru_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDdot_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetConvolutionNdDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetAutoAllocation@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingBackward@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardData@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamin_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetFilterNdDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterWorkspaceSize@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCdotu_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZherk_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNTrainingReserveSize@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgerc_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftDestroy@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhemm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftCreate@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetLRNDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCaxpy_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardTraining@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyTensorDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamax_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyDropoutDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan3d@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtbsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhemv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyrk_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateTensorDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSger_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetStream@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDswap_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormalDouble@libcurand.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotc_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecC2R@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCreate_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan1d@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZrotg_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardInference@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDscal_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDger_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateDropoutDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStbsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandCreateGenerator@libcurand.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetPointerMode_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsymv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyPoolingDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGetPointerMode_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCswap_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateActivationDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspr2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCdotc_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDestroy_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrot_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardInference@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDzasum_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamin_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZswap_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCherk_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsymm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithm@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmBatched@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnActivationForward@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerMatrixParams@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsyrk_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsymm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZscal_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormal@libcurand.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetRNNDescriptor_v6@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataWorkspaceSize@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDasum_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotmg_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamax_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationBackward@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetMathMode@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetDropoutDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgerc_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr2_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSasum_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsymm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemmBatched@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDcopy_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlanMany@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionForward@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyrk_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspr_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardFilter@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCscal_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtbsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterAlgorithm@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdrot_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIzamin_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerBiasParams@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetFilterNdDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2Z@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsrot_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotu_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNParamsSize@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan2d@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionNdForwardOutputDim@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetGeneratorOffset@libcurand.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDaxpy_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan2d@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZaxpy_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensor4dDescriptor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGetMathMode@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZcopy_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemmBatched@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemmBatched@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardWeights@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlanMany@libcufft.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2k_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCcopy_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgbmv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsymv_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSscal_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardTraining@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnTransformTensor@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsyr2k_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetConvolutionMathType@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingForward@libcudnn.so.7'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScasum_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher2k_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsymm_v2@libcublas.so.9.0'\r\n> bazel-out/k8-py3-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateLRNDescriptor@libcudnn.so.7'\r\n> collect2: error: ld returned 1 exit status\r\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n> Use --verbose_failures to see the command lines of failed build steps.\r\n> INFO: Elapsed time: 2509.522s, Critical Path: 152.39s\r\n> **FAILED**: Build did **NOT** complete successfully\r\n> (jpenv) longer@longer:~/Downloads/deeplearning/tensorflow$\r\n> \r\n\r\n\r\nAny solutions so far?\r\n\r\nCheers\r\nPei", "We are working on supporting mobilenet SSD, and when we have it ready we will update this issue.", "@aselle \r\nThank you Andrew... Happy New year... ^_^", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Any updates on this? Is object detection supported in Tensorflow Lite?", "@jiapei100: Your linking error seems to be the same as in #14573. See [my last message there](https://github.com/tensorflow/tensorflow/issues/14573#issuecomment-362306751) for a work-around, but that means that part of TF is not included anymore.", "I had some success by stripping parts of the original graph off and extracted a subgraph. I converted the subgraph to tflite format however I couldn't get it running on mobile since the input tensor is now float and for the output tensor(s) it seems like I'm getting the proposals for the boxes and need to do some post processing... not sure if that will lead to any success...", "Any updates on this? Is object detection supported in Tensorflow Lite?\r\n\r\n", "I understand it'll take some time. Given that people are waiting for this, do you have a timeline or plan when SSD mobilenet will be supported?", "Nagging Assignee @aselle: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "We have had some successes with SSD models recently. The big caveat is that you might have to skip some of the preprocessing and postprocessing which is complicate and not supported by TF Lite. YMMV.", "Yeah I tried to extract a subgraph and do pre / post processing on my own.\nIt would be great to have a sample for this cause it's hard to figure out\nthe necessary steps from the tensorflow model itself\n\nAm Mi., 25. Apr. 2018 um 16:32 Uhr schrieb andrehentz <\nnotifications@github.com>:\n\n> We have had some successes with SSD models recently. The big caveat is\n> that you might have to skip some of the preprocessing and postprocessing\n> which is complicate and not supported by TF Lite. YMMV.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14670#issuecomment-384307531>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AARVvc9KW6T6JU6WU3lsJ-UAV7UdS-mGks5tsIkZgaJpZM4QioeW>\n> .\n>\n", "@dhelleberg \r\nThere is some code here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java\r\nHowever, I think the code to extract score is not right. Using the .001 cutoff generates too much noise.", "Nagging Assignee @aselle: It has been 17 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 32 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @achowdhery: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @achowdhery: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "The updated instructions are coming soon", "@achowdhery How soon?", "Please follow Blog post:\r\nhttps://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\r\n", "I'll close this one for now. If you encounter any issues with the blog instructions, please file a separate bug."]}, {"number": 14669, "title": "Feature Request | Set keras random state with tensorflow", "body": "Is it possible to set the `random_seed` in `keras` with `tensorflow`?  Would you need to set it to a specific graph? I have not found out how to set the random state in `keras` and if this doesn't exist could this be a feature in future versions? ", "comments": ["The feature request has been discussed for one and half years in fchollet/keras#2280, however there seems nothing new. I believe @fchollet must care the issue.", "How should I update this? I'm not sure how to implement a random_state in keras that transfers to tensorflow. ", "Hi, @jolespin. Let's wait for reply from tensorflower. ", "Nagging Assignee @fchollet: It has been 128 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}]