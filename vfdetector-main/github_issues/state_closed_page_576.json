[{"number": 36405, "title": "[core] check index channel before accessing center_frequencies_", "body": "Check index channel before accessing center_frequencies_ since the order of execution for the expression is always left to right.", "comments": []}, {"number": 36404, "title": "sample code of while_loop can't execute on tf nightly", "body": "I am using 2.2.0-dev20200129. I find that the sample code [here](https://tensorflow.google.cn/api_docs/python/tf/while_loop#example_2) cause the following error message\r\n\r\n>TypeError: Cannot iterate over a scalar tensor.\r\n\r\non this version.", "comments": ["Was able to reproduce the issue with TF 2.2.0.dev20200203. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/0a0ec487ea78c0204cf155ba96e02efc/36404.ipynb). Thanks!", "```python\r\nimport tensorflow as tf\r\ni = tf.constant(0)\r\nc = lambda i: tf.less(i, 10)\r\nb = lambda i: (tf.add(i, 1), )  #pass body as a tuple\r\nr = tf.while_loop(c, b, [i])\r\n```\r\nThe above example works in tf-nightly version.\r\nSee https://www.tensorflow.org/api_docs/python/tf/while_loop?version=nightly#example", "OK, so the body has to be a tuple currently.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36404\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36404\">No</a>\n"]}, {"number": 36403, "title": "[core] Avoid HashNode lookup of a null nodedef", "body": "Avoid HashNode lookup of a null nodedef", "comments": []}, {"number": 36402, "title": "Labels missing on TensorFlow Lite example after applying custom model.", "body": "I'm using Teachable Machine for an image classification problem.\r\n\r\nI have exported the model produced by Teachable Machine in FLOAT format.\r\n\r\nI strictly followed the instruction about placing the labels.txt and model on the right folder and also about making changes on ClassifierQuantizedMobileNet and activity_camera.xml\r\n\r\nYet still the labels and the percentage of confidence won't show up as they do in the example.\r\nHow to fix that?\r\n\r\n![Screenshot_2020-02-01-12-34-07-431_org tensorflow lite examples classification](https://user-images.githubusercontent.com/24626324/73590854-26156e80-44f0-11ea-92bd-f5a09a9324fc.jpg)\r\n", "comments": ["@karapapas, Please fill the [template](https://github.com/tensorflow/tensorflow/issues/new/choose) to analyze the reported issue. ", "\"Classifier**Quantized**MobileNet\"\r\n\r\n\"Teachable Machine in **FLOAT** format.\"\r\n\r\nMaybe because the model(float) is not compatible with the classifier (quantized)?", "@karapapas, Did you check @srjoglekar246's comment. ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36401, "title": "dll loading failed in tensorflow", "body": "raise ImportError(msg)\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\sidha\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\sidha\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\sidha\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\sidha\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\sidha\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.", "comments": ["python 3.7", "What version of TensorFlow is this happening on? If this is in nightly do you mind seeing if it is possible to repro in the latest official release?", "Please fill out the template in the future so we are able to better assist you. Looks like [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) can help and is related? We are updating documentation very soon.", "Hi @sidharth1805, \r\n\r\nDid you install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019?\r\n\r\nAccording to the docs at https://www.tensorflow.org/install/pip,\r\n\r\n> Install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019. Starting with the TensorFlow 2.1.0 version, the msvcp140_1.dll file is required from this package (which may not be provided from older redistributable packages). The redistributable comes with Visual Studio 2019 but can be installed separately:\r\n\r\n> Go to the [Microsoft Visual C++ downloads](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads),\r\nScroll down the page to the Visual Studio 2015, 2017 and 2019 section.\r\nDownload and install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 for your platform.\r\nMake sure [long paths](https://superuser.com/questions/1119883/windows-10-enable-ntfs-long-paths-policy-option-missing) are enabled on Windows.\r\n\r\n> Install the [64-bit Python 3 release](https://www.python.org/downloads/windows/) for Windows (select pip as an optional feature).\r\n\r\nTensorflow 2.1.0 is compiled using MSVC 2019, which appears to require an additional DLL.", "thank you sorry for responding late installing  microsoft visual c++ solved the issue"]}, {"number": 36400, "title": "Metrics passed to on_batch_end(...) in Keras are inconsistent", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Uubntu 18.04\r\n- **TensorFlow installed from (source or binary)**: pip tensorflow-gpu\r\n- **TensorFlow version (use command below)**: 2.1\r\n- **Python version**: 3.7\r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**: K80\r\n- **Exact command to reproduce**: see code below\r\n\r\n### Describe the problem\r\nThe method `on_batch_end` of `tf.keras.callbacks.Callback` receives a parameter `logs`, which contains, e.g., `loss` and `accuracy`. While `loss` is the actual loss of the current batch, `accuracy` is a moving average and the same as printed by the progressbar of `model.fit(...)`. \r\nThe expected behavior is a consistent behavior, i.e. either both values are moving average or both are the actual batch values. I don't have a clear preference for either of both, but the moving average probably creates the least amount of confusion as the is consistent with the progress bar and the function `on_epoch_end`.\r\n\r\n### Source code / logs\r\nThe following snipped shows the current bevior:\r\n```python\r\n    from tensorflow import keras\r\n    from tensorflow.keras import layers\r\n\r\n    inputs = keras.Input(shape=(784,), name='digits')\r\n    x = layers.Dense(4*4096, activation='relu', name='dense_1')(inputs)\r\n    x = layers.Dense(4*4096, activation='relu', name='dense_2')(x)\r\n    x = layers.Dense(4*4096, activation='relu', name='dense_3')(x)\r\n    outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\r\n\r\n    model = keras.Model(inputs=inputs, outputs=outputs)\r\n    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n    x_train = x_train.reshape(60000, 784).astype('float32') / 255\r\n    y_train = y_train.astype('float32')\r\n\r\n    class PrintStatsCallback(keras.callbacks.Callback):\r\n        def on_batch_end(self, epoch, logs=None):\r\n            print('\\nON_BATCH_END: loss: {loss:.4f} accuracy: {accuracy:.4f}'.format_map(logs))\r\n\r\n    # Specify the training configuration (optimizer, loss, metrics)\r\n    model.compile(optimizer=keras.optimizers.SGD(lr=0.1),\r\n                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n\r\n    model.fit(x_train, y_train,\r\n              steps_per_epoch=10,\r\n              batch_size=1024,\r\n              callbacks=[PrintStatsCallback()])\r\n```\r\n\r\nThe output is currently as follows:\r\n```\r\n    Train on 60000 samples\r\n    \r\n    ON_BATCH_END: loss: 2.3004 accuracy: 0.1543\r\n     1024/60000 [..............................] - ETA: 1:18 - loss: 2.3004 - accuracy: 0.1543\r\n    ON_BATCH_END: loss: 2.2151 accuracy: 0.2715\r\n     2048/60000 [>.............................] - ETA: 1:11 - loss: 2.2578 - accuracy: 0.2715\r\n    ON_BATCH_END: loss: 2.1440 accuracy: 0.3613\r\n     3072/60000 [>.............................] - ETA: 1:08 - loss: 2.2199 - accuracy: 0.3613\r\n    ...\r\n```\r\n\r\nFor example, compare the last two lines:\r\n`ON_BATCH_END: loss: 2.1440 accuracy: 0.3613` \r\nto \r\n`3072/60000 [>.............................] - ETA: 1:08 - loss: 2.2199 - accuracy: 0.3613`\r\n\r\nThe accuracy of both `on_batch_end` and the progress bar are identical, but the loss value differs as the loss value is not a moving average.", "comments": ["I have tried on colab with TF version 2.1.0-rc2, 2.2.0-dev20200203 and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/7d88b982abb771879829ca3381ae581c/untitled615.ipynb). Thanks!", "@ravikyram Why not providing a parameter (in the `fit` method) that allows you to control what the user sees in the progress bar? Similarly, the callbacks should have options to specify what the user sees and not. \r\n\r\nThis should at least be well-documented. It's not documented anywhere what the progress bar is actually displaying!!\r\n\r\nI've just spent 3 days trying to understand an apparent a weird behaviour, and it turned out that this was just Keras printing a _moving average_ in the progress bar (rather than the actual loss for the single step of the epoch).", "@MarcelSimon I think this was resolved in recent `tf-nightly`. Can you please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/1904128c076a3f65e34be9fb74525f89/untitled615.ipynb).\r\n\r\nThe `batch_end` values are different from the epoch results.\r\n```\r\nON_BATCH_END: loss: 2.3029 accuracy: 0.0898\r\n 1/10 [==>...........................] - ETA: 12:49 - loss: 2.3029 - accuracy: 0.0898\r\nON_BATCH_END: loss: 2.2617 accuracy: 0.1714\r\n 2/10 [=====>........................] - ETA: 11:11 - loss: 2.2823 - accuracy: 0.1306\r\nON_BATCH_END: loss: 2.2223 accuracy: 0.2292\r\n 3/10 [========>.....................] - ETA: 9:47 - loss: 2.2623 - accuracy: 0.1635 \r\nON_BATCH_END: loss: 2.1837 accuracy: 0.3313\r\n 4/10 [===========>..................] - ETA: 8:23 - loss: 2.2427 - accuracy: 0.2054\r\nON_BATCH_END: loss: 2.1452 accuracy: 0.4010\r\n 5/10 [==============>...............] - ETA: 7:00 - loss: 2.2232 - accuracy: 0.2445\r\nON_BATCH_END: loss: 2.1072 accuracy: 0.4518\r\n 6/10 [=================>............] - ETA: 5:35 - loss: 2.2039 - accuracy: 0.2791\r\nON_BATCH_END: loss: 2.0682 accuracy: 0.4915\r\n 7/10 [====================>.........] - ETA: 4:11 - loss: 2.1845 - accuracy: 0.3094\r\nON_BATCH_END: loss: 2.0298 accuracy: 0.5209\r\n 8/10 [=======================>......] - ETA: 2:47 - loss: 2.1651 - accuracy: 0.3359\r\nON_BATCH_END: loss: 1.9884 accuracy: 0.5462\r\n 9/10 [==========================>...] - ETA: 1:23 - loss: 2.1455 - accuracy: 0.3592\r\nON_BATCH_END: loss: 1.9457 accuracy: 0.5699\r\n10/10 [==============================] - 839s 84s/step - loss: 2.1092 - accuracy: 0.3975\r\n<tensorflow.python.keras.callbacks.History at 0x7f6fc8b59518>\r\n```\r\n\r\nPlease verify once and close the issue if this was resolved for you. thanks!", "Looks good, thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36400\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36400\">No</a>\n"]}, {"number": 36399, "title": "Hparams with Estimators", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nHparams cannot be used with estimators in tensorflow 2. There's a `KerasCallback` class that logs the `hparams` when using Keras `model.fit`, however this is not usable when using Estimator API. \r\n\r\nThere could be a feature in the form of a callback or hook that can be attached to estimators (with TrainSpec or EvalSpec) which will log hparams metrics against the `hparams` for the current trial.\r\n\r\n**Will this change the current api? How?**\r\nMost likely, **no**.\r\n\r\n**Who will benefit with this feature?**\r\nThose who rely on Estimator API and tensorboard will benefit.\r\n", "comments": ["I was able to log hparams for the current trial following the instructions when not using keras given at [hparams/api.py](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/hparams/api.py#L38).\r\n\r\n\r\n```py\r\n# log hparams for current trial\r\nwith tf.summary.create_file_writer(train_folder).as_default():\r\n    hp_learning_rate = hp.HParam(\"learning_rate\", hp.RealInterval(0.00001, 0.1))\r\n    hp_distance_margin = hp.HParam(\"distance_margin\", hp.RealInterval(0.1, 1.0))\r\n    hparams_list = [\r\n        hp_learning_rate,\r\n        hp_distance_margin\r\n    ]\r\n    metrics_to_monitor = [\r\n        hp.Metric(\"metrics_standalone/auc\", group=\"validation\"),\r\n        hp.Metric(\"loss\", group=\"train\", display_name=\"training loss\"),\r\n    ]\r\n    hp.hparams_config(hparams=hparams_list, metrics=metrics_to_monitor)\r\n    hparams = {\r\n        hp_learning_rate: params.learning_rate,\r\n        hp_distance_margin: params.distance_margin,\r\n    }\r\n    hp.hparams(hparams)\r\n```\r\n\r\nI can see the logged `hparams` in tensorboard\r\n\r\n![image](https://user-images.githubusercontent.com/8567893/73587634-771f6580-44e4-11ea-87a9-6a670b69bebe.png)\r\n", "However, I am not able to connect the metrics already logged.\r\n\r\n![image](https://user-images.githubusercontent.com/8567893/73587677-dda48380-44e4-11ea-90a2-e6010beac48a.png)", "Since this belongs more on the tensorboard issues page, closing this. Issue moved [here](https://github.com/tensorflow/tensorboard/issues/3206)."]}, {"number": 36398, "title": "Support a generic API for modifying loss / gradients in Keras", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nIn the upcoming 2.2 release, `experimental_run_tf_function` was removed from `tf.keras.Model.compile` (see https://github.com/tensorflow/tensorflow/issues/35138).\r\n\r\nAs a result, [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py#L274) code path is now executed by default.  However, because only the `apply_gradients` method is called on the optimizer, there is no way to perform custom steps such as loss scaling, gradient clipping, or gradient allreduce (in the case of [Horovod](http://horovod.ai/)).\r\n\r\nThe one exception is for the [LossScaleOptimizer](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer), which is hard-coded into the `_process_single_batch` function to get the scaled loss and the unscaled gradients.  \r\n\r\nHowever, this is not a general solution, because (1) not every optimizer will want to inherit from this class in order to provide custom hooks, and (2) because the class is experimental, there's no guarantee of long-term support for this interface from the TensorFlow developers.\r\n\r\nWe propose adding new classes (`WrappedOptimizer`, `WrappedGradientTape`) from which classes such as `LossScaleOptimizer` and Horovod's [DistributedOptimizer](https://github.com/horovod/horovod/blob/6c80085a3c162947e37d331d2b9b371b724bb61d/horovod/_keras/__init__.py#L22) can inherit to provide these hooks:\r\n\r\n1. `def before_compute_gradients_hook(self, loss)`\r\n2. `def after_compute_gradients_hook(self, grads_and_vars)`\r\n3. `def before_apply_gradients_hook(self, grads_and_vars)`\r\n4. `def should_apply_training_step_hook(self, grads_and_vars)` (return a boolean Tensor set to True if the step shall be applied and an `execute_op`)\r\n\r\n**Will this change the current api? How?**\r\n\r\nThis will not change the user-facing API, but will provide new functionality for users who wish to extend the TensorFlow API.  \r\n\r\nInternally, this change will modify `_process_single_batch` to use the new `WrappedOptimizer` interface in place of `LossScaleOptimizer`.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone who wishes to extend TensorFlow with custom loss or gradient modifications (for example, Horovod).\r\n\r\n**Any Other info.**\r\n\r\nContributors:\r\n\r\n@DEKHTIARJonathan \r\n@romerojosh \r\n@abditag2\r\n@tgaddair\r\n\r\nCC:\r\n\r\n@reedwm \r\n", "comments": ["Thank you for the proposal. Subclassing the experimental LossScaleOptimizer and overriding `get_scaled_loss` and `get_unscaled_gradients` is hacky and not what LossScaleOptimizer is intended for, for, so I agree this needs to be addressed.\r\n\r\nOne thing I'm  confused about is whether Keras would expect a `WrappedOptimizer` or a non-wrapped optimizer. Would it use `isinstance` to determine if the optimizer is a `WrappedOptimizer`, and only call `before_compute_gradients_hook`, etc, if the optimizer is a wrapped optimizer? Also how would nesting of `WrappedOptimizers` work, if, e.g., a user wanted a LossScaleDistributedOptimizer? \r\n\r\nWe also should have an `after_allreduce_gradients_hook(grads_and_vars)` since Optimizer itself will all-reduce gradients if `tf.distribute.Strategy` is used. This isn't useful for Horovod which does its own reductions, but would be useful for other purposes, such as unscaling the fp16 gradients and casting them to fp32 after the all-reduce is done.\r\n\r\n/CC @alextp @zongweiz @omalleyt12, thoughts?\r\n", "The high level idea is to expose a bunch of \"high level\" hooks in a similar fashion to the Keras Callback and let the Keras Engine &  the Wrapper Optimizer do the heavy lift and logic aspect for you. This approach has numerous advantage :\n- being easy to extend from: facilitate research\n- no need to care about the complex inner logic of how the backend API on an optimizer operates. The dev/researcher just has to implement his business/research specific logic. How the logic is called is not concern. \n- far less maintenance over time. As long as the WrapperOptimizer is stable, all the optimizer deriving from it shall be stable. If we apply a bug fix, no need to repeat the fix in multiple optimizers... \n\nIMHO this proposal fits very well with the Keras logic and tradition. \n\nIn more technical terms, Keras can check if the optimizer is a subclass of WrapperOptimizer and trigger in consequence the correct hooks at the right time.\n\nTechnically most of the \"hook triggering\" can be done directly inside the WrapperOptimizer and is completely transparent to the Keras logic.\n\nSounds good with me for the 5th hook.\n\nFor nesting, it shouldn't be an issue, and indeed it's an essential feature we need to support. \n\nOverall I think abstracting this kind of behavior is a major progress for the Keras Optimizer API.\nI will try to come up with an prototype design next week to drive the discussion.\n@Reedwm not sure how to properly implement the hook you talked about \ud83d\ude05 so, I'll just give you access to my fork or smthg else if you want to help \ud83d\ude0a ", "Thanks for the proposal!\r\n\r\n> because only the apply_gradients method is called on the optimizer, there is no way to perform custom steps such as loss scaling, gradient clipping, or gradient allreduce\r\n> We propose adding new classes (WrappedOptimizer, WrappedGradientTape) \r\n\r\nIn my opinion, the core issue with our current API is that gradient computation and application is split b/t the `GradientTape` and `Optimizer` objects.\r\n\r\nI think the best way to support hooks like these is to create an API that passes the `GradientTape` into the `Optimizer` like this:\r\n\r\n```\r\nwith tf.GradientTape() as tape:\r\n  loss = ...  # Tensor\r\n  optimizer.minimize(loss, variables=variables, tape=tape)\r\n```\r\n\r\nBy giving the `Optimizer` access to the `GradientTape` object, things like loss scaling can be handled internally by the `Optimizer`. Additionally, the implementation of this method should delegate its functionality to user-overridable hooks, making it easy to create an `Optimizer` subclass that supports custom functionality:\r\n\r\n```\r\nclass Optimizer:\r\n  def minimize(loss, variables, tape):\r\n    self._process_loss(loss)  # Corresponds to `before_compute_gradients_hook`\r\n    gradients = tape.gradients(loss, variables)\r\n    gradients = self._process_unaggregated_gradients(gradients) \r\n    gradients = self._aggregate_gradients(gradients)\r\n    gradients = self._process_aggregated_gradients(gradients)\r\n    self._apply_gradients(gradients, variables)\r\n```\r\n\r\nThis API would apply to all `Optimizer`s, so there would be no need for `Keras` to be aware of a distinction b/t wrapped/unwrapped optimizers. Importantly, high-level frameworks like `Keras` wouldn't have to be aware of these hooks at all, `Keras` would just accept any optimizer and call `model.optimizer.minimize` on it, and the hooks would just be implementation details of this method", "Hey @omalleyt12, thanks for chiming in.  I absolutely agree and think that would be a much cleaner approach.  Do you see this also becoming the standard approach for end-users outside of Keras as well?  So instead of users writing:\r\n\r\n```\r\ngrads = tape.gradient(loss_value, model.trainable_variables)\r\nopt.apply_gradients(zip(grads, model.trainable_variables))\r\n```\r\n\r\nThey would just write this inside their training step:\r\n\r\n```\r\nopt.minimize(loss, variables=model.trainable_variables, tape=tape)\r\n```\r\n\r\n@reedwm, if @omalleyt12's approach sounds good to everyone on your end, we'd be happy to prototype this in @DEKHTIARJonathan's fork.", "Thanks for the ideas @omalleyt12, @tgaddair, and @DEKHTIARJonathan. I have a few questions:\r\n\r\n1. How would a user combine multiple optimizer subclasses, each defining hooks? For example, I may have two optimizer subclasses, `OptimizerA` and `OptimizerB`, each which overrides `_process_unaggregated_gradients`. One way would be to define an optimizer subclassing both:\r\n\r\n   ```\r\n   class MyOptimizer(OptimizerA, OptimizerB):\r\n       pass\r\n   ```\r\n   But this is somewhat irritating, especially considering the order of the bases matters here. With the `WrappedOptimizer` concept, instead users could simply nest optimizers. The nesting structure would also make it more obvious the order of nesting matters.\r\n\r\n2. When subclassing to override hooks, would you override the base `Optimizer` or a concrete optimizer like `Adam`? If overriding `Adam`, what if you want your hooks to apply to a variety of optimizers? If overriding `Optimizer`, users would have to do a similar trick as above with multiple inheritance:\r\n\r\n   ```\r\n   class MyOptimizer(tf.keras.optimizers.Adam, OptimizerA):\r\n       pass\r\n   ```\r\n\r\n3. How would users use a LossScaleOptimizer with a CTL? Currently, they directly call `LossScaleOptimizer.get_scaled_loss` and `LossScaleOptimizer.get_unscaled_gradients`. Would they now instead have to call `LossScaleOptimizer._process_loss` and `LossScaleOptimizer._process_aggregated_gradients`? That seems more unintuitive. We could also recommend they call `minimize`, but I want to make using mixed precision as easy and seamless as possible, and switching to `minimize`, even in its new proposed form, is a bit of work.\r\n\r\nI don't think any of these issues are necessarily deal breakers, but I want to see if you have any ideas that I am not considering.", "> Do you see this also becoming the standard approach for end-users outside of Keras as well?\r\n\r\n@tgaddair  Yep, that would be the idea. We would still have to support `Optimizer.apply_gradients`, which IMO should be implemented along the same lines, but with only a subset of the hooks, since that method assumes the users want control of computing the unaggregated gradients themselves:\r\n\r\n```\r\nclass Optimizer:\r\n  def apply_gradients(self, grads_and_vars):\r\n    gradients, variables = ...  # Unpack the tuple.\r\n    gradients = self._aggregate_gradients(gradients)\r\n    gradients = self._process_aggregated_gradients(gradients)\r\n    self._apply_gradients(gradients, variables)\r\n```\r\n\r\n> How would a user combine multiple optimizer subclasses, each defining hooks?\r\n> If overriding Adam, what if you want your hooks to apply to a variety of optimizers? If overriding Optimizer, users would have to do a similar trick as above with multiple inheritance\r\n> How would users use a LossScaleOptimizer with a CTL?\r\n\r\n@reedwm I think these problems are all solved by using composition rather than inheritance. For example, here is the `LossScaleOptimizer` with this design:\r\n\r\n```python\r\nclass LossScaleOptimizer(Optimizer):\r\n  def __init__(self, optimizer):\r\n    super(LossScaleOptimizer, self).__init__()\r\n    self._optimizer = optimizer\r\n\r\n  def _process_loss(self, loss):\r\n    return self._get_scaled_loss(loss)\r\n\r\n  def _process_unaggregated_gradients(self, gradients):\r\n    return self._get_unscaled_gradients(gradients)\r\n```\r\n\r\nCTL users then just do:\r\n\r\n```python\r\noptimizer = LossScaleOptimizer(tf.optimizers.Adam(1e-3))\r\nwith tf.GradientTape() as tape:\r\n  loss = ...  # No scaling or other special-casing of LossScaleOptimizer needed here.\r\n  optimizer.minimize(loss, variables, tape=tape)\r\n```\r\n\r\nMeanwhile, users of `LossScaleOptimizer` who want to continue using `apply_gradients` directly can continue using the `get_scaled_loss` and `get_unscaled_gradients` hooks.\r\n\r\nFor another example, here is an `Optimizer` that wants to use the hooks of two different optimizers:\r\n\r\n```python\r\nclass CombinedOptimizer(Optimizer):\r\n  def __init__(self, optimizer1, optimizer2):\r\n    \"\"\"Calls hooks of optimizer1, then optimizer2.\"\"\"\r\n    super(CombinedOptimizer, self).__init__()\r\n    self._optimizer1 = optimizer1\r\n    self._optimizer2 = optimizer2\r\n\r\n  def _process_loss(self, loss):\r\n    loss = self._optimizer1._process_loss(loss)\r\n    return self._optimizer2._process_loss(loss)\r\n\r\n  # Same for other hooks.\r\n  ...\r\n```\r\n\r\nWDYT?\r\n    \r\n\r\n", "This looks reasonable. If every hook-based optimizer uses composition, I don't think we need the `CombinedOptimizer`, right? I'm not a big fan of `CombinedOptimizer`, since it can only call `apply_gradients` on one optimizer. Also for your `LossScaleOptimizer` example, I think `_process_loss` has to call `super()._process_loss`, then pass the return value to `_get_scaled_loss`\r\n\r\nAlso, we should probably do the dynamic subclassing trick [Horovod does here](https://github.com/horovod/horovod/blob/6c80085a3c162947e37d331d2b9b371b724bb61d/horovod/_keras/__init__.py#L74) and expose a helper method to do this automatically. @DEKHTIARJonathan  had a PR, #31578, to do this for LossScaleOptimizer. But I couldn't decide if it was the rigtht approach so I stalled accepting it (sorry about that!)\r\n\r\nAlso maybe we should simply have `Optimizer` take a list of callbacks instead? That way we don't have to deal with composition or inheritance. \r\n\r\nAnyway this approach is looking pretty good to me, but others may disagree. Let's wait until we get more feedback.", "> I don't think we need the CombinedOptimizer, right? \r\n\r\nAgreed. This was just an example in response to the Q: \"How would a user combine multiple optimizer subclasses, each defining hooks?\"\r\n\r\nMostly, when users use two Optimizers, I'd imagine they are using them for two separate sets of Variables. In that case, `optimizer1.minimize(loss, vars1, tape)` and `optimizer2.minimize(loss, vars2, tape)` works\r\n\r\n> Also for your LossScaleOptimizer example, I think _process_loss has to call super()._process_loss, then pass the return value to _get_scaled_loss\r\n\r\nTrue, agreed. It should be calling `self._optimizer.process_loss` too.\r\n\r\n> Also, we should probably do the dynamic subclassing trick\r\n\r\nIMO it's cleaner and more explicit to rely on composition: `DistributedOptimizer(optimizer)`\r\nI don't have full context on Horovod's use case here, but for TF core, when possible, we should avoid adding more Python magic\r\n\r\n> Also maybe we should simply have Optimizer take a list of callbacks instead? That way we don't have to deal with composition or inheritance.\r\n\r\nIMO the callback pattern is justified when each callback is:\r\n\r\n(1) optional\r\n(2) independent\r\n\r\nIf we violate (1), we are splitting essential functionality across two objects and providing a foot-gun. If we violate (2), we are creating ordering concerns. Keras's Callbacks in `Model.fit` satisfy (1) and (2). But having callback hooks in the `Optimizer` would violate both. For instance, in that pattern, mixed-precision would require a loss-scaling callback:\r\n\r\n```\r\noptimizer = Adam(1e-3, callbacks=[LossScaling()])\r\n```\r\n\r\nThen, if a user wanted to add another callback, it's not clear which order the callbacks should be in.\r\n\r\nAdditionally, it's safer to wrap an object than to patch it, so when users provide an optimizer like this:\r\n\r\n```python\r\nmodel.compile(optimizer=Adam(), ...)\r\n```\r\n\r\nIt's less surprising to say `optimizer = LossScalingOptimizer(optimizer)` than to say `optimizer.add_callback(LossScaling())`, which will silently modify the user-provided object.\r\n\r\nIn general, I think implementing new `Optimizer` functionality via inheritance and composition is a nice pattern and inline with how we want users to write `Layer`s and `Model`s, for instance.\r\n\r\nIt also makes sharing code easy; if you want to use my custom optimizer logic, you can just instantiate the `MyCustomOptimizer` object ", "The objective of building a base class to implement a \"wrapping optimizer\" was also to avoid code duplication (leading to increased likeness of bugs and heavier maintenance load). Aside of the implementation of the use-case logic like allreduce gradients or loss scaling. There is a significant amount of boilerplate code required to make sure that the right \"hook\" is called at the right time and then forwarding calls to the underlying optimizer.\n\nI don't really see how we can modify the OptimizerV2 class go avoid having to rewrite a lot of boilerplate code each time we want to implement a \"wrapping optimizer\" \n\n@reedwm @omalleyt12 one of you wants to volonteer to come up with a prototype design? I would have done it, I don't really see what you have in mind in this case. It would probably help a lot to fuel the discussion to have a starting point.\n\n@reedwm whatever direction we take, if we manage to merge a solution to this issue before the TF2.2 cut, that would be truly nice.  And would probably avoid having Horovod breaking on TF2 (a lot of people rely on Horovod to implement distributed training) ", "Sorry I'm so late to this thread.\r\n\r\nGoing back to the original proposal, I agree there is a need to customize what happens in the training loop in the steps listed (before computing gradients, after computing gradients, before applying gradients, and maybe the conditional should apply).\r\n\r\nI just wish this extension was done outside the Optimizer class. Ideally the optimizer classes should just concern themselves with applying the actual SGD update; the only reason things like gradient reduction, loss scaling, and others have been pushed into the optimizers is that optimizers were a tempting extension point (specially with TF's optimizer.minimize API and keras's get_updates API being a little too broad).\r\n\r\nCan we add these four methods (or small variations thereof) to the keras callback class and allow users to use callbacks to drive fp16 loss scaling, distributed gradient aggregation, and friends, while pushing complexity out of optimizers so they can look as clean as the math in the research papers?", "@alextp doing so would immediately break any code published with HVD or Mixed Precision. I would agree with the idea of separating the behavior of \"Optimizers\" and Hooks. However, it doesn't feel right to me to break everyone code. There must be a better way", "> I just wish this extension was done outside the Optimizer class. Ideally the optimizer classes should just concern themselves with applying the actual SGD update\r\n\r\n@alextp Could you explain the motivation for this? To me, conceptually, an \"optimizer\" handles everything b/t loss calculation and variable updates. When I think of an optimization interface, I think \"Minimize X w.r.t. to Y\"\r\n\r\nIMO, the LossScaleOptimizer and Horovod's use cases have shown that anything less than that results in a leaky abstraction. By which I mean, Keras and others have to be aware of implementation details of the optimizer:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py#L262\r\n\r\nRe gradient application, I think it's fine that we have lower-level methods like `Optimizer.apply_gradients` that hand back control to the main loop, and don't require subclassing the `Optimizer` to implement custom logic. But it should be possible for 99% of users to treat the optimizer like a black box\r\n\r\n> Can we add these four methods (or small variations thereof) to the keras callback class and allow users to use callbacks to drive fp16 loss scaling, distributed gradient aggregation, and friends, while pushing complexity out of optimizers so they can look as clean as the math in the research papers?\r\n\r\nIMO we need to stop special-casing Keras. It's a double-edged sword in that it:\r\n\r\n(1) Results in a more complex Keras codebase\r\n(2) Leaves out users of custom training loops\r\n\r\nInstead, I think we should build composable and self-contained abstractions that can be leveraged as easily in Keras as in CTLs. I think we can achieve this via exposing an `Optimizer.minimize` API that can handle the use cases described here.\r\n\r\nThe math of our core Optimizers would still be readable. The whole proposal would look like this:\r\n\r\n```python\r\nclass Optimizer:\r\n  def _apply_gradients(self, grads_and_vars):\r\n    # The math goes here.\r\n  \r\n  def minimize(self, loss, variables, tape=None):\r\n    if is_tensor(loss) and not tape:\r\n      raise ValueError('Must provide tape with tensor loss.')\r\n    tape = tape or GradientTape()\r\n    with tape:\r\n      if callable(loss):\r\n        loss = loss()\r\n      loss = self._transform_loss(loss) # A no-op in our built-in optimizers\r\n    gradients = tape.gradients()\r\n    gradients = self._transform_unaggregated_gradients(gradients)  # No-op\r\n    gradients = self._aggregate_gradients(gradients)\r\n    gradients = self._transform_aggregated_gradients(gradients)  # No-op\r\n    self._apply_gradients(zip(gradients, variables))\r\n\r\n  def apply_gradients(self, grads_and_vars, aggregated=False):\r\n    if not aggregated:\r\n      gradients, variables = unzip(grads_and_vars)\r\n      gradients = self._aggregate_gradients(gradients)\r\n      gradients = self._transform_aggregated_gradients(gradients)  # No-op\r\n      grads_and_vars = zip(gradients, variables)\r\n    # By passing aggregated=True, users have complete control.\r\n    self._apply_gradients(grads_and_vars)\r\n```\r\n\r\nHere would be Keras's train_step. It would be capable of supporting any possible customizations of the optimizer:\r\n\r\n```python\r\ndef train_step(data):\r\n  x, y, sw = unpack(data)\r\n  with tf.GradientTape() as tape:\r\n    y_pred = model(x, training=True)\r\n    loss = model.compiled_loss(y, y_pred, sw)\r\n    loss += tf.add_n(model.losses)\r\n  model.optimizer.minimize(loss, model.trainable_variables, tape=tape)\r\n```", "My biggest objection so far is that it makes scaling the loss and unscaling gradients asymmetric, as a user has to explicitly scale the loss, but not unscale the gradients. For example, `LossScaleOptimizer` would be implemented as follows\r\n\r\n```python\r\nclass LossScaleOptimizer(Optimizer):\r\n  def __init__(self, optimizer):\r\n    self._optimizer = optimizer\r\n    self._loss_scale = ...\r\n  \r\n  def get_scaled_loss(loss):\r\n    return loss * self._loss_scale()\r\n\r\n  def get_unscaled_gradients(gradients):\r\n    return gradients / self._loss_scale()\r\n\r\n  def _transform_loss(self, loss):\r\n    loss = super()._transform_loss(loss)\r\n    loss = self.get_scaled_loss(loss)\r\n    return self._optimizer._transform_loss()\r\n\r\n  def _aggregate_gradients(self, gradients):\r\n    gradients = tf.cast(gradients, \"float16\")  # All-reduce in fp16 for performance\r\n    gradients = super()._aggregate_gradients(gradients)\r\n    return tf.cast(gradients, \"float32\")\r\n\r\n  def _transform_aggregated_gradients(self, gradients)\r\n    gradients = super()._transform_aggregated_gradients(gradients)\r\n    gradients = self.get_unscaled_gradients(gradients)\r\n    return self._optimizer._transform_aggregated_gradients(gradients)\r\n\r\n  ... # Delegate all other methods to self._optimizer\r\n```\r\n\r\nIn fit(), everything works as expected. But in a custom training loop, if the user calls `apply_gradients` instead of `minimize`, they must call `get_scaled_loss` (or `_transform_loss`) but not `get_unscaled_gradients`:\r\n\r\n```python\r\nwith tf.GradientTape() as tape:\r\n    loss = loss_fn(features, labels)\r\n    scaled_loss = optimizer.get_scaled_loss(loss)\r\nscaled_grads = tape.gradient(loss, model.trainable_variables)\r\n# apply_gradients will unscale gradients, but not scale loss\r\noptimizer.apply_gradients(list(zip(fp32_scaled_grads, \r\n                                   model.trainable_variables)))\r\n```\r\n\r\nAlternatively, the user could have called `_transform_loss` instead of `get_scaled_loss`. This removes the obvious asymmetry between scaling loss and unscaling gradients, but it makes it less clear what's going on.\r\n\r\nI think this problem is not specific to loss scaling. In general, its somewhat unclear exactly what callback methods `apply_gradients` is calling. \r\n\r\nAnother potential issue is this approach has no way of implementing a loop for loss scaling, where the gradients are computed with loss scaling, and if the gradients have NaNs, lower the loss scale and try computing gradients again until you have no NaNs. This is what the [`LossScaleGradientTape`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/experimental/loss_scaling_gradient_tape_test.py) does, but it currently cannot be used with Keras.fit(). IMO, this isn't a big deal, as I think the benefits from the loop are negligible, but others may disagree. I like the `LossScaleGradientTape` not because of the loop, but because it presents a very nice API.\r\n\r\n> I don't really see how we can modify the OptimizerV2 class go avoid having to rewrite a lot of boilerplate code each time we want to implement a \"wrapping optimizer\"\r\n\r\nWe could still implement a \"wrapping optimizer\" but keep Tom's proposal. The \"wrapping optimizer\" would simply delegate to an inner optimizer (and implement the subclassing trick if we can reach consensus on whether that should be done). A user could subclass the wrapping optimizer to implement the callback methods like `_transform_loss`.", "I'm thinking more of \"what code has to change when users switch optimizers\". And for today's definition of sgd-style optimizers we often use in deep learning, what needs to change is how the gradients are applied. This is the difference between SGD and Adam, etc.\r\n\r\nWhether gradients are reduced or not is a policy decision which belongs at a layer other than the optimizer. For example, in some distributed systems it makes sense to do many local steps before reducing the gradients (if RPCs are slow/expensive); in other cases it makes sense to never reduce gradients at all and instead just occasionally average the weights of different replicas (like in federated learning).\r\n\r\nThese concerns (of what distributed training setup precisely we want to implement) are completely orthogonal to the concerns of how to actually perform the parameter update (if there's momentum, if there's some adaptation, maybe a second-order method like in kfac, etc). Because they're orthogonal they belong in a separate layer where they can be changed without risking a change to the other concerns.\r\n\r\nPushing extra complexity in the optimizer is unfortunate because it makes it harder to implement new optimizers or modify existing ones (and we're still regularly getting papers which make important changes to how optimizers do their gradient updates).\r\n\r\nSo while I agree that pushing this complexity into the optimizer class it self makes the training loop super simple, I think this complexity really belongs in the training loop, as it's unrelated to how exactly the weights are being modified given the gradients. Pushing this complexity into the optimizers also means users have to write optimizers when they want to do things which don't feel like changes to the optimizer, like normalizing gradients.\r\n\r\nSo I think we'd be better off if we had separate things in the code for separate concerns. The optimizer class would deal with apply_gradients, and other classes would deal with loss scaling, gradient reduction, etc. This way a full solution can be composed out of many small individually simple pieces as opposed to looking simple in the surface but relying on complicated hard-to-integrate pieces, which have to be modified by inheritance, and which have many orthogonal unrelated methods.", "> apply_gradients will unscale gradients, but not scale loss\r\n\r\n@reedwm If you look at the `Optimizer.apply_gradients` method I proposed above, it does not modify the user-supplied gradients. The `Optimizer.apply_gradients` method I am proposing is status quo.\r\n\r\n> Because they're orthogonal they belong in a separate layer where they can be changed without risking a change to the other concerns.\r\n> So I think we'd be better off if we had separate things in the code for separate concerns. \r\n\r\n@alextp What would this separate layer look like? It seems like we'd need an object that wraps the Optimizer, does some preprocessing, and then passes the gradients to the Optimizer. But this object would need to have the same API as `Optimizer.minimize` and/or `Optimizer.apply_gradients`, so why not just have it be an optimizer? \r\n\r\nAnd if we don't wrap the `Optimizer`, then how do we support `Optimizer.minimize`?\r\n\r\nImplementing `DistributedOptimizer`, `LossScalingOptimizer`, etc via composition seems like a good way to separate the parameter updates from the other logic\r\n", "I'm not saying a single layer, just trying to orthogonalize things a bit\nmore.\n\nFor example, stuff related to gradient computation can be done in the\ngradient tape; this includes the LossScalingGradientTape and Reed's\nproposal of an AllReduceGradientTape (which might be necessary for loss\nscaling).\n\nI can't tell if gradient reduction is better handled inside the gradient\ntape or outside in the body of the training loop (since it's just a call to\nreduce).\n\nOn Mon, Feb 3, 2020 at 1:32 PM omalleyt12 <notifications@github.com> wrote:\n\n> apply_gradients will unscale gradients, but not scale loss\n>\n> @reedwm <https://github.com/reedwm> If you look at the\n> Optimizer.apply_gradients method I proposed above, it does not modify the\n> user-supplied gradients. The Optimizer.apply_gradients method I am\n> proposing is status quo.\n>\n> Because they're orthogonal they belong in a separate layer where they can\n> be changed without risking a change to the other concerns.\n> So I think we'd be better off if we had separate things in the code for\n> separate concerns.\n>\n> @alextp <https://github.com/alextp> What would this separate layer look\n> like? It seems like we'd need an object that wraps the Optimizer, does some\n> preprocessing, and then passes the gradients to the Optimizer. But this\n> object would need to have the same API as Optimizer.minimize and/or\n> Optimizer.apply_gradients, so why not just have it be an optimizer?\n>\n> And if we don't wrap the Optimizer, then how do we support\n> Optimizer.minimize?\n>\n> Implementing DistributedOptimizer, LossScalingOptimizer, etc via\n> composition seems like a good way to separate the parameter updates from\n> the other logic\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/36398?email_source=notifications&email_token=AAABHROLUS34NFXZK2NKOLTRBCEPJA5CNFSM4KOQZZF2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKVPFHA#issuecomment-581628572>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRIFPQNMNNEQ4CKPVDTRBCEPJANCNFSM4KOQZZFQ>\n> .\n>\n\n\n-- \n - Alex\n", "CC: @cliffwoolley\r\n\r\n@reedwm @alextp I have rapidly prototyped the original idea we proposed in the issue just to _\"show\"_ how this could look like:\r\n\r\n**Git Diff:** https://github.com/tensorflow/tensorflow/compare/master...DEKHTIARJonathan:loss_scale_opt_interface\r\n\r\n**The advantages of this idea:**\r\n- The original API is not changed, Keras doesn't need to know about it\r\n- The new Loss Scale / HVD API is fully backward compatible\r\n- No more hacky _metaclass_ or _`type()`_ call to dynamically subclass => simpler design\r\n- The researcher/developer doesn't have to care about when & how to call the different hooks. The \r\n`WrappingInterfaceOptimizer` is in charge of the heavy logical lift.\r\n- If Keras needs to call specific behavior like it does currently with the loss scale: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py#L261-L262\r\nThis can be replaced by a simple `issubclass(opt, WrappingInterfaceOptimizer)` and a call to the correct hook.\r\n- This prevent from having to \"reinvent\" the wheel and having to re-code how to interface with Keras. Avoid code duplication, less error prone and maintenance intensive\r\n\r\n**Current corner case (edit: now fixed) :**\r\n- Does not work with chained wrapped Opt like Adam => Horovod => LossScaling. I don't think it will be hard to solve, I can work on this if we agree that's the direction we want to take. I just don't want to spend hours fixing smthg we may not want to adopt down the line.\r\n\r\n**All the unnittests are passing without having to change a single line:**\r\n\r\n```python\r\nroot@workstation:/opt/tensorflow/tensorflow/python/keras/mixed_precision/experimental# TF_CPP_MIN_LOG_LEVEL=3 python3 -m loss_scale_optimizer_test\r\n[ RUN      ] LossScaleOptimizerTest.testApplyGradientsGetsUnwrappedTensors\r\n[       OK ] LossScaleOptimizerTest.testApplyGradientsGetsUnwrappedTensors\r\n[ RUN      ] LossScaleOptimizerTest.testArbitraryAttributesNotExposed\r\n[       OK ] LossScaleOptimizerTest.testArbitraryAttributesNotExposed\r\n[ RUN      ] LossScaleOptimizerTest.testCheckpointBase\r\n[       OK ] LossScaleOptimizerTest.testCheckpointBase\r\n[ RUN      ] LossScaleOptimizerTest.testCheckpointDistribute\r\n[       OK ] LossScaleOptimizerTest.testCheckpointDistribute\r\n[ RUN      ] LossScaleOptimizerTest.testDynamicLossScaleBase\r\n[       OK ] LossScaleOptimizerTest.testDynamicLossScaleBase\r\n[ RUN      ] LossScaleOptimizerTest.testDynamicLossScaleDistribute\r\n[       OK ] LossScaleOptimizerTest.testDynamicLossScaleDistribute\r\n[ RUN      ] LossScaleOptimizerTest.testDynamicLossScaleWithFloat16LossBase\r\n[       OK ] LossScaleOptimizerTest.testDynamicLossScaleWithFloat16LossBase\r\n[ RUN      ] LossScaleOptimizerTest.testDynamicLossScaleWithFloat16LossDistribute\r\n[       OK ] LossScaleOptimizerTest.testDynamicLossScaleWithFloat16LossDistribute\r\n[ RUN      ] LossScaleOptimizerTest.testDynamicLossScaleWithSlotsBase\r\n[       OK ] LossScaleOptimizerTest.testDynamicLossScaleWithSlotsBase\r\n[ RUN      ] LossScaleOptimizerTest.testDynamicLossScaleWithSlotsDistribute\r\n[       OK ] LossScaleOptimizerTest.testDynamicLossScaleWithSlotsDistribute\r\n[ RUN      ] LossScaleOptimizerTest.testDynamicUpdateBase\r\n[       OK ] LossScaleOptimizerTest.testDynamicUpdateBase\r\n[ RUN      ] LossScaleOptimizerTest.testDynamicUpdateDistribute\r\n[       OK ] LossScaleOptimizerTest.testDynamicUpdateDistribute\r\n[ RUN      ] LossScaleOptimizerTest.testFixedLossScaleAppliedToLossWithGetGradients\r\n[       OK ] LossScaleOptimizerTest.testFixedLossScaleAppliedToLossWithGetGradients\r\n[ RUN      ] LossScaleOptimizerTest.testFixedLossScaleAppliedToLossWithMinimizeBase\r\n[       OK ] LossScaleOptimizerTest.testFixedLossScaleAppliedToLossWithMinimizeBase\r\n[ RUN      ] LossScaleOptimizerTest.testFixedLossScaleAppliedToLossWithMinimizeDistribute\r\n[       OK ] LossScaleOptimizerTest.testFixedLossScaleAppliedToLossWithMinimizeDistribute\r\n[ RUN      ] LossScaleOptimizerTest.testGetConfig\r\n[       OK ] LossScaleOptimizerTest.testGetConfig\r\n[ RUN      ] LossScaleOptimizerTest.testGetScaledLoss\r\n[       OK ] LossScaleOptimizerTest.testGetScaledLoss\r\n[ RUN      ] LossScaleOptimizerTest.testGetUnscaledGradients\r\n[       OK ] LossScaleOptimizerTest.testGetUnscaledGradients\r\n[ RUN      ] LossScaleOptimizerTest.testGettingAndSettingLearningRateBase\r\n[       OK ] LossScaleOptimizerTest.testGettingAndSettingLearningRateBase\r\n[ RUN      ] LossScaleOptimizerTest.testGettingAndSettingLearningRateDistribute\r\n[       OK ] LossScaleOptimizerTest.testGettingAndSettingLearningRateDistribute\r\n[ RUN      ] LossScaleOptimizerTest.testIterations\r\n[       OK ] LossScaleOptimizerTest.testIterations\r\n[ RUN      ] LossScaleOptimizerTest.testPassingNoneToLossScale\r\n[       OK ] LossScaleOptimizerTest.testPassingNoneToLossScale\r\n[ RUN      ] LossScaleOptimizerTest.testSerializationWithBuiltInOptimizer\r\n[       OK ] LossScaleOptimizerTest.testSerializationWithBuiltInOptimizer\r\n[ RUN      ] LossScaleOptimizerTest.testSerializationWithCustomOptimizer\r\n[       OK ] LossScaleOptimizerTest.testSerializationWithCustomOptimizer\r\n[ RUN      ] LossScaleOptimizerTest.testSlotMethodErrors\r\n[       OK ] LossScaleOptimizerTest.testSlotMethodErrors\r\n[ RUN      ] LossScaleOptimizerTest.testWeightMethods\r\n[       OK ] LossScaleOptimizerTest.testWeightMethods\r\n[ RUN      ] LossScaleOptimizerTest.test_session\r\n[  SKIPPED ] LossScaleOptimizerTest.test_session\r\n----------------------------------------------------------------------\r\nRan 27 tests in 6.767s\r\n\r\nOK (skipped=1)\r\n``` ", "/cc @pkanwar23 ", "@nluehr @reedwm @tgaddair @abditag2 : I added support for nested optimizers:\r\n```python\r\n# Pseudo-code to illustrate\r\nopt = SGD(...)\r\nopt = HVDDistributedOpt(opt, ...)\r\nopt = LossScaleOpt(opt, ...)\r\n```\r\n\r\nNow, doing so will apply in a chain all the hooks in the right order (see below):\r\n\r\nWe also introduce a concept of **\"optimizer priority\"**, this is mainly due to enforce that some hooks kick in first or last no matter the order or wrapping (ensuring the user does not screw up).\r\n\r\n```python\r\n# Configuration A\r\nopt = SGD(...)\r\nopt = HVDDistributedOpt(opt, ...)\r\nopt = LossScaleOpt(opt, ...)\r\n\r\n# Configuration B\r\nopt = SGD(...)\r\nopt = LossScaleOpt(opt, ...)\r\nopt = HVDDistributedOpt(opt, ...)\r\n```\r\n\r\nWith the concept of priority introduced in this PR, now the two configurations (A and B) are strictly equivalent in terms of results. This is mainly done to protect the user from doing something he might not fully understand the consequences.\r\n\r\nThe order of priority can always be overwritten at runtime by changing the value of the class variable directly or by subclassing for testing/research objective. We consider that the slightly increased complexity to control the order is acceptable given the increase security for >95-99% users.  \r\n\r\n**Example:** In this specific case, we want Horovod to kick in first (no matter what) and LossScale last to avoid overflowing gradients.\r\n\r\nAn extensive comment about this mechanism is left in the code: https://github.com/DEKHTIARJonathan/tensorflow/commit/24728ac7385b203c791d92421d26440edcd7a59f#diff-e39ecbeabd8e8a3fc5e5063e3d9290b0R56-R71\r\n\r\n-------------\r\n**The complete git diff:** https://github.com/tensorflow/tensorflow/compare/master...DEKHTIARJonathan:loss_scale_opt_interface\r\n\r\nSimilarly, all the unittests are passing without having to change anything", "I have modified `training_eager.py` to integrate the changes:\r\n\r\n**The complete git diff:** https://github.com/tensorflow/tensorflow/compare/master...DEKHTIARJonathan:loss_scale_opt_interface\r\n\r\nAll the unittests are passing again without any change:\r\n```python\r\n....\r\n[ RUN      ] TrainingTest.test_model_fit_and_validation_with_missing_arg_errors_functional\r\n[       OK ] TrainingTest.test_model_fit_and_validation_with_missing_arg_errors_functional\r\n[ RUN      ] TrainingTest.test_model_fit_and_validation_with_missing_arg_errors_sequential\r\n[       OK ] TrainingTest.test_model_fit_and_validation_with_missing_arg_errors_sequential\r\n[ RUN      ] TrainingTest.test_model_fit_and_validation_with_missing_arg_errors_subclass\r\n[       OK ] TrainingTest.test_model_fit_and_validation_with_missing_arg_errors_subclass\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_multi_io_v2_eager_functional\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_multi_io_v2_eager_functional\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_multi_io_v2_eager_subclass\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_multi_io_v2_eager_subclass\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_multi_io_v2_function_functional\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_multi_io_v2_function_functional\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_multi_io_v2_function_subclass\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_multi_io_v2_function_subclass\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_eager_functional\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_eager_functional\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_eager_sequential\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_eager_sequential\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_eager_subclass\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_eager_subclass\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_function_functional\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_function_functional\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_function_sequential\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_function_sequential\r\n[ RUN      ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_function_subclass\r\n[       OK ] TrainingTest.test_model_methods_with_eager_tensors_single_io_v2_function_subclass\r\n[ RUN      ] TrainingTest.test_session\r\n[  SKIPPED ] TrainingTest.test_session\r\n----------------------------------------------------------------------\r\nRan 34 tests in 15.380s\r\n\r\nOK (skipped=2)\r\n```", "There was a internal discussion on this issue and we have decided we want some sort of hook mechanism, such as the one @tgaddair proposed and @omalleyt12 expanded on. However, we have not yet decided on a concrete proposal. We could go with the proposal detailed by @omalleyt12 in this issue. Alternatively, to avoid deeply nesting optimizers, the base Optimizer could take a \"Callbacks\" object or a list of \"Callbacks\" objects, and optimizes would execute their callbacks in order. A third approach would be to have the callbacks on a Keras Model instead of the Optimizer.\r\n\r\nUnfortunately, it's unlikely to have this implemented and submitted in TensorFlow by 2.2. This will probably require a design review.\r\n\r\n@tgaddair, would it be possible to override `Optimizer.apply_gradients` instead of `Optimizer.get_gradients`? You could perform the all reduce in `apply_gradients`, then call `super().apply_gradients`. If this would not work, subclassing `LossScaleOptimizer` would work for 2.2. By 2.3, we would (hopefully) have a solution implemented so you could switch to that. Subclassing `LossScaleOptimizer` is very hacky, but I think doing so for a single release is acceptable if there is no alternative. Let me know your thoughts.", "My thoughts on the proposal so far:\r\n\r\n@DEKHTIARJonathan, thanks for prototyping this. I think this approach is reasonable, except that I'm a bit worried about the \"priority\" field. If optimizers are nested, it seems unintuitive that the order of nesting would sometimes be ignored in favor of priorities. If the Horovod optimizer overrode `_aggregate_gradients` (as @omalleyt12 proposed), and the LossScaleOptimizer overrode `_transform_aggregated_gradients`, the correct order would occur no matter how the Horovod optimizer and LossScaleOptimizer were ordered.\r\n\r\nAs for using a `WrappingInterfaceOptimizer` in general: one issue is that this will make all-reducing in fp16 difficult if tf.distribute.Strategy is used. As I mentioned in [this comment](https://github.com/tensorflow/tensorflow/issues/36398#issuecomment-581604155), if we all-reduce in fp16, we must all-reduce the scaled gradients instead of the unscaled gradients. If we do this by overriding `_transform_aggregated_gradients` to unscale gradients, then the user will have to explicitly scale the loss, but not unscale the gradients. This asymmetry makes it too easy for the user to forget to scale the loss, or accidentally unscale the gradients twice.\r\n\r\nI'm not sure how to solve this asymmetry problem, but I will give this more thought.", "Hey @reedwm, glad this feature is generating a lot of good discussion.  \r\n\r\nFor our case with Horovod, we cannot implement the aggregation in `apply_gradients` because of Keras' current use of the `LossScaleOptimizer` in [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py#L274) code path, which will have `get_unscaled_gradients` called before `apply_gradients`.\r\n\r\nWe can workaround it by subclassing `LossScaleOptimizer`, which we already have a PR for just in case (https://github.com/horovod/horovod/pull/1692).  But unfortunately this will be something we'll need to keep in the code for a long time if we go this route.  The reason being, Horovod supports many versions of TensorFlow, and so for as long as we support TensorFlow 2.2, that subclassing trick will need to be there in some form.\r\n\r\nMy personal preference is for @omalleyt12's proposal, which gives TensorFlow extensions like ours the most flexibility and control over the training loop.  It's definitely understandable that a change like this would require a design and review process.\r\n\r\nI'm wondering if there's anything that can be done in the interim to prevent us from having to go down this subclassing `LossScaleOptimizer` route?  \r\n\r\nPrior to TensorFlow 2.2, Keras supported `experimental_run_tf_function=False`, which allowed us to circumvent this code path and use the Optimizer's `get_gradients` method instead.  Would it be possible to restore this functionality until a solution to this issue is implemented?", "> For our case with Horovod, we cannot implement the aggregation in `apply_gradients` because of Keras' current use of the `LossScaleOptimizer` in [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py#L274) code path, which will have `get_unscaled_gradients` called before `apply_gradients`.\r\n\r\nIs the issue with all-reducing in apply_gradients is that you all-reduce in fp16 and therefore must all-reduce the scaled gradients when a `LossScaleOptimizer` is used?\r\n\r\n> Prior to TensorFlow 2.2, Keras supported `experimental_run_tf_function=False`, which allowed us to circumvent this code path and use the Optimizer's `get_gradients` method instead. Would it be possible to restore this functionality until a solution to this issue is implemented?\r\n\r\n@omalleyt12 do you know the answer to this?\r\n\r\nIf the answer is \"no\", perhaps we could implement, but not publicly document, the `_aggregate_gradients` function for 2.2. This could be considered an internal refactor without any API changes, but would allow Horovod, or any other user, to subclass it to do arbitrary gradient processing. If we later choose to go a different route, say a callback mechanism in Model, we could delete the function, or keep it since its probably good to have that function for readability purposes anyway. If we do delete it, Horovod would have to use whatever mechanism we replace it with, but I think having to keep the `_aggregate_gradients`  override in Horovod for 2.2 support is a lot easier than having to keep the very hacky `LossScaleOptimizer` subclass.\r\n\r\n@omalleyt12 @alextp @tgaddair WDYT?\r\n", "Hey @reedwm, to answer your question: yes, part of the issue is that we want to perform the allreduce on the scaled gradients in fp16 for performance. @DEKHTIARJonathan or @romerojosh might have additional context on this.\r\n\r\nI think having a single method like `_aggregate_gradients` in the Optimizer API would be a great workaround for now.  I agree that it's not that big of a deal having to support a deprecated method as opposed to a deprecated class hierarchy.  To make sure we're on the same page, are you thinking of modifying `training_eager.py` to do something like this:\r\n\r\n```\r\ngrads = tape.gradient(scaled_total_loss, trainable_weights)\r\nif hasattr(optimizer, '_aggregate_gradients'):\r\n    grads = optimizer._aggregate_gradients(grads)\r\nif isinstance(model.optimizer, loss_scale_optimizer.LossScaleOptimizer):\r\n    grads = model.optimizer.get_unscaled_gradients(grads)\r\nmodel.optimizer.apply_gradients(zip(grads, trainable_weights))\r\n```\r\n\r\nAlternatively, if you were to refactor [training_eager.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py#L274) to use the Optimizer's existing [minimize](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L289-L318) method, then we could simply override `_compute_gradients` similar to how [LossScaleOptimizer](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/mixed_precision/experimental/loss_scale_optimizer.py#L205) does it.  \r\n\r\nEither way would work for us.  Thanks for helping to find a workaround for TF 2.2.", "@reedwm we had quite a looong chat about this priority field internally. If this is a blocker, we can remove it and rely on the user to define optimizers in the correct order. The assumption was that >90% Keras/TF will not have a fine understanding of the consequences of applying order A or order B (and which one to go for). Therefore, we make sure it's done in the correct order by default. Order that you can always overwrite by changing the priorities. Again >90% (realistically even more) users have no reason to even want to do such a thing. \r\n\r\nWith regards to collective allreduce in FP16. I don't see why this would be a problem\r\n\r\nThis approach does not block in any way doing so:\r\n1. `before_compute_gradients_hook(self, loss)` => Loss Scaling\r\n2. Compute Gradients => Base Optimizer/Gradient Tape task\r\n3. `after_compute_gradients_hook(self, grads_and_vars)` => Collective Allreduce (in FP16 or FP32)\r\n4. `before_apply_gradients_hook(self, grads_and_vars)` => UnScale Gradients (output FP32)\r\n5. `cond_apply_step_hook(self, grads_and_vars)` => Allow to skip a step, essential mechanism for LossScaling. Others should not care.\r\n6. Apply Gradients => Base Optimizer task", "@tgaddair I was thinking more of calling `_aggregate_gradients` after `get_unscaled_gradients`, becuase I wanted to factor out [these two lines](https://github.com/tensorflow/tensorflow/blob/64e28cd65f261ecee4a13402faeab6613413d6ed/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L448-L449) into its own `aggregate_gradients` method, which `apply_gradients` would call. Then Keras would not have to explicitly call `_aggregate_gradients`. But I just realized this won't work if you want to all-reduce in fp16, since then you must aggregate gradients before unscaling them.\r\n\r\nI liked factoring out the two lines since we didn't have to do anything special to support Horovod. That change makes sense even without taking into account Horovod, since it (arguably) improved readability of the OptimizerV2 class.\r\n\r\nHow important is supporting `LossScaleOptimizer` with `DistributedOptimizer` with fp16 all-reduce with `Model.fit()`. Does anyone currently do this? Currently, its impossible to all-reduce in fp16 with `tf.distribute.Strategy` even with a custom training loop, so Horovod is already an improvement in that regard. We will introduce the ability to all-reduce in fp16 in a custom training loop in 2.2 for Strategy, but still not `fit()` until 2.3.\r\n\r\nI will keep trying to think of a way to support Horovod with fp16 gradients in fit() for 2.2 without API changes or major implementation changes. Ideally, we wouldn't have to change the core training step  in [training_eager.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py) but I am not personally opposed to doing so if there is no other alternative.", "I just talked to @omalleyt12 and @fchollet. We agreed the best way to solve this for 2.2 is to introduce a `_transform_unaggregated_gradients` method on Optimizer (but maybe with a different name). By default, this would do nothing, and the only place it would be called is right above [this line](https://github.com/tensorflow/tensorflow/blob/5f8ec2e18ba77b6c077048389fd7735d8212ad0e/tensorflow/python/keras/engine/training_eager.py#L274). Overriding this would allow the scaled gradients to be processed. This method would be private and undocumented, so it would not be subject to TensorFlow's backwards compatibility guarantee.\r\n\r\nFor 2.3, we plan on designing and implementing the full API, and potentially removing the `_transform_unaggregated_gradients`. I think this will make it relatively easy for Horovod to support 2.1, 2.2, and 2.3+ for a long time. The `_transform_unaggregated_gradients` override could be kept indefinitely in Horovod. If Optimizer removes that method in 2.3, the Horovod override would simply be ignored. For 2.3, Horovod could use the new API, potentially requiring a check of `tf.__version__`.\r\n\r\nIf I'm understanding correctly, this issue only affects users who call `Model.fit`, not those who use a custom training loop. This means users would never have to directly call `_transform_unaggregated_gradients`, and so it would only be called by `Model.fit`.\r\n\r\nLet me know your thoughts.", "Hey @reedwm, that sounds great.  We can definitely implement the `_transform_unaggregated_gradients` method for now and add support for the new API when it becomes available.\r\n\r\nYes, this issue only affects `Model.fit`.  We've implemented a [DistributedGradientTape](https://github.com/horovod/horovod/blob/master/examples/tensorflow2_mnist.py#L64) for users with custom training loops, which is not affected by this issue.  However, with the new API @omalleyt12 proposed, we could deprecate the `DistributedGradientTape` and consolidate both code paths for Horovod around `optimizer.minimize(...)`.\r\n\r\nOne other question: I noticed that there is some additional gradient clipping logic [here](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L357) in `Optimizer.minimize` that doesn't exist in `training_eager.py`.  Am I correct, or is it being executed somewhere else?  I suspect we may want to implement this logic in `_transform_unaggregated_gradients` if it's not being called in the eager code path.", "Great, I'll implement `_transform_unaggregated_gradients` for now.\r\n\r\n> One other question: I noticed that there is some additional gradient clipping logic here in Optimizer.minimize that doesn't exist in training_eager.py. Am I correct, or is it being executed somewhere else?\r\n\r\nIIRC `Model.fit` (incorrectly) never did this gradient clipping. I could be wrong though, @omalleyt12 can you confirm?", "My understanding is that in TF 1.X, `Model.fit` calls the `Optimizer.get_gradients` method which implements gradient clipping [here](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L398).  In TF 2.X, prior to 2.2, you could force `get_gradients` to be called by setting `experimental_use_tf_function=False`.  But I believe you're right that it was never implemented for eager mode.", "@tgaddair @reedwm Good point, yeah @tomerk is actually working on a fix for this for 2.2\r\n\r\nSince gradient clipping should really be done on the aggregated gradients, we were planning on special-casing this separately in `training_eager.py` for now. Tomer can provide more info", "@tgaddair @reedwm maybe I didn't understood correctly. Please allow me to make double sure here. \n\n```\nWe agreed the best way to solve this for 2.2 is to introduce a _transform_unaggregated_gradients \n[...] \n\nFor 2.3, we plan on designing and implementing the full API, and potentially removing the _transform_unaggregated_gradients\n```\n\nSo that means adding smthg specific for TF2.2 and (potentially?) removing it after? If that's the case then I'm sorry this hardly looks like an acceptable solution to me.\n\nHorovod commits to support multiple versions of TF and for a long time. Doing so would enforce Horovod to have a version specific code and to maintain it over time (with potentially means also adding any new features down the line, otherwise that would block any user from using TF2.2 and HVD together).\n\nIt is acceptable to expose an API that internally changed on the long run since HVD doesn't need to know how a given API is implemented. However, it seems a bad strategy to me to accept a \"hot fix\" that enforces a specific hotfix on the long run for HVD.       ", "@DEKHTIARJonathan \r\n\r\nIIUC (@reedwm correct me if I'm wrong), the (tentative) plan is to add this `Optimizer._transform_unaggregated_gradients` hook into the Keras eager training step.\r\n\r\nThen, long-term we implement something more general, along the lines of the Optimizer hooks I proposed above (we had a discussion yesterday where we agreed on the overall premise, but how to factor out certain pieces isn't yet settled). One of those hooks would be called `Optimizer._transform_unaggregated_gradients`, and that would be called as part of `Optimizer.minimize`. As part of that change, we'll switch Keras to use `Optimizer.minimize`. So the hook would be preserved. I think Reed was saying this might be removed bc we haven't reached full consensus on this part\r\n\r\nSomewhat unrelated, but coming for 2.3 latest is a much more modular `Model.fit` that adds the ability to easily override Keras's built-in training step (there will be a `Model.train_step` method that gets called by `Model.fit`, among other pieces). Once that's in, there will be a much more \"hackable\" endpoint that Horovod can override to expose any hooks it might need. I understand that doesn't help with Horovod's needs to maintain backwards compatibility, but that should help alleviate some of these pain points in the future, so just wanted to make people aware of it here. \r\n\r\nIn summary, I think the hope is we add this `Optimizer._transform_unaggregated_gradients` hook now, call it explicitly in the Keras step for the time being, and then move it into being an implementation detail of `Optimizer.minimize`", "I agree with the long term strategy, I'm only concerned about the short objective.\n\nEarlier today in the Google-Nvidia TF meeting we mentioned the possibility to revert the commit that broke HVD. That would allow us to get more time and implement properly smthg without the rush. Which eventually avoids the need to keep supporting a potentially temporary hook in HVD.\n\nThe only reason we need to rush all of this, is because Horovod is broken and next release is coming. If we allow ourself to revert the old behavior for one more release, it should be sufficient to come up with a clean high level API that can be stable over time.     ", "@omalleyt12 can confirm, but I now think it's not feasible to revert c73c99ca3e0bacf2bca313f270bb3eae28869530, the change which introduced this behavior. Assuming we cannot revert it, then I don't think we have an alternative other than a short term fix. This is because we don't have time to go through design review and finalize an API in time for 2.2.\r\n\r\n@omalleyt12, I'm not sure we have a tentative plan yet, but certainly one option would be to keep the `_transform_unaggregated_gradients` method. I think we should be prepared to remove it however, if a different design is decided on. There is a decent change we will remove or rename the method.\r\n\r\n@DEKHTIARJonathan, I don't think you would need 2.2-specific code. Instead, you could move [this code in get_gradients](https://github.com/horovod/horovod/blob/84333aa9e0cee4243b0114273cfd8c8369f839b9/horovod/_keras/__init__.py#L43-L60) to the `_transform_unaggregated_gradients` method and call it from `get_gradients`. You'd also have to move the `self._get_gradients_used = True` line to that method, and likely rename the field. Then you would support TF 2.0 through TF 2.2, and potentially TF 2.3 if we do keep the method wouldn't renaming it.", "@omalleyt12 and I just discussed this, and we have a slightly difference proposal.\r\n\r\nInstead of an `_transform_unaggregated_gradients` method, we'll add an `_aggregate_gradients` method, with essentially the same semantics. [These two lines](https://github.com/tensorflow/tensorflow/blob/d1577971d7138b24856d786b05feb4d3d578fc33/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L448-L449) in Optimizer, which aggregate the gradients, will be moved to `_aggregate_gradients` and `apply_gradients` will call `_aggregate_gradients`. Horovod's optimizer can override `_aggregate_gradients` to do the all-reduce.\r\n\r\nTo support having a LossScaleOptimizer wrap a Horovod optimizer and have the gradients all-reduced in fp16, we need to make sure the gradients are unscaled after being all-reduced. To do this, we will introduce an `experimental_aggregate_gradients` parameter to `Optimizer.apply_gradients`, which defaults to True. If False, `_aggregate_gradients` will not be called. In Model.fit(), the model will explicitly call `opt._aggregate_gradients`, then call `opt.get_unscaled_gradients`, then call `opt.apply_gradients` and pass `experimental_aggregate_gradients=False`. This way, gradients are unscaled after the all-reduce, allowing the all-reduce to occur in fp16. \r\n\r\nMore specifically, [these four lines](https://github.com/tensorflow/tensorflow/blob/6ba8be4268d602f317ed74a393f72a03f619fa85/tensorflow/python/keras/engine/training_eager.py#L273-L277), which compute and apply gradients as part of Model.fit(), will be replaced with:\r\n\r\n```python\r\ngrads = tape.gradient(scaled_total_loss, trainable_weights)\r\ngrads = model.optimizer._aggregate_gradients(grads)\r\nif isinstance(model.optimizer,\r\n              loss_scale_optimizer.LossScaleOptimizer):\r\n  grads = model.optimizer.get_unscaled_gradients(grads)\r\nmodel.optimizer.apply_gradients(zip(grads, trainable_weights), \r\n                                experimental_aggregate_gradients=False)\r\n```\r\n\r\nThis also allows gradients to be all-reduced in fp16 with `tf.distribute.Strategy` as well. I will probably add an `allreduce_in_fp16=True` argument to the LossScaleOptimizer constructor to make this behavior customizable.\r\n\r\nI think there are two main advantages to this over the previous `_transform_unaggregated_gradients` short-term proposal for 2.2:\r\n1. It is unlikely we'll remove the `_aggregate_gradients` method, as the method arguably make the Optimizer code cleaner, and so it doesn't just exist for the sake of Horovod. I cannot promise we will keep the method however.\r\n2. The name `_transform_unaggregated_gradients` was somewhat misleading, as it would transform *scaled* gradients, while users would likely expected the *unscaled* gradients to be transformed.\r\n\r\n@DEKHTIARJonathan, @tgaddair, WDYT? ", "I think that sounds reasonable @reedwm.  Regarding `experimental_aggregate_gradients`, I believe that regardless of whether you're using Horovod, `apply_gradients` will not call `_aggregate_gradients` unless both `experimental_aggregate_gradients` is `True` (default, I assume) and the user is using a distribution strategy.  Is that correct?\r\n\r\nIn other words, I want to clarify whether we'd need to require the user to set `experimental_aggregate_gradients=False` if they call `apply_gradients` themselves.", "Sounds fair and reasonable to me. So long it's good with @tgaddair, it's good with me.\r\n\r\nThanks a lot for your help everyone, much appreciated. Let me know if you need any help (tests, or smthg else)", "@tgaddair, Optimizer will call `_aggregate_gradients` if and only if `experimental_aggregate_gradients` is True (the default). If the user has no distribution strategy, then the default distribution strategy is used, which does nothing when you ask it to all-reduce.\r\n\r\nThis means if you override `_aggregate_gradients`, it will be called if the user explicitly calls `apply_gradients`. In 2.1, `apply_gradients` does not cause Horovod to aggregate gradients, since that is only done in `get_gradients`. \r\n\r\nDo you think this will be an issue? This will cause problems if a user explicitly calls `DistributedOptimizer.apply_gradients` in TF 2.0/2.1 then upgrades to 2.2. This is because `apply_gradients` previously did not all-reduce, so the user must have been all-reducing using some other mechanism. In 2.2, according the current plan, `DistributedOptimizer.apply_gradients` will all-reduce (unless the user changes their code to pass `experimental_aggregate_gradients=False`), so the gradients will be all-reduced twice.", "I think it should be okay.  Presently, if the user is calling `apply_gradients` themselves, they're using a `DistributedGradientTape` but a plain optimizer, not a `DistributedOptimizer`.  I was trying to imagine a scenario where they would call `apply_gradients` directly on the `DistributedOptimizer`, but I can't think of a such a case.  Worst case scenario, we can always ask them to set `experimental_aggregate_gradients=False`.\r\n\r\nThanks for clarifying, @reedwm.", "Hey @reedwm @omalleyt12 just following up on this.  Is the new API ready to try out yet?", "Almost, sorry about the delay. Should be ready in a few days.", "@tgaddair, this refactor has been done in de68525c48b356b1938af078c91cf3d2736076c9. Let me know if there are still issues supporting DistributedOptimizer with that commit.\r\n\r\nUnfortunately, the 2.2 branch is being cut Monday evening. We may or may not be able to cherrypick fixes after then. So if there are any issues, please let us know as soon as possible. ", "Thanks for the update, @reedwm.  I took a look at the commit, and it looks like everything should work fine.  The one additional step on our end, apart from what we previously discussed, will be to set `_HAS_ALL_REDUCE_SUM_GRAD = True` in the `DistributedOptimizer`, which is fine.\r\n\r\nWill these changes be available in tomorrow's `tf-nightly` builds?", "@tgaddair  I committed the changes earlier today, so it should be available in tonite's build. Let us know once you've been able to test it.", "Will do, @pkanwar23, thanks!  We'll be testing out first thing tomorrow.", "Hey @reedwm @omalleyt12 @pkanwar23.  I had a chance to test the latest `tf-nightly` build, and the new `_aggregate_gradients` hook seems to be working well so far.  So thanks for getting that in on time!\r\n\r\nIn the process of testing it, we did discover one other somewhat related issue, however.  Some of our Keras callbacks rely on accessing `self.params['steps']` in order to take actions based on how far along the process is into the current epoch (e.g., learning rate schedule).  However, it appears that this param is no longer being set properly, even when `mode.fit(steps_per_epoch=...)` is called.\r\n\r\nI did some digging, and it looks like the issue can be traced to the way `CallbackList(steps=...)` is being set [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py#L753).  The `DataAdapter` object is an instance of `DatasetAdapter`, which is initialized with the `steps_per_epoch` param and assigns it to `self._user_steps`, but the `get_size()` method always returns `None` [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/data_adapter.py#L704).\r\n\r\nIs there a workaround for this?  Ideally, we'd like for callbacks to have access to the `steps_per_epoch` information without having to pass it in to each callback manually.  \r\n\r\nLet me know if you feel this issue deserves a separate issue for tracking.  Thanks.", "@tgaddair Can you open a separate issue for the callbacks? Assign it to either reed or me. \r\n\r\nGiven that you've been able to test the issue, I'm going to mark this particular issue closed. Hope that works.", "> However, it appears that this param is no longer being set properly, even when mode.fit(steps_per_epoch=...) is called.\r\n\r\n@tgaddair @pkanwar23 \r\nCame across this issue myself last night, working on a fix now\r\n", "Thanks @omalleyt12 for looking into this, here's the new issue to track: #37237."]}, {"number": 36397, "title": "[tflite] enable INT8 for Java binding", "body": "some models created by full-integer post training quantization,\r\ne.g., the mobilenet v3 edgetpu one [1], have INT8 input and\r\noutput tensors.\r\n\r\nSee also https://github.com/tensorflow/models/issues/7887\r\n\r\n[1] https://storage.cloud.google.com/mobilenet_edgetpu/checkpoints/mobilenet_edgetpu_224_1.0.tgz", "comments": []}, {"number": 36396, "title": "Error while converting saved_model to tflite", "body": "**System information**\r\nWindows 10\r\nTensorflow installed via pip tf-nightly\r\ntensorflow 2.2\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n```\r\nConverterError: See console for info.\r\n2020-02-01 09:13:14.262240: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:108] Ignored output_format.\r\n2020-02-01 09:13:14.262433: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:111] Ignored drop_control_dependency.\r\n2020-02-01 09:13:14.751498: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nloc(fused[\"model/head_block2_bn1_8/FusedBatchNorm@__inference__wrapped_model_1223\", \"StatefulPartitionedCall/model/head_block2_bn1_8/FusedBatchNorm\"]): error: non-broadcastable operands\r\nWindows fatal exception: access violation\r\n\r\nCurrent thread 0x00003154 (most recent call first):\r\n  File \"c:\\users\\san10428\\.conda\\envs\\tfpreview\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 56 in execute\r\n  File \"c:\\users\\san10428\\.conda\\envs\\tfpreview\\lib\\site-packages\\absl\\app.py\", line 250 in _run_main\r\n  File \"c:\\users\\san10428\\.conda\\envs\\tfpreview\\lib\\site-packages\\absl\\app.py\", line 299 in run\r\n  File \"c:\\users\\san10428\\.conda\\envs\\tfpreview\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40 in run\r\n  File \"c:\\users\\san10428\\.conda\\envs\\tfpreview\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 93 in main\r\n  File \"C:\\Users\\san10428\\.conda\\envs\\tfpreview\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7 in <module>\r\n  File \"c:\\users\\san10428\\.conda\\envs\\tfpreview\\lib\\runpy.py\", line 85 in _run_code\r\n  File \"c:\\users\\san10428\\.conda\\envs\\tfpreview\\lib\\runpy.py\", line 193 in _run_module_as_main\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nI am using nchw data format\r\n\r\n", "comments": ["@sandeepgadhwal,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "The issue was that i saved that model using custom keras layers with tensor-flow version 1.14 .\r\n\r\nI saved a model using latest tensorflow and it works fine. \r\n\r\n@amahendrakar  thank you."]}, {"number": 36395, "title": "[Intel MKL] Patch for fix Shape compilation issue in MKL build", "body": "This PR adapts a recent changes in `MakeShape` function.", "comments": ["@penpornk Can you pls take a look at this small PR that is fixing a build failure in MKL backend caused by [recent change](https://github.com/tensorflow/tensorflow/commit/271f6bb49d2140b4c1bca88391caedd1791561cf#diff-df5e1858656225cf1f668278adb47e08). Thanks in advance!", "@penpornk I have fixed it already. Thanks!", "Closing this since it has been merged.", "Thanks for quick review @penpornk.", "@penpornk Changing `CHECK_EQ` to `DCHECK_EQ` is leading to a few unit test failures in MKL build, since compiler is removing that entire line all together(?) So we are working on PR to fix the unit test failures.\r\n\r\n`no new check` means we cannot use any `CHECK` macro now? Can we use `TF_CHECK_OK` instead? ", "@nhasabni Oops. Sorry about that. Yes, `DCHECK`s won't execute in opt mode. I forgot to check if the expression inside is something that needs to be executed. \r\n\r\nI believe `TF_CHECK_OK` is still allowed. Only `CHECK_*` are banned from new code. \r\n\r\nI can change `DCHECK_EQ` to `TF_CHECK_OK` right now too if that's the only fix in the PR. Let me know. Sorry again for the trouble!", "@penpornk thanks for quick reply. We have started an internal unit test run to see if the change fixes the issue. We will test with TF_CHECK_OK. I will update you in an hour or so.", "@penpornk We made following change, and that is passing all the internal testing. Would you like to go ahead and submit the change? Or should I submit a separate PR? Let me know.\r\n\r\n```\r\n     - DCHECK_EQ(tensor::MakeShape(input_tensor, &input_tf_shape).ok(), true);\r\n     + TF_CHECK_OK(tensor::MakeShape(input_tensor, &input_tf_shape));\r\n```", "@nhasabni I can submit the change. Thank you so much!", "@penpornk Sounds good. Thanks!", "@nhasabni Fixed in this commit https://github.com/tensorflow/tensorflow/commit/dc94b3a69e8988e5db1994ce607b893f59d6f2d9"]}, {"number": 36394, "title": "file_io.get_matching_files indefinitely hangs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): GCP cloud shell\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Comes pre-installed in  GCP cloud shell\r\n- TensorFlow version (use command below): TF 2.1\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nfile_io.get_matching_files indefinitely hangs\r\n\r\n**Describe the expected behavior**\r\nfile_io.get_matching_files should not hang!\r\n\r\n**Code to reproduce the issue**\r\nNote the `//` in the first command\r\n```\r\ngsutil cp README-cloudshell.txt gs://<some_bucket>/test//bug.txt\r\ngsutil cp README-cloudshell.txt gs://<some_bucket>/test/bug.txt\r\n```\r\nThis creates a weird `/` folder under the test folder\r\n\r\nNow open python\r\n```\r\nfrom tensorflow.python.lib.io import file_io\r\nfile_io.get_matching_files('gs://<some_bucket>/test/bug.txt')\r\n```\r\nThis will hang. \r\nDelete the `/` folder and this would work fine.\r\n\r\nOne of our training jobs hung because TF somehow created a `/` folder in model output directory!", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36394\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36394\">No</a>\n", "Apologies for the long delay. This should be fixed in the next nightly and the next release."]}, {"number": 36393, "title": "LSTM return sequence is not working unless i use return state", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):mac 10.15\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\nLSTM layer return sequence is not working unless i set return state TRUE \r\n**Describe the expected behavior**\r\nthe expected behavior is to get the hidden states with return sequence without needing to set return state to TRUE\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport tensorflow as tf\r\n\r\ninputs = np.random.random([32, 10, 8]).astype(np.float32)\r\n\r\nlstm = tf.keras.layers.LSTM(4, return_sequences=True)\r\n\r\nprint(\"ouput_shape\",lstm(inputs).shape)\r\n\r\nwhole_sequence_output, final_memory_state = lstm(inputs)\r\n```\r\n\r\n**Other info / logs**\r\n\r\nouput_shape (32, 10, 4)\r\n2020-01-31 20:35:12.115074: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-01-31 20:35:12.124516: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fce9bb25ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-01-31 20:35:12.124525: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/ahmedabaas/Desktop/NLP/codes/utils/preprocess_utils.py\", line 177, in <module>\r\n    whole_sequence_output, final_memory_state = lstm(inputs)\r\nValueError: too many values to unpack (expected 2)\r\n", "comments": []}, {"number": 36392, "title": "ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call due to gradient tape", "body": "Similar to #355226 I am also getting the same Value error but while handling gradient tape.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train_model.py\", line 211, in <module>\r\n    main()\r\n  File \"train_model.py\", line 194, in main\r\n    batch_loss = train_step(inp, targ, enc_hidden, targ_lang, encoder, decoder)\r\n  File \"train_model.py\", line 115, in train_step\r\n    gradients = tape.gradient(loss, variables)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/backprop.py\", line 1011, in gradient\r\n    flat_sources = [_handle_or_self(x) for x in flat_sources]\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/backprop.py\", line 697, in _handle_or_self\r\n    x = x.handle\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/distribute/values.py\", line 720, in handle\r\n    raise ValueError(\"`handle` is not available outside the replica context\"\r\nValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.\r\n``` \r\n\r\nMy code:\r\n```\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    LOSS_OBJECT = tf.keras.losses.SparseCategoricalCrossentropy(\r\n    from_logits=True, reduction='none')\r\n\r\n    OPTIMIZER = tf.keras.optimizers.Adam()\r\n\r\n\r\nwith strategy.scope():\r\n    #@tf.function\r\n    def train_step(inp, targ, enc_hidden, targ_lang, encoder, decoder):\r\n        loss = 0\r\n\r\n        with tf.GradientTape(persistent=True) as tape:\r\n            enc_output, enc_hidden = encoder(inp, enc_hidden)\r\n\r\n            dec_hidden = enc_hidden\r\n\r\n            dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\r\n\r\n            # Teacher forcing - feeding the target as the next input\r\n            for t in range(1, targ.shape[1]):\r\n                # passing enc_output to the decoder\r\n                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\r\n\r\n                loss += loss_function(targ[:, t], predictions)\r\n\r\n                # using teacher forcing\r\n                dec_input = tf.expand_dims(targ[:, t], 1)\r\n\r\n            batch_loss = (loss / int(targ.shape[1]))\r\n\r\n            variables = encoder.trainable_variables + decoder.trainable_variables\r\n\r\n            gradients = tape.gradient(loss, variables)\r\n\r\n            OPTIMIZER.apply_gradients(zip(gradients, variables))\r\n\r\n        return batch_loss\r\n```\r\n\r\nI am using ```Tensorflow==2.1.0``` and ```cuda 10.1```", "comments": ["@aggarwalpiush, Could you provide complete standalone code to analyze the reported issue. Thanks!", "Here you go:\r\n\r\n```\r\n\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nimport os\r\nimport io\r\nimport time\r\n\r\n\r\nclass BahdanauAttention(tf.keras.layers.Layer):\r\n  def __init__(self, units):\r\n    super(BahdanauAttention, self).__init__()\r\n    self.W1 = tf.keras.layers.Dense(units)\r\n    self.W2 = tf.keras.layers.Dense(units)\r\n    self.V = tf.keras.layers.Dense(1)\r\n\r\n  def call(self, query, values):\r\n    # hidden shape == (batch_size, hidden size)\r\n    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\r\n    # we are doing this to perform addition to calculate the score\r\n    hidden_with_time_axis = tf.expand_dims(query, 1)\r\n\r\n    # score shape == (batch_size, max_length, 1)\r\n    # we get 1 at the last axis because we are applying score to self.V\r\n    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\r\n    score = self.V(tf.nn.tanh(\r\n        self.W1(values) + self.W2(hidden_with_time_axis)))\r\n\r\n    # attention_weights shape == (batch_size, max_length, 1)\r\n    attention_weights = tf.nn.softmax(score, axis=1)\r\n\r\n    # context_vector shape after sum == (batch_size, hidden_size)\r\n    context_vector = attention_weights * values\r\n    context_vector = tf.reduce_sum(context_vector, axis=1)\r\n\r\n    return context_vector, attention_weights\r\n\r\nclass Encoder(tf.keras.Model):\r\n  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\r\n    super(Encoder, self).__init__()\r\n    self.batch_sz = batch_sz\r\n    self.enc_units = enc_units\r\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n    self.gru = tf.keras.layers.GRU(self.enc_units,\r\n                                   return_sequences=True,\r\n                                   return_state=True,\r\n                                   recurrent_initializer='glorot_uniform')\r\n\r\n  def call(self, x, hidden):\r\n    x = self.embedding(x)\r\n    output, state = self.gru(x, initial_state = hidden)\r\n    return output, state\r\n\r\n  def initialize_hidden_state(self):\r\n    return tf.zeros((self.batch_sz, self.enc_units))\r\n\r\n\r\n\r\nclass Decoder(tf.keras.Model):\r\n  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\r\n    super(Decoder, self).__init__()\r\n    self.batch_sz = batch_sz\r\n    self.dec_units = dec_units\r\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n    self.gru = tf.keras.layers.GRU(self.dec_units,\r\n                                   return_sequences=True,\r\n                                   return_state=True,\r\n                                   recurrent_initializer='glorot_uniform')\r\n    self.fc = tf.keras.layers.Dense(vocab_size)\r\n\r\n    # used for attention\r\n    self.attention = BahdanauAttention(self.dec_units)\r\n\r\n  def call(self, x, hidden, enc_output):\r\n    # enc_output shape == (batch_size, max_length, hidden_size)\r\n    context_vector, attention_weights = self.attention(hidden, enc_output)\r\n\r\n    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\r\n    x = self.embedding(x)\r\n\r\n    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\r\n\r\n    # passing the concatenated vector to the GRU\r\n    output, state = self.gru(x)\r\n\r\n    # output shape == (batch_size * 1, hidden_size)\r\n    output = tf.reshape(output, (-1, output.shape[2]))\r\n\r\n    # output shape == (batch_size, vocab)\r\n    x = self.fc(output)\r\n\r\n    return x, state, attention_weights\r\n\r\n\r\n# Converts the unicode file to ascii\r\ndef unicode_to_ascii(s):\r\n  return ''.join(c for c in unicodedata.normalize('NFD', s)\r\n      if unicodedata.category(c) != 'Mn')\r\n\r\n\r\ndef preprocess_sentence(w):\r\n  w = unicode_to_ascii(w.lower().strip())\r\n\r\n  # creating a space between a word and the punctuation following it\r\n  # eg: \"he is a boy.\" => \"he is a boy .\"\r\n  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\r\n  w = re.sub(r\"([?.!,\u00bf])\", r\" \\1 \", w)\r\n  w = re.sub(r'[\" \"]+', \" \", w)\r\n\r\n  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\r\n  w = re.sub(r\"[^a-zA-Z?.!,\u00bf]+\", \" \", w)\r\n\r\n  w = w.rstrip().strip()\r\n\r\n  # adding a start and an end token to the sentence\r\n  # so that the model know when to start and stop predicting.\r\n  w = '<start> ' + w + ' <end>'\r\n  return w\r\n\r\n\r\n\r\n\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    LOSS_OBJECT = tf.keras.losses.SparseCategoricalCrossentropy(\r\n    from_logits=True, reduction='none')\r\n\r\n    OPTIMIZER = tf.keras.optimizers.Adam()\r\n\r\n\r\nBATCH_SIZE = 192\r\nEPOCHS = 20\r\nEMBEDDING_DIM = 256\r\nUNITS = 1024\r\nPATH_TO_FILE = \"../data/train/blabla\"\r\nNUM_EXAMPLES = 3000\r\nCHECKPOINT_DIR = './training_checkpoints'\r\n\r\n\r\ndef create_dataset(filepath, num_examples):\r\n  src_lines = io.open(filepath + \".src\", encoding='UTF-8').read().strip().split('\\n')\r\n  dst_lines = io.open(filepath + \".dst\", encoding='UTF-8').read().strip().split('\\n')\r\n  word_pairs = []\r\n  if num_examples == 0 or num_examples > len(src_lines):\r\n    num_examples = len(src_lines)\r\n  for i, l_src in enumerate(src_lines[:num_examples]):\r\n    word_pairs.append([preprocess_sentence(l_src), preprocess_sentence(dst_lines[i])])\r\n\r\n  return zip(*word_pairs)\r\n\r\n\r\ndef max_length(tensor):\r\n  return max(len(t) for t in tensor)\r\n\r\ndef tokenize(lang):\r\n  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\r\n      filters='', oov_token='unk')\r\n  lang_tokenizer.fit_on_texts(lang)\r\n\r\n  tensor = lang_tokenizer.texts_to_sequences(lang)\r\n\r\n  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\r\n                                                         padding='post')\r\n\r\n  return tensor, lang_tokenizer\r\n\r\ndef load_dataset(path, num_examples=None):\r\n  # creating cleaned input, output pairs\r\n  targ_lang, inp_lang = create_dataset(path, num_examples)\r\n\r\n  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\r\n  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\r\n\r\n  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\r\n\r\ndef convert(lang, tensor):\r\n  for t in tensor:\r\n    if t!=0:\r\n      print (\"%d ----> %s\" % (t, lang.index_word[t]))\r\n\r\nwith strategy.scope():\r\n    def loss_function(real, pred):\r\n        mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n        loss_ = LOSS_OBJECT(real, pred)\r\n\r\n        mask = tf.cast(mask, dtype=loss_.dtype)\r\n        loss_ *= mask\r\n\r\n        return tf.reduce_mean(loss_)\r\n\r\nwith strategy.scope():\r\n    #@tf.function\r\n    def train_step(inp, targ, enc_hidden, targ_lang, encoder, decoder):\r\n        loss = 0\r\n\r\n        with tf.GradientTape(persistent=True) as tape:\r\n            enc_output, enc_hidden = encoder(inp, enc_hidden)\r\n\r\n            dec_hidden = enc_hidden\r\n\r\n            dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\r\n\r\n            # Teacher forcing - feeding the target as the next input\r\n            for t in range(1, targ.shape[1]):\r\n                # passing enc_output to the decoder\r\n                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\r\n\r\n                loss += loss_function(targ[:, t], predictions)\r\n\r\n                # using teacher forcing\r\n                dec_input = tf.expand_dims(targ[:, t], 1)\r\n\r\n            batch_loss = (loss / int(targ.shape[1]))\r\n\r\n            variables = encoder.trainable_variables + decoder.trainable_variables\r\n\r\n            gradients = tape.gradient(loss, variables)\r\n    \r\n            OPTIMIZER.apply_gradients(zip(gradients, variables))\r\n\r\n        return batch_loss\r\n\r\n\r\ndef main():\r\n  # Try experimenting with the size of that dataset\r\n\r\n  input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(PATH_TO_FILE, NUM_EXAMPLES)\r\n\r\n#  strategy = tf.distribute.MirroredStrategy()\r\n  # Calculate max_length of the target tensors\r\n  print(max_length(target_tensor), max_length(input_tensor))\r\n  \r\n # BATCH_SIZE *= strategy.num_replicas_in_sync\r\n  input_tensor_train = input_tensor\r\n  target_tensor_train = target_tensor\r\n\r\n  buffer_size = len(input_tensor_train)\r\n  steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\r\n\r\n  vocab_inp_size = len(inp_lang.word_index) + 1\r\n  vocab_tar_size = len(targ_lang.word_index) + 1\r\n\r\n  dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(buffer_size)\r\n  dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\r\n  #dataset = strategy.experimental_distribute_dataset(dataset)\r\n  \r\n\r\n\r\n  # Show length\r\n  print(len(input_tensor_train), len(target_tensor_train))\r\n\r\n  example_input_batch, example_target_batch = next(iter(dataset))\r\n  #print(example_input_batch.shape, example_target_batch.shape)\r\n\r\n  optimizer = tf.keras.optimizers.Adam()\r\n\r\n\r\n  #en, sp = create_dataset(PATH_TO_FILE, None)\r\n\r\n  encoder = Encoder(vocab_inp_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\r\n\r\n  # sample input\r\n  sample_hidden = encoder.initialize_hidden_state()\r\n  with strategy.scope():\r\n    sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\r\n  print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\r\n  print('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\r\n\r\n  attention_layer = BahdanauAttention(10)\r\n  with strategy.scope():\r\n    attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\r\n\r\n  print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\r\n  print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\r\n\r\n  decoder = Decoder(vocab_tar_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\r\n\r\n  with strategy.scope():\r\n    sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\r\n                                        sample_hidden, sample_output)\r\n\r\n  print('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\r\n\r\n  checkpoint_prefix = os.path.join(CHECKPOINT_DIR, \"ckpt\")\r\n  checkpoint = tf.train.Checkpoint(optimizer=optimizer,\r\n                                   encoder=encoder,\r\n                                   decoder=decoder)\r\n  with strategy.scope():\r\n    for epoch in range(EPOCHS):\r\n        start = time.time()\r\n\r\n        enc_hidden = encoder.initialize_hidden_state()\r\n        total_loss = 0\r\n\r\n        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\r\n            batch_loss = train_step(inp, targ, enc_hidden, targ_lang, encoder, decoder)\r\n            total_loss += batch_loss\r\n\r\n            if batch % 100 == 0:\r\n                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\r\n                                                     batch,\r\n                                                     batch_loss.numpy()))\r\n    # saving (checkpoint) the model every 2 epochs\r\n        if (epoch + 1) % 2 == 0:\r\n            checkpoint.save(file_prefix=checkpoint_prefix)\r\n\r\n        print('Epoch {} Loss {:.4f}'.format(epoch + 1,\r\n                                        total_loss / steps_per_epoch))\r\n        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\r\n\r\n\r\n```", "I see you're using MirroredStrategy so I assume you want to distribute the training on multiple GPU. In this case, you need to use strategy.experimental_run_v2 to run your training step. You should also put all model definition under MirroredStrategy.scope(), actually you can put everything under the scope for simplicity.\r\n\r\nPlease see this guide on how to do distributed training with custom training loop: https://www.tensorflow.org/tutorials/distribute/custom_training\r\n\r\nI'm closing this now since it doesn't look a bug to me. Feel free to reopen if you believe there's a TF issue.", "@crccw  This issue also happens with `tf.estimator` with MirroredStrategy, even following the tutorial.", "I'm also facing the same error. Could you please look into my code snippet and help to figure out the problem?\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\nimport numpy as np\r\nimport gym\r\nfrom gym import wrappers\r\nimport tflearn\r\nimport argparse\r\nimport pprint as pp\r\nfrom replay_buffer import ReplayBuffer\r\n\r\n\r\nclass ActorNetwork(object):\r\n    def __init__(self, sess, state_dim, action_dim, action_bound, learning_rate, tau, batch_size):\r\n        self.sess = sess\r\n        self.s_dim = state_dim\r\n        self.a_dim = action_dim\r\n        self.action_bound = action_bound\r\n        self.learning_rate = learning_rate\r\n        self.tau = tau\r\n        self.batch_size = batch_size\r\n\r\n        # Actor Network\r\n        self.inputs, self.out, self.scaled_out = self.create_actor_network()\r\n\r\n        self.network_params = tf.trainable_variables()\r\n\r\n        # Target Network\r\n        self.target_inputs, self.target_out, self.target_scaled_out = self.create_actor_network()\r\n\r\n        self.target_network_params = tf.trainable_variables()[\r\n            len(self.network_params):]\r\n\r\n        # Op for periodically updating target network with online network\r\n        # weights\r\n        self.update_target_network_params = \\\r\n            [self.target_network_params[i].assign(tf.multiply(self.network_params[i], self.tau) +\r\n                                                  tf.multiply(self.target_network_params[i], 1. - self.tau))\r\n                for i in range(len(self.target_network_params))]\r\n\r\n        # This gradient will be provided by the critic network\r\n        self.action_gradient = tf.placeholder(tf.float32, [None, self.a_dim])\r\n\r\n        # Combine the gradients here\r\n        self.unnormalized_actor_gradients = tf.gradients(\r\n            self.scaled_out, self.network_params, -self.action_gradient)\r\n        self.actor_gradients = list(map(lambda x: tf.div(x, self.batch_size), self.unnormalized_actor_gradients))\r\n\r\n        # Optimization Op\r\n        self.optimize = tf.train.AdamOptimizer(self.learning_rate).\\\r\n            apply_gradients(zip(self.actor_gradients, self.network_params))\r\n\r\n        self.num_trainable_vars = len(\r\n            self.network_params) + len(self.target_network_params)\r\n\r\n    def create_actor_network(self):\r\n        inputs = tflearn.input_data(shape=[None, self.s_dim])\r\n        net = tf.keras.layers.Dense(400)(inputs)\r\n        net = tf.keras.layers.BatchNormalization()(net)\r\n        net = tf.keras.layers.ReLU()(net)\r\n        net = tf.keras.layers.Dense(300)(net)\r\n        net = tf.keras.layers.BatchNormalization()(net)\r\n        net = tf.keras.layers.ReLU()(net)\r\n        # Final layer weights are init to Uniform[-3e-3, 3e-3]\r\n        w_init = tf.keras.initializers.RandomUniform(minval=-0.003, maxval=0.003)\r\n        out = tf.keras.layers.Dense(self.a_dim, activation='linear', kernel_initializer=w_init)(net)\r\n        # Scale output to -action_bound to action_bound\r\n        scaled_out = tf.multiply(out, self.action_bound)\r\n        return inputs, out, scaled_out\r\n\r\n    def train(self, inputs, a_gradient):\r\n        self.sess.run(self.optimize, feed_dict={\r\n            self.inputs: inputs,\r\n            self.action_gradient: a_gradient\r\n        })\r\n\r\n    def predict(self, inputs):\r\n        return self.sess.run(self.scaled_out, feed_dict={\r\n            self.inputs: inputs\r\n        })\r\n\r\n    def predict_target(self, inputs):\r\n        return self.sess.run(self.target_scaled_out, feed_dict={\r\n            self.target_inputs: inputs\r\n        })\r\n\r\n    def update_target_network(self):\r\n        self.sess.run(self.update_target_network_params)\r\n\r\n    def get_num_trainable_vars(self):\r\n        return self.num_trainable_vars\r\n\r\nclass CriticNetwork(object):\r\n    def __init__(self, sess, state_dim, action_dim, learning_rate, tau, gamma, num_actor_vars):\r\n        self.sess = sess\r\n        self.s_dim = state_dim\r\n        self.a_dim = action_dim\r\n        self.learning_rate = learning_rate\r\n        self.tau = tau\r\n        self.gamma = gamma\r\n\r\n        # Create the critic network\r\n        self.inputs, self.action, self.out = self.create_critic_network()\r\n\r\n        self.network_params = tf.trainable_variables()[num_actor_vars:]\r\n\r\n        # Target Network\r\n        self.target_inputs, self.target_action, self.target_out = self.create_critic_network()\r\n\r\n        self.target_network_params = tf.trainable_variables()[(len(self.network_params) + num_actor_vars):]\r\n\r\n        # Op for periodically updating target network with online network\r\n        # weights with regularization\r\n        self.update_target_network_params = \\\r\n            [self.target_network_params[i].assign(tf.multiply(self.network_params[i], self.tau) \\\r\n            + tf.multiply(self.target_network_params[i], 1. - self.tau))\r\n                for i in range(len(self.target_network_params))]\r\n\r\n        # Network target (y_i)\r\n        self.predicted_q_value = tf.placeholder(tf.float32, [None, 1])\r\n\r\n        # Define loss and optimization Op\r\n        self.loss = tflearn.mean_square(self.predicted_q_value, self.out)\r\n        self.optimize = tf.train.AdamOptimizer(\r\n            self.learning_rate).minimize(self.loss)\r\n\r\n        # Get the gradient of the net w.r.t. the action.\r\n        # For each action in the minibatch (i.e., for each x in xs),\r\n        # this will sum up the gradients of each critic output in the minibatch\r\n        # w.r.t. that action. Each output is independent of all\r\n        # actions except for one.\r\n        self.action_grads = tf.gradients(self.out, self.action)\r\n\r\n\r\n    def create_critic_network(self):\r\n        inputs = tflearn.input_data(shape=[None, self.s_dim])\r\n        action = tflearn.input_data(shape=[None, self.a_dim])\r\n        net = tf.keras.layers.Dense(400)(inputs)\r\n        net = tf.keras.layers.BatchNormalization()(net)\r\n        net = tf.keras.layers.ReLU()(net)\r\n        # Add the action tensor in the 2nd hidden layer\r\n        # Use two temp layers to get the corresponding weights and biases\r\n        #t1 = tflearn.fully_connected(net, 300)\r\n        #t2 = tflearn.fully_connected(action, 300)\r\n\r\n        #net = tflearn.activation(\r\n         #   tf.matmul(net, t1.W) + tf.matmul(action, t2.W) + t2.b, activation='relu')\r\n\r\n        # linear layer connected to 1 output representing Q(s,a)\r\n        # Weights are init to Uniform[-3e-3, 3e-3]\r\n        w_init = tf.keras.initializers.RandomUniform(minval=-0.003, maxval=0.003)\r\n        out = out = tf.keras.layers.Dense(1, kernel_initializer=w_init)(net)\r\n        return inputs, action, out\r\n\r\n    def train(self, inputs, action, predicted_q_value):\r\n        return self.sess.run([self.out, self.optimize], feed_dict={\r\n            self.inputs: inputs,\r\n            self.action: action,\r\n            self.predicted_q_value: predicted_q_value\r\n        })\r\n\r\n    def predict(self, inputs, action):\r\n        return self.sess.run(self.out, feed_dict={\r\n            self.inputs: inputs,\r\n            self.action: action\r\n        })\r\n\r\n    def predict_target(self, inputs, action):\r\n        return self.sess.run(self.target_out, feed_dict={\r\n            self.target_inputs: inputs,\r\n            self.target_action: action\r\n        })\r\n\r\n    def action_gradients(self, inputs, actions):\r\n        return self.sess.run(self.action_grads, feed_dict={\r\n            self.inputs: inputs,\r\n            self.action: actions\r\n        })\r\n\r\n    def update_target_network(self):\r\n        self.sess.run(self.update_target_network_params)\r\n\r\nclass OrnsteinUhlenbeckActionNoise:\r\n    def __init__(self, mu, sigma=0.3, theta=.15, dt=1e-2, x0=None):\r\n        self.theta = theta\r\n        self.mu = mu\r\n        self.sigma = sigma\r\n        self.dt = dt\r\n        self.x0 = x0\r\n        self.reset()\r\n\r\n    def __call__(self):\r\n        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\r\n                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\r\n        self.x_prev = x\r\n        return x\r\n\r\n    def reset(self):\r\n        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\r\n\r\n    def __repr__(self):\r\n        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)\r\n\r\n\r\n\r\ndef build_summaries():\r\n    episode_reward = tf.Variable(0.)\r\n    tf.summary.scalar(\"Reward\", episode_reward)\r\n    episode_ave_max_q = tf.Variable(0.)\r\n    tf.summary.scalar(\"Qmax Value\", episode_ave_max_q)\r\n\r\n    summary_vars = [episode_reward, episode_ave_max_q]\r\n    summary_ops = tf.summary.merge_all()\r\n\r\n    return summary_ops, summary_vars\r\n\r\n\r\ndef train(sess, env, args, actor, critic, actor_noise):\r\n\r\n    # Set up summary Ops\r\n    summary_ops, summary_vars = build_summaries()\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n    writer = tf.summary.FileWriter(args['summary_dir'], sess.graph)\r\n\r\n    # Initialize target network weights\r\n    actor.update_target_network()\r\n    critic.update_target_network()\r\n\r\n    # Initialize replay memory\r\n    replay_buffer = ReplayBuffer(int(args['buffer_size']), int(args['random_seed']))\r\n\r\n    # Needed to enable BatchNorm. \r\n    # This hurts the performance on Pendulum but could be useful\r\n    # in other environments.\r\n    # tflearn.is_training(True)\r\n\r\n    for i in range(int(args['max_episodes'])):\r\n\r\n        s = env.reset()\r\n\r\n        ep_reward = 0\r\n        ep_ave_max_q = 0\r\n\r\n        for j in range(int(args['max_episode_len'])):\r\n\r\n            if args['render_env']:\r\n                env.render()\r\n\r\n            # Added exploration noise\r\n            #a = actor.predict(np.reshape(s, (1, 3))) + (1. / (1. + i))\r\n            a = actor.predict(np.reshape(s, (1, actor.s_dim))) + actor_noise()\r\n\r\n            s2, r, terminal, info = env.step(a[0])\r\n\r\n            replay_buffer.add(np.reshape(s, (actor.s_dim,)), np.reshape(a, (actor.a_dim,)), r,\r\n                              terminal, np.reshape(s2, (actor.s_dim,)))\r\n\r\n            # Keep adding experience to the memory until\r\n            # there are at least minibatch size samples\r\n            if replay_buffer.size() > int(args['minibatch_size']):\r\n                s_batch, a_batch, r_batch, t_batch, s2_batch = \\\r\n                    replay_buffer.sample_batch(int(args['minibatch_size']))\r\n\r\n\r\n                # Calculate targets\r\n                target_q = critic.predict_target(\r\n                    s2_batch, actor.predict_target(s2_batch))\r\n\r\n                y_i = []\r\n                for k in range(int(args['minibatch_size'])):\r\n                    if t_batch[k]:\r\n                        y_i.append(r_batch[k])\r\n                    else:\r\n                        y_i.append(r_batch[k] + critic.gamma * target_q[k])\r\n\r\n                # Update the critic given the targets\r\n                predicted_q_value, _ = critic.train(\r\n                    s_batch, a_batch, np.reshape(y_i, (int(args['minibatch_size']), 1)))\r\n\r\n                ep_ave_max_q += np.amax(predicted_q_value)\r\n\r\n                # Update the actor policy using the sampled gradient\r\n                a_outs = actor.predict(s_batch)\r\n                grads = critic.action_gradients(s_batch, a_outs)\r\n                actor.train(s_batch, grads[0])\r\n\r\n                # Update target networks\r\n                actor.update_target_network()\r\n                critic.update_target_network()\r\n\r\n            s = s2\r\n            ep_reward += r\r\n\r\n            if terminal:\r\n\r\n                summary_str = sess.run(summary_ops, feed_dict={\r\n                    summary_vars[0]: ep_reward,\r\n                    summary_vars[1]: ep_ave_max_q / float(j)\r\n                })\r\n\r\n                writer.add_summary(summary_str, i)\r\n                writer.flush()\r\n\r\n                print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f}'.format(int(ep_reward), \\\r\n                        i, (ep_ave_max_q / float(j))))\r\n                break\r\n\r\ndef main(args):\r\n\r\n    device_type = 'GPU'\r\n    devices = tf.config.experimental.list_physical_devices(device_type)\r\n    devices_names = [d.name.split(\"e:\")[1] for d in devices]\r\n    strategy = tf.distribute.MirroredStrategy(devices=devices_names[:int(args['ngpus'])])\r\n\r\n    with strategy.scope():\r\n        with tf.Session() as sess:\r\n\r\n            env = gym.make(args['env'])\r\n            np.random.seed(int(args['random_seed']))\r\n            tf.set_random_seed(int(args['random_seed']))\r\n            env.seed(int(args['random_seed']))\r\n\r\n            state_dim = env.observation_space.shape[0]\r\n            action_dim = env.action_space.shape[0]\r\n            action_bound = env.action_space.high\r\n            # Ensure action bound is symmetric\r\n            assert (env.action_space.high == -env.action_space.low)\r\n\r\n            actor = ActorNetwork(sess, state_dim, action_dim, action_bound,\r\n                             float(args['actor_lr']), float(args['tau']),\r\n                             int(args['minibatch_size']))\r\n\r\n            critic = CriticNetwork(sess, state_dim, action_dim,\r\n                               float(args['critic_lr']), float(args['tau']),\r\n                               float(args['gamma']),\r\n                               actor.get_num_trainable_vars())\r\n\r\n            actor_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(action_dim))\r\n\r\n            if args['use_gym_monitor']:\r\n                if not args['render_env']:\r\n                    env = wrappers.Monitor(\r\n                        env, args['monitor_dir'], video_callable=False, force=True)\r\n                else:\r\n                    env = wrappers.Monitor(env, args['monitor_dir'], force=True)\r\n\r\n            train(sess, env, args, actor, critic, actor_noise)\r\n\r\n            if args['use_gym_monitor']:\r\n                env.monitor.close()\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser(description='provide arguments for DDPG agent')\r\n\r\n    # agent parameters\r\n    parser.add_argument('--actor-lr', help='actor network learning rate', default=0.0001)\r\n    parser.add_argument('--critic-lr', help='critic network learning rate', default=0.001)\r\n    parser.add_argument('--gamma', help='discount factor for critic updates', default=0.99)\r\n    parser.add_argument('--tau', help='soft target update parameter', default=0.001)\r\n    parser.add_argument('--buffer-size', help='max size of the replay buffer', default=1000000)\r\n    parser.add_argument('--minibatch-size', help='size of minibatch for minibatch-SGD', default=64)\r\n    parser.add_argument('--ngpus', help='Number of GPUs', default=2)\r\n\r\n    # run parameters\r\n    parser.add_argument('--env', help='choose the gym env- tested on {Pendulum-v0}', default='Pendulum-v1')\r\n    parser.add_argument('--random-seed', help='random seed for repeatability', default=1234)\r\n    parser.add_argument('--max-episodes', help='max num of episodes to do while training', default=50000)\r\n    parser.add_argument('--max-episode-len', help='max length of 1 episode', default=1000)\r\n    parser.add_argument('--render-env', help='render the gym env', action='store_true')\r\n    parser.add_argument('--use-gym-monitor', help='record gym results', action='store_true')\r\n    parser.add_argument('--monitor-dir', help='directory for storing gym results', default='./results/gym_ddpg')\r\n    parser.add_argument('--summary-dir', help='directory for storing tensorboard info', default='./results/tf_ddpg')\r\n\r\n    parser.set_defaults(render_env=False)\r\n    parser.set_defaults(use_gym_monitor=True)\r\n\r\n    args = vars(parser.parse_args())\r\n\r\n    pp.pprint(args)\r\n\r\n    main(args)\r\n```\r\n\r\n\r\nOUTPUT:\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nnon-resource variables are not supported in the long term\r\nScipy not supported!\r\n{'actor_lr': 0.0001,\r\n 'buffer_size': 1000000,\r\n 'critic_lr': 0.001,\r\n 'env': 'Pendulum-v1',\r\n 'gamma': 0.99,\r\n 'max_episode_len': 1000,\r\n 'max_episodes': 50000,\r\n 'minibatch_size': 64,\r\n 'monitor_dir': './results/gym_ddpg',\r\n 'ngpus': 2,\r\n 'random_seed': 1234,\r\n 'render_env': False,\r\n 'summary_dir': './results/tf_ddpg',\r\n 'tau': 0.001,\r\n 'use_gym_monitor': True}\r\n2022-04-11 19:58:20.286219: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions\r\nin performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-04-11 19:58:21.117294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 10795 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7\r\n2022-04-11 19:58:21.118538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 10795 MB memory:  -> device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7\r\n2022-04-11 19:58:21.136084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10795 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7\r\n2022-04-11 19:58:21.137010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10795 MB memory:  -> device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7\r\nWARNING:tensorflow:From ddpg.py:77: The name tf.keras.initializers.RandomUniform is deprecated. Please use tf.compat.v1.keras.initializers.RandomUniform instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v1.py:277: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and\r\nwill be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nTraceback (most recent call last):\r\n  File \"ddpg.py\", line 406, in <module>\r\n    main(args)\r\n  File \"ddpg.py\", line 354, in main\r\n    actor = ActorNetwork(sess, state_dim, action_dim, action_bound,\r\n  File \"ddpg.py\", line 57, in __init__\r\n    self.unnormalized_actor_gradients = tf.gradients(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 165, in gradients\r\n    return gradients_util._GradientsHelper(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\", line 516, in _GradientsHelper\r\n    xs = [\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\", line 517, in <listcomp>\r\n    x.handle if resource_variable_ops.is_resource_variable(x) else x\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/values.py\", line 698, in handle\r\n    raise ValueError(\r\nValueError: DistributedVariable.handle is not available outside the replica context or a `tf.distribute.Strategy.update()` call.\r\n\r\n\r\n\r\n\r\n\r\nNote that I also tried running it without BatchNormalization, however, it did not work for me. Any help will be greatly appreciated. Thanks\r\n"]}, {"number": 36391, "title": "[TF 2.1] Error when converting LSTM model to a frozen graph using convert_variables_to_constants_v2()", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac\r\n- TensorFlow installed from (source or binary): pip install tensorflow\r\n- TensorFlow version (use command below): 2.1\r\n- Python version: 2.7\r\n\r\nI tried to froze a LSTM model build with tf.keras by using the `convert_variables_to_constants_v2` function with the following code\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ndef build_model(vocab_size, embedding_dim, rnn_units, batch_size):\r\n  model = tf.keras.Sequential([\r\n    tf.keras.layers.Embedding(vocab_size, embedding_dim,\r\n                              batch_input_shape=[batch_size, embedding_dim]),\r\n    tf.keras.layers.LSTM(rnn_units,\r\n                        return_sequences=True,\r\n                        stateful=False,\r\n                        recurrent_activation='sigmoid',\r\n                        recurrent_initializer='glorot_uniform'),\r\n    tf.keras.layers.Dense(vocab_size)\r\n  ])\r\n  return model\r\n\r\nembedding_dim = 100\r\nunits = 256\r\nvocab_size = 300\r\nbatch_size = 32\r\n\r\nmodel = build_model(vocab_size, embedding_dim, units, batch_size)\r\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\r\n\r\nfrom tensorflow.python.keras.saving import saving_utils as _saving_utils\r\nfrom tensorflow.python.framework import convert_to_constants as _convert_to_constants\r\n\r\ntf.keras.backend.set_learning_phase(False)\r\nfunc = _saving_utils.trace_model_call(model)\r\nconcrete_func = func.get_concrete_function()\r\nfrozen_func = _convert_to_constants.convert_variables_to_constants_v2(concrete_func)\r\n```\r\nproduces\r\n```\r\nCannot find the Placeholder op that is an input to the ReadVariableOp.\r\n```\r\n", "comments": ["Could replicate issue on colab with Tf 2.1 and Tf-nightly.\r\nPlease find the gist [here](https://colab.research.google.com/gist/gadagashwini/483fa045f51d0112ddbd2039781b1eca/untitled372.ipynb). Thanks!", "Thanks!", "Hi @jakesabathia2, the code snippet you have is using a lot of internal python function, which access a lot implementation details and we don't ensure any API guarantee for them.\r\n\r\nCan you provide more context about why you need to access the frozen graph? Also please check the model saving doc here https://www.tensorflow.org/guide/saved_model. ", "> Hi @jakesabathia2, the code snippet you have is using a lot of internal python function, which access a lot implementation details and we don't ensure any API guarantee for them.\r\n> \r\n> Can you provide more context about why you need to access the frozen graph? Also please check the model saving doc here https://www.tensorflow.org/guide/saved_model.\r\n\r\nI also came along this issue yesterday. I need the frozen graph to list all used Ops for security reasons (models that I did not create, could read or write from/to disk). As far as I know/found, this is only possible using the frozen graph. \r\n\r\nFor example: I want to search for MatchingFiles, ReadFile or WriteFile ops in a model in SavedModel format. The library part of the saved model proto lists this, but it is documented that this is still experimental and might be removed. ", "Any updates on this?", "Adding Kathy for the save model question.", "+@gargn  Should convert_variables_to_constants_v2 be working for this case?", "> +@gargn Should convert_variables_to_constants_v2 be working for this case?\r\n\r\nAnother way of achieving this, is also fine. But it should be possible at least as all the information is in the graph anyway.", "any progress on this issues?", "I was having this issue too with my keras model (TF 2.0 and nightly reported \"Cannot find the Placeholder op that is an input to the ReadVariableOp.\" while trying to convert to SM model) - I managed to solve this by following the suggestions from here: https://stackoverflow.com/questions/51858203/cant-import-frozen-graph-with-batchnorm-layer/52823701#52823701 \r\nBasically:\r\n1) set trainable to false in each element of keras model\r\n2) before converting (in my case to SM, then from SM to frozen graph):\r\n`keras.backend.clear_session()\u2028`\r\n`tf.keras.backend.set_learning_phase(0)`", "> I was having this issue too with my keras model (TF 2.0 and nightly reported \"Cannot find the Placeholder op that is an input to the ReadVariableOp.\" while trying to convert to SM model) - I managed to solve this by following the suggestions from here: https://stackoverflow.com/questions/51858203/cant-import-frozen-graph-with-batchnorm-layer/52823701#52823701\r\n> Basically:\r\n> \r\n> 1. set trainable to false in each element of keras model\r\n> 2. before converting (in my case to SM, then from SM to frozen graph):\r\n>    `keras.backend.clear_session()\u2028   `\r\n>    `tf.keras.backend.set_learning_phase(0)`\r\n\r\nwhich version of the tensorflow did you use?\r\nI have tried by setting learning phase to 0 but, it doesn't work.\r\nI also tried with [this link](https://medium.com/@xianbao.qian/how-to-export-the-inference-model-in-tf2-279ac233915c) methods. methods to freeze my graph, but also doesn't work, i think it is a problem with this issues", "Hmm. I look at the [test code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/convert_to_constants_test.py) of convert_variables_to_constants_v2, It seems like when our model have the LSTM or GRU's layers, what we need to do is by pass one more argument **lower_control_flow=False** in order to make the **convert_variables_to_constants_v2** work.\r\n\r\nThe below code is an example to freeze the model, hope it helps\r\n```\r\nfull_model = tf.function(lambda x: model(x))\r\nfull_model = full_model.get_concrete_function(\r\n    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\r\n\r\n# Get frozen ConcreteFunction   \r\nfrozen_func = convert_variables_to_constants_v2(full_model,lower_control_flow=False)\r\nfrozen_func.graph.as_graph_def()\r\n\r\nlayers = [op.name for op in frozen_func.graph.get_operations()]\r\n# Save frozen graph from frozen ConcreteFunction to hard drive\r\ntf.io.write_graph(graph_or_graph_def=frozen_func.graph,\r\n                  logdir=\"./frozen_models\",\r\n                  name=\"frozen_graph.pb\",\r\n                  as_text=False)\r\n```", "The current implementation of convert_variables_to_constants_v2 does not support graphs that contain embedding related ops, see https://github.com/tensorflow/tensorflow/blob/667485ac4aed337194b3c6d1bf1e2230b214537b/tensorflow/python/framework/convert_to_constants.py#L665\r\nand you used tf.keras.layers.Embedding in your codes, is that why you got this error?", "I am seeing this too, thanks @xixiddd for the insights. That function is also used by the TensorRT examples to create optimized graphs. ", "Also seeing this, I think my issue is related to embedding layers as @xixiddd mentioned. Is there any plan for adding support for embedding related ops?", "Did not face any issues while running your code on Tf Nightly 2.6.0-dev20210524, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/3615ebc38df5e44facd934f33b3ef38a/35650.ipynb#scrollTo=kGg_oY4k3pqV).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36391\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36391\">No</a>\n"]}, {"number": 36390, "title": "Custom metric in tf.keras.Model compile() gives error, but works when run_eagerly=True", "body": "*System information**\r\nTensorflow 2.1 on colab\r\n\r\n**Describe the current behavior**\r\nWhen model.run_eagerly=True this model works correctly. When run_eagerly=False this gives an error\r\n\r\nError:\r\n\r\n> ValueError: Tried to convert 'input' to a tensor and failed. Error: None values not supported.\r\n\r\n**Describe the expected behavior**\r\nThe metric should run without errors in both cases\r\n\r\n**Code to reproduce the issue**\r\nSee colab notebook: https://colab.research.google.com/drive/1SxCf2N6D9bTbnm5fD0c_UYN4CaQ5neNQ\r\n\r\n`class CustomMetric(tf.keras.metrics.Metric):\r\n\r\n    def __init__(self, name='custom_metric', **kwargs):\r\n        super(CustomMetric, self).__init__(name=name, **kwargs)\r\n\r\n    def update_state(self, src, dst, sample_weight=None):\r\n        src = tf.reshape(src, (-1, 4, 2))\r\n        dst = tf.reshape(dst, (-1, 4, 2))\r\n\r\n        def ax(p, q):\r\n            ones = tf.ones(tf.shape(p))[..., 0:1]\r\n            zeros = tf.zeros(tf.shape(p))[..., 0:1]\r\n            return tf.concat(\r\n                [p[:, 0:1], p[:, 1:2], ones, zeros, zeros, zeros,\r\n                 -p[:, 0:1] * q[:, 0:1], -p[:, 1:2] * q[:, 0:1]\r\n                 ], axis=1)\r\n\r\n        def ay(p, q):\r\n            ones = tf.ones(tf.shape(p))[..., 0:1]\r\n            zeros = tf.zeros(tf.shape(p))[..., 0:1]\r\n            return tf.concat(\r\n                [zeros, zeros, zeros, p[:, 0:1], p[:, 1:2], ones,\r\n                 -p[:, 0:1] * q[:, 1:2], -p[:, 1:2] * q[:, 1:2]], axis=1)\r\n\r\n        # we build matrix A by using only 4 point correspondence. The linear\r\n        # system is solved with the least square method, so here\r\n        # we could even pass more correspondence\r\n        p = []\r\n        p.append(ax(src[:, 0], dst[:, 0]))\r\n        p.append(ay(src[:, 0], dst[:, 0]))\r\n\r\n        p.append(ax(src[:, 1], dst[:, 1]))\r\n        p.append(ay(src[:, 1], dst[:, 1]))\r\n\r\n        p.append(ax(src[:, 2], dst[:, 2]))\r\n        p.append(ay(src[:, 2], dst[:, 2]))\r\n\r\n        p.append(ax(src[:, 3], dst[:, 3]))\r\n        p.append(ay(src[:, 3], dst[:, 3]))\r\n\r\n        # A is Bx8x8\r\n        A = tf.stack(p, axis=1)\r\n\r\n        # b is a Bx8x1\r\n        b = tf.stack([\r\n            dst[:, 0:1, 0], dst[:, 0:1, 1],\r\n            dst[:, 1:2, 0], dst[:, 1:2, 1],\r\n            dst[:, 2:3, 0], dst[:, 2:3, 1],\r\n            dst[:, 3:4, 0], dst[:, 3:4, 1],\r\n        ], axis=1)\r\n\r\n        # solve the system Ax = b\r\n        X = tf.linalg.solve(A, b)\r\n        #return X\r\n\r\n    def reset_states(self):\r\n        return\r\n    def result(self):\r\n        return`\r\n\r\n\r\n", "comments": ["I was able to replicate the issue for tf-nightly.Thanks!", "This is fixed with tf-nightly version '2.2.0-dev20200318'. Please give it a try. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36390\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36390\">No</a>\n"]}, {"number": 36389, "title": "[S3] Fix bug when reading from s3 fails due to unforeseen reason", "body": "Fixed a bug when reading a file which treated any error when reading file as if it had reached the end of file. This has been handled by checking explicitly for the error message for when the range goes beyond the end of file (Aws::Http::HttpResponseCode::REQUESTED_RANGE_NOT_SATISFIABLE)", "comments": ["Waiting for this PR to go in https://github.com/tensorflow/tensorflow/pull/36353, so I can reuse a function I introduced there to clean this up", "Merged this with this PR https://github.com/tensorflow/tensorflow/pull/36353"]}, {"number": 36388, "title": "[S3] Skip using temp files/folders when writing to S3", "body": "S3 supports an eventual consistency model, which does not work like a regular file system. This means that many operations currently in the s3 file system crash now and then because the conditions it expects are not satisfied by S3. The following changes tries to address such crashes.\r\n\r\n- Skip usage of temp file when writing to S3:\r\nWhen writing a file to S3, the file system currently writes a temp file locally and syncs at the end by creating a file on S3. This coupled with the fact that S3 provides atomic uploads of files means that we will never see incomplete data uploaded for a file. In this scenario, the current usage of temp files when writing anything to the s3 file system (such as for Checkpoints, SavedModels) are unnecessary. I've removed such usage of temp files for S3 as they not just are unnecessary but cause issues with S3's consistency model. (It may so happen that after writing to a temp file, the file is not visible while moving to final location because changes haven't propagated yet. )\r\n\r\n- Skip usage of temp directory when saving Checkpoints and SavedModels to When saving Checkpoints and SavedModels, there is also the use of a temp directory where all files are uploaded and then moved to the final location. This is even more problematic given S3's eventual consistency model. This sequence of operations involves the writing to temp location, listing of files in temp location, copying each file from this temp location to final location, and deleting the temp location. There are multiple issues users have experienced because of this sequence. When listing files in temp directory, in some cases not all files show up in the list. This causes some files to not be copied. While deleting directory, there is another listing of all files in the directory. Again this list may be inconsistent and the deleting of directory fails. So the usage of such temp directory has been bypassed for S3 file system.\r\n\r\n- The above two changes have been implemented by introducing a has_atomic_move method for the filesystem and exposing it to python similar to how IsDirectory works. This method needs to be used multiple places both in python and CPP. By default for any file system other than S3, it returns False, which allows us to skip the usage of temp locations. The above issues for Checkpointing and SavedModels have been addressed and verified for both code paths of Estimator based training, Session based training as well as Keras.\r\n", "comments": ["@karmel I've updated my code. Please review again. Thanks!", "Can someone please help me with this test failure? I don't understand what's going on in the test, and how my changes are related to the failure. \r\n\r\nhttps://source.cloud.google.com/results/invocations/df79ab6c-104d-41be-9fb8-1a3402851511/targets/%2F%2Ftensorflow%2Fpython%2Fsaved_model:save_test/log\r\n\r\nIt looks like this PR creates some variable which is not cleaned up. Is this from the following, and if so what do I need to do?\r\n\r\n```\r\n_SHARDED_SUFFIX = control_flow_ops.cond(\r\n      string_ops.regex_full_match(checkpoint_prefix, '^s3://.*'),\r\n        lambda: \".part\",\r\n        lambda: \"_temp_%s/part\" % uuid.uuid4().hex)\r\n``` ", "It's because control flow (tf.cond) creates reference cycles and we currently have a check that tf.saved_model.save doesn't create reference cycles. Unfortunate, but the easy thing is just to delete this test: https://github.com/tensorflow/tensorflow/blob/8aa4fe59eb98147609dc690c1244dde315312cd4/tensorflow/python/saved_model/save_test.py#L675", "Thanks @allenlavoie ", "`FAIL: Found 1 non-whitelisted pylint errors:\r\ntensorflow/python/saved_model/save_test.py:22: [W0611(unused-import), ] Unused import sys\r\n\r\n\r\n\r\n=== Sanity check step 3 of 15: do_check_futures_test (Check that python files have certain __future__ imports) ===\r\n\r\n\r\n\r\n=== Sanity check step 4 of 15: do_buildifier (buildifier check) ===\r\n\r\nRunning do_buildifier on 413 files\r\n\r\n\r\nbuildifier took 1 s\r\n\r\nPASS: No buildifier errors or warnings were found\r\n\r\n\r\n=== Sanity check step 5 of 15: do_bazel_nobuild (bazel nobuild) ===`", "can you please fix above error ?", "@rthadur Just fixed it. Please rerun the build. ", "@rthadur Sorry, looks like I missed these two files somehow. Just fixed them. Please rerun the build. ", "Sanity build failure is unrelated. Will retrigger a new build once it gets fixed.", "@mihaimaruseac Have this and the llvm build issue been fixed now?", "I think so, it just needs to pass internal tests now.", "@MihailSalnikov It looks like the test which failed was rolledback yesterday, as seen from the commits here https://github.com/tensorflow/tensorflow/commits/master/tensorflow/python/keras/layers/preprocessing/index_lookup_test.py. \r\n\r\nI've rebased it on current master. Could you please retry the build?\r\n\r\n", "Here is the internal error , can you please verify\r\n`Traceback (most recent call last):\r\n  File \"/google3/runfiles/google3/third_party/py/absl/third_party/unittest3_backport/case.py\", line 37, in testPartExecutor\r\n    yield\r\n  File \"/google3/runfiles/google3/third_party/py/absl/third_party/unittest3_backport/case.py\", line 162, in run\r\n    testMethod()\r\n  File \"/google3/runfiles/google3/learning/brain/contrib/hub/tools/make_module/make_module_test.py\", line 58, in testKeepTags\r\n    module_path = self._make_module(model_path, config_proto)\r\n  File \"/google3/runfiles/google3/learning/brain/contrib/hub/tools/make_module/make_module_test.py\", line 43, in _make_module\r\n    make_module.make_module(meta_graphs, checkpoint_path, export_path, config)\r\n  File \"/google3/runfiles/google3/learning/brain/contrib/hub/tools/make_module/make_module.py\", line 52, in make_module\r\n    _modify_collections(meta_graph, meta_graph_config)\r\n  File \"/google3/runfiles/google3/learning/brain/contrib/hub/tools/make_module/make_module.py\", line 97, in _modify_collections\r\n    \"the config.\" % list(undef_set))\r\nRuntimeError: Unspecified actions for collections: [u'cond_context']. Please add them to keep_collection or drop_collection field in the config.`", "@rthadur could it be a failure due to something other than this PR? I don't see my changes being relevant to that. \r\n\r\nAlso, the two windows failures are failures I saw in different PRs unrelated to these changes. I rebased changes from master today. Can we retry?", "This fails internally:\r\n\r\n```\r\n  File \".../third_party/tensorflow/python/lib/io/file_io_test.py\", line 620, in testHasAtomicMove\r\n    self.assertFalse(file_io.has_atomic_move(\"s3://x/y\"))\r\n  File \"<embedded stdlib>/unittest/case.py\", line 676, in assertFalse\r\n    raise self.failureException(msg)\r\nAssertionError: True is not false\r\n```", "Ref: https://github.com/tensorflow/tensorflow/pull/36388#discussion_r382307430\r\n\r\nIs there anything else different internally that might be relevant for this PR?", "Maybe we just don't have S3 registered, so it's falling back to the default? In which case maybe we should skip the test if s3 is not registered. Or if that's only a google thing, we could skip that one internally somehow.", "I think it's because internally s3 does not exist. I'd suggest not having the test at all.", "Ah that makes sense. \r\n\r\nOkay removing the test since there's some s3 tests in cpp. I'll just leave the non s3 one in python just to make sure the python API works. ", "Looks merged in https://github.com/tensorflow/tensorflow/commit/eacf534690aa2c582e41556b4f92b4adde1d6c8d\r\n\r\nThere were some minor lint changes to appease tooling. But let me know if anything is objectionable and we can follow up. Thank you for your patience.", "Thanks @allenlavoie and @mihaimaruseac for your support!"]}, {"number": 36387, "title": "Fix go proto handling", "body": "Fixes #35133 and #34580 ", "comments": ["Tested out the solution by building from source. This seems to now cause an import cycle.\r\n", "@JWMHayhurst can you file a bug with what you are running and the error message?", "I have a change out to fix the import cycle. Will submit today.", "Fixed in https://github.com/tensorflow/tensorflow/commit/4221d1aa4d20ada495771528bb13ca786d0bdbe0"]}, {"number": 36386, "title": "[ROCm][XLA] Fixing gpu_unrolling_test filecheck string", "body": "Fixing `gpu_unrolling_test` by updating expected IR string. ROCm generated IR is less abstracted than Cuda side, making the test not working as intended. Though, `ROCm` and `Cuda` does share the same ir emission logic. We are covered as long as `Cuda` pass is passing.\r\n\r\n> Note: On ROCm side, we do bare minimal to make the test pass. \"sine\" function is in different code generation path from nvptx: on ROCm platform, it get pulled in from ROCm-Device-Libs, whereas in Cuda, generated llvm IR is compiled to PTX.", "comments": []}, {"number": 36385, "title": "Tensorflow team is so disappointing in documenting installation on windows pc", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Countless hours of my time have been wasted in trying to install tensorflow CPU version 2.1.0 on my Windows 10 desktop. I have tried all methods in a virtual environment - pip install and conda install methods, ideas given on TF official page, on SO and all over the net. In the end when I enter into Python 3.7 interpeter and type \"import tensorflow as tf\" is always says \"ImportError: DLL load failed: The specified module could not be found.\" TF official web page gives a URL to use - I used the one that applies to my case: Windows, Python 3.7, CPU version that I want to install. I provide this URL, installation goes through (as always), and in the end the same error crops up. Can the TF team kindly get in touch with Microsoft and fix this mess? That would save millions hours of wasted time globally as I see that the internet is full of such complaints by people trying to install tensorflow. If TF team claims it works, then I am willing to hand over my PC through Teamviewer or such.\r\n[tf_err_msg.docx](https://github.com/tensorflow/tensorflow/files/4141311/tf_err_msg.docx)\r\n\r\n", "Just passing through and saw this. I'd bet you'd have better luck trying in the windows subsystem for linux, although I'm not sure that will give you GPU access.", "Please fill out the template in the future so we are able to better assist you. Looks like [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) can help and is related? We are updating documentation very soon.", "Hi @psyg0501, \r\n\r\nDid you install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019?\r\n\r\nAccording to the docs at https://www.tensorflow.org/install/pip,\r\n\r\n> Install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019. Starting with the TensorFlow 2.1.0 version, the msvcp140_1.dll file is required from this package (which may not be provided from older redistributable packages). The redistributable comes with Visual Studio 2019 but can be installed separately:\r\n\r\n> Go to the [Microsoft Visual C++ downloads](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads),\r\nScroll down the page to the Visual Studio 2015, 2017 and 2019 section.\r\nDownload and install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 for your platform.\r\nMake sure [long paths](https://superuser.com/questions/1119883/windows-10-enable-ntfs-long-paths-policy-option-missing) are enabled on Windows.\r\n\r\n> Install the [64-bit Python 3 release](https://www.python.org/downloads/windows/) for Windows (select pip as an optional feature).\r\n\r\nTensorflow 2.1.0 is compiled using MSVC 2019, which appears to require an additional DLL.", "Thank you very much. I installed Visual C++ and then tf2. It works. I still think this requirement should be mentioned in red uppercase letters on tf page. I did not see it there.\nThanks again\n\nSent from Yahoo Mail on Android \n \n  On Sun, 2 Feb 2020 at 3:19, Amit Patankar<notifications@github.com> wrote:   \nClosed #36385.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or unsubscribe.\n  \n", "Thank you very much. I installed Visual C++ and then tf2. It works. I still think this requirement should be mentioned in red uppercase letters on tf page. I did not see it there.\r\nThanks again"]}, {"number": 36384, "title": "[XLA] clean up generated LLVM reduction code.", "body": "This ease reading the non-optimized LLVM code.\r\n\r\n@cheshire ", "comments": ["@nouiz Can you please resolve conflicts? Thanks!", "@gbaned It is now merged. So all should be good I think. Thanks for watching what is going on.", "> It is now merged\r\n\r\n@nouiz No it's not, check out the \"merge\" message: `ArmageddonKnight pushed a commit to UofT-EcoSystem/tensorflow that referenced this pull request`", "@nouiz Actually I was wrong, sorry again. Something went unexpected here, let me double check what happened."]}, {"number": 36383, "title": "TimeDistributed does not work with mixed precision training", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 2.1.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: X\r\n- **GCC/Compiler version (if compiling from source)**: X\r\n- **CUDA/cuDNN version**: on CPU\r\n- **GPU model and memory**: X\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport tensorflow_datasets as tfds\r\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\r\n\r\n\r\npolicy = mixed_precision.Policy('mixed_float16')\r\nmixed_precision.set_policy(policy)\r\n\r\n\r\ndef preprocess(ex):\r\n    image = tf.cast(tf.expand_dims(ex['image'], axis=0), tf.float32) / 255.\r\n    image = tf.image.resize(image, [224, 224])\r\n\r\n    return image, ex['label']\r\n\r\n\r\ndata = tfds.load(name='imagenette/full-size', split=\"train\", data_dir=\"/home/glorre/tensorflow_datasets\",\r\n                 shuffle_files=True).repeat()\r\ndata = data.map(preprocess).batch(5)\r\n\r\nimage = keras.Input(shape=[1, 224, 224, 3], name=\"seq\")\r\nfeatures = keras.layers.TimeDistributed(\r\n    keras.applications.ResNet50(include_top=False, weights=None, pooling='avg'))(image)\r\n\r\nfeatures = keras.layers.Lambda(lambda x: tf.squeeze(x, axis=[1]))(features)\r\n\r\nlogits = keras.layers.Dense(10)(features)\r\nlogits = keras.layers.Activation('linear', dtype='float32')(logits)\r\n\r\nmodel = keras.Model(inputs=image, outputs=logits)\r\n\r\noptimizer_1 = keras.optimizers.Adam(0.01)\r\nloss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n\r\nmodel.compile(optimizer=optimizer_1, loss=loss)\r\n\r\nmodel.summary()\r\n\r\nmodel.fit(data, epochs=10, steps_per_epoch=10)\r\n```\r\n\r\n### Describe the problem\r\nTimeDistributed layer raises an input shape error when used with mixed precision.\r\nIt works fine without mixed precision\r\n\r\n### Source code / logs\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/glorre/Code2/test_mixed_precision/mixed_precision.py\", line 25, in <module>\r\n    keras.applications.ResNet50(include_top=False, weights=None, pooling='avg'))(image)\r\n  File \"/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 807, in __call__\r\n    self._set_mask_metadata(inputs, outputs, input_masks)\r\n  File \"/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 1937, in _set_mask_metadata\r\n    output_masks = self.compute_mask(inputs, previous_mask)\r\n  File \"/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/wrappers.py\", line 324, in compute_mask\r\n    output_mask = self.layer.compute_mask(inner_inputs, inner_mask)\r\n  File \"/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 509, in compute_mask\r\n    output_tensors = self._run_internal_graph(inputs, mask=mask)\r\n  File \"/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 891, in _run_internal_graph\r\n    output_tensors = layer(computed_tensors, **kwargs)\r\n  File \"/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 737, in __call__\r\n    self.name)\r\n  File \"/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\", line 177, in assert_input_compatibility\r\n    str(x.shape.as_list()))\r\nValueError: Input 0 of layer conv1_pad is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 1, 224, 224, 3]\r\n\r\nProcess finished with exit code 1\r\n\r\n", "comments": ["i am able to replicate the issue, please find the [gist](https://colab.research.google.com/gist/Saduf2019/533d87b190fe8a0f011c20bc829efab7/untitled21.ipynb) here.", "@guillaumelorre28 I cannot reproduce the issue. Can you please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/e67d90d6542a8f3b7f1303b47fc70941/untitled21.ipynb). Thanks!\r\n\r\nWhen the code was ran without a GPU then it will throw a warning as follows and runs very slowly as mentioned in the warning.\r\n```\r\nWARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\r\nThe dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\r\nIf you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\r\n```\r\n\r\n", "Thanks it works fine with tf-nightly (I had the issue in tensorflow 2.1.0)\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36383\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36383\">No</a>\n"]}, {"number": 36382, "title": "Unable to run unit tests on util_nest", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 2.0\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: \r\n- Bazel version (if compiling from source): 1.2.1\r\n- GCC/Compiler version (if compiling from source): 4 (gotten from the command gcc -dumpversion | cut -f1 -d.)\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: Intel Iris Plus Graphics 640 1.5GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nUnable to run bazel tests using the command `bazel test //tensorflow/python:util_nest_test`.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI built tensorflow from the source by doing the following in sequence:\r\n1. Installed the tensorflow pip packages as stated in the documentation [here](https://www.tensorflow.org/install/source)\r\n2. Ran `./configure`command (with a success message which I will be posting in the logs).\r\n3. Ran `bazel build` and was shown a success message.\r\n4. Ran `bazel test //tensorflow/python:util_nest_test` and it got terminated with an error message\r\n```\r\nERROR: /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/tensorflow/core/util/BUILD:338:1: Executing genrule //tensorflow/core/util:version_info_gen failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_puneethk/4c7f735167707afd63484e296f46e040/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/git/gen_git_source.runfiles/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 340, in <module>\r\n    generate(args.generate, args.git_tag_override)\r\n  File \"/private/var/tmp/_bazel_puneethk/4c7f735167707afd63484e296f46e040/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/git/gen_git_source.runfiles/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 272, in generate\r\n    git_version = get_git_version(data[\"path\"], git_tag_override)\r\n  File \"/private/var/tmp/_bazel_puneethk/4c7f735167707afd63484e296f46e040/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/git/gen_git_source.runfiles/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 172, in get_git_version\r\n    str(\"--work-tree=\" + six.ensure_str(git_base_path)), \"describe\",\r\nAttributeError: 'module' object has no attribute 'ensure_str'\r\nTarget //tensorflow/python:util_nest_test failed to build\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n1. Output of running `./configure`:\r\n```\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 1.2.1 installed.\r\nPlease specify the location of python. [Default is /System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /Library/Python/2.7/site-packages\r\nPlease input the desired Python library path to use.  Default is [/Library/Python/2.7/site-packages]\r\n/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/site-packages\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: \r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: \r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: \r\nClang will not be downloaded.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nDo you wish to build TensorFlow with iOS support? [y/N]: \r\nNo iOS support will be enabled for TensorFlow.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n```\r\n2. Output after running `bazel build`:\r\n```\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=130\r\nINFO: Reading rc options for 'build' from /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --config=v2\r\nINFO: Reading rc options for 'build' from /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=/System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python --action_env PYTHON_LIB_PATH=/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/site-packages --python_path=/System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:v2 in file /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true\r\nINFO: Found applicable config definition build:xla in file /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.tf_configure.bazelrc: --define with_xla_support=true\r\nINFO: Found applicable config definition build:macos in file /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nWARNING: Usage: bazel build <options> <targets>.\r\nInvoke `bazel help build` for full description of usage and options.\r\nYour request is correct, but requested an empty set of targets. Nothing will be built.\r\nINFO: Analyzed 0 targets (0 packages loaded, 0 targets configured).\r\nINFO: Found 0 targets...\r\nINFO: Deleting stale sandbox base /private/var/tmp/_bazel_puneethk/4c7f735167707afd63484e296f46e040/sandbox\r\nINFO: Elapsed time: 1.643s, Critical Path: 0.03s\r\nINFO: 0 processes.\r\nINFO: Build completed successfully, 1 total action\r\n```\r\n\r\n\r\nIf anyone has run into similar problem and fixed it, could you guide me resolve this?", "comments": ["I think six module version is too old. It needs to be at least 1.12. Your issue looks similar to [this](https://stackoverflow.com/questions/57251430/attributeerror-module-object-has-no-attribute-ensure-str). ", "I'll look into this and then try the tests. Thanks.", "@punndcoder28, Did you try @wisefool769's workaround. ", "I updated six to 1.14 and ran the tests. Still getting the same error. I'll try the tests on a different machine and let you know.", "I ran the tests on a different machine and the tests passed. Maybe it is an issue with MacOS and the  packages there? I couldn't figure it out but the tests run fine.", "@punndcoder28, Are you happy to close this issue, since its resolved. Thanks!", "Yes. I'll be closing this issue now. Thanks for the inputs.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36382\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36382\">No</a>\n"]}, {"number": 36381, "title": "dense", "body": "", "comments": ["Closing as spam/no information provided."]}, {"number": 36380, "title": "ERROR: No matching distribution found for tensorboard<2.2.0,>=2.1.0 (from tensorflow)", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nwin10 1903\r\n\r\n- TensorFlow installed from (source or binary):\r\n```pip install tensorflow```\r\n\r\n- TensorFlow version:\r\n2.1.0\r\n\r\n- Python version:\r\n3.7.4\r\n\r\n- Installed using virtualenv? pip? conda?:\r\n```pip install tensorflow```\r\n\r\n- CUDA/cuDNN version:\r\n10.1 / 7.6.5.32\r\n\r\n- GPU model and memory:\r\nrtx 2070s\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```pip install tensorflow```\r\n\r\n**Any other info / logs**\r\n```\r\n pip install tensorflow\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nCollecting tensorflow\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/34/d5/ce8c17971067c0184c9045112b755be5461d5ce5253ef65a367e1298d7c5/tensorflow-2.1.0-cp37-cp37m-win_amd64.whl (355.8MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 355.9MB 133kB/s\r\nCollecting protobuf>=3.8.0 (from tensorflow)\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/30/c6/286db43e2d0d4b89d328a222365c7a253a99a24067812253f0d4f8eb0f1c/protobuf-3.11.2-cp37-cp37m-win_amd64.whl (1.0MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.0MB 71kB/s\r\nCollecting grpcio>=1.8.6 (from tensorflow)\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8b/14/ab1501cfff78b88d7368659b227c603d7599dd25226ff682c71334e78aed/grpcio-1.26.0-cp37-cp37m-win_amd64.whl (1.8MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.8MB 6.4MB/s\r\nCollecting keras-applications>=1.0.8 (from tensorflow)\r\n  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\r\nCollecting gast==0.2.2 (from tensorflow)\r\nCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 450kB 6.8MB/s\r\nRequirement already satisfied: wrapt>=1.11.1 in c:\\users\\hnjyz\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\r\nRequirement already satisfied: six>=1.12.0 in c:\\users\\hnjyz\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\r\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\hnjyz\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.6)\r\nCollecting absl-py>=0.7.0 (from tensorflow)\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 112kB ...\r\nCollecting astor>=0.6.0 (from tensorflow)\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\r\nCollecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\r\n  ERROR: Could not find a version that satisfies the requirement tensorboard<2.2.0,>=2.1.0 (from tensorflow) (from versions: 1.6.0rc0, 1.6.0, 1.7.0, 1.8.0, 1.9.0, 1.10.0, 1.11.0, 1.12.0, 1.12.1, 1.12.2, 1.13.0, 1.13.1, 1.14.0, 1.15.0, 2.0.0, 2.0.1, 2.0.2)\r\nERROR: No matching distribution found for tensorboard<2.2.0,>=2.1.0 (from tensorflow)\r\n```\r\n", "comments": ["pip install tb-nightly first works for me.", "@DachuanZhao You can try \r\npip install --upgrade tensorflow -i https://pypi.org/simple\r\nIt works for me. The reason is that some package can only be downloaded from the default source.\r\n", "@DachuanZhao ,\r\nPlease try `!pip uninstall tensorflow ` and try installing tensorflow again, kindly find the [gist](https://colab.research.google.com/gist/oanush/9fab338dad3830da3dd74e1cbd568b9f/36380.ipynb) for reference.Thanks!", "pip install -upgrade tensorflow-gpu==2.1.0 works on me.", "pip install -upgrade tensorflow==2.1.0-rc0 works.", "> pip install tb-nightly first works for me.\r\n\r\nYes, it works . Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36380\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36380\">No</a>\n", "Oh, my god. I met the same error, too. So terrible!"]}, {"number": 36379, "title": "Enable TF-TRT explicit batch mode", "body": "This PR adds a new experimental feature to TF-TRT: explicit batch mode. Explicit batch mode is the first step on the way to enable dynamic shapes in TF-TRT (PR #36080).\r\n\r\nThe main advantage of explicit batch mode is the following: the batch dimension is not a special dimension in this mode, which means a single TRT network can have layers with different batch sizes and more importantly operators can manipulate the batch dimension. A [unit test](https://github.com/tfeher/tensorflow/blob/trt_explicit_batch_mode/tensorflow/python/compiler/tensorrt/test/explicit_batch_test.py) demonstrates this for the squeeze op.\r\n\r\nCurrently not all TF-TRT ops support explicit batch mode, it is expected to use this feature for elementwise ops. We are soon going to enable all the existing converters to work with this feature.\r\n\r\nCurrently this feature does not support INT8 calibration.\r\n\r\nThis feature is not supposed to change any of the existing behavior of TF-TRT in any of the various modes.\r\n\r\nThe ground work for this PR was already laid down by @pooyadavoodi in PR #34293. The current PR:\r\n- updates the TRTEngineOp to use newer TensorRT API that allows explicit batch mode (enqueueV2)\r\n- update the converter of squeeze op\r\n- add a unit test to demonstrate explicit batch mode using the squeeze op\r\n\r\nTo turn on this experimental feature, one has to use a rewriter config. Here is an example how to do it:\r\n\r\n```\r\n    root = _model()\r\n    save.save(root, input_saved_model_dir,\r\n              {signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: root.run})\r\n\r\n    rewriter_config_with_trt = rewriter_config_pb2.RewriterConfig()\r\n    rewriter_config_with_trt.optimizers.extend(\r\n        [\"constfold\", \"layout\", \"constfold\"])\r\n    rewriter_config_with_trt.meta_optimizer_iterations = (\r\n        rewriter_config_pb2.RewriterConfig.ONE)\r\n    optimizer = rewriter_config_with_trt.custom_optimizers.add()\r\n    rewriter_config_with_trt.custom_optimizers.add().name = \"constfold\"\r\n    optimizer.name = \"TensorRTOptimizer\"\r\n    optimizer.parameter_map[\"minimum_segment_size\"].i = 1\r\n    optimizer.parameter_map[\"is_dynamic_op\"].b = True\r\n    optimizer.parameter_map[\"maximum_cached_engines\"].i = 1\r\n    optimizer.parameter_map[\"use_implicit_batch\"].b = False\r\n\r\n    conversion_params = trt_convert.DEFAULT_TRT_CONVERSION_PARAMS._replace(\r\n        rewriter_config_template=rewriter_config_with_trt)\r\n    converter = trt_convert.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir,\r\n                                    conversion_params=conversion_params)\r\n    converter.convert()\r\n\r\n    output_saved_model_dir = self.mkdtemp()\r\n    converter.save(output_saved_model_dir=output_saved_model_dir)\r\n```\r\n\r\nTagging @bixia1 for review.", "comments": ["Update: this message was intended for the discussion of #36080, I have also added this comment there. \r\n\r\nHere is a list of PRs related to ~the current one~ #36080. They incrementally add changes that shall make #36080 smaller. Each PR is based on the previous one in the list, please review them in the given order:\r\n1  #36379\r\n2. #36434\r\n3. #36435\r\n4. #36439\r\n5. Add optimizaton profiles (Work in progress)\r\n6. Handle multiple contexts (work in progress)\r\n7. Test deserialization of opt profiles (work in progress)\r\n\r\nAfter these ~the current~ #36080 will be reduced to the following: Enable build mode to generate optimization profiles for dynamic shapes. ", "Seems auto-merge is not happening but the changes are now committed so we can close this. Thank you for the PR."]}, {"number": 36378, "title": "[MLIR][Lite] Update emit_quant_adaptor in PostQuantizePass", "body": "Make separate quant-adaptors for inputs and outputs of model in PostQuantizePass.", "comments": ["@Vooblin Can you please address reviewer comments and keep us posted? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 36377, "title": "unable to import tensorflow after installation- DLL load failed: The specified module could not be found error comes up", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["import tensorflow\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-6-d6579f534729>\", line 1, in <module>\r\n    import tensorflow\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nError in callback <bound method AutoreloadMagics.post_execute_hook of <autoreload.AutoreloadMagics object at 0x000001E4A200A588>> (for post_execute):\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 538, in post_execute_hook\r\n    _, pymtime = self._reloader.filename_and_mtime(sys.modules[modname])\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 184, in filename_and_mtime\r\n    if not hasattr(module, '__file__') or module.__file__ is None:\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\nimport tensorflow as tf\r\nError in callback <bound method AutoreloadMagics.post_execute_hook of <autoreload.AutoreloadMagics object at 0x000001E4A200A588>> (for post_execute):\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 538, in post_execute_hook\r\n    _, pymtime = self._reloader.filename_and_mtime(sys.modules[modname])\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 184, in filename_and_mtime\r\n    if not hasattr(module, '__file__') or module.__file__ is None:\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py3-TF2.0\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "You haven't done any work in this issue: haven't filled in the template, haven't formatted your error message and, most egregiously, haven't checked for duplicates.\r\n\r\nClosing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204"]}, {"number": 36376, "title": "Callbacks should be able to access the training and validation data", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1\r\n- Are you willing to contribute it (Yes/No): Maybe\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, AFAIK, there's no direct way of accessing the training and validation data used for the mini-batch in the `on_batch_end` or `on_batch_begin` methods (in `tf.keras`).  Of course, this feature can be very useful, for example, if you want to debug the training data used for each training or validation mini-batches or, for example, if you want to compute other metrics on the specific batch of data used to update the parameters at each training step. Apparently, it was once possible to access the validation data inside the callback class, but this is no more available (not sure why!). See https://github.com/tensorflow/tensorflow/issues/36375. The training data for the mini-batch was never available, AFAIK.\r\n\r\nI have seen people trying to access the training and validation data (used in the current mini-batch/step) in the callbacks, and the solutions are simply disgustingly verbose, inflexible, etc. (see https://stackoverflow.com/q/47079111/3924118). \r\n\r\nWhy don't you provide this feature? This is clearly a useful feature (e.g. [this SO question](https://stackoverflow.com/q/53489352/3924118) shows that this feature would be appreciated). See also https://stackoverflow.com/q/47676248/3924118.\r\n\r\n**Will this change the current api? How?**\r\n\r\nProbably.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nEveryone.\r\n", "comments": ["@nbro Sorry for the late response. Are you still interested in contributing? If yes, please feel free to open a PR in  [keras-team/keras repo.](https://github.com/keras-team/keras/issues) repository.\r\n\r\nPlease note that Keras development moved to keras-team/keras repository to focus on only keras. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}]