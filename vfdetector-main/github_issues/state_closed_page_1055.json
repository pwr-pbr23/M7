[{"number": 21638, "title": "[XLA] ResourceExhaustedError when trying to define a Sequential model in Keras under jit_scope context manager", "body": "Intel i5-2430M, 6 GB RAM\r\nLinux Ubuntu 16.04 | Python 3.6.5 | Bazel 0.16.0 | GCC 5.4.0\r\nTensorFlow 1.8 compiled from source with MKL and XLA support\r\n\r\n---\r\n\r\nSo, my issue is that I try to use XLA for CPU via Keras that is embedded in TensorFlow 1.8 using the `tf.contrib.compiler.jit.experimental_jit_scope` (for CPU it's the only way I know to enable XLA, using `ConfigProto` doesn't work on CPU for me). For some strange reason I am thrown `ResourceExhaustedError` when trying to allocate 0 bytes.  Looks like something's wrong, either in TensorFlow or Keras. Below is the listing of the code I use and the full trace.\r\n\r\n### Code\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import timeline\r\n\r\nimport numpy as np\r\n\r\nJIT_SCOPE = tf.contrib.compiler.jit.experimental_jit_scope\r\n\r\noptions = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)                   \r\nrun_metadata = tf.RunMetadata()\r\n\r\n(train_x, train_y), _ = tf.keras.datasets.mnist.load_data()\r\n\r\ntrain_x = np.expand_dims(train_x, axis=-1) / 255.\r\ntrain_y = tf.keras.utils.to_categorical(train_y)\r\n\r\nwith JIT_SCOPE():                                                               \r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\r\n        tf.keras.layers.MaxPool2D((2, 2)),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(10, activation=\"softmax\")\r\n    ])\r\n\r\n    model.compile(\"sgd\", \"categorical_crossentropy\", options=options, run_metadata=run_metadata)\r\n\r\nmodel.fit(train_x, train_y) # error happens at this moment\r\n\r\ntrace = timeline.Timeline(step_stats=run_metadata.step_stats)\r\nwith open(\"timeline.ctr.json\", \"w\") as f:\r\n    f.write(trace.generate_chrome_trace_format())\r\n\r\n```\r\n\r\n### Traceback\r\n\r\n```\r\nEpoch 1/1\r\n2018-08-15 20:28:54.784459: I tensorflow/compiler/xla/service/service.cc:159] XLA service 0x7f70ec071a30 executing computations on platform Host. Devices:\r\n2018-08-15 20:28:54.784509: I tensorflow/compiler/xla/service/service.cc:167]   StreamExecutor device (0): <undefined>, <undefined>\r\n2018-08-15 20:28:55.548381: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\r\n2018-08-15 20:28:55.548481: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n2018-08-15 20:28:55.561315: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\r\n2018-08-15 20:28:55.561365: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1321     try:\r\n-> 1322       return fn(*args)\r\n   1323     except errors.OpError as e:\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1306       return self._call_tf_sessionrun(\r\n-> 1307           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1308 \r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1408           self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1409           run_metadata)\r\n   1410     else:\r\n\r\nResourceExhaustedError: Out of memory while trying to allocate 0 bytes.\r\n\t [[Node: cluster_1/_4/_5 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_1[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-46-dbab7a29ab1f> in <module>()\r\n----> 1 model.fit(train_x[:1000], train_y[:1000], epochs=1)\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1214           initial_epoch=initial_epoch,\r\n   1215           steps_per_epoch=steps_per_epoch,\r\n-> 1216           validation_steps=validation_steps)\r\n   1217 \r\n   1218   def evaluate(self,\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays.py in fit_loop(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\r\n    243           ins_batch[i] = ins_batch[i].toarray()\r\n    244 \r\n--> 245         outs = f(ins_batch)\r\n    246         if not isinstance(outs, list):\r\n    247           outs = [outs]\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in __call__(self, inputs)\r\n   2797       feed_dict = {}\r\n   2798 \r\n-> 2799     session = get_session()\r\n   2800     data_tensors_to_feed = []\r\n   2801     for tensor, value in zip(self.inputs, inputs):\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in get_session()\r\n    440   if not _MANUAL_VAR_INIT:\r\n    441     with session.graph.as_default():\r\n--> 442       _initialize_variables(session)\r\n    443   return session\r\n    444 \r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in _initialize_variables(session)\r\n    671       v._keras_initialized = True\r\n    672     if uninitialized_vars:\r\n--> 673       session.run(variables_module.variables_initializer(uninitialized_vars))\r\n    674 \r\n    675 \r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    898     try:\r\n    899       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 900                          run_metadata_ptr)\r\n    901       if run_metadata:\r\n    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1134       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1135                              feed_dict_tensor, options, run_metadata)\r\n   1136     else:\r\n   1137       results = []\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1314     if handle is None:\r\n   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1316                            run_metadata)\r\n   1317     else:\r\n   1318       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n~/Work/2018_Summer_CERN/tf_v_tmva/tf_opt/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1333         except KeyError:\r\n   1334           pass\r\n-> 1335       raise type(e)(node_def, op, message)\r\n   1336 \r\n   1337   def _extend_graph(self):\r\n\r\nResourceExhaustedError: Out of memory while trying to allocate 0 bytes.\r\n\t [[Node: cluster_1/_4/_5 = _XlaLaunch[Nresources=0, Targs=[], Tconstants=[], Tresults=[DT_FLOAT], function=cluster_1[_XlaCompiledKernel=true, _XlaNumConstantArgs=0, _XlaNumResourceArgs=0], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "How is this not a bug? In the trace it shows that it tries to allocate 0 bytes and fails, which is strange, and surely not a problem on my side of the code. The problem might be on Keras side tho, but I am not sure.\r\nAll the information requested from the issue template is in the issue already, just formatted in an unorthodox way.", "Hi @AlexandruBurlacu \r\nI was able to execute your code successfully in TensorFlow 1.11\r\nCan you please update your TensorFlow version and try it?\r\nMeanwhile I will create a virtual env for TF 1.8 and execute the script again.", "Quick update I was able to run the script successfully in version TF 1.8 as well.\r\nSo I don't think this is a problem on Keras side as well.", "Interesting, I will check it again and come back with the results on my side. Thank you anyway!"]}, {"number": 21637, "title": "Tensorflow Prediction Artifacts", "body": "### System Information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 18\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: v1.10.0-0-g656e7a2b34 1.10.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0.176/7.1.2\r\n- **GPU model and memory**: Tesla P40 24GB\r\n- **Exact command to reproduce**: python3 example.py\r\n\r\n### Describe the problem\r\nHello,\r\nI am using Tensorflow on 3D image data and I observe some strange prediction artifacts once my input exceeds a certain size.\r\nI created a minimal working example (below) which produces the artifacts. In the example all weights of the loaded u-net are initialized to 0.5 and then a 3D volume (Z: 180, Y: 196, X: 240) with a gradient in Z direction is given as prediction input. The returned output contains the gradient up to Z around 140 and then the output values change to smaller values. \r\n![observation](https://user-images.githubusercontent.com/5450869/44163361-7661fc00-a0c3-11e8-8c67-a3524370b632.png)\r\n\r\nIf a slightly smaller 3D volume (Z: 176, Y: 196, X: 240) is given, the output contains the full gradient as expected. \r\n\r\nUnfortunately I don't know if this is a TensorFlow, CUDA, cuDNN or some other sort of bug. I am grateful for any explanation or any hints on what it could be or how to fix this issue (without cropping/tiling the input).\r\n\r\n### Source code / logs\r\n\r\nThe minimum example:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import model_from_json\r\nimport numpy as np\r\nfrom tifffile import imsave\r\n\r\n# load u-net architecture, kernel-size = 3, depth = 2\r\njson_file = open('model.json', 'r')\r\nloaded_model_json = json_file.read()\r\njson_file.close()\r\nmodel = model_from_json(loaded_model_json)\r\n\r\n# set all weights to 0.5\r\nw = model.get_weights()\r\ninit = []\r\nfor l in w:\r\n    init.append(l*0 + 0.5)\r\n\r\nmodel.set_weights(init)\r\n\r\ntmp = np.zeros((180, 196, 240), np.float32)\r\nfor i in range(tmp.shape[0]):\r\n    tmp[i] = i\r\n\r\ntmp = tmp[:, :, :, np.newaxis]\r\n\r\nprediction_fail = np.moveaxis(model.predict(np.moveaxis(tmp[np.newaxis], 4, -1))[0], 3, 0)\r\ntmp = tmp[:176]\r\nprediction_succ = np.moveaxis(model.predict(np.moveaxis(tmp[np.newaxis], 4, -1))[0], 3, 0)\r\n\r\nimsave('input.tif', tmp)\r\nimsave('prediction_fail.tif', prediction_fail[0])\r\nimsave('prediction_success.tif', prediction_succ[0])\r\n```\r\n\r\nThe model.json with the u-net architecture:\r\n```\r\n{\"class_name\": \"Model\", \"config\": {\"name\": \"model_3\", \"layers\": [{\"name\": \"input\", \"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, null, null, null, 1], \"dtype\": \"float32\", \"sparse\": false, \"name\": \"input\"}, \"inbound_nodes\": []}, {\"name\": \"down_level_0_no_0\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"down_level_0_no_0\", \"trainable\": true, \"filters\": 32, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"input\", 0, 0, {}]]]}, {\"name\": \"down_level_0_no_1\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"down_level_0_no_1\", \"trainable\": true, \"filters\": 32, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"down_level_0_no_0\", 0, 0, {}]]]}, {\"name\": \"max_0\", \"class_name\": \"MaxPooling3D\", \"config\": {\"name\": \"max_0\", \"trainable\": true, \"pool_size\": [2, 2, 2], \"padding\": \"valid\", \"strides\": [2, 2, 2], \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"down_level_0_no_1\", 0, 0, {}]]]}, {\"name\": \"down_level_1_no_0\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"down_level_1_no_0\", \"trainable\": true, \"filters\": 64, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"max_0\", 0, 0, {}]]]}, {\"name\": \"down_level_1_no_1\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"down_level_1_no_1\", \"trainable\": true, \"filters\": 64, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"down_level_1_no_0\", 0, 0, {}]]]}, {\"name\": \"max_1\", \"class_name\": \"MaxPooling3D\", \"config\": {\"name\": \"max_1\", \"trainable\": true, \"pool_size\": [2, 2, 2], \"padding\": \"valid\", \"strides\": [2, 2, 2], \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"down_level_1_no_1\", 0, 0, {}]]]}, {\"name\": \"middle_0\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"middle_0\", \"trainable\": true, \"filters\": 128, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"max_1\", 0, 0, {}]]]}, {\"name\": \"middle_2\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"middle_2\", \"trainable\": true, \"filters\": 64, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"middle_0\", 0, 0, {}]]]}, {\"name\": \"up_sampling3d_5\", \"class_name\": \"UpSampling3D\", \"config\": {\"name\": \"up_sampling3d_5\", \"trainable\": true, \"size\": [2, 2, 2], \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"middle_2\", 0, 0, {}]]]}, {\"name\": \"concatenate_5\", \"class_name\": \"Concatenate\", \"config\": {\"name\": \"concatenate_5\", \"trainable\": true, \"axis\": -1}, \"inbound_nodes\": [[[\"up_sampling3d_5\", 0, 0, {}], [\"down_level_1_no_1\", 0, 0, {}]]]}, {\"name\": \"up_level_1_no_0\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"up_level_1_no_0\", \"trainable\": true, \"filters\": 64, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"concatenate_5\", 0, 0, {}]]]}, {\"name\": \"up_level_1_no_2\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"up_level_1_no_2\", \"trainable\": true, \"filters\": 32, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"up_level_1_no_0\", 0, 0, {}]]]}, {\"name\": \"up_sampling3d_6\", \"class_name\": \"UpSampling3D\", \"config\": {\"name\": \"up_sampling3d_6\", \"trainable\": true, \"size\": [2, 2, 2], \"data_format\": \"channels_last\"}, \"inbound_nodes\": [[[\"up_level_1_no_2\", 0, 0, {}]]]}, {\"name\": \"concatenate_6\", \"class_name\": \"Concatenate\", \"config\": {\"name\": \"concatenate_6\", \"trainable\": true, \"axis\": -1}, \"inbound_nodes\": [[[\"up_sampling3d_6\", 0, 0, {}], [\"down_level_0_no_1\", 0, 0, {}]]]}, {\"name\": \"up_level_0_no_0\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"up_level_0_no_0\", \"trainable\": true, \"filters\": 32, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"concatenate_6\", 0, 0, {}]]]}, {\"name\": \"up_level_0_no_2\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"up_level_0_no_2\", \"trainable\": true, \"filters\": 32, \"kernel_size\": [3, 3, 3], \"strides\": [1, 1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"up_level_0_no_0\", 0, 0, {}]]]}, {\"name\": \"conv3d_3\", \"class_name\": \"Conv3D\", \"config\": {\"name\": \"conv3d_3\", \"trainable\": true, \"filters\": 1, \"kernel_size\": [1, 1, 1], \"strides\": [1, 1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1, 1], \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"up_level_0_no_2\", 0, 0, {}]]]}, {\"name\": \"add_19\", \"class_name\": \"Add\", \"config\": {\"name\": \"add_19\", \"trainable\": true}, \"inbound_nodes\": [[[\"conv3d_3\", 0, 0, {}], [\"input\", 0, 0, {}]]]}, {\"name\": \"activation_52\", \"class_name\": \"Activation\", \"config\": {\"name\": \"activation_52\", \"trainable\": true, \"activation\": \"linear\"}, \"inbound_nodes\": [[[\"add_19\", 0, 0, {}]]]}], \"input_layers\": [[\"input\", 0, 0]], \"output_layers\": [[\"activation_52\", 0, 0]]}, \"keras_version\": \"2.2.0\", \"backend\": \"tensorflow\"}\r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nGPU model and memory\nExact command to reproduce\nMobile device", "Hello\r\n\r\nI am observing same behavior (of example.py) on a totally different system:\r\n\r\nOS Platform: Windows 10\r\nCUDA/cuDNN version: 9.0.176/7.1.4\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version: 1.9.0\r\nPython version: 3.6\r\nGPU model and memory: nvidia geforce gtx 1070, 8 GB\r\n\r\n\r\n\r\n\r\n", "@fchollet Can you take a look at this?  Is it an incompatibility between the input size and the model definition, or does it look like a bug somewhere?", "Hello even i am facing the same issue on windows 10,can anyone help?", "for the record, I tested this code in a tf 1.8 and 1.10 container obtained from [dockerhub](https://hub.docker.com/r/tensorflow/tensorflow/) with Nvidia driver 384.145 and the artifact cannot be seen!\r\n\r\nI then did the same in a tf installation, produced by following the suggested method in the [online tensorflow documentation](https://www.tensorflow.org/install/install_linux#InstallingVirtualenv). Interestingly the artifact did appear! \r\n\r\n", "same setup with virtualenv and tf1.10, a TitanXp and nvidia driver 390.42 ... no artifact (also using the containers mentioned above). could it be the wheels contain problematic ptx for the P40?\r\n@tomasvicar what is the version of your nvidia driver?", "Hello, i also encountered this issue.\r\nI isolated the layer in my network that produced this artefact: it comes from the operation Conv3D.\r\nIt doesn't occur for every input size, output channel, or kernel size.\r\n\r\nHere is the code i used to reproduce the behaviour:\r\n```\r\nfrom keras.models import Model\r\nfrom keras.layers import Input, Conv3D\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\ndef conv_model_kernel_1(in_channel, out_channel):\r\n    inputs = Input((None, None, None, in_channel))\r\n    output = Conv3D(out_channel, kernel_size=1, padding='same', kernel_initializer='ones', bias_initializer='zeros')(inputs)\r\n    return Model(inputs, output)\r\n\r\nchannels = 32\r\nvolume = np.ones((202, 236, 185, channels))\r\nnet = conv_model_kernel_1(channels, channels)\r\nconv_keras = net.predict(np.expand_dims(volume, 0))\r\n\r\nplt.figure()\r\nplt.imshow(conv_keras[0, :, :, 0, 0])\r\nplt.show()\r\n```\r\n\r\nThe network as defined previously should take every input channel and sum them in each output channel. Each voxel of each volume contained in every output channel should have the same value : 32.\r\n\r\nHere the slice 0 of the output predicted volume contained in channel 0:\r\n![conv3dartifact](https://user-images.githubusercontent.com/24569806/44464042-eb7c8680-a619-11e8-969a-809973f84650.png)\r\n\r\nYellow pixels are 32s, purple ones are 0s.\r\n\r\nI tested this code on different system configurations and everytime it produced the artifact.\r\n\r\nI'd be thankful if you could take a look.\r\nThanks\r\n", "Hi @lucncdm \r\nThat is an even better minimal example!\r\nIs your tf installation in an environment or is it a docker? It looks like the artifact is __not__ appearing in the docker.", "Hi @tibuch \r\nI compiled tensorflow from source using bazel. I didn't try using a docker yet.\r\nHere is my system configuration, just in case:\r\nCentOs\r\ntensorflow: 1.7\r\nkeras: 2.0.9\r\ncuda: 9.1\r\ncudnn: 7.1\r\nnvidia driver: 390.48\r\n\r\nEDIT1: I ran the same code with tf 1.10 compiled from source this time and the artifact doesn't appear\r\nEDIT2: Artifact still appears for different volume input shapes", "Hi, \r\n\r\nI've seen the same prediction artifacts with CUDA 9.0, tf 1.12, cudnn 7.4.2 and even for more innocuous input shapes (e.g. `96, 480, 480`). **The solution was to install all the CUDA 9.0 patches** that are listed at the [installation page](https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1704&target_type=runfilelocal). Afterwards, all was back to normal. \r\n\r\nThe following should indicate whether these patches were installed (thx @uschmidt83):\r\n\r\n```\r\ncat /usr/local/cuda/version.txt \r\nCUDA Version 9.0.176\r\nCUDA Patch Version 9.0.176.1\r\nCUDA Patch Version 9.0.176.2\r\nCUDA Patch Version 9.0.176.3\r\nCUDA Patch Version 9.0.176.4\r\n```", "Hi @tibuch !\r\nWe are checking to see whether you still need help in this issue . Have you tried latest versions TF 2.6/2.7 yet? . Thanks!", "I tried out the small example of @lucncdm with CUDA 10.1.243, CUDNN 7.6.5 and TensorFlow 2.3.0 on a NVIDIA GeForce GTX 1080 Ti with NVIDIA driver 470.57.02 and the error did __not__ show up.\r\n\r\nI also tried both examples with TF 2.7 CPU and the error did not show up.", "Ok! @tibuch ,Thanks for confirming the same! Closing this issue as it seems to be resolved .", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21637\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21637\">No</a>\n"]}, {"number": 21636, "title": "dataset cache, repeat problem", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new). Please provide all the information it asks. Thank you.\r\n\r\n(It seems that the issue just contains the template, no details were provided. I'm guessing that is a mistake, so feel free to re-open with all the details or file a new issue with them)\r\n", "Hi Asimshankar;\r\n\r\ntks for follow up. I guess I figured out the issue basically i tried to start the data with np.nan for the dataset. with cache and repeat, for some reason, the value of np.nan is changed by the program sometimes and my code can not detect the np.nan which i used it to mark the new batch as there is no such api with the repeat dataset indicates the end of one cycle.\r\n\r\ni used additional data with the number to detect and it works now. \r\n\r\nthe issue is the repeat cache dataset changes the value of np.nan sometimes.\r\n\r\nJian"]}, {"number": 21635, "title": "Can't compile frozen facenet graph ", "body": "Have I written custom code: NO\r\nOS Platform and Distribution: Ubuntu 16.04 x86_64\r\nTensorFlow installed from: github, from source\r\nTensorFlow version: 1.9\r\nBazel version: 0.16.1\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: \r\n`./tfcompile --graph=frozen_20170512-110547.pb --config=frozen_20170512-110547.pbtxt --cpp_class=\"my_super_class\" --target_features=\"+avx2\"`\r\nMobile device: No\r\n\r\nMy .pbtx:\r\n```\r\nfeed {\r\n  id { node_name: \"input\" }\r\n  shape {\r\n    dim { size: 160 }\r\n    dim { size: 160 }\r\n  }\r\n}\r\n\r\nfetch {\r\n  id { node_name: \"embeddings\" }\r\n}\r\n```\r\nAnd I've got this:\r\nINVALID ARGUMENTS: Unable to functionalize control flow in graph: Switch ('InceptionResnetV1/Conv2d_1a_3x3/BatchNorm/cond/Switch_1') has operands ('InceptionResnetV1/Conv2d_1a_3x3/BatchNorm/cond/Switch_1/Switch' and 'InceptionResnetV1/Conv2d_1a_3x3/BatchNorm/cond/pred_id') that have different switch depths (1 != 0)\r\n \r\nWhat Do I do wrong?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device"]}, {"number": 21634, "title": "Compilation Error: suffix or operands invalid for `vpaddd'", "body": "Hi,\r\ni'm trying to install tensorflow with CUDA support and I have the following issue whe i execute \r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n\r\nERROR: \r\n/home/user/.cache/bazel/_bazel_user/95b102d38f4be088a2028c5510fdf1c2/external/boringssl/BUILD:130:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\ncd /home/user/.cache/bazel/_bazel_user/95b102d38f4be088a2028c5510fdf1c2/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/share/apps/libxc-3.0.1/lib/:/share/apps/libgpuarray/lib/:/opt/python/lib/:/share/apps/gcc-6.3.0/lib64:/opt/gridengine/lib/linux-x64 \\\r\n    PATH=/share/apps/python/python2.7/bin/:/opt/python/bin/:/share/apps/cmake-3.9.1/bin:/share/apps/gcc-6.3.0/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/bio/ncbi/bin:/opt/bio/mpiblast/bin:/opt/bio/EMBOSS/bin:/opt/bio/clustalw/bin:/opt/bio/tcoffee/bin:/opt/bio/hmmer/bin:/opt/bio/phylip/exe:/opt/bio/mrbayes:/opt/bio/fasta:/opt/bio/glimmer/bin:/opt/bio/glimmer/scripts:/opt/bio/gromacs/bin:/opt/bio/gmap/bin:/opt/bio/tigr/bin:/opt/bio/autodocksuite/bin:/opt/bio/wgs/bin:/opt/eclipse:/opt/ganglia/bin:/opt/ganglia/sbin:/usr/java/latest/bin:/opt/rocks/bin:/opt/rocks/sbin:/opt/gridengine/bin/linux-x64:/share/apps/local/bin:/home/user/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/external/boringssl/_objs/crypto/chacha20_poly1305_x86_64.pic.d -iquote external/boringssl -iquote bazel-out/host/genfiles/external/boringssl -iquote bazel-out/host/bin/external/boringssl -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -iquote bazel-out/host/bin/external/bazel_tools -isystem external/boringssl/src/include -isystem bazel-out/host/genfiles/external/boringssl/src/include -isystem bazel-out/host/bin/external/boringssl/src/include -g0 '-march=native' -Wa,--noexecstack '-D_XOPEN_SOURCE=700' -Wall -Werror '-Wformat=2' -Wsign-compare -Wmissing-field-initializers -Wwrite-strings -Wshadow -fno-common '-std=c11' -Wmissing-prototypes -Wold-style-definition -Wstrict-prototypes -c external/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S -o bazel-out/host/bin/external/boringssl/_objs/crypto/chacha20_poly1305_x86_64.pic.o)\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S: Assembler messages:\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4104: Error: no such instruction: `vbroadcasti128 0(%r9),%ymm4'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4105: Error: no such instruction: `vbroadcasti128 16(%r9),%ymm8'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4106: Error: no such instruction: `vbroadcasti128 32(%r9),%ymm12'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4107: Error: suffix or operands invalid for `vpaddd'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4118: Error: suffix or operands invalid for `vpaddd'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4119: Error: suffix or operands invalid for `vpxor'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4120: Error: suffix or operands invalid for `vpshufb'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4121: Error: suffix or operands invalid for `vpaddd'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4122: Error: suffix or operands invalid for `vpxor'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4123: Error: suffix or operands invalid for `vpsrld'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4124: Error: suffix or operands invalid for `vpslld'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4125: Error: suffix or operands invalid for `vpxor'\r\nexternal/boringssl/linux-x86_64/crypto/cipher_extra/chacha20_poly1305_x86_64.S:4126: Error: suffix or operands invalid for `vpaddd'\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Thanks for the answer. \r\nOS: CentOS 6.2\r\nTensorflow installed from source.\r\nTensorflow version: 1.10\r\nPython version: 2.7\r\nBazel version: 0.16.0\r\nGCC version: 6.3.0\r\nCUDA 8.0\r\ncuDNN: 6.0\r\nGPU: GeForce GTX 770\r\nCommand:\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures", "I got the similar error when i install tensorflow without CUDA\r\n\r\nERROR: /home/user/.cache/bazel/_bazel_user/539629cca61901b68a2179672fed247c/external/boringssl/BUILD:115:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1)\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/p256-x86_64-asm.S: Assembler messages:\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/p256-x86_64-asm.S:638: Error: suffix or operands invalid for `vpxor'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/p256-x86_64-asm.S:639: Error: suffix or operands invalid for `vpxor'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/p256-x86_64-asm.S:640: Error: suffix or operands invalid for `vpxor'\r\n...\r\n\r\nOS:Alibaba Group Enterprise Linux Server release 6.2 (DogTag)\r\nTensorflow installed from source.\r\nTensorflow version: 1.10\r\nPython version: 3.6\r\nBazel version: 0.15.2\r\nGCC version: 7.2.0\r\nCommand:\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nThanks!", "Hi,\r\nI resolved the issue by adding \"binutils 2.29\" to the environment variables PATH and LD_LIBRARY_PATH:\r\nPATH=/share/apps/binutils/binutils-2.29.1/bin/:$PATH\r\nLD_LIBRARY_PATH=/share/apps/binutils/binutils-2.29.1/lib/:$LD_LIBRARY_PATH\r\n"]}, {"number": 21633, "title": "TFLite Model Benchmark Tool : tensorflow/contrib/lite/error_reporter.cc:52: error: undefined reference to '__android_log_vprint'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Macbook Pro  10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: 1.10.0\r\n- **TensorFlow version (use command below)**:  tf.VERSION = 1.10.0\r\n- **Python version**: Python 2.7.10\r\n- **Bazel version (if compiling from source)**: bazel release 0.15.2-homebrew\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.1.0 (clang-902.0.39.2)\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n-**Android SDK Version : Android SDK Platform 28\r\n-**ANdroid NDK Version : android-ndk-r14b\r\n- **Exact command to reproduce**:\r\nbazel build -c opt \\\r\n  --config=android_arm \\\r\n  --cxxopt='--std=c++11' \\\r\n  tensorflow/contrib/lite/tools/benchmark:benchmark_model\r\n\r\n\r\n### Describe the problem\r\nI am trying to build the benchmark_model for android for the TFLite Model Benchmark Tool, but I get an \"error: undefined reference to '__android_log_vprint'\" error.\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/tools/benchmark#reducing-variance-between-runs-on-android\r\n\r\nbazel build -c opt \\\r\n  --config=android_arm \\\r\n  --cxxopt='--std=c++11' \\\r\n  tensorflow/contrib/lite/tools/benchmark:benchmark_model\r\n\r\n### Source code / logs\r\n\r\nERROR: \r\ntensorflow/contrib/lite/error_reporter.cc:52: error: undefined reference to '__android_log_vprint'\r\ntensorflow/contrib/lite/nnapi_delegate.cc:45: error: undefined reference to '__android_log_vprint'\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nTarget //tensorflow/contrib/lite/tools/benchmark:benchmark_model failed to build\r\n\r\n", "comments": ["I solved the problem through the stackoverflow link below. I fixed the problem by adding the option --linkopt = '- llog'.\r\n\r\nhttps://stackoverflow.com/questions/48850364/failed-to-load-android-log-print-in-libtensorflowlite-jni-so/48850600#48850600?newreg=7a617742737e420fb1846cc2406323a2\r\n\r\nbazel build -c opt \\\r\n--config = android_arm \\\r\n--cxxopt = '- std = c ++ 11' \\\r\n--linkopt = '- llog' \\\r\ntensorflow / contrib / lite / tools / benchmark: benchmark_model"]}, {"number": 21632, "title": "Python free error", "body": "```\r\n*** Error in `python': free(): invalid pointer: 0x00007fe15f3e5340 ***\r\n```\r\nThe above error happened when I included the following 2 lines.\r\n```\r\nfrom tensorflow.python.ops import math_ops\r\nfrom tensorflow.contrib.boosted_trees.python.ops import quantile_ops\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I managed to do the operations outside tensorflow using Numpy. But the problem hasn't been solved yet.", "@HenryZhou7 Is this still an issue? Can you please update your system information? It will help to guide you better.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I am getting the same issue when trying to use tf.contrib.losses even when just \r\n```\r\nimport tensorflow as tf \r\ntf.contrib.losses\r\n```\r\n\r\nsystem: \r\nconda with python 3.6 \r\nlist of packages: \r\n\r\n_license                  1.1                      py36_1  \r\nabsl-py                   0.6.1                 py36_1000    conda-forge\r\nalabaster                 0.7.10                   py36_0  \r\nanaconda                  custom                   py36_0  \r\nanaconda-client           1.6.3                    py36_0  \r\nanaconda-navigator        1.6.4                    py36_0  \r\nanaconda-project          0.6.0                    py36_0  \r\nasn1crypto                0.22.0                   py36_0  \r\nastor                     0.7.1                      py_0    conda-forge\r\nastroid                   1.5.3                    py36_0  \r\nastropy                   2.0.1               np113py36_0  \r\nbabel                     2.5.0                    py36_0  \r\nbackports                 1.0                      py36_0  \r\nbackports.weakref         1.0rc1                   py36_0  \r\nbeautifulsoup4            4.6.0                    py36_0  \r\nbitarray                  0.8.1                    py36_0  \r\nbkcharts                  0.2                      py36_0  \r\nblas                      1.1                    openblas    conda-forge\r\nblaze                     0.10.1                   py36_0  \r\nbleach                    1.5.0                    py36_0  \r\nbokeh                     0.12.7                   py36_0  \r\nboto                      2.48.0                   py36_0  \r\nbottleneck                1.2.1               np113py36_0  \r\nc-ares                    1.15.0               h470a237_1    conda-forge\r\nca-certificates           2018.11.29           ha4d7672_0    conda-forge\r\ncairo                     1.14.8                        0  \r\ncertifi                   2016.2.28                py36_0  \r\ncffi                      1.10.0                   py36_0  \r\nchardet                   3.0.4                    py36_0  \r\nclick                     6.7                      py36_0  \r\ncloudpickle               0.4.0                    py36_0  \r\nclyent                    1.2.2                    py36_0  \r\ncolorama                  0.3.9                    py36_0  \r\ncontextlib2               0.5.5                    py36_0  \r\ncryptography              1.8.1                    py36_0  \r\ncudatoolkit               8.0                           3  \r\ncudnn                     6.0.21                cuda8.0_0  \r\ncurl                      7.52.1                        0  \r\ncycler                    0.10.0                   py36_0  \r\ncython                    0.26                     py36_0  \r\ncytoolz                   0.8.2                    py36_0  \r\ndask                      0.15.2                   py36_0  \r\ndatashape                 0.5.4                    py36_0  \r\ndbus                      1.10.20                       0  \r\ndecorator                 4.1.2                    py36_0  \r\ndistributed               1.18.1                   py36_0  \r\ndocutils                  0.14                     py36_0  \r\nentrypoints               0.2.3                    py36_0  \r\net_xmlfile                1.0.1                    py36_0  \r\nexpat                     2.1.0                         0  \r\nfastcache                 1.0.2                    py36_1  \r\nflask                     0.12.2                   py36_0  \r\nflask-cors                3.0.3                    py36_0  \r\nfontconfig                2.12.1                        3  \r\nfreetype                  2.5.5                         2  \r\ngast                      0.2.0                      py_0    conda-forge\r\nget_terminal_size         1.0.0                    py36_0  \r\ngevent                    1.2.2                    py36_0  \r\nglib                      2.50.2                        1  \r\ngreenlet                  0.4.12                   py36_0  \r\ngrpcio                    1.16.0           py36hd60e7a3_0    conda-forge\r\ngst-plugins-base          1.8.0                         0  \r\ngstreamer                 1.8.0                         0  \r\nh5py                      2.7.0               np113py36_0  \r\nharfbuzz                  0.9.39                        2  \r\nhdf5                      1.8.17                        2  \r\nheapdict                  1.0.0                    py36_1  \r\nhtml5lib                  0.9999999                py36_0  \r\nicu                       54.1                          0  \r\nidna                      2.6                      py36_0  \r\nimagesize                 0.7.1                    py36_0  \r\nipykernel                 4.6.1                    py36_0  \r\nipython                   6.1.0                    py36_0  \r\nipython_genutils          0.2.0                    py36_0  \r\nipywidgets                6.0.0                    py36_0  \r\nisort                     4.2.15                   py36_0  \r\nitsdangerous              0.24                     py36_0  \r\njbig                      2.1                           0  \r\njdcal                     1.3                      py36_0  \r\njedi                      0.10.2                   py36_2  \r\njinja2                    2.9.6                    py36_0  \r\njpeg                      9b                            0  \r\njsonschema                2.6.0                    py36_0  \r\njupyter                   1.0.0                    py36_3  \r\njupyter_client            5.1.0                    py36_0  \r\njupyter_console           5.2.0                    py36_0  \r\njupyter_core              4.3.0                    py36_0  \r\nkeras                     2.2.4                    py36_0    conda-forge\r\nkeras-applications        1.0.4                      py_1    conda-forge\r\nkeras-preprocessing       1.0.2                      py_1    conda-forge\r\nlazy-object-proxy         1.3.1                    py36_0  \r\nlibffi                    3.2.1                         1  \r\nlibgcc                    5.2.0                         0  \r\nlibgcc-ng                 7.2.0                hdf63c60_3    conda-forge\r\nlibgfortran               3.0.0                         1  \r\nlibgpuarray               0.6.9                         0  \r\nlibiconv                  1.14                          0  \r\nlibpng                    1.6.30                        1  \r\nlibprotobuf               3.6.1                hd28b015_0    conda-forge\r\nlibsodium                 1.0.10                        0  \r\nlibstdcxx-ng              7.2.0                hdf63c60_3    conda-forge\r\nlibtiff                   4.0.6                         3  \r\nlibtool                   2.4.2                         0  \r\nlibtorch                  0.1.12                  nomkl_0  [nomkl]\r\nlibxcb                    1.12                          1  \r\nlibxml2                   2.9.4                         0  \r\nlibxslt                   1.1.29                        0  \r\nllvmlite                  0.20.0                   py36_0  \r\nlocket                    0.2.0                    py36_1  \r\nlxml                      3.8.0                    py36_0  \r\nmako                      1.0.6                    py36_0  \r\nmarkdown                  2.6.9                    py36_0  \r\nmarkupsafe                1.0                      py36_0  \r\nmatplotlib                2.0.2               np113py36_0  \r\nmistune                   0.7.4                    py36_0  \r\nmkl                       2017.0.3                      0  \r\nmkl-service               1.1.2                    py36_3  \r\nmpmath                    0.19                     py36_1  \r\nmsgpack-python            0.4.8                    py36_0  \r\nmultipledispatch          0.4.9                    py36_0  \r\nnavigator-updater         0.1.0                    py36_0  \r\nnbconvert                 5.2.1                    py36_0  \r\nnbformat                  4.4.0                    py36_0  \r\nnccl                      1.3.4                 cuda8.0_1  \r\nnetworkx                  1.11                     py36_0  \r\nnltk                      3.2.4                    py36_0  \r\nnose                      1.3.7                    py36_1  \r\nnotebook                  5.0.0                    py36_0  \r\nnumba                     0.35.0              np113py36_0  \r\nnumexpr                   2.6.9            py36hf8a1672_0    conda-forge\r\nnumpy                     1.13.3          py36_blas_openblas_200  [blas_openblas]  conda-forge\r\nnumpydoc                  0.7.0                    py36_0  \r\nodo                       0.5.1                    py36_0  \r\nolefile                   0.44                     py36_0  \r\nopenblas                  0.2.19                        2    conda-forge\r\nopenpyxl                  2.4.8                    py36_0  \r\nopenssl                   1.0.2p               h470a237_1    conda-forge\r\npackaging                 16.8                     py36_0  \r\npandas                    0.20.3                   py36_0  \r\npandocfilters             1.4.2                    py36_0  \r\npango                     1.40.3                        1  \r\npartd                     0.3.8                    py36_0  \r\npath.py                   10.3.1                   py36_0  \r\npathlib2                  2.3.0                    py36_0  \r\npatsy                     0.4.1                    py36_0  \r\npcre                      8.39                          1  \r\npep8                      1.7.0                    py36_0  \r\npexpect                   4.2.1                    py36_0  \r\npickleshare               0.7.4                    py36_0  \r\npillow                    4.2.1                    py36_0  \r\npip                       9.0.1                    py36_1  \r\npixman                    0.34.0                        0  \r\nply                       3.10                     py36_0  \r\nprompt_toolkit            1.0.15                   py36_0  \r\nprotobuf                  3.6.1            py36hfc679d8_1    conda-forge\r\npsutil                    5.2.2                    py36_0  \r\nptyprocess                0.5.2                    py36_0  \r\npy                        1.4.33                   py36_0  \r\npycodestyle               2.3.1                    py36_0  \r\npycosat                   0.6.2                    py36_0  \r\npycparser                 2.18                     py36_0  \r\npycrypto                  2.6.1                    py36_6  \r\npycurl                    7.43.0                   py36_2  \r\npyflakes                  1.6.0                    py36_0  \r\npygments                  2.2.0                    py36_0  \r\npygpu                     0.6.9                    py36_0  \r\npylint                    1.7.2                    py36_0  \r\npyodbc                    4.0.17                   py36_0  \r\npyopenssl                 17.0.0                   py36_0  \r\npyparsing                 2.2.0                    py36_0  \r\npyqt                      5.6.0                    py36_2  \r\npytables                  3.4.2               np113py36_0  \r\npytest                    3.2.1                    py36_0  \r\npython                    3.6.2                         0  \r\npython-dateutil           2.6.1                    py36_0  \r\npytorch                   0.1.12             py36_nomkl_0  [nomkl]\r\npytz                      2017.2                   py36_0  \r\npywavelets                0.5.2               np113py36_0  \r\npyyaml                    3.12                     py36_0  \r\npyzmq                     16.0.2                   py36_0  \r\nqt                        5.6.2                         4  \r\nqtawesome                 0.4.4                    py36_0  \r\nqtconsole                 4.3.1                    py36_0  \r\nqtpy                      1.3.1                    py36_0  \r\nreadline                  6.2                           2  \r\nrequests                  2.14.2                   py36_0  \r\nrope                      0.9.4                    py36_1  \r\nruamel_yaml               0.11.14                  py36_1  \r\nscikit-image              0.13.0              np113py36_0  \r\nscikit-learn              0.19.1          py36_blas_openblas_200  [blas_openblas]  conda-forge\r\nscipy                     0.19.1          py36_blas_openblas_202  [blas_openblas]  conda-forge\r\nseaborn                   0.8                      py36_0  \r\nsetuptools                36.4.0                   py36_1  \r\nsimplegeneric             0.8.1                    py36_1  \r\nsingledispatch            3.4.0.3                  py36_0  \r\nsip                       4.18                     py36_0  \r\nsix                       1.10.0                   py36_0  \r\nsnowballstemmer           1.2.1                    py36_0  \r\nsortedcollections         0.5.3                    py36_0  \r\nsortedcontainers          1.5.7                    py36_0  \r\nsphinx                    1.6.3                    py36_0  \r\nsphinxcontrib             1.0                      py36_0  \r\nsphinxcontrib-websupport  1.0.1                    py36_0  \r\nspyder                    3.2.3                    py36_0  \r\nsqlalchemy                1.1.13                   py36_0  \r\nsqlite                    3.13.0                        0  \r\nstatsmodels               0.8.0               np113py36_0  \r\nsympy                     1.1.1                    py36_0  \r\ntblib                     1.3.2                    py36_0  \r\ntensorboard               1.10.0                   py36_0    conda-forge\r\ntensorflow                1.10.0                   py36_0    conda-forge\r\ntensorflow-base           1.3.0            py36h5293eaa_1  \r\ntensorflow-tensorboard    0.1.5                    py36_0  \r\ntermcolor                 1.1.0                      py_2    conda-forge\r\nterminado                 0.6                      py36_0  \r\ntestpath                  0.3.1                    py36_0  \r\ntheano                    0.9.0                    py36_0  \r\ntk                        8.5.18                        0  \r\ntoolz                     0.8.2                    py36_0  \r\ntorchvision               0.1.8                    py36_0  \r\ntornado                   4.5.2                    py36_0  \r\ntraitlets                 4.3.2                    py36_0  \r\nunicodecsv                0.14.1                   py36_0  \r\nunixodbc                  2.3.4                         0  \r\nwcwidth                   0.1.7                    py36_0  \r\nwerkzeug                  0.12.2                   py36_0  \r\nwheel                     0.29.0                   py36_0  \r\nwidgetsnbextension        3.0.2                    py36_0  \r\nwrapt                     1.10.11                  py36_0  \r\nxlrd                      1.1.0                    py36_0  \r\nxlsxwriter                0.9.8                    py36_0  \r\nxlwt                      1.3.0                    py36_0  \r\nxz                        5.2.3                         0  \r\nyaml                      0.1.6                         0  \r\nzeromq                    4.1.5                         0  \r\nzict                      0.1.2                    py36_0  \r\nzlib                      1.2.11                        0 "]}, {"number": 21631, "title": "Keras model converted to an Estimator does not handle 1D labels correctly", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOSX 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: No\r\n- **TensorFlow version (use command below)**: v1.10.0-rc1-19-g656e7a2b34 1.10.0\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: see script below (keras model converges, not estimator)\r\n\r\n### Describe the problem\r\nKeras model converges on MNIST (> 97% accuracy after 5 epochs with batches of 32 instances), using the class IDs as labels (i.e., a 1D array of int32). However, after I convert the model to an Estimator, it does not converge (around 10% accuracy, again after 5 epochs with batches of 32 instances). Once I reshape the labels to a column vector (`y_train.reshape(-1, 1)`), it converges well. I double-checked with a `DNNClassifier`, and it accepts the labels both as a 1D array or as a column vector (2D). I believe this is a bug, and people might spend hours searching for the cause (as I did).\r\n\r\n### Source code / logs\r\nIf you run the code below, it will train three models on MNIST, first using 1D labels, then using 2D labels (i.e., column vectors):\r\n\r\n1. a Keras model\r\n2. the same Keras model converted to an Estimator\r\n3. an equivalent `DNNClassifier`\r\n\r\nThe final outputs below show that they all converge except for the Keras model converted to an Estimator when the labels are 1D (I removed the \"You CPU supports...\" and \"Using temporary folder...\" warnings from the outputs). The behavior is identical in eager mode and in graph mode.\r\n\r\n```\r\n==== Training with 1D labels... ====\r\nKeras model:\r\n    Eval: [0.07029167589747813, 0.9792]\r\nKeras model converted to an estimator:\r\n    Eval: ({'accuracy': 0.10245253, 'loss': 0.07640489, 'global_step': 18751}, [])\r\nDNNClassifier:\r\n    Eval: ({'accuracy': 0.1135, 'average_loss': 2.3010197, 'loss': 291.2683, 'global_step': 9375}, [])\r\n\r\n==== Training with 2D labels... ====\r\nKeras model:\r\n    Eval: [0.06944960513310507, 0.9779]\r\nKeras model converted to an estimator:\r\n    Eval: ({'accuracy': 0.97171676, 'loss': 0.09046984, 'global_step': 18751}, [])\r\nDNNClassifier:\r\n    Eval: ({'accuracy': 0.976, 'average_loss': 0.08481478, 'loss': 10.736049, 'global_step': 9375}, [])\r\n```\r\n\r\nHere is the source code:\r\n\r\n```python\r\nfrom __future__ import division, print_function, unicode_literals\r\n\r\nimport logging\r\nlogging.basicConfig(level=logging.WARNING)\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n#tf.enable_eager_execution() # same problem in eager mode or graph mode\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\nn_epochs = 5\r\nbatch_size = 32\r\n\r\ndef create_keras_model():\r\n    keras.backend.clear_session()\r\n    model = keras.models.Sequential([\r\n        keras.layers.Dense(300, activation=\"relu\", input_shape=[28*28]),\r\n        keras.layers.Dense(100, activation=\"relu\"),\r\n        keras.layers.Dense(10, activation=\"softmax\")\r\n    ])\r\n    optimizer = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.9)\r\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\r\n                  metrics=[\"accuracy\"])\r\n    return model\r\n\r\ndef create_keras_estimator():\r\n    model = create_keras_model()\r\n    input_name = model.input_names[0]\r\n    estimator = tf.keras.estimator.model_to_estimator(model)\r\n    return estimator, input_name\r\n\r\ndef create_dnn_estimator():\r\n    input_name = \"pixels\"\r\n    pixels = tf.feature_column.numeric_column(input_name, shape=[28 * 28])\r\n    estimator = tf.estimator.DNNClassifier(hidden_units=[300, 100, 10],\r\n                                           n_classes=10,\r\n                                           feature_columns=[pixels])\r\n    return estimator, input_name\r\n\r\ndef train_and_evaluate_estimator(estimator, input_name,\r\n                                 X_train, y_train, X_test, y_test):\r\n    train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n        x={input_name: X_train}, y=y_train, num_epochs=5, batch_size=32,\r\n        shuffle=True)\r\n    test_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n        x={input_name: X_test}, y=y_test, shuffle=False)\r\n    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn)\r\n    eval_spec = tf.estimator.EvalSpec(input_fn=test_input_fn)\r\n    return tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n\r\ndef load_and_scale_MNIST():\r\n    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\r\n    X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\r\n    X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\r\n    y_train = y_train.astype(np.int32)\r\n    y_test = y_test.astype(np.int32)\r\n    return X_train, y_train, X_test, y_test\r\n\r\nif __name__ == '__main__':\r\n    X_train, y_train, X_test, y_test = load_and_scale_MNIST()\r\n    \r\n    for run in range(2):\r\n        if run == 0:\r\n            print(\"==== Training with 1D labels... ====\")\r\n            assert y_train.ndim == 1 and y_test.ndim == 1\r\n        else:\r\n            y_train = y_train.reshape(-1, 1)\r\n            y_test = y_test.reshape(-1, 1)\r\n            print()\r\n            print(\"==== Training with 2D labels... ====\")\r\n            assert y_train.ndim == 2 and y_test.ndim == 2\r\n\r\n        print(\"Keras model:\")\r\n        keras_model = create_keras_model()\r\n        keras_model.fit(X_train, y_train, epochs=n_epochs,\r\n                        batch_size=batch_size, verbose=0)\r\n        print(\"    Eval:\", keras_model.evaluate(X_test, y_test, verbose=0))\r\n\r\n        print(\"Keras model converted to an estimator:\")\r\n        keras_estimator, input_name = create_keras_estimator()\r\n        print(\"    Eval:\", train_and_evaluate_estimator(\r\n            keras_estimator, input_name, X_train, y_train, X_test, y_test))\r\n\r\n        print(\"DNNClassifier:\")\r\n        dnn_estimator, input_name = create_dnn_estimator()\r\n        print(\"    Eval:\", train_and_evaluate_estimator(\r\n            dnn_estimator, input_name, X_train, y_train, X_test, y_test))\r\n```", "comments": ["Thank you for providing such a clear minimal case. cc @fchollet ", "@yifeif Hi, yifei. Would you have any thoughts on this?", "I think this is a stale issue. I cannot reproduce the issue with the `tf-nightly` and the results are as expected. Please check below for more details. \r\n\r\n```\r\n==== Training with 1D labels currently shows expected output... ====\r\nKeras model:\r\n    Eval: [0.06719633173451293, 0.9787]\r\nKeras model converted to an estimator:\r\n    Eval: ({'acc': 0.9802, 'loss': 0.0662133, 'global_step': 9375}, [])\r\nDNNClassifier:\r\n    Eval: ({'accuracy': 0.1135, 'average_loss': 2.3010228, 'loss': 291.26868, 'global_step': 9375}, [])\r\n```\r\n\r\nI am closing the issue. If the issue still persists in the newer version of TF, please feel free to reopen it. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=21631\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=21631\">No</a>\n"]}, {"number": 21630, "title": "Distributed training with SyncReplicasOptimizer may throw session close error after training ", "body": "\r\n### System information\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.13.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.1.0 (clang-902.0.39.1)\r\nTarget: x86_64-apple-darwin17.5.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.2\r\nprotobuf                           3.5.2.post1\r\ntensorflow                         1.8.0\r\ntensorflow-hub                     0.1.0\r\ntensorflow-model-analysis          0.6.0\r\ntensorflow-serving-api             1.8.0\r\ntensorflow-tensorboard             1.5.0\r\ntensorflow-transform               0.6.0\r\ntensorflowjs                       0.1.0\r\ntensorflowonspark                  1.0.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\r\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\r\nSanity check: array([1], dtype=int32)\r\n/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 106: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.13.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.1.0 (clang-902.0.39.1)\r\nTarget: x86_64-apple-darwin17.5.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.2\r\nprotobuf                           3.5.2.post1\r\ntensorflow                         1.8.0\r\ntensorflow-hub                     0.1.0\r\ntensorflow-model-analysis          0.6.0\r\ntensorflow-serving-api             1.8.0\r\ntensorflow-tensorboard             1.5.0\r\ntensorflow-transform               0.6.0\r\ntensorflowjs                       0.1.0\r\ntensorflowonspark                  1.0.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\r\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\r\nSanity check: array([1], dtype=int32)\r\n/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: line 106: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n### Describe the problem\r\n\r\nWe have used `MonitoredTrainingSession` and  `SyncReplicasOptimizer` for distributed sync training. All the master(the worker with index 0) and workers will work synchronously. But at the end of master process, it throw `CancelledError` while trying to close the session. Sometimes we re-run all the processes and the error will not be thrown.\r\n\r\n<img width=\"1439\" alt=\"screen shot 2018-08-15 at 5 37 58 pm\" src=\"https://user-images.githubusercontent.com/2715000/44142776-dbe72ba0-a0b3-11e8-892f-dc3012fde656.png\">\r\n\r\n### Source code / logs\r\n\r\nAbove.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Please provide more details and steps to reproduce.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 21629, "title": "Workers or master may not start when other tasks exit in async distributed training", "body": "\r\n### System information\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.13.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.1.0 (clang-902.0.39.1)\r\nTarget: x86_64-apple-darwin17.5.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.2\r\nprotobuf                           3.5.2.post1\r\ntensorflow                         1.8.0\r\ntensorflow-hub                     0.1.0\r\ntensorflow-model-analysis          0.6.0\r\ntensorflow-serving-api             1.8.0\r\ntensorflow-tensorboard             1.5.0\r\ntensorflow-transform               0.6.0\r\ntensorflowjs                       0.1.0\r\ntensorflowonspark                  1.0.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\r\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\r\nSanity check: array([1], dtype=int32)\r\n/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 106: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.13.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.1.0 (clang-902.0.39.1)\r\nTarget: x86_64-apple-darwin17.5.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.2\r\nprotobuf                           3.5.2.post1\r\ntensorflow                         1.8.0\r\ntensorflow-hub                     0.1.0\r\ntensorflow-model-analysis          0.6.0\r\ntensorflow-serving-api             1.8.0\r\ntensorflow-tensorboard             1.5.0\r\ntensorflow-transform               0.6.0\r\ntensorflowjs                       0.1.0\r\ntensorflowonspark                  1.0.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\r\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\r\nSanity check: array([1], dtype=int32)\r\n/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: line 106: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n### Describe the problem\r\n\r\nWe have implement the async distributed TensorFlow training and find some issues. Once all the master(the worker with index 0), ps and workers start, the master will start training. And sometime(not always) one of the workers will halt and have no chance to end the progress.\r\n\r\nHere is the [test distributed script](https://github.com/tobegit3hub/distributed_tensorflow/blob/master/auto_stop_ps/task.py) .\r\n\r\nHere is the log of master which is normal and successfully finished.\r\n\r\n<img width=\"1437\" alt=\"screen shot 2018-08-15 at 5 07 00 pm\" src=\"https://user-images.githubusercontent.com/2715000/44141773-bbfdb51e-a0b0-11e8-922a-c16e15d76637.png\">\r\n\r\nHere is the log of ps which is normal and join for all workers finished.\r\n\r\n<img width=\"1439\" alt=\"screen shot 2018-08-15 at 5 06 48 pm\" src=\"https://user-images.githubusercontent.com/2715000/44141836-dda5391c-a0b0-11e8-82b0-a1390182454b.png\">\r\n\r\nHere is the log of worker which is abnormal. It failed to run since master has been finished. If the epoch is larger and master need more time to run, this worker may run and finish as well.\r\n\r\n<img width=\"1439\" alt=\"screen shot 2018-08-15 at 5 06 32 pm\" src=\"https://user-images.githubusercontent.com/2715000/44141884-097955dc-a0b1-11e8-8f56-0e68d1478744.png\">\r\n\r\n### Source code / logs\r\n\r\nAbove.\r\n", "comments": ["Moreover, we have test in multi-node with unstable network. The worker may finishes before master starting, which results in that master could never exit and export the model.\r\n\r\nI don't think it's what we expect. Is there any way to guarantee the master to finish at any situation?", "@mrry this seems like a \"distributed training\" issue. Can you please comment?", "I can see two possibilities here:\r\n* If one task depends on another then you need some mechanism to ensure that all tasks eventually come up at the same time, and retry in the event of failure. A cluster manager like Kubernetes or Slurm would be helpful here.\r\n* If a task can run independently, then try setting `ConfigProto.device_filters` to contain only the device name prefixes for the devices it needs (e.g. the filters for the master task could be `[\"/job:master\", \"/job:ps\"]` if the master task does not need to use the worker tasks).", "I've run into the same issue. As suggested by @mrry , I was able to resolve this by using device filters.\r\n\r\nFor example,\r\n```\r\ndef _get_session_config_from_env_var():\r\n  \"\"\"Returns a tf.ConfigProto instance that has appropriate device_filters set.\r\n  \"\"\"\r\n\r\n  tf_config = json.loads(os.environ.get('TF_CONFIG', '{}'))\r\n\r\n  if (tf_config and 'task' in tf_config and 'type' in tf_config['task'] and\r\n      'index' in tf_config['task']):\r\n    # Master should only communicate with itself and ps\r\n    if tf_config['task']['type'] == 'master':\r\n      return tf.ConfigProto(device_filters=['/job:ps', '/job:master'])\r\n    # Worker should only communicate with itself and ps\r\n    elif tf_config['task']['type'] == 'worker':\r\n      return tf.ConfigProto(device_filters=[\r\n          '/job:ps',\r\n          '/job:worker/task:%d' % tf_config['task']['index']\r\n      ])\r\n  return None\r\n```\r\n(originally from https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/census/estimator/trainer/task.py)\r\n\r\nOutside of an estimator, you can use a `MonitoredTrainingSession`:\r\n```\r\nsession = tf.train.MonitoredTrainingSession(config=_get_session_config_from_env_var(), ...)\r\n``` \r\n\r\nWith an estimator, instead, this just involves using\r\n```\r\nconfig = tf.estimator.RunConfig(session_config=_get_session_config_from_env_var())\r\n```", "Nagging Assignee @mrry: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@tobegit3hub Hi, please try using ConfigProto.device_filters and see if you are able to resolve this issue.\r\n\r\nNote : Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Sorry for the late response.\r\n\r\nThe `ConfigProto.device_filters` works work me as well. Thanks @mrry and @mattkindy-praetorian \ud83d\ude03 "]}, {"number": 21628, "title": "Add grpc as default rpc layer for distribute coordinator server", "body": "Would you like to comment? @yuefengz ", "comments": ["Close it for now as the code is being actively developed."]}, {"number": 21627, "title": "The return value of _has_variables() in freeze_graph.py is not consistent with what its name imply", "body": "https://github.com/tensorflow/tensorflow/blob/3109a8fb2c966ea5ce198c8906a703ee48af75fb/tensorflow/python/tools/freeze_graph.py#L71-L74\r\n\r\n\r\n\r\nI'm a bit of surprised to notice this. Shouldn't the helper function `_has_variables` simply returns `False` (line 74) when no `Variable` has been found in the operations? Shall we change the function name to `_has_no_variables` or reverse the true/false logic?\r\n\r\nFurthermore, \r\nhttps://github.com/tensorflow/tensorflow/blob/3109a8fb2c966ea5ce198c8906a703ee48af75fb/tensorflow/python/tools/freeze_graph.py#L171-L173\r\n\r\nif `_has_variables` returns true, why it prints out \"no variable were found....\"? \r\n\r\nBad naming.\r\n\r\nHave I written custom code: no\r\nOS Platform and Distribution: ubuntu 14.04\r\nTensorFlow installed from: tensorflow-gpu\r\nTensorFlow version: 1.9\r\nBazel version: N/A\r\nCUDA/cuDNN version: 9.0/7.0\r\nGPU model and memory: TITAN Xp 12GB\r\nExact command to reproduce: N/A (just read the source code I pointed out)\r\nMobile device: N/A", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Just updated the description. Thanks. ", "@gargn any thoughts on the function naming?", "Thanks for reporting this issue. It has been fixed [here](https://github.com/tensorflow/tensorflow/commit/09e272a6a5c3359b671a068f4dac2bca8b312358).", "\ud83d\udcaf "]}, {"number": 21626, "title": "change the swap threshold by adding an elastic percentage", "body": "Originally, heuristic memory swapping feature won't improve much on the batch size, that's because IdentifySwappingCandidates are fully trusting the statically analysis.\r\nPer my experiment, this did not improve the batch size at all.\r\n\r\nWhile If we make the swapping threshold to be lower,for example, when analyzed memory usage is 0.8 * GPU mem size, then swapping feature is triggered.\r\n\r\nAccording to my experiments, for my K80 (12G), ResNet50, batch size can be improved from 128 to 150", "comments": ["@protoget This is really a very cheap change, could you please take a look at it? ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 21625, "title": "export symbols in the stream_executor namespace", "body": "Some of these symbols were previously in the perftools::gputools namespace. Not\r\nhaving these symbols causes custom ops loading to fail in the monolithic mode.\r\n\r\nFor example,\r\n\r\nbazel test --config monolithic //tensorflow/contrib/rnn:ops/gru_ops_test", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "@zheng-xq Can you review this PR please? ", "@gunan Can you take a look at this PR?", "@pcloudy @mrry \r\nI remember on windows we ran into problems with this, with certain build options we hit windows symbol export limit. Is that why we are not exporting stream executor?", "@gunan I thought we were exporting the stream executor symbols, thanks to your change in https://github.com/tensorflow/tensorflow/commit/a4a6bab62151616b54216059919bb2c111a45881\r\n\r\n(I haven't followed the renames in this area, and of course this script only affects the Windows CMake build. IIUC, the `.lds` files don't affect the Windows Bazel or CMake builds, unless there is some extra work going on somewhere to convert them to `link.exe` options.)", "Ping", "Nagging Assignee @protoget: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21624, "title": "unknown type name 'lzma_check'", "body": "", "comments": []}, {"number": 21623, "title": "How to fix pb to tflite error", "body": "### System information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):NO\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):mac os 10.13.5\r\n\r\nTensorFlow installed from (source or binary):pip\r\n\r\nTensorFlow version (use command below):'1.8.0\r\n\r\nPython version: 3.6.4\r\n\r\nBazel version (if compiling from source):\r\nBuild label: 0.14.0-homebrew\r\nBuild target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Jun 1 14:26:58 2018 (1527863218)\r\nBuild timestamp: 1527863218\r\nBuild timestamp as int: 1527863218\r\n\r\nGCC/Compiler version (if compiling from source):no\r\n\r\nCUDA/cuDNN version:no\r\n\r\nGPU model and memory:no\r\n\r\nExact command to reproduce:no\r\n\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n`directory:/models-master/research/slim/nets/mobilenet_v1_train.py`\r\nmobilenet_v1_train.py:Training department PBTXT and CKPT\r\n`directory:/tensorflow/tensorflow/python/tools/freeze_graph.py`\r\nfreeze_graph.py:Use the command to roll out the pb\r\nThe command:\r\n```\r\nbazel-bin/tensorflow/python/tools/freeze_graph \r\n--input_graph=/image/model_frozen.pb \\\r\n--input_checkpoint=/image/model.ckpt-10000 \\\r\n--output_node_names=MobilenetV1/Predictions/Reshape_1 \\\r\n--output_graph=/image/freesn_frozen.pb\r\n```\r\n\r\nWe need to turn pb into tflite\r\nThe command:\r\n\r\n```\r\nbazel build tensorflow/contrib/lite/toco:toco && \\\r\n  /Users/dchealth/tensorflow/bazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n  --input_file=/image/freesn_frozen.pb \\\r\n  --output_file=/image/freesn_frozen.tflite \\\r\n  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --input_shape=\"1,224, 224,3\" \\\r\n  --input_array=input \\\r\n  --output_array=MobilenetV1/Predictions/Reshape_1 \\\r\n  --std_value=128 --mean_value=128\r\n\r\n```\r\n\r\n### Pb turns tflite wrong\r\n2018-08-09 13:53:42.799490: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: FIFOQueueV2\r\n2018-08-09 13:53:42.800203: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: QueueDequeueManyV2\r\n2018-08-09 13:53:42.819149: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.819195: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.819249: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.819387: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.819493: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.819514: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.819537: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.819665: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.819816: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.819840: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.819866: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820013: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.820132: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820154: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820179: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820315: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.820452: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820471: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820491: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820596: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.820700: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820718: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820739: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820844: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.820966: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.820984: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821000: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821112: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.821235: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821258: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821282: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821434: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.821565: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821585: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821605: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821731: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.821832: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821851: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821875: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.821997: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.822146: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.822170: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.822195: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.822334: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.822434: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.822458: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.822477: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.822582: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.822715: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.822736: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.822761: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.822887: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.822993: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823061: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823205: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.823339: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823360: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823387: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823494: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.823608: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823641: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823664: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823808: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.823951: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823971: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.823996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.824128: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.824234: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.824270: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.824292: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.824424: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.824582: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.824606: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.824630: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.824771: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.824884: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.824898: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.824914: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825035: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.825182: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825201: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825224: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825366: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.825489: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825510: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825528: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825666: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.825811: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825833: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825849: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.825990: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.826120: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.826137: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.826167: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.826307: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.826479: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.826503: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.826526: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.826639: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.826794: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.826810: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.826832: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.826965: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.827130: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.827155: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.827191: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-08-09 13:53:42.827316: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Reciprocal\r\n2018-08-09 13:53:42.827440: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.827708: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.827756: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.827922: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.827961: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.828082: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.828208: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.828248: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.828352: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.828514: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.828576: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.828722: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.828760: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.828858: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.828940: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.828974: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.829096: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.829233: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.829297: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.829499: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.829542: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.829696: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.829852: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.829909: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.830068: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.830206: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.830266: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.830462: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.830499: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.830618: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.830749: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.830788: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.830882: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.831007: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.831082: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.831230: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.831267: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.831362: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.831449: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.831484: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.831603: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.831741: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.831817: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.831964: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.832000: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.832092: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.832173: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.832208: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.832327: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.832469: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.832532: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.832701: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.832740: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.832839: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.832921: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.832955: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.833071: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.833216: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.833290: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.833467: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.833538: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.833661: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.833822: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.833850: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.833996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.834158: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.834222: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.834440: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.834483: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.834604: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.834716: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.834757: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.834874: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.835019: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.835083: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.835298: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.835334: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.835456: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.835566: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.835602: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.835727: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.835870: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.835935: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.836186: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.836249: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.836370: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.836493: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.836538: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.836664: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.836830: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.836891: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.837101: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.837133: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.837226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.837333: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.837383: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.837507: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.837628: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.837685: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.837852: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.837883: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.837975: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.838071: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.838121: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.838244: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.838363: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.838417: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.838584: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.838619: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.838720: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.838832: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.838886: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.838984: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.839103: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.839156: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.839329: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.839366: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.839535: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.839620: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.839651: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.839744: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.839857: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.839920: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.840090: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.840140: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.840240: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.840336: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.840378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.840496: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.840644: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.840707: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.840876: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.840911: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.841008: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.841105: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.841155: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.841273: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.841392: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.841455: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.841622: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.841658: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.841771: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.841859: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.841885: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.841985: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.842103: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.842171: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.842353: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.842385: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.842476: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.842575: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.842624: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.842747: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.842880: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.842927: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.843095: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.843137: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.843231: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.843328: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.843386: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.843502: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.843638: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.843679: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.843848: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.843890: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.843986: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.844097: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.844138: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.844256: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.844382: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.844440: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.844619: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.844669: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.844767: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.844875: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.844926: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.845040: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.845161: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.845210: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.845381: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.845414: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.845511: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.845611: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.845662: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.845779: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.845899: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.845949: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.846122: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.846154: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.846252: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.846348: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.846383: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.846493: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.846611: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.846659: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.846824: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.846850: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.846990: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.847086: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.847123: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.847277: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.847426: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.847497: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.847717: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.847751: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.847846: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.847946: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.848000: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.848121: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.848244: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.848297: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.848464: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.848498: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.848590: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.848689: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.848741: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.848861: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.848984: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.849044: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: Assign\r\n2018-08-09 13:53:42.849213: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.849264: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.849366: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.849509: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:42.849552: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignAdd\r\n2018-08-09 13:53:42.849650: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1053] Converting unsupported operation: AssignSub\r\n2018-08-09 13:53:43.170870: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2450 operators, 3763 arrays (0 quantized)\r\n2018-08-09 13:53:43.375158: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 2058 operators, 3203 arrays (0 quantized)\r\n2018-08-09 13:53:43.563516: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2058 operators, 3203 arrays (0 quantized)\r\n2018-08-09 13:53:43.603805: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"MobilenetV1/Logits/Dropout_1b/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2018-08-09 13:53:43.763273: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 1386 operators, 2360 arrays (0 quantized)\r\n2018-08-09 13:53:43.817254: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"MobilenetV1/Logits/Dropout_1b/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2018-08-09 13:53:43.887386: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 1386 operators, 2360 arrays (0 quantized)\r\n2018-08-09 13:53:43.958709: F tensorflow/contrib/lite/toco/tooling_util.cc:1618] Array MobilenetV1/Logits/Dropout_1b/dropout/random_uniform/RandomUniform, which is an input to the Add operator producing the output array MobilenetV1/Logits/Dropout_1b/dropout/add, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\r\nAbort trap: 6", "comments": ["Hi, \r\n\r\nI faced a similar issue. \r\nIt took me a few days to figure out the solution.  \r\nI used the follow code to create the eval model and then freeze it. \r\n\r\n```\r\ndef export_eval_pbtxt():\r\n  \"\"\"Export eval.pbtxt.\"\"\"\r\n  with tf.Graph().as_default() as g:\r\n    images = tf.placeholder(dtype=tf.float32,shape=[None,224,224,3])\r\n    # using one of the following methods to create graph, depends on you\r\n    #_, _ = mobilenet_v1.mobilenet_v1(inputs=images,num_classes=NUM_CLASSES, is_training=False)\r\n    with slim.arg_scope(mobilenet_v1.mobilenet_v1_arg_scope(is_training=False,regularize_depthwise=True)):\r\n      _, _ = mobilenet_v1.mobilenet_v1(inputs=images, is_training=False, depth_multiplier=1.0, num_classes=NUM_CLASSES)\r\n    eval_graph_file = '/home/garylau/Desktop/mobilenet_v1/mobilenet_v1_eval.pbtxt'\r\n    with tf.Session() as sess:\r\n        with open(eval_graph_file, 'w') as f:\r\n            f.write(str(g.as_graph_def()))\r\n```\r\n\r\nThe solution came from the following link. \r\nhttps://github.com/tensorflow/tensorflow/issues/17684\r\n\r\nHope this is helpful for you.", "Thank you @ychen404 !\r\n\r\n@baihualinxin did that work for you?", "@ychen404 How do I use this function.\r\nI'm using ssd_ mobilenet_v1 to generate pb that's frozen.", "@drpngx No solution, no idea what the input is", "Hi, \r\nyou can directly call the function. \r\nI pasted the full script I used for my simplified mobilenet. \r\nI trained the model with cifar10 model. You may need to change the script according to your dataset. \r\n\r\n```\r\nimport tensorflow as tf\r\nslim = tf.contrib.slim\r\nfrom nets import mobilenet_v1\r\n\r\nNUM_CLASSES = 10\r\n\r\ndef export_eval_pbtxt():\r\n  \"\"\"Export eval.pbtxt.\"\"\"\r\n  with tf.Graph().as_default() as g:\r\n    images = tf.placeholder(dtype=tf.float32,shape=[None,32,32,3])\r\n    # using one of the following methods to create graph, depends on you\r\n    #_, _ = mobilenet_v1.mobilenet_v1(inputs=images,num_classes=NUM_CLASSES, is_training=False)\r\n    with slim.arg_scope(mobilenet_v1.mobilenet_v1_arg_scope(is_training=False,regularize_depthwise=True)):\r\n      _, _ = mobilenet_v1.mobilenet_v1(inputs=images, is_training=False, depth_multiplier=1.0, num_classes=NUM_CLASSES)\r\n    eval_graph_file = '/home/users/saman/yitao/tensorflow_android/models/research/slim/mobilenet_v1_eval.pbtxt'\r\n    with tf.Session() as sess:\r\n        with open(eval_graph_file, 'w') as f:\r\n            f.write(str(g.as_graph_def()))\r\n\r\ndef main():\r\n    print(\"python main function\")\r\n    export_eval_pbtxt()\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```", "@ychen404  PBTXT generated by input?\r\neval_graph_file  What is specified", "The following two line creates the graph from the mobilenet model. \r\n```\r\nwith slim.arg_scope(mobilenet_v1.mobilenet_v1_arg_scope(is_training=False,regularize_depthwise=True)):\r\n      _, _ = mobilenet_v1.mobilenet_v1(inputs=images, is_training=False, depth_multiplier=1.0, num_classes=NUM_CLASSES)\r\n```", "@ychen404You have skype or WeChat\uff0cI have trained CKPT and PBTXT. How to use", "@baihualinxin I prefer email. My email is ychen404@asu.edu. We can discuss through email. ", "The solution of creating an a separate eval graph, freezing, and converting that is described in the comments above, and correct. Will close this since its answered. Thanks!", "I've some issue for runnig the toco instruction;\r\n\r\n(py27) Snows-Mac:VA_Python snow$ toco --graph_def_file=./_binary/frozen_model.pb --output_file=./_binary/optimized_graph.lite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shape=1,39 --input_arrays=in --output_arrays=out --inference_type=FLOAT --input_data_type=FLOAT\r\n2018-12-05 22:20:04.181216: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nTraceback (most recent call last):\r\n  File \"/Users/snow/py27/bin/toco\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/snow/py27/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 401, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/Users/snow/py27/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/Users/snow/py27/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 397, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/Users/snow/py27/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 159, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"/Users/snow/py27/lib/python2.7/site-packages/tensorflow/contrib/lite/python/lite.py\", line 439, in convert\r\n    **converter_kwargs)\r\n  File \"/Users/snow/py27/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 309, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/Users/snow/py27/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 109, in toco_convert_protos\r\n    (stdout, stderr))\r\nRuntimeError: TOCO failed see console for info.\r\n2018-12-05 22:20:06.764764: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 31 operators, 43 arrays (0 quantized)\r\n2018-12-05 22:20:06.765055: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 30 operators, 42 arrays (0 quantized)\r\n2018-12-05 22:20:06.769208: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 30 operators, 42 arrays (0 quantized)\r\n2018-12-05 22:20:06.770583: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2018-12-05 22:20:06.770785: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 11 operators, 22 arrays (0 quantized)\r\n2018-12-05 22:20:06.770911: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2018-12-05 22:20:06.771001: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 11 operators, 22 arrays (0 quantized)\r\n2018-12-05 22:20:06.771127: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 2048 bytes, theoretical optimal value: 2048 bytes.\r\n2018-12-05 22:20:06.772440: F tensorflow/contrib/lite/toco/tflite/export.cc:374] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.contrib.lite.TocoConverter(). Here is a list of operators for which  you will need custom implementations: RandomUniform.\r\n\r\nNone\r\n\r\nAnd, if I add the parameter \"--allow_custom_ops\", then it doesn't happen.\r\nwhat's wrong for this?", "@baihualinxin hi\uff0cI meet the same error with yours\uff0ccan we communicate in wechat or another way\uff1f", "I encounter the same issue in the dropout layer with **tf1.13** using converter.convert() like the docs. Is there another solution? Is this fixed in the new version of tf? thanks\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"pb_analyse.py\", line 81, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/anaconda3/envs/tf113/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 455, in convert\r\n    **converter_kwargs)\r\n  File \"/anaconda3/envs/tf113/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 442, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/anaconda3/envs/tf113/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 205, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-10-13 00:52:27.616393: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2019-10-13 00:52:29.109063: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 329 operators, 461 arrays (0 quantized)\r\n2019-10-13 00:52:29.132690: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 329 operators, 461 arrays (0 quantized)\r\n2019-10-13 00:52:29.133571: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv1/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.134499: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv1bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.135750: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv2/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.136713: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv2bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.138284: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv3/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.141411: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv3bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.151782: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv4/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.214538: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv4bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.470455: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv6/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.494979: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv6bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.497203: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/deconv2/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.505634: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv7/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.508536: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv7bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.509364: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/deconv3/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.510714: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv8/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.511519: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv8bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.511922: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/deconv4/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.512466: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv9/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.512860: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv9bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.515783: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 176 operators, 270 arrays (0 quantized)\r\n2019-10-13 00:52:29.516497: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv9bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.516612: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv9/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.516747: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/deconv4/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.516854: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv8bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.516965: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv8/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.517096: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/deconv3/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.517200: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv7bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.517309: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv7/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.517438: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/deconv2/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.517540: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv6bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.517644: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/decontractor/conv6/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.517887: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv4bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.517990: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv4/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.518098: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv3bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.518199: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv3/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.518305: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv2bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.518403: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv2/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.518501: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv1bis/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.518582: W tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:85] RandomUniform op outputting \"model/contractor/conv1/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-10-13 00:52:29.521213: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 176 operators, 270 arrays (0 quantized)\r\n2019-10-13 00:52:29.526547: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 553648128 bytes, theoretical optimal value: 520093696 bytes.\r\n2019-10-13 00:52:29.527241: I tensorflow/contrib/lite/toco/toco_tooling.cc:397] Estimated count of arithmetic ops: 615.48 billion (note that a multiply-add is counted as 2 ops).\r\n2019-10-13 00:52:29.538807: F tensorflow/contrib/lite/toco/tflite/export.cc:386] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.contrib.lite.TFLiteConverter(). Here is a list of operators for which  you will need custom implementations: RandomUniform.\r\n\r\n```"]}, {"number": 21622, "title": "NotFoundError (see above for traceback): Key conv1/biases not found in checkpoint \t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](_recv_save/Const_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@Darkknight2018 \r\nCould you please try on latest stable version of tf and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21622\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21622\">No</a>\n"]}, {"number": 21621, "title": " add `tf.div_no_nan` op for division by zero", "body": "Fix #15706, #17350, #20091. \r\nRef #19105.\r\n\r\nThis is a summary of discussion in #15706:\r\n\r\n+ op name: div_no_nan\r\n+ op behavior: return 0 when denominator is zero\r\n+ designed for float value only: float32, float 64\r\n+ op kernel: CPU for now  (GPU kernel will be add later).", "comments": ["As suggested by @yifeif, create a follow up PR for #19105.\r\ncc @drpngx @martinwicke @asimshankar ", "Thanks. Looks good to me. Inheriting API approval from earlier PR.", "Thanks @facaiy. Could you take a look at the api_compatibility_test failure?", "Hi, @yifeif. The UnsafeDiv op #19105 was merged prematurely before we finished the discussion about its API design in  #15706. I think it's an expected failure, because UnsafeDiv op is being renamed DivNoNan here. But the PR, actually, do not break backwards_compatibility of released version, I think we can ignore the failure.", "That matches my understanding. However, do we need to update goldens here?", "Thanks for reminding me. I didn't recognize that there are two versions for golden file: v1 and v2. Those files are updated. Is there anything else that has to be done?", "The two versions are new in preparation of 2.0. Thanks for updating. Running tests. ", "Thanks for your explanation. Except of backwards_compatibility_test, other failures seems unrelated?", "@yifeif I merged this PR (using a clone), but for some reason the PR isn't closed? Is that some asynchronous process? Did I mess something up?", "This is expected. The tool only automatically merges the PR if the last commit in the PR matches the imported version. Looks like the internal change only officially imported up to hash c69459 (not including the latest commit in this PR). But I saw @martinwicke you made the same V1 golden fix internally as the last commit made by @facaiy, so we should be good here. I'll close this PR.", "Thank you everyone!", "@yifeif Yifei, could you help close issue #15706, #17350 and #20091 ? I think all are resolved."]}, {"number": 21620, "title": "transform_graph-2.params", "body": "There is nothing error when building bazel,but it is transform_graph-2.params rather than transform_graph in folder bazel-bin/tensorflow/tools/graph_transforms/.Why?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 31 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 21619, "title": "tf.data.Dataset data remain as tensor even after sess.run()?", "body": "Hello Professional Tensorflow Developers,\r\n\r\nI apologize if I am making a noob mistake over here. But my finding about the data that remain in the tf.data.Dataset remain as tensor even after sess.run(). Below are the source code:\r\n\r\n```\r\n\r\nimport matplotlib.pyplot as plt\r\nfrom scipy import misc\r\nimport numpy as np\r\nfrom skimage import exposure\r\nfrom math import ceil\r\nimport tensorflow as tf\r\nimport math\r\nimport glob\r\nimport collections\r\nimport re\r\nfrom pathlib import Path\r\nfrom PIL import Image\r\nfrom skimage import data, img_as_float, io, img_as_uint\r\nfrom skimage._shared._warnings import expected_warnings\r\nfrom sklearn.preprocessing import LabelBinarizer\r\nfrom sklearn.preprocessing import OneHotEncoder\r\nprint(\"Tensorflow version \" + tf.__version__)\r\n\r\nimport tensorflow.contrib.eager as tfe\r\ntfe.enable_eager_execution()\r\n\r\ntf.set_random_seed(0)\r\n\r\n\r\n\r\nint_list = [0,1,2,3,4,5,6,7,8,9]\r\n\r\nlb = LabelBinarizer()\r\n\r\n\r\n\r\ndef parse_function(data_list):\r\n\r\n\tprint(\"data_list: \", data_list,\"\\n\")\r\n\r\n\tprint(\"tf.print: \", tf.Print(data_list, [data_list]),\"\\n\")\r\n\r\n\tgraph1 = tf.Graph()\r\n\t\r\n\twith graph1.as_default():\r\n\t\tx = tf.placeholder(tf.int32)\r\n\t\ty = x * 1\r\n\t\t#z = tf.Variable(data_list)\r\n\r\n\tprint(\"x: \", x, \"\\n\")\r\n\t#print(\"z: \", z, \"\\n\")\t\r\n\r\n\t#sess = tf.InteractiveSession()\r\n\r\n\t#with sess.as_default():\r\n\twith tf.Session() as sess:\r\n\t\tsess.run(tf.global_variables_initializer())\r\n\t\t#sess.run(tf.local_variables_initializer())\r\n\t\t#tf.global_variables_initializer().run()\r\n\t\t#tf.local_variables_initializer().run()\r\n\t\t#tf.tables_initializer().run()\r\n\t\t\r\n\t\t#feed = {x: sess.run(tf.data_list)}\r\n\t\t#feed = {x: data_list}\r\n\t\t\r\n\t\t#data = sess.run(data_list)\r\n\t\t\r\n\t\t#print(\"data: \", data,\"\\n\")\r\n\t\t#print(\"feed: \", feed, \"\\n\")\r\n\r\n\t\tprint(\"tf.print: \", tf.Print(data_list, [data_list]),\"\\n\")\r\n\t        \r\n                print(\"sess.run(data_list): \", sess.run(data_list), \"\\n\")\r\n\r\n\t\t#label_eval = sess.run(y, feed_dict=feed)\r\n\t\t#label_eval = sess.run(z)\r\n\t\t#label_eval = sess.run(data_list)\r\n\r\n\t\t#print(\"x: \", x, \"\\n\")\r\n\r\n\t\t#label_eval = x.eval()\r\n\t\t#print(\"label_eval: \", label_eval,\"\\n\")\r\n\t\t#one_hot_label = tf.one_hot(label, 10) #no issue\r\n\t\t#one_hot_label = lb.fit_transform(label_eval)\r\n\t\t#print(\"one_hot_label: \", one_hot_label, \"\\n\")\r\n\r\n\tsess.close()\r\n\r\n\t#return one_hot_label\r\n\r\nint_list = tf.convert_to_tensor(int_list, dtype=tf.float32)\r\n\r\nint_dataset = tf.data.Dataset.from_tensor_slices(int_list).map(lambda z: parse_function(z))\r\n\r\nint_dataset = int_dataset.batch(100)\r\n\r\nint_iterator = int_dataset.make_initializable_iterator()\r\n\r\nint_iterator = train_iterator.get_next()\r\n```\r\n\r\nThe error output:\r\n\r\n```\r\nTensorflow version 1.8.0\r\n2018-08-15 10:09:18.992919: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\ndata_list:  Tensor(\"arg0:0\", shape=(), dtype=float32) \r\n\r\ntf.print:  Tensor(\"Print:0\", shape=(), dtype=float32) \r\n\r\nx:  Tensor(\"Placeholder:0\", dtype=int32) \r\n\r\ntf.print:  Tensor(\"Print_1:0\", shape=(), dtype=float32) \r\n\r\nTraceback (most recent call last):\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 282, in __init__\r\n    fetch, allow_tensor=True, allow_operation=True))\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3590, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3669, in _as_graph_element_locked\r\n    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\r\nValueError: Tensor Tensor(\"arg0:0\", shape=(), dtype=float32) is not an element of this graph.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"./tf_dataset.py\", line 93, in <module>\r\n    int_dataset = tf.data.Dataset.from_tensor_slices(int_list).map(lambda z: parse_function(z))\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 851, in map\r\n    return MapDataset(self, map_func)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1839, in __init__\r\n    self._map_func.add_to_graph(ops.get_default_graph())\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 484, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 319, in _create_definition_if_needed\r\n    self._create_definition_if_needed_impl()\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 336, in _create_definition_if_needed_impl\r\n    outputs = self._func(*inputs)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1804, in tf_map_func\r\n    ret = map_func(nested_args)\r\n  File \"./tf_dataset.py\", line 93, in <lambda>\r\n    int_dataset = tf.data.Dataset.from_tensor_slices(int_list).map(lambda z: parse_function(z))\r\n  File \"./tf_dataset.py\", line 72, in parse_function\r\n    print(\"sess.run(data_list): \", sess.run(data_list), \"\\n\")\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 427, in __init__\r\n    self._fetch_mapper = _FetchMapper.for_fetch(fetches)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 253, in for_fetch\r\n    return _ElementFetchMapper(fetches, contraction_fn)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 289, in __init__\r\n    'Tensor. (%s)' % (fetch, str(e)))\r\nValueError: Fetch argument <tf.Tensor 'arg0:0' shape=() dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"arg0:0\", shape=(), dtype=float32) is not an element of this graph.)\r\n```\r\n\r\npip list:\r\n```\r\npip3 list\r\nPackage                       Version               \r\n----------------------------- ----------------------\r\nabsl-py                       0.2.2                 \r\naiohttp                       2.2.5                 \r\naniso8601                     1.3.0                 \r\napturl                        0.5.2                 \r\nasn1crypto                    0.23.0                \r\nastor                         0.6.2                 \r\nasync-timeout                 2.0.0                 \r\nattrs                         17.3.0                \r\nAutomat                       0.6.0                 \r\nbase58                        0.2.5                 \r\nbeautifulsoup4                4.6.0                 \r\nbehave                        1.2.5                 \r\nBigchainDB                    1.2.0.dev0            \r\nbigchaindb-driver             0.4.0                 \r\nbleach                        1.5.0                 \r\nblinker                       1.3                   \r\nBrlapi                        0.6.4                 \r\ncached-property               1.3.0                 \r\ncertifi                       2017.7.27.1           \r\ncffi                          1.11.2                \r\nchardet                       3.0.4                 \r\ncheckbox-support              0.22                  \r\nclick                         6.7                   \r\ncloudpickle                   0.5.3                 \r\ncommand-not-found             0.3                   \r\nconstantly                    15.1.0                \r\ncryptoconditions              0.6.0.dev1            \r\ncryptography                  2.1.3                 \r\ncssselect                     1.0.1                 \r\ncycler                        0.10.0                \r\ndask                          0.18.1                \r\ndecorator                     4.1.2                 \r\ndefer                         1.0.6                 \r\ndocker                        2.5.1                 \r\ndocker-compose                1.16.1                \r\ndocker-pycreds                0.2.1                 \r\ndockerpty                     0.4.1                 \r\ndocopt                        0.6.2                 \r\ndpkt                          1.9.1                 \r\nenum34                        1.1.6                 \r\nfeedparser                    5.1.3                 \r\nFlask                         0.12.2                \r\nFlask-Cors                    3.0.3                 \r\nFlask-RESTful                 0.3.6                 \r\ngast                          0.2.0                 \r\ngrpcio                        1.13.0                \r\nguacamole                     0.9.2                 \r\ngunicorn                      19.7.1                \r\nh5py                          2.8.0                 \r\nhtml5lib                      0.9999999             \r\nhttplib2                      0.9.1                 \r\nhyperlink                     17.3.1                \r\nhypothesis                    3.18.5                \r\nhypothesis-regex              0.2                   \r\nidna                          2.6                   \r\nincremental                   17.5.0                \r\nitsdangerous                  0.24                  \r\nJinja2                        2.9.6                 \r\njsonschema                    2.5.1                 \r\nKeras                         2.2.0                 \r\nKeras-Applications            1.0.2                 \r\nKeras-Preprocessing           1.0.1                 \r\nlanguage-selector             0.1                   \r\nlogstats                      0.2.1                 \r\nlouis                         2.6.4                 \r\nlxml                          4.1.1                 \r\nMako                          1.0.3                 \r\nMarkdown                      2.6.11                \r\nMarkupSafe                    1.0                   \r\nmatplotlib                    2.0.2                 \r\nmultidict                     3.3.0                 \r\nmultipipes                    0.1.0                 \r\nnetworkx                      1.11                  \r\nnose                          1.3.7                 \r\nnumpy                         1.14.0                \r\noauthlib                      1.0.3                 \r\nolefile                       0.44                  \r\nonboard                       1.2.0                 \r\npadme                         1.1.1                 \r\nparse                         1.8.2                 \r\nparse-type                    0.3.4                 \r\nparsel                        1.2.0                 \r\npexpect                       4.0.1                 \r\nPillow                        5.2.0                 \r\npip                           10.0.1                \r\nplainbox                      0.25                  \r\nprotobuf                      3.5.1                 \r\npsutil                        5.3.0                 \r\nptyprocess                    0.5                   \r\npy                            1.4.34                \r\npyasn1                        0.4.2                 \r\npyasn1-modules                0.2.1                 \r\npycparser                     2.18                  \r\npycups                        1.9.73                \r\npycurl                        7.43.0                \r\nPyDispatcher                  2.0.5                 \r\nPygments                      2.2.0                 \r\npygobject                     3.20.0                \r\nPyJWT                         1.3.0                 \r\npymongo                       3.5.1                 \r\nPyNaCl                        1.1.2                 \r\npyOpenSSL                     17.4.0                \r\npyparsing                     2.2.0                 \r\npysha3                        1.0.2                 \r\npytest                        3.2.3                 \r\npytest-mock                   1.6.3                 \r\npython-apt                    1.1.0b1+ubuntu0.16.4.2\r\npython-dateutil               2.6.1                 \r\npython-debian                 0.1.27                \r\npython-rapidjson              0.0.11                \r\npython-rapidjson-schema       0.1.1                 \r\npython-systemd                231                   \r\npytz                          2017.2                \r\nPyWavelets                    0.5.2                 \r\npyxdg                         0.25                  \r\nPyYAML                        3.12                  \r\nqueuelib                      1.4.2                 \r\nreportlab                     3.3.0                 \r\nrequests                      2.18.4                \r\nrethinkdb                     2.3.0.post6           \r\nscikit-image                  0.14.0                \r\nscikit-learn                  0.19.0                \r\nscipy                         0.19.1                \r\nScrapy                        1.4.0                 \r\nselenium                      3.7.0                 \r\nservice-identity              17.0.0                \r\nsessioninstaller              0.0.0                 \r\nsetuptools                    38.4.0                \r\nsix                           1.11.0                \r\nstatsd                        3.2.1                 \r\nsystem-service                0.3                   \r\ntensorboard                   1.8.0                 \r\ntensorflow                    1.8.0                 \r\ntensorflow-tensorboard        0.4.0                 \r\ntermcolor                     1.1.0                 \r\ntexttable                     0.9.1                 \r\ntoolz                         0.9.0                 \r\ntornado                       4.5.2                 \r\nTwisted                       17.9.0                \r\nubuntu-drivers-common         0.0.0                 \r\nufw                           0.35                  \r\nunattended-upgrades           0.1                   \r\nunity-scope-calculator        0.1                   \r\nunity-scope-chromiumbookmarks 0.1                   \r\nunity-scope-colourlovers      0.1                   \r\nunity-scope-devhelp           0.1                   \r\nunity-scope-firefoxbookmarks  0.1                   \r\nunity-scope-gdrive            0.7                   \r\nunity-scope-manpages          0.1                   \r\nunity-scope-openclipart       0.1                   \r\nunity-scope-texdoc            0.1                   \r\nunity-scope-tomboy            0.1                   \r\nunity-scope-virtualbox        0.1                   \r\nunity-scope-yelp              0.1                   \r\nunity-scope-zotero            0.1                   \r\nurllib3                       1.22                  \r\nusb-creator                   0.3.0                 \r\nw3lib                         1.18.0                \r\nwebsocket-client              0.44.0                \r\nWerkzeug                      0.14.1                \r\nwheel                         0.30.0                \r\nxdiagnose                     3.8.4.1               \r\nxkit                          0.0.0                 \r\nXlsxWriter                    0.7.3                 \r\nyarl                          0.13.0                \r\nzope.interface                4.4.3 \r\n```          \r\n\r\nI am using Ubuntu 16.04 64 Bits, Python 3.5.2 and tensorflow 1.8.0\r\n\r\nAdditional information:\r\n\r\nHave I written custom code\r\n\r\nNo\r\n\r\nOS Platform and Distribution\r\n\r\nLinux OS Ubuntu 16.04 x64 \r\n\r\nTensorFlow installed from\r\n\r\nTensorflow 1.8.0 CPU only version install from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.8.0rc1-cp35-cp35m-linux_x86_64.whl\r\n\r\nBazel version\r\n\r\nn/a\r\n\r\nCUDA/cuDNN version\r\n\r\nn/a\r\n\r\nGPU model and memory\r\n\r\nn/a due to I am using CPU only version\r\n\r\nExact command to reproduce\r\n\r\nPlease execute my source code which mentioned above\r\n\r\nMobile device\r\n\r\nn/a due to I am using PC not mobile device\r\n\r\nThanks\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I have updated the original post", "Why are you creating tf.Graph and tf.Sessions in a tf.data map function? Your error is occuring on the line `print(\"sess.run(data_list): \", sess.run(data_list), \"\\n\")`, because the tensor that is the argument to the map function is defined in the (original) default graph, which is different from the graph in the session. But more generally, creating sessions and graphs in tf.data function is not a common or supported pattern. What is the objective of your program? \r\n\r\n(Side note: If you removed the commented out code lines in your code before sharing the snippet, it would be more human readable :) )", "Ok, I updated the source code to:\r\n\r\n```\r\nimport matplotlib.pyplot as plt\r\nfrom scipy import misc\r\nimport numpy as np\r\nfrom skimage import exposure\r\nfrom math import ceil\r\nimport tensorflow as tf\r\nimport math\r\nimport glob\r\nimport collections\r\nimport re\r\nfrom pathlib import Path\r\nfrom PIL import Image\r\nfrom skimage import data, img_as_float, io, img_as_uint\r\nfrom skimage._shared._warnings import expected_warnings\r\nfrom sklearn.preprocessing import LabelBinarizer\r\nfrom sklearn.preprocessing import OneHotEncoder\r\nprint(\"Tensorflow version \" + tf.__version__)\r\n\r\nimport tensorflow.contrib.eager as tfe\r\ntfe.enable_eager_execution()\r\n\r\ntf.set_random_seed(0)\r\n\r\n\r\n\r\nint_list = [0,1,2,3,4,5,6,7,8,9]\r\n\r\nlb = LabelBinarizer()\r\n\r\n\r\nprint(\"int_list: \", int_list, \"\\n\")\r\n\r\ndef parse_function(data_list):\r\n\r\n\tprint(\"data_list: \", data_list,\"\\n\")\r\n\r\n\tprint(\"tf.print: \", tf.Print(data_list, [data_list]),\"\\n\")\r\n\t\r\n\twith tf.Session() as sess:\r\n\t\t\r\n\t\tsess.run(tf.global_variables_initializer())\r\n\t\tsess.run(tf.local_variables_initializer())\r\n\r\n\t\tprint(\"tf.print: \", tf.Print(data_list, [data_list]),\"\\n\")\r\n\r\n\t\tprint(\"sess.run(data_list): \", sess.run(data_list), \"\\n\")\r\n\r\n\r\n\tsess.close()\r\n\r\n\t#return one_hot_label\r\n\r\nint_list = tf.convert_to_tensor(int_list, dtype=tf.float32)\r\n\r\nint_dataset = tf.data.Dataset.from_tensor_slices(int_list).map(lambda z: parse_function(z))\r\n\r\nint_dataset = int_dataset.batch(100)\r\n\r\nint_iterator = int_dataset.make_initializable_iterator()\r\n\r\nint_iterator = train_iterator.get_next()\r\n```\r\nOutput:\r\n\r\n```\r\nTensorflow version 1.8.0\r\nint_list:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \r\n\r\n2018-08-16 14:36:08.644195: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\ndata_list:  Tensor(\"arg0:0\", shape=(), dtype=float32) \r\n\r\ntf.print:  Tensor(\"Print:0\", shape=(), dtype=float32) \r\n\r\ntf.print:  Tensor(\"Print_1:0\", shape=(), dtype=float32) \r\n\r\nTraceback (most recent call last):\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'arg0' with dtype float\r\n\t [[Node: arg0 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"./tf_dataset.py\", line 103, in <module>\r\n    int_dataset = tf.data.Dataset.from_tensor_slices(int_list).map(lambda z: parse_function(z))\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 851, in map\r\n    return MapDataset(self, map_func)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1839, in __init__\r\n    self._map_func.add_to_graph(ops.get_default_graph())\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 484, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 319, in _create_definition_if_needed\r\n    self._create_definition_if_needed_impl()\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 336, in _create_definition_if_needed_impl\r\n    outputs = self._func(*inputs)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1804, in tf_map_func\r\n    ret = map_func(nested_args)\r\n  File \"./tf_dataset.py\", line 103, in <lambda>\r\n    int_dataset = tf.data.Dataset.from_tensor_slices(int_list).map(lambda z: parse_function(z))\r\n  File \"./tf_dataset.py\", line 83, in parse_function\r\n    print(\"sess.run(data_list): \", sess.run(data_list), \"\\n\")\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'arg0' with dtype float\r\n\t [[Node: arg0 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op 'arg0', defined at:\r\n  File \"./tf_dataset.py\", line 103, in <module>\r\n    int_dataset = tf.data.Dataset.from_tensor_slices(int_list).map(lambda z: parse_function(z))\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 851, in map\r\n    return MapDataset(self, map_func)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1839, in __init__\r\n    self._map_func.add_to_graph(ops.get_default_graph())\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 484, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 319, in _create_definition_if_needed\r\n    self._create_definition_if_needed_impl()\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 332, in _create_definition_if_needed_impl\r\n    argholder = array_ops.placeholder(argtype, name=argname)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1808, in placeholder\r\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4848, in placeholder\r\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 686, in create_op\r\n    **kwargs)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\r\n    op_def=op_def)\r\n  File \"/home/dragon/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'arg0' with dtype float\r\n\t [[Node: arg0 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\n```\r\nI still gave me an error but was a different type of error.\r\n\r\nI am not sure what happen at the tf.data.Dataset.from_tensor_slices(int_list) whereby it turned the int_list into tensor object or tensor tensor? I still puzzled that I am unable to convert the tensor inside the tf.data.Dataset, which is the data_list into numpy array by using both tf.session.run() or tensor.eval(session=tf.session()).\r\n\r\nThanks", "In eager mode (which you turned on with `tf.enable_eager_execution`), variables are initialized as soon as they are created, so you don't need `global_variables_initializer` and `local_variables_initializer`, and you should not create a `Session` at all.\r\n\r\nYou also need not explicitly create an iterator for datasets in eager mode. In eager, you can iterate over datasets as follows: \r\n\r\n```\r\nfor x in int_dataset:\r\n  print(x)\r\n```\r\n\r\nCheck out the [eager execution guide](https://www.tensorflow.org/guide/eager) on the tensorflow website for more information.\r\n\r\n(Note that even in non-eager mode, you should never create a `Session` in a tf.data map function!). \r\n\r\nOur error message here in tf.data could have been more helpful, and I'll look into how we can improve it. ", "I don't think the code you pasted gave the error you pasted because the last iteration of the code has no placeholders.\r\n\r\nIn general you are not supposed to create a tensorflow session inside a python function which is supposed to be building a graph (and functions passed to Dataset.map are supposed to build graphs).\r\n\r\nIt might be easier for you to take a step back and describe what you're trying to achieve here (specially because your parse_function isn't actually doing any parsing).\r\n\r\nAnswering your question, tf.data.Dataset.from_tensor_slices returns a Dataset, not a tensor. A Dataset is an object from which you can build iterators and other datasets (using tools like map and friends). The iterators you build from a dataset have an op which you can run to get a tensor.\r\n\r\nPlease refer to the documentation in [tf.data](https://www.tensorflow.org/guide/datasets) or [one of Derek's talks on the subject](https://www.youtube.com/watch?v=uIcqeP7MFH0).\r\n\r\nFor now I'm closing this issue since I do not think it's a bug in tf. "]}, {"number": 21618, "title": "AttributeError: module 'tensorflow.contrib.lite.python.convert_saved_model' has no attribute 'convert'", "body": "### System information\r\n- **OS Platform and Distribution: Linux Ubuntu 16.04**:\r\n- **TensorFlow installed from source**:\r\n- **TensorFlow version 1.10**:\r\n- **Python version 3.6**:\r\n- **Bazel version Build label: 0.16.0**:\r\n- **Exact command to reproduce: convert_saved_model.convert(saved_model_dir=saved_model, output_tflite=\"/TF_Lite_Model\")**:\r\n\r\nI am trying to convert my premade DNN Model to tflite file, using the function:\r\n\r\nfrom tensorflow.contrib.lite.python import convert_saved_model\r\n**convert_saved_model.convert**(saved_model_dir=saved_model, output_tflite=\"/TF_Lite_Model\")\r\n\r\nI have the last verison of tensorflow installed 1.10\r\nI am using UBUNTU 16.04\r\n\r\nthe error is the following:\r\n\r\nAttributeError: module 'tensorflow.contrib.lite.python.convert_saved_model' has no attribute 'convert'\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "This issue has been reported on [Stack Overflow](https://stackoverflow.com/questions/51863312/attributeerror-module-tensorflow-contrib-lite-python-convert-saved-model-has)."]}, {"number": 21617, "title": "Error trying to convert from saved model to tflite", "body": "### System information\r\n- **OS Platform and Distribution: Linux Ubuntu 16.04**:\r\n- **TensorFlow installed from source**:\r\n- **TensorFlow version 1.10**:\r\n- **Python version 3.6**:\r\n- **Bazel version Build label: 0.16.0**:\r\n\r\nWhile trying to convert a saved model to tflite file I get the following error:\r\n\r\nF tensorflow/contrib/lite/toco/tflite/export.cc:363] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.contrib.lite.toco_convert(). Here is a list of operators for which you will need custom implementations: AsString, ParseExample.\\nAborted (core dumped)\\n' None\r\n\r\nI am using the DNN premade Estimator.\r\n\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nIRIS_TRAINING = \"iris_training.csv\"\r\nIRIS_TEST = \"iris_test.csv\"\r\nINPUT_TENSOR_NAME = 'inputs'\r\n\r\ndef main():\r\ntraining_set = tf.contrib.learn.datasets.base.load_csv_with_header(\r\n    filename=IRIS_TRAINING,\r\n    target_dtype=np.int,\r\n    features_dtype=np.float32)\r\n\r\nfeature_columns = [tf.feature_column.numeric_column(INPUT_TENSOR_NAME, shape=[4])]\r\n\r\n# Build 3 layer DNN with 10, 20, 10 units respectively.\r\nclassifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\r\n                           hidden_units=[10, 20, 10],\r\n                           n_classes=3,\r\n                           model_dir=\"/tmp/iris_model\")\r\n\r\n\r\n# Define the training inputs\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={INPUT_TENSOR_NAME: np.array(training_set.data)},\r\n    y=np.array(training_set.target),\r\n    num_epochs=None,\r\n    shuffle=True)\r\n\r\n# Train model.\r\nclassifier.train(input_fn=train_input_fn, steps=2000)\r\n\r\ninputs = {'x': tf.placeholder(tf.float32, [4])}\r\ntf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n\r\nsaved_model=classifier.export_savedmodel(export_dir_base=\"/tmp/iris_model\", serving_input_receiver_fn=serving_input_receiver_fn)\r\n\r\nconverter = tf.contrib.lite.TocoConverter.from_saved_model(saved_model)\r\ntflite_model = converter.convert()\r\n\r\ndef serving_input_receiver_fn():\r\n    feature_spec = {INPUT_TENSOR_NAME: tf.FixedLenFeature(dtype=tf.float32, shape=[4])}\r\n    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nIris files can be downloaded form the following links:\r\n\r\nIRIS_TRAINING FILE: \"http://download.tensorflow.org/data/iris_training.csv\"\r\n\r\nIRIS_TEST FILE: \"http://download.tensorflow.org/data/iris_test.csv\"", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "The list of supported ops are available [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md). The two recommended solutions are:\r\n1. Add a custom op as described [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/custom_operators.md).\r\n2. Only use the ops that are currently supported by TFLite in your model.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Try using this operation modifier while converting the model to TFLite.\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"_modelspath_\")\r\nconverter.post_training_quantize=True\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                        tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\nopen(\"litemodel.tflite\", \"wb\").write(tflite_model)\r\n```", "@mrtehseen Please file a new issue with instructions to reproduce your issue. Include the model or enough of the model to reproduce the error along with your error."]}, {"number": 21616, "title": "[Java] Render secondary factory for default output types", "body": "This is an API optimization. Right now, when an attribute of an operation is optional (i.e. has a default value if not provided explicitly by the user), it ends up in the `Options` nested class of that operation. Since the operation factory accepts a vararg value of `Options...`, it could be passed or left empty.\r\n\r\nThe exception is the case where that attribute is the type of an output. Since the value of the attribute alter the generic type of the produce tensors, it need to be passed explicitly in the invokation, like in:\r\n```\r\nArgMax<Long> argMax = ops.argMax(input, dimension, Long.class)\r\n```\r\nBut that makes the signature of the factory a bit too verbose, since most of the time the user would be more than happy with the default output type (`Long` in this case) and would prefer not specifying it.\r\n\r\nTo handle such case, this PR creates a secondary factory method for those operations, where the default output type is implicitly provided by the API. So while it is still possible to the `ArgMax` the previous (to allow output type customization), it is now also possible to simply call:\r\n```\r\nArgMax<Long> argMax = ops.argMax(input, dimension)\r\n```\r\n\r\nCC: @asimshankar , please note that this PR must be merge after #21589 (which is already accepted) or it will fail to compile ", "comments": ["@asimshankar : just a little reminder to please take a look at this PR now that the previous one has been merged, thanks!"]}, {"number": 21615, "title": "Fine tuning a model by building a Scaffold in Mirrored Strategy is not supported", "body": "### System information\r\nHave I written custom code: Yes\r\nOS Platform and Distribution: Linux Ubuntu 18.04\r\nMobile device: N/A\r\nTensorFlow installed from: source\r\nTensorFlow version: ('v1.9.0-rc2-2165-g7b80190d52', '1.10.0-rc1')\r\nPython version: 2.7\r\nBazel version: 0.15.2\r\nGCC/Compiler version: gcc version 6.4.0 20180424\r\nCUDA/cuDNN version: 9.1 / 7.1\r\nGPU model and memory: K80,  12GB\r\nExact command to reproduce: N/A\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nI have been trying to  fine tune my model using Mirrored Strategy. To initialize the weights from a given checkpoint, I pass a scaffold object to Estimator_Spec object, with init_fn as a parameter. However, when I run it, the program crashes (refer to the stacktrace below for more details). I looked around for similar issue, but couldn't find any. Hence, I had to dig through the source code to figure the cause of the issue. While exploring, I ran into this message:\r\n**TODO(anjalisridhar): Figure out how to resolve the following scaffold parameters: init_feed_dict, init_fn**\r\ncalled here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L1599\r\n\r\nI was wondering whether fixing this is on priority list, or whether it has been sitting on the back burner until other issues have been resolved.\r\n\r\ni am not sure how to present a reproducible code in this context, but do let me know if I need to clarify some more.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 120, '_session_config': allow_soft_placement: true\r\n, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7fd221bfad10>, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd221bfacd0>, '_model_dir': '../data/model2', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}\r\n2018-08-11 08:50:44.010343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-08-11 08:50:44.164489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Found device 1 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:05:00.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-08-11 08:50:44.164798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1485] Adding visible gpu devices: 0, 1\r\n2018-08-11 08:50:44.719187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:966] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-11 08:50:44.719236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:972]      0 1\r\n2018-08-11 08:50:44.719243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 0:   N Y\r\n2018-08-11 08:50:44.719247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 1:   Y N\r\n2018-08-11 08:50:44.719771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/device:GPU:0 with 10757 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)\r\n2018-08-11 08:50:44.885422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/device:GPU:1 with 10757 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\r\nINFO:tensorflow:Configured nccl all-reduce.\r\n2018-08-11 08:50:45.166638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1485] Adding visible gpu devices: 0, 1\r\n2018-08-11 08:50:45.166758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:966] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-11 08:50:45.166769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:972]      0 1\r\n2018-08-11 08:50:45.166777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 0:   N Y\r\n2018-08-11 08:50:45.166793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 1:   Y N\r\n2018-08-11 08:50:45.167078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10757 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)\r\n2018-08-11 08:50:45.167251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10757 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 34 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 167, in <module>\r\n    tf.app.run()\r\n  File \"/home/weinman/virtualenv/tf-master-7b80190d52/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"train.py\", line 164, in main\r\n    classifier.train( input_fn=_get_input, max_steps=FLAGS.max_num_steps )\r\n  File \"/home/weinman/virtualenv/tf-master-7b80190d52/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 343, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/weinman/virtualenv/tf-master-7b80190d52/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1127, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/home/weinman/virtualenv/tf-master-7b80190d52/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1256, in _train_model_distributed\r\n    grouped_estimator_spec.scaffold, self._train_distribution)\r\n  File \"/home/weinman/virtualenv/tf-master-7b80190d52/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1576, in _combine_distributed_scaffold\r\n    init_fn = distribution.group(init_fn)\r\n  File \"/home/weinman/virtualenv/tf-master-7b80190d52/local/lib/python2.7/site-packages/tensorflow/python/training/distribute.py\", line 1007, in group\r\n    return control_flow_ops.group(value, name=name)\r\n  File \"/home/weinman/virtualenv/tf-master-7b80190d52/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3396, in group\r\n    \"'%s' with type '%s'\" % (inp, type(inp)))\r\n**TypeError: Expected tf.group() expected Tensor arguments not '<function <lambda> at 0x7fcfe46a8c08>' with type '<type 'function'>'**", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nExact command to reproduce\nMobile device", "Yes, the code still fails with a freshly compiled master, 1bc856ba29bd57378d5c1ca08afc255460597f7f.", "@anj-s @guptapriya Can you comment?", "Thanks. I'm not sure how to best construct a minimum working example, but here's a more concrete sketch than the description in the OP.\r\n\r\nIn our `model_fn.py` which has all the custom Estimator framework, we have something like ...\r\n\r\n```\r\ndef train_fn( tune_from_model ): \r\n    \"\"\"Returns a function that trains the model\"\"\"\r\n\r\n    def train( features, labels, mode ):\r\n\r\n        train_op, loss = _get_training( )\r\n        scaffold = tf.train.Scaffold( init_fn=\r\n                                      _get_init_pretrained( tune_from ) )\r\n\r\n        return tf.estimator.EstimatorSpec( mode=mode, \r\n                                           loss=loss, \r\n                                           train_op=train_op,\r\n                                           scaffold=scaffold )\r\n    return train\r\n```\r\n\r\nand then in our  `train.py` driver \r\n\r\n```\r\n    # Initialize the classifier\r\n    classifier = tf.estimator.Estimator( config=_get_config(), \r\n                                         model_fn=model_fn.train_fn(FLAGS.tune_from),\r\n                                         model_dir=FLAGS.output )\r\n   \r\n    # Train the model\r\n    classifier.train( input_fn=_get_input, max_steps=FLAGS.max_num_steps )\r\n```\r\n\r\nThe root issue seems to be tied to [this line/comment](https://github.com/tensorflow/tensorflow/blob/c8a0dfc741736a59f8fd1776b71f38619d66da56/tensorflow/python/estimator/estimator.py#L1628) in `estimator.py`.", "[Yes](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L1686).", "Does https://github.com/tensorflow/estimator/commit/1f478bf50e922202e6a378557878bd049d4c9007#diff-d934b9f2c2d9384e077e7ab45e001f69 fix this issue? (My guess is not, but want to check) ", "Hello, anything new on this issue ? It seems Scaffold is just unusable with MirroredStrategy, is there a better way ?", "@bamine I haven't tried with the new build yet suggested above, but I hope to soon. I don't know of any convenient alternatives at this time. Are there other ways of loading model parameters?", "I have tried 1.13.1 version, and encounter the same error.", "Hi There,\r\n\r\nWe are moving this issue to closed status, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions.\r\nPlease open a new issue for any help you need against 2.x, and we will get you the right help.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21615\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21615\">No</a>\n"]}, {"number": 21614, "title": "Keras to estimator errors for RNNs", "body": "It seems like a bug that the following model results in the following assert:\r\n\r\nThe model (simplified from seq2seq):\r\n```python\r\n\r\nimport tensorflow as tf\r\n\r\nparams = {\r\n    'seq_len': 32,\r\n    'vocab_size': 50,\r\n    'emb_act_size': 32,\r\n    'rnn_act_size': 64,\r\n    'out_size': 16\r\n}\r\n\r\n\r\ndef mfunc(params):\r\n    inputs = tf.keras.layers.Input(shape=(50, ), dtype='int32')\r\n    emb = tf.keras.layers.Embedding(params[\"vocab_size\"],\r\n                                    params[\"emb_act_size\"])(inputs)\r\n    lstm1, s_h, s_c = tf.keras.layers.LSTM(\r\n        params[\"rnn_act_size\"],\r\n        return_sequences=True,\r\n        return_state=True,\r\n        implementation=2)(emb)\r\n    lstm2 = tf.keras.layers.LSTM(\r\n        params[\"rnn_act_size\"], return_sequences=True)(\r\n            lstm1, initial_state=[s_h, s_c])\r\n    y = tf.keras.layers.Dense(params[\"out_size\"], activation='softmax')(lstm2)\r\n    model = tf.keras.Model(inputs, y)\r\n    model.compile(optimizer='sgd', loss='categorical_crossentropy')\r\n    return model\r\n\r\nx = mfunc(params)\r\ntf.keras.estimator.model_to_estimator(keras_model=x)\r\n```\r\nThe assert we are hitting in TF 1.10:\r\n```python\r\nTraceback (most recent call last):\r\n  File \"Downloads/tmp.py\", line 30, in <module>\r\n    tf.keras.estimator.model_to_estimator(keras_model=x)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/keras.py\", line 548, in model_to_estimator\r\n    keras_weights)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/keras.py\", line 449, in _save_first_checkpoint\r\n    custom_objects)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/keras.py\", line 315, in _clone_and_build_model\r\n    model = models.clone_model(keras_model, input_tensors=input_tensors)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/models.py\", line 263, in clone_model\r\n    return _clone_functional_model(model, input_tensors=input_tensors)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/models.py\", line 168, in _clone_functional_model\r\n    **kwargs))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/recurrent.py\", line 526, in __call__\r\n    self._num_constants)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/recurrent.py\", line 2590, in _standardize_args\r\n    assert initial_state is None and constants is None\r\nAssertionError\r\n```\r\n\r\nHere is the result of the environment capture script:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n== cat /etc/issue ===============================================\r\nLinux 97ddc7134519 4.9.93-linuxkit-aufs #1 SMP Wed Jun 6 16:55:56 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux 97ddc7134519 4.9.93-linuxkit-aufs #1 SMP Wed Jun 6 16:55:56 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy              1.14.5\r\nprotobuf           3.6.0\r\ntensorflow         1.10.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.10.0\r\ntf.GIT_VERSION = v1.10.0-0-g656e7a2b34\r\ntf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34\r\nSanity check: array([1], dtype=int32)", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I'm a colleague of @jmchen-g, and can update the issue while he is away:\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Docker on Mac\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: docker image `tensorflow/tensorflow:1.10.0-py3`\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: python 3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See Below:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nparams = {\r\n    'seq_len': 32,\r\n    'vocab_size': 50,\r\n    'emb_act_size': 32,\r\n    'rnn_act_size': 64,\r\n    'out_size': 16\r\n}\r\n\r\ndef mfunc(params):\r\n    inputs = tf.keras.layers.Input(shape=(50, ), dtype='int32')\r\n    emb = tf.keras.layers.Embedding(params[\"vocab_size\"],\r\n                                    params[\"emb_act_size\"])(inputs)\r\n    lstm1, s_h, s_c = tf.keras.layers.LSTM(\r\n        params[\"rnn_act_size\"],\r\n        return_sequences=True,\r\n        return_state=True,\r\n        implementation=2)(emb)\r\n    lstm2 = tf.keras.layers.LSTM(\r\n        params[\"rnn_act_size\"], return_sequences=True)(\r\n            lstm1, initial_state=[s_h, s_c])\r\n    y = tf.keras.layers.Dense(params[\"out_size\"], activation='softmax')(lstm2)\r\n    model = tf.keras.Model(inputs, y)\r\n    model.compile(optimizer='sgd', loss='categorical_crossentropy')\r\n    return model\r\n\r\nx = mfunc(params)\r\ntf.keras.estimator.model_to_estimator(keras_model=x)\r\n```\r\n\r\nRunning this yields the following trace:\r\n```\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/keras.py\", line 548, in model_to_estimator\r\n    keras_weights)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/keras.py\", line 449, in _save_first_checkpoint\r\n    custom_objects)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/keras.py\", line 315, in _clone_and_build_model\r\n    model = models.clone_model(keras_model, input_tensors=input_tensors)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/models.py\", line 263, in clone_model\r\n    return _clone_functional_model(model, input_tensors=input_tensors)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/models.py\", line 168, in _clone_functional_model\r\n    **kwargs))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/recurrent.py\", line 526, in __call__\r\n    self._num_constants)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/recurrent.py\", line 2590, in _standardize_args\r\n    assert initial_state is None and constants is None\r\nAssertionError\r\n```\r\n\r\nHere is some more system diag info from running `tf_env_collect.sh`\r\n\r\n```\r\n== cat /etc/issue ===============================================\r\nLinux 97ddc7134519 4.9.93-linuxkit-aufs #1 SMP Wed Jun 6 16:55:56 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux 97ddc7134519 4.9.93-linuxkit-aufs #1 SMP Wed Jun 6 16:55:56 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy              1.14.5\r\nprotobuf           3.6.0\r\ntensorflow         1.10.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.10.0\r\ntf.GIT_VERSION = v1.10.0-0-g656e7a2b34\r\ntf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n```\r\n", "Thank you for providing such a clear minimal case.  cc @tanzhenyu @pavithrasv  @fchollet could you take a look?", "Also @qlzh727 for recurrent cells.", "And @k-w-w because this is happening in clone_and_build", "Probably is a bug in the model_to_estimator.\r\n\r\nBtw, the input of the model is not constructed correctly, namely the input shape.\r\n\r\nThe input should be in shape (batch, input_length), which should be (None, seq_len) in your case. The line tf.keras.layers.Input(shape=(50, ) will cause the emb to return (None, 50, 32) and the expected input to LSTM should be (None, 32, 50) \"(batch, timestep, vocab)\".", "@k-w-w and @tanzhenyu, I did some debug and seems that when the lstm2 layer is loaded, the initial_state is showing up both in input as well as initial_state. Since the LSTM layer only accept one input tensor (batch, timestep, vocab), that's why it throws exception. \r\n\r\nDo u have any insight about why the initial_state is picked up both as part of the input and also the kwarg [\"initial_state\"]?", "Hi @k-w-w and @tanzhenyu Any update on this please? Thanks.", "Adding @fchollet, as the error also appears when cloning the model using models.clone_model. ", "I've run into the same issue, and it seem like  _clone_functional_model ends up passing the initial state as both inputs and as a keyword argument to the __call__/_standardize_args method of the Recurrent layer. (1) \r\n\r\nA **nasty workaround** for us was to comment out the code extracting the initial state from the inputs as follows, since the shape of the state in the input list was not complete, but it was in the kwarg:\r\n\r\n`  \r\ndef _standardize_args(...):\r\n  if isinstance(inputs, list):\r\n    # assert initial_state is None and constants is None\r\n    # if num_constants is not None:\r\n    #   constants = inputs[-num_constants:]\r\n    #   inputs = inputs[:-num_constants]\r\n    # if len(inputs) > 1:\r\n    #   initial_state = inputs[1:]\r\n    inputs = inputs[0]`\r\n  ...\r\n(1) in the call to standardize_args when converting to an estimator I get this: \r\n`inputs: [<tf.Tensor 'time_distributed_7/transpose_1:0' shape=(1, ?, 320) dtype=float32>, <tf.Tensor 'input_state_h_2/input_state_h/Identity:0' shape=(?,) dtype=float32>, <tf.Tensor 'input_state_c_2/input_state_c/Identity:0' shape=(?,) dtype=float32>]\r\n\r\ninitial_state kwarg: [<tf.Tensor 'input_state_h:0' shape=(1, 100) dtype=float32>, <tf.Tensor 'input_state_c:0' shape=(1, 100) dtype=float32>]`\r\n\r\nI've not had time to debug where this happens, but I hope it helps someone.", "Can anyone help with this?", "Can you call the model with some input and see it works before converting to the estimator? I suspect this is because initial_state is not passed to the first LSTM.", "This is fixed with latest tf-nightly version '1.15.0-dev20190726'. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=21614\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=21614\">No</a>\n"]}, {"number": 21613, "title": "Implement a Transformer class compatible with seq2seq library", "body": "The current implementation from tensor2tensor is not compatible to the seq2seq library. Another possible implementation in openNMT also write the helper function like `dynamic_decode` itself. This is an attempt to try to add Transformer to have the same interface as `RNNCell` so that it can be more easily used.\r\n\r\nHave I written custom code: N/A\r\nOS Platform and Distribution: N/A\r\nTensorFlow installed from: N/A\r\nTensorFlow version: N/A\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A\r\nMobile device: N/A", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 21612, "title": "conv2d support for bfloat16", "body": "As in the reference for r1.8.0 of tensorflow, the tf.nn.conv2d support bfloat16, but actually when run conv2d with bfloat16 format, got error:\r\nNo OpKernel was registered to support Op 'Conv2D' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_HALF]\r\n\r\nSo is reference wrong, or it is something which would be added later?\r\n", "comments": ["The `DataType` definition calls out that \r\n\r\n```\r\nDT_BFLOAT16 = 14;  // Float32 truncated to 16 bits.  Only for cast ops.\r\n```\r\n\r\nYou could use an artificially less precise Float32 to emulate 16 bits for the time being. ", "thanks.  so reference of conv2d is misleading.\r\n\r\n\r\n\r\n\r\n\r\nOn 2018-08-14 22:00 , Shaba Abhiram<mailto:notifications@github.com> Wrote:\r\n\r\n\r\nThe DataType definition calls out that\r\n\r\nDT_BFLOAT16 = 14;  // Float32 truncated to 16 bits.  Only for cast ops.\r\n\r\n\r\nYou could use an artificially less precise Float32 to emulate 16 bits for the time being.\r\n\r\n\u2014\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/21612#issuecomment-413079257>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AURARP6rlRaYrMOGNbOCEs0SUxxP_OCNks5uQ47YgaJpZM4V9BBy>.\r\n", "It looks as if the docs are wrong yes.", "It looks like the documentation of `conv2d` is automatically generated from tensorflow/core/api_def/base_api/api_def_Conv2D.pbtxt, and `nn_ops.cc`:\r\nhttps://github.com/tensorflow/tensorflow/blob/62191da0819b25906c1b2ed96159cfe36ba00383/tensorflow/core/ops/nn_ops.cc#L265-L270\r\n\r\nDeleting `bfloat16` from `nn_ops.cc` will fix the doc issue although that may break API backward compatibility I think.\r\n\r\nAlternatively it might possible to create a python wrapper of `def conv2d` in `nn_ops.py`, that calls `gen_nn_ops.conv2d`. Then inside `def conv2d` we could have the correct documentation.\r\n\r\nNot sure the best way to handle this situation. Would be happy to create a PR with some guidance.", "Nagging Assignee @MarkDaoust: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21611, "title": "removing redundant semicolon", "body": "## Summary\r\nI discovered semicolon which is the redundant symbol in python.", "comments": ["Nagging Assignee @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21610, "title": "fix 'channels_first' conv3d with None shape inputs", "body": "use array_ops.shape such that 'channels_first' conv3d can support None shape inputs.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Here is a code snippet to reproduce the bug and test the proposed fix: \r\n\r\n```\r\nimport tensorflow as tf\r\nx = tf.placeholder(dtype=tf.float32, shape=[None, 1, None, None, None])\r\ny = tf.layers.conv3d(inputs=x, filters=32, kernel_size=3, data_format='channels_first')\r\n```\r\n\r\n", "With the proposed fix, I can confirm that conv3d can be used with None shape inputs.\r\n\r\n**System information**\r\n- Have I written custom code: yes, as there is no TF sample using conv3d with None shape inputs\r\n- OS Platform and Distribution: Linux Ubuntu 16.04.5 LTS x86_64\r\n- Mobile device: N/C\r\n- TensorFlow installed from: source\r\n- TensorFlow version: b'v1.12.0-874-g70b346d' 1.12.0 / b'v1.10.1-0-g4dcfddc' 1.10.1 / also tested on v1.11\r\n- Python version: 3.5\r\n- Bazel version: 0.15.0 / 0.16.1\r\n- GCC/Compiler version: 5.4.0\r\n- CUDA/cuDNN version: rocm 1.9.2 / cuda 9.2 / cudnn 7.1.4\r\n- GPU model and memory: AMD RX VEGA 56 - 8Gb / Nvidia GTX 1060 - 6 Gb\r\n\r\nOf course conv3d work as expected only with Nvidia GPU, because with AMD GPU there is the MIOpen layout that is limited to 4D tensors and you need a 5D tensors to run conv3d.\r\n", "@shiyangc-intusurg can you please resolve conflicts ?", "It seems since 2.0.0alpha, conv3d does not need to be treated specially when doing bias_add. That means it should not have any problem doing conv3d with None shape and channel_first. If you can verify that is true, feel free to close this request.", "From the context looks like conv3d is fixing this issue. Closing it."]}, {"number": 21609, "title": "Tensorflow profiling data for every layers of CNN", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nNot applicable\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary. pip install in virtualenv\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n1.9.0\r\n- **Bazel version (if compiling from source)**:\r\nNot applicable\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nProblem is related to profiling of Tensorflow model for specific network arhitecture, for instance, consider vgg16. We want to get all operator level profiling data on a layer (Layers in CNN) by layer basis. I have used tf.profiler.Profiler class and was able to generate profiling data. But those data are all aggregration of all operations. In tensorflow lite there is a mechanism using which we can generate layer by layer, operator level profiling data.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/tools/benchmark/README.md\r\n============================== Run Order ==============================\r\n\t             [node type]\t  [start]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\r\n\t                 CONV_2D\t    0.000\t    4.269\t    4.269\t  0.107%\t  0.107%\t     0.000\t        0\t[MobilenetV1/MobilenetV1/Conv2d_0/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t    4.270\t    2.150\t    2.150\t  0.054%\t  0.161%\t     0.000\t        0\t[MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6]\r\n\t                 CONV_2D\t    6.421\t    6.107\t    6.107\t  0.153%\t  0.314%\t     0.000\t        0\t[MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Relu6]\r\nIs there anyway I can generate that kind of data in tensorflow?\r\n\r\n\r\n### Source code / logs\r\nTensorflow benchmarking script is being used to generate profiling data.\r\nhttps://github.com/tensorflow/benchmarks.git", "comments": ["@ahsankabir18 : You can use: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/benchmark for similar numbers."]}]