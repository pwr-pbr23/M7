[{"number": 5213, "title": "dyld: lazy symbol binding failed", "body": "I use OSX10.12, I try to use OpenCV in tensorflow, I use the first method which is mentioned [here](http://stackoverflow.com/questions/34984290/building-opencv-code-using-bazel).\n\nI build my code successfully but there are some questions as following when I execute it:\n`dyld: lazy symbol binding failed: Symbol not found: __ZN2cv6String8allocateEm\nReferenced from: /Users/philokey/Practice/github/tensorflow/./bazel-bin/tensorflow/examples/test_cv/test_cv\nExpected in: flat namespace`\n\nThe build file is as following:\n\n```\ncc_binary(\nname = \"test_cv\",\nsrcs = [\n    \"test_cv.cc\",\n],\ndeps = [\n    \"@opencv//:opencv\",\n],\n)\n```\n\nHow can I sovle this problem?\nBy the way, the question is also asked in [stackoverflow](http://stackoverflow.com/questions/40259156/osx-tensorflow-opencv-symbol-not-found-expected-in-flat-namespace)\n", "comments": ["I solved this problem.\nI should use .dylib instead of .so\n"]}, {"number": 5212, "title": "ubuntu16.04 GTX1060 cuda8.0 Found 0 targets...", "body": "tensorflow$ ./configure ~/Documents/tensorflow ~/Documents/tensorflow\nPlease specify the location of python. [Default is /home/hammer/anaconda2/bin/python]: \nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] y\nHadoop File System support will be enabled for TensorFlow\nFound possible Python library paths:\n  /home/hammer/anaconda2/lib/python2.7/site-packages\n  /home/hammer/Documents/SSD/caffe/python\nPlease input the desired Python library path to use.  Default is [/home/hammer/anaconda2/lib/python2.7/site-packages]\n\n/home/hammer/anaconda2/lib/python2.7/site-packages\nDo you wish to build TensorFlow with GPU support? [y/N] y\nGPU support will be enabled for TensorFlow\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: \nPlease specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nlibcudnn.so resolves to libcudnn.5\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n...........\nINFO: All external dependencies fetched successfully.\nConfiguration finished\nGT72VR-6RD:~/Documents/tensorflow$ bazel build -c opt --config=cuda\nINFO: Found 0 targets...\nINFO: Elapsed time: 1.535s, Critical Path: 0.01s\n\nI get no error, but I don't know what to do.\n", "comments": ["You have to specify at least one target to build, e.g. tensorflow/examples/label_image:label_image or the pip package:\n`bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`\n\nPlease follow the next step after ./configure [Installing from sources](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#create-the-pip-package-and-install).\n", "Thank you. I always think \"//\" means note  \n"]}, {"number": 5211, "title": "Fix: also include dirent.h in cuda_diagnostics for compilation on mac.", "body": "", "comments": ["@gunan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @guschmue, @keveman and @yaroslavvb to be potential reviewers.\n", "http://ci.tensorflow.org/job/tensorflow-pull-requests-mac-gpu/1\nrunning test for mac-gpu, where the issue showed up.\n", "the gpu mac build shows the main issue being fixed, however it reveals another problem :|\n", "First of all, thanks for fixing the compilation error! I'm not sure what could be causing the error... could it be a driver or CUDA version issue on the Mac?\n\nThere are a few warnings in the stream_executor code, but no smoking gun that I can see....\n", "Nope, the test failure is we are trying to run multiple tests on a single\nGPU. That one is my bad.\n\nOn Oct 26, 2016 7:36 AM, \"Derek Murray\" notifications@github.com wrote:\n\n> First of all, thanks for fixing the compilation error! I'm not sure what\n> could be causing the error... could it be a driver or CUDA version issue on\n> the Mac?\n> \n> There are a few warnings in the stream_executor code, but no smoking gun\n> that I can see....\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/5211#issuecomment-256366506,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AHlCOS7ojZFMwLzqV2iERksUDSQyYf3cks5q32VlgaJpZM4Kg2XA\n> .\n", "Ah cool. I'm happy to approve this, anyway! Are the Mac GPU tests passing again?\n", "I will work on those next, as I was not able to test my changes.\n", "Nope, just completed setting up the new macs, I will look into the failures\nnow.\n\nOn Wed, Oct 26, 2016 at 10:42 AM, Derek Murray notifications@github.com\nwrote:\n\n> _@mrry_ approved this pull request.\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/5211#pullrequestreview-5909329,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AHlCOUnf9Aqq5RW1VkPmhIXym_OwhnC5ks5q35EUgaJpZM4Kg2XA\n> .\n"]}, {"number": 5210, "title": "Mingmingyang patch 1", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@mingmingyang, thanks for your PR! By analyzing the history of the files in this pull request, we identified @dsmilkov, @keveman and @danmane to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 5209, "title": "Cherry Pick: Automatically build SWIG from source", "body": "Reviewer: @gunan \n\nThis PR cherry-picks 1dba78b997dc49df9df663a838e0bacd6602f5b8 and cl/137268906 onto r0.11.\n", "comments": ["@jart, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @vrv and @tensorflower-gardener to be potential reviewers.\n", "@yifeif looks like we have a few more fixes. This one is needed to fix docker build at head.\nThe tests look bad. Could you look into what is wrong with them?\n", "Yeah whatever those errors are, they look pretty bad.\n", "If we cherry-pick this, please cherry-pick the upgrade CL/137268906 as well.\n", "The latest builds on this branch have been healthy, so the test failures are either infra issues or caused by this PR.\n", "Done. Please don't squash when merging.\n", "All three builds failed with '/tensorflow/python/BUILD:1749:1: C++ compilation of rule '//tensorflow/python:_pywrap_tensorflow.so' failed'\n", "Is there anything else that's needed from master to go with this PR?\n", "I don't even know where to begin with that error. I can't reproduce it locally.\n", "We cannot merge the PR with the test failures.\nTo unblock the release, can we add the swig dependency to the master Dockerfile to unblock the release, and with 0.12, we can remove that dependency?\n", "Just to make sure, Jenkins, test this please.\n", "These do not look like flakes. I am closing this PR, let's fix the issue in master by adding the deb package back.\n"]}, {"number": 5208, "title": "Cherry-picks for 0.11.0rc2", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ebrevdo, @ilblackdragon and @gunan to be potential reviewers.\n"]}, {"number": 5207, "title": "fix for issue #5169", "body": "in nvcc -gencode we need to specify both sm_ and compute_, else we can not\nfallback to a lower compute capability.\n", "comments": ["Can one of the admins verify this patch?\n", "@guschmue, thanks for your PR! By analyzing the history of the files in this pull request, we identified @mrry, @ageron and @lilac to be potential reviewers.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 5206, "title": "Let build_server.sh take whl file URL as an input argument.", "body": "This make it possible to test OSS GRPC distributed runtime in\ndist_test/remote_test.sh against a release build.\n\nUsage example:\n1. Build the server using a release whl file. (Obviously this means that\nthe Linxu CPU PIP release build has to pass first.)\n  $ export DOCKER_VERSION_TAG=\"0.11.0rc1\"\n    $ tensorflow/tools/dist_test/build_server.sh\n    tensorflow/tf_grpc_test_server:${DOCKER_VERSION_TAG}\n    http://ci.tensorflow.org/view/Release/job/release-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-${DOCKER_VERSION_TAG}-cp27-none-linux_x86_64.whl\n    --test\n\n```\n2. Run remote_test.sh:\n  $ export TF_DIST_DOCKER_NO_CACHE=1\n  $ export\nTF_DIST_SERVER_DOCKER_IMAGE=\"tensorflow/tf_grpc_test_server:${DOCKER_VERSION_TAG}\"\n$ export TF_DIST_GCLOUD_PROJECT=\"my-project\"\n$ export TF_DIST_GCLOUD_COMPUTE_ZONE=\"my-zone\"\n$ export TF_DIST_CONTAINER_CLUSTER=\"my-cluster\"\n$ export TF_DIST_GCLOUD_KEY_FILE=\"/path/to/my/key.json\"\n$ tensorflow/tools/dist_test/remote_test.sh\n      \"http://ci.tensorflow.org/view/Release/job/release-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-${DOCKER_VERSION_TAG}-cp27-none-linux_x86_64.whl\"\n```\n", "comments": ["@caisq, thanks for your PR! By analyzing the history of the files in this pull request, we identified @yifeif to be a potential reviewer.\n"]}, {"number": 5205, "title": "tensorflow runs much slower/ installation issue?", "body": "I installed tensorflow version 0.11.0rc0 using the .whl provided and the following code runs terribly slower (on macosx cpu) compared to its numpy counterpart.\n\nIs  tf version  0.11.0rc0 a stable release?  Is tensorflow expected to run extremely slow inside a python for loop?\n\n```\nfrom math import *\nimport numpy as np\nimport sys\nfrom multiprocessing import Pool\nimport tensorflow as tf\n\ndef Trajectory_Fun(tspan, a, b, session=None, server=None):\n    if session==None:\n        if server==None:\n            sess = tf.Session()\n        else:\n            sess = tf.Session(server.target)       \n    else:\n        sess = session\n    B = np.zeros(np.size(tspan), dtype=np.float64)\n    B[0] = b\n    for i, t in enumerate(tspan):\n        r = np.random.rand(1)\n        if r>a:\n            c = sess.run(tf.trace(tf.random_normal((4, 4), r, 1.0)))\n        else:\n            c = 0.0 # sess.run(tf.trace(tf.random_normal((4, 4), 0.0, 1.0)))\n        B[i] = c\n    if session==None:\n        sess.close()\n    return B\n\n\ndef main(argv):\n   tspan = np.arange(0.0, 1000.0)\n   a = 0.1\n   b = 0.0\n   B = Trajectory_Fun(tspan, a, b, None, None)\n   print 'Done!'\n\n\nif __name__ == \"main\":\n    main(sys.argv[1:]) `\n```\n", "comments": ["Could you cross-post on stackoverflow with tag \"tensorflow\"?\n\n@aselle about numpy comparison.\n", "@drpngx, I already posted on stackoverflow as well. Technically, this is not quite a numpy comparison. It is more about running tensorflow inside a python for loop. I must be missing something here. The above code runs incredibly slow.\n", "Of a total elapsed time of 54s, with 17M function calls.\n\n| ncalls | tottime | percall | cumtime | percall | `filename:lineno(function)` |\n| --: | --: | --- | --- | --- | --- |\n| 904 | 35.775 | 0.040 | 35.775 | 0.040 | `{_pywrap_tensorflow.TF_ExtendGraph}` |\n| 904 | 6.605 | 0.007 | 6.605 | 0.007 | `{_pywrap_tensorflow.TF_Run}` |\n| 378938/246954 | 1.420 | 0.000 | 3.013 | 0.000 | `python_message.py:481(init)` |\n| 904 | 0.585 | 0.001 | 2.634 | 0.003 | `ops.py:2191(_as_graph_def)` |\n| 239560/128368 | 0.507 | 0.000 | 1.808 | 0.000 | `python_message.py:1229(MergeFrom)` |\n\n[profile.txt](https://github.com/tensorflow/tensorflow/files/551851/profile.txt)\n", "Thanks.  Now, if you replace  \nc = sess.run(tf.trace(tf.random_normal((4, 4), r, 1.0)))\nwith\nc = np.sum(np.diag(np.random.normal(0.0, 1.0, (4, 4))))\n\nin for loop of \"Trajectory_Fun\", the entire program runs in about  1 second.\n", "@annarev @mrry for potential additional insights.\n", "As far as TensorFlow programs go, this is a pessimal case. The underlying assumption in TensorFlow is (approximately) that you'll build a graph once and then call `sess.run()` on (various parts of) it multiple times. The tax of calling `TF_ExtendGraph` is paid once on the first use of a graph, and subsequent uses are much cheaper. If you must use a loop _within_ your TensorFlow graph, there are constructs like `tf.while_loop()` (and, similarly, `tf.cond()` for if-statements) that you can use.\n\nYou can make this program much faster by constructing the graph once and using (e.g.) a placeholder to feed in the value that changes in each iteration. For example, the following should do the trick:\n\n``` python\ndef Trajectory_Fun(tspan, a, b, session=None, server=None):\n    if session==None:\n        if server==None:\n            sess = tf.Session()\n        else:\n            sess = tf.Session(server.target)       \n    else:\n        sess = session\n    B = np.zeros(np.size(tspan), dtype=np.float64)\n    B[0] = b\n\n    # Define the TensorFlow graph once and reuse it in each iteration of the for loop.\n    r_placeholder = tf.placeholder(tf.float32, shape=[])\n    out_t = tf.trace(tf.random_normal((4, 4), r_placeholder, 1.0))\n\n    for i, t in enumerate(tspan):\n        r = np.random.rand(1)\n        if r>a:\n            c = sess.run(out_t, feed_dict={r_placeholder: r})\n        else:\n            c = 0.0\n        B[i] = c\n    if session==None:\n        sess.close()\n    return B\n```\n\nYou could potentially make this even more efficient by using a TF loop and making fewer calls to `sess.run()`, but the general principle is the same: reuse the graph multiple times to get the benefit of TensorFlow.\n", "Many thanks for clarifying. It cleared up some of my confusion.  \n"]}, {"number": 5204, "title": "Fixed failed building of /pi_examples/label_image.", "body": "Included <stdio.h> before including <jpeglib.h> because jpeglib.h implicitly requires it.\nCast 'usage' variable to 'const char*' because tensorflow::port::InitMain() function requires C-style string instead of std::string.\n", "comments": ["Can one of the admins verify this patch?\n", "@drag0, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener to be a potential reviewer.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "@googlebot I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "One more try.  @tensorflow-jenkins test this please\n", "Seems like unrelated failures.\n"]}, {"number": 5203, "title": "Explanation about 'SAME' padding doesn't cover edge cases", "body": "In the [docs](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#convolution), it explains the padding as follows:\n\n```\nFor the 'SAME' padding, the output height and width are computed as:\n\nout_height = ceil(float(in_height) / float(strides[1]))\nout_width  = ceil(float(in_width) / float(strides[2]))\n\nand the padding on the top and left are computed as:\n\npad_along_height = ((out_height - 1) * strides[1] +\n                    filter_height - in_height)\npad_along_width = ((out_width - 1) * strides[2] +\n                   filter_width - in_width)\npad_top = pad_along_height / 2\npad_left = pad_along_width / 2\n```\n\nWhen `in_height=20, stride=2, filter_height=1`, we will end up with `pad_along_height=-1`. I think it's unclear what this means (is there padding or not?). Further explanation are needed to document the behavior in this case.\n\nAlso, when `in_height=19, stride=2, filter_height=1`, we will end up with `out_height=10, pad_along_height=0, pad_top=0`.  But with 19 inputs and stride=2 how can you have 10 output without padding? This doesn't seem right.\n", "comments": ["It sounds reasonable to add documentation and a unit test to clarify, if you're willing to submit a PR.\n\n@vrv perhaps to weigh in on the 2nd point.\n", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/common_shape_fns.cc#L19 is the implementation the runtime uses.  For the first case, a negative padding is clipped to 0, though what it means is that the windows do not cover the entire input because you couldn't satisfy the 'output size' for SAME if you tried.\n\nAs for the second:  Let's say our 19 values are:\n\nA B C D E F G H I J K L M N O P Q R S\n\nWe are selecting filter size of 1 and stride of 2, so we get:\nA C E G I K M O Q S\n\nwhich are 10 values.\n\nFeel free to update our documentation if you think there's something better we can do, but I don't think there's a bug here?\n", "Oh yes. The second case is my misunderstanding. There isn't a bug here but the documentation can be improved a bit on the first case.\n", "Thanks @vrv for the clarification! @ppwwyyxx, please send a PR with doc changes if you want.\n"]}, {"number": 5202, "title": "Bug report: Commit 20c02ff broke something concerning building example /label_image for Raspberry Pi", "body": "This is the diff in question:\nhttps://github.com/tensorflow/tensorflow/commit/20c02ffe0e6b8af4902487f852e15daa16caa523#diff-48887acc98c15e53f942842ecd65190fR318\n\nI managed to successfully build this example by changing code. Since I'm not really good with C++ I'm not sure if my solution is the best. It would be great if someone more experienced could take a look at it.\n\nHere is the issue where I explain how I fixed it: https://github.com/tensorflow/tensorflow/issues/5200\n", "comments": ["See #5200, PR coming.\n"]}, {"number": 5201, "title": "Let build_server.sh take whl file URL as an input argument.", "body": "This make it possible to test OSS GRPC distributed runtime in\ndist_test/remote_test.sh against a release build.\n\nUsage example:\n1. Build the server using a release whl file. (Obviously this means that\nthe Linxu CPU PIP release build has to pass first.)\n  $ export DOCKER_VERSION_TAG=\"0.11.0rc1\"\n    $ tensorflow/tools/dist_test/build_server.sh\n    tensorflow/tf_grpc_test_server:${DOCKER_VERSION_TAG}\n    http://ci.tensorflow.org/view/Release/job/release-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-${DOCKER_VERSION_TAG}-cp27-none-linux_x86_64.whl\n    --test\n\n```\n2. Run remote_test.sh:\n  $ export TF_DIST_DOCKER_NO_CACHE=1\n    $ export\nTF_DIST_SERVER_DOCKER_IMAGE=\"tensorflow/tf_grpc_test_server:${DOCKER_VERSION_TAG}\"\n  $ export TF_DIST_GCLOUD_PROJECT=\"my-project\"\n    $ export TF_DIST_GCLOUD_COMPUTE_ZONE=\"my-zone\"\n      $ export TF_DIST_CONTAINER_CLUSTER=\"my-cluster\"\n        $ export TF_DIST_GCLOUD_KEY_FILE=\"/path/to/my/key.json\"\n      $ tensorflow/tools/dist_test/remote_test.sh\n      \"http://ci.tensorflow.org/view/Release/job/release-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-${DOCKER_VERSION_TAG}-cp27-none-linux_x86_64.whl\"\n```\n", "comments": ["@caisq, thanks for your PR! By analyzing the history of the files in this pull request, we identified @gunan to be a potential reviewer.\n", "Is this commit merged into master?\nIf not, let's first merge it there then cherrypick into release.\n", "@gunan sounds good.\n", "@tensorflow-jenkins test this please.\n", "what's the best way to merge this into master without creating a bunch of conflicts?\n", "The easiest way is for @caisq to create a new branch and a new PR with this.\nWe cannot simply change base branch, as that will try to merge the development branch to be merged, with all specific r0.11 changes, I think.\n", "@gunan, @yifeif let me create a PR for the master branch.\n", "Thanks @caisq !\n", "Closing this PR. Will cherry pick 7ba17e2c0dc0e1f1a92de0a3373b4f2197ad8077 to r0.11 branch.\n"]}, {"number": 5200, "title": "Error when building /pi_examples/label_image on RPi 3 (/usr/include/jpeglib.h:792:3: error: \u2018size_t\u2019 does not name a type)", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nSome comments here mention the same problem: https://github.com/tensorflow/tensorflow/issues/4680#issuecomment-256078792\n### Environment info\n\nOperating System:\nRaspberry Pi 3\nRASPBIAN JESSIE WITH PIXEL\nImage with PIXEL desktop based on Debian Jessie\nVersion:September 2016\nRelease date:2016-09-23\nKernel version:4.4\nIf installed from source, provide \n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nfollowed instructions here:\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples/\n### What other attempted solutions have you tried?\n\nTried changing compiler defined in Makefile to g++-4.8 but to no avail\n### Logs or other output that would be helpful\n\n> make -f tensorflow/contrib/pi_examples/label_image/Makefile \n> gcc --std=c++11 -O0 -I/usr/local/include -I. -I/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/downloads -I/home/pi/code/tensorflow/t\n> ensorflow/contrib/pi_examples/label_image/../../makefile/downloads/eigen/ -I/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto\n> / -I/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/../../makefile/gen/proto_text/ -c tensorflow/contrib/pi_examples/label_image/label_image.cc -o /\n> home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o\n> In file included from tensorflow/contrib/pi_examples/label_image/label_image.cc:26:0:\n> /usr/include/jpeglib.h:792:3: error: \u2018size_t\u2019 does not name a type\n>    size_t free_in_buffer; /\\* # of byte spaces remaining in buffer _/\n>    ^\n> /usr/include/jpeglib.h:804:3: error: \u2018size_t\u2019 does not name a type\n>    size_t bytes_in_buffer; /_ # of bytes remaining in buffer _/\n>    ^\n> In file included from /usr/include/jpeglib.h:29:0,\n>                  from tensorflow/contrib/pi_examples/label_image/label_image.cc:26:\n> /usr/include/jpeglib.h:835:3: error: \u2018size_t\u2019 has not been declared\n>    JMETHOD(void *, alloc_small, (j_common_ptr cinfo, int pool_id,\n>    ^\n> /usr/include/jpeglib.h:837:3: error: \u2018size_t\u2019 has not been declared\n>    JMETHOD(void FAR *, alloc_large, (j_common_ptr cinfo, int pool_id,\n>    ^\n> In file included from tensorflow/contrib/pi_examples/label_image/label_image.cc:26:0:\n> /usr/include/jpeglib.h:990:34: error: \u2018size_t\u2019 has not been declared\n>  EXTERN(void) jpeg_CreateCompress JPP((j_compress_ptr cinfo,\n>                                   ^\n> /usr/include/jpeglib.h:992:36: error: \u2018size_t\u2019 has not been declared\n>  EXTERN(void) jpeg_CreateDecompress JPP((j_decompress_ptr cinfo,\n>                                     ^\n> /usr/include/jpeglib.h:1000:30: error: \u2018FILE\u2019 has not been declared\n>  EXTERN(void) jpeg_stdio_dest JPP((j_compress_ptr cinfo, FILE \\* outfile));\n>                               ^\n> /usr/include/jpeglib.h:1001:29: error: \u2018FILE\u2019 has not been declared\n>  EXTERN(void) jpeg_stdio_src JPP((j_decompress_ptr cinfo, FILE \\* infile));\n>                              ^\n> tensorflow/contrib/pi_examples/label_image/label_image.cc: In function \u2018tensorflow::Status LoadJpegFile(std::string, std::vector<unsigned char>_, int_, int_, int_)\u2019:\n> tensorflow/contrib/pi_examples/label_image/label_image.cc:108:32: error: cannot convert \u2018FILE_ {aka _IO_FILE_}\u2019 to \u2018int_\u2019 for argument \u20182\u2019 to \u2018void jpeg_stdio_src(j_dec\n> ompress_ptr, int_)\u2019\n>    jpeg_stdio_src(&cinfo, infile);\n>                                ^\n> tensorflow/contrib/pi_examples/label_image/label_image.cc: In function \u2018int main(int, char__)\u2019:\n> tensorflow/contrib/pi_examples/label_image/label_image.cc:318:3: error: \u2018vector\u2019 was not declared in this scope\n>    vector tensorflow::Flag > flag_list = {\n>    ^\n> tensorflow/contrib/pi_examples/label_image/label_image.cc:318:3: note: suggested alternatives:\n> In file included from /usr/include/c++/4.9/vector:64:0,\n>                  from tensorflow/contrib/pi_examples/label_image/label_image.cc:29:\n> /usr/include/c++/4.9/bits/stl_vector.h:214:11: note:   \u2018std::vector\u2019\n>      class vector : protected _Vector_base<_Tp, _Alloc>\n>            ^\n> /usr/include/c++/4.9/bits/stl_vector.h:214:11: note:   \u2018std::vector\u2019\n> tensorflow/contrib/pi_examples/label_image/label_image.cc:333:52: error: \u2018flag_list\u2019 was not declared in this scope\n>    string usage = tensorflow::Flags::Usage(argv[0], flag_list);\n>                                                     ^\n> tensorflow/contrib/pi_examples/label_image/label_image.cc:335:8: error: in argument to unary !\n>    if (!parse_result) {\n>         ^\n> tensorflow/contrib/pi_examples/label_image/label_image.cc:341:49: error: cannot convert \u2018std::string {aka std::basic_string<char>}\u2019 to \u2018const char_\u2019 for argument \u20181\u2019 to\n>  \u2018void tensorflow::port::InitMain(const char_, int_, char_**)\u2019\n>    tensorflow::port::InitMain(usage, &argc, &argv);\n>                                                  ^\n> tensorflow/contrib/pi_examples/label_image/Makefile:79: recipe for target '/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contri\n> b/pi_examples/label_image/label_image.o' failed\n> make: *_\\* [/home/pi/code/tensorflow/tensorflow/contrib/pi_examples/label_image/gen/obj/tensorflow/contrib/pi_examples/label_image/label_image.o] Error 1\n", "comments": ["I've solved half of errors by adding \n`#include <stdio.h>`\nbefore line:\n`#include <jpeglib.h>`\n\nNow I'm getting:\n\n> tensorflow/contrib/pi_examples/label_image/label_image.cc:319:3: error: \u2018vector\u2019 was not declared in this scope\n", "Just managed to build it successfully with slight code changes. I don't know C++ but I followed errors and fixed it one by one. It seems that this commit broke things: https://github.com/tensorflow/tensorflow/commit/20c02ffe0e6b8af4902487f852e15daa16caa523#diff-48887acc98c15e53f942842ecd65190f\n\nSo what I did was:\n\nOpen label_image.cc and do this:\n\nAdd:\n`#include <stdio.h>`\nbefore \n`include <jpeglib.h>`\n\nFind:\n`vector tensorflow::Flag > flag_list = {` around line 320 and change it to:\n`std::vector<tensorflow::Flag> flag_list = {`\n\nLast thing, just couple lines after last change:\n`tensorflow::port::InitMain(usage, &argc, &argv);` change it to:\n`tensorflow::port::InitMain(argv[0], &argc, &argv);`\n\nThat's it, now just run:\n`make -f tensorflow/contrib/pi_examples/label_image/Makefile`\nand wait a minute while it finishes, you can then run example by running:\n`tensorflow/contrib/pi_examples/label_image/gen/bin/label_image`\n\nCould anyone help me understand what happened in this diff that broke things and how it got merged to master? Also, I'm not really sure last change is the right thing to do, but it compiles and builds so it is a quickfix for me.\n", "Thanks! Would you mind sending a PR?\n", "No problem, It's getting a bit late here so I might send it tomorrow morning. \n", "Nice, thanks!\n", "Thanks, worked for me! Some really obvious errors there that a linter would have picked up.\n", "Go this to work, thank you @drag0 \n"]}, {"number": 5199, "title": "tensor.eval() function converts a tensor to a numpy array is very slow. ", "body": "I am using inception V1 model to predict image. The input needs a 4d array.\n\nThis section is read a image and resize to 224 \\* 224 \\* 3, then whitening, then convert to 4D tensor\n\n---\n\n  with open(image, 'rb') as f:\n    image_data = f.read()\n\n  image_buffer=tf.image.decode_jpeg(image_data)\n  resize_image=tf.image.resize_images(image_buffer,[224,224])\n  unified_image=tf.image.per_image_whitening(resize_image)\n  image_4dTensor=tf.expand_dims(unified_image, 0)\n\n---\n\nThis section is to input an image and run the session. Since i can't input a 4D tensor but a numpy array into the session, I need convert 4D tensor to 4D array by call **tensor.eval()**. However i found that this conversion for a 1 \\* 224 \\* 224 \\* 3 tensor is very slow. It needs 0.4-0.6s. The prediction itself only takes less than 0.2s (run through 22 layers for a input 4D array ). So Is there anyway to convert a tensor to a numpy array faster?\n\n  with tf.Session() as sess:\n\n```\nstamp1=time.time()\nimage_array=image_4dTensor.eval()\ntime_cost=time.time()-stamp1\nprint (time_cost)\n```\n", "comments": ["This may be better for stackoverflow, but I would guess you need to hook up your inception v1 to accept a tensor instead of numpy array, possibly using graph_editor to do the change if you are loading an existing graph\n", "I am using the public inception v1 model. pb file. I do not change anything.\n", "tensorflow model itself does not accept a tensor object is very ironic.\n", "That's because to accept a tensor, you need to prepend a node to an existing graph, and until recently (graph_editor), this was not possible because graphs were append-only (no prepend)\n", "I also have the same issue but with my own code. I tried to use image_batch.eval() and it is extremely slow. the batch size is only 3, 1024, 1024, 3. I am not sure if the eval() works properly.", "`eval` recalculates all tensors that are needed to get the result, if you want to speed things up, you should cache things into `tf.Variable` objects"]}, {"number": 5198, "title": "[issue#4453]Get rid of the variable_op wrapper.", "body": "PR for the `# TODO(mrry): Move this to where it is used, so we can get rid of this op wrapper?`\nin the [state_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/state_ops.py#L151)\n\nDetails refer to [issue#4453](https://github.com/tensorflow/tensorflow/issues/4453)\n\nChanged file list which call the `state_ops.variable_op()`:\n\n```\nVariables.py\nVariables_test.py\nTensor_util_test.py\nMoving_averages_test.py\nLearning_rate_decay_test.py\nGraph_util_test.py\nControl_flow_ops_py_test.py\n```\n\n@drpngx Please review\n", "comments": ["Can one of the admins verify this patch?\n", "@DjangoPeng, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @theweiho and @martinwicke to be potential reviewers.\n", "I think @drpngx has been looking at the necessary API changes for the internal version, so I'll defer to his good judgement on this PR :).\n", "@drpngx Update `name` of all variables with more info.\n", "Jenkins, test this please.\n", "Oh, there's no set_shape. Could you fix & check?\n", "It seems like that I have to use `var.set_shape()` instead of passing the `set_shape` arg into `gen_state_ops._variable()`. \n", "@drpngx Fixed, please check and test.\n", "Jenkins, test this please.\n", "You need to change the `control_flow_ops_test`.\n", "We also have internal changes that might interfere with this. We'll merge them soon. Stay tuned.\n", "@drpngx Sorry, I forget `Control_flow_ops_py_test.py`.  \nLook forward to your good news :).\n", "Jenkins, test this please.\n", "@drpngx It says there is a conflicting file named `variables.py`, while I can't find where to check the conflicts. Do you know how to handle it?\n", "If you pull the latest and rebase , it should show you. if there is no\nconflict,then just check the tests and push\n\nOn Oct 28, 2016 7:52 AM, \"Jingtian Peng\" notifications@github.com wrote:\n\n> @drpngx https://github.com/drpngx It says there is a conflicting file\n> named variables.py, while I can't find where to check the conflicts. Do\n> you know how to handle it?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/5198#issuecomment-256941107,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AT_SbRZOywVdquuLJwEKUsp1PeJ05QQHks5q4gw5gaJpZM4KgQsV\n> .\n", "@mrry updated `variables.py` yesterday. Luckily, I find the conflict and work on it.@drpngx\n", "Jenkins, test this please.\n", "@drpngx I resolved the conflicts manually. Do I need to `reset --hard origin/master` and update code to push a new commit? \n", "@drpngx I reset the branch and `commit -am`. Please test the change, thanks.\n", "Jenkins, test this please.\n", "Jenkins, test this please.\n", "@drpngx LGTM\n"]}, {"number": 5197, "title": "Mac nightly build links in readme are broken", "body": "Maybe this is because the last successful build was a month ago?\n\ne.g. \nMac CPU-only: Python 3 ->\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac1-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc1-py3-none-any.whl\n\nThis page shows:\n\n```\nHTTP ERROR 404\n\nProblem accessing /view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac1-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc1-py3-none-any.whl. Reason:\n\n    Not Found\n```\n", "comments": ["How about this one?\n\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc1-py3-none-any.whl\n", "Also, nightly wheels for Mac GPU are present, but still using the old 11rc0\nname instead of 11rc1\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-mac-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-mac/\n\nOn Tue, Oct 25, 2016 at 9:49 AM, Will Whitney notifications@github.com\nwrote:\n\n> Maybe this is because the last successful build was a month ago?\n> \n> e.g.\n> Mac CPU-only: Python 3 ->\n> https://ci.tensorflow.org/view/Nightly/job/nightly-\n> matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_\n> BUILD_PYTHON_VERSION=PYTHON3,label=mac1-slave/\n> lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.\n> 0rc1-py3-none-any.whl\n> \n> This page shows:\n> \n> HTTP ERROR 404\n> \n> Problem accessing /view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac1-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc1-py3-none-any.whl. Reason:\n> \n> ```\n> Not Found\n> ```\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/5197, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHAaTbsthl6S9Ml-oK4SQY28sFJ31ks5q3jMUgaJpZM4KgOOZ\n> .\n", "Yup, that works.\n\nOn Tue, Oct 25, 2016 at 2:38 PM drpngx notifications@github.com wrote:\n\n> How about this one?\n> \n> https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc1-py3-none-any.whl\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/5197#issuecomment-256131420,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAkfRUDSGxeZpNnqHqk44N3g4vq10Nesks5q3kyMgaJpZM4KgOOZ\n> .\n", "Woohoo!\n"]}, {"number": 5196, "title": "Changed context creation to use primary context", "body": "Using cuCtxCreate/Destroy does not give any benefits over using primary context and is not advised by the CUDA documentation: http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#multiple-contexts.\nMoreover, it breaks interaction with some runtime API calls, like cudaPointerGetAttributes and cudaEnablePeerAccess (see section Context Interoperability in: http://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER.html#group__CUDART__DRIVER).\nThis PR changes how the context are obtained and released from cuCtxCreate/Destroy to cuDevicePrimaryCtxRetain/Release \n", "comments": ["Can one of the admins verify this patch?\n", "@ptrendx, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman and @zheng-xq to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@leary-google, @henline, could you review this change? \n", "@tensorflow-jenkins test this please. \n", "Wait, this PR is created against the r0.11 release branch.\nIt should be submitted to master. I think there has been a mistake.\n\nWe are not accepting anything but bugfixes into r0.11 branch, therefore I will close this PR.\n"]}, {"number": 5195, "title": "Sum Total of in-use chunks: 7.23GiB, but it tried to allocate 8.00GiB", "body": "> I tensorflow/core/common_runtime/bfc_allocator.cc:689]      Summary of in-use Chunks by size: \n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 22 Chunks of size 256 totalling 5.5KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 5 Chunks of size 512 totalling 2.5KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 1280 totalling 1.2KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 7499 Chunks of size 2048 totalling 14.65MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1087 Chunks of size 4096 totalling 4.25MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 4608 totalling 4.5KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 6144 totalling 6.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 616 Chunks of size 8192 totalling 4.81MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 9984 totalling 9.8KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 4 Chunks of size 10240 totalling 40.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 2 Chunks of size 12288 totalling 24.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 303 Chunks of size 14336 totalling 4.14MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 5 Chunks of size 198656 totalling 970.0KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 208384 totalling 203.5KiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 919 Chunks of size 8388608 totalling 7.18GiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 10775552 totalling 10.28MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:692] 1 Chunks of size 14428160 totalling 13.76MiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:696] Sum Total of in-use chunks: 7.23GiB\n> I tensorflow/core/common_runtime/bfc_allocator.cc:698] Stats: \n> Limit:                  7967745639\n> InUse:                  7764832256\n> MaxInUse:               7764842496\n> NumAllocs:                   60834\n> MaxAllocSize:             14428160\n> \n> W tensorflow/core/common_runtime/bfc_allocator.cc:270] ****************************************************************************************************\n> W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 8.00MiB.  See logs for memory state.\n> W tensorflow/core/framework/op_kernel.cc:968] Resource exhausted: OOM when allocating tensor with shape[1024,2048]\n> E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 8.00G (8589934592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n> E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 8.00G (8589934592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n\nI have a 8G GPU memory (7.8G for free), and the allocator need to use 7.23G, which could be able to allocate.\nBut, it tried to allocate 8.00G, and threw out CUDA_ERROR_OUT_OF_MEMORY\nI also set `config.gpu_options.allow_growth=True` , but it didn't matter.\nHow can I solve it? Thanks a lot!\n", "comments": ["Note that 7.23 GiB = 7.76 GB, so you were on the verge of exceeding your 7.8GB limit. Generally the solution is to is to reduce memory usage. You can get more detailed memory allocation stats by recompiling with VLOG_IS_ON as described [here](http://stackoverflow.com/questions/36331419/tensorflow-how-to-measure-how-much-gpu-memory-each-tensor-takes/36505898#36505898) or using StepStats to see where memory gets allocated (that requires your .run call to succeed ) -- http://stackoverflow.com/questions/40190510/tensorflow-how-to-log-gpu-memory-vram-utilization/40197094#40197094\n", "Yaroslav's answer should be sufficient. Feel free to re-open if you encounter a bug.\n"]}, {"number": 5194, "title": "Fix confusing CTC documentation", "body": "From the docs it seems that CTC decoder have problems and it can't handle labelings like `A B B`, but if you will look at the [code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_decoder.h#L84), it is not the case, everything is OK, just typo in the docs.\n", "comments": ["@Jihadik, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ebrevdo, @tensorflower-gardener and @igormq to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Can one of the admins verify this patch?\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Hi, @Jihadik.\n\nIf you try this piece of code\n\n``` python\nimport numpy as np\nimport tensorflow as tf\n\n#A B B * B * B, where * means blank\nabb_b_b = np.array([[1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0]]) # One hot encoding\nabb_b_b = abb_b_b[None, :, :].transpose((1,0,2)) # Added batch axis and transpose (it's time major notation)\nseq_len = [7]\n\nsess = tf.InteractiveSession()\nmerge = tf.sparse_tensor_to_dense(tf.nn.ctc_greedy_decoder(abb_b_b, seq_len)[0][0]).eval()\nnon_merge = tf.sparse_tensor_to_dense(tf.nn.ctc_greedy_decoder(abb_b_b, seq_len, merge_repeated=False)[0][0]).eval()\n\nprint(merge)\nprint(non_merge)\n```\n\nyou'll get this output\n\n``` python\n[[0 1 1 1]] # Which means ABBB\n[[0 1 1 1 1]] # Which means ABBBB. There is a extra 1 in the docs!\n```\n\nSo, the docs seems to have a problem, but not only the problem that you've point to. If you look at [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_decoder.h#L88) line of code, you can see that if `merge_repeated = False`, then the greedy decoder will only append to output the maximum target if it isn't blank. In case of `merge_repeated=True`, the maximum target will only be appended to output if it isn't the blank label and if it isn't equal the previous label. \n\nLook at the comment [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/ctc_ops.py#L184). As you can see, there is a typo. Instead of \\* `A B B B B B` if `merge_repeated=False`., it should be \\* `A B B B B` if `merge_repeated=False`.\n\nSo, I recommend you to change your PR to fix this typo too! :)\n", "@tensorflow-jenkins test this please. \n", "You're right, thanks!\n", "@tensorflow-jenkins test this please.\n", "Are we merging it, @ebrevdo?\n", "Let's pause on it.  I need to find out how many people the true fix would break.\n", "Ping for @ebrevdo -- let me know approximately when you think you'll have found your answer?\n", "Btw, what is the problem with merging comments? :)\n", "As I thought :), thanks!\n", "@vrv, I fixed it!\n", "(Thanks, now will wait for @ebrevdo to review)\n", "@ebrevdo, ping!\n", "It's not the documentation that's wrong - it's the code.  Would you like to fix the code instead?\n", "No problems, I will look at the code a little bit later.\n", "Can confirm that I ran into this the other day. I was doing some training with labels that had repeated symbols, but it would output the warning \"No Valid Path Found\", and would return a cost of infinity. \n", "Ling, I'm not sure that is related.\n\nOn Nov 20, 2016 5:53 AM, \"Ling Zhang\" notifications@github.com wrote:\n\n> Can confirm that I ran into this the other day. I was doing some training\n> with labels that had repeated symbols, but it would output the warning \"No\n> Valid Path Found\", and would return a cost of infinity.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/5194#issuecomment-261779617,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim_DFjlGmmPt89m0z6vbeibCvFcmaks5rAFDGgaJpZM4KgErU\n> .\n", "Actually yeah, I investigated further and it was just that I did not make the seq_len long enough to allow for the blanks to be between the labels, so thus \"No Valid Path Found\"\n\nThough I'm confused about your earlier comment @ebrevdo where you said it's not the documentation but the code that is wrong. The unit test linked and @igormq seems to show merge_repeated demonstrating the correct behavior?\n", "The unit test is either wrong, or doesn't actually test repeats correctly.\n\nOn Nov 20, 2016 10:10 AM, \"Ling Zhang\" notifications@github.com wrote:\n\n> Actually yeah, I investigated further and it was just that I did not make\n> the seq_len long enough to allow for the blanks to be between the labels,\n> so thus \"No Valid Path Found\"\n> \n> Though I'm confused about your earlier comment @ebrevdo\n> https://github.com/ebrevdo where you said it's not the documentation\n> but the code that is wrong. The unit test linked and @igormq\n> https://github.com/igormq seems to show merge_repeated demonstrating\n> the correct behavior?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/5194#issuecomment-261794277,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtimz6ECS67TyVxKr4Xvcxboa0bJzknks5rAI0RgaJpZM4KgErU\n> .\n", "Ping! What's the next step for this?", "Soon I will try to fix it. I was really busy last few weeks.", "I have run into several issues in the CTC decoding.\r\n\r\n1) The greedy decoder seems to work right but has a problem with the documentation (still). Documentation online still shows \r\nA B B * B * B (where '*' is the blank label) becomes\r\n    A B if merge_repeated=True.\r\n    A B B B B B if merge_repeated=False.\r\n\r\nBoth results are wrong.\r\nThis should read:\r\n    A B B B if merge_repeated=True.\r\n    A B B B B  if merge_repeated=False.\r\n\r\n2) I had a problem with the beamsearch decoder. Running the code of **igormq** above, but switching in the beamsearch decoder in place of the greedy decoder via:\r\n`merge = tf.sparse_tensor_to_dense(tf.nn.ctc_beam_search_decoder(abb_b_b, seq_len, merge_repeated=True)[0][0]).eval()\r\n\r\nnon_merge = tf.sparse_tensor_to_dense(tf.nn.ctc_beam_search_decoder(abb_b_b, seq_len, merge_repeated=False)[0][0]).eval()\r\n\r\nprint(merge)\r\nprint(non_merge)\r\n`\r\n\r\nthe results for both are:\r\n[[0 1 0 1]] or A B A B\r\n\r\nwhich makes no sense.\r\n\r\nAdditionally, I have also had the problem where the beamsearch decoder did not properly deal with repeated characters and had to switch merge_repeated to False. \r\n\r\nIn summary, documentation problems in greedy decoder,  code problems in beamsearch decoder.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "You have merge_repeated=false in both cases for your beam search code. For\ngreedy decoder, the documentation isn't wrong, the code is. I'll look into\nthe beam search decoder in early January.\n\nOn Dec 13, 2016 3:22 AM, \"saseptim\" <notifications@github.com> wrote:\n\n> I have run into several issues in the CTC decoding.\n>\n>    1. The greedy decoder seems to work right but has a problem with the\n>    documentation (still). Documentation online still shows\n>    A B B * B * B (where '*' is the blank label) becomes\n>    A B if merge_repeated=True.\n>    A B B B B B if merge_repeated=False.\n>\n> Both results are wrong.\n> This should read:\n> A B B B if merge_repeated=True.\n> A B B B B if merge_repeated=False.\n>\n>    1. I had a problem with the beamsearch decoder. Running the code of\n>    *igormq* above, but switching in the beamsearch decoder in place of\n>    the greedy decoder via:\n>    `merge = tf.sparse_tensor_to_dense(tf.nn.ctc_beam_search_decoder(abb_b_b,\n>    seq_len, merge_repeated=False)[0][0]).eval()\n>\n> non_merge = tf.sparse_tensor_to_dense(tf.nn.ctc_beam_search_decoder(abb_b_b,\n> seq_len, merge_repeated=False)[0][0]).eval()\n>\n> print(merge)\n> print(non_merge)\n> `\n>\n> the results for both are:\n> [[0 1 0 1]] or A B A B\n>\n> which makes no sense.\n>\n> Additionally, I have also had the problem where the beamsearch decoder did\n> not properly deal with repeated characters and had to switch merge_repeated\n> to False.\n>\n> In summary, documentation problems in greedy decoder, code problems in\n> beamsearch decoder.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/5194#issuecomment-266736700>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimxvHCRCkf9gd3YMhAeF2t6nmSgdJks5rHpv8gaJpZM4KgErU>\n> .\n>\n", "Regarding the beamsearch, you are right, I copied the code wrong (now it is fixed) but the results are the same - [[0 1 0 1]] - still incorrect.\r\n\r\nAs for the greedy decoder, I do not understand why you think the code is wrong. The code acts for me as expected. The comments, on the other hand, are certainly wrong, just the fact that the result has 5 B's and the input has 4.", "For greedy beam search, the code should act like the documentation... Not\nthe other way around. It's a bug.\n\nOn Dec 13, 2016 11:12 PM, \"saseptim\" <notifications@github.com> wrote:\n\nRegarding the beamsearch, you are right, I copied the code wrong (now it is\nfixed) but the results are the same - [[0 1 0 1]] - still incorrect.\n\nAs for the greedy decoder, I do not understand why you think the code is\nwrong. The code acts for me as expected. The comments, on the other hand,\nare certainly wrong, just the fact that the result has 5 B's and the input\nhas 4.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\n<https://github.com/tensorflow/tensorflow/pull/5194#issuecomment-266981939>,\nor mute the thread\n<https://github.com/notifications/unsubscribe-auth/ABtim0_STlBnqmWH-4NVgaQ4b7x_TCRtks5rH7LjgaJpZM4KgErU>\n.\n", "@ebrevdo, I really disagree with you. If `merge_repeated=True` then it is exactly [Graves' CTC](http://www.cs.toronto.edu/~graves/icml_2006.pdf) and in case `A B B * B * B` firstly it merges repeated labels and make `A B * B * B` then it removes all blanks and our sequence become `A B B B`, not `A B` as in docs now. If it firstly remove all blanks and only then merge labels then we will never have two consecutive labels in a row which is not good and was not intended by Graves.\r\n\r\nIf I'm wrong, please prove it.", "I agree, there is a problem with the documentation of the greedy decoder and the code of the beamsearch decoder. ", "@Jihadik I really appreciate your willingness to contribute. Basically, the way it works is that google staff is maintaining the code and needs to make the final decision on changes we're comfortable with. We can't really merge @ebrevdo has a different opinion.", "I'll revisit tomorrow.\n\nOn Jan 11, 2017 3:50 PM, \"drpngx\" <notifications@github.com> wrote:\n\n> @Jihadik <https://github.com/Jihadik> I really appreciate your\n> willingness to contribute. Basically, the way it works is that google staff\n> is maintaining the code and needs to make the final decision on changes\n> we're comfortable with. We can't really merge @ebrevdo\n> <https://github.com/ebrevdo> has a different opinion.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/5194#issuecomment-272032990>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim3hTJN830TME1FmFxFfujCZTINu7ks5rRWrAgaJpZM4KgErU>\n> .\n>\n", "@Jihadik, you are right.  lgtm.\n\nOn Jan 11, 2017 4:00 PM, \"Eugene Brevdo\" <ebrevdo@gmail.com> wrote:\n\n> I'll revisit tomorrow.\n>\n> On Jan 11, 2017 3:50 PM, \"drpngx\" <notifications@github.com> wrote:\n>\n>> @Jihadik <https://github.com/Jihadik> I really appreciate your\n>> willingness to contribute. Basically, the way it works is that google staff\n>> is maintaining the code and needs to make the final decision on changes\n>> we're comfortable with. We can't really merge @ebrevdo\n>> <https://github.com/ebrevdo> has a different opinion.\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/pull/5194#issuecomment-272032990>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/ABtim3hTJN830TME1FmFxFfujCZTINu7ks5rRWrAgaJpZM4KgErU>\n>> .\n>>\n>\n", "Jenkins, test this please."]}, {"number": 5192, "title": "Fixed typo in train api documentation", "body": "\"It `True`\" -> \"If `True`\". Fixed upstream as suggested by @drpngx.\n", "comments": ["Can one of the admins verify this patch?\n", "@oskopek, thanks for your PR! By analyzing the history of the files in this pull request, we identified @martinwicke, @tensorflower-gardener and @keveman to be potential reviewers.\n", "Jenkins, test this please.\n", "@tensorflow-jenkins test this please\n"]}, {"number": 5191, "title": "sucessfully configure, but build error with bazel", "body": "the configure sucessfully finished\nbut when run \"bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\"\nit reports the error: ......./tensorflow/tensorflow/python/BUILD:1806:1: in cc_library rule //tensorflow/python:tf_session_helper: non-test target '//tensorflow/python:tf_session_helper' depends on testonly target '//tensorflow/python:construction_fails_op' and doesn't have testonly attribute set\n", "comments": ["it works when comment all the testonly dependencies\n", "#5093 \n\nCould you tell us more about your configuration?\n", "@davidzchen @jart \n\nThe comment before \"construction_fails_op\" makes it clear that it's a genuine `testonly`.\n\nI can build just fine, but:\n\n```\nbazel query 'allpaths(//tensorflow/python:tf_session_helper, //tensorflow/python:construction_fails_op)'\n//tensorflow/python:tf_session_helper\n//tensorflow/python:construction_fails_op\n```\n\nAnd also some other test ops?\n\n```\nbazel query 'deps(//tensorflow/python:tf_session_helper) intersect //tensorflow/python/...'\n//tensorflow/python:tf_session_helper\n//tensorflow/python:test_ops_kernels\n//tensorflow/python:numpy_lib\n//tensorflow/python:construction_fails_op\n```\n\nI can't quite see why it should be the case.\n", "I comment these two lines of \"..../python/BUILD\":\n1811 \":construction_fails_op\", \n1813         \":test_ops_kernels\",\nthen the build is fine.\n", "Did you test the rest of the code? It probably fails somewhere. If you can fix the code, then it would be good to send a PR\n", "We've got cl/137268906 in the oven which fixes this internally. It's will be synced soon.\n", "Nice thanks!\n", "Thanks!\n", "I've got the same error when I attempted to build the last release (https://github.com/tensorflow/tensorflow/releases/tag/v0.11.0). Probably, the fix was not included into it.\n", "Re-opening this issue for triage.\n", "How about the master tensorflow branch?\n", "The master branch builds normally.\n", "@jart Is this fixed now that that CL is in?\n", "Just tried v0.11.0. Doesn't work. Seems to work on master and it's building now.\n", "This issue should be resolved in both master and 0.12"]}, {"number": 5190, "title": "tf.self_adjoint_eig does not work for complex matrices", "body": "The documentation of tf.self_adjoint_eig (and the likes) does not state that which data types are accepted by this function. Turns out, only float32 and float64. But the name is misleading: self-adjointness is a property of complex matrices, and one could expect that this function would work on complex64 and complex128 as well.\n\nFor me it would be very useful if tf.self_adjoint_eig could work for complex matrices.\n\nPlease amend the documentation with the list of accepted dtypes (this goes for SVD and other similar functions as well). And of course it would be great if tf.self_adjoint_eig could accept complex data. :)\n", "comments": ["Good to know, would you be able to send a PR?\n", "I would happily send a pull request if I knew how to make it work for complex matrices.\n", "@rmlarsen checking if that makes sense.\n", "Yes, the documentation is lacking (and yes, it was lame to name an op self_adjoint and then not support complex - I filed an appropriately snarky meme for that a while ago). Feel free to send a PR to add support for complex. You would simply need to add the kernel registrations for complex types here: \n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/self_adjoint_eig_v2_op.cc#L85\n\nand update the unit tests here:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/self_adjoint_eig_op_test.py\n\nYou can look at svd_op\\* as an example.\n", "Created a PR #8662 to support complex64 and complex128. Please take a look."]}, {"number": 5189, "title": "lstm with variable bath_size", "body": "we know ,during training,we need to feed_dict a batch.However,in the last epoch, the number of data is less than a batch size.how could i do? i try to use variable batch_size,but i meet some problems. the code is below:\ninput_data = tf.placeholder(tf.int32, [None, num_steps])\nwith tf.variable_scope('forward'):\n            cellL = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=1.0)\nstate_init_L = tf.get_variable(\"init_L\", initializer=cellL.zero_state(tf.shape(input_data)[0],tf.float32))\n\nhere,  i want to initialize it,error is \nValueError: initial_value must have a shape specified: Tensor(\"model/init_variable_L/zeros:0\", shape=(?, 100), dtype=float32, device=/device:GPU:0)\n\nthanks~\n", "comments": ["Thanks for your interest. This is best sent to stackoverflow, with the tag \"tensorflow\" which we monitor.\n"]}, {"number": 5188, "title": "freeze_graph.py \"AttributeError: 'module' object has no attribute 'checkpoint_exists' in latest commit", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\n\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nnone, latest commit from 4 days ago caused this issue to arise.\n### Environment info\n\nOperating System: OSX Sierra\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nno Cuda support\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed: compiled from source\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.11.0rc1\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n   bac7faa9a3eb5b60687a83336202cd3493de5385\n2. The output of `bazel version`\n   Build label: 0.3.2-homebrew\n   Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\n   Build time: Sat Oct 8 08:02:20 2016 (1475913740)\n   Build timestamp: 1475913740\n   Build timestamp as int: 1475913740\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n### What other attempted solutions have you tried?\n\nUsed a version prior to the latest commit 4 days ago and it worked.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n\n$ python freeze_graph.py --input_graph=train.txt --input_checkpoint=model.ckpt-194000 --output_graph=frozen_graph.pb --output_node_names=final_result\n\n  File \"freeze_graph.py\", line 135, in <module>\n    tf.app.run()\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"freeze_graph.py\", line 132, in main\n    FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)\n  File \"freeze_graph.py\", line 84, in freeze_graph\n    if not tf.train.checkpoint_exists(input_checkpoint):\nAttributeError: 'module' object has no attribute 'checkpoint_exists'\n", "comments": ["I have the same error. How did you solve this problem?\n", "I have the same issue. As a temporary measure, I commented this check out.\n", "simply change the tf.train.checkpoint_exists(....) into tf.gfile.Exists(.....) and it can work", "In my case a similar error was due to trying to run scripts from the latest source while an earlier compiled tensorflow package was installed. The correct fix would be to compile and install from source, but as @lintzuhsiang suggests tf.gfile.Exists(.....) is a workaround"]}, {"number": 5187, "title": "Reading data from tfrecords error", "body": "When I use tf to read traing and testing data from tfrecords, it runed for a while, then stoped with errors like this (this is testing net error, traing net is the same problem):\nINFO:tensorflow:Executing eval_op 8133/15916\nINFO:tensorflow:Executing eval_op 8134/15916\nINFO:tensorflow:Executing eval_op 8135/15916\nINFO:tensorflow:Executing eval_op 8136/15916\nINFO:tensorflow:Executing eval_op 8137/15916\nINFO:tensorflow:Executing eval_op 8138/15916\nINFO:tensorflow:Executing eval_op 8139/15916\nINFO:tensorflow:Executing eval_op 8140/15916\nINFO:tensorflow:Executing eval_op 8141/15916\nINFO:tensorflow:Executing eval_op 8142/15916\nINFO:tensorflow:Executing eval_op 8143/15916\nINFO:tensorflow:Executing eval_op 8144/15916\nINFO:tensorflow:Executing eval_op 8145/15916\nINFO:tensorflow:Executing eval_op 8146/15916\nINFO:tensorflow:Executing eval_op 8147/15916\nINFO:tensorflow:Executing eval_op 8148/15916\nINFO:tensorflow:Executing eval_op 8149/15916\nINFO:tensorflow:Executing eval_op 8150/15916\nINFO:tensorflow:Executing eval_op 8151/15916\nINFO:tensorflow:Executing eval_op 8152/15916\nINFO:tensorflow:Executing eval_op 8153/15916\nINFO:tensorflow:Executing eval_op 8154/15916\nINFO:tensorflow:Executing eval_op 8155/15916\nINFO:tensorflow:Executing eval_op 8156/15916\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.InvalidArgumentError'>, Input to reshape is a tensor with 836310 values, but the requested shape has 65712\n         [[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](case_1/If_2/Merge, Reshape_14/shape)]]\n         [[Node: eval_image/Mul/_3773 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_eval_image/Mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Reshape_14', defined at:\n  File \"eval_image_classifier.py\", line 210, in <module>\n    tf.app.run()\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"eval_image_classifier.py\", line 130, in main\n    common_queue_min=FLAGS.batch_size)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\n    tensors = dataset.decoder.decode(data, items)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\n    image = self._decode(image_buffer, image_format)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 328, in _decode\n    image = array_ops.reshape(image, self._shape)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py\", line 1758, in reshape\n    name=name)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2333, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1252, in __init__\n    self._traceback = _extract_stack()\n\nTraceback (most recent call last):\n  File \"eval_image_classifier.py\", line 210, in <module>\n    tf.app.run()\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"eval_image_classifier.py\", line 206, in main\n    variables_to_restore=variables_to_restore)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/evaluation.py\", line 323, in evaluate_once\n    global_step=global_step)\n  File \"/usr/lib/python2.7/contextlib.py\", line 35, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py\", line 969, in managed_session\n    self.stop(close_summary_writer=close_summary_writer)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/training/supervisor.py\", line 797, in stop\n    stop_grace_period_secs=self._stop_grace_secs)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/training/coordinator.py\", line 386, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/training/queue_runner.py\", line 225, in _run\n    sess.run(enqueue_op)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 836310 values, but the requested shape has 65712\n         [[Node: Reshape_14 = Reshape[T=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](case_1/If_2/Merge, Reshape_14/shape)]]\n         [[Node: eval_image/Mul/_3773 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_eval_image/Mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Reshape_14', defined at:\n  File \"eval_image_classifier.py\", line 210, in <module>\n    tf.app.run()\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"eval_image_classifier.py\", line 130, in main\n    common_queue_min=FLAGS.batch_size)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py\", line 78, in __init__\n    tensors = dataset.decoder.decode(data, items)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 398, in decode\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 297, in tensors_to_item\n    image = self._decode(image_buffer, image_format)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 328, in _decode\n    image = array_ops.reshape(image, self._shape)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/ops/gen_array_ops.py\", line 1758, in reshape\n    name=name)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2333, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1252, in __init__\n    self._traceback = _extract_stack()\n###### \n\nwhile I wrote the tfrecords like this:\n\ndef _process_image(file_path, label, coder, logfile=None):\n    \"\"\"Process a single image file.\n\n```\nArgs:\n    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n    coder: instance of ImageCoder to provide TensorFlow image coding utils.\nReturns:\n    image_buffer: string, JPEG encoding of RGB image.\n    height: integer, image height in pixels.\n    width: integer, image width in pixels.\n\"\"\"\n# Clean the dirty data.\nif _is_not_jpg(file_path):\n    print('Image %s is not a JPEG image, and its label is %d' % (file_path, label))\n    if logfile:\n        logfile.write('Image %s is not a JPEG image, and its label is %d\\n' % (file_path, label))\n    return -1, None\n\nif not tf.gfile.Exists(file_path):\n    print('Image %s is not exist, and its label is %d' % (file_path, label))\n    if logfile:\n        logfile.write('Image %s is not exist, and its label is %d\\n' % (file_path, label))\n    return -1, None\n\n# Read the image file.\nimage_data = tf.gfile.FastGFile(file_path, 'r').read()\n\n# Decode the RGB JPEG.\nheight, width, channels = coder.read_image_dims(image_data)\n\n# Check that image converted right\nif height != 148 and width != 148 and channels != 3:\n    print('The size of image %s is wrong, which is h[%d] w[%d] c[%d], but requested h[148] w[148] c[148]\\n' % (file_path, height, width, channels))\n    if logfile:\n        logfile.write('The size of image %s is wrong, which is h[%d] w[%d], but requested h[148] w[148] c[148]\\n' % (file_path, height, width, channels))\n    return -1, None\n\nreturn 0, _convert_to_example(image_data, height, width, channels, 'jpg', label)\n```\n\ndef _process_image_files_batch(coder, thread_index, ranges, name, filenames, labels, num_shards, logfile=None):\n\n```\nnum_threads = len(ranges)\nassert not num_shards % num_threads\nnum_shards_per_batch = int(num_shards / num_threads)\n\nshard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], num_shards_per_batch + 1).astype(int)\nnum_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n\ncounter = 0\nfor s in xrange(num_shards_per_batch):\n    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n    shard = thread_index * num_shards_per_batch + s\n    output_file = '%s-%.5d-of-%.5d.tfrecord' % (name, shard, num_shards)\n    writer = tf.python_io.TFRecordWriter(output_file)\n\n    shard_counter = 0\n    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n    for i in files_in_shard:\n        file_path = filenames[i]\n        label = labels[i]\n\n        errCode, example = _process_image(file_path, label, coder, logfile)\n        if -1 == errCode:\n            continue\n\n        writer.write(example.SerializeToString())\n        shard_counter += 1\n        counter += 1\n\n        if not counter % 1000:\n            print('%s [thread %d]: Processed %d of %d images in thread batch.' % (datetime.now(), thread_index, counter, num_files_in_thread))\n            sys.stdout.flush()\n\n    print('%s [thread %d]: Wrote %d images to %s' % (datetime.now(), thread_index, shard_counter, output_file))\n    sys.stdout.flush()\n    shard_counter = 0\nprint('%s [thread %d]: Wrote %d images to %d shards.' % (datetime.now(), thread_index, counter, num_files_in_thread))\nsys.stdout.flush()\n```\n###### \n\nSo I checked all the images as the same shape and same size of 65712, and write them by jpg format, Ibut I don't know where the problem is.\n", "comments": ["Could you try stackoverflow with tag \"tensorflow\" as well?\n", "Automatically closing due to lack of recent activity, we will reopen if further information becomes available. Thanks!\n"]}, {"number": 5186, "title": "Fix test_installation to skip using parallel_gpu_execute when not using gpu.", "body": "", "comments": ["@gunan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ebrevdo, @ilblackdragon and @tensorflower-gardener to be potential reviewers.\n", "@caisq  How do we run pip tests for this one?\n", "Jenkins, test this please.\n", "Jenkins, test this please.\n", "debugging, please do not merge.\n", "It is finally working for CPU tests, but please wait until I complete testing on all platforms.\n"]}, {"number": 5185, "title": "Fix broken link to creating a Docker group", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@djones, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @keveman and @martinwicke to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "@googlebot I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Thanks for the contribution! \n"]}, {"number": 5184, "title": "Can't run iOS makefile on MacOS Sierra, required file 'build-aux/ltmain.sh' not found", "body": "Well from now on I should probably think twice before I update. Before it used to work correctly but now I get this message when i run `compile_ios_protobuf.sh`\n\n```\n+ ./autogen.sh\n+ autoreconf -f -i -Wall,no-obsolete\n/usr/local/bin/glibtoolize: line 406: /usr/local/Library/ENV/4.3/sed: No such file or directory\n/usr/local/bin/glibtoolize: line 2513: /usr/local/Library/ENV/4.3/sed: No such file or directory\n/usr/local/bin/glibtoolize: line 2513: /usr/local/Library/ENV/4.3/sed: No such file or directory\n/usr/local/bin/glibtoolize: line 3601: /usr/local/Library/ENV/4.3/sed: No such file or directory\n/usr/local/bin/glibtoolize: line 3845: /usr/local/Library/ENV/4.3/sed: No such file or directory\n/usr/local/bin/glibtoolize: line 861: /usr/local/Library/ENV/4.3/sed: No such file or directory\n: putting auxiliary files in '.'.\n: copying file './ltmain.sh'\n/usr/local/bin/glibtoolize: line 3771: /usr/local/Library/ENV/4.3/sed: No such file or directory\nconfigure.ac:30: error: required file 'build-aux/ltmain.sh' not found\nautoreconf: automake failed with exit status: 1\n```\n\nI hav MacOS Sierra installed and Xcode 8. If anyone has a workaround for this please let me know.\n", "comments": ["Ugh, configure.\n\n@jart if you're interested.\n", "running into the same issue\n", "Could you try this? Verify that glibtoolize works first?\n\nhttps://github.com/Homebrew/legacy-homebrew/issues/43874\n", "Thanks for bringing this to our attention @KevinAyuque. The problem is most likely upstream and related to the Homebrew issue @drpngx provided. If we have reason to suspect otherwise, please let us know, and I'll re-open this issue.\n", "@KevinAyuque this solved my issue:\n`cd \"$(brew --repository)\" && git fetch && git reset --hard origin/master`\n\nsource: https://github.com/Homebrew/brew/issues/557\n", "Thanks, `brew uninstall libtool && brew install libtool` worked for me but now i have another error `configure: error: cannot run C compiled programs` which I imagine has something to do with my Xcode. I'll post here if I find a solution. \n"]}, {"number": 5183, "title": "Problems when using \"bazel build\"  to download ImageNet data", "body": "Hi all,\nI tried to download the Imagenet data with the code provided in Inception model, but there was a problem when I used code:\n `bazel build inception/download_and_preprocess_imagenet`\nThe tensorflow was installed in a Singularity container. And the environment is a high-performance cluster.\n### Running Code:\n\n`[yichengwang125@i21a-s2 ~]$ ml load tensorflow`\n`[yichengwang125@i21a-s2 ~]$ cd ufrc/image/image/models-master/inception/`\n`[yichengwang125@i21a-s2 inception]$ touch WORKSPACE`\n`[yichengwang125@i21a-s2 inception]$ DATA_DIR=$HOME/image/`\n`[yichengwang125@i21a-s2 inception]$ bazel build inception/download_and_preprocess_imagenet`\n`WARNING: Output base /home/yichengwang125/.cache/bazel/_bazel_yichengwang125/bad337a79300dc0e5a9ba2ac2e22c48a' is on NFS. This may lead to surprising failures and undetermined behavior.`\n`WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nINFO: Found 1 target...`\n`Target //inception:download_and_preprocess_imagenet up-to-date:\n  bazel-bin/inception/download_and_preprocess_imagenet\nINFO: Elapsed time: 2.952s, Critical Path: 0.02s`\n`ERROR  : Could not remove session directory /tmp/.singularity-session-4308.2575366.144117625721484141: Device or resource busy`\n### Environment info\n\nOperating System:\nRed Hat Enterprise Linux Server release 6.7 (Santiago)\n### I tried to\n\n`lsof +D /tmp/.singularity-session-4308.2575366.144117625721484141`\nbut only shows\n`COMMAND   PID     USER             FD   TYPE    DEVICE SIZE/OFF       NODE NAME`\n`java         25707  yichengwang125  7r   DIR             8,3            4096 43779163 /tmp/.singularity-session-4308.2575366.144117625721484141`\n", "comments": ["Did you try to build anything else?\n", "Perhaps also put this: `workspace(name = \"inception\")` in `WORKSPACE`?\n", "I tried with basic hello world code, \n\n```\n$ bazel build :hello\nbazel build :hello\nERROR  : Could not obtain shared lock on /tmp/.singularity-session-4308.2575366.144117625721484141: Resource temporarily unavailable\nABORT  : Retval = 255\n```\n", "I think that could possibly be the problem of **singularity**. By the way, you should put your code in a single code block for easier reading.\n", "Sorry I'm not familiar with Singularity. I think it's a config issue where you need to give some more permissions.\n\n@davidzchen bazel doesn't work on Singularity, if you're interested.\n", "That's interesting. I'm not too familiar with Singularity either.\n\n@yichengwang125 Can you open a bug on bazelbuild/bazel for this issue? Thanks!\n", "Feel free to link the issue once created.\n", "I created an issue on bazel\nhttps://github.com/bazelbuild/bazel/issues/1989\n"]}]