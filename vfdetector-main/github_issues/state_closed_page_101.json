[{"number": 52080, "title": "Migrate fuzzing to new atheris version", "body": "Signed-off-by: David Korczynski <david@adalogics.com>\r\n\r\nRecently Atheris the Python fuzzer used by tensorflow-py in the OSS-Fuzz repository had an update. This has caused the fuzzers not to build in OSS-Fuzz and consequentially the fuzzers need to be re-written in the way they handle instrumentation of code. This PR fixes this.\r\n\r\nPlease see the following PR on OSS-Fuzz where the new atheris version is outlined: https://github.com/google/oss-fuzz/pull/6060\r\n\r\nCross-referencing this PR https://github.com/google/oss-fuzz/pull/6417 on the OSS-Fuzz repo as in that PR I outline the build issue in the fuzzers. ", "comments": []}, {"number": 52078, "title": "Correcting Installation from Install", "body": "Hey, \r\nI have seen most of the documentation over the internet use the words installation guide so I thought this change would be something useful for the newbies.\r\nLet me know if you have any queries!", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52078) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac \r\n"]}, {"number": 52077, "title": "[PluggableDevice] C-API Symbols not exposed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary (pypi)\r\n- TensorFlow version: 2.6.0.dev20210612 \r\n- Python version: 3.7.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nHello,\r\n\r\nI\u2019m getting started with building a plugin using the new PluggableDeviceAPI, and am hitting a few snags. Using [this example](https://github.com/jzhoulon/community/tree/plugin_tutorial/rfcs/20200624-pluggable-device-for-tensorflow/sample) as my starting point, my current goal is to have my own custom optimize callback function that walks the NodeDef's and prints the shapes of each of the Input/Output Tensor(s).\r\n\r\nVersion of tensorflow I\u2019m using:\r\ntf-nightly == 2.6.0.dev20210612\r\n\r\nThis problem reproduced on the latest tf-nightly for me too.\r\n\r\nThe c_api.cc symbols and the grappler.cc symbols are not exposed in the monolithic libtensorflow_framework.so. The header files are part of the tensorflow wheel distribution, but we get linker errors for things calling functions like TF_NewBuffer when using @local_config_tf//:tf_header_lib as a dep. When running nm -gDC libtensorflow_framework.so.2 it\u2019s clear that these symbols aren\u2019t exposed. Are there any known workarounds for this?\r\n\r\nAlso, what is the recommended way to use the C-API _with_ `libtensorflow_framework.so`? When using the `@local_config_tf` provided in the BUILD files at the example linked above, I get duplicate registries / static global's when trying to link `libtensorflow.so` _with_ `libtensorflow_framework.so` at runtime. \r\n\r\nCross post from [the Tensorflow forum](https://discuss.tensorflow.org/t/pluggabledeviceapi-c-api-symbols-not-exposed/3662) due to inactivity.\r\n\r\nThanks in advance!\r\n", "comments": ["Hi @jvishnuvardhan ,Could you please look at this issue?", "@bsarden,\r\n[This post](https://blog.tensorflow.org/2021/06/pluggabledevice-device-plugins-for-TensorFlow.html), introduces the [PluggableDevice](https://github.com/tensorflow/community/blob/master/rfcs/20200624-pluggable-device-for-tensorflow.md) architecture which offers a plugin mechanism for registering devices with TensorFlow without the need to make changes in TensorFlow code. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52077\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52077\">No</a>\n"]}, {"number": 52075, "title": "unnecessary casting and condition removed", "body": "unnecessary casting and condition removed", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52075) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "It looks like your PR relates to the Keras component. Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. Thankyou.\r\n@fchollet, @qlzh727"]}, {"number": 52073, "title": "Can't install tensorflow 1.8 on windows 10", "body": " python --version --> `Python 3.8.8`\r\n pip --version --> `pip 21.0.1 from C:\\Python\\anaconda3\\lib\\site-packages\\pip (python 3.8)`\r\n\r\nI typed `pip install tensorflow==1.8`\r\nbut it's giving me an error\r\n\r\n```\r\nERROR: Could not find a version that satisfies the requirement tensorflow==1.8\r\nERROR: No matching distribution found for tensorflow==1.8\r\n```\r\n\r\nthere is no more tensorflow 1.8 ?\r\nHow can I install tensorflow 1.8 ?", "comments": ["@godomainz ,\r\nWe see that you are using tf version 1.8, 1.x is not actively supported, please update to tf v2.5 or 2.6 and let us know if you are using same issue.Also please take a look at this [link](https://www.tensorflow.org/install) for installing tf latest version.It helps.Thanks", "@tilakrayal my CODE is done from  tf version 1.8. \r\nIs it possible to get tf version 1.8 ?\r\nupdating the whole program is NOT possible", "@godomainz ,\r\nKindly open a tf discussion forum issue for this as there is no support for 1.x is not actively supported. There is a big community to support and learn from your questions.Thanks\r\n", "@godomainz The available versions are as follows\r\n`from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0rc0, 2.1.0rc1, 2.1.0rc2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0rc0, 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.5.0rc0, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0, 2.5.1, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0)\r\n`\r\n\r\nSo, TF1.8 is not available. But, you should be able to run your code in `TF1.15.5` which is the most latest `TF1.x` code. Please note that there is no support for `TF1.x` related issues so we suggest users to try using `TF2.x` versions. Thanks!\r\n\r\nI am closing this issue as this was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52073\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52073\">No</a>\n"]}, {"number": 52072, "title": "Oks", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["> _Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template_\r\n> \r\n> **System information**\r\n> \r\n> * Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n> * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n> * TensorFlow installed from (source or binary):\r\n> * TensorFlow version (use command below):\r\n> * Python version:\r\n> * Bazel version (if compiling from source):\r\n> * GCC/Compiler version (if compiling from source):\r\n> * CUDA/cuDNN version:\r\n> * GPU model and memory:\r\n> \r\n> You can collect some of this information using our environment capture\r\n> [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n> You can also obtain the TensorFlow version with:\r\n> \r\n> 1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n> 2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n> \r\n> **Describe the current behavior**\r\n> \r\n> **Describe the expected behavior**\r\n> \r\n> **[Contributing](https://www.tensorflow.org/community/contribute)**\r\n> \r\n> * Do you want to contribute a PR? (yes/no):\r\n> * Briefly describe your candidate solution(if contributing):\r\n> \r\n> **Standalone code to reproduce the issue**\r\n> Provide a reproducible test case that is the bare minimum necessary to generate\r\n> the problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n> \r\n> **Other info / logs** Include any logs or source code that would be helpful to\r\n> diagnose the problem. If including tracebacks, please include the full\r\n> traceback. Large logs and files should be attached.\r\n\r\n", "Hi @soffieswan041 ,\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52072\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52072\">No</a>\n"]}, {"number": 52071, "title": "Tensor flow", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["> _Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template_\r\n> \r\n> **System information**\r\n> \r\n> * Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n> * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n> * TensorFlow installed from (source or binary):\r\n> * TensorFlow version (use command below):\r\n> * Python version:\r\n> * Bazel version (if compiling from source):\r\n> * GCC/Compiler version (if compiling from source):\r\n> * CUDA/cuDNN version:\r\n> * GPU model and memory:\r\n> \r\n> You can collect some of this information using our environment capture\r\n> [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n> You can also obtain the TensorFlow version with:\r\n> \r\n> 1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n> 2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n> \r\n> **Describe the current behavior**\r\n> \r\n> **Describe the expected behavior**\r\n> \r\n> **[Contributing](https://www.tensorflow.org/community/contribute)**\r\n> \r\n> * Do you want to contribute a PR? (yes/no):\r\n> * Briefly describe your candidate solution(if contributing):\r\n> \r\n> **Standalone code to reproduce the issue**\r\n> Provide a reproducible test case that is the bare minimum necessary to generate\r\n> the problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n> \r\n> **Other info / logs** Include any logs or source code that would be helpful to\r\n> diagnose the problem. If including tracebacks, please include the full\r\n> traceback. Large logs and files should be attached.\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52071\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52071\">No</a>\n", "> Are you satisfied with the resolution of your issue?\r\n> [Yes](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52071)\r\n> [No](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP9\r\n\r\n", "@soffieswan041 \r\nWhat is the issue faced, can you fill in the issue template.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52071\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52071\">No</a>\n"]}, {"number": 52070, "title": "AttributeError: module 'tensorflow_datasets' has no attribute 'deprecated'", "body": "I'm using tensorflow Version: 2.3.0\r\nand python 3.8.5", "comments": ["@luguzman \r\nKindly fill the issue template which helps resolve the issue.\r\nMeanwhile you may verify if you have followed this [link](https://www.tensorflow.org/datasets/api_docs/python/tfds) and similar error issues: [link](https://stackoverflow.com/questions/40956954/tensorflow-attributeerror-module-object-has-no-attribute-deprecated), [link1](https://github.com/tensorflow/tensorflow/issues/6063),[link2](https://github.com/tensorflow/datasets/issues/2647)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52070\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52070\">No</a>\n"]}, {"number": 52069, "title": "bazel test //tensorflow/tools/docs:tf_doctest fails on aarch64", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): git HEAD\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nTest fails\r\n\r\n**Describe the expected behavior**\r\n\r\nTest passes\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing): I think the test needs to be relaxed slightly to accept the values produced by AARCH64 CPUs.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nbazel test //tensorflow/tools/docs:tf_doctest\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n======================================================================\r\nFAIL: Tanh (tensorflow.python.ops.gen_math_ops)\r\nDoctest: tensorflow.python.ops.gen_math_ops.Tanh\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.8/doctest.py\", line 2204, in runTest\r\n    raise self.failureException(self.format_failure(new.getvalue()))\r\nAssertionError: Failed doctest test for tensorflow.python.ops.gen_math_ops.Tanh\r\n  File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py\", line 408, in Tanh\r\n\r\n----------------------------------------------------------------------\r\nFile \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py\", line 416, in tensorflow.python.ops.gen_math_ops.Tanh\r\nFailed example:\r\n    tf.math.tanh(x)\r\nExpected:\r\n    <tf.Tensor: shape=(8,), dtype=float32, numpy=\r\n    array([-1.        , -0.99990916, -0.46211717,  0.7615942 ,  0.8336547 ,\r\n            0.9640276 ,  0.9950547 ,  1.        ], dtype=float32)>\r\nGot:\r\n    <tf.Tensor: shape=(8,), dtype=float32, numpy=\r\n    array([-0.99999976, -0.99990916, -0.46211717,  0.7615942 ,  0.8336546 ,\r\n            0.9640276 ,  0.9950547 ,  0.99999976], dtype=float32)>\r\n\r\n\r\n\r\n    #############################################################\r\n    Check the documentation\r\n    (https://www.tensorflow.org/community/contribute/docs_ref) on how to write testable docstrings.\r\n    #############################################################\r\n\r\n======================================================================\r\nFAIL: tanh (tensorflow.python.ops.gen_math_ops)\r\nDoctest: tensorflow.python.ops.gen_math_ops.tanh\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.8/doctest.py\", line 2204, in runTest\r\n    raise self.failureException(self.format_failure(new.getvalue()))\r\nAssertionError: Failed doctest test for tensorflow.python.ops.gen_math_ops.tanh\r\n  File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py\", line 11336, in tanh\r\n\r\n----------------------------------------------------------------------\r\nFile \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py\", line 11344, in tensorflow.python.ops.gen_math_ops.tanh\r\nFailed example:\r\n    tf.math.tanh(x)\r\nExpected:\r\n    <tf.Tensor: shape=(8,), dtype=float32, numpy=\r\n    array([-1.        , -0.99990916, -0.46211717,  0.7615942 ,  0.8336547 ,\r\n            0.9640276 ,  0.9950547 ,  1.        ], dtype=float32)>\r\nGot:\r\n    <tf.Tensor: shape=(8,), dtype=float32, numpy=\r\n    array([-0.99999976, -0.99990916, -0.46211717,  0.7615942 ,  0.8336546 ,\r\n            0.9640276 ,  0.9950547 ,  0.99999976], dtype=float32)>\r\n\r\n\r\n\r\n    #############################################################\r\n    Check the documentation\r\n    (https://www.tensorflow.org/community/contribute/docs_ref) on how to write testable docstrings.\r\n    #############################################################\r\n\r\n======================================================================\r\nFAIL: sigmoid (tensorflow.python.ops.math_ops)\r\nDoctest: tensorflow.python.ops.math_ops.sigmoid\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.8/doctest.py\", line 2204, in runTest\r\n    raise self.failureException(self.format_failure(new.getvalue()))\r\nAssertionError: Failed doctest test for tensorflow.python.ops.math_ops.sigmoid\r\n  File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py\", line 174, in sigmoid\r\n\r\n----------------------------------------------------------------------\r\nFile \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py\", line 187, in tensorflow.python.ops.math_ops.sigmoid\r\nFailed example:\r\n    tf.math.sigmoid(x)\r\nExpected:\r\n    <tf.Tensor: shape=(4,), dtype=float32,\r\n    numpy=array([0.5      , 0.7310586, 1.       , 1.       ], dtype=float32)>\r\nGot:\r\n    <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5      , 0.7310586, 0.9999998, 0.9999998], dtype=float32)>\r\n\r\n", "comments": ["@cfRod\r\n@nSircombe", "> _Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template_\r\n> \r\n> **System information**\r\n> \r\n> * Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n> * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n> * TensorFlow installed from (source or binary): source\r\n> * TensorFlow version (use command below): git HEAD\r\n> * Python version: 3.8.10\r\n> * Bazel version (if compiling from source): 3.7.2\r\n> * GCC/Compiler version (if compiling from source): 10.3.0\r\n> * CUDA/cuDNN version: n/a\r\n> * GPU model and memory: n/a\r\n> \r\n> You can collect some of this information using our environment capture\r\n> [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n> You can also obtain the TensorFlow version with:\r\n> \r\n> 1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n> 2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n> \r\n> **Describe the current behavior**\r\n> \r\n> Test fails\r\n> \r\n> **Describe the expected behavior**\r\n> \r\n> Test passes\r\n> \r\n> **[Contributing](https://www.tensorflow.org/community/contribute)**\r\n> \r\n> * Do you want to contribute a PR? (yes/no): no\r\n> * Briefly describe your candidate solution(if contributing): I think the test needs to be relaxed slightly to accept the values produced by AARCH64 CPUs.\r\n> \r\n> **Standalone code to reproduce the issue**\r\n> Provide a reproducible test case that is the bare minimum necessary to generate\r\n> the problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n> \r\n> bazel test //tensorflow/tools/docs:tf_doctest\r\n> \r\n> **Other info / logs** Include any logs or source code that would be helpful to\r\n> diagnose the problem. If including tracebacks, please include the full\r\n> traceback. Large logs and files should be attached.\r\n> \r\n> ## ======================================================================\r\n> FAIL: Tanh (tensorflow.python.ops.gen_math_ops)\r\n> Doctest: tensorflow.python.ops.gen_math_ops.Tanh\r\n> Traceback (most recent call last):\r\n> File \"/usr/lib/python3.8/doctest.py\", line 2204, in runTest\r\n> raise self.failureException(self.format_failure(new.getvalue()))\r\n> AssertionError: Failed doctest test for tensorflow.python.ops.gen_math_ops.Tanh\r\n> File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py\", line 408, in Tanh\r\n> \r\n> File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py\", line 416, in tensorflow.python.ops.gen_math_ops.Tanh\r\n> Failed example:\r\n> tf.math.tanh(x)\r\n> Expected:\r\n> <tf.Tensor: shape=(8,), dtype=float32, numpy=\r\n> array([-1. , -0.99990916, -0.46211717, 0.7615942 , 0.8336547 ,\r\n> 0.9640276 , 0.9950547 , 1. ], dtype=float32)>\r\n> Got:\r\n> <tf.Tensor: shape=(8,), dtype=float32, numpy=\r\n> array([-0.99999976, -0.99990916, -0.46211717, 0.7615942 , 0.8336546 ,\r\n> 0.9640276 , 0.9950547 , 0.99999976], dtype=float32)>\r\n> \r\n> ```\r\n> #############################################################\r\n> Check the documentation\r\n> (https://www.tensorflow.org/community/contribute/docs_ref) on how to write testable docstrings.\r\n> #############################################################\r\n> ```\r\n> \r\n> ## ======================================================================\r\n> FAIL: tanh (tensorflow.python.ops.gen_math_ops)\r\n> Doctest: tensorflow.python.ops.gen_math_ops.tanh\r\n> Traceback (most recent call last):\r\n> File \"/usr/lib/python3.8/doctest.py\", line 2204, in runTest\r\n> raise self.failureException(self.format_failure(new.getvalue()))\r\n> AssertionError: Failed doctest test for tensorflow.python.ops.gen_math_ops.tanh\r\n> File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py\", line 11336, in tanh\r\n> \r\n> File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/gen_math_ops.py\", line 11344, in tensorflow.python.ops.gen_math_ops.tanh\r\n> Failed example:\r\n> tf.math.tanh(x)\r\n> Expected:\r\n> <tf.Tensor: shape=(8,), dtype=float32, numpy=\r\n> array([-1. , -0.99990916, -0.46211717, 0.7615942 , 0.8336547 ,\r\n> 0.9640276 , 0.9950547 , 1. ], dtype=float32)>\r\n> Got:\r\n> <tf.Tensor: shape=(8,), dtype=float32, numpy=\r\n> array([-0.99999976, -0.99990916, -0.46211717, 0.7615942 , 0.8336546 ,\r\n> 0.9640276 , 0.9950547 , 0.99999976], dtype=float32)>\r\n> \r\n> ```\r\n> #############################################################\r\n> Check the documentation\r\n> (https://www.tensorflow.org/community/contribute/docs_ref) on how to write testable docstrings.\r\n> #############################################################\r\n> ```\r\n> \r\n> ## ======================================================================\r\n> FAIL: sigmoid (tensorflow.python.ops.math_ops)\r\n> Doctest: tensorflow.python.ops.math_ops.sigmoid\r\n> Traceback (most recent call last):\r\n> File \"/usr/lib/python3.8/doctest.py\", line 2204, in runTest\r\n> raise self.failureException(self.format_failure(new.getvalue()))\r\n> AssertionError: Failed doctest test for tensorflow.python.ops.math_ops.sigmoid\r\n> File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py\", line 174, in sigmoid\r\n> \r\n> File \"/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/math_ops.py\", line 187, in tensorflow.python.ops.math_ops.sigmoid\r\n> Failed example:\r\n> tf.math.sigmoid(x)\r\n> Expected:\r\n> <tf.Tensor: shape=(4,), dtype=float32,\r\n> numpy=array([0.5 , 0.7310586, 1. , 1. ], dtype=float32)>\r\n> Got:\r\n> <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5 , 0.7310586, 0.9999998, 0.9999998], dtype=float32)>\r\n\r\n", "> @cfRod\r\n> @nSircombe\r\n\r\n", "Hi @Saduf2019 ,Could you please look  at this issue!", "non-critical failure if it only fails on aarch64, marking contributions welcome!", "It turns out that the doctest was overly strict on the output and this is not a numerical accuracy issue at all. Relax the test by removing the unneeded white space allows the test to pass. See the attached PR.", "Doesn't seem to be caused by spacing, the error message has very different numbers\r\n\r\n```\r\nExpected:\r\n<tf.Tensor: shape=(8,), dtype=float32, numpy=\r\narray([-1. , -0.99990916, -0.46211717, 0.7615942 , 0.8336547 ,\r\n0.9640276 , 0.9950547 , 1. ], dtype=float32)>\r\nGot:\r\n<tf.Tensor: shape=(8,), dtype=float32, numpy=\r\narray([-0.99999976, -0.99990916, -0.46211717, 0.7615942 , 0.8336546 ,\r\n0.9640276 , 0.9950547 , 0.99999976], dtype=float32)>\r\n```", "The tolerance is 1e-03. The numbers are close enough to match. It is the spaces that cause the string comparison to fail.\r\nhttps://github.com/tensorflow/tensorflow/blob/c1ddc3f097997094d0e045bd81502805a169937c/tensorflow/tools/docs/tf_doctest_lib.py#L117", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52069\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52069\">No</a>\n"]}, {"number": 52068, "title": "Loss output gives Nan in Linux but gives normal values in Windows ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux & Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): GCC 7.5.0\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI defined a model (two inputs and two outputs) that trains well on my local PC (Windows 10), but only produce Nan in Linux\r\n**Describe the expected behavior**\r\nThe model should be trained properly in both Windows and Linux\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n[slurm-8183898.txt](https://github.com/tensorflow/tensorflow/files/7195723/slurm-8183898.txt)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["can you provide the code ? ", "@sliu729 \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "@vulkomilev  @sushreebarsa Hey, thanks for your prompt reaction. The code was not organized to be portable, I will try to reorganize and provide the code to reproduce the problem. In the meanwhile, the NaN problem disappears when I disabled the use of mixed_float16. Is that something already reported by someone else? ", "Maybe the problem was the usage of different types of variables for weights and backprop. The float format is not very intuitive and funny things can happen.", "> Maybe the problem was the usage of different types of variables for weights and backprop. The float format is not very intuitive and funny things can happen.\r\n\r\n@vulkomilev Thanks for your comment. The funny thing is that I got recommended by the profiler to use mixed_float16, and the calculation speed was greatly increased. It is sad that it would not work properly. ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sliu729 \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here.Please try to execute your code using latest `TF v2.6.0`, & have a look at the similar [issue](https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network) .Please let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52068\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52068\">No</a>\n"]}, {"number": 52067, "title": "Memory Consumption | Boosting model", "body": "<em> This is an issue related to performance of [TensorFlow.BoostedTree](https://www.tensorflow.org/tutorials/estimator/boosted_trees)</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): '2.4.1'\r\n- Python version:  3.6.5\r\n\r\n**Describe the model**\r\n\r\nI am training the Boosted Tree of the TensorFlow to review the memory consumption of the model by using the tracemalloc.\r\nThis model is based on the Gradient Boosting and XGBoost idea.\r\n\r\n**Describe the current behavior**\r\n\r\nThe trend of the model is not growing linearly and has too much noise in terms of memory consumption.\r\n\r\n**Describe the expected behavior**\r\n\r\nAs the XGboost demonstrates, it should grow linearly.\r\n\r\n**Possible cause**\r\nI think there is something inside tf.estimator that causes this behavior, if it is so, would you please indicate the exact reason?\r\n\r\n**Standalone code to reproduce the issue**\r\nI provided a notebook over a UCI Dataset in this [link](https://github.com/samanemami/TFBoostedTree/blob/main/examples/memory_consumption_tensorflow.ipynb).\r\nWhich shows the memory consumption of the model.\r\n", "comments": []}, {"number": 52066, "title": "SyntaxError: positional argument follows keyword argument", "body": "```\r\n base_model = tf.keras.applications.MobileNetV2(input_shape=( 160, 160, 3),\r\n                                                   include_top=False, # <== Important!!!!\r\n                                                   weights='imagenet') # From imageNet\r\n    \r\n    # freeze the base model by making it non trainable\r\n    base_model.trainable = False \r\n\r\n    # create the input layer (Same as the imageNetv2 input size)\r\n    inputs = tf.keras.Input(shape=160,160,3) \r\n    \r\n    # apply data augmentation to the inputs\r\n    x = data_augmentation(inputs)\r\n    \r\n    # data preprocessing using the same weights the model was trained on\r\n    x = preprocess_input('imagenet') \r\n    \r\n    # set training to False to avoid keeping track of statistics in the batch norm layer\r\n    x = base_model(x, training=False) \r\n    \r\n    # add the new Binary classification layers\r\n    # use global avg pooling to summarize the info in each channel\r\n    x = keras.layers.GlobalAveragePooling2D()(x)\r\n    x = keras.layers.Dropout(0.2)(x) \r\n    # include dropout with probability of 0.2 to avoid overfitting\r\n    \r\n        \r\n    # use a prediction layer with one neuron (as a binary classifier only needs one)\r\n    outputs = keras.layers.Dense(1)(x)\r\n\r\n```\r\n![4 1](https://user-images.githubusercontent.com/26819449/134000933-2fcf9fdb-cdd6-4663-a5cb-b76f5691ba04.JPG)\r\n![4 2](https://user-images.githubusercontent.com/26819449/134000944-17c2f7be-99b9-492c-ae3e-e55bea84537f.JPG)\r\n\r\nThis is from documentation:\r\n![image](https://user-images.githubusercontent.com/26819449/134001112-2940bf65-c4fb-4546-a737-2e70986faacf.png)\r\n Is this is a bug ??\r\n\r\nThanks!\r\n\r\n\r\n", "comments": ["Hi @starboyvarun ! \r\nCould you please fill  issue template  as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced]. You could fill the issue template for [here.](https://github.com/tensorflow/tensorflow/issues/new/choose) Thanks!", "@mohantym Thank you. I have solved this particular issue."]}, {"number": 52065, "title": "Issue with weight clustering API -Error : Tried to expand dim index 4 for tensor with 3 dimensions. [Op:ExpandDims]", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nhttps://colab.research.google.com/drive/1ID38NAluH0FA0d4G2kSaKZo4C5IinHlh#scrollTo=PzHWGU72831C \r\n\r\nHi , Please use the above link for the reference code.\r\nI did some experiments with weight clustering method . I could able to do with some layers like Dense, Conv2D. \r\nBut , my model consists of Conv1d layers and one use defined custom layer . In this case is it possible to do weight clustering method for this model ?\r\nI got the below mentioned error , while I tried some sample model consists are conv1d layer. How to resolve this error.\r\n\r\nInvalidArgumentError: Tried to expand dim index 4 for tensor with 3 dimensions. [Op:ExpandDims]\r\n\r\nFew more questions I'm having : \r\n1)Does weight clustering supported by tf.keras.layers.Conv1D layer or not ?\r\nif , by default it is not supported , then How can I do it .\r\n2)  (I model consists conv1d layers and Conv1DTranspose layer) Shall I use weight clustering method for my model , what are the blocking things to do it . \r\nCan you anyone give some ideas to optimize this kind of model .", "comments": ["@vanajareedy0426 \r\nIn order to expedite the trouble-shooting process, please provide access to your colab link or gist to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52063, "title": "tf.math.unsorted_segment_sum silently output wrong result on GPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.6.0 / 2.7.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nWhen `segment_ids` exceeds the range `[0, num_segments)`, `tf.math.unsorted_segment_sum` did not throw any exception, and outputs a zero-dimension tensor on GPU. `tf.math.unsorted_segment_sum` can throw an Exception in this case on CPU.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ndata = tf.random.uniform([3, 80], dtype=tf.float32)\r\nsegment_ids = [1, 0, 1]\r\nnum_segments = 0\r\n\r\ntry:\r\n  with tf.device('/GPU:0'):\r\n    res_GPU = tf.math.unsorted_segment_sum(data=data,segment_ids=segment_ids,num_segments=num_segments,)\r\n    print(\"res_GPU: \", res_GPU)\r\nexcept Exception as e_gpu:\r\n  print('error on gpu', e_gpu)\r\n    \r\ntry:\r\n  with tf.device('/CPU'):\r\n    res_CPU = tf.math.unsorted_segment_sum(data=data,segment_ids=segment_ids,num_segments=num_segments,)\r\n    print(\"res_CPU: \", res_CPU)\r\nexcept Exception as e_cpu:\r\n  print('error on cpu:', e_cpu)\r\n\r\n```\r\noutputs:\r\n```\r\nres_GPU:  tf.Tensor([], shape=(0, 80), dtype=float32)\r\nerror on cpu: segment_ids[0] = 1 is out of range [0, 0) [Op:UnsortedSegmentSum]\r\n```\r\n", "comments": ["I think that the library for the cpu and gpu differs thus the different outcome. ", "@lugalUrim ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here", "Also please try to execute in latest stable v 2.7 and let us know if the issue still persists.Thanks!", "Hi @tilakrayal, I have updated the complete code to reproduce the issue (just added one line of import). I tried in TFv2.7.0 and the issue still persists. Thanks!", "@sachinprasadhs ,\r\nI was able to reproduce the issue in tf v2.6,v2.7 and nightly.Please find the gist here.[1](https://colab.research.google.com/gist/tilakrayal/2a88c5b9c8563a36e5adf87969310c59/cpu52063.ipynb) and [2](https://colab.research.google.com/gist/tilakrayal/051ecdd0588e8483db37b76368a8ab61/untitled124.ipynb)", "Thank you for submitting this bug. Sorry, unfortunately TensorFlow does not throw errors during GPU execution of this kind of op. I have updated the source for the documentation for tf.math.unsorted_segment_sum and similar unsorted_segment_* ops to include a caution about this GPU vs. CPU difference. This will be reflected in the future in the tensorflow.org API documentation. See https://github.com/tensorflow/tensorflow/commit/41ad65049b13213b6119b7d07a264e2b2661c72b", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52063\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52063\">No</a>\n"]}, {"number": 52062, "title": "NotFoundError: NewRandomAccessFile failed to Create/Open: images/labelmap.pbtxt : The system cannot find the file specified; No such file or directory", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Install-TensorFlow-Python 3.7 file from github repository given by the tutorial below.\r\n- TensorFlow version: 2.3\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.4\r\n- GPU model and memory: \r\n\r\n\r\n\r\n**Describe the problem**\r\nOK, so I followed this tutorial to the T: https://www.youtube.com/watch?v=a1br6gW-8Ss&t=157s. And then I get this random error. Everything was fine, I used labelImg, I generated the tfrecords, I downloaded all the software, I organized the files and extracted all the files. I'm using an up to date version of tensorflow. And the images/labelmap.pbtxt exists in the images folder (maniacal laughter). Why can't it find this file? I added a path, that still doesn't work.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npython model_main_tf2.py --pipeline_config_path=training/ssd_efficientdet_d0_512x512_coco17_tpu-8.config --model_dir=training --alsologtostderr.\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n![Screen Shot 2021-09-18 at 8 18 19 PM](https://user-images.githubusercontent.com/69585784/133936283-762c2bfa-dc92-4cc7-a8ea-b86b42942b95.png)\r\n![Screen Shot 2021-09-19 at 1 07 55 PM](https://user-images.githubusercontent.com/69585784/133936400-d9c7b782-9a8f-4000-bdf0-e01096105dd6.png)\r\n\r\n", "comments": ["@TriangularFarOutPoint \r\nplease share the error in text so it will benefit any other user with similar error. [Also please upgrade your tf version to tf 2.4.1/2.5]\r\nYou may refer to these issues and let us know:[link](https://github.com/tensorflow/models/issues/6595),[link1](https://github.com/tensorflow/tensorflow/issues/14905)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52062\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52062\">No</a>\n"]}, {"number": 52061, "title": "GPU delegate problems in tensorflow-lite in android studio", "body": "hello everyone! I'm new in the community so please bear with me. I would like to get some help with my problem that I've been stuck in for a while now. I get an error when I run my app in android studio and through my mobile phone. I am following ElectroCode's tutorial videos in making sign language recognition app on youtube.\r\n\r\nThis is my error log:\r\n\r\n\t\tE/AndroidRuntime: FATAL EXCEPTION: Thread-4\r\n\t\t    Process: com.example.imagepro, PID: 7161\r\n\t\t    java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: Next operations are not supported by GPU delegate:\r\n\t\t    CUSTOM TFLite_Detection_PostProcess: Operation is not supported.\r\n\t\t    First 98 operations will run on the GPU, and the remaining 1 on the CPU.\r\n\t\t    OpenCL library not loaded - dlopen failed: library \"libOpenCL-pixel.so\" not found\r\n\t\t    Falling back to OpenGL\r\n\t\t    TfLiteGpuDelegate Invoke: ToTensorConverter: input data size does not match expected size.\r\n\t\t       Node number 99 (TfLiteGpuDelegateV2) failed to invoke.\r\n    \r\n\t        \tat org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)\r\n\t        \tat org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:163)\r\n\t        \tat org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:360)\r\n\t        \tat com.example.imagepro.objectDetectorClass.recognizeImage(objectDetectorClass.java:159)\r\n\t        \tat com.example.imagepro.CameraActivity.onCameraFrame(CameraActivity.java:130)\r\n\t\t        at org.opencv.android.CameraBridgeViewBase.deliverAndDrawFrame(CameraBridgeViewBase.java:392)\r\n\t\t        at org.opencv.android.JavaCameraView$CameraWorker.run(JavaCameraView.java:373)\r\n\t \t       at java.lang.Thread.run(Thread.java:929)\r\n\t\tD/CameraBridge: call checkCurrentState\r\n", "comments": ["Hi @yanzxcasdqwe ! \r\nCould you please feel the issue template too as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced]. You could visit [here](https://github.com/tensorflow/tensorflow/issues/new/choose) to create a new issue.  Feel free to visit [this issue](https://github.com/tensorflow/tensorflow/issues/31949) with similar Error stack trace.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52061\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52061\">No</a>\n"]}, {"number": 52060, "title": "ValueError: Shapes (None, 8) and (None, 7) are incompatible", "body": "ValueError: in user code:\r\n\r\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\r\n        outputs = model.train_step(data)\r\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:789 train_step\r\n        y, y_pred, sample_weight, regularization_losses=self.losses)\r\n    /usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py:201 __call__\r\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\r\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:141 __call__\r\n        losses = call_fn(y_true, y_pred)\r\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:245 call  **\r\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\r\n        return target(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:1666 categorical_crossentropy\r\n        y_true, y_pred, from_logits=from_logits, axis=axis)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\r\n        return target(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/keras/backend.py:4839 categorical_crossentropy\r\n        target.shape.assert_is_compatible_with(output.shape)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\r\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\n\r\n    ValueError: Shapes (None, 8) and (None, 7) are incompatible\r\n\r\nPlease check the code in \r\n[link](https://colab.research.google.com/drive/1WHp2T_jOjtXUHeBhiYR3zaeumtXtSDwn#scrollTo=1rsivhQNf36Y&uniqifier=3)", "comments": ["@akankshaaa13 \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "Hi @akankshaaa13 ,\r\n\r\nIn `OneD_CNN(input_shape)` you have:\r\n`model.add(Dense(7))`\r\nIt should be:\r\n`model.add(Dense(8)) `", "Hi @szutenberg \r\nIt worked Thankyou so much!!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52060\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52060\">No</a>\n"]}, {"number": 52059, "title": "keras load_model not working", "body": "1. Tensorflow Version 2.4.0\r\n2. Ubuntu 20.04\r\n3. Python 3.8.5\r\n\r\nI have two projects. Use the same training code. One is for one gpu training (Project A), the other one is for  two gpus training (Project B). And these two projects in different paths.\r\n\r\nWhen I use Project A get trained model   C   in Project B path for prediction, Most of  the results is simillar . But When use  model C from  Project A  in Project A, It works fine. I'm Sure that the model file is the same by md5 code.\r\n\r\nProject A save model code is about like this:\r\n\r\n```\r\nmodel = create_mdoel()\r\n......\r\ntraining task\r\n......\r\nmodel.save(\"c.h5\")\r\n```\r\nand the results is :\r\n\r\n\r\n\r\nProject B load model code is about like this:\r\n```\r\nfrom tensorflow.keras.models import load_model\r\nmodel = load_model(\"c.h5\")\r\n```\r\n\r\nI use different images ,but got the simillar prediction.\r\n```\r\n[[1.01394113e-02 2.92072829e-04 4.19789851e-02 1.22826849e-03\r\n  9.46218133e-01 1.30874541e-04 1.23131176e-05]\r\n\r\n [1.06976507e-02 3.13456461e-04 4.33462970e-02 1.27648050e-03\r\n  9.44213808e-01 1.38900723e-04 1.34185420e-05]\r\n\r\n [1.01642376e-02 2.94585945e-04 4.19760570e-02 1.23549451e-03\r\n  9.46185470e-01 1.31785186e-04 1.24300368e-05]\r\n\r\n [1.05263414e-02 3.09864059e-04 4.28950936e-02 1.27590902e-03\r\n  9.44842041e-01 1.37657087e-04 1.31396355e-05]\r\n\r\n [1.04539478e-02 3.05163179e-04 4.27655652e-02 1.25962391e-03\r\n  9.45066750e-01 1.35915790e-04 1.30421986e-05]\r\n\r\n [1.04103265e-02 3.03133012e-04 4.26876061e-02 1.25538185e-03\r\n  9.45195496e-01 1.35144786e-04 1.29277996e-05]\r\n\r\n [1.06208669e-02 3.10785865e-04 4.33004946e-02 1.27685803e-03\r\n  9.44339037e-01 1.38675998e-04 1.33183985e-05]\r\n\r\n [1.04063889e-02 3.03731475e-04 4.25971374e-02 1.25621166e-03\r\n  9.45288241e-01 1.35323397e-04 1.29246901e-05]]\r\n```\r\n\r\n\r\nWhat's more, When I changed checkpoint directory name in the project A, The model trained by project A is not working in Project A.\r\nIf I reset checkpoint directory name to before , The checkpoint weights works fine again in project A ! \r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["It was just like not load trained weight. And the model wat initialized with random weights."]}, {"number": 52058, "title": "Issue with tensorflow lite interpreter ", "body": "`import tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n(ds_train, ds_test), ds_info = tfds.load( 'mnist',\r\nsplit=['train', 'test'],\r\nshuffle_files=True,\r\nas_supervised=True,\r\nwith_info=True,\r\n)\r\ndef normalize_img(image, label):\r\nreturn tf.cast(image, tf.float32) / 255., label\r\n\r\nds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\nds_train = ds_train.cache()\r\nds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\r\nds_train = ds_train.batch(128)\r\nds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\r\nds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n\r\nds_test = ds_test.batch(128)\r\nds_test = ds_test.cache()\r\nds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n#model\r\nmodel = tf.keras.models.Sequential([\r\ntf.keras.layers.Flatten(input_shape=(28, 28)),\r\ntf.keras.layers.Reshape((1,784)),\r\ntf.keras.layers.Conv1D( 16, 1,use_bias=False,activation = 'relu' ),\r\ntf.keras.layers.Conv1D(16, 1,use_bias=False ,activation = 'relu' ),\r\ntf.keras.layers.Conv1D( 16, kernel_size=3, strides=1, padding= \"causal\", dilation_rate=2**0, groups=16,use_bias=False,activation ='relu'),\r\ntf.keras.layers.Conv1D( 16, 1 ,use_bias=False) ,\r\ntf.keras.layers.Flatten(),\r\ntf.keras.layers.Dense(10)\r\n])\r\nmodel.compile(\r\noptimizer=tf.keras.optimizers.Adam(0.001),\r\nloss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\nmetrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\r\n)\r\n\r\nmodel.fit(\r\nds_train,\r\nepochs=1,\r\nvalidation_data=ds_test,\r\n)\r\nmodel.summary()\r\nmodel.save(\"./model.h5\")\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nwith open('model.tflite', 'wb') as f:\r\nf.write(tflite_model)\r\n`\r\n\r\nThis the code of my model , after executing this code I'm getting .tflite model . \r\nBut when I'm trying to interpret the tflite model I'm getting the error. \r\n`interpreter = tf.lite.Interpreter(model_path=\"./assignment.tflite\")\r\ninterpreter.allocate_tensors()\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\ninput_shape = input_details[0]['shape']\r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\ninterpreter.invoke()\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\n`\r\nThis is the tflite inference code I'm using \r\n\r\n2021-09-18 20:55:19.573161: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n  File \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"c:\\Users\\itmee\\.vscode\\extensions\\ms-python.python-2021.9.1230869389\\pythonFiles\\lib\\python\\debugpy\\__main__.py\", line 45, in <module>\r\n    cli.main()\r\n  File \"c:\\Users\\itmee\\.vscode\\extensions\\ms-python.python-2021.9.1230869389\\pythonFiles\\lib\\python\\debugpy/..\\debugpy\\server\\cli.py\", line 444, in main\r\n    run()\r\n  File \"c:\\Users\\itmee\\.vscode\\extensions\\ms-python.python-2021.9.1230869389\\pythonFiles\\lib\\python\\debugpy/..\\debugpy\\server\\cli.py\", line 285, in run_file\r\n    runpy.run_path(target_as_str, run_name=compat.force_str(\"__main__\"))\r\n  File \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 265, in run_path\r\n    return _run_module_code(code, init_globals, run_name,\r\n  File \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 97, in _run_module_code\r\n    _run_code(code, mod_globals, init_globals,\r\n  File \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"d:\\MVNS\\assignment\\tf_Asg-1.py\", line 17, in <module>\r\n    interpreter.invoke()\r\n  File \"C:\\Users\\itmee\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\", line 833, in invoke\r\n    self._interpreter.Invoke()\r\nRuntimeError: tensorflow/lite/kernels/conv.cc:349 input->dims->data[3] != filter->dims->data[3] (16 != 1)Node number 13 (CONV_2D) failed to prepare.\r\n Error traceback details are as mentioned above. \r\n\r\n", "comments": ["Hi @vanajareedy0426 ,\r\nCould you please fill the issue template,  as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!", "> Hi @vanajareedy0426 ,\r\n> Could you please fill the issue template, as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!\r\n\r\nTensorflow version is 2.5.0 \r\nentire code is given above. Once I got the mode. h5 , then I'm converting it into tflite . \r\n\r\ntflite conversion is successful . And I'm trying to use that .tflite model and get output (inference) \r\n`interpreter = tf.lite.Interpreter(model_path=\"./assignment.tflite\") \r\ninterpreter.allocate_tensors()\r\n input_details = interpreter.get_input_details() \r\noutput_details = interpreter.get_output_details() \r\ninput_shape = input_details[0]['shape'] \r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32) \r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\n interpreter.invoke()\r\n output_data = interpreter.get_tensor(output_details[0]['index'])`\r\n\r\nThis is the code I'm using for interpreting .\r\n\r\n\r\n2021-09-18 20:55:19.573161: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\nFile \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\r\nreturn _run_code(code, main_globals, None,\r\nFile \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 87, in run_code\r\nexec(code, run_globals)\r\nFile \"c:\\Users\\itmee.vscode\\extensions\\ms-python.python-2021.9.1230869389\\pythonFiles\\lib\\python\\debugpy_main.py\", line 45, in\r\ncli.main()\r\nFile \"c:\\Users\\itmee.vscode\\extensions\\ms-python.python-2021.9.1230869389\\pythonFiles\\lib\\python\\debugpy/..\\debugpy\\server\\cli.py\", line 444, in main\r\nrun()\r\nFile \"c:\\Users\\itmee.vscode\\extensions\\ms-python.python-2021.9.1230869389\\pythonFiles\\lib\\python\\debugpy/..\\debugpy\\server\\cli.py\", line 285, in run_file\r\nrunpy.run_path(target_as_str, run_name=compat.force_str(\"main\"))\r\nFile \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 265, in run_path\r\nreturn _run_module_code(code, init_globals, run_name,\r\nFile \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 97, in _run_module_code\r\n_run_code(code, mod_globals, init_globals,\r\nFile \"C:\\Users\\itmee\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\r\nexec(code, run_globals)\r\nFile \"d:\\MVNS\\assignment\\tf_Asg-1.py\", line 17, in\r\ninterpreter.invoke()\r\nFile \"C:\\Users\\itmee\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\", line 833, in invoke\r\nself._interpreter.Invoke()\r\nRuntimeError: tensorflow/lite/kernels/conv.cc:349 input->dims->data[3] != filter->dims->data[3] (16 != 1)Node number 13 (CONV_2D) failed to prepare.\r\nError traceback details are as mentioned above.\r\n", "@vanajareedy0426 , I was  facing different error in model.fit() operation though. Attaching [gist](https://colab.research.google.com/gist/mohantym/55b7ee284c7c0d25accb49880a05657c/github_52058.ipynb) for reference. The error stack trace was similar to this [issue ](https://github.com/tensorflow/tensorflow/issues/50397). Could you provide a colab gist with above Error stack trace? ", "> @vanajareedy0426 , I was different error in model.fit() operation , attaching [gist](https://colab.research.google.com/gist/mohantym/55b7ee284c7c0d25accb49880a05657c/github_52058.ipynb) for reference. The error stack trace was similar to this [issue ](https://github.com/tensorflow/tensorflow/issues/50397). Could you provide a colab gist with above Error stack trace?\r\n\r\nHi , [https://colab.research.google.com/drive/1m5dwOikj-Qz_0p9NMqHWvkGN46aKwbL2#scrollTo=LBuUa6Wk2zhT](url)\r\nuse the following link to recreate the error , \r\n", " Could you please share the same as a Colab Gist? ", "> Could you please share the same as a Colab Gist?\r\n\r\n[gist](https://colab.research.google.com/gist/vanajareedy0426/263f985bd45e8579891507896a0093d4/issue_github.ipynb)\r\n\r\nPlease use this gist link", "Hi @sanatmpa1 ,Could you please look at this issue , This issue's Error stack trace is similar [this one](https://github.com/tensorflow/tensorflow/issues/50397)  and replicating in TF [2.4](https://colab.research.google.com/gist/mohantym/11fed15ea42a02ec58b0d15b6755285d/issue_github.ipynb#scrollTo=rT_RErtZMVo8),[2.5](https://colab.research.google.com/gist/mohantym/aba97023fafc2986c822e34b4985f608/issue_github.ipynb#scrollTo=rT_RErtZMVo8),[2.6](https://colab.research.google.com/gist/mohantym/99a8bd75c5fbc873045f41398f91377b/issue_github.ipynb#scrollTo=4VeNDoFX2MH9) and [2.7.0dev](https://colab.research.google.com/gist/mohantym/f40447c6e638b03d72782314cae40989/issue_github.ipynb#scrollTo=8mFYoV3x2mc7)(nightly) . The real cause  might be in  model.fit() operation.", "@vanajareedy0426,\r\n\r\nAs per the [gist](https://colab.research.google.com/gist/vanajareedy0426/263f985bd45e8579891507896a0093d4/issue_github.ipynb) that you provided, you have commented out the model.fit() and have you trained the model properly and saved it before converting it to lite?\r\n\r\nAs pointed out by @mohantym [here](https://github.com/tensorflow/tensorflow/issues/52058#issuecomment-922665116), we got the below error while training your model, `InvalidArgumentError:  filter_size does not have enough elements, requested 768, got 48`. On checking, it is mostly related to  value provided for `group` argument in the `3rd Conv1D layer` in your architecture.\r\n\r\nI removed the `group` argument from that layer and now the code is running fine without any errors. Please take a look at this [gist](https://colab.research.google.com/gist/sanatmpa1/6c7d4be50ed3dbc345e3a084dc844050/52058.ipynb) ", "\r\n> I removed the `group` argument from that layer and now the code is running fine without any errors. Please take a look at this [gist](https://colab.research.google.com/gist/sanatmpa1/6c7d4be50ed3dbc345e3a084dc844050/52058.ipynb)\r\n\r\nThanks for the confirmation, with out groups it is working fine. But  I want to use grouped convolution in this model.\r\n\r\nDoes tflite converter and interpreter works in case grouped convolutions ? or not ? Can you provide any comments on this \r\n\r\n", "@vanajareedy0426,\r\n\r\nYou can take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/40044) to know more about grouped convolution support in TFLite", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52058\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52058\">No</a>\n"]}, {"number": 52057, "title": "ValueError: ('Input has undefined rank:', TensorShape(None))", "body": "```\r\ndef identity_block(X, f, filters, training=True, initializer=random_uniform):\r\n    \"\"\"\r\n    Implementation of the identity block as defined in Figure 4\r\n    \r\n    Arguments:\r\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\r\n    f -- integer, specifying the shape of the middle CONV's window for the main path\r\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\r\n    training -- True: Behave in training mode\r\n                False: Behave in inference mode\r\n    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\r\n    \r\n    Returns:\r\n    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\r\n    \"\"\"\r\n    \r\n    # Retrieve Filters\r\n    F1, F2, F3 = filters\r\n    \r\n    # Save the input value. You'll need this later to add back to the main path. \r\n    X_shortcut = X\r\n    \r\n    # First component of main path\r\n    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\r\n    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\r\n    X = Activation('relu')(X)\r\n    \r\n    ### START CODE HERE\r\n    ## Second component of main path (\u22483 lines)\r\n    X = Conv2D(filters= F1,kernel_size= f ,strides=(1,1),padding='same',kernel_initializer=glorot_uniform(seed=0))(X)\r\n    X = BatchNormalization(axis=3)(X,training=training)\r\n    X = Activation('relu')(X)\r\n\r\n    ## Third component of main path (\u22482 lines)\r\n    X = Conv2D(filters=F3,kernel_size= 1,strides=(1,1),padding='valid',kernel_initializer=glorot_uniform(seed=0))\r\n    X = BatchNormalization(axis=3)(X,training=training)\r\n    \r\n    \r\n    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (\u22482 lines)\r\n    X = Add()([X,X_shortcut])\r\n    X = Activation('relu')(X) \r\n    ### END CODE HERE\r\n\r\n    return X\r\n\r\n\r\n```\r\nWhy I am getting this error,I checked all the docs of tfs.\r\n![3](https://user-images.githubusercontent.com/26819449/133884934-1a3c2cfe-a763-4279-a48b-9ec5e7a18a74.JPG)\r\n", "comments": ["@starboyvarun \r\nplease paste your error in text as it will be easy for anyone to look it up. We see that you have not filled the issue template, it will be easier to help you if the issue template is filled.\r\nYou may refer to similar issues and let us know: [link](https://stackoverflow.com/questions/43480732/none-dimension-raise-valueerror-in-batch-norm-with-tensorflow)\r\n\r\ni ran the code shared and face different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/0bef138c03dcd8aa8c4a670ab8ee01d3/untitled639.ipynb).", "@Saduf2019  Thank you so much for the gist. I solved the particular error.", "@starboyvarun \r\nThank you for your update, Glad your issue is resolved."]}, {"number": 52056, "title": "Added explanation to README.md and some changed some spaces which relieve developer's eyes", "body": "Add explanation to the tutorial in README.md", "comments": ["So, um, did it get accepted ?", "Hi, \r\n\r\nThanks for taking the time to send a PR, but please try to focus on one thing at a time. \r\n\r\n\"Does the readme need this description paragraph?\" is one question. I'm leaning \"no\".\r\n\r\nRandom whitespace changes in a bunch of other places is not part of that question, and would not be accepted as a PR on its own."]}, {"number": 52055, "title": "Autograph could not transform ... will run it as is", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur 11.5.1\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: MacBook Air 2020\r\n- TensorFlow installed from (source or binary): These instructions: https://towardsdatascience.com/installing-tensorflow-on-the-m1-mac-410bb36b776\r\n- \r\n(tf installed from these 2 links)\r\n\r\ntensorflow_addons_macos-0.1a3-cp38-cp38-macosx_11_0_arm64.whl \u2014 https://github.com/apple/tensorflow_macos/releases/download/v0.1alpha3/tensorflow_addons_macos-0.1a3-cp38-cp38-macosx_11_0_arm64.whl\r\n\r\ntensorflow_macos-0.1a3-cp38-cp38-macosx_11_0_arm64.whl \u2014 https://github.com/apple/tensorflow_macos/releases/download/v0.1alpha3/tensorflow_macos-0.1a3-cp38-cp38-macosx_11_0_arm64.whl\r\n\r\n- TensorFlow version (use command below): tf_macos-v0.1-alpha2-AS-67-gf3595294ab 2.4.0-rc0\r\n- Python version: 3.8.12\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: M1 7 cores\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI can not use my model to predict values and also get that warning when I fit, evaluate, and train.\r\n**Describe the expected behavior**\r\nI'm hopefully supposed to be able to predict stuff and not get that warning\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): I don't know what this is so no.\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nimport tensorflow as tf\r\n\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nx_train = tf.keras.utils.normalize(x_train, axis=1)\r\nx_test = tf.keras.utils.normalize(x_test, axis=1)\r\n\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.layers.Flatten())\r\nmodel.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\r\nmodel.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\r\nmodel.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\r\n\r\nmodel.compile(optimizer= \"adam\",\r\n             loss= \"sparse_categorical_crossentropy\",\r\n             metrics= [\"accuracy\"])\r\n\r\nmodel.fit(x_train, y_train, epochs=3)\r\n\r\nError appears after this ^ line. I also try to run model.predict() and it runs in definitely long.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nI tried the 'export AUTOGRAPH_VERBOSITY=10' line with and without quotation marks and either get a string output or syntax error so I unfortunately can not attach that. Furthermore, I tried it in terminal with the Conda environment active and got export as not a valid command or no output at all.\r\n\r\nWARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x156c9e160> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: unsupported operand type(s) for -: 'NoneType' and 'int'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x156c9e160> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: unsupported operand type(s) for -: 'NoneType' and 'int'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert", "comments": ["The `export` command is a bash command, not a Python instruction. In Python, try this, after the imports: `tf.autograph.set_verbosity(10)`.\r\n\r\nThis might be an environment issue. If you get the chance, you may also want to install using the official instructions instead: https://www.tensorflow.org/install.", "@ajohnson114 , did you try the above step and tried installing [Tensorflow](https://www.tensorflow.org/install.) here?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52055\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52055\">No</a>\n", "I try it but still I face same issue \r\n```\r\n\r\n%%time\r\nimport tensorflow.compat.v2 as tf\r\nimport tensorflow_datasets as tfds\r\n\r\ntf.enable_v2_behavior()\r\ntf.autograph.set_verbosity(10)\r\n\r\nfrom tensorflow.python.framework.ops import disable_eager_execution\r\ndisable_eager_execution()\r\n\r\n\r\n(ds_train, ds_test), ds_info = tfds.load(\r\n    'mnist',\r\n    split=['train', 'test'],\r\n    shuffle_files=True,\r\n    as_supervised=True,\r\n    with_info=True,\r\n)\r\n\r\ndef normalize_img(image, label):\r\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\r\n  return tf.cast(image, tf.float32) / 255., label\r\n\r\nbatch_size = 128\r\n\r\nds_train = ds_train.map(\r\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\nds_train = ds_train.cache()\r\nds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\r\nds_train = ds_train.batch(batch_size)\r\nds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n\r\nds_test = ds_test.map(\r\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\nds_test = ds_test.batch(batch_size)\r\nds_test = ds_test.cache()\r\nds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\r\n                 activation='relu'),\r\n  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\r\n                 activation='relu'),\r\n  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\r\n#   tf.keras.layers.Dropout(0.25),\r\n  tf.keras.layers.Flatten(),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n#   tf.keras.layers.Dropout(0.5),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\nmodel.compile(\r\n    loss='sparse_categorical_crossentropy',\r\n    optimizer=tf.keras.optimizers.Adam(0.001),\r\n    metrics=['accuracy'],\r\n)\r\n\r\nmodel.fit(\r\n    ds_train,\r\n    epochs=12,\r\n    validation_data=ds_test,\r\n)\r\n```", "@araby123 can you include the console output?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52055\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52055\">No</a>\n", "> @araby123 can you include the console output?\r\n\r\nas you see below this are coming out to me and until now I can not solve this issue and train my model\r\n\r\n> @araby123 can you include the console output?\r\n\r\n```\r\nMetal device set to: Apple M1\r\nWARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x14a760dc0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function normalize_img at 0x14a760dc0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n2021-10-19 13:11:41.757046: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-10-19 13:11:41.757319: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\nWARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x14a760dc0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function normalize_img at 0x14a760dc0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function normalize_img at 0x14a760dc0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function normalize_img at 0x14a760dc0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n2021-10-19 13:11:41.892468: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-10-19 13:11:41.892489: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n2021-10-19 13:11:41.897826: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\r\n2021-10-19 13:11:41.980346: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:41.991484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.018471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.032453: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.095177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.110084: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.132235: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.149814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.168231: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n```", "I think you're running an unsupported Python runtime. If you run `python --version`, what does it print?\r\n\r\nAt any rate, those are just warnings and many times TF can continue past them. If you don't see an error further down the logs, then you can normally ignore them.", "> \r\n\r\n@mdanatg as you see I have 3.9.7 version\r\n<img width=\"403\" alt=\"Screen Shot 2021-11-23 at 4 46 57 PM\" src=\"https://user-images.githubusercontent.com/7244313/143035668-b283ea56-afb2-4dd5-9f78-5dcfb9cca1ba.png\">\r\n ", "Odd, the printout doesn't say, so I'll assume it's cpython, which is supported. Are you using precompiled Python by any chance?", "> Odd, the printout doesn't say, so I'll assume it's cpython, which is supported. Are you using precompiled Python by any chance?\r\n\r\nNo at All", "Strange. And can you confirm that `normalize_img` is a function defined in a Python file, that you `import`?\r\nIf you run `import inspect; inspect.getsource(normalize_img)` in your program, does it throw an error?"]}, {"number": 52054, "title": "TF probability cannot broadcast last batch dimension if event_shape is not a scalar", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: GTX 1060M\r\n\r\n**Describe the current behavior**\r\nlog_prob fails to broadcast to batch dims if event_shape is not a scalar, even if event_shape matches. I'm pretty sure this should be a trivial broadcast, but maybe I'm wrong here.\r\nNotImplementedError: Broadcasting is not supported; unexpected batch and event shape (expected [2 3 2], saw [2 1 2]).\r\n\r\n**Describe the expected behavior**\r\nIn the example here: https://www.tensorflow.org/probability/examples/Understanding_TensorFlow_Distributions_Shapes#computing_log_prob_for_scalar_distributions\r\nAt the section describing \"get the log probability of each value at each point in the batch\", an example is shown of broadcasting a tensor shaped [2, 2, 1] into a distribution with batch_shape [2, 3] and event_shape of (). The broadcasted shape is then [2, 2, 3].\r\n\r\nAttempting to do the same where the shape instead is [2, 2, 1, 2] into a distribution with batch_shape [2, 3] and event_shape of [2]. The expected broadcast shape would simply be [2, 2, 3, 2], where the last batch_dim would be broadcast just like in the example.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow_probability import distributions as tfd\r\n\r\n\r\nif __name__ == '__main__':\r\n    x = tf.constant([[[0.5, 0.75], [0.1, 0.25], [0.35, 0.9]], [[0.4, 0.45], [0.5, 0.7], [0.8, 0.25]]], tf.float32)\r\n    p_x = tfd.Independent(tfd.Normal(x, 1), 1)\r\n\r\n    x_dist = tfd.BatchReshape(distribution=p_x, batch_shape=[2, 3], validate_args=True)\r\n\r\n    # compare each point against every other point\r\n    transposed_elems = tf.expand_dims(tf.transpose(x, perm=(1, 0, 2)), axis=-2)\r\n    pointwise_log_prob = x_dist.log_prob(transposed_elems)\r\n    pass\r\n```\r\n", "comments": ["I just noticed the error is actually on broadcasting on a BatchReshape layer. Is there a workaround for this until it is implemented?", "Hi @sanatmpa1 ,Could you please look into this issue?", "I am able to reproduce the error and here's the [gist](https://colab.research.google.com/gist/sanatmpa1/7dd035860a40bdaf41c4c3f5bd177261/52054.ipynb). Found a similar [issue](https://github.com/tensorflow/probability/issues/1206) in tf-probability repo.\r\n", "@LukeBolly,\r\n\r\nAs this issue if related to `BatchReshape` in `tensorflow_probability`, Can you open an issue in this [repo](https://github.com/tensorflow/probability) for proper assistance? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52054\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52054\">No</a>\n"]}, {"number": 52052, "title": "[oneDNN] V2.4_rc upgrade", "body": "Upgrading oneDNN version to oneDNN v2.4_rc. \r\nLink: https://github.com/oneapi-src/oneDNN/releases/tag/v2.4-rc\r\n\r\nAttn: @penpornk  PR related to TF2.7", "comments": []}, {"number": 52051, "title": "Nested list of feature not accepted by tf.from_tensor_slices", "body": "I'm trying to create a Dataset object with the following record structure and the code:\r\n```\r\nratings_dataset = tf.data.Dataset.from_tensor_slices(np.array(preprocessed))\r\n```\r\n```\r\npreprocessed = [['YoVfDbnISlW0f7abNQACIg', 'RA4V8pr014UyUbDvI-LW2A', 0.0499525, 0.6, 'Framingham', 7, \r\n['Department Stores', 'Optometrists', 'Home & Garden', 'Discount Store', 'Fashion', 'Furniture Stores', \r\n'Grocery', 'Food', 'Shopping', 'Drugstores', 'Electronics', 'Health & Medical', '<PAD>', '<PAD>', \r\n'<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', \r\n'<PAD>', '<PAD>', '<PAD>', '<PAD>']],.........]\r\n```\r\n```\r\nValueError: Can't convert Python sequence with mixed types to Tensor.\r\n```\r\nI converted to NumPy and I got the following error:\r\n```\r\nValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).\r\n```\r\nWithout having the category list (the list inside the list), the Dataset object is created, exactly how I want it to.\r\n\r\nHow do I create a Dataset object with a list of features in it?", "comments": ["```\r\nratings_dataset = tf.data.Dataset.from_tensor_slices({\r\n        'user_id':preprocessed[:,0].tolist(),\r\n        'business_id':preprocessed[:,1].tolist(),\r\n        'fans':preprocessed[:,2].tolist(),\r\n        'norm_rating':preprocessed[:,3].tolist(),\r\n        'city':preprocessed[:,4].tolist(),\r\n        'month':preprocessed[:,5].tolist(),\r\n        'categories':tuple(np.transpose(np.array([x for x in (preprocessed[:,6])])).tolist())\r\n    })\r\n```\r\n\r\nThis worked"]}, {"number": 52050, "title": "[TF-TRT] ConvertReduce with added INT32 support", "body": "@bixia1 for Review\r\n\r\nThis PR enables ConvertReduce to work with INT32 precision,  which is enabled since TRT >= 7.\r\nVery useful for BERT, GPT-2, etc.", "comments": ["```bash\r\nINFO: Elapsed time: 59.236s, Critical Path: 53.36s\r\nINFO: 4 processes: 1 internal, 3 local.\r\nINFO: Build completed successfully, 4 total actions\r\n//tensorflow/compiler/tf2tensorrt:convert_nodes_test                     PASSED in 18.4s\r\n\r\nExecuted 1 out of 1 test: 1 test passes.\r\nINFO: Build completed successfully, 4 total actions\r\n```"]}, {"number": 52047, "title": "Load and select optimization profiles for static TRT engine", "body": "This PR implements TRT optimization profile handling in case of static engine:\r\n- Initializes the optimization profile helper class from ICudaEngine\r\n- Select the optimization profile for the input shape\r\n\r\nThis is PR is necessary to use dynamic shape mode with static engines.\r\n\r\nTracker #52012\r\n\r\nTagging @bixia1 for review.", "comments": ["Improved trt_engine_op_test to cover the static engine path (including profile handling).\r\n\r\nThe logic of handling and creating engines in `TrtEngineOp::GetEngine` needs some simplification. I propose to do that in a follow up PR,  so that here we have a clear overview of the changes.\r\n\r\n@bixia1 ready for review"]}, {"number": 52046, "title": "Downloading \"Imdb_reviews\" from Tensorflow_datasets: UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 30 invalid continuation byte", "body": "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10\r\n- TensorFlow version (use command below):\r\n- 2.3.0\r\n- Python version:\r\n- 3.8.8\r\n\r\n**Describe the current behavior**\r\nWhen I was downloading \"imbd_reviews\" dataset I am facing the below error,\r\n\r\n**'utf-8' codec can't decode byte 0xc5 in position 171: invalid continuation byte**\r\n\r\n``` \r\nimport tensorflow_datasets as tfds\r\ndatasets, info = tfds.load(\"imdb_reviews\",as_supervised=True, with_info=True)\r\n\r\nDownloading and preparing dataset imdb_reviews (80.23 MiB) to C:\\Users\\desig\\tensorflow_datasets\\imdb_reviews\\plain_text\\0.1.0...\r\nDl Completed...:\r\n0/0 [00:00<?, ? url/s]\r\nDl Size...:\r\n0/0 [00:00<?, ? MiB/s]\r\n\r\n\r\n---------------------------------------------------------------------------\r\nUnicodeDecodeError                        Traceback (most recent call last)\r\n<ipython-input-6-f3ae52bd604b> in <module>\r\n      1 import numpy as np\r\n----> 2 datasets, info = tfds.load(\"imdb_reviews\",as_supervised=True, with_info=True)\r\n      3 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51     _check_required(fn, kwargs)\r\n---> 52     return fn(*args, **kwargs)\r\n     53 \r\n     54   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py in load(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\r\n    298   if download:\r\n    299     download_and_prepare_kwargs = download_and_prepare_kwargs or {}\r\n--> 300     dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n    301 \r\n    302   if as_dataset_kwargs is None:\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51     _check_required(fn, kwargs)\r\n---> 52     return fn(*args, **kwargs)\r\n     53 \r\n     54   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in download_and_prepare(self, download_dir, download_config)\r\n    305         self.info.size_in_bytes = dl_manager.downloaded_size\r\n    306         # Write DatasetInfo to disk, even if we haven't computed the statistics.\r\n--> 307         self.info.write_to_directory(self._data_dir)\r\n    308     self._log_download_done()\r\n    309 \r\n\r\n~\\anaconda3\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n    118         if type is None:\r\n    119             try:\r\n--> 120                 next(self.gen)\r\n    121             except StopIteration:\r\n    122                 return False\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py in incomplete_dir(dirname)\r\n    198   try:\r\n    199     yield tmp_dir\r\n--> 200     tf.io.gfile.rename(tmp_dir, dirname)\r\n    201   finally:\r\n    202     if tf.io.gfile.exists(tmp_dir):\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in rename_v2(src, dst, overwrite)\r\n    543     errors.OpError: If the operation fails.\r\n    544   \"\"\"\r\n--> 545   _pywrap_file_io.RenameFile(\r\n    546       compat.as_bytes(src), compat.as_bytes(dst), overwrite)\r\n    547 \r\n\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc5 in position 171: invalid continuation byte\r\n\r\n```\r\nDo any one have  idea, Thank you.\r\n", "comments": ["Hi, \r\nmay be problem in the incorrect system local setting? ", "@NikoRepo ,\r\nI was able to execute the code in tf v2.6 without any error.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/932c367339126a9f5dcecb17a9c10bee/untitled79.ipynb).Also please find this [comment](https://github.com/tensorflow/tensorflow/issues/50837#issuecomment-882476390) from the issue with similar error.It helps.Thanks!", "@tilakrayal  , thank u for your help, I just upgraded my both tensorflow and tensorflow-datasets to latest versions and it worked.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52046\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52046\">No</a>\n"]}, {"number": 52043, "title": "Jupyter notebook can't launch the program correctly, but  anaconda prompt can.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow version: 2.3.0\r\n- Python version: 3.7.11\r\n- Installed using virtualenv? pip? conda?: conda\r\n- CUDA/cuDNN version: 10.1\r\n\r\n**Describe the problem**\r\n\r\nWith Anaconda, I create a virtual environment to install the cpu version of tensorflow. The System information is shown above. I install tensorflow using the command ``conda install tensorflow`` that deals with dependency automatically.\r\n\r\nIt appears to be normal when I run some basic example in **\"anaconda prompt\"**.\r\n\r\nBut when I try to run these in **\"Jupyter Notebook\"**. The kernel can't restart and turns to be dead finally.\r\n\r\nThen I downgrade the version of **\"numpy\"**. It raises the problem about **\"numpy import error\"**:\r\n\r\n![image](https://user-images.githubusercontent.com/62245023/133754574-ffbd33bc-1dda-4c65-b1ae-6f31e0e2d924.png)\r\n\r\n\r\n", "comments": ["@Beliefuture ,\r\nInstallation issues within the Anaconda environment are tracked in the Anaconda repo.Also please try to downgrade the numpy version and try installing latest stable tensorflow v2.6 from [here](https://www.tensorflow.org/install).It helps.Thanks!", "> @Beliefuture ,\r\n> Installation issues within the Anaconda environment are tracked in the Anaconda repo.Also please try to downgrade the numpy version and try installing latest stable tensorflow v2.6 from [here](https://www.tensorflow.org/install).It helps.Thanks!\r\n\r\nThanks for your reply. It seems to be the version of numpy, pyzmq, h5py. I previously think that \"conda\" will manage the version dependency well. But it is apparently not.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52043\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52043\">No</a>\n"]}, {"number": 52042, "title": "TensorFlowLiteC and TensorFlowLiteSelectOps iOS Pods :: Duplicate symbols", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X Mojave (10.14.6)\r\n- TensorFlow installed from (source or binary): Cocoapods (nightly pod)\r\n- TensorFlow version: Tensorflow Lite 0.0.1-nightly.20210915\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n(Following the comment over [here](https://github.com/tensorflow/tensorflow/issues/41876#issuecomment-921400513))\r\n\r\nExperiencing duplicate symbols with the current nightly builds, this doesn't occur with pod versions set to 2.6.0.\r\n\r\nCurrent podfile\r\n```\r\n'TensorFlowLiteObjC', '~> 0.0.1-nightly'\r\n'TensorFlowLiteObjC/Metal', '~> 0.0.1-nightly'\r\n'TensorFlowLiteSelectTfOps', '~> 0.0.1-nightly'\r\n```\r\nResolves to lockfile\r\n```\r\n  - TensorFlowLiteC (0.0.1-nightly.20210915):\r\n    - TensorFlowLiteC/Core (= 0.0.1-nightly.20210915)\r\n  - TensorFlowLiteC/Core (0.0.1-nightly.20210915)\r\n  - TensorFlowLiteC/Metal (0.0.1-nightly.20210915):\r\n    - TensorFlowLiteC/Core\r\n  - TensorFlowLiteObjC (0.0.1-nightly.20210915):\r\n    - TensorFlowLiteObjC/Core (= 0.0.1-nightly.20210915)\r\n  - TensorFlowLiteObjC/Core (0.0.1-nightly.20210915):\r\n    - TensorFlowLiteC (= 0.0.1-nightly.20210915)\r\n  - TensorFlowLiteObjC/Metal (0.0.1-nightly.20210915):\r\n    - TensorFlowLiteC/Metal (= 0.0.1-nightly.20210915)\r\n    - TensorFlowLiteObjC/Core (= 0.0.1-nightly.20210915)\r\n  - TensorFlowLiteSelectTfOps (0.0.1-nightly.20210915)\r\n```\r\n\r\nThe duplicate symbols are `_TfLiteXNNPackDelegateCreate `, `_TfLiteXNNPackDelegateDelete `, `_TfLiteXNNPackDelegateGetThreadPool `, and `_TfLiteXNNPackDelegateOptionsDefault`. \r\n\r\nThey're duplicated between `/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)` and `Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC`.\r\n\r\n(If pod versions are specified as 2.6.0 then they work fine)\r\n", "comments": ["This looks related to the recent change where XNNPack is enabled by default.\r\n@multiverse-tf Could you please take a look?\r\n\r\nAlso cc-ing @thaink who has more experience in these duplicate symbol issues on iOS side.", "@Maratyszcza just fyi.", "> _Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template_\r\n> \r\n> **System information**\r\n> \r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X Mojave (10.14.6)\r\n> * TensorFlow installed from (source or binary): Cocoapods (nightly pod)\r\n> * TensorFlow version: Tensorflow Lite 0.0.1-nightly.20210915\r\n> \r\n> **Describe the problem**\r\n> \r\n> **Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n> \r\n> (Following the comment over [here](https://github.com/tensorflow/tensorflow/issues/41876#issuecomment-921400513))\r\n> \r\n> Experiencing duplicate symbols with the current nightly builds, this doesn't occur with pod versions set to 2.6.0.\r\n> \r\n> Current podfile\r\n> \r\n> ```\r\n> 'TensorFlowLiteObjC', '~> 0.0.1-nightly'\r\n> 'TensorFlowLiteObjC/Metal', '~> 0.0.1-nightly'\r\n> 'TensorFlowLiteSelectTfOps', '~> 0.0.1-nightly'\r\n> ```\r\n> \r\n> Resolves to lockfile\r\n> \r\n> ```\r\n>   - TensorFlowLiteC (0.0.1-nightly.20210915):\r\n>     - TensorFlowLiteC/Core (= 0.0.1-nightly.20210915)\r\n>   - TensorFlowLiteC/Core (0.0.1-nightly.20210915)\r\n>   - TensorFlowLiteC/Metal (0.0.1-nightly.20210915):\r\n>     - TensorFlowLiteC/Core\r\n>   - TensorFlowLiteObjC (0.0.1-nightly.20210915):\r\n>     - TensorFlowLiteObjC/Core (= 0.0.1-nightly.20210915)\r\n>   - TensorFlowLiteObjC/Core (0.0.1-nightly.20210915):\r\n>     - TensorFlowLiteC (= 0.0.1-nightly.20210915)\r\n>   - TensorFlowLiteObjC/Metal (0.0.1-nightly.20210915):\r\n>     - TensorFlowLiteC/Metal (= 0.0.1-nightly.20210915)\r\n>     - TensorFlowLiteObjC/Core (= 0.0.1-nightly.20210915)\r\n>   - TensorFlowLiteSelectTfOps (0.0.1-nightly.20210915)\r\n> ```\r\n> \r\n> The duplicate symbols are `_TfLiteXNNPackDelegateCreate `, `_TfLiteXNNPackDelegateDelete `, `_TfLiteXNNPackDelegateGetThreadPool `, and `_TfLiteXNNPackDelegateOptionsDefault`.\r\n> \r\n> They're duplicated between `/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)` and `Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC`.\r\n> \r\n> (If pod versions are specified as 2.6.0 then they work fine)\r\n\r\nThx for reporting this! Could you help find the culprit commit? As @yyoon mentioned, we recently enabled XNNPACK backend by default on iOS (see 6fa4ddfd459386d9fa32ce5c19813f9aff56ae2a and 418156b52654f66b0286096cf8f58531f7473b1d for details). It's possible one of these two commits has caused this issue.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52042\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52042\">No</a>\n", "same issue\r\nI just follow the step [https://www.tensorflow.org/lite/guide/ops_select](url)\r\n\r\n# In your Podfile target:\r\n  pod 'TensorFlowLiteSwift'   # or 'TensorFlowLiteObjC'\r\n  pod 'TensorFlowLiteSelectTfOps', '~> 0.0.1-nightly'\r\nAfter running pod install, you need to provide an additional linker flag to force load the select TF ops framework into your project. In your Xcode project, go to Build Settings -> Other Linker Flags, and add:\r\n\r\n\r\n-force_load $(SRCROOT)/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps\r\n\r\nif config the force_load in Build Setting in XCode.\r\n\r\nduplicate symbol '_TfLiteXNNPackDelegateCreate' in:\r\n    /Users/ruomu/Desktop/ruomu_Project/iOS/TestTensorFlow/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)\r\n    /Users/ruomu/Desktop/ruomu_Project/iOS/TestTensorFlow/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC\r\nduplicate symbol '_TfLiteXNNPackDelegateDelete' in:\r\n    /Users/ruomu/Desktop/ruomu_Project/iOS/TestTensorFlow/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)\r\n    /Users/ruomu/Desktop/ruomu_Project/iOS/TestTensorFlow/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC\r\nduplicate symbol '_TfLiteXNNPackDelegateGetThreadPool' in:\r\n    /Users/ruomu/Desktop/ruomu_Project/iOS/TestTensorFlow/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)\r\n    /Users/ruomu/Desktop/ruomu_Project/iOS/TestTensorFlow/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC\r\nduplicate symbol '_TfLiteXNNPackDelegateOptionsDefault' in:\r\n    /Users/ruomu/Desktop/ruomu_Project/iOS/TestTensorFlow/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)\r\n    /Users/ruomu/Desktop/ruomu_Project/iOS/TestTensorFlow/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC\r\nld: 4 duplicate symbols for architecture arm64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n\r\n----------------------------------------------\r\n\r\nPODS:\r\n  - TensorFlowLiteC (2.6.0):\r\n    - TensorFlowLiteC/Core (= 2.6.0)\r\n  - TensorFlowLiteC/Core (2.6.0)\r\n  - TensorFlowLiteObjC (2.6.0):\r\n    - TensorFlowLiteObjC/Core (= 2.6.0)\r\n  - TensorFlowLiteObjC/Core (2.6.0):\r\n    - TensorFlowLiteC (= 2.6.0)\r\n  - TensorFlowLiteSelectTfOps (0.0.1-nightly.20211008)\r\n\r\nDEPENDENCIES:\r\n  - TensorFlowLiteObjC\r\n  - TensorFlowLiteSelectTfOps (~> 0.0.1-nightly)", "I'm getting the same issues with the most recent TensorFlowLiteSelectTfOps (0.0.1-nightly.20211013) and TensorFlowLiteSwift 2.6.0 as well as 2.4.0. \r\n\r\nIn another project, with an older TensorFlowLiteSelectTfOps (0.0.1-nightly.20210202) and TFLiteSwift 2.4.0, it works. \r\n\r\nIs there a way to downgrade/choose another TensorFlowLiteSelectTfOps version?\r\n\r\n**Edit**: Mine now works again with version 2.4.0 and by editing my Podfile.lock to the following and running _pod install_:\r\n\r\n```\r\n  - TensorFlowLiteC (2.4.0):\r\n    - TensorFlowLiteC/Core (= 2.4.0)\r\n  - TensorFlowLiteC/Core (2.4.0)\r\n  - TensorFlowLiteSelectTfOps (0.0.1-nightly.20210202)\r\n  - TensorFlowLiteSwift (2.4.0):\r\n    - TensorFlowLiteSwift/Core (= 2.4.0)\r\n  - TensorFlowLiteSwift/Core (2.4.0):\r\n    - TensorFlowLiteC (= 2.4.0)\r\n```", "Version 2.7 still has the issue. Any plans to resolve it?", "@yyoon Can you reopen this and possibly reassign to someone else. The issue may be stale, but the problem is still exists.", "ok @normano ! Reopening this issue as requested.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52042\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52042\">No</a>\n", "The fixed version of the SelectTfOps framework will be available soon via nightly builds (unfortunately, this problem will remain in 2.8.0). Will notify this thread once again when the nightly build is published.", "@yyoon @terryheo Hi, I'm experiencing the exact same issue on 2.8.0 with the 4 duplicate symbols.\r\n\r\nI tried your fix by adding `\"//tensorflow/lite/delegates/xnnpack:xnnpack_delegate\"` to `avoid_deps` like\r\n[this](https://github.com/tensorflow/tensorflow/commit/282772e0c27e302be91e060587dbe99289832365)\r\n\r\nI re-run:\r\n`bazel build -c opt --config=ios_arm64 tensorflow/lite/ios:TensorFlowLiteSelectTfOps_framework`\r\n\r\nThe 4 symbols are no longer duplicated but I'm facing a different problem now with a lot of missing symbols (see below).\r\nIn case this can help, I generated my `TensorFlowLiteC_framework` file wih:\r\n`bazel build --config=ios_arm64 -c opt tensorflow/lite/ios:TensorFlowLiteC_framework `\r\n\r\nIs there any tweak I can make to get these symbols back into `TensorFlowLiteSelectTfOps_framework` ?\r\n```\r\n\r\nError (Xcode): Undefined symbol: tflite::logging_internal::MinimalLogger::LogFormatted(tflite::LogSeverity, char const*, char*)\r\n\r\nError (Xcode): Undefined symbol: ruy::ScopedSuppressDenormals::ScopedSuppressDenormals()\r\n\r\nError (Xcode): Undefined symbol: ruy::ScopedSuppressDenormals::~ScopedSuppressDenormals()\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::Sub1Vector(short const*, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::CwiseAdd(short const*, short const*, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::CwiseClipping(short*, int, short)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::MatrixBatchVectorMultiply(signed char const*, int, signed char const*, int, int, int, int, int, signed char*, signed char)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::VectorScalarMultiply(signed char const*, int, float, float*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::TwoGateSaturatingAdd(signed char const*, signed char, signed char const*, signed char, int, int, int, int, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::ApplyLayerNormFloat(short const*, short const*, int, int, int const*, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::ApplySigmoidFloat(short const*, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::CwiseMul(short const*, short const*, int, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::MatrixBatchVectorMultiply(short const*, signed char const*, int, int, int const*, int, int, int, int, signed char*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::ApplyLayerNorm(short const*, short const*, int const*, int, int, int, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::CwiseClipping(float*, int, float)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::BatchVectorBatchVectorDotProduct(short const*, short const*, int, int, int*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate(signed char const*, int const*, signed char const*, int, int, int, int, int, int, int*, short*, tflite::CpuBackendContext*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate(signed char const*, int, int, signed char const*, float const*, int, float*, float const*, int const*, int*, int*, bool*, tflite::CpuBackendContext*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::ReductionSumVector(int const*, int*, int, int)\r\n\r\nError (Xcode): Undefined symbol: ruy::Pack8bitColMajorForNeonA55ish(void const*, void const*, void const*, void const*, int, int, int, int, int, int, signed char*, int*, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetIntermediatesSafe(TfLiteContext const*, TfLiteNode const*, int, TfLiteTensor**)\r\n\r\nError (Xcode): Undefined symbol: tflite::DynamicBuffer::WriteToTensorAsVector(TfLiteTensor*)\r\n\r\nError (Xcode): Undefined symbol: tflite::PreprocessLogSoftmaxScalingExp(double, double, int, int*, int*, int*, int*)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetOutput(TfLiteContext*, TfLiteNode const*, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::DynamicBuffer::AddString(tflite::StringRef const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::SparseMatrixBatchVectorMultiplyAccumulate1x4(float const*, int const*, int const*, int, int, float const*, int, float*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate(float const*, int, int, float const*, int, float*)\r\n\r\nError (Xcode): Undefined symbol: tflite::NudgeQuantizationRange(float, float, int, int, float*, float*, float*)\r\n\r\nError (Xcode): Undefined symbol: tflite::DetectArmNeonDotprod()\r\n\r\nError (Xcode): Undefined symbol: ruy::Allocator::AllocateBytes(long)\r\n\r\nError (Xcode): Undefined symbol: tflite::internal::sparsity::FormatConverter<signed char>::FormatConverter(std::__1::vector<int, std::__1::allocator<int> > const&, TfLiteSparsity const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::ApplySigmoid(short const*, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: ruy::Ctx::SelectPath(ruy::Path)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::MatrixBatchVectorMultiplyAccumulate(signed char const*, int, int, signed char const*, float const*, int, int*, float*, tflite::CpuBackendContext*)\r\n\r\nError (Xcode): Undefined symbol: tflite::internal::sparsity::FormatConverter<signed char>::SparseToDense(signed char const*, unsigned long, signed char*, TfLiteContext*)\r\n\r\nError (Xcode): Undefined symbol: tflite::FakeQuantizeArray(float, float, float, float const*, float*, float)\r\n\r\nError (Xcode): Undefined symbol: tflite::IsMobilePlatform()\r\n\r\nError (Xcode): Undefined symbol: tflite::internal::sparsity::FormatConverter<float>::FormatConverter(std::__1::vector<int, std::__1::allocator<int> > const&, TfLiteSparsity const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::PopulateConvolutionQuantizationParams(TfLiteContext*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor*, TfLiteFusedActivation const&, int*, int*, int*, int*, int*, int*, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::HaveSameShapes(TfLiteTensor const*, TfLiteTensor const*)\r\n\r\nError (Xcode): Undefined symbol: ruy::PackFloatColMajorForNeon(float const*, float const*, float const*, float const*, int, int, int, int, int, float*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::MatrixScalarMultiplyAccumulate(signed char const*, int, int, int, int*)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetOptionalInputTensor(TfLiteContext const*, TfLiteNode const*, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::logging_internal::MinimalLogger::Log(tflite::LogSeverity, char const*, ...)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::CwiseClipping(signed char*, int, signed char)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::Sub1Vector(float const*, int, float*)\r\n\r\nError (Xcode): Undefined symbol: tflite::internal::sparsity::FormatConverter<float>::SparseToDense(float const*)\r\n\r\nError (Xcode): Undefined symbol: ruy::detail::MultiplyByQuantizedMultiplier(int, int, int)\r\n\r\nError (Xcode): Undefined symbol: ruy::Kernel8bitNeon1Col(ruy::KernelParams8bit<4, 4> const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::transpose_utils::IsTranspose2DApplicable(tflite::TransposeParams const&, tflite::RuntimeShape const&, int*, int*)\r\n\r\nError (Xcode): Undefined symbol: ruy::Kernel8bitNeon(ruy::KernelParams8bit<4, 4> const&)\r\n\r\nError (Xcode): Undefined symbol: ruy::Pack8bitColMajorForNeon(void const*, void const*, void const*, void const*, int, int, int, int, int, int, signed char*, int*, int)\r\n\r\nError (Xcode): Undefined symbol: ruy::Kernel8bitNeonDotprod1Col(ruy::KernelParams8bit<8, 8> const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetQuantizedConvolutionMultipler(TfLiteContext*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor*, double*)\r\n\r\nError (Xcode): Undefined symbol: ruy::Pack8bitRowMajorForNeon(unsigned char const*, int, int, int, int, int, int, signed char*, int, int, int*, int, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::VectorBatchVectorCwiseProductAccumulate(short const*, int, short const*, int, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetOutputShapeFromInput(TfLiteContext*, TfLiteTensor const*, TfLiteIntArray**)\r\n\r\nError (Xcode): Undefined symbol: ruy::Kernel8bitNeonDotprodX1(ruy::KernelParams8bit<8, 8> const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::internal::sparsity::FormatConverter<Eigen::half>::SparseToDense(Eigen::half const*, unsigned long, Eigen::half*, TfLiteContext*)\r\n\r\nError (Xcode): Undefined symbol: ruy::Kernel8bitNeonDotprod(ruy::KernelParams8bit<8, 8> const&)\r\n\r\nError (Xcode): Undefined symbol: ruy::Pack8bitColMajorForNeonDotprodA55ish(void const*, void const*, void const*, void const*, int, int, int, int, int, int, signed char*, int*, int)\r\n\r\nError (Xcode): Undefined symbol: ruy::Ctx::clear_performance_advisories()\r\n\r\nError (Xcode): Undefined symbol: ruy::Pack8bitRowMajorForNeonDotprod(void const*, void const*, void const*, void const*, int, int, int, int, int, int, signed char*, int, int*, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::DynamicBuffer::WriteToTensor(TfLiteTensor*, TfLiteIntArray*)\r\n\r\nError (Xcode): Undefined symbol: ruy::KernelFloatNeonDotprodA55ish(ruy::KernelParamsFloat<8, 8> const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::SparseMatrixBatchVectorMultiplyAccumulate(signed char const*, unsigned char const*, int, int, signed char const*, float const*, int, float*)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetInput(TfLiteContext const*, TfLiteNode const*, int)\r\n\r\nError (Xcode): Undefined symbol: ruy::KernelFloatNeonX1(ruy::KernelParamsFloat<8, 8> const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetInputSafe(TfLiteContext const*, TfLiteNode const*, int, TfLiteTensor const**)\r\n\r\nError (Xcode): Undefined symbol: tflite::TfLiteTypeGetSize(TfLiteType)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetQuantizedConvolutionMultipler(TfLiteContext*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor*, double*)\r\n\r\nError (Xcode): Undefined symbol: ruy::ThreadPool::ExecuteImpl(int, int, ruy::Task*)\r\n\r\nError (Xcode): Undefined symbol: ruy::KernelFloatNeon(ruy::KernelParamsFloat<8, 8> const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::ReductionSumVector(signed char const*, int*, int, int)\r\n\r\nError (Xcode): Undefined symbol: ruy::PackFloatColMajorForNeonA55ish(float const*, float const*, float const*, float const*, int, int, int, int, int, float*)\r\n\r\nError (Xcode): Undefined symbol: tflite::CheckedLog2(float, int*)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::ApplyTanh(int, short const*, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetTemporarySafe(TfLiteContext const*, TfLiteNode const*, int, TfLiteTensor**)\r\n\r\nError (Xcode): Undefined symbol: ruy::KernelFloatNeonA55ish(ruy::KernelParamsFloat<8, 8> const&)\r\n\r\nError (Xcode): Undefined symbol: ruy::Kernel8bitNeonDotprodA55ish(ruy::KernelParams8bit<8, 8> const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::ExternalCpuBackendContext::ExternalCpuBackendContext()\r\n\r\nError (Xcode): Undefined symbol: ruy::get_ctx(ruy::Context*)\r\n\r\nError (Xcode): Undefined symbol: ruy::Ctx::GetMainAllocator()\r\n\r\nError (Xcode): Undefined symbol: tflite::transpose_utils::RemoveOneSizeDimensions(tflite::RuntimeShape*, tflite::RuntimeShape*, tflite::TransposeParams*)\r\n\r\nError (Xcode): Undefined symbol: ruy::Pack8bitColMajorForNeonDotprod(void const*, void const*, void const*, void const*, int, int, int, int, int, int, signed char*, int*, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::CalculateInputRadius(int, int, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::transpose_utils::Flatten(tflite::RuntimeShape const&, tflite::RuntimeShape const&, tflite::TransposeParams const&, tflite::RuntimeShape*, tflite::RuntimeShape*, tflite::TransposeParams*)\r\n\r\nError (Xcode): Undefined symbol: tflite::internal::sparsity::FormatConverter<float>::SparseToDense(float const*, unsigned long, float*, TfLiteContext*)\r\n\r\nError (Xcode): Undefined symbol: tflite::CalculateShapeForBroadcast(TfLiteContext*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor const*, TfLiteIntArray**)\r\n\r\nError (Xcode): Undefined symbol: tflite::internal::sparsity::FormatConverter<Eigen::half>::FormatConverter(std::__1::vector<int, std::__1::allocator<int> > const&, TfLiteSparsity const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetTemporary(TfLiteContext*, TfLiteNode const*, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::ApplyTanhFloat(short const*, int, int, int, short*)\r\n\r\nError (Xcode): Undefined symbol: tflite::CpuBackendContext::GetFromContext(TfLiteContext*)\r\n\r\nError (Xcode): Undefined symbol: ruy::Kernel8bitNeonA55ish(ruy::KernelParams8bit<4, 4> const&)\r\n\r\nError (Xcode): Undefined symbol: tflite::QuantizeMultiplier(double, int*, int*)\r\n\r\nError (Xcode): Undefined symbol: tflite::CalculateActivationRangeQuantized(TfLiteContext*, TfLiteFusedActivation, TfLiteTensor*, int*, int*)\r\n\r\nError (Xcode): Undefined symbol: tflite::GetString(TfLiteTensor const*, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::VectorVectorDotProduct(float const*, float const*, int)\r\n\r\nError (Xcode): Undefined symbol: tflite::tensor_utils::CwiseMul(short const*, short const*, int, int, int, int, int, signed char*)\r\n\r\n```"]}]