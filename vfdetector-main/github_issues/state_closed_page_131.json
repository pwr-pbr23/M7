[{"number": 51017, "title": "Prevent division by 0 in LSH projection.", "body": "PiperOrigin-RevId: 387225857\nChange-Id: Iaeb572a763618c64f503e0026f6dd9fd769bf50c", "comments": []}, {"number": 51016, "title": "Prevent nullptr dereference in MLIR TFLite dialect/optimizer.", "body": "PiperOrigin-RevId: 387220762\nChange-Id: Id136ef04bb3d36123b4685d316ae81a9ec924d6b", "comments": []}, {"number": 51015, "title": "Prevent heap OOB read in TFLite's `gather_nd.cc`.", "body": "Passing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387208551\nChange-Id: I6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd", "comments": ["This is the same as #51014"]}, {"number": 51014, "title": "Prevent heap OOB read in TFLite's `gather_nd.cc`.", "body": "Passing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387208551\nChange-Id: I6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd", "comments": []}, {"number": 51013, "title": "Prevent an OOB read in `expand_dims.cc`", "body": "The for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. If user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in Python one can do `l[-3]` to mean `l[-3 + len(l)]`).\n\nPiperOrigin-RevId: 387200206\nChange-Id: I162f4feba12d547c3a4340833ae682016a2ebfab", "comments": []}, {"number": 51012, "title": "Ensure non-empty input_splits in tf.raw_ops.UnicodeEncode", "body": "PiperOrigin-RevId: 387170080\nChange-Id: I3b489acc51c5cb4124c535b9df7cc6e62ef21766", "comments": []}, {"number": 51011, "title": "Ensure non-empty input_splits in tf.raw_ops.UnicodeEncode", "body": "PiperOrigin-RevId: 387170080\nChange-Id: I3b489acc51c5cb4124c535b9df7cc6e62ef21766", "comments": []}, {"number": 51010, "title": "Ensure non-empty input_splits in tf.raw_ops.UnicodeEncode", "body": "PiperOrigin-RevId: 387170080\nChange-Id: I3b489acc51c5cb4124c535b9df7cc6e62ef21766", "comments": []}, {"number": 51009, "title": "Ensure non-empty input_splits in tf.raw_ops.UnicodeEncode", "body": "PiperOrigin-RevId: 387170080\nChange-Id: I3b489acc51c5cb4124c535b9df7cc6e62ef21766", "comments": []}, {"number": 51008, "title": "Secure tf.raw_ops.QuantizeV2", "body": "Validate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318", "comments": []}, {"number": 51007, "title": "Secure tf.raw_ops.QuantizeV2", "body": "Validate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318", "comments": []}, {"number": 51006, "title": "Secure tf.raw_ops.QuantizeV2", "body": "Validate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318", "comments": []}, {"number": 51005, "title": "Secure tf.raw_ops.QuantizeV2", "body": "Validate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318", "comments": []}, {"number": 51004, "title": "[Cherrypick2.6] In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape", "body": null, "comments": []}, {"number": 51003, "title": "[Cherrypick2.5] In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape", "body": null, "comments": []}, {"number": 51002, "title": "[Cherrypick2.4] In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape", "body": null, "comments": []}, {"number": 51001, "title": "[Cherrypick2.3] In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape", "body": null, "comments": []}, {"number": 51000, "title": "[Cherrypick2.5] Disallow empty node_id_range in tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2 and tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature", "body": null, "comments": []}, {"number": 50999, "title": "[Cherrypick2.4] Disallow empty node_id_range in tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2 and tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature", "body": null, "comments": []}, {"number": 50998, "title": "[Cherrypick2.3] Disallow empty node_id_range in tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2 and tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature", "body": null, "comments": []}, {"number": 50997, "title": "[Cherrypick2.6] Disallow empty node_id_range in tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2 and tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature", "body": null, "comments": []}, {"number": 50996, "title": "Revert \"Update shape_refiner.cc\"", "body": "This reverts commit 1886d486348a93fc328a6e40bdea9ed91f44f0b7.\r\n\r\nThis is not needed on r2.6", "comments": []}, {"number": 50995, "title": "[minor] add missing kwargs to resnet_v2 constructors", "body": "thanks", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50995) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "It looks like your PR relates to the Keras component. Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. Thankyou.\r\n@fchollet, @qlzh727"]}, {"number": 50993, "title": "fake quant in tflite ignores the num_bits that is passed", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0\r\n\r\n### 2. Code\r\n\r\n``` python\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nkeras = tf.keras\r\nlayers = tf.keras.layers\r\n\r\ninput_shape = (1, 1000)\r\ninputs = layers.Input(shape=input_shape)\r\noutputs = tf.quantization.fake_quant_with_min_max_args(inputs=inputs, num_bits=2, min=-2, max=2)\r\nmodel = keras.Model(inputs=inputs, outputs=outputs)\r\n\r\n\r\ndef convert_to_tflite(model):\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    tflite_model = converter.convert()\r\n    return tflite_model\r\n\r\n\r\ndef infer(tflite_model, img):\r\n    interpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n    interpreter.allocate_tensors()\r\n    input_details = interpreter.get_input_details()[0]\r\n    interpreter.set_tensor(input_details[\"index\"], img)\r\n    interpreter.invoke()\r\n    output_details = interpreter.get_output_details()[0]\r\n    output = interpreter.get_tensor(output_details[\"index\"])[0]\r\n    return output\r\n\r\n\r\nimg = np.sort(np.random.random((1,)+input_shape).astype(np.float32) * 5 - 2.5)\r\ntflite_model = convert_to_tflite(model)\r\ntf_output = model.predict(img)\r\ntflite_output = infer(tflite_model, img)\r\n\r\nfig, axs = plt.subplots(2)\r\nfig.suptitle('FakeQuant TFLite vs TF')\r\n\r\nx = img.flatten()\r\naxs[0].plot(x, tflite_output.flatten())\r\naxs[1].plot(x, tf_output.flatten())\r\nplt.show()\r\n```\r\n\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\nWhen quantizing using fake quant with less than 8 bits, it seems to actually quantize the input with 8 bits anyway.\r\nIn Tensorflow it seems to work, but not in TFLite.\r\n\r\n### 5. (optional) Any other info / logs\r\nHere for example is a plot of quantizing a tensor using 2 bits. The upper subplot is the output of TFLite, while the bottom subplot is the output of Tensorflow.\r\n\r\n\r\n![fq_issue](https://user-images.githubusercontent.com/44209964/127321225-4b2181bc-a822-40d4-bebc-3557a3deb8c7.png)\r\n", "comments": ["Currently TFLite doesn't support any quantized data type with bitwidth less than 8, so even though the fake quant op seems to be working in TF, when converted to TFLite, (with default optimization) it will assume that the requested behavior is to produce an 8bit operation (quantize to 8 bits). In the future we may support 4bit and ternary types, but at the moment, there is no way to get the behavior you desire."]}, {"number": 50991, "title": "[oneDNN]  Fix for build failure.", "body": "Fixes a build error due to a recent commit https://github.com/tensorflow/tensorflow/commit/d6f2afb314f19090e742da1f94367e08be86ef93. Llvm openMP failed to build due to a missing py_binary call that was not copied over from llvm/BUILD to llvm_openmp/BUILD.", "comments": []}, {"number": 50990, "title": "Help Me \ud83d\ude05", "body": "Can Anyone tell me why is this happening? I am new to Python so it might be a silly issue \ud83d\ude05\r\n![dfhdfhdtr](https://user-images.githubusercontent.com/70793550/127268620-ba792466-e339-4231-95a3-d66d4fed52b5.JPG)\r\n", "comments": ["i think you need to install the python package: pillow \n`pip install Pillow`", "@Shion7581 ,\r\nCan you please take a look at this [link](https://www.geeksforgeeks.org/python-pillow-a-fork-of-pil/) for more information.It helps.Thanks!", "This question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!", "Thank you everyone for telling me the solution appreciate your kindness :)", "@Shion7581 ,\r\nGlad the issue is resolved for you, please feel free to move this to closed status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50990\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50990\">No</a>\n"]}, {"number": 50988, "title": "How to convert model trained with tensorflow object detection api to tflite model that supported by Android GPU", "body": "I train a ssd_resnet50 with tensorflow object detection api. Then export and convert the model. The tflite model has lots of nodes like while, gather that that are not supported by tflite GPU. However ssd_mobile model with similar framework on tensorflow hub can ran on android gpu.\r\nDid I forget some operations? How to remove nodes not supported by android gpu in model conversion.", "comments": ["@Yoline777,\r\nCan you please check the [documentation of Pruning](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras) and let us know if it helps? Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50988\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50988\">No</a>\n"]}, {"number": 50987, "title": "use `std::make_tuple` in `cupti_tracer.cc`", "body": "This reverts commit 501a0b2f8cba60b8fc1343646ec61d71af40e0dc and is splited from #50929.\r\n\r\nThe errors I got during builds were\r\n```\r\nExecution platform: @local_execution_config_platform//:platform\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc: In function 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool> tensorflow::profiler::{anonymous}::DecodeDriverMemcpy(CUpti_CallbackId, const void*)':\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:162:67: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->ByteCount, CuptiTracerEventType::MemcpyH2D, false};\r\n                                                                   ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:167:66: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->ByteCount, CuptiTracerEventType::MemcpyH2D, true};\r\n                                                                  ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:171:67: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->ByteCount, CuptiTracerEventType::MemcpyD2H, false};\r\n                                                                   ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:176:66: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->ByteCount, CuptiTracerEventType::MemcpyD2H, true};\r\n                                                                  ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:180:67: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->ByteCount, CuptiTracerEventType::MemcpyD2D, false};\r\n                                                                   ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:185:66: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->ByteCount, CuptiTracerEventType::MemcpyD2D, true};\r\n                                                                  ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:189:69: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->ByteCount, CuptiTracerEventType::MemcpyOther, false};\r\n                                                                     ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:193:68: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->ByteCount, CuptiTracerEventType::MemcpyOther, true};\r\n                                                                    ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:197:61: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {Bytes2D(p->pCopy), MemcpyKind(p->pCopy), false};\r\n                                                             ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:202:60: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {Bytes2D(p->pCopy), MemcpyKind(p->pCopy), true};\r\n                                                            ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:206:60: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {Bytes3D(p->pCopy), MemcpyKind(p->pCopy), true};\r\n                                                            ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:211:60: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {Bytes3D(p->pCopy), MemcpyKind(p->pCopy), true};\r\n                                                            ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:216:76: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p2p_params->ByteCount, CuptiTracerEventType::MemcpyP2P, false};\r\n                                                                            ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:221:75: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p2p_params->ByteCount, CuptiTracerEventType::MemcpyP2P, true};\r\n                                                                           ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:225:58: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {0, CuptiTracerEventType::Unsupported, false};\r\n                                                          ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc: In function 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool> tensorflow::profiler::{anonymous}::DecodeDriverMemset(CUpti_CallbackId, const void*)':\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:235:56: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->N, CuptiTracerEventType::Memset, false};\r\n                                                        ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:239:56: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->N, CuptiTracerEventType::Memset, false};\r\n                                                        ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:243:56: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->N, CuptiTracerEventType::Memset, false};\r\n                                                        ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:247:75: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->dstPitch * p->Height, CuptiTracerEventType::Memset, false};\r\n                                                                           ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:251:75: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->dstPitch * p->Height, CuptiTracerEventType::Memset, false};\r\n                                                                           ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:255:75: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->dstPitch * p->Height, CuptiTracerEventType::Memset, false};\r\n                                                                           ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:259:55: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->N, CuptiTracerEventType::Memset, true};\r\n                                                       ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:263:55: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->N, CuptiTracerEventType::Memset, true};\r\n                                                       ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:267:55: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {const long unsigned int&, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->N, CuptiTracerEventType::Memset, true};\r\n                                                       ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:272:74: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->dstPitch * p->Height, CuptiTracerEventType::Memset, true};\r\n                                                                          ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:277:74: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->dstPitch * p->Height, CuptiTracerEventType::Memset, true};\r\n                                                                          ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:282:74: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {p->dstPitch * p->Height, CuptiTracerEventType::Memset, true};\r\n                                                                          ^\r\ntensorflow/core/profiler/internal/gpu/cupti_tracer.cc:286:58: error: converting to 'std::tuple<long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool>' from initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {int, tensorflow::profiler::CuptiTracerEventType, bool}; <template-parameter-2-2> = void; _Elements = {long unsigned int, tensorflow::profiler::CuptiTracerEventType, bool}]'\r\n       return {0, CuptiTracerEventType::Unsupported, false};\r\n                                                          ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```\r\n\r\n`std::make_tuple` was replaced in 60b9283c9e5308bae6fe19d2db531a6c230baffd. After I restored `std::make_tuple`, the build passed.\r\n\r\ncc @yisitu ", "comments": []}, {"number": 50986, "title": "Make passthrough alias work for resource updates", "body": "\r\nModify `alias_passthrough_params` so that it can work with `resource update alias`. Concretely, `module->input_output_alias_config()` could have some aliases preset by `resource update alias`.\r\n\r\nI will upstream another change to enable `resource update alias` for auto-clustering right after this PR is merged.", "comments": ["@cheshire, could you please help to take a look at this small PR? Thanks!"]}, {"number": 50985, "title": "Fix segmentation fault in shape inference logic.", "body": "When running shape functions, some functions (such as `MutableHashTableShape`)\nproduce extra output information in the form of a `ShapeAndType` struct.  The\nshapes embedded in this struct are owned by an inference context that is\ncleaned up almost immediately; if the upstream code attempts to access this\nshape information, it can trigger a segfault.\n\n`ShapeRefiner` is mitigating this for normal output shapes by cloning them\n(and thus putting the newly created shape under ownership of an inference\ncontext that will not die), but we were not doing the same for shapes and\ntypes.  This commit fixes that by doing similar logic on output shapes and\ntypes.\n\nPiperOrigin-RevId: 384761124\nChange-Id: I07c0c42d29dfbb55bfa13ec1f09ef825fb0a1a1d", "comments": []}]