[{"number": 22399, "title": "MirroredStrategy AssertionError in 1.11.0-rc0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04; Not on mobile device\r\n- **TensorFlow installed from (source or binary)**:\r\nsource \r\nmodels's commit = 17fa52864bfc7a7444a8b921d8a8eb1669e14ebd and tensorflow's commit = 1e438195399650604fb3aa3a53c67339f1167882\r\n- **TensorFlow version (use command below)**:\r\ngit checkout -b v1.11.0-rc0 v1.11.0-rc0\r\n- **Python version**:\r\nPython 3.5.2 (default, Nov 23 2017, 16:37:01)\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.17.1\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\nGeForce GTX 1070 Ti 8G*4\r\n- **Exact command to reproduce**:\r\n# python object_detection/model_main.py --pipeline_config_path=object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config --logtostderr --model_dir=/data/checkpoint/del2 --num_gpus=4\r\nand meet AssertionError:\r\nFile \"/home/soft/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/values.py\", line 414, in _tensor_conversion_mirrored\r\n    assert not as_ref\r\nAssertionError\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\n### Describe the problem\r\nSimilar issue: https://github.com/tensorflow/tensorflow/issues/21968. \r\nReply: Actually, this issue is likely fixed in release 1.11, could you try with that and see if that fixes the issue? But I meet the issue in 1.11.0-rc0.\r\n\r\n### Source code / logs\r\n 1\r\ngit diff object_detection/model_main.py\r\n-config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir)\r\n+distribution = tf.contrib.distribute.MirroredStrategy()\r\n+config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir, train_distribute=distribution, eval_distribute=distribution)\r\n2\r\ncd /models/research\r\n# python object_detection/model_main.py --pipeline_config_path=object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config --logtostderr --model_dir=/data/sisi.wu/checkpoint/del2 --num_gpus=4\r\n3\r\n[multi-GPU.log](https://github.com/tensorflow/tensorflow/files/2399199/multi-GPU.log)\r\n\r\n\r\nThanks.", "comments": ["sorry for missed info:\r\nCUDA/cuDNN version:\r\nCuda compilation tools, release 9.0, V9.0.176;cuDNN7.0", "Update env.txt, [tf_env.txt](https://github.com/tensorflow/tensorflow/files/2399219/tf_env.txt)\r\nThanks.", "@cococyx Thanks for reporting this. Could you check whether this issue is seen in TensorFlow 1.11.0-rc1?", "Thanks for you reply. This issue is seen in TensorFlow 1.11.0-rc1, and I'll try 1.11.0-rc2.\r\n>>> tf.__version__\r\n'1.11.0-rc1'\r\n[multi-GPU-1.11.0-rc1.log](https://github.com/tensorflow/tensorflow/files/2413482/multi-GPU-1.11.0-rc1.log)\r\n\r\n", ">>> tf.__version__\r\n'1.11.0-rc2'\r\n[multi-GPU-1.11.0-rc2.log](https://github.com/tensorflow/tensorflow/files/2413626/multi-GPU-1.11.0-rc2.log)\r\n", "@cococyx Thanks for catching and reporting this. It appears there is a sync issue, we will certainly note it down.", "Will close this as the issue is fixed in TensorFlow 1.11.0 and 1.12.0", "I still have this issue for Resnet50, and TensorFlow 1.12.0... Seems to be related with tf.slim's convolution2d, but not with batch_norm as I've seen elsewhere: add_weight, instead. \r\n\r\n(On another note, I had problems with batch_norm, namely using sonnet, but disabling the corresponding layers work, so this makes me think that not all layers are supported with MirroredStrategy yet)", "Same error here.\r\nIssue for rfcn-resnet101 and tensorflow 1.12.0-rc2.\r\nRelated with tf.slim's convolution2d  but not with batch_norm.\r\nHave you solve this? @AVCarreiro ", "Not yet, and it seems more people have this issue.", "I had similar error with mirroredstrategy and I am using TensorFlow 1.12.0. I found that if I delete the regularizers.l2_regularizer(weight_decay) in conv2d (set the weight regularizer to None) inside the function 'resnet_arg_scope' in 'resnet_utils' to None then MirroredStrategy works fine. ", "Is there any update on this issue?", "> I had similar error with mirroredstrategy and I am using TensorFlow 1.12.0. I found that if I delete the regularizers.l2_regularizer(weight_decay) in conv2d (set the weight regularizer to None) inside the function 'resnet_arg_scope' in 'resnet_utils' to None then MirroredStrategy works fine.\r\n\r\nIt works for me", "is there any update? same error", "TF 1.11 has passed it's end of life. Please upgrade to TF 1.14 or TF 2.0 beta.", "any update.. I am getting the same error while training based on multi gpu using MirroredStrategy?", "Are you using TF2.0 or TF 1.15?", "> Are you using TF2.0 or TF 1.15?\r\n\r\nI am using TF2.0", "Please open a new issue filling the entire template.\r\n\r\nI am going to close this one so there won't be confusion w.r.t. versions used."]}, {"number": 22398, "title": "CUDA implementation of BiasAddGrad op is non-determinstic", "body": "I'm running TensorFlow 1.5.0 on a K80 GPU on Python 2.7\r\n\r\nFailing test case:\r\n```python\r\nfrom __future__ import print_function\r\nimport hashlib\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nnp.random.randn(2018)\r\ntf.set_random_seed(2018)\r\n\r\nX = np.random.randn(1024, 50).astype(np.float32)\r\nb = tf.get_variable('bias', [50])\r\nz = tf.nn.bias_add(X, b)\r\n\r\ngrad = tf.gradients(z*z, b)[0]\r\n\r\ninit_op = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init_op)\r\n\r\n    run1 = sess.run(grad)\r\n    run2 = sess.run(grad)\r\n\r\n    print(np.all(run1 == run2))\r\n    print(np.max(np.abs(run1 - run2)))\r\n\r\n    dohash = lambda X: hashlib.md5(X.tostring()).hexdigest()\r\n    print(dohash(run1))\r\n    print(dohash(run2))\r\n```\r\n\r\nOutputs\r\n```\r\nFalse\r\n6.10352e-05\r\nb489a1d659518b2ae9213f5a21e35df2\r\n187a57d563468e59ba5f9d9cf51ca5cb\r\n```\r\n\r\nThis bug still exists in master, because the code in master uses the unsafe CUDA atomic floating point add in several places. See https://github.com/tensorflow/tensorflow/blob/abc55107eb7a03fe3d83f95fd5e1b8e4def90826/tensorflow/core/kernels/bias_op_gpu.cu.cc \r\nIf TensorFlow will be ever be fully determinstic, atomic floating point add should never be used (it is inherently non-determinstic due to non-associativity of floating point).\r\n\r\nNotably, Keras's `Dense` layer uses `bias_add`, so all networks that use this layer are non-reproducible. This is relevant to https://github.com/keras-team/keras/issues/2280 .\r\n\r\n This can currently be avoided by using `tf.add` instead of `tf.nn.bias_add` at a slightly performance hit. The correct fix would be refactor the `BiasAddGrad` op to use a (deterministic) reduction tree.\r\n\r\nedit with issue template fields:\r\nHave I written custom code: Python test case, see above\r\nOS Platform and Distribution: RHEL 7.5 (Linux)\r\nTensorFlow installed from: source\r\nTensorFlow version: 1.5.0\r\nBazel version: unknown\r\nCUDA/cuDNN version: CUDA 8.0.61, cuDNN v6\r\nGPU model and memory: Nvidia K80, 12GB memory\r\nExact command to reproduce: run the above script\r\nMobile device: NA", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@eamartin A small amount of non-determinstism in TensorFlow computations is expected on GPU. Ongoing efforts are put forth and FR is in place. [18096](https://github.com/tensorflow/tensorflow/issues/18096) Latest developments from algorithms and hardware architecture perspectives reaped success where challenges remain.\r\n\r\nPlease resort to workarounds, e.g. tf.add for now until more concrete solutions come forth.  ", "Closing this issue for now, will use FR to track progress.", "@wt-huang This issue is completely separate from https://github.com/tensorflow/tensorflow/issues/18096 as it has nothing to do with cuDNN. Is this the FR (= feature request?) that you are referring to? \r\n\r\nThe non-determinism here is in the TensorFlow source itself, not a 3rd party library. Adding support for configuring cuDNN determinism will resolve https://github.com/tensorflow/tensorflow/issues/18096 but will do nothing to fix this issue. I fear merging this issue with an unrelated cuDNN issue will lead to this bug becoming untracked and neglected.", "@eamartin This problem is a subset of the non-determinism issue resides in cuDNN. When the feature request is completed and the solution implemented will be transferred to `tf.nn.bias_add`", "This problem is a non-determinism issue, but is separate from non-determinism issues with cuDNN.\r\n\r\nThe solution to cuDNN non-determinism is to pass the correct flags into the library specifying which algorithm to use. See https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#reproducibility\r\n\r\nThe solution of \"set the right cudDNN flags\" cannot be transferred to non-cuDNN issues such as this. Resolving this issue involves modifying CUDA kernels in the TF source. Resolving https://github.com/tensorflow/tensorflow/issues/18096 probably does not.\r\n\r\nAdditionally, this issue affects more users than https://github.com/tensorflow/tensorflow/issues/18096 as `bias_add` is used for fully connected layers (including through Keras) while cuDNN primarily affects CNNs.\r\n\r\nAn appropriate \"remove non-deterministic behavior\" parent issue should not be solely about cuDNN in my opinion. It should include mention of removing all uses of atomic floating point instructions in the TF source.", "https://github.com/tensorflow/tensorflow/issues/2732 is a more relevant issue than https://github.com/tensorflow/tensorflow/issues/18096", "Nagging Assignee @wt-huang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@eamartin Yes, atomic floating point addition is one of the primary triggers of non-determinism, which happens to be prevalent in CUDA regime. Often times they go hand it hand. [#2732](https://github.com/tensorflow/tensorflow/issues/2732) is related to this issue so are a few others.\r\n\r\nWe are very well aware of this issue and progress is underway.", "@wt-huang Has this issue been solved? Why has it been closed?", "@eamartin We are aware of this issue, fix is in the progress.", "Is there a PR or a branch on Github for this in-progress fix?\r\nI'd prefer to leave this issue open until the bug is fixed in master.", "@eamartin, this issue was resolved, in Oct 2019, with PR [31465](https://github.com/tensorflow/tensorflow/pull/31465). In TensorFlow version 2.1 and onwards, you can enable the solution by setting the environment variable `TF_DETERMINISTIC_OPS` to \"1\" or \"true\".\r\n\r\nFor more information, see https://github.com/NVIDIA/tensorflow-determinism", "@duncanriach thank you very much for that fix as well as all of your other work on TensorFlow determinism!", "You're welcome, @eamartin. Thank you for the appreciation."]}, {"number": 22395, "title": "numpy not found during python_api generation", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS-7.4\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: None\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.10.1, earlier versions\r\n- **Python version**: 2.7, 3.6 (separate rebuilds same issue)\r\n- **Bazel version (if compiling from source)**: 0.17.1\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.5, 6.3.1 (separate rebuilds same issue)\r\n- **CUDA/cuDNN version**: CPU only build\r\n- **GPU model and memory**: Quadro K4000\r\n- **Exact command to reproduce**: Not reproducible with single command\r\n\r\n### Describe the problem\r\nProblem manifests as \"No module named numpy\", during python api generation as detailed below in log section.\r\n\r\nIf placing a simple `print(sys.path)` or `print(os.environ['PYTHONPATH'])` in the listed `__init__.py` (in below log), none of the resulting paths listed include the path that numpy is included on via the PYTHONPATH, which is being passed along to the build environ included via bazels CLI opts, `--action_env` and `--test_env` arguments to the build call.\r\n\r\nI believe this issue will be reproducible only under a state where someone has installed numpy to a nonstandard location, and is including it via PYTHONPATH and `--action_env` such as is listed. However, all python modules in our environment are in separate paths, as managed by an environment manager, so I cannot install them to a common system path for testing if the issue resolves itself. What is strange is that earlier steps that require numpy have built just fine and not errored from what I can tell.\r\n\r\nApologies if my details included are omitting some crucial detail. The specific set of config values seems unnecessary for detail here, but let me know if they are needed. (Every optional component driven by `TF_NEED_{var}` is turned off except for `TF_NEED_JEMALLOC` which does not appear to be part of the problem)\r\n\r\n### Source code / logs\r\n\r\nbuild command, while prefaced by many environment variable changes and the ./configure step, is of the form:\r\n`bazel --batch build --action_env=PYTHONPATH --action_env=LD_LIBRARY_PATH --test_env=PYTHONPATH --test_env=LD_LIBRARY_PATH -c opt --copt=-mfpmath=both --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n`ERROR: ${build_root}/tensorflow/BUILD:581:1: Executing genrule //tensorflow:tensorflow_python_api_gen failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/home/${user}/.cache/bazel/_bazel_${user}/ff38b9a62494579437724e08cde1b695/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/${user}/.cache/bazel/_bazel_${user}/ff38b9a62494579437724e08cde1b695/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 49, in <module>\r\n    import numpy as np\r\nImportError: No module named numpy`", "comments": ["@maxnbk TensorFlow has a dependency on NumPy module. Please install NumPy and build again.", "numpy is installed. Please read the details more thoroughly. It is simply not in a typical system-installed path, but is available on the PYTHONPATH.", "Not sure how bazel resolves/uses `PYTHONPATH` I am guessing that may be a part of the problem.\r\nDid you use `pip install` command to install numpy?", "Wanted to report that I've run into the same issue when upgrading from tensorflow 1.6 to 1.10.1 [building from source, we also have a not-very-typical installation of python modules (including numpy). I haven't found a way to force my PYTHONPATH to be used (with --action_env or otherwise)", "pip install was used to install numpy, but you must be aware that people can relocate pip packages with --prefix or --target commands (depending on the install procedure), and as such, PYTHONPATH should be used to find a python module, not relying that all systems or users install it in the same location on every type of host or user environment.\r\n\r\nbazel declares in it's docs that --action_env is how one can ensure an environment variable makes it from the shell-executed environment to the build environment, and --test_env is similar but obviously for the test running environments. However it appears it is also required for a bazel build to declare something else I am unfamiliar with in order to propagate the environment to the task which runs the build components. That is the portion that I am declaring there is an issue with.\r\n\r\nGlad to hear I am not alone with David Lange, as our last built tensorflow was 1.4.1 . I could attempt to nail down the exact version it stopped working in.", "CC @annarev ", "I was able to produce a working 1.9.0 build, but unable to produce a working 1.10.0 build with the same exact build settings, with completely accurate details as above, e.g. did not do GPU build etc (nothing else was changed other than the release version that I selected.)", "I'm running into a very similar problem as reported here, where `import keras_applications` fails during the build of TensorFlow 1.11.0 (cfr. #21518), even though `Keras-Applications` is installed in a location listed in `$PYTHONPATH` (installed with `pip install --prefix`, so not in a standard location).\r\n\r\nTesting with `python -c \"import keras_applications\"` confirms that my environment (outside of the Bazel sandbox) is correctly set up.\r\n\r\nLike @maxnbk I have tried instructing Bazel (v0.16.0 in my case) to pass down `$PYTHONPATH` using `--action_env=PYTHONPATH`, but that doesn't fix the issue...\r\n\r\nAny updates on this?", "I ran a build with the latest 1.12.0-rc0 and experienced the same issue, in case testing it against the most recent release helps locate the problem.", "Can you try removing PYTHON_LIB_PATH setting from .tf_configure.bazelrc file in the root tensorflow directory? (this file is generated when running ./configure)\r\n\r\nWhy I think that might work:\r\nWe look for pip packages in location specified when running ./configure. This location is stored as value of PYTHON_LIB_PATH in .tf_configure.bazelrc file. If PYTHON_LIB_PATH is not set, then we seem to fallback to PYTHONPATH\r\n(https://github.com/tensorflow/tensorflow/blob/master/third_party/py/python_configure.bzl#L177).\r\n\r\n", "Actually I don't think my suggestion above would work. Seems like even if we pick up PYTHONPATH, we only take 1st path in PYTHONPATH. As I understand, this bug is for configurations that have Python modules installed in multiple locations.\r\n\r\n@meteorcloudy do you know the right way to pass PYTHONPATH to bazel?", "@annarev I think you can use `--action_env=PYTHONPATH`", "Thank you @meteorcloudy!\r\n\r\nhm passing --action_env PYTHONPATH=<pythonpath value> works for me. I tried the following:\r\n1. Setup virtualenv \"venv\" and install pip dependencies *except keras_applications*\r\n2. Setup virtualenv \"venv1\" and install *only keras_applications*\r\n3. Then I activate \"venv\" and run:\r\n```\r\nbazel test tensorflow/tools/api/tests:api_compatibility_test --nocache_test_results\r\n```\r\nIt fails because keras_applications is not found, as expected.\r\n\r\n4. Then, I run the same but pass PYTHONPATH that points to venv1 site-packages:\r\n```\r\nbazel test --action_env PYTHONPATH=\"<path to venv1>/venv1/lib/python2.7/site-packages\" tensorflow/tools/api/tests:api_compatibility_test --nocache_test_results\r\n```\r\nThis command passes.\r\n\r\n\r\n\r\nIn case relevant, this is my setup:\r\n```\r\nvirtualenv venv1\r\nsource venv1/bin/activate\r\npip install keras_applications==1.0.4\r\ndeactivate\r\n\r\nvirtualenv venv\r\nsource venv/bin/activate\r\npip install --upgrade setuptools==39.1.0\r\npip install keras_preprocessing==1.0.2\r\npip install --upgrade six mock portpicker scipy sklearn grpcio\r\npip install numpy==1.14.5\r\npip uninstall keras_applications\r\n\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow/\r\nexport TF_NEED_CUDA=0\r\nyes \"\" | python configure.py\r\n```\r\n", "That's still just one path inside pythonpath, though? Creating a virtualenv will not be a solve if someone has, for example, some python packages installed at system root, and some at user root, and must build like that.\r\n\r\nIf you made two venvs and passed a PYTHONPATH var which contains two paths via --action_env would it work?", "@maxnbk I believe so, `PYTHONPATH` is like `PATH`, it can contain a list of path instead of just one.\r\n\r\nSee more from https://docs.python.org/3/using/cmdline.html#envvar-PYTHONPATH", "Perhaps I just have a typo... but this does not work solve the issue I've had - changing\r\n\r\nbazel --output_user_root ../build build -s --verbose_failures -c opt --cxxopt=$CXX_OPT_FLAGS //tensorflow/tools/pip_package:build_pip_package\r\n\r\nto\r\n\r\nbazel --output_user_root ../build build -s --verbose_failures -c opt --cxxopt=$CXX_OPT_FLAGS --action_env PYTHONPATH=\"${PYTHON27PATH}\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\nresults in the same error of numpy missing. [where PYTHON27PATH is a PATH like variable listing all of the entries I want in PYTHONPATH]\r\n\r\n  File \"/build/dlange/180925/BUILD/slc6_amd64_gcc700/external/tensorflow-sources/1.10.1/build/0a8c18c4045ab378bcc6\\\r\n140b80b5d812/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api.runfiles/org_tenso\\\r\nrflow/tensorflow/python/__init__.py\", line 47, in <module>\r\n    import numpy as np\r\nImportError: No module named numpy\r\n\r\nI added a printout to the failing script (create_python_api.py) just to confirm that in fact the python environment is not being seen. eg, \r\n\r\nimport sys\r\nprint(sys.path)\r\n\r\nindeed does not include any of my PYTHONPATH\r\n\r\n> On Oct 12, 2018, at 11:06 PM, annarev <notifications@github.com> wrote:\r\n> \r\n> Thank you @meteorcloudy!\r\n> \r\n> hm passing --action_env PYTHONPATH= works for me. I tried the following:\r\n> \r\n> \t\u2022 Setup virtualenv \"venv\" and install pip dependencies except keras_applications\r\n> \t\u2022 Setup virtualenv \"venv1\" and install only keras_applications\r\n> \t\u2022 Then I activate \"venv\" and run:\r\n> bazel test tensorflow/tools/api/tests:api_compatibility_test --nocache_test_results\r\n> \r\n> It fails because keras_applications is not found, as expected.\r\n> \r\n> \t\u2022 Then, I run the same but pass PYTHONPATH that points to venv1 site-packages:\r\n> bazel test --action_env PYTHONPATH=\"<path to venv1>/venv1/lib/python2.7/site-packages\" tensorflow/tools/api/tests:api_compatibility_test --nocache_test_results\r\n> \r\n> This command passes.\r\n> \r\n> In case relevant, this is my setup:\r\n> \r\n> virtualenv venv1\r\n> source venv1/bin/activate\r\n> pip install keras_applications==1.0.4\r\n> deactivate\r\n> \r\n> virtualenv venv\r\n> source venv/bin/activate\r\n> pip install --upgrade setuptools==39.1.0\r\n> pip install keras_preprocessing==1.0.2\r\n> pip install --upgrade six mock portpicker scipy sklearn grpcio\r\n> pip install numpy==1.14.5\r\n> pip uninstall keras_applications\r\n> \r\n> git clone https://github.com/tensorflow/tensorflow.git\r\n> cd tensorflow/\r\n> export TF_NEED_CUDA=0\r\n> yes \"\" | python configure.py\r\n> \r\n> \u2014\r\n> You are receiving this because you commented.\r\n> Reply to this email directly, view it on GitHub, or mute the thread.\r\n> \r\n\r\n", "@meteorcloudy You slightly missed the point here, .. Only one specific path as set, out of many, on the PYTHONPATH is being consumed by the numpy-needing components of the build, or something to that effect, functionally. ", "I see, @annarev do you know why only one specific path is consumed by the numpy build?", "My instructions above have a flaw. Really sorry about that! I actually tested by first running a successful build with keras-applications installed, then uninstalled keras-applications and reran the test. It probably didn't rebuild api-generation genrule for the second run. That's why I missed the error.\r\n\r\nI experimented a bit more. Looks like PYTHONPATH gets picked up at runtime but not at genrule execution time. I then tried passing `--distinct_host_configuration=false` to bazel and PYTHONPATH got picked up during genrule execution as well.\r\n\r\nSo, you can try `--distinct_host_configuration=false` as a workaround if you are building for the same platform where you are running the build.\r\n\r\n@meteorcloudy does `--action_env` apply to `host` and/or `target` configuration?\r\n", "That workaround (using --distinct_host_configuration=false as part of the bazel build flags) is working for me in non-GPU build tests.\r\nOf course, I don't like workarounds, but it will get me through until a conclusive solve is worked out.\r\nThanks @annarev . I am happy to run any other tests needed / provide data to help debug further.", "Ah, weird. Perhaps premature. The resulting wheel doesn't want to install on my platform, despite attempting to install for the same platform as the build was run for.", "@annarev `--action_env` should apply to both host and target configuration", "Apologies for waffling back and forth, I've gotten the --distinct_host_configuration=false wheel to install, I had a name wrong due to testing on the latest RC and the error is a little bit misleading.\r\nThat functions correctly for me. Is there a downside to this if my current platform will always be my target platform?", "Also able to produce valid GPU build with above details still relevant.", "Its great that it works. Thank you for trying it out @maxnbk. --distinct_host_configuration=false flag is fine so long as your target is same as current platform.\r\n\r\nThank you @meteorcloudy for investigating and opening a bazel bug!\r\n\r\nIt would be nice if it worked without that flag. I want to look at skipping this genrule during build (instead submitting some data that it generates). So, I will keep this issue open.", "@annarev, for a similar defect https://github.com/tensorflow/tensorflow/issues/23695, I created this patch: https://github.com/wdirons/tensorflow/commit/01c28a94e63edc8aa301ee377ca026107762858b\r\n\r\nPlease review and let me know if you think it should be submitted as a PR?\r\n\r\nEdit: The more I read about this defect, the more I realize the above fix has nothing to do with this defect. (just the other defect)", "Hi @maxnbk!\r\nIt seems you are using older versions(1.x versions) of Tensorflow which is not supported any more. Could you confirm whether issue is replicating after [migrating](https://www.tensorflow.org/guide/migrate/migrate_tf2) to 2.6 or not ? Thanks!", "My issue was worked around with the `--distinct_host_configuration=false` flag and my production environment has switched to using wheels after v2.0 I believe, so I don't believe I need this solved personally. I'd still recommend that someone independently verify the issue, as single-pythonpath-entry-consumption could be an issue in any number of other environments, but not mine anymore. Do what you will with the issue according to whichever principles this org operates by. Cheers.", "Ok @maxnbk ! Thanks for confirmation. Closing this issue as it seems to be resolved from above [comment](https://github.com/tensorflow/tensorflow/issues/22395#issuecomment-980499820).", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 22394, "title": "Tensorflow == operator is inconsistent with NumPy, other TF comparison operators", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: \r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: not relevant\r\n- **Exact command to reproduce**: A == B\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nHello,\r\n\r\nI recently ran into a bug in my code where I was trying to use the == operator to compare arrays element-wise. I found out that == was comparing the entire array, rather than comparing element-wise, so the whole expression evaluated to false. The false scalar was then broadcast across other arrays in the program, making the bug difficult to detect. I was able to fix the bug by using the function tf.equal().\r\n\r\nMy question is, why does == have this behavior in Tensorflow? In Numpy, == compares arrays element-wise. Even in Tensorflow, the other comparison operators (>, >=. <, <=) operate element-wise. Is there a specific reason for breaking this convention only for the == operator?\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nNumpy code:\r\n\r\n>>> import numpy as np\r\n>>> A = np.eye(3)\r\n>>> A == 1\r\narray([[ True, False, False],\r\n       [False,  True, False],\r\n       [False, False,  True]])\r\n", "comments": ["@bbrister Please refer a similar [issue](https://github.com/tensorflow/tensorflow/issues/9359). This can help to get an idea why the equal (==) and not equal (!=) operators which are overloaded in NumPy are not in TensorFlow.", "@ymodak Thanks for the clarification. I had not considered that == is needed for hashing tensors in feed_dict. That thread does suggest some interesting alternatives."]}, {"number": 22393, "title": "ERROR: /home/developer/tensorflow/tensorflow/BUILD:652", "body": ":1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/home/developer/.cache/bazel/_bazel_developer/6acbce31a4e8077fc84a239074e8eda3/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/developer/.cache/bazel/_bazel_developer/6acbce31a4e8077fc84a239074e8eda3/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 70, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/home/developer/.cache/bazel/_bazel_developer/6acbce31a4e8077fc84a239074e8eda3/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py\", line 52, in <module>\r\n    from tensorflow.python.framework.importer import import_graph_def\r\n  File \"/home/developer/.cache/bazel/_bazel_developer/6acbce31a4e8077fc84a239074e8eda3/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 27, in <module>\r\n    from tensorflow.python.framework import function\r\n  File \"/home/developer/.cache/bazel/_bazel_developer/6acbce31a4e8077fc84a239074e8eda3/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/framework/function.py\", line 36, in <module>\r\n    from tensorflow.python.ops import resource_variable_ops\r\n  File \"/home/developer/.cache/bazel/_bazel_developer/6acbce31a4e8077fc84a239074e8eda3/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 38, in <module>\r\n    from tensorflow.python.ops import variables\r\n  File \"/home/developer/.cache/bazel/_bazel_developer/6acbce31a4e8077fc84a239074e8eda3/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py\", line 20, in <module>\r\n    import enum  # pylint: disable=g-bad-import-order\r\nImportError: No module named enum\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1418.730s, Critical Path: 243.25s\r\nINFO: 9922 processes: 9922 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@phalexo Can you please describe the problem clearly.", "Ubuntu 16.04, building TF from source with CUDA, MPI, NCCL 2.2 support. I modified the code with ToString proposed fix (not sure it has been committed into the master yet). So after that error was no more I ran into this build error. I've tried bazel 0.15, 0.16\r\n\r\nINFO: From Compiling external/llvm/lib/Transforms/Scalar/JumpThreading.cpp:\r\nexternal/llvm/lib/Transforms/Scalar/JumpThreading.cpp: In member function 'void llvm::JumpThreadingPass::UpdateBlockFreqAndEdgeWeight(llvm::BasicBlock*, llvm::BasicBlock*, llvm::BasicBlock*, llvm::BasicBlock*)':\r\nexternal/llvm/lib/Transforms/Scalar/JumpThreading.cpp:2165:61: warning: '*((void*)& BBSuccFreq +16)' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n       *std::max_element(BBSuccFreq.begin(), BBSuccFreq.end());\r\n                                                             ^\r\nERROR: /home/developer/tensorflow/tensorflow/BUILD:652:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\n", " bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --verbose_failures //tensorflow/tools/pip_package:build_pip_package\r\n\r\nis the command line that was run.", "INFO: From Compiling tensorflow/compiler/xla/service/cpu/parallel_task_assignment.cc:\r\nIn file included from ./tensorflow/compiler/xla/service/hlo_computation.h:35:0,\r\n                 from ./tensorflow/compiler/xla/service/hlo_cost_analysis.h:21,\r\n                 from ./tensorflow/compiler/xla/service/cpu/parallel_task_assignment.h:20,\r\n                 from tensorflow/compiler/xla/service/cpu/parallel_task_assignment.cc:16:\r\n./tensorflow/compiler/xla/service/hlo_instruction.h: In member function 'void xla::HloInstruction::ReplaceCalledComputations(std::function<xla::HloComputation*(xla::HloComputation*)>)':\r\n./tensorflow/compiler/xla/service/hlo_instruction.h:1119:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int64 i = 0; i < called_computations_.size(); ++i) {\r\n                       ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/gtl/flatmap.h:26,\r\n                 from ./tensorflow/compiler/xla/service/cpu/target_machine_features.h:22,\r\n                 from ./tensorflow/compiler/xla/service/cpu/parallel_task_assignment.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/parallel_task_assignment.cc:16:\r\n./tensorflow/core/platform/default/logging.h: In instantiation of 'std::string* tensorflow::internal::Check_LEImpl(const T1&, const T2&, const char*) [with T1 = long long int; T2 = long unsigned int; std::string = std::basic_string<char>]':\r\n./tensorflow/compiler/xla/shape_util.h:118:5:   required from here\r\n./tensorflow/core/platform/default/logging.h:232:35: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)\r\n./tensorflow/core/platform/macros.h:88:49: note: in definition of macro 'TF_PREDICT_TRUE'\r\n #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))\r\n                                                 ^\r\n./tensorflow/core/platform/default/logging.h:232:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\r\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)\r\n ^\r\nIn file included from ./tensorflow/compiler/xla/array2d.h:29:0,\r\n                 from ./tensorflow/compiler/xla/literal.h:31,\r\n                 from ./tensorflow/compiler/xla/service/dfs_hlo_visitor.h:24,\r\n                 from ./tensorflow/compiler/xla/service/hlo_cost_analysis.h:20,\r\n                 from ./tensorflow/compiler/xla/service/cpu/parallel_task_assignment.h:20,\r\n                 from tensorflow/compiler/xla/service/cpu/parallel_task_assignment.cc:16:\r\n./tensorflow/compiler/xla/array.h: In instantiation of 'bool xla::Array<T>::operator==(const xla::Array<T>&) const [with T = long long int]':\r\n./tensorflow/compiler/xla/service/hlo_sharding.h:189:38:   required from here\r\n./tensorflow/compiler/xla/array.h:421:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int64 i = 0; i < sizes_.size(); ++i) {\r\n                       ~~^~~~~~~~~~~~~~~\r\nERROR: /home/developer/tensorflow/tensorflow/BUILD:652:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1): bash failed: error executing command\r\n  (cd /home/developer/.cache/bazel/_bazel_developer/6acbce31a4e8077fc84a239074e8eda3/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/lib: \\\r\n    PATH=/home/developer/anaconda3/envs/AI/bin:/home/developer/anaconda3/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1 --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/host/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow._api.v1 bazel-out/host/genfiles/tensorflow/_api/v1/__init__.py bazel-out/host/genfiles/tensorflow/_a", "Has the problem been solved? I also encountered this problem, how can I not solve it?", "Same here, Ubuntu 18.04, very latest CUDA, NCCL etc.\r\n\r\nEDIT: Fixed by pointing the tensorflow config at python rather than python3 folder. ", "The failure is right in your logs:\r\n```\r\nImportError: No module named enum\r\n```\r\nIn the failing python distro, you may need to install enum."]}, {"number": 22392, "title": "Fix bug in tf.keras.metrics.sparse_categorical_accuracy", "body": "Fix #22190\r\n\r\nFor the input of ```tf.keras.metrics.sparse_categorical_accuracy```, the shape of ```y_true``` can be ```(num_samples, 1)``` or ```(num_samples,)```, see #22190 for detail. The existing code assume the shape of ```y_true``` is ```(num_samples, 1)```, always reduce in the last dimension which leads the incorrect output. Actually we should check the shape of ```y_true``` and squeeze if applicable.\r\nMeanwhile, I also fix ```sparse_top_k_categorical_accuracy``` which has the same issue.", "comments": ["I think the test failures are non-relevant."]}, {"number": 22391, "title": "Fixed broken links", "body": "", "comments": []}, {"number": 22390, "title": "bazel absence of ZIP64 support cause tensorflow build fail", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1803\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v1.11.0-rc1\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: 0.15.2\r\n- **GCC/Compiler version (if compiling from source)**: vs2017 15.8 / cl.exe 19.15.26726\r\n- **CUDA/cuDNN version**: 9.2.148.1/7.2.1\r\n- **GPU model and memory**: 1080ti 11GB\r\n- **Exact command to reproduce**: \r\n```\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nbazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package C:/tmp/tensorflow_pkg\r\n```\r\n### Describe the problem\r\n\r\nIf build artifact large than 4GB, it can't generate the python package.\r\n\r\nA easy way to reproduce the issue\r\n```\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,7.0]: 3.0,3.2,3.5,5.0,5.2,5.3\r\n```\r\n\r\nrelated link:\r\nhttps://github.com/tensorflow/tensorflow/issues/20332#issuecomment-415974623\r\nhttps://github.com/tensorflow/tensorflow/issues/22382\r\nhttps://github.com/bazelbuild/bazel/blob/0.17.1/third_party/ijar/zip.cc#L74\r\n\r\n### Source code / logs\r\n```\r\nUncompressed input jar has size ???, which exceeds the maximum supported output size 4294967295.\r\nAssuming that ijar will be smaller and hoping for the best.\r\n\r\nUnzipping simple_console_for_windows.zip to create runfiles tree...\r\n[./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip]\r\n  End-of-central-directory signature not found.  Either this file is not\r\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\r\n  latter case the central directory and zipfile comment will be found on\r\n  the last disk(s) of this archive.\r\nunzip:  cannot find zipfile directory in one of ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip or\r\n        ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.zip, and cannot find ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.ZIP, period.\r\n\r\n```\r\n\r\n", "comments": ["@meteorcloudy This is an interesting issue.\r\nwhat would be the correct pacman command to install zip64?", "The zip file is created by a [custom zipper binary](https://github.com/bazelbuild/bazel/blob/0.17.1/third_party/ijar/BUILD#L11) built from source in bazel, which doesn't have zip64 support. So installing zip64 from pacman is not going to help.\r\n\r\nThe root cause here is we are zipping redundant files in `./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip` because it depends on some other py_binary targets which are also built as a zip file. This results a zip file containing many other zip files, and all of them have `//tensorflow:tensorflow_py` as a dependency.\r\n\r\nI'm trying to figure out a way to exclude redundant files.\r\n\r\n", "Probably good to clean up what is going into that zip, but could also try to fix the zipper. Zlib seems to have zip64 support just fine, so maybe there is an issue with the bazel zlib client or something? I don't see any related issues on `bazelbuild`.", "Yes, ideally bazel's zip tool should support zip64. I filed https://github.com/bazelbuild/bazel/issues/6211\r\n\r\nBut I prefer to refactor tensorflow's dependency to clean up the zip file, because it will also improve the performance of creating TF pip package a lot. ", "@fo40225 @bstriner Can you try https://github.com/tensorflow/tensorflow/pull/22483 to see if it fixes the problem?", "@meteorcloudy \r\n\r\nv1.11.0-rc2 +  cherry-pick 2a01b6ad169dc433d002bb61a3a7581cb0662556\r\n\r\nIt can build with most consumer compute capability.\r\n\r\nThank you for help.", "@gunan You might want to cherry-pick #22483 into v1.11.0 ?", "@angersson if we are doing another RC, yes.\r\nIf not, I would wait until 1.12", "Unfortunately, we have to [rollback](https://github.com/tensorflow/tensorflow/commit/9fa8939c4ad08d8783a3336aa28552febd2c08df) a part of 77e2686. If anyone encounter this issue again, please build TensorFlow with `--define=no_tensorflow_py_deps=true`\r\n", "Building the pip package succeeded for me after including the `--define=no_tensorflow_py_deps=true`.\r\n\r\n<details>\r\n  <summary>Error without \"no dependencies\" flag (Click to expand)</summary>\r\n(tf-gpu-src) C:\\Users\\hbeck3\\tf-gpu\\tensorflow>bazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package C:\\Users\\hbeck3\\tf-gpu\\pip-package-cuda10-py3.6.6\r\n\r\nSun Oct 28 13:50:53 WEST 2018 : === Preparing sources in dir: /tmp/tmp.cSTaMzHDFx\r\nUnzipping simple_console_for_windows.zip to create runfiles tree...\r\n[./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip]\r\n  End-of-central-directory signature not found.  Either this file is not\r\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\r\n  latter case the central directory and zipfile comment will be found on\r\n  the last disk(s) of this archive.\r\nunzip:  cannot find zipfile directory in one of ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip or\r\n        ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.zip, and cannot find ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.ZIP, period.\r\n\r\n(tf-gpu-src) C:\\Users\\hbeck3\\tf-gpu\\tensorflow>\r\n</details>\r\n\r\n<details>\r\n  <summary>Success with \"no dependencies\" flag (Click to expand)</summary>\r\n(tf-gpu-src) C:\\Users\\hbeck3\\tf-gpu\\tensorflow>bazel build --define=no_tensorflow_py_deps=true --jobs 1 --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n[...]\r\nINFO: Build completed successfully, 50 total actions\r\n\r\n(tf-gpu-src) C:\\Users\\hbeck3\\tf-gpu\\tensorflow>bazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package C:\\Users\\hbeck3\\tf-gpu\\pip-package-cuda10-py3.6.6\r\n[...]\r\nSun Oct 28 14:53:58 WEST 2018 : === Output wheel file is in: C:\\Users\\hbeck3\\tf-gpu\\pip-package-cuda10-py3.6.6\r\n\r\n(tf-gpu-src) C:\\Users\\hbeck3\\tf-gpu\\tensorflow>\r\n</details>", "@aaniin can you please post your setup as I'm still getting the same error even with `--define=no_tensorflow_py_deps=true`\r\n\r\nThanks!", "Hello @gunan,\r\n\r\nWould it be possible to add the flag recommendation here? https://www.tensorflow.org/install/source_windows\r\n\r\nI believe this would help many people who try to build Tensorflow from source for Windows.\r\n\r\nMy goal was compute capability 3.5 support to have it run faster on my laptop.\r\n\r\nHere is the PR to docs repository: https://github.com/tensorflow/docs/pull/178\r\n\r\nThank you!\r\nAnatoly", "Thank you very much for your PR, it is reviewed, approved and merged!", "having same issue even after including `--define=no_tensorflow_py_deps=true`\r\n\r\nbuild succeeds but following command gives error \r\n` bazel-bin/tensorflow/tools/pip_package/build_pip_package C:/tmp/tensorflow_pkg`\r\n\r\ntried in both msys and cmd\r\n\r\nboth showing same error \r\n```\r\nUnzipping simple_console_for_windows.zip to create runfiles tree...\r\n[./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip]\r\n  End-of-central-directory signature not found.  Either this file is not\r\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\r\n  latter case the central directory and zipfile comment will be found on\r\n  the last disk(s) of this archive.\r\nunzip:  cannot find zipfile directory in one of ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip or\r\n        ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.zip, and cannot find ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.ZIP, period.\r\n```"]}, {"number": 22389, "title": "tensorflow.python.framework.errors_impl.FailedPreconditionError: temp/G2D19_P2OF_ResHB_1LSTM_dataAug_expLR; Not a directory ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\n\r\nYes. I was trying out the code given in https://github.com/JoshuaPiinRueyPan/ViolenceDetection\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nUbuntu 18.04\r\n\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n\r\nNA\r\n\r\n- **TensorFlow (CPU version) installed from (source or binary)**:\r\n\r\nInstalled using pip3 as shown in https://www.python36.com/install-tensorflow-using-official-pip-pacakage/\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\n1.9\r\n\r\n- **Python version**:\r\n\r\n3.6.5\r\n\r\n- Machine details\r\n\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              4\r\nOn-line CPU(s) list: 0-3\r\nThread(s) per core:  2\r\nCore(s) per socket:  2\r\nSocket(s):           1\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               142\r\nModel name:          Intel(R) Core(TM) i7-7600U CPU @ 2.80GHz\r\n\r\n- **Exact command to reproduce**:\r\n\r\n>> python Train.py \r\n\r\nThis is from the code given in https://github.com/JoshuaPiinRueyPan/ViolenceDetection\r\n\r\n### Describe the problem\r\n\r\nThe code contains an LSTM+CNN network and when training with a set of videos, it fails with a tensorflow error. I checked and found that the 'temp/G2D19_P2OF_ResHB_1LSTM_dataAug_expLR' mentioned in the error log is indeed a directory. However Tensorflow complains that it is not and throws an error. I am unable to understand why.\r\n\r\n### Source code / logs\r\n\r\nTraceback (most recent call last):\r\nFile \"Train.py\", line 199, in\r\nmain = Main()\r\nFile \"Train.py\", line 19, in init\r\nself.trainer = Trainer(classifier)\r\nFile \"/home/vandana/Documents/Code/ViolenceDetection-master/src/Trainer.py\", line 36, in init\r\nself._summaryWriter = tf.summary.FileWriter(trainSettings.PATH_TO_SAVE_MODEL+\"/train\")\r\nFile \"/home/vandana/anaconda3/lib/python3.6/site-packages/tensorflow/python/summary/writer/writer.py\", line 366, in init\r\nfilename_suffix)\r\nFile \"/home/vandana/anaconda3/lib/python3.6/site-packages/tensorflow/python/summary/writer/event_file_writer.py\", line 67, in init\r\ngfile.MakeDirs(self._logdir)\r\nFile \"/home/vandana/anaconda3/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\", line 379, in recursive_create_dir\r\npywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)\r\nFile \"/home/vandana/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 519, in exit\r\nc_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: temp/G2D19_P2OF_ResHB_1LSTM_dataAug_expLR; Not a directory\r\nSend Stop singal to Loading threads...\r\nThe Loading threads will Stop in about 100 (s).\r\nSend Stop singal to Loading threads...\r\nThe Loading threads will Stop in about 100 (s).\r\nTrainDataManager.thread.join() successfully.\r\nException ignored in: <bound method Main.del of <main.Main object at 0x7f91467b57f0>>\r\nTraceback (most recent call last):\r\nFile \"Train.py\", line 55, in del\r\nself.session.close()\r\nAttributeError: 'Main' object has no attribute 'session'\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Nagging Assignee @ymodak: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Is this still an issue? Can you try updating your TensorFlow version and check is the issue still persists?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22388, "title": "Added support for half precision type in linear algebra operators", "body": "Fixes #22086 \r\nFollowing changes were made:\r\n- Added float16 support to relevant ops defined in [linalg_ops.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/linalg_ops.cc)\r\n- Added unit tests in [linalg_ops_test.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/linalg_ops_test.cc) for validation of float16 support. \r\n\r\n ", "comments": ["I am new to tensorflow development. So it would be nice if someone can review the code and suggest any edits if any. ", "Patrick, can u take a look? Thanks.", "The clang format check is failing, see https://source.cloud.google.com/results/invocations/70c2c0dc-d4b3-4074-a5c3-415c740c1c22/targets/%2F%2Ftensorflow%2Ftools%2Fci_build:gen_ci_clang_format_out/log\r\n\r\ndiff --git a/tensorflow/core/ops/linalg_ops_test.cc b/tensorflow/core/ops/linalg_ops_test.cc\r\nindex 8bcd271660..52d77991bd 100644\r\n--- a/tensorflow/core/ops/linalg_ops_test.cc\r\n+++ b/tensorflow/core/ops/linalg_ops_test.cc\r\n@@ -84,7 +84,7 @@ TEST(LinalgOpsTest, SelfAdjointEigV2_ShapeFn) {\r\n                      .Input({{\"input\", 0, DT_FLOAT}})\r\n                      .Attr(\"compute_v\", compute_v)\r\n                      .Finalize(&op.node_def));\r\n-    //test for float16\r\n+    // test for float16\r\n     TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Pack\")\r\n                      .Input({{\"input\", 0, DT_HALF}})\r\n                      .Attr(\"compute_v\", compute_v)", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 22387, "title": "Error compiling optional_ops.cc when building from source with MSVC 2017", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Microsoft Windows [Version 10.0.17134.228]\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: trunk\r\n- **Python version**: Python 3.7.0\r\n- **Bazel version (if compiling from source)**: Build label: 0.17.1\r\n- **GCC/Compiler version (if compiling from source)**: Microsoft (R) C/C++ Optimizing Compiler Version 19.15.26729 for x64\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: \r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\nUnable to build from sources with Microsoft Build Tools 2017. Error when compiling **tensorflow/core/kernels/data/optional_ops.cc**\r\n\r\n### Source code / logs\r\n```\r\nC:/Program Files (x86)/Microsoft Visual Studio/2017/Professional/VC/Tools/MSVC/14.15.26726/bin/HostX64/x64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/bazel_tools /Ibazel-out/x64_windows-opt/genfiles/external/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/bazel_tools /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DTF_USE_SNAPPY /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=\"redacted\" -D__TIMESTAMP__=\"redacted\" -D__TIME__=\"redacted\" /Gy /Gw -w /arch:AVX -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/data/_objs/optional_ops/optional_ops.obj /c tensorflow/core/kernels/data/optional_ops.cc\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\VC\\Tools\\MSVC\\14.15.26726\\include\\xmemory(217): error C2678: binary '*': no operator found which takes a left-hand operand of type 'const _Iter' (or there is no acceptable conversion)\r\n        with\r\n        [\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\n.\\tensorflow/core/framework/op_kernel.h(404): note: could be 'const tensorflow::Tensor &tensorflow::OpArgIterator<tensorflow::OpInputList,const tensorflow::Tensor>::operator *(void)'\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\VC\\Tools\\MSVC\\14.15.26726\\include\\xmemory(217): note: while trying to match the argument list '(const _Iter)'\r\n        with\r\n        [\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(1823): note: see reference to function template instantiation '_FwdIt *std::_Uninitialized_copy<_Iter,tensorflow::Tensor*,std::allocator<_Ty>>(const _InIt,const _InIt,_FwdIt,_Alloc &)' being compiled\r\n        with\r\n        [\r\n            _FwdIt=tensorflow::Tensor *,\r\n            _Iter=tensorflow::OpInputList::Iterator,\r\n            _Ty=tensorflow::Tensor,\r\n            _InIt=tensorflow::OpInputList::Iterator,\r\n            _Alloc=std::allocator<tensorflow::Tensor>\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(708): note: see reference to function template instantiation 'tensorflow::Tensor *std::vector<tensorflow::Tensor,std::allocator<_Ty>>::_Ucopy<_Iter>(_Iter,_Iter,tensorflow::Tensor *)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(708): note: see reference to function template instantiation 'tensorflow::Tensor *std::vector<tensorflow::Tensor,std::allocator<_Ty>>::_Ucopy<_Iter>(_Iter,_Iter,tensorflow::Tensor *)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(723): note: see reference to function template instantiation 'void std::vector<tensorflow::Tensor,std::allocator<_Ty>>::_Range_construct_or_tidy<_Iter>(_Iter,_Iter,std::forward_iterator_tag)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(723): note: see reference to function template instantiation 'void std::vector<tensorflow::Tensor,std::allocator<_Ty>>::_Range_construct_or_tidy<_Iter>(_Iter,_Iter,std::forward_iterator_tag)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\ntensorflow/core/kernels/data/optional_ops.cc(112): note: see reference to function template instantiation 'std::vector<tensorflow::Tensor,std::allocator<_Ty>>::vector<tensorflow::OpInputList::Iterator,void>(_Iter,_Iter,const _Alloc &)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator,\r\n            _Alloc=std::allocator<tensorflow::Tensor>\r\n        ]\r\ntensorflow/core/kernels/data/optional_ops.cc(111): note: see reference to function template instantiation 'std::vector<tensorflow::Tensor,std::allocator<_Ty>>::vector<tensorflow::OpInputList::Iterator,void>(_Iter,_Iter,const _Alloc &)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator,\r\n            _Alloc=std::allocator<tensorflow::Tensor>\r\n        ]\r\nexternal/com_google_absl\\absl/container/inlined_vector.h(73): note: see reference to class template instantiation 'std::allocator<T>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::MemoryType\r\n        ]\r\n.\\tensorflow/core/framework/op_kernel.h(176): note: see reference to class template instantiation 'absl::InlinedVector<tensorflow::MemoryType,4,std::allocator<T>>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::MemoryType\r\n        ]\r\nexternal/com_google_absl\\absl/container/inlined_vector.h(73): note: see reference to class template instantiation 'std::allocator<T>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::TensorReference\r\n        ]\r\n.\\tensorflow/core/framework/unique_tensor_references.h(66): note: see reference to class template instantiation 'absl::InlinedVector<tensorflow::TensorReference,4,std::allocator<T>>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::TensorReference\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\VC\\Tools\\MSVC\\14.15.26726\\include\\xmemory(217): error C2100: illegal indirection\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Professional\\VC\\Tools\\MSVC\\14.15.26726\\include\\xmemory(217): error C2062: type 'unknown-type' unexpected\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n```", "comments": ["Found the solution ( hinted by #15925 ). In file **/tensorflow/core/framework/op_kernel.h** \r\nadd **const** at operator* for OpArgIterator class:\r\n\r\n`reference operator*() const { return (*list_)[i_]; }`", "Nagging Assignee @gunan: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Looks like this was resolved?\r\nSorry I missed when it was assigned to me.", "Dear @gunan ,\r\nI experienced the same compilation failure as @lakeofsoft , when trying to compile today's tensorflow master with Visual Studio 2017. Adding the `const` as [described above](https://github.com/tensorflow/tensorflow/issues/22387#issuecomment-422925731) let to successful compilation.\r\nIs adding the const appropriate?\r\n**/tensorflow/core/framework/op_kernel.h**\r\n```reference operator*() const { return (*list_)[i_]; }``` \r\n\r\nBuild error without the const added.\r\n```\r\nERROR: C:/users/hbeck3/tf-gpu/tensorflow/tensorflow/core/kernels/data/BUILD:270:1: C++ compilation of rule '//tensorflow/core/kernels/data:parse_example_dataset_op' failed (Exit 2): msvc_wrapper_for_nvcc.bat failed: error executing command\r\n  cd C:/users/hbeck3/_bazel_hbeck3/gyijrzyg/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\MSBuild\\15.0\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.17763.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\Tools\\;;C:\\windows\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Users/hbeck3/tf-gpu/env/Scripts/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/hbeck3/tf-gpu/env/lib/site-packages\r\n    SET TEMP=C:\\Users\\hbeck3\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=5.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TMP=C:\\Users\\hbeck3\\AppData\\Local\\Temp\r\n  external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.bat /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/bazel_tools /Ibazel-out/x64_windows-opt/genfiles/external/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/bazel_tools /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cuda/include/crt /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include/crt /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include/crt /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w /arch:AVX2 -DGOOGLE_CUDA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -DGOOGLE_CUDA=1 /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/data/_objs/parse_example_dataset_op/parse_example_dataset_op.o /c tensorflow/core/kernels/data/parse_example_dataset_op.cc\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include\\xmemory(217): error C2678: binary '*': no operator found which takes a left-hand operand of type 'const _Iter' (or there is no acceptable conversion)\r\n        with\r\n        [\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\n.\\tensorflow/core/framework/op_kernel.h(405): note: could be 'const tensorflow::Tensor &tensorflow::OpArgIterator<tensorflow::OpInputList,const tensorflow::Tensor>::operator *(void)'\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include\\xmemory(217): note: while trying to match the argument list '(const _Iter)'\r\n        with\r\n        [\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(1823): note: see reference to function template instantiation '_FwdIt *std::_Uninitialized_copy<_Iter,tensorflow::Tensor*,std::allocator<_Ty>>(const _InIt,const _InIt,_FwdIt,_Alloc &)' being compiled\r\n        with\r\n        [\r\n            _FwdIt=tensorflow::Tensor *,\r\n            _Iter=tensorflow::OpInputList::Iterator,\r\n            _Ty=tensorflow::Tensor,\r\n            _InIt=tensorflow::OpInputList::Iterator,\r\n            _Alloc=std::allocator<tensorflow::Tensor>\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(708): note: see reference to function template instantiation 'tensorflow::Tensor *std::vector<tensorflow::Tensor,std::allocator<_Ty>>::_Ucopy<_Iter>(_Iter,_Iter,tensorflow::Tensor *)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(708): note: see reference to function template instantiation 'tensorflow::Tensor *std::vector<tensorflow::Tensor,std::allocator<_Ty>>::_Ucopy<_Iter>(_Iter,_Iter,tensorflow::Tensor *)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(723): note: see reference to function template instantiation 'void std::vector<tensorflow::Tensor,std::allocator<_Ty>>::_Range_construct_or_tidy<_Iter>(_Iter,_Iter,std::forward_iterator_tag)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include\\vector(723): note: see reference to function template instantiation 'void std::vector<tensorflow::Tensor,std::allocator<_Ty>>::_Range_construct_or_tidy<_Iter>(_Iter,_Iter,std::forward_iterator_tag)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator\r\n        ]\r\ntensorflow/core/kernels/data/parse_example_dataset_op.cc(91): note: see reference to function template instantiation 'std::vector<tensorflow::Tensor,std::allocator<_Ty>>::vector<tensorflow::OpInputList::Iterator,void>(_Iter,_Iter,const _Alloc &)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator,\r\n            _Alloc=std::allocator<tensorflow::Tensor>\r\n        ]\r\ntensorflow/core/kernels/data/parse_example_dataset_op.cc(90): note: see reference to function template instantiation 'std::vector<tensorflow::Tensor,std::allocator<_Ty>>::vector<tensorflow::OpInputList::Iterator,void>(_Iter,_Iter,const _Alloc &)' being compiled\r\n        with\r\n        [\r\n            _Ty=tensorflow::Tensor,\r\n            _Iter=tensorflow::OpInputList::Iterator,\r\n            _Alloc=std::allocator<tensorflow::Tensor>\r\n        ]\r\nexternal/com_google_absl\\absl/container/inlined_vector.h(73): note: see reference to class template instantiation 'std::allocator<_Ty>' being compiled\r\n        with\r\n        [\r\n            _Ty=Eigen::DenseIndex\r\n        ]\r\n.\\tensorflow/core/util/tensor_format.h(451): note: see reference to class template instantiation 'absl::InlinedVector<tensorflow::int64,4,std::allocator<_Ty>>' being compiled\r\n        with\r\n        [\r\n            _Ty=Eigen::DenseIndex\r\n        ]\r\nexternal/com_google_absl\\absl/container/inlined_vector.h(73): note: see reference to class template instantiation 'std::allocator<T>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::MemoryType\r\n        ]\r\n.\\tensorflow/core/framework/op_kernel.h(177): note: see reference to class template instantiation 'absl::InlinedVector<tensorflow::MemoryType,4,std::allocator<T>>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::MemoryType\r\n        ]\r\nexternal/com_google_absl\\absl/container/inlined_vector.h(73): note: see reference to class template instantiation 'std::allocator<T>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::TensorReference\r\n        ]\r\n.\\tensorflow/core/framework/unique_tensor_references.h(66): note: see reference to class template instantiation 'absl::InlinedVector<tensorflow::TensorReference,4,std::allocator<T>>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::TensorReference\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include\\xmemory(217): error C2100: illegal indirection\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.15.26726\\include\\xmemory(217): error C2062: type 'unknown-type' unexpected\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 636,778s, Critical Path: 251,57s\r\nINFO: 783 processes: 783 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "Thank you! It works with the solution.", "Does the fix go to 1.12.1? (it's on the master)", "Still present in 1.13.0-rc2...\r\nhttps://github.com/tensorflow/tensorflow/commit/ec727016282383aacf9d26386b01f6bdbd65b14b"]}, {"number": 22386, "title": "Expand stateless random generators to match their stateful cousins", "body": "`stateless_random_uniform` now takes `minval+maxval` and handles ints, and `stateless_normal/stateless_truncated_normal` take `mean+stddev`.  Additionally, all of the stateless functions now have proper doc strings.\r\n\r\nThis is step one of moving stateless random numbers out of contrib.\r\n\r\nI've only tested this on my laptop, which means only on CPU, so some test iteration may be required.", "comments": ["tensorflow/core/api_def/api_test.cc:201: Failure\n2429\nValue of: api_defs_map_.find(op.name()) != api_defs_map_.end()\n2430\nActual: false\n2431\nExpected: true\n2432\nStatelessRandomUniformInt op does not have api_def_*.pbtxt file. Please add\napi_def_StatelessRandomUniformInt.pbtxt file under\ntensorflow/core/api_def/base_api/ directory.\n2433\n\n\n\nyou will need to move your .Doc() op docstrings into a pbtxt\n\nOn Wed, Sep 19, 2018 at 9:39 AM, Geoffrey Irving <notifications@github.com>\nwrote:\n\n> stateless_random_uniform now take minval+maxval and handles ints,\n> and stateless_normal/stateless_truncated_normal take mean+stddev.\n> Additionally, all of the stateless functions now have proper doc\n> strings.\n>\n> This is step one of moving stateless random numbers out of contrib.\n>\n> I've only tested this on my laptop, which means only on CPU, so some test\n> iteration may be required.\n> ------------------------------\n> You can view, comment on, or merge this pull request online at:\n>\n>   https://github.com/tensorflow/tensorflow/pull/22386\n> Commit Summary\n>\n>    - Expand stateless random generators to match their stateful cousins\n>\n> File Changes\n>\n>    - *M* tensorflow/contrib/stateless/BUILD\n>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-0> (2)\n>    - *M* tensorflow/contrib/stateless/__init__.py\n>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-1> (8)\n>    - *M* tensorflow/contrib/stateless/python/kernel_tests/stateless_\n>    random_ops_test.py\n>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-2>\n>    (154)\n>    - *A* tensorflow/contrib/stateless/python/stateless_ops.py\n>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-3>\n>    (214)\n>    - *M* tensorflow/core/kernels/random_op.cc\n>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-4>\n>    (34)\n>    - *M* tensorflow/core/kernels/stateless_random_ops.cc\n>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-5>\n>    (119)\n>    - *M* tensorflow/core/ops/stateless_random_ops.cc\n>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-6>\n>    (53)\n>\n> Patch Links:\n>\n>    - https://github.com/tensorflow/tensorflow/pull/22386.patch\n>    - https://github.com/tensorflow/tensorflow/pull/22386.diff\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/22386>, or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim1aG96yB5SHgVQm585JDpJ6bYIlcks5ucnM6gaJpZM4Wwi4b>\n> .\n>\n", "(may also need to update XLA kernels since i believe some of those\nimplement the stateless ops)\n\nOn Wed, Sep 19, 2018 at 9:47 AM, Eugene Brevdo <ebrevdo@google.com> wrote:\n\n> tensorflow/core/api_def/api_test.cc:201: Failure\n> 2429\n> Value of: api_defs_map_.find(op.name()) != api_defs_map_.end()\n> 2430\n> Actual: false\n> 2431\n> Expected: true\n> 2432\n> StatelessRandomUniformInt op does not have api_def_*.pbtxt file. Please\n> add api_def_StatelessRandomUniformInt.pbtxt file under\n> tensorflow/core/api_def/base_api/ directory.\n> 2433\n>\n>\n>\n> you will need to move your .Doc() op docstrings into a pbtxt\n>\n> On Wed, Sep 19, 2018 at 9:39 AM, Geoffrey Irving <notifications@github.com\n> > wrote:\n>\n>> stateless_random_uniform now take minval+maxval and handles ints,\n>> and stateless_normal/stateless_truncated_normal take mean+stddev.\n>> Additionally, all of the stateless functions now have proper doc\n>> strings.\n>>\n>> This is step one of moving stateless random numbers out of contrib.\n>>\n>> I've only tested this on my laptop, which means only on CPU, so some test\n>> iteration may be required.\n>> ------------------------------\n>> You can view, comment on, or merge this pull request online at:\n>>\n>>   https://github.com/tensorflow/tensorflow/pull/22386\n>> Commit Summary\n>>\n>>    - Expand stateless random generators to match their stateful cousins\n>>\n>> File Changes\n>>\n>>    - *M* tensorflow/contrib/stateless/BUILD\n>>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-0>\n>>    (2)\n>>    - *M* tensorflow/contrib/stateless/__init__.py\n>>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-1>\n>>    (8)\n>>    - *M* tensorflow/contrib/stateless/python/kernel_tests/stateless_r\n>>    andom_ops_test.py\n>>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-2>\n>>    (154)\n>>    - *A* tensorflow/contrib/stateless/python/stateless_ops.py\n>>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-3>\n>>    (214)\n>>    - *M* tensorflow/core/kernels/random_op.cc\n>>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-4>\n>>    (34)\n>>    - *M* tensorflow/core/kernels/stateless_random_ops.cc\n>>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-5>\n>>    (119)\n>>    - *M* tensorflow/core/ops/stateless_random_ops.cc\n>>    <https://github.com/tensorflow/tensorflow/pull/22386/files#diff-6>\n>>    (53)\n>>\n>> Patch Links:\n>>\n>>    - https://github.com/tensorflow/tensorflow/pull/22386.patch\n>>    - https://github.com/tensorflow/tensorflow/pull/22386.diff\n>>\n>> \u2014\n>> You are receiving this because your review was requested.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/pull/22386>, or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/ABtim1aG96yB5SHgVQm585JDpJ6bYIlcks5ucnM6gaJpZM4Wwi4b>\n>> .\n>>\n>\n>\n", "First I need to somehow install `clang-tidy` to fix the code formatting without extremely painful round trip times, but unfortunately https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md only has installation instructions for Ubuntu.", "@ebrevdo The only XLA change would be for random uniform ints: the other kernels didn't change.", "Up to you.  If you move to python/ops, then for now add aliases in contrib/\n(we'll have to clean up internally later)\n\nOn Wed, Sep 19, 2018 at 10:03 AM, Geoffrey Irving <notifications@github.com>\nwrote:\n\n> *@girving* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/contrib/stateless/python/stateless_ops.py\n> <https://github.com/tensorflow/tensorflow/pull/22386#discussion_r218885535>\n> :\n>\n> > @@ -0,0 +1,214 @@\n> +# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n>\n> Date fixed, but it seems cleaner to have one commit that rewrites\n> tf.contrib.stateless and another that moves it out of contrib. Would you\n> prefer I do it all at once? Also, whenever I move it: should I leave\n> tf.contrib.stateless around or delete it entirely?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/22386#discussion_r218885535>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim9N35H3aRl2ud2jb_8qYRevje9S6ks5ucnj2gaJpZM4Wwi4b>\n> .\n>\n", "@ebrevdo How do I make that pbtxt?  I tried `core/api_def/update_api_def.sh`, but all it made was\r\n\r\n```\r\nop {\r\n  graph_op_name: \"StatelessRandomUniformInt\"\r\n}\r\n```", "It's annoying. Find another, copy it, replace the doc field.\n\nOn Wed, Sep 19, 2018, 10:58 AM Geoffrey Irving <notifications@github.com>\nwrote:\n\n> @ebrevdo <https://github.com/ebrevdo> How do I make that pbtxt? I tried\n> core/api_def/update_api_def.sh, but all it made was\n>\n> op {\n>   graph_op_name: \"StatelessRandomUniformInt\"\n> }\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/22386#issuecomment-422899320>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimwaM4gkp2nzkC7GU04snhvE3aZWFks5ucoW_gaJpZM4Wwi4b>\n> .\n>\n", "What's the status of this PR?  Are you blocked on anything?  Let us know if we can do anything to help.", "Sorry for the delay, @ebrevdo.  I'm not blocked, I've just been busy working around other unrelated TensorFlow bugs.", "Cc @prazek, since you have a Grappler TODO related to this PR.", "Yep, @mrry have already told me about it. Definitely useful!", "@hawkinsp: If I were to add XLA support for stateless random uniform ints, what's the right set of types?  Also: should I extend the existing float XLA ops to do `bfloat16`?\r\n\r\n**Edit:** Unless it's important I'll probably skip doing the XLA updates in this PR.", "In a perfect world, when a build failed I'd click some sort of link and see the error message for the failing test.  As it is, I have no idea what's going wrong: the links either say \"FAILED\" with no information or include a huge wall of text none of which seems related to the tests which failed.  I expect some but not all of it is my fault (locally I see a few tests fail which definitely aren't my fault).  @ebrevdo: Could I get some help?\r\n\r\nGiving up for the night, and based on recent history that may mean giving up for a week or two.", "@girving re: \"If I were to add XLA support for stateless random uniform ints, what's the right set of types? Also: should I extend the existing float XLA ops to do bfloat16?\"\r\n\r\nIn general, the TF -> XLA \"kernels\" are written to be as type-generic as possible. These ops (since they do bit manipulations) are some of the few exceptions that actually require some amount of type-specific code.\r\n\r\nIn general, the right thing to do would be to implement them at all types where they make sense; if some backend does not support a particular type then that case will simply not be triggered by that backend. Unlike the TF core kernels, since the TF/XLA kernels are doing JIT compilation, typically you still have a single \"kernel\" for all types, with a switch statement choosing between different implementations. So it's just a question of which cases you stick in that switch statement.\r\n\r\nYes, it makes perfect sense to implement bfloat16 \u2014 I implemented only float32 out of expediency, not because there's any reason the ops don't make sense for other types. I'm happy to give further pointers or review a follow-up PR implementing the XLA variants of these ops.", "Your inability to see the logs is a dev bug.   We can't see some of the\nlogs either.  We're working on it.\n\nOn Fri, Sep 28, 2018, 9:55 PM Geoffrey Irving <notifications@github.com>\nwrote:\n\n> In a perfect world, when a build failed I'd click some sort of link and\n> see the error message for the failing test. As it is: I have no idea what's\n> going wrong. I expect some but not all of it is my fault (locally I see a\n> few tests fail which definitely aren't my fault). @ebrevdo\n> <https://github.com/ebrevdo>: Could I get some help?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/22386#issuecomment-425615932>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim3RAQshL3MC3P8Px5qi3UnnFiqkfks5ufv0ogaJpZM4Wwi4b>\n> .\n>\n", "@ebrevdo Any progress?  It looks like the PR is already degrading (now there is a conflict).  It may be that the only practical way to make this change is for someone inside Google to take it over.", "+Gunhan Gulsoy <gunan@google.com> looks like a config change is required on\nour end?\n\nOn Thu, Oct 4, 2018, 8:53 AM Geoffrey Irving <notifications@github.com>\nwrote:\n\n> @ebrevdo <https://github.com/ebrevdo> Any progress? It looks like the PR\n> is already degrading (now there is a conflict).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/22386#issuecomment-427070800>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimyKKekQEfRHbbcx5rvvV9v_sGXnvks5uhi73gaJpZM4Wwi4b>\n> .\n>\n", "@martinwicke It can't be ready to pull yet: there's a conflict and possibly a variety of failing unit tests.  The problem is that last time I tried to fix unit tests they failed but didn't say why.", "@gunan FYI (@ebrevdo not sure your way of mention worked)\r\n\r\n@girving can you look into the conflict? it sounds like there's already something in ops?", "Conflict was pretty mild; should be fixed.  I haven't tested it locally, though, since it would take 30-40 minutes to build.  We'll see what happens with the automated tests.", "Whoops, looks like I handled the conflict incorrectly.  Fixing.", "Plausible that the API compatibility failure is my fault, but I don't know what to do if so.  I vaguely recall the api update script only working on Python 2, in which case I can't fix it myself.", "It works in py3 now. Alternatively, you can apply the diff output by the test yourself.", "Running the test with `update_goldens` has no affect for me.", "Ah. But it does have to be run on Linux, I think.", "@annarev I felt like I had seen a \"good\" diff somewhere, but maybe it was another test... this one isn't really usable (https://source.cloud.google.com/results/invocations/353a913c-d878-4b40-a94a-ea26dcb5e245/targets/%2F%2Ftensorflow%2Ftools%2Fapi%2Ftests:api_compatibility_test/log)\r\n\r\n", "@martinwicke I fixed the diff getting truncated earlier by adding self.maxDiff = None and didn't realize it is still all getting printed on one line. I will take a look.", "@annarev Let me know if you figure anything out.  I'm blocked until then.\r\n\r\n@martinwicke Why does it depend on Linux?  Is that fixable?", "Let's see if it's a fluke; rerunning tests.", "Let's get this in and we'll fix it on our end.", "@girving So far it seems like output is not split into new lines if it is very large (roughly over ~65000 characters it seems). I will look at splitting output by newlines in our code.\r\n\r\nFor now, you can try running api_compatibility_test with --update_goldens and then look at the golden file diffs. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/api/tests/README.txt", "@annarev the golden file diffs are probably OK on his machine but break on ubuntu python2.  so we'll have to test it ourselves w/ a vm.", "Thank you for letting me know Eugene. I didn't read that previous message and didn't realize --update_goldens=True doesn't work either. I thought only error printing is messed up.\r\n\r\nAlso, I am still working on fixing the error message. But for now I patched this change and ran api_compatibility_test. The change I see is:\r\n```\r\nmember_method {\r\n    name: \"stateless_random_uniform_int\"\r\n    argspec: \"args=[\\'shape\\', \\'seed\\', \\'minval\\', \\'maxval\\', \\'name\\'], varargs=None, keywords=None, defaults=[\\'None\\'], \"\r\n}\r\n```\r\nThis is added right before \"stop_gradient\" member_method here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/api/golden/v1/tensorflow.pbtxt#L2059\r\n\r\nThe same change also needs to be made to tensorflow/tools/api/golden/v2/tensorflow.pbtxt file.\r\n\r\n@girving does api_compatibility_test pass for you locally or does it fail for you but doesn't update the goldens?", "@annarev It passes for me.  Not sure why, since `stateless_random_uniform_int` does not show up anywhere in TensorFlow except where I call it (i.e., not the api compatibility files).", "That api update script needs to run to add it to the pbtxt.  It reads from\ntf_export decorated functions.  We'll do it internally.\n\nOn Fri, Oct 5, 2018 at 2:22 PM, Geoffrey Irving <notifications@github.com>\nwrote:\n\n> @annarev <https://github.com/annarev> It passes for me. Not sure why,\n> since stateless_random_uniform_int does not show up anywhere in\n> TensorFlow except where I call it (i.e., not the api compatibility files).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/22386#issuecomment-427502308>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim1ASTNw8sCJqqvaOmk4K_Hhr-hLtks5uh82rgaJpZM4Wwi4b>\n> .\n>\n", "@girving `stateless_random_uniform_int` is added to API because in tensorflow/core/api_def/base_api/api_def_StatelessRandomUniformInt.pbtxt `visibility` is `VISIBLE` by default. If you want to hide it from API, you can set it to `HIDDEN`. https://github.com/tensorflow/tensorflow/blob/31e9d08398a2118537abc1a02f47376c4d2c7d9d/tensorflow/core/framework/api_def.proto#L51\r\n\r\nAnyhow, this sounds like a bug in api_compatibility_test if the test is passing. I will try to reproduce it.", "@annarev Ah, perfect.  That should definitely be hidden.  Will fix and push; hopefully that resolves it.", "Looks like only Windows Bazel fails now.  I can't see the output for those; are they problematic?", "Nobody can see them. They're very secret. Kokoro looked at them and got so scared, it's not showing them to anyone. One copy was printed out and put in a safe, and you can make a one hour appointment to look at it.\r\n\r\nIt's a bug. I'm going to assume it's ok, and attempt to pull this in. If we see a failure in that process, we'll report it back.", "Only one senator at a time gets to look in the safe?", "In this case, noone got to look into the safe at all, we completely broke it temporarily. Retriggering tests.", "Thanks all!"]}, {"number": 22385, "title": "session = tf.Session()", "body": "Can someone please tell me how to solve this. Though I'm able to run forward in tf.\r\n\r\n```\r\nsession = tf.Session()\r\n\r\n2018-09-19 21:16:27.452934: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-19 21:16:27.547097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-09-19 21:16:27.547742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \r\nname: GeForce 920M major: 3 minor: 5 memoryClockRate(GHz): 0.954\r\npciBusID: 0000:08:00.0\r\ntotalMemory: 3.95GiB freeMemory: 3.70GiB\r\n2018-09-19 21:16:27.547773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-09-19 21:16:27.838759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-19 21:16:27.838808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \r\n2018-09-19 21:16:27.838817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \r\n2018-09-19 21:16:27.839009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3439 MB memory) -> physical GPU (device: 0, name: GeForce 920M, pci bus id: 0000:08:00.0, compute capability: 3.5)\r\n\r\n```", "comments": ["@dhananjaisharma10 tf.Session provides you with a list of devices that are available. These are warning messages for your current session and not fatal error's therefore you can proceed further.\r\nIf you want to disable these warnings you can try:\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'", "I get your point, @ymodak. But this means that there is an aberrant behaviour in my system, as otherwise, I wouldn't have received these messages. Anyway, I wrote `export TF_CPP_MIN_LOG_LEVEL=2` in my .bashrc and now I'm not getting those messages. But do let me know if there's something that needs to be done to eradicate those warnings. Thanks!", "@dhananjaisharma10 The warning messages tell you that the binaries that were used to install TensorFlow were not optimized for your system architecture. This is almost for every case where we use pre-built binaries for installation. However they can be optimized if you [install TensorFlow from source](https://www.tensorflow.org/install/install_sources). This will eradicate those warning messages.", "@dhananjaisharma10 : You mentioned \" Though I'm able to run forward in tf.\", but I'm not clear on what the issue is.\r\n\r\nThose messages are just informative messages printed to stderr and as @ymodak pointed out, they can be disabled. But regardless, they are just informative messages that shouldn't affect your subsequent use of TensorFlow.\r\n\r\nPlease reopen if I'm mistaken.", "@ymodak @asimshankar, Thank you so much!!"]}, {"number": 22384, "title": "BUG: reciprocal GPU kernel for complex 1/1 division not found", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.2/7.2.1\r\n- **GPU model and memory**: GeForce GTX 1050 mobile, 4096MiB\r\n- **Exact command to reproduce**:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# create a lot of points\r\n# CHANGE NUMBER BELOW (higher -> fails)\r\nn_points = 670000  # fails around > 650'000 (e.g. 1'000'000) for np.linspace generation\r\n\r\n\r\n# points creation\r\npoints = np.ones(n_points)\r\n# alternate points creation\r\n# low = 100.  # irrelevant, only > 0 -> no 0 (division)\r\n# high = 200.  # irrelevant\r\n# points = tf.random_uniform(shape=[n_points], minval=low, maxval=high)\r\n# points = np.linspace(low, high, n_points)\r\n\r\nwith tf.Session() as sess:\r\n    # just do complex division: 1.0+0j / points\r\n    complex_1_0 = tf.cast(1., dtype=tf.complex128)\r\n    denom = tf.cast(points, dtype=tf.complex128)\r\n    division = complex_1_0 / denom\r\n    result = sess.run(division)\r\n    print(result)\r\n```\r\n\r\n### Describe the problem\r\nFor a certain amount of points, the complex division kernel (or rather reciprocal kernel) \"seems to not be available on the GPU\".\r\n**It works for**\r\n- a lower number of points\r\n- for floats\r\n- on CPU (tested with \"tf.devices\")\r\n\r\n**It seems to be independent of**\r\n- the generation of the points (see commented lines for alternate creation)\r\n- GPU (also tested on Tesla K80) with lower TF/Cuda version\r\n\r\nNo idea where to start...\r\n\r\n### Source code / logs\r\nrelevant error:\r\nNotFoundError (see above for traceback): No registered 'Reciprocal' OpKernel for GPU devices compatible with node truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\t [[Node: truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)]]\r\n\r\nFull stacktrace of failure: \r\n2018-09-19 17:18:40.965160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3010 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-09-19 17:18:41.104747: E tensorflow/core/common_runtime/executor.cc:697] Executor failed to create kernel. Not found: No registered 'Reciprocal' OpKernel for GPU devices compatible with node truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\t [[Node: truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)]]\r\nTraceback (most recent call last):\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\r\n    return fn(*args)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Reciprocal' OpKernel for GPU devices compatible with node truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\t [[Node: truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)]]\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-0ba75500be23>\", line 1, in <module>\r\n    runfile('/home/jonas/Documents/uni/Master_thesis/code/test/tf_playground/test/gpu_div_bug.py', wdir='/home/jonas/Documents/uni/Master_thesis/code/test/tf_playground/test')\r\n  File \"/usr/share/pycharm/helpers/pydev/_pydev_bundle/pydev_umd.py\", line 197, in runfile\r\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\r\n  File \"/usr/share/pycharm/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/home/jonas/Documents/uni/Master_thesis/code/test/tf_playground/test/gpu_div_bug.py\", line 20, in <module>\r\n    result = sess.run(division)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n    run_metadata_ptr)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n    run_metadata)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'Reciprocal' OpKernel for GPU devices compatible with node truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\t [[Node: truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)]]\r\nCaused by op 'truediv', defined at:\r\n  File \"/usr/share/pycharm/helpers/pydev/pydevconsole.py\", line 511, in <module>\r\n    pydevconsole.start_server(host, int(port), int(client_port), client_host)\r\n  File \"/usr/share/pycharm/helpers/pydev/pydevconsole.py\", line 336, in start_server\r\n    process_exec_queue(interpreter)\r\n  File \"/usr/share/pycharm/helpers/pydev/pydevconsole.py\", line 192, in process_exec_queue\r\n    more = interpreter.add_exec(code_fragment)\r\n  File \"/usr/share/pycharm/helpers/pydev/_pydev_bundle/pydev_console_utils.py\", line 281, in add_exec\r\n    more = self.do_add_exec(code_fragment)\r\n  File \"/usr/share/pycharm/helpers/pydev/_pydev_bundle/pydev_ipython_console.py\", line 41, in do_add_exec\r\n    res = bool(self.interpreter.add_exec(code_fragment.text))\r\n  File \"/usr/share/pycharm/helpers/pydev/_pydev_bundle/pydev_ipython_console_011.py\", line 442, in add_exec\r\n    self.ipython.run_cell(line, store_history=True)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2907, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-0ba75500be23>\", line 1, in <module>\r\n    runfile('/home/jonas/Documents/uni/Master_thesis/code/test/tf_playground/test/gpu_div_bug.py', wdir='/home/jonas/Documents/uni/Master_thesis/code/test/tf_playground/test')\r\n  File \"/usr/share/pycharm/helpers/pydev/_pydev_bundle/pydev_umd.py\", line 197, in runfile\r\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\r\n  File \"/usr/share/pycharm/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/home/jonas/Documents/uni/Master_thesis/code/test/tf_playground/test/gpu_div_bug.py\", line 19, in <module>\r\n    division = complex_1_0 / denom\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 850, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 958, in _truediv_python3\r\n    return gen_math_ops.real_div(x, y, name=name)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 5881, in real_div\r\n    \"RealDiv\", x=x, y=y, name=name)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\r\n    op_def=op_def)\r\n  File \"/home/jonas/anaconda3/envs/zfit36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\nNotFoundError (see above for traceback): No registered 'Reciprocal' OpKernel for GPU devices compatible with node truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\t [[Node: truediv = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)]]\r\n", "comments": ["@mayou36 The fix has been pushed. #22420 Can you please confirm it?", "It looks like a fix to me, I am however not able to build a pip package from the branch currently (from master works) on the linux machine, so can't fully confirm either. But thanks anyway! I'll try again once the GNU problem is fixed.", "Cool. Please feel free to reopen the issue if it still persists and post your findings.", "I am also impacted by this bug. Since the pull request was not accepted, this issue is still active and should be reopened.", "@ymodak this issue still persists in 1.12 (binary) and the corresponding PR #22420 has been closed and the branch deleted. Seems also that I am not the only one affected. Can we reopen this? ", "@yongtang Do you have any updates on the PR #22420? Thanks!", "@azaks2 any updates here? I just stumbled in a completely different problem again on it (am I the only one doing complex divisions? :) )\r\n\r\nFor completeness the slighlty changed error message (from the example code above) which now incorporates the XLAs:\r\n\r\n```python\r\nNotFoundError (see above for traceback): No registered 'Reciprocal' OpKernel for GPU devices compatible with node node truediv (defined at <ipython-input-2-fde784715ebe>:18)  = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BFLOAT16, DT_HALF]\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_HALF]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_HALF]\r\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BFLOAT16, DT_HALF]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\r\n\t [[node truediv (defined at <ipython-input-2-fde784715ebe>:18)  = Reciprocal[T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast_1)]]\r\n\r\n```", "I encountered this bug on a much smaller scale -- trying to do division on a single complex number.\r\n\r\nI did this in a Colab notebook running Python 3, running the op on a GPU. On a CPU, no error is thrown.\r\n\r\n```\r\nx = tf.random.uniform(shape=())  # change to tf.constant(1.0) and error disappears\r\ncx_x = tf.cast(x, dtype=tf.complex128)\r\n\r\nnumerator = 1  # change to 1.1 (error disappears) or 1.0 (throws same error)\r\n\r\nwith tf.Session() as sess:\r\n  sess.run(numerator/cx_x)\r\n```\r\n\r\nHere's the error message:\r\n\r\n> ---------------------------------------------------------------------------\r\n> NotFoundError                             Traceback (most recent call last)\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n>    1333     try:\r\n> -> 1334       return fn(*args)\r\n>    1335     except errors.OpError as e:\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n>    1318       return self._call_tf_sessionrun(\r\n> -> 1319           options, feed_dict, fetch_list, target_list, run_metadata)\r\n>    1320 \r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n>    1406         self._session, options, feed_dict, fetch_list, target_list,\r\n> -> 1407         run_metadata)\r\n>    1408 \r\n> \r\n> NotFoundError: No registered 'Reciprocal' OpKernel for GPU devices compatible with node {{node truediv_5}}\r\n> \t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_COMPLEX128, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"\r\n> \t.  Registered:  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BFLOAT16, DT_HALF]\r\n>   device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_HALF]\r\n>   device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_HALF]\r\n>   device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BFLOAT16, DT_HALF]\r\n>   device='GPU'; T in [DT_INT64]\r\n>   device='GPU'; T in [DT_DOUBLE]\r\n>   device='GPU'; T in [DT_HALF]\r\n>   device='GPU'; T in [DT_FLOAT]\r\n>   device='CPU'; T in [DT_COMPLEX128]\r\n>   device='CPU'; T in [DT_COMPLEX64]\r\n>   device='CPU'; T in [DT_DOUBLE]\r\n>   device='CPU'; T in [DT_HALF]\r\n>   device='CPU'; T in [DT_FLOAT]\r\n> \r\n> \t [[{{node truediv_5}}]]", "@mayou36 , This issue has been fixed in the recent Tensorflow GPU version 2.4.1, please find the [gist](https://colab.research.google.com/gist/sachinprasadhs/ab5150a0978cff62b3aff5dffc9029dd/22384.ipynb) here.", "Good to hear, many thanks for resolving this!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22384\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22384\">No</a>\n"]}, {"number": 22383, "title": "Inconsistency in tf.nn.top_k when using sorted=False and tf.float32 tensor and GPU placement", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA.\r\n- **TensorFlow installed from (source or binary)**: Binary.\r\n- **TensorFlow version (use command below)**: 'v1.10.1-0-g4dcfddc5d1', '1.10.1'\r\n- **Python version**: Python 3.6.5 :: Anaconda, Inc.\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: CUDAToolkit 9.0, CuDNN 7.1.4\r\n- **GPU model and memory**: NVIDIA Quadro P4000, 8GB (driver version 396.37)\r\n- **Exact command to reproduce**: See source code below.\r\n\r\n### Describe the problem\r\nThe indices and values returned by top_k(sorted=False) seem to be shuffled with respect to each other when tf.float32 tensors are used, but not when tf.int32 tensors are used. I understand that we can not expect the values to be returned in ascending/descending order since we've set sorted=False, but shouldn't the values and indices at least be consistently ordered with respect to each other? Hope this makes sense. See my minimum working example below.\r\n\r\nEdit: This seems to be a GPU-only problem.\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.set_random_seed(21)\r\n\r\ndef demo_bug(np_dtype, tf_dtype):\r\n    np_arr = np.array([3, 2, 8, 1], np_dtype)\r\n    arr = tf.convert_to_tensor(np_arr, tf_dtype)\r\n    top_k = tf.nn.top_k(arr, k=3, sorted=False)\r\n\r\n    with tf.Session() as sess:\r\n        vals, inds = sess.run(top_k)\r\n\r\n    print('dtype:   ', tf_dtype.__repr__())\r\n    print('arr:     ', np_arr)\r\n    print('inds:    ', inds)\r\n    print('tf_vals: ', vals)\r\n    print('np_vals: ', np_arr[inds])\r\n\r\ndemo_bug(np.int32, tf.int32)\r\ndemo_bug(np.float32, tf.float32)\r\n\r\n>> dtype:    tf.int32\r\n>> arr:      [3 2 8 1]\r\n>> inds:     [2 0 1]\r\n>> tf_vals:  [8 3 2]\r\n>> np_vals:  [8 3 2]\r\n\r\n>> dtype:    tf.float32\r\n>> arr:      [3. 2. 8. 1.]\r\n>> inds:     [2 0 1]\r\n>> tf_vals:  [2. 3. 8.]\r\n>> np_vals:  [8. 3. 2.]\r\n```", "comments": ["@jhultman Hi, I've executed your code and I get the values and indices in a consistent order. Please find the result below.\r\n\r\n('dtype:   ', 'tf.int32')\r\n('arr:     ', array([3, 2, 8, 1], dtype=int32))\r\n('inds:    ', array([1, 0, 2], dtype=int32))\r\n('tf_vals: ', array([2, 3, 8], dtype=int32))\r\n('np_vals: ', array([2, 3, 8], dtype=int32))\r\n('dtype:   ', 'tf.float32')\r\n('arr:     ', array([3., 2., 8., 1.], dtype=float32))\r\n('inds:    ', array([1, 0, 2], dtype=int32))\r\n('tf_vals: ', array([2., 3., 8.], dtype=float32))\r\n('np_vals: ', array([2., 3., 8.], dtype=float32))", "I just tried it again in a different virtualenv installed from source (not pip package) with tf.__version__ == 1.9.0 and I was able to reproduce the bug. My colleague was not able to reproduce the bug (on CPU) despite being on 16.04 with tf v1.10.1 latest pip package.\r\n\r\nI also tried again in my environment with a different test case and got the same problem:\r\n\r\n```\r\ndtype:    tf.float32\r\narr:      [3. 2. 8. 6.]\r\ninds:     [2 3 0]\r\ntf_vals:  [3. 6. 8.]\r\nnp_vals:  [8. 6. 3.]\r\n```", "@jhultman Okay. The issue is with tensorflow v 1.9. Please use tensorflow v 1.10 for this op.", "@harshini-gadige Sorry, I think maybe I didn't explain well. I am able to reproduce the bug in _both_ v 1.9.0 and v 1.10.1. (But I have not yet been able to reproduce on another machine.)", "I tried with different device placements and it seems like a GPU-only bug for tf.float32 tensors. Maybe someone else can try with GPU placement and see if they can reproduce the bug. See my updated dummy example below.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport itertools\r\ntf.set_random_seed(21)\r\n\r\ndef demo_bug(np_dtype, tf_dtype, device):\r\n    np_arr = np.array([3, 2, 8, 1], np_dtype)\r\n    arr = tf.convert_to_tensor(np_arr, tf_dtype)\r\n    \r\n    with tf.device(device):\r\n        top_vals, top_inds = tf.nn.top_k(arr, k=3, sorted=False)\r\n\r\n    with tf.Session() as sess:\r\n        vals, inds = sess.run((top_vals, top_inds))\r\n\r\n    print('device:     ', device)\r\n    print('dtype:      ', tf_dtype.__repr__())\r\n    print('arr:        ', np_arr)\r\n    print('inds:       ', inds)\r\n    print('tf_vals:    ', vals)\r\n    print('np_vals:    ', np_arr[inds], end='\\n\\n')\r\n\r\nint_dtypes = (np.int32, tf.int32)\r\nfloat_dtypes = (np.float32, tf.float32)\r\n\r\ndemo_bug(*int_dtypes, '/cpu')\r\ndemo_bug(*float_dtypes, '/cpu')\r\ndemo_bug(*int_dtypes, '/gpu')\r\ndemo_bug(*float_dtypes, '/gpu')\r\n\r\n>> device:      /cpu\r\n>> dtype:       tf.int32\r\n>> arr:         [3 2 8 1]\r\n>> inds:        [1 0 2]\r\n>> tf_vals:     [2 3 8]\r\n>> np_vals:     [2 3 8]\r\n \r\n>> device:      /cpu\r\n>> dtype:       tf.float32\r\n>> arr:         [3. 2. 8. 1.]\r\n>> inds:        [1 0 2]\r\n>> tf_vals:     [2. 3. 8.]\r\n>> np_vals:     [2. 3. 8.]\r\n\r\n>> device:      /gpu\r\n>> dtype:       tf.int32\r\n>> arr:         [3 2 8 1]\r\n>> inds:        [2 0 1]\r\n>> tf_vals:     [8 3 2]\r\n>> np_vals:     [8 3 2]\r\n\r\n>> device:      /gpu\r\n>> dtype:       tf.float32\r\n>> arr:         [3. 2. 8. 1.]\r\n>> inds:        [2 0 1]\r\n>> tf_vals:     [2. 3. 8.]\r\n>> np_vals:     [8. 3. 2.]\r\n```", "Anybody interested in this?", "This looks like a bug in the gpu implementation of top_k. @chsigg could you take a look at this?", "Nagging Assignees @martinwicke, @chsigg: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Thanks for reporting this. It is caused by constant folding. TF folds partial output of TopK on GPU with dtype float.\r\n\r\nI am sending out a fix to change constant folding to either fold all the outputs of an op or not fold any outputs at all."]}, {"number": 22382, "title": "Creating pip package for TensorFlow with GPU support results in 0 byte simple_console_for_windows.zip", "body": "Here is the stackoverflow question: https://stackoverflow.com/questions/52394305/creating-pip-package-for-tensorflow-with-gpu-support-results-in-0-byte-simple-co\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.11\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.2/7.2.1\r\n- **GPU model and memory**: Nvidia M1000M\r\n- **Exact command to reproduce**: bazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package C:/tmp/tensorflow_pkg\r\n\r\n### Describe the problem\r\nAfter successfully building TensorFlow with GPU support, I'm trying to build the pip package and I'm getting an error saying it can't read the simple_console_for_windows.zip file.  \r\n\r\nI've confirmed that the file is in C:\\tensorflow\\bazel-bin\\tensorflow\\tools\\pip_package folder, but it is 0 bytes.\r\n\r\nThis is my pip build command:\r\n    bazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package C:/tmp/tensorflow_pkg\r\n\r\nMy build command was:\r\n    bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Source code / logs\r\nThis is the full error:\r\n\r\n    Unzipping simple_console_for_windows.zip to create runfiles tree...\r\n    [./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip]\r\n      End-of-central-directory signature not found.  Either this file is not\r\n      a zipfile, or it constitutes one disk of a multi-part archive.  In the\r\n      latter case the central directory and zipfile comment will be found on\r\n      the last disk(s) of this archive.\r\n    unzip:  cannot find zipfile directory in one of ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip or\r\n            ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.zip, and cannot find ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_windows.zip.ZIP, period.\r\n", "comments": ["Just started happening to me, too. Tossing the zip files manually seems to fix. Linking the other issue directly: https://github.com/tensorflow/tensorflow/issues/20332", "This is a duplicate of #22390, I'm closing this one. Let's follow the progress in #22390."]}, {"number": 22381, "title": "fix for issue #22347", "body": "fix for #22347 in contrib/graph_editor/transform: clear the colocation attribute when copying the node_def such that the new subgraph can be exported separate from the original copied subgraph", "comments": ["I can't find any documentation on the node_def so I'm only going off what I saw in my examples, which I agree is not rigorous. I'll have to find out if the \"_class\" attribute can hold things other than colocation. I'll try to dig into this more next week.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Please resubmit a clean pr", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "I'm going to close this as my application might be a special case and it's easier for me to just maintain my own version of transform.graph_replace.\r\n\r\nedit: sorry for the above mess, I tried to merge the new master into my branch and it apparently added ~100 reviewers to the PR for some reason"]}, {"number": 22380, "title": "ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory", "body": "Hi! I have CUDA 9.2 and CUDNN 7.2.1\r\nI have seen this error in the issues page before but didn't get a nice answer as to solve it. Should I downgarde the CUDA version, if yes, which one to? Thanks in advance!\r\n\r\n```\r\nPython 3.6.5 |Anaconda custom (64-bit)| (default, Apr 29 2018, 16:14:56) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 6.4.0 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import tensorflow as tf\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in <module>()\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~/anaconda3/lib/python3.6/imp.py in load_module(name, file, filename, details)\r\n    242         else:\r\n--> 243             return load_dynamic(name, filename, file)\r\n    244     elif type_ == PKG_DIRECTORY:\r\n\r\n~/anaconda3/lib/python3.6/imp.py in load_dynamic(name, path, file)\r\n    342             name=name, loader=loader, origin=path)\r\n--> 343         return _load(spec)\r\n    344 \r\n\r\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-64156d691fe5> in <module>()\r\n----> 1 import tensorflow as tf\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py in <module>()\r\n     20 \r\n     21 # pylint: disable=g-bad-import-order\r\n---> 22 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     23 \r\n     24 try:\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/dhananjai/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/dhananjai/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/dhananjai/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/dhananjai/anaconda3/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/dhananjai/anaconda3/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```", "comments": ["Downgraded from CUDA 9.2 to 9.0\r\nSolved this issue, but still, have a few more.\r\n\r\nThanks!"]}, {"number": 22379, "title": "[TF1.10] Use the method \"experimental_create_eval_graph()\" of quantize_graph.py to quantize a frozen_model, succeeded but failed at serializing by graph_util", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu==1.10.0\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: no\r\n- **GCC/Compiler version (if compiling from source)**: clang 9.1.0\r\n- **CUDA/cuDNN version**: no\r\n- **GPU model and memory**: no\r\n- **Exact command to reproduce**: Please refer to my test script below:\r\n\r\nHi, \r\nI tried to use the tool named quantize_graph.py to quantize a frozen_graph from FP32 to INT8.\r\nAfter import the frozen model, I called the method named \"experimental_create_eval_graph\" and seems succeeded.\r\nLater when I try to use graph_util to freeze variables to constant, error occurred.\r\nScript:\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.layers.python.layers import layers\r\nfrom tensorflow.contrib.quantize.python import quantize_graph\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.framework import test_util\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.ops import init_ops\r\nfrom tensorflow.python.ops import nn_ops\r\n\r\nfrom tensorflow.python.framework import importer as importer\r\nfrom tensorflow.python.client import session as csess\r\nfrom tensorflow.core.protobuf import config_pb2 as cpb2\r\nfrom tensorflow.python.framework import ops as ops\r\nfrom tensorflow.python.framework import graph_util\r\nfrom tensorflow.python.platform import gfile\r\n\r\n#tf.enable_eager_execution()\r\n\r\noutput_node_name = 'InceptionV3/Logits/SpatialSqueeze'\r\ninput_node_name = 'Placeholder'\r\noutput_path = 'test.pb'\r\ng = tf.Graph()\r\nwith g.as_default():\r\n    output_graph_def = tf.GraphDef()\r\n    with open('frozen_graph.pb', 'rb') as f:\r\n        output_graph_def.ParseFromString(f.read())\r\n        _ = tf.import_graph_def(output_graph_def, name='')\r\n    print([n.name for n in output_graph_def.node])\r\n    quantize_graph.experimental_create_eval_graph(\r\n        input_graph = g,\r\n        weight_bits = 8,\r\n        activation_bits = 8,\r\n        quant_delay=None,\r\n        scope=None)\r\n\r\n    print('=========================')\r\n    print([n.name for n in g.as_graph_def().node])\r\n\r\n\r\n#saver = tf.train.Saver(write_version=tf.train.SaverDef.V1)\r\nwith csess.Session(config=cpb2.ConfigProto(), graph=g) as sess:\r\n    inp = tf.get_default_graph().get_tensor_by_name('Placeholder:0')\r\n    out = tf.get_default_graph().get_tensor_by_name('InceptionV3/Logits/SpatialSqueeze:0')\r\n    g = graph_util.convert_variables_to_constants(sess, g.as_graph_def(), out)\r\n    with tf.gfile.GFile(output_path, \"wb\") as f:\r\n        f.write(g.SerializeToString())\r\n#    saver_path = saver.save(sess, \"model.ckpt\")\r\n```\r\nThe Error log:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 48, in <module>\r\n    g = graph_util.convert_variables_to_constants(sess, g.as_graph_def(), out)\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/graph_util_impl.py\", line 232, in convert_variables_to_constants\r\n    inference_graph = extract_sub_graph(input_graph_def, output_node_names)\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/graph_util_impl.py\", line 174, in extract_sub_graph\r\n    _assert_nodes_are_present(name_to_node, dest_nodes)\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/graph_util_impl.py\", line 132, in _assert_nodes_are_present\r\n    for d in nodes:\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py\", line 431, in __iter__\r\n    \"Tensor objects are not iterable when eager execution is not \"\r\nTypeError: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.\r\n\r\n```\r\nAfter enabling the eager execution mode, the error remains the same.\r\nNot sure whether my script is correct and whether there is a way to serialize the quantized graph to a file? Any idea will be welcome.\r\n\r\nThanks,\r\n\r\n--------------------------\r\n\r\nI wrote a script to try to evaluate the accuracy of the quantized model over a test dataset.\r\nBut a \"FailedPreconditionError\" error raised. Note that I'm using the official inceptionv3 model, and the output node is named \"InceptionV3/Logits/SpatialSqueeze\".\r\nI wonder whether there will be a demo about how to use the quantized graph to do the prediction?\r\nLet me update the full log\r\n```\r\n\r\n2018-09-25 10:51:49.521178: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-25 10:51:49.700182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:84:00.0\r\ntotalMemory: 11.91GiB freeMemory: 11.75GiB\r\n2018-09-25 10:51:49.700336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-09-25 10:51:50.023026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-25 10:51:50.023106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \r\n2018-09-25 10:51:50.023120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \r\n2018-09-25 10:51:50.023437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11364 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 61, in <module>\r\n    val = sess.run(out, {inp: preProcessImage(img_path)})\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n    run_metadata_ptr)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n    run_metadata)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights_quant/min\r\n\t [[Node: InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights_quant/min/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights_quant/min)]]\r\n\t [[Node: InceptionV3/Logits/SpatialSqueeze/_755 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2389_InceptionV3/Logits/SpatialSqueeze\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op u'InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights_quant/min/read', defined at:\r\n  File \"test.py\", line 50, in <module>\r\n    quantize_graph.experimental_create_eval_graph(input_graph = g,weight_bits = 8,activation_bits = 8,quant_delay=None,scope=None)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/quantize/python/quantize_graph.py\", line 228, in experimental_create_eval_graph\r\n    scope=scope)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/quantize/python/quantize_graph.py\", line 73, in _create_graph\r\n    scope=scope)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/quantize/python/quantize.py\", line 94, in Quantize\r\n    consumer_scope=scope)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/quantize/python/quantize.py\", line 545, in _InsertQuantOp\r\n    name_prefix=name_prefix))\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/quantize/python/quant_ops.py\", line 101, in LastValueQuantize\r\n    trainable=False)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 297, in model_variable\r\n    use_resource=use_resource)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 252, in variable\r\n    use_resource=use_resource)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1467, in get_variable\r\n    aggregation=aggregation)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1217, in get_variable\r\n    aggregation=aggregation)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 527, in get_variable\r\n    aggregation=aggregation)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 481, in _true_getter\r\n    aggregation=aggregation)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 903, in _get_single_variable\r\n    aggregation=aggregation)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2443, in variable\r\n    aggregation=aggregation)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2425, in <lambda>\r\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2406, in default_variable_creator\r\n    constraint=constraint)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 259, in __init__\r\n    constraint=constraint)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 422, in _init_from_args\r\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 80, in identity\r\n    return gen_array_ops.identity(input, name=name)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3264, in identity\r\n    \"Identity\", input=input, name=name)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\r\n    op_def=op_def)\r\n  File \"/home/web_server/dlpy72/dlpy/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights_quant/min\r\n\t [[Node: InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights_quant/min/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights_quant/min)]]\r\n\t [[Node: InceptionV3/Logits/SpatialSqueeze/_755 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2389_InceptionV3/Logits/SpatialSqueeze\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\n```\r\n", "comments": ["@oscarriddle Hi, can you please share frozen_graph.pb", "@harshini-gadige Hi, unfortunately this is an internal model that can't be distributed. I think you can choose a common inceptionv3 model and try the serialization and session run after been quantized.", "@sguada Hi, could you please look into this issue.", "[TensorFlow 1.12]\r\nI tried to quantize the graph and create a session to run it, but failed, saying:\r\n`KeyError: \"The name 'Placeholder:0' refers to a Tensor which does not exist. The operation, 'Placeholder', does not exist in the graph.\"`\r\n\r\nHowever, Placeholder is in the graph node list, so I'm confused about the correct way of using the quantization method.\r\nThe script is:\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.layers.python.layers import layers\r\nfrom tensorflow.contrib.quantize.python import quantize_graph\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.framework import test_util\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.ops import init_ops\r\nfrom tensorflow.python.ops import nn_ops\r\n\r\nfrom tensorflow.python.framework import importer as importer\r\nfrom tensorflow.python.client import session as csess\r\nfrom tensorflow.core.protobuf import config_pb2 as cpb2\r\nfrom tensorflow.python.framework import ops as ops\r\nfrom tensorflow.python.framework import graph_util\r\nfrom tensorflow.python.platform import gfile\r\nfrom tensorflow.python.framework import tensor_util\r\n\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport io,os                                                                                                                                                                   \r\n\r\noutput_node_name = 'InceptionV3/Logits/SpatialSqueeze'\r\ninput_node_name = 'Placeholder'\r\noutput_path = 'test.pb'\r\nimg_path = './1223832538_h.jpg'\r\n\r\ndef preProcessImage(img_path):\r\n    list = []\r\n    img = io.BytesIO(open(img_path,'rb').read())\r\n    img = Image.open(img)\r\n    img = img.resize((299, 299), Image.NEAREST)\r\n    images = np.array(img, dtype=np.uint32)\r\n    for x in xrange(16):\r\n        list.append(images)\r\n    list_np = np.array(list)\r\n    return list_np\r\n\r\ndef get_all_const(graph_nodes):\r\n    wts = [n for n in graph_nodes if n.op=='Const']\r\n    for n in wts:\r\n        print(\"Name of the node - %s\" % n.name)\r\n        print(\"Value - \")\r\n        print(tensor_util.MakeNdarray(n.attr['value'].tensor).shape)\r\n        print(tensor_util.MakeNdarray(n.attr['value'].tensor))\r\n    return wts\r\n\r\ng = tf.Graph()\r\nwith g.as_default():\r\n    output_graph_def = tf.GraphDef()\r\n    with open('frozen_graph.pb', 'rb') as f:\r\n        output_graph_def.ParseFromString(f.read())\r\n        _ = tf.import_graph_def(output_graph_def, name='')\r\n    print([n.name for n in output_graph_def.node])\r\n    graph_nodes=[n for n in output_graph_def.node]                                                                                                                                                         \r\n    quantize_graph.experimental_create_eval_graph(input_graph = g,weight_bits = 8,activation_bits = 8)\r\n    #quantize_graph.create_eval_graph(input_graph = g)                                                                                                                                         \r\n    for i in xrange(5):\r\n        print('=========================')\r\n    print([n.name for n in g.as_graph_def().node])\r\n    graph_nodes=[n for n in g.as_graph_def().node]      \r\n\r\ngpu_options = cpb2.GPUOptions(per_process_gpu_memory_fraction = 0.8)\r\noutput_tensor_name = output_node_name\r\ninp = tf.get_default_graph().get_tensor_by_name('Placeholder:0')\r\nout = tf.get_default_graph().get_tensor_by_name('InceptionV3/Logits/SpatialSqueeze:0')\r\nprint('here')\r\nimages = preProcessImage(img_path)\r\nwith csess.Session(config=cpb2.ConfigProto(gpu_options=gpu_options), graph=g) as sess:\r\n    val = sess.run(out, {inp: images})\r\nprint(val)\r\n\r\n```\r\nError log is:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 75, in <module>\r\n    inp = tf.get_default_graph().get_tensor_by_name('Placeholder:0')\r\n  File \"/home/web_server/dlpy72/dlpy.tensor1.12/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3666, in get_tensor_by_name\r\n    return self.as_graph_element(name, allow_tensor=True, allow_operation=False)\r\n  File \"/home/web_server/dlpy72/dlpy.tensor1.12/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3490, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/home/web_server/dlpy72/dlpy.tensor1.12/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3532, in _as_graph_element_locked\r\n    \"graph.\" % (repr(name), repr(op_name)))\r\nKeyError: \"The name 'Placeholder:0' refers to a Tensor which does not exist. The operation, 'Placeholder', does not exist in the graph.\"\r\n```\r\nAny idea will be welcome.", "Apologies for the delay in response. Is this still an issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22378, "title": "Stop the gradient computation for Keras eager execution mode", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: \r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: python 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI  am facing problems when implementing some custom loss function in Keras based on the eager execution mode. The problem is that some loss functions require to stop the gradient computation for some specific variables. When executed in a graph, we can use the op tf.stop_gradient. In fact, for Keras the GradientTape is internally handled by the function [`_process_single_batch` ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py)\r\n\r\n### Source code / logs\r\nHere is an example : \r\n   \r\n```\r\n    def virtual_adversarial_loss(X, DAE_encoder):\r\n        r_vadv = generate_virtual_adversarial_perturbation(X, DAE_encoder)\r\n        tape.reset()\r\n        tape.watch(X)\r\n        tape.watch(r_vadv)\r\n        p =  DAE_encoder(X)\r\n        p = tape.watch(p)\r\n        q = DAE_encoder(x+r_vadv)\r\n        loss = kl(p, q)\r\n        return tf.identity(loss, name=\"vat_loss\")\r\n```\r\n\r\n```\r\n    def virtual_adversarial_loss(X, DAE_encoder):\r\n        r_vadv = generate_virtual_adversarial_perturbation(X, DAE_encoder)\r\n        tf.stop_gradient(X)\r\n        tf.stop_gradient(r_vadv)\r\n        p =  DAE_encoder(X)\r\n        p = tf.stop_gradient(p)\r\n        q = DAE_encoder(x+r_vadv)\r\n        loss = kl(p, q)\r\n        return tf.identity(loss, name=\"vat_loss\")\r\n```\r\n\r\nBoth of these functions do not work. The problem with the first one is that I can't use the tape variable created by the internal Keras wrapper function [`_process_single_batch` ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py). The problem with the second one is that I can't use tf.stop_gradient for the eager execution mode.\r\n\r\nIs there a way to stop the gradient computation in Keras eager execution mode?", "comments": ["@nairouz just ran above snippets in eager execution and both of these functions should work. You would need to add something like:\r\n`from tensorflow import keras`\r\n`from tensorflow.python.eager.backprop import GradientTape`\r\n`from tensorflow import keras as ks`\r\n\r\nMake sure to add `with GradientTape() as tape:` in your first function.", "@wt-huang thank you for the response. Yes, I made sure to add all the required imports.\r\n\r\nPlease let further explain the problem. Some loss functions require to stop the gradient for some specific variables. In fact, there are two cases:\r\n\r\n1) In the graph execution mode, one can use the  `tf.stop_gradient(input=a)` and this operator will exclude the \"a\" variable from any gradient backpropagation.\r\n\r\n2) In the eager execution mode, a tape should be created based on the GradientTape class to record the operations since we do not have a graph and only then we can exclude some variables from the gradient backpropagation.\r\n\r\nUnfortunately in Keras, one should not create a tape himself since the gradient computation will be done using the tape created by tensorflow developers in this function [`_process_single_batch`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py#L479). Even if I create a tape myself, it will not be used for the gradient computation performed by Keras engine unless I implement my own training loop function and hence have my own  backpropagation. In this case,  I would be deprived of Keras high-level API functions like `fit` and `predict`.\r\n\r\nI think it will be quite useful to extend tensorflow with the following operator:\r\ntf.get_GradientTape() which can return the actual gradient context manager if there is one.", "@nairouz You can leverage tf.GradientTape() where all operations are recorded in order to compute the gradients of any tensor computed within the context. You can customize this function any way you want. This should not block you from using high-level Keras API.", "@wt-huang thank you for the response.\r\nBut what if I am not the one who created the gradient context (i.e., in Keras it is created internally) and I do not have access to the `tape` variable. How can I stop the gradient? \r\nHere is a toy example to illustrate the problem:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ntfe = tf.contrib.eager\r\ntf.enable_eager_execution()\r\n\r\na = tfe.Variable(0.)\r\n\r\ndef custom_loss(y_true, y_pred):\r\n  #here I want to stop the gradient how can I do so?\r\n  #I can only write the code of the custom loss function\r\n\r\n#This is a simplification of what  Keras high-level API is doing\r\ndef keras_backprop(loss, model, lr, x, y_true):\r\n  with tf.GradientTape() as tape:\r\n    y_pred = model(x)\r\n    l = loss(y_true, y_pred)\r\n  dw = tape.gradient(l, model.w)\r\n  model.w = model.w - lr * dw\r\n\r\n```\r\n", "Actually, I have found a workaround. I can simply wrap the tensor which I want to exclude from the gradient computation with `tfe.Variable()`.\r\nThe code would look something like this\r\n```\r\n\r\ndef virtual_adversarial_loss(X, DAE_encoder):\r\n    r_vadv = tfe.Variable(generate_virtual_adversarial_perturbation(X, DAE_encoder))\r\n    p = tfe.Variable(DAE_encoder(X))\r\n    q = DAE_encoder(X+r_vadv)\r\n    loss = tf.reduce_mean(kl(p, q), axis=0)\r\n    return tf.identity(loss, name=\"vat_loss\")\r\n\r\n```\r\nBut obviously, this is not intuitive at all.", "@nairouz Glad you found a workaround, will close this for now. Feel free to open a new issue if problem persists.", "Cc: @fchollet \r\nI think this should be fixed since there is no way to handle the `tape` in Keras eager execution mode :("]}, {"number": 22377, "title": "tflite can't ResizeInputTensor size", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:16.04.1-Ubuntu\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:N/A\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:1.11.0rc0\r\n- **Python version**:3.5\r\n- **Bazel version (if compiling from source)**:0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**:N/A\r\n- **GPU model and memory**:N/A\r\n- **Exact command to reproduce**:See below\r\n### Describe the problem\r\nWhen I use tflite,I set ResizeInputTensor different from model, error show:\r\n```\r\ntensorflow/contrib/lite/kernels/reshape.cc:58 num_input_elements != num_output_elements (880 != 440)\r\nNode number 0 (RESHAPE) failed to prepare.\r\n```\r\nfisrt,my net input is [?,440], I convert it by set intput to [1,440]. I want to use it in forward with different size [n,440].Maybe I conert it to tflite wrong?\r\n### Source code / logs\r\n*my code:\r\n```\r\nint main() {\r\n\r\n    // load model\r\n    std::unique_ptr<tflite::FlatBufferModel> model;\r\n    std::unique_ptr<tflite::Interpreter> interpreter;\r\n    model = tflite::FlatBufferModel::BuildFromFile(\"./moble.tflite\");\r\n    if (!model) {\r\n\tcout << \"load model err.\" << endl;\r\n\texit(-1);\r\n    }\r\n\r\n    // build op\r\n    tflite::ops::builtin::BuiltinOpResolver resolver;\r\n\r\n    tflite::InterpreterBuilder (*model, resolver)(&interpreter);\r\n    if (!interpreter) {\r\n\tcout << \"Failed to construct interpreter\\n\" << endl;\r\n\texit(-1);\r\n    }\r\n\r\n    interpreter->UseNNAPI(0);\r\n    interpreter->SetNumThreads(1);\r\n\r\n    // allocate tensors space\r\n    int input = interpreter->inputs()[0];\r\n    interpreter->ResizeInputTensor(input, {2,440});\r\n    if (interpreter->AllocateTensors() != kTfLiteOk) {\r\n\tcout << \"Failed to allocate tensors.\\n\";\r\n\texit(-1);\r\n    }\r\n\r\n    // set input\r\n    float *in = interpreter->typed_tensor<float>(input);\r\n    for (int i = 0; i < 440 * 2; i++) {\r\n\tin[i] = i + 1.0f;\r\n    }\r\n\r\n    // inference\r\n    if (interpreter->Invoke() != kTfLiteOk) {\r\n\tcout << \"Failed to invoke!\\n\";\r\n\texit(-1);\r\n    }\r\n\r\n    // get result\r\n    float *output = interpreter->typed_output_tensor<float>(0);\r\n    for (int i = 0; i < 200; i++) {\r\n\tcout << output[i] << \" \";\r\n    }\r\n    cout << endl;\r\n    return 0;\r\n}\r\n```\r\n* python convert script\r\n** my net\r\n```\r\nbazel run tensorflow/tools/graph_transforms:summarize_graph -- --in_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/graph_vprint.pb\r\n```\r\nresult\r\n```\r\nFound 1 possible inputs: (name=ac_input, type=float(1), shape=[?,440]) \r\nNo variables spotted.\r\nFound 1 possible outputs: (name=Inference/final_output/output, op=Identity) \r\nFound 382867 (382.87k) const parameters, 0 (0) variable parameters, and 0 control_edges\r\nOp types used: 50 Const, 13 Reshape, 13 Identity, 12 Transpose, 6 BiasAdd, 4 Conv2D, 4 Relu, 3 ConcatV2, 3 Mul, 2 GatherV2, 2 Add, 2 Cast, 2 Prod, 2 Mean, 2 MaxPool, 2 MatMul, 1 Pack, 1 Placeholder, 1 Range, 1 ListDiff, 1 Less, 1 Shape, 1 Sqrt, 1 Sub, 1 GreaterEqual\r\n```\r\n** transform net\r\n```\r\nbazel run tensorflow/tools/graph_transforms:transform_graph -- --in_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/graph_vprint.pb --out_graph=/home/aisp/work_mirror/tensorflow/model/cnn/vocal_print_model/transformed_graph_simple.pb --inputs='ac_input' --outputs='Inference/final_output/output' --transforms='strip_unused_nodes(type=float,shape=\"1,440\") fold_constants(ingore_errors=true) fold_batch_norms fold_old_batch_norms'\r\n```\r\n** convert to lite\r\n```\r\ntflite_convert   --output_file=$(pwd)/model/cnn/vocal_print_model/moble.tflite  --graph_def_file=$(pwd)/model/cnn/vocal_print_model/transformed_graph_simple.pb   --input_arrays=ac_input   --output_arrays=Inference/final_output/output --input_shapes=1,440\r\n```", "comments": ["@aselle Please help me look at this problem. It really makes me wonder.", "\r\nHere are my model.\r\n\r\n[model.tar.gz](https://github.com/tensorflow/tensorflow/files/2400554/model.tar.gz)\r\n", "@TPcoding did you solve this issue? Thank you.", "> @TPcoding did you solve this issue? Thank you.\r\n\r\nNo, I rewrite my graph ,only support one frame input.This issue still open.", "@TPCoding, not all models can have their inputs resized for example\r\n\r\nx = tf.placeholder()\r\ny = tf.reshape(x, (440,1))\r\n... do more stuff\r\n\r\nThis model needs to have shapes that have 440 elements. you cannot feed a tensor that is length 3 it would have a similar error. ", "@aselle your comment below is making me wonder, why changing output tensor dimension (change label file classes - Add/remove ) **works in case of IOS tflite demo , but Not in Android.**\r\n\r\n\"@TPcoding, not all models can have their inputs resized\"\r\n\r\nI h'v tried in both IOS & Android tflite demos. So, In IOS it's working but not in Android.\r\n\r\nPlease help me resolve this issue in android as well. I h'v mentioned details of bug in official demo.\r\nI'm not able to work around it, please let me know your response on it!!\r\n\r\nLink to opened issue : \r\nhttps://github.com/tensorflow/tensorflow/issues/23940\r\n\r\n", "@aselle  Half year passed,Does this issues will be done in new tflite version plan. I really need this function.Recently, I have to implement several model which has variable sequence length when input to tflite.", "I am having the same issue with a fully convolution 1D network (in tf.keras having variable model size is not a problem). I export the model with a fixed size of 180x3 (since it won't export with None in any dimension) and then when I try to change the size with ResizeInput I get the message above.\r\nDuring the conversion process the Conv1D operations are converted into 2D convolutions is this why it cannot be resized?", "Hi @TPcoding !\r\nWe are checking to see if you still need help on this issue. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Any solutions? Meeting the same issue."]}, {"number": 22376, "title": "Failed to build TF from source with MPI support", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04 LTS\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.11.0-rc0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: 0.17.1\r\n- **GCC/Compiler version (if compiling from source)**: 7.3.0\r\n- **CUDA/cuDNN version**: 9.2/7.2\r\n- **GPU model and memory**: Asus GTX 1080Ti\r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\nI canno't seem to compile tensorflow from source when I try to enable MPI support. The build always fails.\r\n```\r\nWARNING: An illegal reflective access operation has occurred\r\nWARNING: Illegal reflective access by com.google.protobuf.UnsafeUtil (file:/home/stefan/.cache/bazel/_bazel_stefan/install/28c1d2ace0add449e21862ae9f2d2289/_embedded_binaries/A-server.jar) to field java.lang.String.value\r\nWARNING: Please consider reporting this to the maintainers of com.google.protobuf.UnsafeUtil\r\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\nWARNING: All illegal access operations will be denied in a future release\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.17.1 installed.\r\nPlease specify the location of python. [Default is /home/stefan/.tmp/venv3/bin/python]: \r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: module 'site' has no attribute 'getsitepackages'\r\nFound possible Python library paths:\r\n  /home/stefan/.tmp/venv3/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/stefan/.tmp/venv3/lib/python3.6/site-packages]\r\n\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: \r\nGoogle Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: \r\nHadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon AWS Platform support? [Y/n]: \r\nAmazon AWS Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: \r\nApache Kafka Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: \r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: \r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with nGraph support? [y/N]: \r\nNo nGraph support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: 9.2\r\n\r\n\r\nPlease specify the location where CUDA 9.2 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 7.2\r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify the NCCL version you want to use. If NCCL 2.2 is not installed, then you can use version 1.3 that can be fetched automatically but it may have worse performance with multiple GPUs. [Default is 2.2]: \r\n\r\n\r\nPlease specify the location where NCCL 2 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:/usr/local/cuda/nccl\r\n\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: \r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: y\r\nMPI support will be enabled for TensorFlow.\r\n\r\nPlease specify the MPI toolkit folder. [Default is /usr/local]: \r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\nConfiguration finished\r\n```\r\nThis is my configuration. Note that the build succeeds with MPI set to no.\r\nError message when build fails:\r\n```\r\nERROR: /home/stefan/.tmp/tensorflow/tensorflow/contrib/mpi/BUILD:60:1: C++ compilation of rule '//tensorflow/contrib/mpi:mpi_rendezvous_mgr' failed (Exit 1)\r\nIn file included from ./tensorflow/core/framework/common_shape_fns.h:22:0,\r\n                 from ./tensorflow/core/framework/resource_mgr.h:24,\r\n                 from ./tensorflow/core/common_runtime/device.h:43,\r\n                 from ./tensorflow/core/common_runtime/device_mgr.h:24,\r\n                 from ./tensorflow/core/distributed_runtime/worker_session.h:21,\r\n                 from ./tensorflow/core/distributed_runtime/base_rendezvous_mgr.h:24,\r\n                 from ./tensorflow/contrib/mpi/mpi_rendezvous_mgr.h:35,\r\n                 from tensorflow/contrib/mpi/mpi_rendezvous_mgr.cc:18:\r\n./tensorflow/core/util/tensor_format.h: In function 'tensorflow::TensorShape tensorflow::ShapeFromFormat(tensorflow::TensorFormat, tensorflow::int64, tensorflow::gtl::ArraySlice<long long int>, tensorflow::int64)':\r\n./tensorflow/core/util/tensor_format.h:501:45: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (format == FORMAT_NHWC_VECT_W && dim == spatial.size() - 1) {\r\n                                         ~~~~^~~~~~~~~~~~~~~~~~~~~\r\nIn file included from tensorflow/contrib/mpi/mpi_rendezvous_mgr.cc:18:0:\r\n./tensorflow/contrib/mpi/mpi_rendezvous_mgr.h: In member function 'void tensorflow::MPISendTensorCall::Init(const tensorflow::Rendezvous::ParsedKey&, tensorflow::int64, bool)':\r\n./tensorflow/contrib/mpi/mpi_rendezvous_mgr.h:74:36: error: 'using StringPiece = class absl::string_view {aka class absl::string_view}' has no member named 'ToString'\r\n     mRes_.set_key(parsed.FullKey().ToString());\r\n                                    ^~~~~~~~\r\ntensorflow/contrib/mpi/mpi_rendezvous_mgr.cc: In member function 'virtual void tensorflow::MPIRemoteRendezvous::RecvFromRemoteAsync(const tensorflow::Rendezvous::ParsedKey&, const tensorflow::Rendezvous::Args&, tensorflow::Rendezvous::DoneCallback)':\r\ntensorflow/contrib/mpi/mpi_rendezvous_mgr.cc:139:38: error: 'using StringPiece = class absl::string_view {aka class absl::string_view}' has no member named 'ToString'\r\n   mgr->QueueRequest(parsed.FullKey().ToString(), step_id_,\r\n                                      ^~~~~~~~\r\ntensorflow/contrib/mpi/mpi_rendezvous_mgr.cc: In lambda function:\r\ntensorflow/contrib/mpi/mpi_rendezvous_mgr.cc:261:45: error: 'using StringPiece = class absl::string_view {aka class absl::string_view}' has no member named 'ToString'\r\n         SendQueueEntry req(parsed.FullKey().ToString().c_str(), std::move(res));\r\n                                             ^~~~~~~~\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/contrib/mpi/mpi_utils.h:25,\r\n                 from ./tensorflow/contrib/mpi/mpi_rendezvous_mgr.h:34,\r\n                 from tensorflow/contrib/mpi/mpi_rendezvous_mgr.cc:18:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 863.199s, Critical Path: 65.99s\r\nINFO: 3852 processes: 3852 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\nIt says that StringPiece has no member ToString.\r\nI installed MPI with:\r\n```\r\nwget https://www.open-mpi.org/software/ompi/v3.0/downloads/openmpi-3.1.2.tar.gz\r\ntar -xvf openmpi-3.1.2.tar.gz\r\ncd openmpi-3.1.2\r\n./configure --disable-mpi-fortran --with-cuda=/usr/local/cuda/ --prefix /usr/local/\r\nmake\r\nmake install\r\n```\r\n", "comments": ["@stefanpantic A PR #22084 is pending for review. The PR will fix the issue you mentioned.", "Feel free to reopen if you face the issue again.", "This issue has been closed, BUT it has not been resolved. I see exactly the same problem right now.", "@phalexo Please wait until the PR is completed. You may track it #22084 ", "Still not fix for TF1.11.0 release, still get same error", "I have been able to build from source, with MPI support. I pulled the\nlatest master branch, but I tweaked the two references with ToString method.\n\nOn Thu, Sep 27, 2018 at 11:46 PM beew <notifications@github.com> wrote:\n\n> Still not fix for TF1.11.0 release, still get same error\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22376#issuecomment-425311467>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEY95bb4GNy4Nh4xmbAuo4XmRSfWBLBDks5ufZuJgaJpZM4WvvEc>\n> .\n>\n", "@phalexo I thought the `ToString()` issue has been fixed in #22084 and has been merged. But let me double check again.", "I did it before the merge, so it is probably not needed now. One might need\nto either do \"bazel clean\" or just delete the folder and clone the repo\nagain. I installed MPI under /usr/local and passed that to \"./configure\".\n\n\nOn Fri, Sep 28, 2018 at 11:32 AM Yong Tang <notifications@github.com> wrote:\n\n> @phalexo <https://github.com/phalexo> I thought the ToString() issue has\n> been fixed in #22084 <https://github.com/tensorflow/tensorflow/pull/22084>\n> and has been merged. But let me double check again.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22376#issuecomment-425471656>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEY95c2ZnBlsAetravCHolLDxOgupL3uks5ufkEkgaJpZM4WvvEc>\n> .\n>\n", "I tested TF with MPI using some examples from the openAI \"glow\" repo.\n\n\nOn Fri, Sep 28, 2018 at 12:01 PM pensive introvert <\npensive.introvert@gmail.com> wrote:\n\n> I did it before the merge, so it is probably not needed now. One might\n> need to either do \"bazel clean\" or just delete the folder and clone the\n> repo again. I installed MPI under /usr/local and passed that to\n> \"./configure\".\n>\n>\n> On Fri, Sep 28, 2018 at 11:32 AM Yong Tang <notifications@github.com>\n> wrote:\n>\n>> @phalexo <https://github.com/phalexo> I thought the ToString() issue has\n>> been fixed in #22084\n>> <https://github.com/tensorflow/tensorflow/pull/22084> and has been\n>> merged. But let me double check again.\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/22376#issuecomment-425471656>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/AEY95c2ZnBlsAetravCHolLDxOgupL3uks5ufkEkgaJpZM4WvvEc>\n>> .\n>>\n>\n", "By the way, the GPU utilization was kind of underwhelming. I was expecting\nbetter load balancing with MPI. Maybe it just has to do with specific\n\"glow\" examples.\n\n\nOn Fri, Sep 28, 2018 at 12:03 PM pensive introvert <\npensive.introvert@gmail.com> wrote:\n\n> I tested TF with MPI using some examples from the openAI \"glow\" repo.\n>\n>\n> On Fri, Sep 28, 2018 at 12:01 PM pensive introvert <\n> pensive.introvert@gmail.com> wrote:\n>\n>> I did it before the merge, so it is probably not needed now. One might\n>> need to either do \"bazel clean\" or just delete the folder and clone the\n>> repo again. I installed MPI under /usr/local and passed that to\n>> \"./configure\".\n>>\n>>\n>> On Fri, Sep 28, 2018 at 11:32 AM Yong Tang <notifications@github.com>\n>> wrote:\n>>\n>>> @phalexo <https://github.com/phalexo> I thought the ToString() issue\n>>> has been fixed in #22084\n>>> <https://github.com/tensorflow/tensorflow/pull/22084> and has been\n>>> merged. But let me double check again.\n>>>\n>>> \u2014\n>>> You are receiving this because you were mentioned.\n>>> Reply to this email directly, view it on GitHub\n>>> <https://github.com/tensorflow/tensorflow/issues/22376#issuecomment-425471656>,\n>>> or mute the thread\n>>> <https://github.com/notifications/unsubscribe-auth/AEY95c2ZnBlsAetravCHolLDxOgupL3uks5ufkEkgaJpZM4WvvEc>\n>>> .\n>>>\n>>\n", "@phalexo Thanks. I tried with the latest master and it works. Let me know if you still encounter issues."]}, {"number": 22375, "title": "Tensorflow Object Detection - Car is wrongly detected as N/A", "body": "In Google-colab I am trying to detect car using Tensorflow Object-Detection API with SSD_mobilenet_v1_pets.config, it detect humans as car and car as N/A. The following are the  size config and image dimensions: \r\n\r\nanchor_generator {\r\n      ssd_anchor_generator {\r\n        num_layers: 6\r\n        min_scale: 0.2\r\n        max_scale: 0.95\r\n        aspect_ratios: 1.0\r\n        aspect_ratios: 2.0\r\n        aspect_ratios: 0.5\r\n        aspect_ratios: 3.0\r\n        aspect_ratios: 0.3333\r\n      }\r\n    }\r\n    image_resizer {\r\n      fixed_shape_resizer {\r\n        height: 300\r\n        width: 300\r\n      }\r\n\r\n\r\nI have 1160 images with various dimensions (ex: 73 x 63, 118 x 62, 62 x 56, 71 x 56, 276 x 183, 259 x 184, 318 x 159, 700 x 420, 647 x 407, 897 x 554) \r\n\r\nThis is the output I got:[enter image description here][1][enter image description here][2]\r\n\r\n\r\nPlease clarify, Is the problem of the wrong detection of car is because of the image dimensions or anything else?\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/eeau4.png\r\n  [2]: https://i.stack.imgur.com/flkbA.png\r\n![download](https://user-images.githubusercontent.com/39641762/45741779-186e8a00-bc16-11e8-92bf-462d46c20acb.png)\r\n![download 1](https://user-images.githubusercontent.com/39641762/45741856-3dfb9380-bc16-11e8-9845-ec459818ebea.png)\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 22374, "title": "*** stack smashing detected ***: <unknown> terminated \u5df2\u653e\u5f03 (\u6838\u5fc3\u5df2\u8f6c\u50a8)", "body": "## describe problems\uff1a\r\n1. ubuntu 18.04 cmake\r\n2. c++ with libtensorflow_cc.so\r\n3. I can compile my code,but when I run it,the error is \"*** stack smashing detected ***: <unknown> terminated \u5df2\u653e\u5f03 (\u6838\u5fc3\u5df2\u8f6c\u50a8)\"\r\n\r\n## code\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\n\r\nusing namespace std;\r\nusing namespace chrono;\r\nusing namespace tensorflow;\r\nint main(int argc, char* argv[]) {\r\n  // SessionOptions options;\r\n  // std::unique_ptr<tensorflow::Session> session(tensorflow::NewSession(options));\r\n  Session *session = NewSession(SessionOptions());\r\n  if(session == nullptr)\r\n  {\r\n    throw runtime_error(\"Could not create tensorflow session\");\r\n  }\r\n  session->Close();\r\n  return 0;\r\n}\r\n## So, what should I do?Thank you!", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "### OS platform:ubuntu:16.04\r\n### ensorflow install from source code\r\n### tensorflow version:1.11(master branch)\r\n### Bazel version:0.17.1\r\n### CPU\r\n## 1\u3001comand:\r\nbazel build --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=monolithic //tensorflow:libtensorflow_cc.so\r\nbazel build --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=monolithic //tensorflow:libtensorflow_framework.so\r\n\r\nsudo mkdir /usr/local/include/tf\r\nsudo mkdir /usr/local/include/tf/tensorflow\r\nsudo cp -r bazel-genfiles/ /usr/include/tf\r\nsudo cp -r tensorflow/cc /usr/include/tf/tensorflow\r\nsudo cp -r tensorflow/core /usr/include/tf/tensorflow\r\nsudo cp -r third_party /usr/include/tf\r\nsudo cp -r bazel-bin/tensorflow/libtensorflow_cc.so /usr/local/lib\r\nsudo cp -r bazel-bin/tensorflow/libtensorflow_framework.so /usr/local/lib\r\n## 2\u3001code:\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\n\r\nusing namespace std;\r\nusing namespace chrono;\r\nusing namespace tensorflow;\r\nint main(int argc, char* argv[]) {\r\n// SessionOptions options;\r\n// std::unique_ptrtensorflow::Session session(tensorflow::NewSession(options));\r\nSession *session = NewSession(SessionOptions());\r\nif(session == nullptr)\r\n{\r\nthrow runtime_error(\"Could not create tensorflow session\");\r\n}\r\nStatus status = session->Close();\r\nreturn 0;\r\n}\r\n## 3\u3001the status is status.ok() is right,but the error is \"*** stack smashing detected ***: terminated \u5df2\u653e\u5f03 (\u6838\u5fc3\u5df2\u8f6c\u50a8)\"", "Closing this issue as new issue #22411 is opened with updated information."]}, {"number": 22373, "title": "AttributeError: 'TocoConverter' object has no attribute 'get_input_arrays'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NO\r\n- **TensorFlow installed from (source or binary)**: pip install-gpu==1.9\r\n- **TensorFlow version (use command below)**: 1.9 GPU\r\n- **Python version**: python27\r\n- **Bazel version (if compiling from source)**: NO\r\n- **CUDA/cuDNN version**: CUDA9.0 cuDNN7.0\r\n- **GPU model and memory**: GTX1070 8G\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI want to conver the pb file to tflite file, \r\naccording to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/python_api.md, \r\nI run the example codes, but failed\r\nI run the following code\r\n### Source code \r\n\r\n`import tensorflow as tf\r\nimg = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\r\nconst = tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\r\nval = img + const\r\nout = tf.fake_quant_with_min_max_args(val, min=0., max=1., name=\"output\")\r\n\r\nwith tf.Session() as sess:\r\n  converter = tf.contrib.lite.TocoConverter.from_session(sess, [img], [out])\r\n  converter.inference_type = tf.contrib.lite.constants.QUANTIZED_UINT8\r\n  input_arrays = converter.get_input_arrays()\r\n  converter.quantized_input_stats = {input_arrays[0] : (0., 1.)}  # mean, std_dev\r\n  tflite_model = converter.convert()\r\n  open(\"converted_model.tflite\", \"wb\").write(tflite_model)`\r\n\r\n\r\n\r\nerror occurs, logs are below\r\n###  logs\r\n2018-09-19 15:22:25.875027: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-19 15:22:25.964421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-09-19 15:22:25.964839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8225\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.92GiB freeMemory: 7.77GiB\r\n2018-09-19 15:22:25.964854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\r\n2018-09-19 15:22:26.147714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-19 15:22:26.147746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \r\n2018-09-19 15:22:26.147752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \r\n2018-09-19 15:22:26.147938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7502 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 10, in <module>\r\n    input_arrays = converter.get_input_arrays()\r\nAttributeError: 'TocoConverter' object has no attribute 'get_input_arrays'\r\n\r\n\r\nwhat should I do?\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "I have updated them ", "It seems this feature is not available in TensorFlow 1.9 or 1.10. Please try and run your code on the nightly build (`pip install --upgrade tf-nightly`).", "thank you very much , I tried , and solved the problem"]}, {"number": 22372, "title": "crosstool_wrapper_driver_is_not_gcc failed: error executing command", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.11.0rc1\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: 0.17.1\r\n- **GCC/Compiler version (if compiling from source)**: c++ (Ubuntu 7.3.0-16ubuntu3) 7.3.0\r\n- **CUDA/cuDNN version**: 9.2 / 7.2.1\r\n- **GPU model and memory**: GeForce 940MX\r\n- **Exact command to reproduce**: bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n**When the VERBS support is enabled the tensorflow build fails with the following error message:\r\n~/tensorflow/tensorflow/contrib/verbs/BUILD:90:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma_rendezvous_mgr' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command**\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nERROR: ~/Documents/dev/git/tensorflow/tensorflow/contrib/verbs/BUILD:90:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma_rendezvous_mgr' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd ~/.cache/bazel/_bazel_blablabla/cf67b2b2e967476eb2b1ee98e33ab5bd/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    NCCL_INSTALL_PATH=/usr/local/nccl_2.2.13-1+cuda9.2_x86_64 \\\r\n    PATH=~/bin:/usr/local/sbin:/usr/local/lib:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:/home/linuxbrew/.linuxbrew/opt/coreutils/libexec/gnubin:/usr/local/cuda/bin:/usr/local/share/apache/hadoop/sbin:/usr/local/share/apache/hadoop/bin:/usr/local/share/apache/spark/sbin:/usr/local/share/apache/spark/bin:/usr/games:/usr/local/games:~/bin:/snap/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=5.0 \\\r\n    TF_CUDA_VERSION=9.2 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION=2 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/contrib/verbs/_objs/rdma_rendezvous_mgr/rdma_rendezvous_mgr.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/contrib/verbs/_objs/rdma_rendezvous_mgr/rdma_rendezvous_mgr.pic.o' '-DGRPC_ARES=0' '-DPB_FIELD_16BIT=1' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -DTENSORFLOW_USE_JEMALLOC -DTF_USE_SNAPPY -DTENSORFLOW_USE_VERBS -DTENSORFLOW_USE_GDR -DCURL_STATICLIB -DPLATFORM_LINUX -DENABLE_CURL_CLIENT -DENABLE_NO_ENCRYPTION -iquote . -iquote bazel-out/k8-opt/genfiles -iquote bazel-out/k8-opt/bin -iquote external/protobuf_archive -iquote bazel-out/k8-opt/genfiles/external/protobuf_archive -iquote bazel-out/k8-opt/bin/external/protobuf_archive -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -iquote bazel-out/k8-opt/bin/external/bazel_tools -iquote external/grpc -iquote bazel-out/k8-opt/genfiles/external/grpc -iquote bazel-out/k8-opt/bin/external/grpc -iquote external/zlib_archive -iquote bazel-out/k8-opt/genfiles/external/zlib_archive -iquote bazel-out/k8-opt/bin/external/zlib_archive -iquote external/boringssl -iquote bazel-out/k8-opt/genfiles/external/boringssl -iquote bazel-out/k8-opt/bin/external/boringssl -iquote external/com_google_absl -iquote bazel-out/k8-opt/genfiles/external/com_google_absl -iquote bazel-out/k8-opt/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/k8-opt/genfiles/external/nsync -iquote bazel-out/k8-opt/bin/external/nsync -iquote external/jemalloc -iquote bazel-out/k8-opt/genfiles/external/jemalloc -iquote bazel-out/k8-opt/bin/external/jemalloc -iquote external/eigen_archive -iquote bazel-out/k8-opt/genfiles/external/eigen_archive -iquote bazel-out/k8-opt/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/k8-opt/genfiles/external/local_config_sycl -iquote bazel-out/k8-opt/bin/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/k8-opt/genfiles/external/gif_archive -iquote bazel-out/k8-opt/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/k8-opt/genfiles/external/jpeg -iquote bazel-out/k8-opt/bin/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/genfiles/external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/genfiles/external/farmhash_archive -iquote bazel-out/k8-opt/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/genfiles/external/fft2d -iquote bazel-out/k8-opt/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/genfiles/external/highwayhash -iquote bazel-out/k8-opt/bin/external/highwayhash -iquote external/local_config_cuda -iquote bazel-out/k8-opt/genfiles/external/local_config_cuda -iquote bazel-out/k8-opt/bin/external/local_config_cuda -iquote external/double_conversion -iquote bazel-out/k8-opt/genfiles/external/double_conversion -iquote bazel-out/k8-opt/bin/external/double_conversion -iquote external/curl -iquote bazel-out/k8-opt/genfiles/external/curl -iquote bazel-out/k8-opt/bin/external/curl -iquote external/jsoncpp_git -iquote bazel-out/k8-opt/genfiles/external/jsoncpp_git -iquote bazel-out/k8-opt/bin/external/jsoncpp_git -iquote external/aws -iquote bazel-out/k8-opt/genfiles/external/aws -iquote bazel-out/k8-opt/bin/external/aws -isystem external/protobuf_archive/src -isystem bazel-out/k8-opt/genfiles/external/protobuf_archive/src -isystem bazel-out/k8-opt/bin/external/protobuf_archive/src -isystem external/grpc/include -isystem bazel-out/k8-opt/genfiles/external/grpc/include -isystem bazel-out/k8-opt/bin/external/grpc/include -isystem external/zlib_archive -isystem bazel-out/k8-opt/genfiles/external/zlib_archive -isystem bazel-out/k8-opt/bin/external/zlib_archive -isystem external/grpc/third_party/address_sorting/include -isystem bazel-out/k8-opt/genfiles/external/grpc/third_party/address_sorting/include -isystem bazel-out/k8-opt/bin/external/grpc/third_party/address_sorting/include -isystem external/boringssl/src/include -isystem bazel-out/k8-opt/genfiles/external/boringssl/src/include -isystem bazel-out/k8-opt/bin/external/boringssl/src/include -isystem external/nsync/public -isystem bazel-out/k8-opt/genfiles/external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/jemalloc/include -isystem bazel-out/k8-opt/genfiles/external/jemalloc/include -isystem bazel-out/k8-opt/bin/external/jemalloc/include -isystem external/eigen_archive -isystem bazel-out/k8-opt/genfiles/external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/k8-opt/genfiles/external/gif_archive/lib -isystem bazel-out/k8-opt/bin/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/genfiles/external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/com_google_absl -isystem bazel-out/k8-opt/genfiles/external/com_google_absl -isystem bazel-out/k8-opt/bin/external/com_google_absl -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include -isystem external/local_config_cuda/cuda/cuda/include/crt -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda/cuda/include/crt -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include/crt -isystem external/double_conversion -isystem bazel-out/k8-opt/genfiles/external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/curl/include -isystem bazel-out/k8-opt/genfiles/external/curl/include -isystem bazel-out/k8-opt/bin/external/curl/include -isystem external/jsoncpp_git/include -isystem bazel-out/k8-opt/genfiles/external/jsoncpp_git/include -isystem bazel-out/k8-opt/bin/external/jsoncpp_git/include -isystem external/aws/aws-cpp-sdk-core/include -isystem bazel-out/k8-opt/genfiles/external/aws/aws-cpp-sdk-core/include -isystem bazel-out/k8-opt/bin/external/aws/aws-cpp-sdk-core/include -isystem external/aws/aws-cpp-sdk-kinesis/include -isystem bazel-out/k8-opt/genfiles/external/aws/aws-cpp-sdk-kinesis/include -isystem bazel-out/k8-opt/bin/external/aws/aws-cpp-sdk-kinesis/include -isystem external/aws/aws-cpp-sdk-s3/include -isystem bazel-out/k8-opt/genfiles/external/aws/aws-cpp-sdk-s3/include -isystem bazel-out/k8-opt/bin/external/aws/aws-cpp-sdk-s3/include '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -mavx -mavx2 -mfma '-mfpmath=both' -msse4.2 -c tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc -o bazel-out/k8-opt/bin/tensorflow/contrib/verbs/_objs/rdma_rendezvous_mgr/rdma_rendezvous_mgr.pic.o)\r\nIn file included from ./tensorflow/core/framework/common_shape_fns.h:22:0,\r\n                 from ./tensorflow/core/framework/resource_mgr.h:24,\r\n                 from ./tensorflow/core/common_runtime/device.h:43,\r\n                 from ./tensorflow/core/common_runtime/device_mgr.h:24,\r\n                 from ./tensorflow/core/distributed_runtime/worker_session.h:21,\r\n                 from ./tensorflow/core/distributed_runtime/base_rendezvous_mgr.h:24,\r\n                 from ./tensorflow/contrib/verbs/rdma_rendezvous_mgr.h:22,\r\n                 from tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc:18:\r\n./tensorflow/core/util/tensor_format.h: In function 'tensorflow::TensorShape tensorflow::ShapeFromFormat(tensorflow::TensorFormat, tensorflow::int64, tensorflow::gtl::ArraySlice<long long int>, tensorflow::int64)':\r\n./tensorflow/core/util/tensor_format.h:501:45: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (format == FORMAT_NHWC_VECT_W && dim == spatial.size() - 1) {\r\n                                         ~~~~^~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/verbs/rdma_rendezvous_mgr.cc: In member function 'virtual void tensorflow::RdmaRemoteRendezvous::RecvFromRemoteAsync(const tensorflow::Rendezvous::ParsedKey&, const tensorflow::Rendezvous::Args&, tensorflow::Rendezvous::DoneCallback)':\r\ntensorflow/contrib/verbs/rdma_rendezvous_mgr.cc:66:41: error: 'using StringPiece = class absl::string_view {aka class absl::string_view}' has no member named 'ToString'\r\n   string key(std::move(parsed.FullKey().ToString()));\r\n                                         ^~~~~~~~\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/refcount.h:22,\r\n                 from ./tensorflow/core/platform/tensor_coding.h:21,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/types.h:31,\r\n                 from ./tensorflow/contrib/verbs/verbs_util.h:21,\r\n                 from ./tensorflow/contrib/verbs/rdma.h:30,\r\n                 from ./tensorflow/contrib/verbs/rdma_mgr.h:24,\r\n                 from ./tensorflow/contrib/verbs/rdma_rendezvous_mgr.h:21,\r\n                 from tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc:18:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 7400.912s, Critical Path: 180.41s\r\nINFO: 10108 processes: 10108 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["@vyepishov this is a recurring issue which is similar to #21999 and #22113.\r\n\r\n@yongtang could you take a look at this? It seems some of the functions or files may be missing or not uploaded properly to the PR.", "@vyepishov @wt-huang The PR #22003 was merged only later than 1.11.0rc1. Though the PR is in the master now so the issue is fixed.\r\n\r\nOn the other hand, due to some other changes recently, the verbs is broken in the master. I have created a PR #22415 to fix the build.", "It is still reproducible in the r1.11.0rc2 version with CUDA 10.0, CuDNN 7.3.0, and NCCL 2.3.4.\r\nThe cause of the error is still exactly the same.", "@yongtang Thanks for the PR! Noticed that some of the files may still be missing or not merged properly. Could you look into this?", "The PR #22415 has been approved and is pending merge. The issue should be resolved once #22415 is merged internally.", "The issue is still reproducible during the tensorflow 1.12 build.\r\nIt was NOT reproducible in tensorflow 1.12rc1 and 1,12rc2.\r\nMy setup:\r\n- Linux Ubuntu 18.04\r\n- TensorFlow installed from source\r\n- TensorFlow version: 1.12\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 0.19\r\n- GCC/Compiler version (if compiling from source): 7.3.0", "any fix for this? ", "Same issue here with 1.13\r\n\r\n- Linux Ubuntu 18.04\r\n- TensorFlow 1.13\r\n- Python 3.6\r\n- Bazel 19.2\r\n- GCC 4.8", "Something similar is reproducible on TensorFlow 1.15.3+nv20.07, NVIDIA's fork of 1.15.3 with A100 support:\r\n\r\n```\r\ntensorflow-1.15.3-nv20.07/tensorflow/python/BUILD:4597:1: Linking of rule '//tensorflow/python:_tf_stack.so' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n```", "Turns out this happens because `third_party/gpus/cuda_configure.bzl` has a hardcoded path to libtools, here:\r\n`cuda_defines[\"%{linker_bin_path_flag}\"] = 'flag: \"-B/usr/bin\"'`\r\n\r\nIf you have a system with a broken libtools (like Redhat/CentOS 7) and have your properly patched libtools somewhere else, Bazel will ignore this since someone didn't think this through when decided to hardcode a binary.", "> Turns out this happens because `third_party/gpus/cuda_configure.bzl` has a hardcoded path to libtools, here:\r\n> `cuda_defines[\"%{linker_bin_path_flag}\"] = 'flag: \"-B/usr/bin\"'`\r\n> \r\n> If you have a system with a broken libtools (like Redhat/CentOS 7) and have your properly patched libtools somewhere else, Bazel will ignore this since someone didn't think this through when decided to hardcode a binary.\r\n\r\ni meet the same problem when i compile tf1.15.x + cuda11 + cudnn8 + ubuntu18.04\uff0cwhat should i do to solve this problem?\r\n\r\n", "\r\n> i meet the same problem when i compile tf1.15.x + cuda11 + cudnn8 + ubuntu18.04\uff0cwhat should i do to solve this problem?\r\n\r\nI gave up and I'm using NVIDIA's container version :-(", "> > Turns out this happens because `third_party/gpus/cuda_configure.bzl` has a hardcoded path to libtools, here:\r\n> > `cuda_defines[\"%{linker_bin_path_flag}\"] = 'flag: \"-B/usr/bin\"'`\r\n> > If you have a system with a broken libtools (like Redhat/CentOS 7) and have your properly patched libtools somewhere else, Bazel will ignore this since someone didn't think this through when decided to hardcode a binary.\r\n> \r\n> i meet the same problem when i compile tf1.15.x + cuda11 + cudnn8 + ubuntu18.04\uff0cwhat should i do to solve this problem?\r\n\r\n+1 I meet the same problem,1.15+cuda11+cudnn8+ubuntu16.04. either gcc 5.4 nor 7"]}, {"number": 22371, "title": "Fix trt allocator, convert nodes logic, etc", "body": "This PR fixes a few things:\r\n\r\n1. broken python tests caused by string<->bytes conversion issue in python 3\r\n2. #21248, whose root-cause is the converter sets the ITensor name multiple times which change the input binding name incorrectly\r\n3. naming conflicts in `RegisterSegmentFunctionToFunctionLibrary` (function parameter and local variable have same name `name`)\r\n4. trt allocator crashes when allocating 0 size tensors. I also change the type of all size related parameters from size_t to int64_t, since on different platforms size_t have different meanings.", "comments": ["@pooyadavoodi please help to take a look, thanks.", "All looks good. Thanks @aaroey "]}, {"number": 22370, "title": "model_to_estimator not working on float16", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n   custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n    Linux\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n   N/A\r\n- **TensorFlow installed from (source or binary)**:\r\n   Binary\r\n- **TensorFlow version (use command below)**:\r\n    Codalab\r\n- **Python version**:\r\n   Codalb\r\n- **Bazel version (if compiling from source)**:\r\n  N/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\n  N/A\r\n- **CUDA/cuDNN version**:\r\n  N/A\r\n- **GPU model and memory**:\r\n  N/a\r\n- **Exact command to reproduce**:\r\n  You can run exactly this code on colab\r\n\r\n### Describe the problem\r\nUsing float16 crash `model_to_estimator`\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nfrom tensorflow import keras as ks\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.estimator import keras as keras_lib\r\n\r\nks.backend.clear_session()\r\nks.backend.set_floatx('float16')\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\nmy_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"digit_a\": np.array(np.random.rand(1, 27, 27, 1).astype(np.float32))},\r\n    y={\"mydense\": np.array(np.random.rand(1,1).astype(np.float32))},\r\n      batch_size=500,\r\n      num_epochs=1,\r\n      shuffle=False)\r\n\r\n# First, define the modules\r\ndigit_input = ks.Input(shape=(299, 299, 3), name=\"digit_input\")\r\nvision_model= ks.applications.xception.Xception(input_tensor=digit_input, include_top=False, weights='imagenet',classes=1)\r\n\r\n\r\n# Then define the tell-digits-apart model\r\ndigit_a = ks.Input(shape=(299, 299, 3), name=\"digit_a\")\r\n\r\n# The vision model will be shared, weights and all\r\nout_a = vision_model(digit_a)\r\n\r\n\r\nout = ks.layers.Dense(1, activation='sigmoid', name=\"mydense\")(out_a)\r\n\r\nm2 = ks.Model([digit_a], out, name=\"Xception_enc\")\r\n\r\nm2.compile(loss={ 'mydense': 'binary_crossentropy'},optimizer=tf.keras.optimizers.Adam())\r\n\r\n\r\nest = keras_lib.model_to_estimator(\r\n            keras_model=m2,\r\n            config=tf.estimator.RunConfig(session_config=tf.ConfigProto(log_device_placement=True)))\r\n````\r\n\r\nLOG:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-9-03750f8e4923> in <module>()\r\n     37 est = keras_lib.model_to_estimator(\r\n     38             keras_model=m2,\r\n---> 39             config=tf.estimator.RunConfig(session_config=tf.ConfigProto(log_device_placement=True)))\r\n     40 \r\n     41 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/keras.py in model_to_estimator(keras_model, keras_model_path, custom_objects, model_dir, config)\r\n    546                            estimator,\r\n    547                            custom_objects,\r\n--> 548                            keras_weights)\r\n    549   elif keras_model.built:\r\n    550     logging.warning('You are creating an Estimator from a Keras model '\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/keras.py in _save_first_checkpoint(keras_model, estimator, custom_objects, keras_weights)\r\n    455         if not model.train_function:\r\n    456           # pylint: disable=protected-access\r\n--> 457           model._make_train_function()\r\n    458           K._initialize_variables(sess)\r\n    459           # pylint: enable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _make_train_function(self)\r\n    596           # Training updates\r\n    597           updates = self.optimizer.get_updates(\r\n--> 598               params=self._collected_trainable_weights, loss=self.total_loss)\r\n    599         # Unconditional updates\r\n    600         updates += self.get_updates_for(None)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizers.py in get_updates(self, loss, params)\r\n    478 \r\n    479     for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\r\n--> 480       m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\r\n    481       v_t = (self.beta_2 * v) + (1. - self.beta_2) * math_ops.square(g)\r\n    482       if self.amsgrad:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in _run_op(a, *args)\r\n    856       # pylint: disable=protected-access\r\n    857       value = a._AsTensor()\r\n--> 858       return tensor_oper(value, *args)\r\n    859 \r\n    860     # Propagate __doc__ to wrapper\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\r\n    851       elif not isinstance(y, sparse_tensor.SparseTensor):\r\n    852         try:\r\n--> 853           y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\r\n    854         except TypeError:\r\n    855           # If the RHS is not a tensor, it might be a tensor aware object\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\r\n    996       name=name,\r\n    997       preferred_dtype=preferred_dtype,\r\n--> 998       as_ref=False)\r\n    999 \r\n   1000 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1092 \r\n   1093     if ret is None:\r\n-> 1094       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1095 \r\n   1096     if ret is NotImplemented:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _TensorConversionFunction(v, dtype, name, as_ref)\r\n    796       raise ValueError(\r\n    797           \"Incompatible type conversion requested to type '%s' for variable \"\r\n--> 798           \"of type '%s'\" % (dtype.name, v.dtype.name))\r\n    799     if as_ref:\r\n    800       return v._ref()  # pylint: disable=protected-access\r\n\r\nValueError: Incompatible type conversion requested to type 'float16' for variable of type 'float32'\r\n```\r\n/cc @tanzhenyu ", "comments": ["During the graph copying process, dtype is probably not copied, and I am under the impression that float16 is not supported in Estimator at all. As we're getting into 2.0, I would suggest you to use tf.Kears natively.\r\nClosing it for now, but let me know if you have any other concerns, thanks!"]}, {"number": 22368, "title": "Accepts `PathLike` objects for dataset readers", "body": "Continuation from #17465\r\n* Dataset operations convert `PathLike` objects to string\r\n* `compat.path_to_str` now accepts one or more objects to convert\r\n* Unit tests\r\n\r\nFurther work to #15784 to allow `PathLike` objects to be passed to Dataset readers as well. ", "comments": ["@qlzh727 how are the required checks triggered here? They are listed as required but still waiting, is this usual", "Lint is failing for this change. See more details in https://source.cloud.google.com/results/invocations/00af55ab-8a63-48e9-9ddf-22e9764663d4/log. \r\n\r\nMostly its related to py formet, eg, 4 space indent vs 2 space indent.", "Thanks @qlzh727 \r\nRan pylint on python file changes and fixed issues. There were still three notices on tensorflow/python/util/compat.py of:\r\n```\r\ntensorflow/python/util/compat.py:58:2: R1705: Unnecessary \"elif\" after \"return\" (no-else-return)\r\ntensorflow/python/util/compat.py:80:2: R1705: Unnecessary \"elif\" after \"return\" (no-else-return)\r\ntensorflow/python/util/compat.py:109:2: R1705: Unnecessary \"else\" after \"return\" (no-else-return)\r\n```\r\nI hadn't made changes to these lines in this PR so didn't change. \r\n\r\nAll my changes for compat.py, compat_test.py and readers.py are now fixed for linting", "@qlzh727 noticed a couple of checks failing:\r\nFrom sanity checks (I'm not sure what the fix for these are, can you suggest?)\r\n- 10. do_check_load_py_test: Check load py_test: Check that BUILD files with py_test target properly load py_test\r\n- do_buildifier: buildifier check\r\n\r\nAnd the XLA check? Any suggestions or changes needed before merge?\r\n", "Thanks @qlzh727 updated with your suggested cleanups", "@qlzh727 can the checks be run again to get an updated status on where this PR is at?", "Sorry for the delay, kicking off new tests now.", "@qlzh727 seems like some of the builds failed, but seem unrelated to the files changed in this PR. Do you have suggestions on a fix?", "The error message was buried in the log and bit hard to find, but here it is.\r\n\r\n=== Sanity check step 4 of 12: do_buildifier (buildifier check) ===\r\nRunning do_buildifier on 386 files\r\ntensorflow/python/BUILD # reformat listsort unsafesort sort:py_test.deps\r\nbuildifier took 0 s\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\n3713d3712\r\n<         \":client_testlib\",\r\n3715,3716c3714,3716\r\n<         \":util\"\r\n<     ]\r\n---\r\n>         \":client_testlib\",\r\n>         \":util\",\r\n>     ],\r\nPlease fix manually or run buildifier <file> to auto-fix.", "it requires \",\" for each of the deps.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@qlzh727 fixed that error with commas on the BUILD file\r\n\r\nAlso rebased from master to get the PR up to date", "It has been 29 days that this pull-request has stalled. Please create a new pull-request with the requested changes.", "The PR need to rebase again. Please do so if this is still active. Thanks and sorry for the late reply.", "@qlzh727 thanks. I've rebased with master now. Thanks for the ongoing work on this and appreciate the feedback and involvement", "It has been 28 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 22367, "title": "a problem about using the tflite_convert", "body": "### System information\r\n- **Have I written custom code**:  NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NO\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu==1.9\r\n- **TensorFlow version (use command below)**: 1.9 GPU\r\n- **Python version**: python 27\r\n- **Bazel version (if compiling from source)**: NO\r\n- **GCC/Compiler version (if compiling from source)**: \r\n- **CUDA/cuDNN version**: CUDA9.0 cuDNN 7.0\r\n- **GPU model and memory**: GTX1070 8G\r\n\r\n### Describe the problem\r\n   I want to conver the inception_v3 from .ckpt to .tflite, but I meet a problem when I conver the .pb to .tflite,    I use the following method\r\n\r\n 1)  download the inception_v3_2016_08_28.tar.gz from  https://github.com/tensorflow/models/tree/master/research/slim\r\ndecompression it and move to /tmp\r\n\r\n2)  Export nception_v3_inf_graph.pb file that without parameters\r\n` cd /mypath/models-master/research/slim`\r\n`python export_inference_graph.py --model_name=inception_v3 --output_file=/tmp/inception_v3_inf_graph.pb`\r\n\r\n3)  freezon the pb file\r\n`cd /mypath/tensorflow-master/tensorflow/python/training`\r\n`python freeze_graph.py --input_graph=/tmp/inception_v3_inf_graph.pb --input_checkpoint=/tmp/inception_v3.ckpt --output_graph=/tmp/inception_v3_frozen_graph.pb  --input_binary=true --output_node_names=InceptionV3/Predictions/Reshape_1`\r\n\r\n4)  quantized pb file\r\n`cd /mypath/tensorflow-master/tensorflow/tools/quantization`\r\n`python quantize_graph.py --input=/tmp/inception_v3_frozen_graph.pb --output=/tmp/inception_v3_quantized.pb --output_node_names=\"InceptionV3/Predictions/Reshape_1\" --mode=eightbit`\r\n\r\nabove steps all successed, but\r\n\r\n5)  .pb-->. tflite\r\n`tflite_convert  --output_file=/tmp/inception_v3_quantized.tflite  --graph_def_file=/tmp/inception_v3_quantized.pb --inference_type=QUANTIZED_UINT8 --input_arrays=input --output_arrays=InceptionV3/Predictions/Reshape_1 --mean_values=128  --std_dev_values=127`\r\n\r\n### Source code\r\n`tflite_convert  --output_file=/tmp/inception_v3_quantized.tflite  --graph_def_file=/tmp/inception_v3_quantized.pb --inference_type=QUANTIZED_UINT8 --input_arrays=input --output_arrays=InceptionV3/Predictions/Reshape_1 --mean_values=128  --std_dev_values=127`\r\n\r\n### Source  logs\r\n\r\n2018-09-19 10:54:02.077094: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-19 10:54:02.163219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-09-19 10:54:02.163667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8225\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.92GiB freeMemory: 7.77GiB\r\n2018-09-19 10:54:02.163682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\r\n2018-09-19 10:54:02.346515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-19 10:54:02.346548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \r\n2018-09-19 10:54:02.346555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \r\n2018-09-19 10:54:02.346742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7502 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"/home/icare/.local/bin/tflite_convert\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 121, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/lite.py\", line 309, in convert\r\n    allow_custom_ops=self.allow_custom_ops)\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 225, in toco_convert\r\n    input_data.SerializeToString())\r\n  File \"/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 107, in toco_convert_protos\r\n    (stdout, stderr))\r\nRuntimeError: TOCO failed see console for info.\r\n2018-09-19 10:54:03.713531: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.713589: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.713603: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.713612: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.713620: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.713657: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.713668: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.713687: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.713711: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.713719: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.713741: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.713787: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.713797: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.713829: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.713841: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.713862: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.713884: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.713929: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.713939: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.713962: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedMaxPool\r\n2018-09-19 10:54:03.713980: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714003: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714012: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714034: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714066: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.714108: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714120: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714129: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714137: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714173: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714183: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.714193: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedMaxPool\r\n2018-09-19 10:54:03.714212: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714224: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714232: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714241: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714275: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714286: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.714295: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714314: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714325: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714334: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714343: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714376: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714387: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.714418: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714431: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714440: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714448: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714482: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714492: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.714501: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714519: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714530: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714539: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714548: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714581: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714591: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.714614: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714626: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714635: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714643: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714681: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714692: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.714717: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714729: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714738: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714746: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714779: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714790: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.714798: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714808: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.714827: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714839: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714847: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714889: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714900: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.714909: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.714941: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.714953: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.714964: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.714973: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.714981: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715015: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715025: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.715034: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715061: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715073: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.715084: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.715093: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.715102: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715135: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715146: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.715171: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.715183: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.715192: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.715201: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715235: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715245: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.715254: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715281: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715293: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.715304: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.715312: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.715321: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715353: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715364: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.715387: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.715399: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.715408: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.715417: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715451: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715462: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.715488: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.715500: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.715508: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.715517: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715551: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715562: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.715570: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715589: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715600: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.715620: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.715631: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.715640: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.715649: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715686: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715696: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.715705: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715738: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715750: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.715760: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.715769: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.715778: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715811: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715821: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.715829: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715868: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.715879: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.715888: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.715896: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.715929: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.715940: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.715965: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.715977: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.715985: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.715994: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.716027: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.716037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.716046: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.716074: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.716085: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.716096: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.716105: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.716114: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.716148: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.716158: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.716180: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.716192: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.716201: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.716209: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.716242: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.716253: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.716278: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.716290: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.716299: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.716308: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.716341: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.716351: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.716360: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.716379: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.716390: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.716410: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.716422: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.716430: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.716439: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.716473: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.716483: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.716492: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.716875: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.716890: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.716901: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.716910: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.716918: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.716955: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.716966: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.716974: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717004: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717016: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.717027: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.717036: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.717044: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717087: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.717111: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.717122: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.717132: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.717140: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717176: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717187: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.717213: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.717224: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.717233: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.717242: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717276: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717286: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.717295: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717314: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717324: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedMaxPool\r\n2018-09-19 10:54:03.717335: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717381: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717394: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.717405: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.717414: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.717422: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717456: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717466: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.717474: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717512: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717524: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.717535: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.717543: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.717552: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717587: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717597: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.717627: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.717639: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.717648: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.717656: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717690: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717701: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.717735: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.717748: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.717759: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.717768: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717804: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717814: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.717823: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717860: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717872: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.717883: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.717892: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.717901: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.717934: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.717945: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.717975: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.717987: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.717995: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.718004: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718039: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718049: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.718079: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.718091: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.718100: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.718109: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718145: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718155: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.718185: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.718197: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.718206: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.718215: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718262: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718273: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.718309: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.718321: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.718330: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.718339: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718373: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718383: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.718392: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718418: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718429: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.718465: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.718477: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.718486: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.718495: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718530: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718540: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.718549: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718597: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718610: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.718621: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.718629: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.718639: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718674: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718684: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.718693: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718734: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718747: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.718758: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.718767: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.718775: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718810: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718821: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.718857: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.718869: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.718878: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.718887: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.718923: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.718933: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.718974: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.718987: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.718996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.719004: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719040: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719050: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.719059: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719101: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719114: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.719125: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.719134: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.719143: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719179: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719189: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.719225: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.719237: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.719247: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.719256: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719291: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719302: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.719339: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.719351: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.719360: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.719369: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719405: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719416: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.719452: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.719465: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.719474: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.719483: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719518: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719529: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.719570: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.719582: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.719592: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.719600: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719637: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719648: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.719656: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719677: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719688: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.719724: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.719736: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.719745: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.719754: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719790: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719801: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.719809: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719857: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719870: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.719881: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.719890: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.719899: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719936: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.719947: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.719955: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.719996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720009: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.720020: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.720028: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.720037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720073: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720083: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.720119: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.720132: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.720141: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.720150: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720187: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720198: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.720239: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.720251: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.720260: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.720269: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720305: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720316: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.720325: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720364: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.720388: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.720397: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.720406: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720441: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720452: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.720488: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.720500: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.720509: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.720518: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720554: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720564: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.720601: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.720614: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.720623: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.720631: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720667: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720678: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.720715: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.720727: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.720736: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.720745: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720780: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720791: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.720831: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.720844: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.720852: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.720861: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720897: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720908: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.720917: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.720937: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.720948: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.720983: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.720996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.721005: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.721014: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721050: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721061: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.721070: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721118: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721131: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.721142: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.721151: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.721160: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721195: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721205: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.721214: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721257: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721270: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.721281: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.721289: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.721298: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721334: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721344: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.721390: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.721402: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.721412: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.721420: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721456: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721467: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.721515: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.721528: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.721537: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.721546: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721582: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721593: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.721602: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721646: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721659: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.721670: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.721679: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.721687: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721723: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721734: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.721779: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.721791: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.721800: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.721808: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721845: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721855: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.721899: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.721912: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.721921: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.721930: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.721966: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.721977: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.722021: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.722037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.722046: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.722056: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722091: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722102: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.722146: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.722158: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.722167: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.722175: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722212: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722223: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.722232: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722252: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722263: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.722298: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.722310: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.722319: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.722328: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722365: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722376: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.722385: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722442: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722456: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.722467: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.722475: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.722484: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722520: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722530: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.722611: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.722623: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.722632: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.722641: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722680: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722690: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.722699: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722741: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722754: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.722765: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.722774: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.722783: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722819: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722829: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.722875: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.722887: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.722896: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.722905: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.722943: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.722953: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.722998: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.723010: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.723020: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.723028: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723065: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.723076: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.723128: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.723140: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.723149: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.723158: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723245: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.723257: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.723266: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723287: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.723298: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedMaxPool\r\n2018-09-19 10:54:03.723308: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723382: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.723395: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.723406: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.723415: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.723423: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723460: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.723471: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.723480: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723556: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.723570: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.723581: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.723590: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.723598: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723634: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.723645: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.723708: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.723720: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.723729: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.723738: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723774: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.723784: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.723793: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723860: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.723872: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.723882: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.723890: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.723928: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.723938: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.723948: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.724042: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.724055: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.724066: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.724075: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.724084: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.724121: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.724132: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.724701: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.724719: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.724728: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.724737: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.724775: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.724786: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.724851: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.724864: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.724873: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.724881: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.724918: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.724928: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.724937: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725000: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.725013: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.725022: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.725030: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725068: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.725079: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.725087: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725113: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.725124: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.725171: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.725183: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.725192: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.725201: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725237: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.725248: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.725256: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725357: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.725371: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.725382: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.725390: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.725399: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725435: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.725446: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.725455: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725562: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.725576: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.725587: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.725596: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.725604: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725643: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.725654: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.725718: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.725730: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.725739: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.725748: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725786: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.725796: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.725805: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725870: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.725882: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.725891: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.725899: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.725936: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.725947: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.725955: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.726322: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.726337: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.726348: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.726356: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.726364: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.726408: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.726420: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.726984: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.727001: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.727010: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.727019: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.727058: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.727069: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.727132: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.727145: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.727154: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.727163: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.727200: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.727211: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.727219: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.727282: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.727294: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.727303: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.727312: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.727348: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.727359: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.727367: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.727393: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.727404: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.727464: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.727476: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.727484: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.727493: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.727529: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.727539: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedRelu\r\n2018-09-19 10:54:03.727548: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.727574: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.727585: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedAvgPool\r\n2018-09-19 10:54:03.728329: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedConv2D\r\n2018-09-19 10:54:03.728346: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.728356: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.728374: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedBiasAdd\r\n2018-09-19 10:54:03.728384: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: RequantizationRange\r\n2018-09-19 10:54:03.728393: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Requantize\r\n2018-09-19 10:54:03.728402: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.728429: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.728439: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedReshape\r\n2018-09-19 10:54:03.728448: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.728475: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizeV2\r\n2018-09-19 10:54:03.728485: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: QuantizedReshape\r\n2018-09-19 10:54:03.728494: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Dequantize\r\n2018-09-19 10:54:03.794554: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1479 operators, 3498 arrays (0 quantized)\r\n2018-09-19 10:54:03.893920: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1479 operators, 3498 arrays (0 quantized)\r\n2018-09-19 10:54:04.023420: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 1292 operators, 3014 arrays (1 quantized)\r\n2018-09-19 10:54:04.147459: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 1292 operators, 3014 arrays (1 quantized)\r\n2018-09-19 10:54:04.224980: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 1292 operators, 3014 arrays (1 quantized)\r\n2018-09-19 10:54:04.322794: F tensorflow/contrib/lite/toco/tooling_util.cc:1589] Array InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D_eightbit_min_input, which is an input to the (Unsupported TensorFlow op: QuantizeV2) operator producing the output array InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D_eightbit_quantize_input, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\r\nAborted (core dumped)\r\n\r\nNone\r\n\r\n\r\n\r\nI also try\r\n### Source code\r\n`tflite_convert  --output_file=/tmp/inception_v3_quantized.tflite  --graph_def_file=/tmp/inception_v3_quantized.pb --inference_type=QUANTIZED_UINT8 --input_arrays=input --output_arrays=InceptionV3/Predictions/Reshape_1 --mean_values=128  --std_dev_values=127 --default_ranges_min=0 --default_ranges_max=6`\r\n\r\n\r\n` tflite_convert  --output_file=/tmp/inception_v3_quantized.tflite  --graph_def_file=/tmp/inception_v3_frozen_graph.pb --inference_type=QUANTIZED_UINT8 --input_arrays=input --output_arrays=InceptionV3/Predictions/Reshape_1 --mean_values=128  --std_dev_values=127 --default_ranges_min=0 --default_ranges_max=6`\r\n\r\n### Source log\r\n\r\nusage: tflite_convert [-h] --output_file OUTPUT_FILE\r\n                      (--graph_def_file GRAPH_DEF_FILE | --saved_model_dir SAVED_MODEL_DIR)\r\n                      [--output_format {TFLITE,GRAPHVIZ_DOT}]\r\n                      [--inference_type {FLOAT,QUANTIZED_UINT8}]\r\n                      [--inference_input_type {FLOAT,QUANTIZED_UINT8}]\r\n                      [--input_arrays INPUT_ARRAYS]\r\n                      [--input_shapes INPUT_SHAPES]\r\n                      [--output_arrays OUTPUT_ARRAYS]\r\n                      [--saved_model_tag_set SAVED_MODEL_TAG_SET]\r\n                      [--saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY]\r\n                      [--std_dev_values STD_DEV_VALUES]\r\n                      [--mean_values MEAN_VALUES]\r\n                      [--default_ranges_min DEFAULT_RANGES_MIN]\r\n                      [--default_ranges_max DEFAULT_RANGES_MAX]\r\n                      [--drop_control_dependency DROP_CONTROL_DEPENDENCY]\r\n                      [--reorder_across_fake_quant REORDER_ACROSS_FAKE_QUANT]\r\n                      [--change_concat_input_ranges CHANGE_CONCAT_INPUT_RANGES]\r\n                      [--allow_custom_ops ALLOW_CUSTOM_OPS]\r\ntflite_convert: error: --default_ranges_min and --default_ranges_max must be used together\r\n\r\n\r\nHow should I solve the problem ?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "I have updated them", "There was an error in TensorFlow 1.9 that didn't detect `--default_ranges_min=0` as a valid value. Can you update your TensorFlow verison to 1.10 or tf-nightly (`pip install tf-nightly`) and try to convert your model?", "Thank you very much , I  tried pip install tf-nightly,  and solved the problem"]}]