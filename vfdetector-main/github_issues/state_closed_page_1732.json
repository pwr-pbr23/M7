[{"number": 938, "title": "apply_gradients.run seems to leak memory", "body": "I'm running a large scale network with tensorflow and I keep getting memory errors, so I pull out memory_profiler and found this \n\nFilename: parameterservermodel.py\n\nLine    Memtotal    Increment   Line Contents\n   110   2121.9 MiB     39.2 MiB            self.apply_gradients.run(session=self.session, feed_dict=feed_dict)\n\nIf I'm not mistaken, it looks like like apply_gradients.run allocates almost 40MB and doesn't return anything for me to free. I might be missing something here. \n", "comments": ["Looks like the memory_profiler has a lag, it was a previous line in the code that was causing it.\n"]}, {"number": 937, "title": "Build fail on OSX (@ 2cb25ab)", "body": "I recently refreshed my master and now build fails on my laptop. Also tried building from a fresh clone. That fails too.\n\n```\nbazel build -c opt //tensorflow/tools/pip_package:build_pip_package\n.........\nERROR: /Users/delip/Softwares/tensorflow/tensorflow/models/embedding/BUILD:10:6: syntax error at '\"//tensorflow:tensorflow.bzl\"': First argument of load() is a path, not a label. It should start with a single slash if it is an absolute path..\n...\n```\n\nI just noticed now that Jenkins status is red for OSX too. Until this gets fixed, what is the latest commit for which OSX builds were working? Also, any tips on fixing this locally will help too. I'm not conversant with Bazel, unfortunately.\n", "comments": ["After digging, I noticed there another thread (https://github.com/tensorflow/tensorflow/issues/927) similar to this. Closing this and continuing conversation there.\n"]}, {"number": 936, "title": "Reduce 1_notmnist.ipynb memory requirements.", "body": "Lots of people are having trouble downloading and pickling the data. need to look into ways to make that easier.\n", "comments": ["Please Vincent add also an intermediate pickle of the dataset. The first cell where train and test is formed is slow to run every time you break your notebook session.\n", "@bhack under which conditions do you 'lose' the pickle? Is it because you're using an ephemeral docker container?\n", "I don't lose the pickle but I think it is better to save also another one at an intermediate point. What happens if people doesn't run the pickle step? You have a safe condition  for not run again the download but some cell are also heavy so it is safer to save train and test set as soon are formed.\n", "@rthouvenin your approach is a net improvement over the status quo.\nWould you be ok cleaning it up (in a way that can be easily diffed) and sending me a PR?\nhttps://github.com/rthouvenin/tensorflow/blob/notmnist-lowmem/tensorflow/examples/udacity/1_notmnist.ipynb\n", "Sure, just opened the PR (I got what you meant by easily diffed, notebook doesn't play nicely on that aspect... :)).\n\nThough I did not have trouble to download the files (it just took time), I was also a bit scared it would be difficult as my connection is quite erratic sometimes. I don't think there is much to be done, but I would suggest warning the reader about it, and suggesting them to download the file separately if they have a slow / not reliable connection (e.g. with a download manager that support pause/resume). \nTo help with that, maybe a torrent link could be set up (I didn't check if there is already one).\n", "@vincentvanhoucke Ok the intermediate pickling is introduced in @rthouvenin PR.\n"]}, {"number": 935, "title": "Python PIP test-on-install", "body": "PIP package is built and installed in a Docker container. Then the Python unit tests in the TF source are moved to a separate folder and ran with the plain Python environment without Blaze.\n\nFour out of 151 tests were skipped for now due to dependency on modules in TF source that are not publicly exported.\n\nTests performed: Jenkins experimental builds for CPU and GPU Python test-on-install, see passing results at: \nhttp://ci.tensorflow.org/view/Experimental/job/experimental-cais-tensorflow-cpu-python27-copt_pip_install-test/1/consoleFull\nhttp://ci.tensorflow.org/view/Experimental/job/experimental-cais-tensorflow-gpu-python27-copt_pip_install-test/1/consoleFull\n", "comments": ["Can one of the admins verify this patch?\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "Can you either sign the CLA for your other email address or amend the\ncommits (or squash them) to use only your CLA-ok email?\nOn Fri, Jan 29, 2016 at 08:30 caisq notifications@github.com wrote:\n\n> PIP package is built and installed in a Docker container. Then the Python\n> unit tests in the TF source are moved to a separate folder and ran with the\n> plain Python environment without Blaze.\n> \n> Four out of 151 tests were skipped for now due to dependency on modules in\n> TF source that are not publicly exported.\n> \n> Tests performed: Jenkins experimental builds for CPU and GPU Python\n> test-on-install, see passing results at:\n> \n> http://ci.tensorflow.org/view/Experimental/job/experimental-cais-tensorflow-cpu-python27-copt_pip_install-test/1/consoleFull\n> \n> ## http://ci.tensorflow.org/view/Experimental/job/experimental-cais-tensorflow-gpu-python27-copt_pip_install-test/1/consoleFull\n> \n> You can view, comment on, or merge this pull request online at:\n> \n>   https://github.com/tensorflow/tensorflow/pull/935\n> Commit Summary\n> - Python PIP test on install\n> - Improving test_on_install.sh\n> - Minor topy fix\n> \n> File Changes\n> - _M_ tensorflow/tools/ci_build/Dockerfile.cpu\n>   https://github.com/tensorflow/tensorflow/pull/935/files#diff-0 (8)\n> - _M_ tensorflow/tools/ci_build/Dockerfile.gpu\n>   https://github.com/tensorflow/tensorflow/pull/935/files#diff-1 (9)\n> - _A_ tensorflow/tools/ci_build/builds/test_on_install.sh\n>   https://github.com/tensorflow/tensorflow/pull/935/files#diff-2 (120)\n> - _A_ tensorflow/tools/ci_build/ci_test_on_install.sh\n>   https://github.com/tensorflow/tensorflow/pull/935/files#diff-3 (81)\n> \n> Patch Links:\n> - https://github.com/tensorflow/tensorflow/pull/935.patch\n> - https://github.com/tensorflow/tensorflow/pull/935.diff\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/935.\n", "One of the commits is created using \"cais cais@ci.tensorflow.org\", maybe just squash the commits, then you should be fine.\n", "I'm closing this pull request and creating a new one to address wicke's comments and the cla issue. See https://github.com/tensorflow/tensorflow/pull/939\n"]}, {"number": 934, "title": "Adding --recurse-submodules flag to git clone in ci_bulid README", "body": "This simple doc fix is related to issue: https://github.com/tensorflow/tensorflow/issues/896\n", "comments": ["Can one of the admins verify this patch?\n", "merged.\n"]}, {"number": 933, "title": "thread pool does not execute all remaining tasks on shutdown", "body": "ThreadPool claims to finish all remaining work on shutdown. This is not the case. If remaining tasks submit new tasks, the new tasks do not get executed. This happens because the sentinel tasks are fetched before the newly submitted real tasks.\n\nThreadPool must either execute all pending work, or execute nothing on shutdown. It does not make sense to execute half of work.\n\nHere is a repro:\n\n``` c\nstatic void BM_ParallelDivide(int iters, const char* impl) {\n  THREAD_POOL_IMPL_NAME = impl;\n  for (int i = 0; i < iters; i++) {\n    const int kTasks = 10;\n    const int kLevels = 22;\n    std::atomic<unsigned> count(kTasks * (1 << kLevels));\n    mutex done_lock;\n    condition_variable done;\n    bool done_flag = false;\n    std::function<void(int)> work;\n    ThreadPool pool(Env::Default(), \"test\", kNumThreads);\n    work = [&pool, &work, &count, &done_lock, &done, &done_flag](int level) {\n      if (level-- > 0) {\n        pool.Schedule([&work, level]() { work(level); });\n        pool.Schedule([&work, level]() { work(level); });\n        return;\n      }\n      delay();\n    };\n    for (int t = 0; t < kTasks; ++t) {\n      pool.Schedule([&work]() {\n        work(kLevels);\n      });\n    }\n  }\n}\n```\n", "comments": ["Personally, I find this behaviour of performing potentially unlimited work in the destructor to be strange.  I think it would make more sense for the caller to explicitly ask for all work to be performed, and for the destructor to finish as fast as possible, even if it meant leaving work in the queue.\n", "@jeremybarnes I fine either way as long as it is documented. It is just the current implementation that does not make sense.\n", "Note that there are some places in the existing codebase (and tests) that assume this behavior.  I had to implement it in my PR in order to avoid deadlocks.\n", "@dvyukov, @rmlarsen: Is this resolved?  \n", "Yes, it's fixed. New thread pool waits for completion of all work.\n"]}, {"number": 932, "title": "thread pool deadlocks on shutdown", "body": "ThreadPool dtor does not pop waiters from waiters_ list. As the result dead waiters are left on the list. If remaining tasks submit new tasks, thread pool deadlocks because some notifications are consumed by the leftover dead waiters instead of alive threads that should receive the notifications.\n\nHere is a simple test that does classical parallel decomposition and reliably deadlocks:\n\n``` c\nstatic void BM_ParallelDivide(int iters, const char* impl) {\n  THREAD_POOL_IMPL_NAME = impl;\n  for (int i = 0; i < iters; i++) {\n    const int kTasks = 10;\n    const int kLevels = 22;\n    std::atomic<unsigned> count(kTasks * (1 << kLevels));\n    mutex done_lock;\n    condition_variable done;\n    bool done_flag = false;\n    std::function<void(int)> work;\n    ThreadPool pool(Env::Default(), \"test\", kNumThreads);\n    work = [&pool, &work, &count, &done_lock, &done, &done_flag](int level) {\n      if (level-- > 0) {\n        pool.Schedule([&work, level]() { work(level); });\n        pool.Schedule([&work, level]() { work(level); });\n        return;\n      }\n      delay();\n    };\n    for (int t = 0; t < kTasks; ++t) {\n      pool.Schedule([&work]() {\n        work(kLevels);\n      });\n    }\n  }\n}\n```\n", "comments": ["@zheng-xq: Do you have thoughts on this?  The non-blocking thread pool PR is problematic since it breaks Eigen's FIFO requirement, but the deadlock issue seems like something we should fix. \n", "@zheng-xq @girving \n\nOn Tue, Mar 8, 2016 at 8:08 PM, Zhifeng Chen wrote:\n\n> The thread calling 'delete p' should have the sole ownership of p, where p is generally any c++ object. \n> So, it's not valid if one thread is calling a threadpool p while another thread calling p->Add().\n\nThat's true. But the thread pool waits for the existing tasks to finish in destructor. If you combine these two points, you conclude that tasks are not allowed to submit child tasks to the thread pool. Ever. That's just does not make sense. So you need to either (1) wait for _all_ tasks to finish, including subtasks of existing tasks, or (2) don't wait in thread pool destructor at all, stop threads as soon as possible, assert that the queue is empty now and exit.\n\nI am working on a fix.\n", "@dvyukov, @rmlarsen: Did the recent thread pool changes resolve this?  \n", "@rmlarsen: Assigning you since @dvyukov isn't part of the Github org.  Should we add him? \n", "Yes, it's fixed. New thread pool waits for completion of all work.\n"]}, {"number": 931, "title": "Text window slider not working on TensorFlow.org Download and Setup page", "body": "On TensorFlow.org - Download and Setup page\n\nhttps://www.tensorflow.org/versions/master/get_started/os_setup.html\n\nUnder Pip Installation\nFor python3:\n\nthe text window slider does not allow you to slide to the right. \n\nIf works for the text window slider above under Install TensorFlow:\n\nAs a work around you can visit the instructions on the GitHub page\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md\n", "comments": ["It works for me. What browser are you using?\n", "Closing. Please reopen with more information if it persists.\n"]}, {"number": 930, "title": "installation shell script Improvement", "body": "merge improve and master\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 929, "title": "label_image deadlocks", "body": "I am on commit 14cd77baeb0ee6f4b40816afc1f8c9c5d186bb8e.\n\nI've added the following change that randomizes order of execution of tasks in thread pool:\n\n```\ndiff --git a/tensorflow/core/lib/core/threadpool.cc b/tensorflow/core/lib/core/threadpool.cc\nindex 50aec3e..03c4485 100644\n--- a/tensorflow/core/lib/core/threadpool.cc\n+++ b/tensorflow/core/lib/core/threadpool.cc\n@@ -20,6 +20,8 @@ limitations under the License.\n #include \"tensorflow/core/platform/tracing.h\"\n #include \"tensorflow/core/platform/types.h\"\n\n+#include <unistd.h>\n+\n namespace tensorflow {\n namespace thread {\n\n@@ -34,6 +36,7 @@ ThreadPool::ThreadPool(Env* env, const string& name, int num_threads)\n ThreadPool::ThreadPool(Env* env, const ThreadOptions& thread_options,\n                        const string& name, int num_threads)\n     : name_(name) {\n+  rand_ = getpid();\n   CHECK_GE(num_threads, 1);\n   string name_prefix = \"tf_\" + name_;\n   for (int i = 0; i < num_threads; i++) {\n@@ -102,6 +105,7 @@ void ThreadPool::WorkerLoop() {\n         w.cv.wait(l);\n       }\n     }\n+    std::swap(pending_[0], pending_[rand_r(&rand_) % pending_.size()]);\n     // Pick up pending work\n     Item item = pending_.front();\n     pending_.pop_front();\ndiff --git a/tensorflow/core/lib/core/threadpool.h b/tensorflow/core/lib/core/threadpool.h\nindex ef37dcf..ae1eef3 100644\n--- a/tensorflow/core/lib/core/threadpool.h\n+++ b/tensorflow/core/lib/core/threadpool.h\n@@ -66,6 +66,7 @@ class ThreadPool {\n   std::vector<Thread*> threads_;  // All threads\n   std::vector<Waiter*> waiters_;  // Stack of waiting threads.\n   std::deque<Item> pending_;      // Queue of pending work\n+  unsigned rand_;\n\n   TF_DISALLOW_COPY_AND_ASSIGN(ThreadPool);\n };\n```\n\nThen run label_image as:\n\n```\nwhile echo OK; do bazel-bin/tensorflow/examples/label_image/label_image; done\n```\n\nafter few iterations it deadlocks. All threads are blocked on condition variables, but tasks they are waiting for can't run because all thread pool threads are busy:\n\n```\n(gdb) info threads\n  Id   Target Id         Frame \n  97   Thread 0x7f0d04038700 (LWP 74836) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  96   Thread 0x7f0d03837700 (LWP 74837) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  95   Thread 0x7f0d03036700 (LWP 74838) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  94   Thread 0x7f0d02835700 (LWP 74839) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  93   Thread 0x7f0d02034700 (LWP 74840) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  92   Thread 0x7f0d01833700 (LWP 74841) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  91   Thread 0x7f0d01032700 (LWP 74842) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  90   Thread 0x7f0d00831700 (LWP 74843) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  89   Thread 0x7f0cf3fff700 (LWP 74844) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  88   Thread 0x7f0cf37fe700 (LWP 74845) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  87   Thread 0x7f0cf2ffd700 (LWP 74846) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  86   Thread 0x7f0cf27fc700 (LWP 74847) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  85   Thread 0x7f0cf1ffb700 (LWP 74848) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  84   Thread 0x7f0cf17fa700 (LWP 74849) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  83   Thread 0x7f0cf0ff9700 (LWP 74850) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  82   Thread 0x7f0ce7fff700 (LWP 74851) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  81   Thread 0x7f0ce77fe700 (LWP 74852) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  80   Thread 0x7f0ce6ffd700 (LWP 74853) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  79   Thread 0x7f0ce67fc700 (LWP 74854) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  78   Thread 0x7f0ce5ffb700 (LWP 74855) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  77   Thread 0x7f0ce57fa700 (LWP 74856) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  76   Thread 0x7f0ce4ff9700 (LWP 74857) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  75   Thread 0x7f0cdffff700 (LWP 74858) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  74   Thread 0x7f0cdf7fe700 (LWP 74859) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  73   Thread 0x7f0cdeffd700 (LWP 74860) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  72   Thread 0x7f0cde7fc700 (LWP 74861) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  71   Thread 0x7f0cddffb700 (LWP 74862) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  70   Thread 0x7f0cdd7fa700 (LWP 74863) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  69   Thread 0x7f0cdcff9700 (LWP 74864) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  68   Thread 0x7f0cdc7f8700 (LWP 74865) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  67   Thread 0x7f0cdbff7700 (LWP 74866) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  66   Thread 0x7f0cdb7f6700 (LWP 74867) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  65   Thread 0x7f0cdaff5700 (LWP 74868) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  64   Thread 0x7f0cda7f4700 (LWP 74869) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  63   Thread 0x7f0cd9ff3700 (LWP 74870) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  62   Thread 0x7f0cd97f2700 (LWP 74871) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  61   Thread 0x7f0cd8ff1700 (LWP 74872) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  60   Thread 0x7f0cd3fff700 (LWP 74873) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  59   Thread 0x7f0cd37fe700 (LWP 74874) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  58   Thread 0x7f0cd2ffd700 (LWP 74875) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  57   Thread 0x7f0cd27fc700 (LWP 74876) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  56   Thread 0x7f0cd1ffb700 (LWP 74877) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  55   Thread 0x7f0cd17fa700 (LWP 74878) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  54   Thread 0x7f0cd0ff9700 (LWP 74879) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  53   Thread 0x7f0cd07f8700 (LWP 74880) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  52   Thread 0x7f0ccfff7700 (LWP 74881) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  51   Thread 0x7f0ccf7f6700 (LWP 74882) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  50   Thread 0x7f0cceff5700 (LWP 74883) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  49   Thread 0x7f0cce7f4700 (LWP 74884) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  48   Thread 0x7f0ccdff3700 (LWP 74885) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  47   Thread 0x7f0ccd7f2700 (LWP 74886) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  46   Thread 0x7f0cccff1700 (LWP 74887) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  45   Thread 0x7f0cc7fff700 (LWP 74888) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  44   Thread 0x7f0cc77fe700 (LWP 74889) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  43   Thread 0x7f0cc6ffd700 (LWP 74890) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  42   Thread 0x7f0cc67fc700 (LWP 74891) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  41   Thread 0x7f0cc5ffb700 (LWP 74892) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  40   Thread 0x7f0cc57fa700 (LWP 74893) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  39   Thread 0x7f0cc4ff9700 (LWP 74894) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  38   Thread 0x7f0cb7fff700 (LWP 74895) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  37   Thread 0x7f0cb77fe700 (LWP 74896) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  36   Thread 0x7f0cb6ffd700 (LWP 74897) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n---Type <return> to continue, or q <return> to quit---\n  35   Thread 0x7f0cb67fc700 (LWP 74898) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  34   Thread 0x7f0cb5ffb700 (LWP 74899) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  33   Thread 0x7f0cb57fa700 (LWP 74900) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  32   Thread 0x7f0cb4ff9700 (LWP 74901) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  31   Thread 0x7f0caffff700 (LWP 74902) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  30   Thread 0x7f0caf7fe700 (LWP 74903) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  29   Thread 0x7f0caeffd700 (LWP 74904) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  28   Thread 0x7f0cae7fc700 (LWP 74905) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  27   Thread 0x7f0cadffb700 (LWP 74906) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  26   Thread 0x7f0cad7fa700 (LWP 74907) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  25   Thread 0x7f0cacff9700 (LWP 74908) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  24   Thread 0x7f0ca7fff700 (LWP 74909) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  23   Thread 0x7f0ca77fe700 (LWP 74910) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  22   Thread 0x7f0ca6ffd700 (LWP 74911) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  21   Thread 0x7f0ca67fc700 (LWP 74912) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  20   Thread 0x7f0ca5ffb700 (LWP 74913) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  19   Thread 0x7f0ca57fa700 (LWP 74914) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  18   Thread 0x7f0ca4ff9700 (LWP 74915) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  17   Thread 0x7f0ca47f8700 (LWP 74916) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  16   Thread 0x7f0ca3ff7700 (LWP 74917) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  15   Thread 0x7f0ca37f6700 (LWP 74918) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  14   Thread 0x7f0ca2ff5700 (LWP 74919) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  13   Thread 0x7f0ca27f4700 (LWP 74920) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  12   Thread 0x7f0ca1ff3700 (LWP 74921) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  11   Thread 0x7f0ca17f2700 (LWP 74922) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  10   Thread 0x7f0ca0ff1700 (LWP 74923) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  9    Thread 0x7f0c9bfff700 (LWP 74924) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  8    Thread 0x7f0c9b7fe700 (LWP 74925) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  7    Thread 0x7f0c9affd700 (LWP 74926) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  6    Thread 0x7f0c9a7fc700 (LWP 74927) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  5    Thread 0x7f0c99ffb700 (LWP 74928) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  4    Thread 0x7f0c997fa700 (LWP 74929) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  3    Thread 0x7f0c98ff9700 (LWP 74930) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  2    Thread 0x7f0c987f8700 (LWP 74931) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n* 1    Thread 0x7f0d0ad4c780 (LWP 74835) \"label_image\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n(gdb) thread 53\n[Switching to thread 53 (Thread 0x7f0cd07f8700 (LWP 74880))]\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n185 in ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S\n(gdb) bt\n#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n#1  0x00007f0d09fb94bc in __gthread_cond_wait (__mutex=<optimized out>, __cond=<optimized out>)\n    at /build/buildd/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/include/x86_64-linux-gnu/bits/gthr-default.h:864\n#2  std::condition_variable::wait (this=<optimized out>, __lock=...) at ../../../../../src/libstdc++-v3/src/c++11/condition_variable.cc:52\n#3  0x00000000004464fc in Eigen::Notification::WaitForNotification() ()\n#4  0x000000000064f49a in void Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>::packRhsAndKernel<Eigen::internal::packRhsAndKernelArg<float, float, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, Eigen::internal::blas_data_mapper<float, long, 0, 0>, long>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 8, 4, false, false> >(Eigen::internal::packRhsAndKernelArg<float, float, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, Eigen::internal::blas_data_mapper<float, long, 0, 0>, long>) ()\n#5  0x0000000000634b1f in std::_Function_handler<void (), std::_Bind<void (*(Eigen::internal::packRhsAndKernelArg<float, float, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, Eigen::internal::blas_data_mapper<float, long, 0, 0>, long>))(Eigen::internal::packRhsAndKernelArg<float, float, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, Eigen::internal::blas_data_mapper<float, long, 0, 0>, long>)> >::_M_invoke(std::_Any_data const&) ()\n#6  0x0000000000e44cef in std::_Function_handler<void (), tensorflow::thread::ThreadPoolDefaultImpl::ThreadPoolDefaultImpl(tensorflow::Env*, tensorflow::ThreadOptions const&, std::string const&, int)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\n#7  0x00007f0d09fbca40 in std::(anonymous namespace)::execute_native_thread_routine (__p=<optimized out>) at ../../../../../src/libstdc++-v3/src/c++11/thread.cc:84\n#8  0x00007f0d0a217184 in start_thread (arg=0x7f0cd07f8700) at pthread_create.c:312\n#9  0x00007f0d09a2a34d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\n```\n\nThis come up during testing of a faster thread pool implementation that has distributed queues and so does not preserve FIFO order. But I think it can come up with current pool as well (maybe after some unrelated code changes, or maybe just due to unlucky scheduling order).\n\nComputational tasks running on a fixed-size thread pool must not ever block. Instead they should schedule continuations. Besides deadlocks blocking leads to serious CPU underutilization. I.e. on my machine label_image utilizes only about half of cores, because half of threads in pool are blocked waiting for other tasks.\n", "comments": ["@jeremybarnes I wonder didn't you this with your pool?\n", "(I've been submerged for the last couple of weeks, and I didn't see the notification).\n\nI didn't see any deadlocks, but I can see that they are definitely possible on any thread pool that doesn't know to schedule a new thread if a worker thread blocks.  We need to be very careful in any bounded thread scenario, as it's not possible to guarantee progress in the general case on a finite number of threads.\n\nIn general the pattern I use to work around these kind of deadlocks with a fixed number of threads is to poll instead of block, and perform work from the threadpool after un unsuccessful poll to guarantee forward progress.  That would require some deeper changes to Eigen so that it knew it was in a worker thread and could adjust its behaviour accordingly.\n", "Thanks, Jeremy. To clarify, you run label_image with your pool and did not see deadlocks; or you did not run label_image and did not see deadlocks?\n\nPulling for work while waiting can help to some degree, but it still has problems when blocked tasks stack up on a single thread:\n1. Stack can grow without limit and cause stack overflow, and you can't limit recursion at runtime because then you get back to deadlocks.\n2. This limit available parallelism: a task can be already ready to run but is sitting on a thread stack, and the thread is busy executing another task. It is not possible to execute the readied task until all tasks on the same thread finish.\n3. And more importantly, it is subject to deadlocks as well. Consider that a task is waiting for completion of a task that is blocked on the very same stack below it. Oops.\n\nSome parallel computation libraries avoid the deadlocks by imposing a DAG requirement of work structure where all dependent tasks must be spawned by the task itself. This again requires fixing structure of all algorithms rather than just plugging polling into wait objects. And it makes (2) worse.\n\nSome other systems solve this by playing tricks with virtual memory:\nhttp://groups.csail.mit.edu/sct/wiki/index.php?title=The_Cilk-M_Project\nhttp://supertech.csail.mit.edu/papers/stacks.pdf\nBut I think this is out of question here.\n\nI would suggest to explicitly schedule continuations instead of blocking on worker thread stack. Continuations suck code-wise. But that's what we have in C++. Hopefully it's not that bad with closures.\n", "I ran label_image and did not see any deadlocks, although I wasn't looking for them.\n\nI don't think that continuations would be an issue code-wise; it's more enabling the synchronization methods to accept them that would take work.\n", "Also, the reason for having work-stealing across thread's work queues was to deal with your point 2 above.  I agree it's a big deal.\n", "An issue I've been having with multiple file and batch queues may be related. See this [question](http://stackoverflow.com/questions/35414009/multiple-queues-causing-tf-to-lock-up/35420394) on stack overflow.\n", "@dvyukov, @rmlarsen: Did the recent thread pool changes resolve this?\n", "Yes, it's fixed with the contraction changes.\n"]}, {"number": 928, "title": "ci_build: support gpu build and interactive workflow better", "body": "- mount cuda devices and libraries into container\n- improve docker run extra parameter handling\n", "comments": []}, {"number": 927, "title": "cannot compile pip package after update to the HEAD", "body": "error as follows:\n\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\nERROR:./tensorflow/models/embedding/BUILD:10:6: First argument of load() is a path, not a label. It should start with a single slash if it is an absolute path..\nERROR: ./tensorflow/models/embedding/BUILD:10:6: file '/tensorflow:tensorflow.bzl.bzl' was not correctly loaded. Make sure the 'load' statement appears in the global scope in your file.\nERROR: ./tensorflow/models/embedding/BUILD:104:1: name 'tf_gen_op_wrapper_py' is not defined.\nERROR: ./tensorflow/tools/pip_package/BUILD:13:1: Target '//tensorflow/models/embedding:package' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:build_pip_package'.\nERROR: Loading failed; build aborted.\n\nwhich work well before update to the Newest version.\n", "comments": ["I had the same problem and it was solved after updating bazel to version 0.1.4\n", "I'm having the same problem with similar error messages (see issue https://github.com/tensorflow/tensorflow/issues/937). However, after following @phsmit's suggestion, I upgraded my Bazel installation, and those message went away. Now I'm getting a different set of errors instead:\n\n```\n$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\nERROR: /Users/delip/Softwares/tensorflow/WORKSPACE:73:1: iron-ajax is not a legal workspace name.\nERROR: /Users/delip/Softwares/tensorflow/WORKSPACE:80:1: iron-dropdown is not a legal workspace name.\nERROR: /Users/delip/Softwares/tensorflow/WORKSPACE:87:1: accessibility-developer-tools is not a legal workspace name.\n```\n\nAny ideas on how to fix this?\n", "Did you upgrade to 0.1.4 or bazel HEAD?  0.1.4 should work.  bazel HEAD probably doesn't right now, because they changed the legal names of entries in WORKSPACE files.  I suspect they'll update our WORKSPACE file before their next official release.\n", "@vrv, You're right (as always)! I had built bazel from HEAD. Recompiled Bazel from tag 0.1.4 and now TensorFlow compile is progressing. Thanks!\n"]}, {"number": 926, "title": "Add the code to request the runtime permission for the camera.", "body": "Note that this change requires the bazel to be able to import v13 support\nlibrary. Until this issue (https://github.com/bazelbuild/bazel/issues/827) is\nfixed, thisc change doesn't build.\n(I tested by changing my local bazel setting)\n\nPR for https://github.com/tensorflow/tensorflow/issues/925\n", "comments": ["I see. It will not build until bazel is fixed.\n\nDoes that means bazel has to be fixed and released in order to use new android version? Con it be done without forcing tens of thousands of people who cloned tensorflow repo to upgrade bazel?\n", "Added another commit to replace FragmentComapt (which requires v13 support library) by inlined methods.\n\nThis should work without depending on v13 support library.\n\nIs it possible to trigger the build again?\n", "It is currently building pull requests of all people in google organization automatically. We will disable that soon though.\n\nThe android build still failed.\n", "Looks like android-support-v4.jar is missing in the build server.\nIs it possible to install the android-support-v4.jar in the server?\n\nIf not, I can inline the ContextCompat (which requires android-support-v4.jar) like the way I did for v13 support library.\n", "IT would be better if you can avoid that dependency by just a few lines of code. Otherwise we would have to change setup instructions and everybody would have to go go through manual process of launching sdk manager and installing something. Or is it in some public maven repo? If so you can just add it as external dependency in BUILD file.\n", "v4 support library is pretty common for Android developers, but it requires the SDK manager to install.\nOk, I'll inline the code to avoid v4 support library dependency.\n", "It is, imho, better to inline it if it is a few lines of code. If it is bigger we can add the dependency.\n\n(if it was in maven central I would have different threshold)\n", "Added another commit to remove the v4 support library dependency.\nI think the build in the CI server should be now fixed.\n", "LGTM\n\nThank you!\n", "@vrv can we merge this?\n", "@thagikura can you squash your commits? \n", "Squashed the commits.\n", "merged.\n", "Glad to see this go in. FYI there's also \"adb install -r -g tensorflow_demo.apk\" which will automatically grant permissions upon install (so you don't need to grant manually on every install). Unfortunately there's no way to do this currently directly through bazel, but they are working on it.\n"]}, {"number": 925, "title": "Android demo crashes on Android 6 devices", "body": "When I tried to run the Android demo, it instantly crashed when I opened the app.\nThe CameraConnectionFragment doesn't handle the runtime permission for camera.\n\nThe code needs to handle the runtime permission.\n\n```\n01-29 17:23:43.694 15962-15962/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: main\nProcess: org.tensorflow.demo, PID: 15962\njava.lang.SecurityException\n    at android.os.BinderProxy.transactNative(Native Method)\n    at android.os.BinderProxy.transact(Binder.java:503)\n    at android.hardware.ICameraService$Stub$Proxy.connectDevice(ICameraService.java:364)\n    at java.lang.reflect.Method.invoke(Native Method)\n    at android.hardware.camera2.utils.Decorator.invoke(Decorator.java:80)\n    at java.lang.reflect.Proxy.invoke(Proxy.java:393)\n    at $Proxy0.connectDevice(Unknown Source)\n    at android.hardware.camera2.CameraManager.openCameraDeviceUserAsync(CameraManager.java:321)\n    at android.hardware.camera2.CameraManager.openCamera(CameraManager.java:457)\n    at org.tensorflow.demo.CameraConnectionFragment.openCamera(CameraConnectionFragment.java:380)\n    at org.tensorflow.demo.CameraConnectionFragment.access$000(CameraConnectionFragment.java:63)\n    at org.tensorflow.demo.CameraConnectionFragment$1.onSurfaceTextureAvailable(CameraConnectionFragment.java:96)\n    at android.view.TextureView.getHardwareLayer(TextureView.java:368)\n    at android.view.View.updateDisplayListIfDirty(View.java:15151)\n    at android.view.View.draw(View.java:15948)\n    at android.view.ViewGroup.drawChild(ViewGroup.java:3609)\n    at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3399)\n    at android.view.View.updateDisplayListIfDirty(View.java:15169)\n    at android.view.View.draw(View.java:15948)\n    at android.view.ViewGroup.drawChild(ViewGroup.java:3609)\n    at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3399)\n    at android.view.View.draw(View.java:16181)\n    at android.view.View.updateDisplayListIfDirty(View.java:15174)\n    at android.view.View.draw(View.java:15948)\n    at android.view.ViewGroup.drawChild(ViewGroup.java:3609)\n    at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3399)\n    at android.view.View.updateDisplayListIfDirty(View.java:15169)\n    at android.view.View.draw(View.java:15948)\n    at android.view.ViewGroup.drawChild(ViewGroup.java:3609)\n    at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3399)\n    at android.view.View.updateDisplayListIfDirty(View.java:15169)\n    at android.view.View.draw(View.java:15948)\n    at android.view.ViewGroup.drawChild(ViewGroup.java:3609)\n    at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3399)\n    at android.view.View.draw(View.java:16181)\n    at com.android.internal.policy.PhoneWindow$DecorView.draw(PhoneWindow.java:2690)\n    at android.view.View.updateDisplayListIfDirty(View.java:15174)\n    at android.view.ThreadedRenderer.updateViewTreeDisplayList(ThreadedRenderer.java:281)\n    at android.view.ThreadedRenderer.updateRootDisplayList(ThreadedRenderer.java:287)\n    at android.view.ThreadedRenderer.draw(ThreadedRenderer.java:322)\n    at android.view.ViewRootImpl.draw(ViewRootImpl.java:2615)\n    at android.view.ViewRootImpl.performDraw(ViewRootImpl.java:2434)\n    at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2067)\n    at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1107)\n    at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:6013)\n    at android.view.Choreographer$CallbackRecord.run(Choreographer.java:858)\n    at android.view.Choreographer.doCallbacks(Choreographer.java:670)\n    at android.view.Choreographer.doFrame(Choreographer.java:606)\n    at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:844)\n    at android.os.Handler.handleCallback(Handler.java:739)\n    at android.os.Handler.dispatchMessage(Handler.java:95)\n    at android.os.Looper.loop(Looper.java:148)\n    at android.app.ActivityThread.main(ActivityThread.java:5417)\n    at java.lang.reflect.Method.invoke(Native Method)\n    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)\n    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)\n```\n", "comments": ["Fixed by #926, but the demo app still crashes due to another error.\nI'll close this issue and file another one.\n"]}, {"number": 924, "title": "git clone hangs when building from source", "body": "$bazel build -c opt --config=cuda --spawn_strategy=standalone --verbose_failures //tensorflow/tools/pip_package:build_pip_package\n..........\n[4 / 4] Cloning https://github.com/Polymer/polymer.git: Resolving deltas (13948 / 15071)\n\nit hangs here for a few hours.\n", "comments": ["GitHub was having trouble. Is this still a problem?\nOn Thu, Jan 28, 2016 at 23:54 LiLi notifications@github.com wrote:\n\n> $bazel build -c opt --config=cuda --spawn_strategy=standalone\n> --verbose_failures //tensorflow/tools/pip_package:build_pip_package\n> \n> [4 / 4] Cloning https://githubcom/Polymer/polymergit: Resolving deltas\n> (13948 / 15071)\n> \n> it hangs here for a few hours\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/924.\n", "I'll close this. If you still have trouble, reopen it.\n"]}, {"number": 923, "title": "Out of range: FIFOQueue '_0_fifo_queue'", "body": "When I test  [cifar10_input_test.py](tensorflow/tensorflow/models/image/cifar10/cifar10_input_test.py).I got the following information, how could I solve this error.\n\n```\nW tensorflow/core/common_runtime/executor.cc:1052] 0x1fe5ea0 Compute status: Out of range: FIFOQueue '_0_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n     [[Node: ReaderRead = ReaderRead[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](FixedLengthRecordReader, fifo_queue)]]\n```\n", "comments": ["This is a warning, not an error.  It might be an unhelpful warning though.\n\nDid the test end up failing?\n", "I go this, when the filename queue could not find any elements for the glob pattern i specified. Might be related?\n", "This is a message that's printed when you reach the end of the queue, so it's part of normal operation\n", "@vrv The test end up success.\n@yaroslavvb Thanks I understand what's the meaning of this message. \n", "Is there any way to suppress this warning? It fills up my logs.\n", "Why this message was printed? I encountered this problem in my program too, but occasionally this message occurred, not every time. I am wondering what triggered it. @yaroslavvb ", "Thanks @yaroslavvb "]}, {"number": 922, "title": "Fix/udacity notebooks py3", "body": "@vincentvanhoucke In reference to https://github.com/tensorflow/tensorflow/pull/871#issuecomment-176560995\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n\nOn 28 January 2016 at 23:21, googlebot notifications@github.com wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n> \n> [image: :memo:] _Please visit https://cla.developers.google.com/\n> https://cla.developers.google.com/ to sign._\n> \n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> \n> ## verify. Thanks.\n> - If you've already signed a CLA, it's possible we don't have your\n>   GitHub username or you're using a different email address. Check your\n>   existing CLA data https://cla.developers.google.com/clas and verify\n>   that your email is set on your git commits\n>   https://help.github.com/articles/setting-your-email-in-git/.\n> - If you signed the CLA as a corporation, please let us know the\n>   company's name.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/922#issuecomment-176567477\n> .\n", "CLAs look good, thanks!\n\n<!-- ok -->\n"]}, {"number": 921, "title": "tensorflow.Session() Hangs on 24-Logical Core Machine", "body": "We have a newish (<6 months old) server with two hyperthreaded 6-core processors, and when we try to create a tensorflow.Session(), it hangs indefinitely in what `top` reports is state D (uninterruptible sleep), unresponsive even to SIGKILL. Relevant output is below.\n\n```\n>>> sess = tf.Session() \nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 24\n[...indefinite hang...]\n```\n", "comments": ["can you try sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=1))\nIf it still hangs, maybe you could compile in debug mode, attach GDB to hanging process and do \"bt\" to see where it's stuck\n", "I couldn't find documentation on where to specify those arguments (certainly not to Python, and I could find no such ConfigProto flags). However, I did try setting intra_op_parallelism_threads to 1, and the same issue occurred. I'll try seeing if GDB can shed some light on the matter.\n\n```\n>>> sess = tf.Session(config=tf.ConfigProto(\n...     intra_op_parallelism_threads=1))          \nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 1\n[...indefinite hang...]\n```\n", "Oops, brain freeze, updated to use the proper ConfigProto object rather than unsupported flags\n", "After a machine reboot, this problem no longer occurred. It seems that our cards' driver might have been hung somewhere, as other CUDA code was also hanging.\n"]}, {"number": 920, "title": "Upgraded to a newer version of Eigen that fixes a compilation error when compiling with nvcc and clang", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, would you be so kind and test this please?\n", "Merged.\n"]}, {"number": 919, "title": "Fixes SummaryWriter namespace in TensorBoard warning messages", "body": "", "comments": ["Can one of the admins verify this patch?\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "Closing, we need the CLA to be signed to look at it :(.  Feel free to sign it and we'll reopen.\n", "Strange. Maybe the email matches now?\n"]}, {"number": 918, "title": "bug in machine translation example - learning rate randomly changes", "body": "I'm running into a strange issue with translate.py. I'm getting NaNs in the learning rate, or at least that's what my debug printouts suggest. \n\nMy code is bleeding edge (5572b1a9205d94a0de8dc843f51197ce8bbedf7a) and unmodified except I added print statements like this at the start, and after each model.get_batch and model.step call:\nprint('got a batch: lr = %.9f'% model.learning_rate.eval())\n\nEach run is different, but here are is one example:\n\nCUDA_VISIBLE_DEVICES=1 python translate.py --data_dir enfr_data --train_dir foo --en_vocab_size=50000 --fr_vocab_size=50000 --size=600 --num_layers=3 --batch_size 128 --steps_per_checkpoint 200 --max_train_data_size 110000\n...\n\n```\nCreating 3 layers of 600 units.\nCreated model with fresh parameters.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.57GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x2047a0000 extends to 0x4a8b24400\nbefore loop: lr=0.500000000\nReading development and training data (limit: 110000).\n  reading data line 100000\ngot a batch: lr = 0.500000000\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 7642 get requests, put_count=3359 evicted_count=1000 eviction_rate=0.297708 and unsatisfied allocation rate=0.704397\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110\ndid a step: lr = 0.500000000\ngot a batch: lr = 0.500000000\ndid a step: lr = 0.500000000\ngot a batch: lr = 0.500000000\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 22 get requests, put_count=2034 evicted_count=2000 eviction_rate=0.983284 and unsatisfied allocation rate=0\ndid a step: lr = 0.500000000\ngot a batch: lr = 0.500000000\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 46 get requests, put_count=7059 evicted_count=7000 eviction_rate=0.991642 and unsatisfied allocation rate=0\ndid a step: lr = 0.967365444\ngot a batch: lr = 0.967365444\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 44 get requests, put_count=6060 evicted_count=6000 eviction_rate=0.990099 and unsatisfied allocation rate=0\ndid a step: lr = nan\ngot a batch: lr = nan\ndid a step: lr = nan\ngot a batch: lr = nan\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 6 get requests, put_count=3025 evicted_count=3000 eviction_rate=0.991736 and unsatisfied allocation rate=0\n```\n\nAnd here is another:\n\nCUDA_VISIBLE_DEVICES=1 python translate.py --data_dir enfr_data --train_dir foo --en_vocab_size=50000 --fr_vocab_size=50000 --size=600 --num_layers=3 --batch_size 128 --steps_per_checkpoint 2 --max_train_data_size 110000\n\n```\n\nCreating 3 layers of 600 units.\nCreated model with fresh parameters.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.57GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x2047a0000 extends to 0x4a8b24400\nbefore loop: lr=0.500000000\nReading development and training data (limit: 110000).\n  reading data line 100000\ngot a batch: lr = 0.500000000\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 7642 get requests, put_count=3316 evicted_count=1000 eviction_rate=0.301568 and unsatisfied allocation rate=0.710024\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110\ndid a step: lr = 0.500000000\ngot a batch: lr = 0.500000000\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 8 get requests, put_count=5019 evicted_count=5000 eviction_rate=0.996214 and unsatisfied allocation rate=0\ndid a step: lr = 0.000000000\nglobal step 2 learning rate 0.0000 step-time 4.49 perplexity 14766.28\n  eval: bucket 0 perplexity inf\n  eval: bucket 1 perplexity inf\n  eval: bucket 2 perplexity inf\n  eval: bucket 3 perplexity inf\n```\n\nCan anyone else replicate this, or have any idea how to fix it? Seems like a buffer overflow...\n", "comments": ["UPDATE: OK, the real issue was that the memory in one of my GPUs was going bad and randomly giving me garbage. \n"]}, {"number": 917, "title": "Sequence-Wise Batch Normalization for RNN's", "body": "Hey TF,\n\nRecently, for deep RNN's, sequence wise batch normalization has proven to be very helpful. [Deep Speech 2](http://arxiv.org/pdf/1512.02595v1.pdf) in section 3.2 explains this in more detail. Sequence-wise batch normalization is described in section 4.1 in [Batch Normalized RNNs](http://arxiv.org/pdf/1510.01378v1.pdf).\n\n`tf.nn.moments` is very useful for batch normalization because it gives you the mean and variance. However, in seq2seq setups, we need to do a batch normalization across all timesteps (the entire sequence). Unfortunately, the way `seq2seq.py` is written, each timestep is within a separate 2D matrix. This means that there is a list of 2d tensors for the entire sequence.\n\nIf somehow, `tf.nn.moments` could be modified to accept lists of tensors (all of the same dimensions), it would be incredibly helpful. This way, we could input the entire list of tensors, and compute the resulting mean and variance for that sequence. \n\nThanks!\n", "comments": ["This is a good idea, we put this on the list of things to do.\n", "Thanks really appreciate it!\n", "@LeavesBreathe I'm looking into some of these issues right now. Is there any specific reason why a `tf.nn.moments([] ...)` type of API would be preferable to simply doing `tf.nn.moments(tf.pack([]) ...)` ?\n", "If I understand things correctly, tf.pack would copy all the tensors, and require more memory. Please correct me if I'm wrong. \n\nOtherwise, your right: this is a much better solution. Thanks for the help. \n", "@LeavesBreathe in the grand scheme of things, it will not affect memory consumption much: as soon as the copy is performed, the input buffers will no longer be needed for the backward pass, and be releasable to the pool. Packing things into one tensor also potentially enables more efficient contractions to take place. What matters most to memory consumption is long-lived tensors, e.g. ones that have to be preserved between the forward and the backward pass. One could still consider a different API if there is evidence that this is a problem.\nI'm also looking into separating the collection of sufficient statistics (which can be performed online) from the actual aggregation, which would give users the freedom to make the reductions more granular if they wanted. I'll be closing this bug now, and treat the other items as opportunities for optimization.\n", "Thank you vincent, I will try this approach and apologize for not thinking of it sooner!\n", "I have just committed a change to `nn.moments()` which allows you to decouple the collection of the sufficient statistics `nn.sufficient_statistics()` from the computation of the means and variances `nn.normalize_moments()`. This allows you to build compact statistics at each time step, aggregate them by summing them whichever way you want, and normalize them afterwards. I hope this helps.\n", "@vincentvanhoucke I have been away for a while but I'm trying to implement batch norm now on LSTMs. \n\nThank you for updating `nn.moments()` -- I will try to work on this to implement sequence wise batch normalization. Really appreciate the help!\n"]}, {"number": 916, "title": "a CUDA runtime call was likely performed without using a StreamExecutor context", "body": "I want use my pylearn2 dataset code with tensorflow. But when I add `from pylearn2.datasets.dense_design_matrix import DefaultViewConverter` into mnist convolutional.py and run it in my server, I get this errors:\n\n`F tensorflow/stream_executor/cuda/cuda_driver.cc:302] current context was not created by the StreamExecutor cuda_driver API: 0x38e0330; a CUDA runtime call was likely performed without using a StreamExecutor context\nAborted (core dumped)`\n\nMy server is GTX980 with 8 core CPU, I will get that errors in my server. But I can run it in my desktop PC with GTX960/GTX970 and 4 core CPU and I don't get any errors. All the cuda version is same in my machices.\nDoes anyone can help me? \n\nthe full traceback is:\n\n```\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally\nUsing gpu device 0: GeForce GTX 980 (CNMeM is disabled)\n/home/b3432/ShareCache/houzhi/data\ntrain-images-idx3-ubyte.gz\n/home/b3432/ShareCache/houzhi/data\ntrain-labels-idx1-ubyte.gz\n/home/b3432/ShareCache/houzhi/data\nt10k-images-idx3-ubyte.gz\n/home/b3432/ShareCache/houzhi/data\nt10k-labels-idx1-ubyte.gz\nExtracting /home/b3432/ShareCache/houzhi/data/train-images-idx3-ubyte.gz\nExtracting /home/b3432/ShareCache/houzhi/data/train-labels-idx1-ubyte.gz\nExtracting /home/b3432/ShareCache/houzhi/data/t10k-images-idx3-ubyte.gz\nExtracting /home/b3432/ShareCache/houzhi/data/t10k-labels-idx1-ubyte.gz\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8\nF tensorflow/stream_executor/cuda/cuda_driver.cc:302] current context was not created by the StreamExecutor cuda_driver API: 0x38e0330; a CUDA runtime call was likely performed without using a StreamExecutor context\nAborted (core dumped)\n```\n", "comments": ["I am having the same error when I try to use caffe in the same python session as tensorflow. The problem probably is that caffe is using the gpu without using the StreamExecutor cuda_driver API and tensorflow doesn't accept that. How can I reset the GPU (as if I exit and enter in python again) so I can use tensorflow after having used caffe? I can't exit python, because I don't want to lose some computed variables and I don't to save those to the disk and load them again.\n", "I am having the same issue\n", "My issue is probably script specific. I ran the demo mnist model and it was running fine.\n", "I am having the same issue when using Theano along with Tensorflow. When disabled GPU for Theano, the error is gone.\n", "I'm getting this error. Are there any workarounds? @xlangacadia, what do you mean by \"disabled GPU for Theano\"? In .theanorc? I restarted the computer (Theano was running previuosly), so that should have taken care of getting Theano off the GPU, I would think. Restarting did not help.\n", "@jmugan Make sure you don't have a `import theano.tensor as t` line lying around in your code -- this will cause this issue to happen.\n", "That fixed it, thanks @moustaki! I couldn't find where I was doing the import, but I changed the device to cpu in .theanorc, and now it works.\n", "@zheng-xq: Can you take a look at this?  Seems like it fell through the cracks. \n", "We are not using theano or caffe, but are running into this issue in our unit test framework which uses tensorflow operators as well as cuda runtime calls. Are there any plans to fix this?\n", "Using TensorFlow with other frameworks is a bit tricky, since there are many places assuming it has exclusive access to the GPU. So disables GPU functionalities in one of them sounds reasonable. \n\n@kbrems, with your use case, it is not recommended to use TensorFlow operators in the same thread as other Cuda runtime calls. TensorFlow uses stream-executor a faster Cuda runtime alternative. If standard Cuda runtime APIs is called on the same context, it confuses stream-executor with what context is bound to what thread, and many of its internal data structure. \n\nIf you have to make Cuda calls, either: \n1. Call the stream-executor alternative. \n2. Call the Cuda driver API similar to what stream-executor does, and make sure you restore the context binding after you are done. \n", "Closing for now since making TensorFlow share the GPU seems out of reach.\n", "Using the trick suggested by @jmugan - \"I changed the device to cpu in .theanorc, and now it works.\", I can use either tensorflow or theano to be keras's backend to run the same python script. \n", "Alternatively, just start your tensorflow job with `THEANO_FLAGS='device=cpu' python myNN.py`.\r\nThat way you do not have to mess with your `.theanorc`", "@jalammar @girving I have the same error:\r\n`tensorflow/stream_executor/cuda/cuda_driver.cc:334] current context was not created by the StreamExecutor cuda_driver API: 0x2862ff0; a CUDA runtime call was likely performed without using a StreamExecutor context`\r\nit means that another program is accessing or using the GPU?  ", "@xiangacadia @moustaki @girving @jmugan I have the same error:\r\n`tensorflow/stream_executor/cuda/cuda_driver.cc:334] current context was not created by the StreamExecutor cuda_driver API: 0x2862ff0; a CUDA runtime call was likely performed without using a StreamExecutor context`, but I do not use keras or theno, and I only use tf.  Besides, there are no other programs are accessing or using the GPU.  \r\nwhat causes this problem?\r\nany advice is appreciated?\r\nthank you in advance!", "Exactly same issue, any body could give an solution? I installed boost and dlib which may using CUDA ,  got same error, now I don't want disable any, how to resolve this?", "One possible workaround is to launch the Tensorflow code in a separate worker thread.  This isolates Tensorflow's CUDA context and allows it to coexist peacefully with Caffe (and other CUDA-enabled libraries).  \r\n\r\nI'm using python's `threading` and `Queue` libraries for this, and no complaints (although they're still battling for memory, but that's a different story).", "@sstirlin yes, I also create another subprocess  for other CUDA-used  processes. and no complaints"]}, {"number": 915, "title": "Remove compiler warnings on CHECK_* and DCHECK_* macros.", "body": "This removes lots of simple compiler warnings on 'signed' and 'unsigned'\ncomparisons on CHECK_\\* and DCHECK_\\* macros (reported in #128).\nIn most cases, `static_cast<>` is used to remove the warnings.\n\nThis does not fix 3rd-party(stream_executor/eigen/protobuf)-related warnings and\nalso does not change any function signatures.\n", "comments": ["Can one of the admins verify this patch?\n", "Also we might be able to clean up most of these warnings by properly declaring Node::num_inputs and num_outputs as a size_t (and fix all the callers).  That seems like a much more correct change than masking these type errors.\n", "+1 for fixing the underlying problem.\n", "Yep, it would be much better. As I wrote in commit log, I was just afraid to change function signature. :)\nMay I change those types, too? (But, I'm not sure the sideeffect as of now)\n", "Oh, sorry, I meant the type of class variables.\n", "I think I can update this PR (including testing) in a few hours if there is not another change. \n", "Thank you, @vrv  and @martinwicke . \nAccording to the comments, I'm changing `Node::num_inputs` and `Node::num_outputs` and using `size_t{0}`.  I agree with you that is the best way.\n", "The code is updated and rebased to the master. Thanks.\n", "I found something strange. During rebasing, some of @vrv 's comments are gone.  As far as I remember, GitHub kept the commit logs and I could access them via commit hashtag before. In anyway, I'm sorry for that.\n", "Hi, @vrv . \nTo preserve current comments and show what I mean, I made another PR handling only `numeric literals`, #944 . Is it okay for you?\n", "Thank you all for reviewing. Since #944 is merged, I'll close this issue. I think this PR goes too far.\nI believe the underlying problem will be handled inside Google much nicely.\nThank you again.\n"]}, {"number": 914, "title": "label_image example failing due to missing types.h", "body": "```\nIn file included from tensorflow/examples/label_image/command_line_flags.cc:16:0:\n./tensorflow/examples/label_image/command_line_flags.h:20:44: fatal error: tensorflow/core/platform/types.h: No such file or directory\n #include \"tensorflow/core/platform/types.h\"\n```\n\nthere is no such file.  there is a `tensorflow/core/framework/types.h`\n", "comments": ["https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/types.h\n\nAre you properly synced?\n", "ah i was 8 days ago or so...i see the changes...thanks and sorry for the noise.\n", "actually my problem came down to the fact that the docker containers are all on the 0.6.0 release.  thus if you accidentally mix later examples with the 0.6.0 release of tensorflow, it doesn't work.  \n"]}, {"number": 913, "title": "First assignment on Google Deep Learning, Exception raised on download", "body": "This is the first time taking a course on udacity. With atmost interest opened up the first assignment and ended up in Exception:\nThe screenshot attached\n![screenshot from 2016-01-28 10 17 30](https://cloud.githubusercontent.com/assets/16772566/12635403/c45f8344-c5a8-11e5-9aa2-bb641a451d60.png)\n", "comments": ["This is not the best place to ask questions about the class. In this case, delete the file and try to download it again. You can also try to download it from the website manually and see if that succeeds.\n"]}, {"number": 912, "title": "\"Cannot allocate memory\" error on first Udacity assignment", "body": "![screenshot](http://i.imgur.com/r1PTe4C.png)\n\nThough, as the screenshot shows, I have allocated 5GB of memory to the Docker container running [the course's first Jupyter notebook](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb), I can't seem to get past this cell because of Python's `cannot allocate memory` error. Sometimes it happens with `notMNIST_large/B` and sometimes with `notMNIST_large/C`. I don't see why this error is thrown when the container reaches 1.4GB, since it should be able to go up to 5GB...\n\nI doubt this is a problem with TensorFlow but, since it's part of the course, I figured this issue might be helpful to other students as well.\n\nThis is the Docker command I'm running (differs from [the original command](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/udacity#running-the-docker-container-from-the-google-cloud-repository) in that this gets rid of `--rm` and adds `--memory=5gb`):\n\n``` shell\ndocker run --name udacity_deep_learning --memory=5g -p 8888:8888 -it b.gcr.io/tensorflow-udacity/assignments\n```\n", "comments": ["If you have more memory than that, can you try raising the ceiling and see if it fails later?\nSomeone else commented they had needed more.\n", "`--memory=8g` let it go up to `notMNIST_large/D`... then it went back down to `notMNIST_large/C` with 12GB before it crashed with the same `OSError: [Errno 12] Cannot allocate memory`.\n\nMeanwhile the usage stats of the container (`docker stats udacity_deep_learning`) show that it's nowhere near the limit (the most it went up to before crashing was about 1.5GB)\n\n```\nCONTAINER               CPU %               MEM USAGE / LIMIT     MEM %               NET I/O               BLOCK I/O\nudacity_deep_learning   0.01%               1.402 GB / 12.88 GB   10.88%              256.3 MB / 657.9 kB   733.4 MB / 237.6 kB\n```\n\nThank you for your help!\n", "@timothyjlaurent was successful with the Docker container. Any gotcha there? I haven't tried recently. Maybe @craigcitro has some advice too.\n", "What I did to get it running was to ensure that my docker-machine VM had sufficient memory. Initially the VM only had 4GB, increasing the VM to have 8GB was sufficient to get it working. Also, you don't need to tune the amount of memory in the `docker run`  command -- docker will use whatever is available if you don't specify a constraint.\n\n1 last IMPORTANT hint -- mount the udacity directory in your container like so \n\n`docker run --rm -v <path to udacity dir>`:/notebooks <image name>`\n\nThis will ensure that all the work and FS writes will go on your disk and not be ephemerally lost when your container goes down. \n\nhope this helps  @mamigot\n", "ah, this one is interesting: the problem here is that while `docker run` happily allocates more memory to the container, the problem is that the underlying **vm** (owned by `docker-machine`) doesn't have any more memory to give.\n\ni followed the second option in [this SO post](http://stackoverflow.com/questions/32834082/how-to-increase-docker-machine-memory-mac) to bump the underlying vm's memory to 8GB, and things seem to be humming along.\n\nso:\n- we probably want to add a note to the course instructions for OSX users about ensuring their machine has enough RAM.\n- `docker stats` probably wasn't lying about the total memory _used_, just about total amount _available_. :grin: \n- it's also possible that we could do a bit more cleanup of leftover objects in the python code itself (i think sometimes numpy is bad about cleaning up after itself, but i could be wrong), but that's really a secondary concern (since we definitely need more memory in the base VM regardless).\n", "Would someone who understands this well mind adding those tips to the README.md?\n", "Sending a CL out now.\n", "Gracias\n", "Thank you, @vincentvanhoucke, @craigcitro and @timothyjlaurent , that worked perfectly!\nLooking forward to the course and using TensorFlow!\n"]}, {"number": 911, "title": "MNIST 0.6.0 Tutorial Documentation bug", "body": "At this URL:\n\nhttps://www.tensorflow.org/versions/0.6.0/tutorials/mnist/beginners/index.html\n\nThe 2nd line of syntax is wrong:\n\n`mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)`\n\nIt should be:\n\n`mnist = tensorflow.examples.tutorials.mnist.input_data.read_data_sets(\"MNIST_data/\", one_hot=True)`\n", "comments": ["It's fixed at Head https://github.com/tensorflow/tensorflow/blob/411f57e291839094108afdaa9c43094f44979eaa/tensorflow/g3doc/tutorials/mnist/beginners/index.md\n"]}, {"number": 910, "title": "Error downloading jpegsrc.v9a.tar.gz", "body": "I'm getting the following build error:\n\n```\n$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nERROR:  tensorflow/tensorflow/core/platform/default/build_config/BUILD:36:1: \nno such package '@jpeg_archive//': \nError downloading from http://www.ijg.org/files/jpegsrc.v9a.tar.gz\n```\n\nIt turns out that bazel cannot download directly from the `ijg.org` in my network, due to security restrictions. However, I am able to download the file by hand. \n\nI tried just putting it into the required `.cache/bazel` location by hand and run the bazel command again. This used to work, but it won't work in the latest version, and the same error comes up again.\n\nWould it be possible to enable bazel to pick up a locally downloaded `jpegsrc.v9a.tar.gz` file?\n\nOr, if I don't work on JPEGs, how do I get rid of this dependency altogether?\n", "comments": ["Can you file this bug with bazel and mention this bug?  bazel team is much more suited to helping you in this case.\n"]}, {"number": 909, "title": "Adding instructions for wheel on python3.5", "body": "The current python3 wheel installation instructions doesn't work for python3.5, since the pip3 (python3.5) is unable to recognize the wheel file \"tensorflow-0.6.0-cp34-none-linux_x86_64.whl\" due to the version information contained in the file name \"cp34-none\". See issue #468\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "I'm wondering whether we should leave the code as is and write text to tell people to rename the whl file before installing it. The code gets very bifurcated the way it's written now.\n", "Closing due to inactivity.  We'll try to get better python install instructions if we can, without creating too much duplicate text\n"]}]