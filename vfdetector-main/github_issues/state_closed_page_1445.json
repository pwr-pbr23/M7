[{"number": 9610, "title": "Broken link Mac/GPU/py3 whl file", "body": "On page: \r\n[https://www.tensorflow.org/install/install_mac#the_url_of_the_tensorflow_python_package](https://www.tensorflow.org/install/install_mac#the_url_of_the_tensorflow_python_package)\r\n\r\nThis link is broken:\r\n[https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl](https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl)", "comments": ["Same problem.", "Anyone know a mirror?", "Fixed. Thanks for pointing this out @kinergy !"]}, {"number": 9609, "title": "R0.11", "body": "Extract translate.py", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->"]}, {"number": 9608, "title": "Correct self_check label in label_image example", "body": "`military uniform` is the 654th label in inceptionV3 package. As said in `README`: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/README.md#to-buildinstallrun", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 9607, "title": "Added -D_GLIBCXX_USE_CXX11_ABI=0 to bazel build", "body": "Fixes issues with missing symbols when compiling with GCC 5.x. See\r\nissue tensorflow/tensorflow#1419.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "PR merged. Thanks, @aleist "]}, {"number": 9606, "title": "Group LSTM cell", "body": "Implementing (in contrib/rnn) group LSTM cell from \"Factorization Tricks for LSTM Networks\" ICLR 2017 Workshop.\r\nhttps://openreview.net/forum?id=ByxWXyNFg&noteId=ByxWXyNFg", "comments": ["Can one of the admins verify this patch?", "@ebrevdo can you review or suggest someone appropriate?", "@ebrevdo, Thanks for your fast feedback! I think I've address all your comments (and fixed few other similar nits).", "Since this is being proposed as a few function in tf.contrib (as opposed to tf), removing the API Review label", "@tensorflow-jenkins test this please", "@ebrevdo how's it look now?", "thanks Vijay  and Eugene!", "Can one of the admins verify this patch?", "sorry, closed by accident before it was merged. re-opened now", "I can't use the GLSTMCell to build a dynamic rnn. When I use the tf.contrib.rnn.GLSTMCell in tf.contrib.rnn.stack_bidirectional_dynamic_rnn() or tf.nn.dynamic_rnn(), like\r\n\r\n    rnn_outputs, _, _ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\r\n    [tf.contrib.rnn.GLSTMCell(num_units=self.num_hidden, num_proj=self.num_proj, number_of_groups=4) for _ in range(self.num_layers)],\r\n    [tf.contrib.rnn.GLSTMCell(num_units=self.num_hidden, num_proj=self.num_proj, number_of_groups=4) for _ in range(self.num_layers)],\r\n    self.rnn_inputs, dtype=tf.float32, sequence_length=self.rnn_seq_len, scope='BDDLSTM')\r\n\r\n\r\nI got the error\r\n\r\n    Traceback (most recent call last):\r\n    File \"/home/frisasz/pycharm/helpers/pydev/pydevd.py\", line 1591, in <module>\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n    File \"/home/frisasz/pycharm/helpers/pydev/pydevd.py\", line 1018, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n    File \"/media/frisasz/DATA/FSZ_Work/deep learning/IDOCR_/work/train.py\", line 171, in <module>\r\n    train(train_dir='/media/frisasz/Windows/40T/', val_dir='../../0000/40V/')\r\n    File \"/media/frisasz/DATA/FSZ_Work/deep learning/IDOCR_/work/train.py\", line 41, in train\r\n    FLAGS.momentum)\r\n    File \"/media/frisasz/DATA/FSZ_Work/deep learning/IDOCR_/work/model.py\", line 61, in __init__\r\n    self.logits = self.rnn_net()\r\n    File \"/media/frisasz/DATA/FSZ_Work/deep learning/IDOCR_/work/model.py\", line 285, in rnn_net\r\n    outputs, _ = tf.nn.dynamic_rnn(tf.contrib.rnn.GLSTMCell(self.num_hidden), self.rnn_inputs, self.rnn_seq_len, dtype=tf.float32)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 574, in dynamic_rnn\r\n    dtype=dtype)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 737, in _dynamic_rnn_loop\r\n    swap_memory=swap_memory)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 720, in _time_step\r\n    skip_conditionals=True)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 206, in _rnn_step\r\n    new_output, new_state = call_cell()\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 708, in <lambda>\r\n    call_cell = lambda: cell(input_t, state)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 180, in __call__\r\n    return super(RNNCell, self).__call__(inputs, state)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 441, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/rnn_cell.py\", line 2054, in call\r\n    R_k = _linear(x_g_id, 4 * self._group_shape[1], bias=False)\r\n    File \"/home/frisasz/miniconda2/envs/dl/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1005, in _linear\r\n    \"but saw %s\" % (shape, shape[1]))\r\n    ValueError: linear expects shape[1] to be provided for shape (?, ?), but saw ?\r\n\r\nI'm not sure if this is the right way or it is a bug", "@FrisaSZ  https://stackoverflow.com/questions/45235253/use-glstmgroup-lstm-cell-to-build-bidirectional-rnn-in-tensorflow/46117195#46117195"]}, {"number": 9605, "title": "Add check for duplicate names in import_graph_def", "body": "Found when working on #8999. Currently, `import_graph_def` naively goes through all the Ops in the GraphDef without asserting that all names are unique. This causes bugs when [it loops through the ops a second time in order to update their input values](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/importer.py#L310-L313), as the input values for one op may be assigned to another op.\r\n\r\nGenerally, people don't need to worry about unique names, as TensorFlow provides that functionality automatically. However, this will be a useful debugging check to have for tools that modify GraphDefs directly (such as the [`quantize_graph`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/quantization/quantize_graph.py) tool).", "comments": ["Can one of the admins verify this patch?", "I think this is good, but want mrry@ to double-check in case there's any sneaky name_scope issues to deal with.", "@tensorflow-jenkins test this please", "Looks like a build failure, so I'll merge since the other scenarios are passing."]}, {"number": 9604, "title": "Branch 154885009", "body": "", "comments": ["Everything passing except for Android Demo app, going to try again and see if it's consistent.  If android passes quickly, I'll merge.\r\n\r\n@tensorflow-jenkins test this please", "cc @caisq or @yifeif if they have any idea why the Android build is failing with\r\n\r\n```\r\n18:05:18 INFO: Loading package: tensorflow/c\r\n18:05:18 ERROR: /workspace/tensorflow/core/BUILD:1363:1: in cmd attribute of genrule rule //tensorflow/core:version_info_gen: $(PYTHON_BIN_PATH) not defined. Since this rule was created by the macro 'tf_version_info_genrule', the error might have been caused by the macro implementation in /workspace/tensorflow/tensorflow.bzl:1188:7.\r\n18:05:18 ERROR: Analysis of target '//tensorflow/examples/android:tensorflow_demo' failed; build aborted.\r\n18:05:18 INFO: Elapsed time: 2.669s\r\n```\r\n\r\nThe only likely culprit is the .bazel.rc commit, but I can't see why that would cause this to fail.", "Is it related to this PR? #9547", "Maybe, but that PR passed before. @andrewharp thinks it is related to stand alone strategy", "Going to try to revert 50aff7a2735ac595199abb67f4c96fa39193007c for now so we can make progress, and then let someone else figure out how to get around this sandboxing issue.", "@tensorflow-jenkins test this please"]}, {"number": 9603, "title": "Try launch tensorflow and get error", "body": "i have install tensorflow on windows 10 and when i put a demo he gives me this error plz help me tanks\r\n\r\n![capturar](https://cloud.githubusercontent.com/assets/17919329/25643061/65e33d62-2f95-11e7-9d78-18ad59ec8526.JPG)\r\n", "comments": ["Could you please try to install [Microsoft Visual C++ 2015 Redistributable Update 3](https://www.microsoft.com/en-us/download/details.aspx?id=53587) and let me know if it solves for you?\r\nIn a future situation when you need to report an issue please fill the template and post your log instead of screenshots as it helps us assess the situation, otherwise is quite difficult.", "I have same error and above solution doesn't work. \r\n(Windows 10)", "@dzid26 Could you please provide all the info (OS, Python distribution and version, TensorFlow version, stack trace etc and other relevant information)? Otherwise we won't be able to help you. Thanks.", "Win10 64bit, \r\nPython.org v3.5.2:4def2a2901a5, MSC v.1900 64 bit (AMD64)] on win32\r\nTensorflow 0.11.10 for GPU, \r\n\r\n\r\n```\r\n> >pip3 install --upgrade tensorflow-gpu\r\n> Requirement already up-to-date: tensorflow-gpu in c:\\program files\\python35\\lib\\site-packages\r\n> Requirement already up-to-date: werkzeug>=0.11.10 in c:\\program files\\python35\\lib\\site-packages (from tensorflow-gpu)\r\n> Collecting protobuf>=3.2.0 (from tensorflow-gpu)\r\n>   Downloading protobuf-3.3.0.tar.gz (271kB)\r\n>     100% |################################| 276kB 1.0MB/s\r\n> Requirement already up-to-date: wheel>=0.26 in c:\\program files\\python35\\lib\\site-packages (from tensorflow-gpu)\r\n> Requirement already up-to-date: six>=1.10.0 in c:\\program files\\python35\\lib\\site-packages (from tensorflow-gpu)\r\n> Requirement already up-to-date: numpy>=1.11.0 in c:\\program files\\python35\\lib\\site-packages (from tensorflow-gpu)\r\n> Requirement already up-to-date: setuptools in c:\\program files\\python35\\lib\\site-packages (from protobuf>=3.2.0->tensorflow-gpu)\r\n> Requirement already up-to-date: appdirs>=1.4.0 in c:\\program files\\python35\\lib\\site-packages (from setuptools->protobuf>=3.2.0->tensorflow-gpu)\r\n> Requirement already up-to-date: packaging>=16.8 in c:\\program files\\python35\\lib\\site-packages (from setuptools->protobuf>=3.2.0->tensorflow-gpu)\r\n> Requirement already up-to-date: pyparsing in c:\\program files\\python35\\lib\\site-packages (from packaging>=16.8->setuptools->protobuf>=3.2.0->tensorflow-gpu)\r\n> Building wheels for collected packages: protobuf\r\n>   Running setup.py bdist_wheel for protobuf ... done\r\n>   Stored in directory: C:\\Users\\dzidm\\AppData\\Local\\pip\\Cache\\wheels\\1b\\42\\a0\\4c7343df5b629ec9c75655468dce7652b28026896b0209ba55\r\n> Successfully built protobuf\r\n> Installing collected packages: protobuf\r\n>   Found existing installation: protobuf 3.2.0\r\n>     Uninstalling protobuf-3.2.0:\r\n>       Successfully uninstalled protobuf-3.2.0\r\n> Successfully installed protobuf-3.3.0\r\n```\r\n\r\n\r\n\r\n\r\nAnd then the full error:\r\n```\r\nPython 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 51, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n```\r\n", "@dzid26 could you check if your cuDNN and CUDA DLLs are properly set in your `%PATH%`? TF 0.11 or you meant 1.1?", "![image](https://cloud.githubusercontent.com/assets/841061/25648829/ff785c2a-2f9d-11e7-97f9-5ed3196f5d9e.png)\r\nSeems ok, I guess. The same error was present, when I tried running the command without cuDNN even being installed.\r\nI am actually surprised that the error message isntt more detailed. Is there a way to see what DLL is it complaining about ?", "Your CUDA is an unsupported version. TensorFlow only supports CUDA 8.0 and cuDNN 5.1 on WIndows. \r\nThe error message is indeed uninformative and this is been addressed on #9170.", "@dzid26 @tonymdsl did you have any progress with the solution provided? Please let us know if it worked!", "No is the same error \r\n\r\n\r\nPython 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Imposs\u00edvel localizar o m\u00f3dulo especificado.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 51, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Imposs\u00edvel localizar o m\u00f3dulo especificado.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Tonymds\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>> hello = tf.constant('Hello, TensorFlow!')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nNameError: name 'tf' is not defined\r\n>>> sess = tf.Session()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nNameError: name 'tf' is not defined", "![capturar](https://cloud.githubusercontent.com/assets/17919329/25676826/6ec74896-303b-11e7-8b76-b295ee59f174.JPG)\r\n", "Just by seeing your `%PATH%` screenshot is still difficult to conclude everything is properly installed. Could you make sure your cuDNN DLLs are properly set as CUDA's? This is most likely a CUDA/cuDNN misconfiguration, assuming your TF version is the latest with GPU support, as you didn't specify.", "is working now the problem is i use cudNN 6.0 and now i put the cudNN 5.1 and now it's working tank u very much for the help", "@tonymdsl TensorFlow only supports cuDNN 5.1 on Windows, glad it's working now! \r\nThank you for reporting, this issue can be closed.", "Finally it worked for me too. But it was not obvious that /bin folder\nwithin cudann was supposed to be add.\n\nAlso this instruction on the website is inaccurate because CUDA 8.0\ndocumentation doesn't mention setting up %path%. And that is not even\nrelevant, since the path is added automatically by the installer.\n\nThe main problem is with cudann nvidia's instructions.\n\n\n\nAnyway, hopefully better installation process will be developed in the\nfuture. Thanks guys\n\nRadek\n\nOn Wed, May 3, 2017 at 5:24 PM, Skye Wanderman-Milne <\nnotifications@github.com> wrote:\n\n> Closed #9603 <https://github.com/tensorflow/tensorflow/issues/9603>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9603#event-1068015874>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAzVZY915eM0fzDAs3Pg8983EUXswMZQks5r2PCGgaJpZM4NOzR3>\n> .\n>\n", "For users who find this issue when searching for the error message, I've created a script for diagnosing common TensorFlow on Windows installation issues. Please download the script from https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c and run `python tensorflow_self_check.py`. It will print suggestions for how to fix your installation. Let me know if you are still facing problems after running the script."]}, {"number": 9602, "title": "Corrected SummaryHook with SummarySaverHook.", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks!"]}, {"number": 9601, "title": "Fix tf_env_collect.sh on macos by avoiding >>& redirection", "body": "Avoid using redirection \">>& foo.txt\".\r\nInstead use \"2>&1  >> foo.txt\"\r\n\r\nFixes #9587", "comments": ["Thank you! \ud83d\udc4d "]}, {"number": 9600, "title": "Why the basic function of different rnn cells are different?", "body": "I'd like to tackle two issues. The first one is about the initializer. I can define initializer in `LSTMCell ` but not in `GRU` cell. The second one is `layer_normalization`. There is `LayerNormBasicLSTMCell` available for using layer normalization on LSTM cell. But there is not other kinds of cell used in that way. I wonder why not make this general functions available for all kinds of cells?\r\n", "comments": ["PRs are welcome.", "If there is no volunteer yet, can I try this issue?\r\nI reviewed source codes of GRUCell, LSTMCell, and LayerNormBasicLSTMCell.\r\nI think I can give it a shot.", "If making API changes I encourage sooner rather than later. They should be\nbackwards compatible. I'll move rnncells back to core soon and it will be\nharder to make changes after that.\n\nOn May 4, 2017 10:38 AM, \"Chris Hoyean Song\" <notifications@github.com>\nwrote:\n\n> If there is no volunteer yet, can I try this issue?\n> I reviewed source codes of GRUCell, LSTMCell, and LayerNormBasicLSTMCell.\n> I think I can give it a shot.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9600#issuecomment-299256748>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim1zLJxrq9rLxH13veYxsl8xplZ8wks5r2g0VgaJpZM4NOdFo>\n> .\n>\n", "@ebrevdo Okay, I'll make it quick.\r\n\r\nThere are two tasks.\r\n1. Add initializer parameter to GRUCell, MultiRNNCell\r\nI've done this issue. I'll make a PR for this one first.\r\n\r\n2. Add layer_norm, norm_gain, norm_shift parameters\r\n to TimeFreqLSTMCell, CoupledInputForgetGateLSTMCell, GridLSTMCell, BidirectionalGridLSTMCell ( all LSTMCells in rnn_cell.py )\r\n\r\n```\r\n    Args:\r\n      layer_norm: If `True`, layer normalization will be applied.\r\n      norm_gain: float, The layer normalization gain initial value. If\r\n        `layer_norm` has been set to `False`, this argument will be ignored.\r\n      norm_shift: float, The layer normalization shift initial value. If\r\n        `layer_norm` has been set to `False`, this argument will be ignored.\r\n```\r\n\r\nThis issue will take some more time to apply because I couldn't find a way to make general wrapper like `LayerNormWrapper`(I named it).\r\n\r\nI think I need to add layer_norm parameters to all those LSTMCells, and implement it separately.\r\nIf you have any good idea, please tell me.\r\n\r\n", "https://github.com/chris-chris/tensorflow/commit/a9ddcbddddb3d8a375c1e128d3c21b78e8bef2f6\r\n\r\nI applied layer normalization to CoupledInputForgetGateLSTMCell. \r\nBut I'm not sure that this is the right application. So I need some reviews.\r\nI didn't make a PR yet.\r\n\r\nPlease leave a comment if you have any feedback.\r\n\r\nI'm now reading the references for layer normalization now...\r\n\r\n[Reference]\r\nhttps://arxiv.org/abs/1607.06450\r\n\"Layer Normalization\"\r\nJimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton", "Closing this issue since it looks like the corresponding PR has been merged. Please let me know if I should reopen."]}, {"number": 9599, "title": "couldn't find libtensorflow_demo.so", "body": "java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader\r\nI tried to integrate the tensorflow android sample to my existing project but the TensorFlowClassifier cannot execute since libtensorflow_demo.so is not loaded. What should I do?", "comments": ["You'll need to build it too; it's defined in tensorflow/examples/android/BUILD. Alternatively you can download the pre-built .so files [here](https://ci.tensorflow.org/view/Nightly/job/nightly-android/).", "thank you for this answer..\r\nI already have a libtensorflow_demo.so file placed in my jnilibs, but yet, it can't be found.\r\nthis is the error java.lang.UnsatisfiedLinkError: No implementation found for int ph.com.spamast.mliapp.TensorFlowClassifier.initializeTensorFlow()...\r\n\r\nI will try now the files you refer.. thanks again!\r\n", "What is the content of your APK? You can see this with e.g. `unzip -v tensorflow_demo.apk`\r\n\r\nNote that you need all the .so files present at the highest architecture level any of them are present at. So if you have one added to your apk in libs/arm64-v8a, all of the others used need to be in that directory as well.", "Already added the files libandroid_tensorflow_lib.lo, libpthread.so, libtensorflow_demo.so, and libtensorflow_inference.so to jniLibs, yet, still have the same error.\r\n\r\nAt the moment, still decompiling tensorflow_demo.apk to check its contents.\r\n\r\nthank you @andrewharp ", "I have tried to configure JNI. I created native classes, Application.mk, Android.mk, and imported several C++ files.. Seems like I got lost & now I have this error.\r\n\r\nError:error: 'errno' was not declared in this scope\r\nError:error: 'EINTR' was not declared in this scope\r\nError:Execution failed for task ':app:ndkBuild'.\r\n> Process 'command 'C:/Users/user/AppData/Local/Android/sdk/ndk-bundle/ndk-build.cmd'' finished with non-zero exit value 2\r\n\r\nAlso modified the build.gradle with this:\r\n task ndkBuild(type: Exec, description: 'Compile JNI source via NDK'){\r\n  commandLine \"C:/Users/user/AppData/Local/Android/sdk/ndk-bundle/ndk-build.cmd\",\r\n             'NDK_PROJECT_PATH=build/intermediates/ndk',\r\n             'NDK_LIBS_OUT=src/main/jniLibs',\r\n            'APP_BUILD_SCRIPT=src/main/jni/Android.mk',\r\n            'NDK_APPLICATION_MK=src/main/jni/Application.mk',\r\n            '-j1'\r\n}\r\n    tasks.withType(JavaCompile){\r\n        compileTask -> compileTask.dependsOn ndkBuild\r\n\r\n    }\r\n\r\nSorry, newbie to android here.", "What is the content of your APK?\r\n\r\nWe don't use Android/application.mk to build TF, so I would not suggest going down this path.\r\n\r\nWhat OS are you developing on? You should be placing the libs in the \"libs/<target>\" folders.\r\n\r\nAlso what version of TF are you using? There are currently no native methods in TensorFlowImageClassifier, so I don't see how this could be native libraries related with any recent release. And if you're changing package names you're really outside the scope of TF support.", "issue solved..\r\n\r\nYour answer at the top is correct.\r\n\r\n> Note that you need all the .so files present at the highest architecture level any of them are present at. So if you have one added to your apk in libs/arm64-v8a, all of the others used need to be in that directory as well.\r\n\r\n> ", "Thank you.. @andrewharp "]}, {"number": 9598, "title": "Fix a link error in the doc of histogram_summary", "body": "As mentioned in [issue 9467](https://github.com/tensorflow/tensorflow/issues/9467), the link \"look '[here](https://www.tensorflow.org/code/tensorflow/contrib/deprecated/__init__.py)'\" can not point to the right page in the [doc of histogram_summary](https://www.tensorflow.org/api_docs/python/tf/contrib/deprecated/histogram_summary), so I change the link to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/deprecated/__init__.py.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 9597, "title": "Invalid link in https://www.tensorflow.org/deploy/distributed", "body": "Seems that the [CIFAR-10 multi-GPU trainer](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/image/cifar10/cifar10_multi_gpu_train.py) link in https://www.tensorflow.org/deploy/distributed is broken. Actually this code only exists <= r0.12. There is three ways to fix it:\r\n  1. Use an old version such as  [CIFAR-10 multi-GPU trainer](https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow_models/tutorials/image/cifar10/cifar10_multi_gpu_train.py)\r\n  2. Remove this link in the doc page\r\n  3. Create a new cifar10_multi_gpu_train.py file for r1.1\r\n\r\nI can work on this issue, is there any suggestions on which way to go?\r\n\r\nPlease go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@wolffg can you comment or further triage this issue? Thanks.", "Actually I found that this issue has already been fix by [this commit](https://github.com/tensorflow/tensorflow/commit/0c08c585591152046ca1e6781d1f2fa573427dfc), seems that the https://www.tensorflow.org is not updated yet, will close this issue."]}, {"number": 9596, "title": "Synchronous distributed tensorflow training doesn't synchronize among workers", "body": "### System Information:\r\n- **Debian 4.5.5**\r\n- **TF installed from binary (pip3 install tensorflow-gpu==1.0.1 --user)**\r\n- **TF version: v1.0.0-65-g4763edf-dirty 1.0.1**\r\n- **Bazel version: N.A.**\r\n- **CUDA 8.0 cuDNN v5.1**\r\n\r\n### Steps to reproduce\r\n1. Make a directory and download the following files into it:\r\n[training.py](https://gist.github.com/GD06/b88d4b20a4587add984323525bbf4be2) [run.sh](https://gist.github.com/GD06/0bdb36ba6b76070b7cd7fadfd30fce6b)\r\n2. Run the command ./run.sh to simply reproduce this issue.\r\n\r\n### Detailed descriptions for the bug\r\n\r\nRecently, I tried to deploy the synchronous distributed tensorflow training on the cluster. I followed the tutorial and the inception example to write my own program. The [training.py](https://gist.github.com/GD06/b88d4b20a4587add984323525bbf4be2) is from other user's [implementation](http://ischlag.github.io/2016/06/12/async-distributed-tensorflow/), which follows the same API usage as the official example. I modified it to enable it running on a single machine with multiple GPUs by making them communicate through localhost and mapping each worker to see only one GPU.\r\n\r\nThe [run.sh](https://gist.github.com/GD06/0bdb36ba6b76070b7cd7fadfd30fce6b) launched three processes. One of them is the parameter server and the others are two workers implemented by between-graph replication. I created the training supervisor by tf.train.Supervisor() to manage multiple sessions in the distributed training for the initialization and synchronization. \r\n\r\nI expect these two workers would synchronize each batch and work in the same epoch. However, the worker 0, which is launched prior to the worker 1, completed the whole training set without waiting for the worker 1. After that, the process of the worker 0 finished training process and exited normally while worker 1 behaved like falling into the deadlock and keep near 0% utilization of CPU and GPU for several hours.\r\n\r\nBased on my observation, I suspect these two workers didn't communicate and synchronize at all for the data they passed. I report this problem as a bug because I create the optimizer tf.train.SyncReplicasOptimizer as suggested by the official website and the inception example. However, it seems that the synchronization behaviors, if any, are very strange and the program can not exit normally.\r\n\r\n### Source code / logs\r\nTwo files:\r\n[training.py](https://gist.github.com/GD06/b88d4b20a4587add984323525bbf4be2): This file contains the source code for the parameter server and workers created to use synchronous distributed optimizers (tf.train.SyncReplicasOptimizer). \r\n[run.sh](https://gist.github.com/GD06/0bdb36ba6b76070b7cd7fadfd30fce6b): This file launched the parameter server and the workers.\r\nLog:\r\nPlease produce according to the steps and look at worker_0_log and worker_1_log\r\n\r\n### Update\r\nTo ensure that two workers don't synchronize with each other, I write another [training.py](https://gist.github.com/GD06/b56d62b718bbd0b033703320e4b214dc) by making the worker 1 exist after the first time output information. Then the worker 0 continue to execute without waiting for the worker 1 and obtain the final trained model. This kind of behavior surely disobeys the definition of the synchronous distributed training.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@andydavis1 Thank you for your kind suggestions! Actually, I found the [similar problem](http://stackoverflow.com/questions/41293576/distributed-tensorflow-good-example-for-synchronous-training-on-cpus) on the StackOverflow and these are no any useful solutions so far.\r\n\r\nSince I don't think we use the optimizer and supervisor in any incorrect way, I put this as an issue. I sincerely hope there is anyone helping us to understand the reason if it's not a bug.", "@GD06 @andydavis1  I am a rookie in developing DL applications with tensorflow and mxnet. Recently there is a  synchronize problem between my TF workers which I suspect is the same problem mentioned in this issue.\r\nI have run the code uploaded by @GD06 in my server with titanX GPUs and the program also gets blocked while I still can't find the error in your code (just like ours) by myself.\r\nSo have you solved the problem? Would you please let us know if there is any update? Thanks very much!", "@andydavis1 To ensure that the workers executing asynchronously, I improve the [training.py](https://gist.github.com/GD06/b56d62b718bbd0b033703320e4b214dc) and make worker 1 exist after the first time output information. As expected, the worker 0 continue to execute without waiting to the worker 1. ", "There is a known issue with sync_rep_opt_v2 with the device setter/chooser related to the allocation of the local variable created in the sync_rep_opt_v2. You can either use the old sync_rep_opt or wait until that is fixed (where we might need to have similar signature anyway). Thanks.", "@jmchen-g Thanks a lot! Would you mind reopening this issue? I think this issue should be clarified that it's not caused by incorrect API uses. Otherwise, other developers will be still very confused in such examples as in the official guide and tensorflow examples. ", "@andydavis1 Would you mind reopening this issue? Or at least you need to label this issue as the same/similar to the known issue pointed by @jmchen-g.\r\nThanks! ", "Can I have a question related to thread?\r\nI have no idea about this page a little, so Is there multi-thread code in this page?\r\nPlease, I really wanna solid information that I catch up synchronous & threading programming\r\nThanks.", "@HokyungLee \r\nThere is no any multi-thread code in this page. The script run.sh is only used to start the distributed training by starting the worker and parameter server in a multi-process way.\r\nWe regard each GPU as a worker and a CPU process as a parameter server.", "Thank you for answering\r\nIt makes me help a lot @GD06 ", "It seems that this issue is still closed. Is it being tracked under a separate ID or has it been resolved?"]}, {"number": 9595, "title": "[issue#9328]fix invalid pointer when free()", "body": "Fix the [issue#9328](https://github.com/tensorflow/tensorflow/issues/9328) of TensorFlow v1.0 images.", "comments": ["Can one of the admins verify this patch?", "@caisq @girving Please check.", "@tensorflow-jenkins test this please", "Linux XLA didn't exist at r1.0, so I'm assuming this is probably good.  Merging.", "@vrv Looks like this was only merged into r1.0 and is not currently in master or any of the later releases. Should we merge this into those branches as well?", "I don't know, maybe see the original bug for context?", "I see, looks like it was planned in that issue to merge into r1.0 specifically. No worries then."]}, {"number": 9594, "title": "How can I check the test coverage?", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.12\r\n- **TensorFlow installed from (source or binary)**: (binary) pip install tensorflow\r\n- **TensorFlow version (use command below)**: \r\ntensorflow (1.1.0)\r\ntensorflow-gpu (1.0.1)\r\n- **Bazel version (if compiling from source)**: 0.4.5-homebrew\r\n- **CUDA/cuDNN version**: 7.0\r\n- **GPU model and memory**: AMD Radeon R9 M370X 2048 MB\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI'm planning to develop some test codes for contribution.\r\nTherefore, I need to find some untested codes using code coverage tools.\r\n\r\nI have tried to find the way to check test coverage in this project.\r\nBut I couldn't figure that out.\r\n\r\nIs there anyone tell me how to check it out?\r\n\r\nI'm now running tests like this.\r\n```\r\n./configure\r\nbazel test //tensorflow/tensorboard/backend:application_test\r\n```\r\n\r\nSincerely\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 9593, "title": "libtensorflow.so: undefined reference to `__cpu_model'", "body": "When linking with the tensorflow C++ library, the following error occurs: libtensorflow.so: undefined reference to `__cpu_model'\r\n\r\nSeems to be related to issue #7223\r\n\r\nI manage to work around this error with: ( as done by https://github.com/tensorflow/tensorflow/pull/7241/commits/d7955a66088567ade60213448bbab861de9055cd)\r\n`#ifndef USE_SSE_CRC32C`\r\nin the file tensorflow/core/lib/hash/crc32c_accelerate.cc\r\n\r\nDoing this removed the error.\r\n\r\nSystem information:\r\nUbuntu 16.04 64 bit\r\nIntel i5 CPU\r\nNVIDIA GTX 980 GPU\r\nBuilt using CMake with BUILD_SHARED_LIB enabled which creates the libtensorflow.so file\r\n", "comments": ["This does seem to be the same problem as #7223. Can you post what compiler you're using to build TensorFlow? I wonder if we need to expand the check in https://github.com/tensorflow/tensorflow/pull/7241/commits/d7955a66088567ade60213448bbab861de9055cd.", "The compiler used is gcc 5.4:\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\n", "Looks like gcc 5 has a similar bug to the one referenced in #7223: https://bugs.launchpad.net/ubuntu/+source/gcc-5/+bug/1568899\r\n\r\nAccording to the bug report, a workaround is to \"add -lgcc_s -lgcc at the end of the g++ command that links the shared library\".\r\n\r\n@smistad do you think you could wade into the CMake build and try the workaround? (Even if you don't plumb it all the way through maybe you can at least confirm it works by printing and manually modifying the compiler commands.)", "Sure, I will try it and if it works I can add an \"if GCC version 5\" in cmake, add the libraries mentioned to the linker and create a pull request for it.", "I am using clang 4.0.0 and also having the same problem. However as the compiler is not GCC then the line with target_link_libraries() is not activated. Commenting out the IF() line solves the problem."]}, {"number": 9592, "title": "Added 10 comments that illustrate each tests in EventAccumulator.", "body": "I added 10 comments for event_accumulator module in Tensorboard.\r\n\r\nLet me fix it if you find any misunderstanding toward the test codes.", "comments": ["Can one of the admins verify this patch?", "@vrv Thank you! :)"]}, {"number": 9591, "title": "Several links error in README.md.", "body": "### System information\r\n- **OS: Windows 10 Enterprise x64**:\r\n- **Browser: Chrome 58 x64**:\r\n- **Location: China**:\r\n\r\n### Issue\r\nThe [Installing TensorFlow](https://www.tensorflow.org/install/) link from [README.md](https://github.com/tensorflow/tensorflow) fails with error:\r\n```\r\nError: Not Found\r\n\r\nThe requested URL /versions/r0.12/install/index.html was not found on this server.\r\n```\r\n\r\nThe [Community](https://www.tensorflow.org/community/) link fails with error:\r\n```\r\nError: Not Found\r\n\r\nThe requested URL /versions/r0.12/community/index.html was not found on this server.\r\n```\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Please also include more information on what commands you ran to produce the output. Thanks!", "@skye Thanks for reply. I know it's not a product bug, but it's a doc bug. The README.md doc has several invalid site links, i don't think this should be asked in StackOverflow.", "Ah sorry, didn't read the issue closely enough!", "Hm, the \"Installing Tensorflow\" link at https://github.com/tensorflow/tensorflow goes to https://www.tensorflow.org/install/, and the \"Community\" link goes to https://www.tensorflow.org/community/. Am I missing something?", "Yes, you are right. But the two links redirect to invalid sites with a \"`404 Not Found`\" result in my environment.\r\nhttps://www.tensorflow.org/install/ redirects to \r\n[https://www.tensorflow.org/versions/r0.12/install/index.html](https://www.tensorflow.org/versions/r0.12/install/index.html)\r\n\r\nand https://www.tensorflow.org/community/ redirects to [https://www.tensorflow.org/versions/r0.12/community/index.html](https://www.tensorflow.org/versions/r0.12/community/index.html)\r\n\r\nbtw: I'm in China, hope this helps.", "@dr4b does this ring any bells for you? (See the above comment.) Those links don't redirect for me, but I'm not sure if being in China should affect this.", "It seems like you might be accessing an old version of the site somehow. I'll ping our infrastructure team to see if they can look into this. In the meantime, if you have access to the github, you can look at the docs source directly:\r\n\r\nInstallation page: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/install/index.md\r\nCommunity page: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/community/index.md\r\n\r\nAll the non-API pages should be in that docs_src directory, and the documentation for individual API methods, classes, etc. is generated from the docstrings in the source files. Let me know if you need help finding something.", "@skye Thanks."]}, {"number": 9590, "title": "Memory Leak from Deep Learning Training Step? (Finalized Graph)", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes, although my code is somewhat based on the MNIST deep learning tutorial.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 14.04 VERSION=\"14.04.5 LTS, Trusty Tahr\"\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary (I think, not 100% sure since it's been a few months since install. How can I check?)\r\n- **TensorFlow version (use command below)**:\r\n('v0.11.0-2614-g14aeb08-dirty', '0.12.0-rc0')\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\nCUDA Version 8.0.44\r\n- **GPU model and memory**:\r\nGeForce GTX 780M 4GB\r\n- **Exact command to reproduce**:\r\n`self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels, self.keepratio: self.training_keep_rate})`\r\n\r\n### Describe the problem\r\n\r\nI apologize if this is not an actual bug; I am relatively new to TensorFlow. I have posted on StackOverflow [here](http://stackoverflow.com/questions/43695085/tensorflow-deep-learning-memory-leak) and the only response I have gotten suggests filing a bug report here.\r\n\r\nIf I comment the sess.run line above, _and only that line_, out (but still do all my pre-processing and validation/testing and such for a few thousand training batches), the memory leak does not happen.\r\n\r\nThe leak is on the order of a few GB per hour (I am running Ubuntu, and have 16GB RAM + 16GB swap; the system becomes very laggy and unresponsive after 1-3 hours of running, when about 1/3-1/2 the RAM is used, which is a bit weird to me since I still have lots of RAM and the CPU is mostly free when this happens...)\r\n\r\nHere is some of the initializer code (only run once, at the beginning) if it is relevant:\r\n```\r\n\r\n    with tf.name_scope('after_final_layer') as scope:\r\n        self.layer1 = weights[\"wc1\"]\r\n        self.y_conv = network(self.x, weights, biases, self.keepratio)['out']\r\n        variable_summaries(self.y_conv)\r\n        # Note: Don't add a softmax reducer in the network if you are going to use this\r\n        # cross-entropy function\r\n        self.cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.y_conv, self.y_true, name = \"softmax/cross_ent\"), name = \"reduce_mean\")\r\n        self.train_step = tf.train.AdamOptimizer(learning_rate, name = \"Adam_Optimizer\").minimize(self.cross_entropy)\r\n\r\n        self.prediction = tf.argmax(self.y_conv, 1)\r\n        self.correct_prediction = tf.equal(self.prediction, tf.argmax(self.y_true, 1))\r\n\r\n        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\r\n\r\n        if tensorboard:\r\n            # Merge all the summaries and write them out to the directory below\r\n            self.merged = tf.summary.merge_all()\r\n            self.my_writer = tf.summary.FileWriter('/home/james/PycharmProjects/AI_Final/my_tensorboard', graph=self.sess.graph)\r\n\r\n        # self.sess.run(tf.initialize_all_variables()) #old outdated way to do below\r\n        tf.global_variables_initializer().run(session=self.sess)\r\n        self.sess.graph.finalize() #make sure nothing new is added to graph\r\n\r\n```\r\nNotice that I have finalized the graph, so nothing new should be added to it.\r\n\r\nAm I doing something wrong/is this expected behavior, or is this a real bug?\r\n\r\nI have attached the source code as well (two .py files in directory).  **Note: I am happy put in the work to reduce the source to a minimal recreation of the bug, but first I'd like verification that 1) this would be helpful (i.e. that the above info is not enough) and that 2) this is probably a bug, and not just an obvious beginner mistake on my part.**\r\n\r\nThank you in advance.\r\n\r\n[source.zip](https://github.com/tensorflow/tensorflow/files/969906/source.zip)", "comments": ["@jart could you take a look at the summary portion to see if you find anything obvious there?\r\n\r\nI don't see obvious leak.\r\n\r\nCould you run with the env variable `TF_CPP_MIN_VLOG_LEVEL=1` *look at anything with `__LOG_MEMORY__` and `tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)`?\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/1824 is a good example of debugging.", "@drpngx Every thousand steps, instead of doing a normal training step, I did \r\n\r\n```\r\n                run_metadata = tf.RunMetadata()\r\n                self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels,\r\n                                                      self.keepratio: self.training_keep_rate, },\r\n                          options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)\r\n                text_file = open(\"Output.txt\", \"a\")\r\n                text_file.write(\"\\n\\n\\nstep %s\\n:\" % self.training_step_counter)\r\n                text_file.write(str(run_metadata))\r\n\r\n                text_file.close()\r\n\r\n```\r\nDid I do it correctly?  The output is attached for steps 0, 1000, 2000, 3000, 4000 (by which time a few GB have leaked).  Search for \"step [number]\" to go quickly between them.  I don't see anything about \\_\\_LOG_MEMORY\\_\\_ in there.  If I did it wrong, please let me know and I'll run it again.  Thanks!\r\n\r\n[Output.txt](https://github.com/tensorflow/tensorflow/files/982152/Output.txt)\r\n", "It looks like it didn't work. You need to set the env variable, something like this\r\n\r\n```\r\nenv TF_CPP_MIN_LOG_LEVEL=1 python my_tensorflow_program.py\r\n```", "I tried again, running it like you directed.  I still do not see anything about \\_\\_LOG_MEMORY\\_\\_ in there.  If it's still not correct, the code is the same as above (every 1000 training steps I run the following)\r\n\r\n```\r\n                run_metadata = tf.RunMetadata()\r\n                self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels,\r\n                                                      self.keepratio: self.training_keep_rate, },\r\n                          options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)\r\n                text_file = open(\"Output.txt\", \"a\")\r\n                text_file.write(\"\\n\\n\\nstep %s\\n:\" % self.training_step_counter)\r\n                text_file.write(str(run_metadata))\r\n\r\n                text_file.close()\r\n\r\n```\r\n\r\nand the command I ran was\r\n\r\n```\r\nenv TF_CPP_MIN_LOG_LEVEL=1 python deep_1_02.py\r\n```\r\n\r\nSorry if I'm not doing it correctly; I appreciate your help!\r\n\r\n[Output.txt](https://github.com/tensorflow/tensorflow/files/987324/Output.txt)\r\n", "Sorry, try setting the min `VLOG` level (`TF_CPP_MIN_VLOG_LEVEL`). There should be a lot of spew.", "Note that setting `TF_CPP_MIN_VLOG_LEVEL` if `TF_CPP_MIN_LOG_LEVEL` is set will have no effect. So you have to unset `TF_CPP_MIN_LOG_LEVEL` first.\r\n\r\nI wrote [memory_util](https://github.com/yaroslavvb/memory_util) to parse this log output. Save log to `stderr.txt`, and then do something like this to get a human readable timeline\r\n\r\n`memory_util.print_memory_timeline(open('stderr.txt').read(), ignore_less_than_bytes=10**6)\r\n`", "No luck getting any other kinds of output.  What am I looking for?  Will it print out in the console or is it going to be stored in my run_metadata = tf.RunMetadata() variable?\r\n\r\nI've tried:\r\n- unsetting the env variables\r\n- os.environ['TF_CPP_MIN_VLOG_LEVEL'] = \"1\"\r\n- os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"1\"\r\n- restarting the computer\r\n- Exporting both versions of the above. (Doing it in the terminal instead of in the Python code)\r\n- Looking for results in both my output file and in my terminal\r\n\r\nWhat exactly am I looking for?  Any ideas on why I'm not getting all the output?  Thank you again for the help.", "I just did this on my mac, using Mac CPU nightly from last week:\r\n\r\n```\r\nunset TF_CPP_MIN_LOG_LEVEL\r\nexport TF_CPP_MIN_VLOG_LEVEL=1\r\npython -c \"import tensorflow as tf; s = tf.Session(); s.run(tf.ones(()))\"\r\n\r\n```\r\nand I saw a bunch of messages like this\r\n\r\n```\r\n2017-05-09 12:24:27.745962: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: \"Unknown (from Proto)\" tensor { dtype: DT_FLOAT shape { } allocation_description { requested_bytes: 4 allocator_name: \"cpu\" ptr: 140654466064000 } } }\r\n2017-05-09 12:24:27.746192: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocator_name: \"cpu\" }\r\n2017-05-09 12:24:27.746206: I tensorflow/core/framework/op_kernel.cc:1034] Instantiating kernel for node: ones = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 1>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()\r\n2017-05-09 12:24:27.746243: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: \"Unknown (from Proto)\" tensor { dtype: DT_FLOAT shape { } allocation_description { requested_bytes: 4 allocator_name: \"cpu\" ptr: 140654466061120 } } }\r\n2017-05-09 12:24:27.776009: I tensorflow/core/framework/op_kernel.cc:1034] Instantiating kernel for node: _retval_ones_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ones)\r\n2017-05-09 12:24:27.776123: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogStep { step_id: 1 handle: \"->ones:0//0/;0\" }\r\n2017-05-09 12:24:27.776198: I tensorflow/core/common_runtime/executor.cc:1556] Process node: 0 step 1 _SOURCE = NoOp[]() is dead: 0\r\n2017-05-09 12:24:27.776254: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: \"Unknown (from Proto)\" tensor { dtype: DT_FLOAT shape { } allocation_description { requested_bytes: 4 allocator_name: \"cpu\" ptr: 140654466065440 } } }\r\n\r\n```", "```\r\nunset TF_CPP_MIN_LOG_LEVEL\r\nexport TF_CPP_MIN_VLOG_LEVEL=1\r\npython -c \"import tensorflow as tf; s = tf.Session(); s.run(tf.ones(()))\"\r\n```\r\nresults only in\r\n\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 780M\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\r\npciBusID 0000:01:00.0\r\nTotal memory: 3.97GiB\r\nFree memory: 3.64GiB\r\nW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2f6e280\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: \r\nname: GeForce GTX 780M\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\r\npciBusID 0000:07:00.0\r\nTotal memory: 3.97GiB\r\nFree memory: 3.92GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 780M, pci bus id: 0000:07:00.0)\r\n```\r\n\r\nDo I need to update my version or am I doing something else wrong? I'm using tf version 0.12.0-rc0, np version 1.12.0b1, Python version 2.7.6.  Thanks!", "Correct, your TF version is too old, you need at least 1.0, but perhaps a later version", "The issue is corrected in 1.1.  Thank you both for the help!  The reason I was using the old version is because [it says here that 0.12 is the latest stable version.](https://www.tensorflow.org/versions/)  If that is not the case I would suggest updating that page if possible to avoid other people making the same mistake.  Thanks again for your time and help!"]}, {"number": 9589, "title": "sparse_reshape could not generate correct SparseTensor shape before eval", "body": "**System information**\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X EL Capitan & CentOS7.3.1611\r\nTensorFlow installed from (source or binary): N/A (compiling from HEAD)\r\nTensorFlow version (use command below): 1.1.0\r\nCUDA/cuDNN version: none (AMD GPU)\r\nExact command to reproduce:\r\n\r\n````\r\n# python 2.7.12, tensorflow 1.1.0\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import gen_sparse_ops\r\nfrom tensorflow.python.framework import sparse_tensor\r\nfrom tensorflow.python.ops import array_ops\r\n\r\nori = tf.SparseTensor([[1,2],[3,4],[5,5]], [1,2,5], [10,10])\r\na = tf.sparse_reshape(ori, [100,1])\r\nprint(a.get_shape())  # will get TensorShape([Dimension(None), Dimension(None)]) instead of (TensorShape([Dimension(100), Dimension(1)]))\r\n````\r\n\r\n**Describe the problem**\r\nsparse_reshape could not generate correct SparseTensor shape before eval. (but it is correct with tf.Session().run(a))\r\nThis will cause some problems for further matrix operation if we want to eval later.\r\nThe issue came from sparse_ops.py, line 428:\r\n```SparseTensor( reshaped_ind, array_ops.identity(sp_input.values), reshaped_shape)``` \r\nSparseTensor could not convert ```dense_shape=reshaped_shape``` correctly before eval()\r\n", "comments": []}, {"number": 9588, "title": "Feature Request: SparseTensor operation", "body": "Hi, \r\nI am recently using SparseTensor. However, I found that there are a lot of math operations not supported for SparseTensor. For example, mod , floor, and argmin, etc. Do you have plans for extending the math operations of SparseTensor. \r\n\r\nThanks,\r\nAnthony", "comments": ["It's not currently a high priority, I think we may end up creating a\ndifferent object that's optimized for math operations.  In the meantime,\nPRs that extent sparsetensor functionality are welcome.\n\nOn May 2, 2017 9:49 AM, \"andydavis1\" <notifications@github.com> wrote:\n\n> Assigned #9588 <https://github.com/tensorflow/tensorflow/issues/9588> to\n> @ebrevdo <https://github.com/ebrevdo>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9588#event-1065912843>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim00f0xzz-k1QnrkijDyMFFdG2M6sks5r116YgaJpZM4NNvnv>\n> .\n>\n", "Got it. Luckily I had find some ways to bypass my problem currently. Thanks for your quick response.", "This is too broad, so I'm going to close.  More specific sparse tensor ops should be filed as separate issues (or submitted as PRs)."]}, {"number": 9587, "title": "tf_env_collect.sh script is not working well in Mac OS", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.12\r\n- **TensorFlow installed from (source or binary)**: (binary) pip install tensorflow\r\n- **TensorFlow version (use command below)**: \r\ntensorflow (1.1.0)\r\ntensorflow-gpu (1.0.1)\r\n- **Bazel version (if compiling from source)**: 0.4.5-homebrew\r\n- **CUDA/cuDNN version**: 7.0\r\n- **GPU model and memory**: AMD Radeon R9 M370X 2048 MB\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nThis script to extract the environment is not working well in my Mac. ( MacOS 10.12 )\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nI think we should replace &>> into >> in the script.\r\nThere are 4 *&>>* in this script.\r\n```\r\nc++ --version &>> $OUTPUT_FILE\r\n```\r\n\r\n```\r\nc++ --version >> $OUTPUT_FILE\r\n```\r\n\r\n\r\n\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nLet me show my results.\r\n```\r\n./tf_env_collect.sh \r\nCollecting system information...\r\ncat: /proc/1/cgroup: No such file or directory\r\n./tf_env_collect.sh: line 31: syntax error near unexpected token `>'\r\n./tf_env_collect.sh: line 31: `c++ --version &>> $OUTPUT_FILE'\r\n\r\n$ cat tf_env.txt \r\n\r\n== cat /etc/issue ===============================================\r\nDarwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\n```\r\n\r\nafter replacing &>> into >>, the script works well in my computer.\r\n\r\n```\r\n$ ./tf_env_collect.sh \r\nCollecting system information...\r\ncat: /proc/1/cgroup: No such file or directory\r\n2017-05-02 14:34:10.933872: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-02 14:34:10.933897: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-02 14:34:10.933903: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-02 14:34:10.933908: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-02 14:34:10.933912: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n./tf_env.sh: line 77: nvidia-smi: command not found\r\nWrote environment to tf_env.txt. You can review the contents of that file.\r\nand use it to populate the fields in the github issue template.\r\n\r\ncat tf_env.txt\r\n\r\n\r\n$ cat tf_env.txt \r\n\r\n== cat /etc/issue ===============================================\r\nDarwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\n\r\n== uname -a =====================================================\r\nDarwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n\r\n== cuda libs  ===================================================\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 8.1.0 (clang-802.0.38)\r\nTarget: x86_64-apple-darwin16.5.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy (1.12.1)\r\nnumpydoc (0.6.0)\r\nprotobuf (3.2.0)\r\ntensorflow (1.1.0)\r\ntensorflow-gpu (1.0.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.1.0\r\ntf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5\r\ntf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n\r\n== cuda libs  ===================================================\r\n```", "comments": ["Probably `2>&1 >> file` is the portable way to do that. Do you want to submit a PR?", "That doesn't seem to work either. It seems the fancy redirects aren't working within the shell script but do work from the command line."]}, {"number": 9586, "title": "Support custom loss function for DNNRegressor", "body": "DNNRegressor is commonly used, and it does not support customize the loss function, which limits itself.\r\n\r\nI wanna know if there are any schedule to support the customize loss function for DNNRegressor or is there any difficulties for supporting that?", "comments": ["What other loss function would you like to have?", "You can use `tf.contrib.learn.DNNEstimator` which takes a `head` as argument.\r\nYou can define any loss fn you want via `head`.", "I will use DNNEstimator, thanks for replying."]}, {"number": 9585, "title": "Links in RNN Tutorial are broken", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.12\r\n- **TensorFlow installed from (source or binary)**: (binary) pip install tensorflow\r\n- **TensorFlow version (use command below)**: \r\ntensorflow (1.1.0)\r\ntensorflow-gpu (1.0.1)\r\n- **Bazel version (if compiling from source)**: 0.4.5-homebrew\r\n- **CUDA/cuDNN version**: 7.0\r\n- **GPU model and memory**: AMD Radeon R9 M370X 2048 MB\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI found two broken links from the RNN Tutorial.\r\n\r\nhttps://www.tensorflow.org/versions/r0.12/tutorials/recurrent/\r\n\r\n1. [Penn Tree Bank] link is broken \r\n<img width=\"903\" alt=\"rnn_tutorial1\" src=\"https://cloud.githubusercontent.com/assets/3013964/25601837/ea13bdc6-2f29-11e7-8bd5-c70975f3e77b.png\">\r\nCurrent link url is \r\nhttp://www.cis.upenn.edu/~treebank/\r\n\r\n2. [building from source] link is broken\r\n<img width=\"1414\" alt=\"rnn_tutorial2\" src=\"https://cloud.githubusercontent.com/assets/3013964/25601838/ebfa28f0-2f29-11e7-9346-7c78c7ab9534.png\">\r\nCurrent link url is \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup#installing-from-sources\r\n", "comments": ["Thats r0.12. Using the latest version they work fine: https://www.tensorflow.org/tutorials/recurrent/", "@wesley42666 Ah Thanks! \ud83d\udc4d "]}, {"number": 9584, "title": "Remove comments about an unused argument", "body": "Remove comments about an unused argument in `tf.train.suffle_batch` and `tf.train.batch`. There are commented lines which exactly is:\r\n\r\n> Note: if `num_epochs` is not `None`, this function creates local counter\r\n  `epochs`. Use `local_variables_initializer()` to initialize local variables.\r\n\r\nBut, there is no argument called `num_epochs`. So, it is unnecessary comments! \ud83d\ude04 ", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 9583, "title": "TensorArray: Tried to write to index 18 but array is not resizeable and size is: 18", "body": "### Problem\r\nI wrote an application using TensorArray. It prints out error about allocate memory.\r\nFor each sample. It must create a lot of TensorArray to store temporary data.\r\nWith few number of samples (around 20), it passed smoothly 100 epochs.\r\nWhen I trained with the whole dataset (10.000 samples), it have never passed epoch 6. The stopped epochs are varied.\r\n\r\n### Logs\r\n2017-05-02 10:29:25,886 CFG INFO [Epoch 0] Shuffling data...                                                                                                                                     \r\n(0.058350346982479095, 0.76190478)                                                                                                                                                               \r\n2017-05-02 10:29:31.197277: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: Tried to read from index 23 but array size is: 23                                                   \r\n2017-05-02 10:29:31.197277: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: TensorArray bu/dec_c_ta_4628: Tried to write to index 23 but array is not resizeable and size is: 23\r\nTraceback (most recent call last):                                                                                                                                                               \r\n  File \"/work/vietld/py27/lib/python2.7/runpy.py\", line 174, in _run_module_as_main                                                                                                              \r\n  File \"/work/vietld/py27/lib/python2.7/runpy.py\", line 72, in _run_code                                                                                                                         \r\n    exec code in run_globals                                                                                                                                                                     \r\n  File \"/home/s1610204/tree-lstm/py/run.py\", line 45, in <module>                                                                                                                                \r\n    train(args)                                                                                                                                                                                  \r\n  File \"/home/s1610204/tree-lstm/py/run.py\", line 29, in train                                                                                                                                   \r\n    loss, acc = treelstm.train(session, train_data)                                                                                                                                              \r\n  File \"py/lstmtree.py\", line 175, in train                                                                                                                                                      \r\n    loss, acc, _ = session.run([self.full_loss, self.acc, self.train_op], feed_dict)                                                                                                             \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 778, in run                                                                                     \r\n    run_metadata_ptr)                                                                                                                                                                            \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 982, in _run                                                                                    \r\n    feed_dict_string, options, run_metadata)                                                                                                                                                     \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1032, in _do_run                                                                                \r\n    target_list, options, run_metadata)                                                                                                                                                          \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1052, in _do_call                                                                               \r\n    raise type(e)(node_def, op, message)                                                                                                                                                         \r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray bu/dec_c_ta_4628: Tried to write to index 23 but array is not resizeable and size is: 23                               \r\n         [[Node: bu/while_decode/dec/write_dec_c_ta/write_dec_c_ta = TensorArrayWriteV3[T=DT_FLOAT, _class=[\"loc:@bu/dec_c_ta\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](bu/while_decode\r\n/dec/cond_1/gather_dec_c_ta/Enter, bu/while_decode/Identity_3, bu/while_decode/dec/LSTM/add_6, bu/while_decode/Identity_1)]]                                                                     \r\n                                                                                                                                                                                                 \r\nCaused by op u'bu/while_decode/dec/write_dec_c_ta/write_dec_c_ta', defined at:                                                                                                                   \r\n  File \"/work/vietld/py27/lib/python2.7/runpy.py\", line 174, in _run_module_as_mai \"__main__\", fname, loader, pkg_name)                                                                                                              \r\n                                                                                                                                                         \r\n  File \"/work/vietld/py27/lib/python2.7/runpy.py\", line 72, in _run_code exec code in run_globals                                                                                                                                                                                                                                                                                     \r\n  File \"/home/s1610204/tree-lstm/py/run.py\", line 45, in <module>                                                                                                                                \r\n    train(args)                                                                                                                                                                                  \r\n  File \"/home/s1610204/tree-lstm/py/run.py\", line 20, in train                                                                                                                                   \r\n    treelstm = RecursiveLSTM(config)                                                                                                                                                             \r\n  File \"py/lstmtree.py\", line 137, in __init__                                                                                                                                                   \r\n    name='while_decode')                                                                                                                                                                         \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2623, in while_loop                                                                       \r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)                                                                                                                          \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2456, in BuildLoop                                                                        \r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)                                                                                                                                 \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2406, in _BuildLoop                                                                       \r\n    body_result = body(*packed_vars_for_body)                                                                                                                                                    \r\n  File \"py/lstmtree.py\", line 115, in decode_body                                                                                                                                                \r\n    r_dec_c_ta = dec_c_ta.write(i, c, name='write_dec_c_ta')                                                                                                                                     \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 279, in write                                                                             \r\n    name=name)                                                                                                                                                                                   \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 2823, in _tensor_array_write_v3                                                          \r\n    name=name)                                                                                                                                                                                   \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op                                                                      \r\n    op_def=op_def)                                                                                                                                                                               \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op                                                                               \r\n    original_op=self._default_original_op, op_def=op_def)                                                                                                                                        \r\n  File \"/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__                                                                                \r\n    self._traceback = _extract_stack()                                                                                                                                                           \r\n                                                                                                                                                                                                 \r\nInvalidArgumentError (see above for traceback): TensorArray bu/dec_c_ta_4628: Tried to write to index 23 but array is not resizeable and size is: 23                                             \r\n         [[Node: bu/while_decode/dec/write_dec_c_ta/write_dec_c_ta = TensorArrayWriteV3[T=DT_FLOAT, _class=[\"loc:@bu/dec_c_ta\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](bu/while_decode\r\n/dec/cond_1/gather_dec_c_ta/Enter, bu/while_decode/Identity_3, bu/while_decode/dec/LSTM/add_6, bu/while_decode/Identity_1)]]      \r\n\r\n------------------------\r\n### System information\r\n- **Operating system**: Altix-UV 3000, SUSE Enterprise Server 12 SP2\r\n- **TensorFlow installed from**: binary\r\n- **TensorFlow version**: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: No GPU, 256GB RAM\r\n- **Exact command to reproduce**:\r\n\r\nSYSTEM ENVIRONMENT: == cat /etc/issue ===============================================\r\nLinux altix-uv 3.12.62-60.64.8-default #1 SMP Tue Oct 18 12:21:38 UTC 2016 (42e0a66) x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION = 12\r\nVERSION=\"12-SP1\"\r\nVERSION_ID=\"12.1\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (SUSE Linux) 4.8.5\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux altix-uv 3.12.62-60.64.8-default #1 SMP Tue Oct 18 12:21:38 UTC 2016 (42e0a66) x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.12.1)\r\nprotobuf (3.2.0)\r\ntensorflow (1.1.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\n2017-05-02 10:42:09.139127: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-02 10:42:09.139314: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-02 10:42:09.139322: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-02 10:42:09.139328: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-02 10:42:09.139334: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nsched_getaffinity: Invalid argument\r\ncan't determine number of CPU cores: assuming 4\r\nsched_getaffinity: Invalid argument\r\ncan't determine number of CPU cores: assuming 4\r\ntf.VERSION = 1.1.0\r\ntf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5\r\ntf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /opt/cuda/8.0/lib64:/opt/cuda/8.0/lib:/work/vietld/cuda/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 77: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n### Source code / logs\r\nI dont know why github cant attach this .zip file\r\nPlease download it from https://drive.google.com/open?id=0BxQsywFyW2C7UUVSeHBHZ25mWXM\r\n", "comments": ["Arrays are zero-based, which means the first array element has index 0, and not 1, thus the last index of an 18 element array is 17, and not 18. Maybe your indexing system is for a one-based array. Try subtracting 1 to the indexing variable.", "The problem is that it ran few epochs before getting this error. Other word, it passed all sample several times in our dataset including training, validation and test set", "I'm not super familiar with TensorArrays, but I think the problem may arise from the size of TensorArrays being frozen once the gradient calculation begins, even if dynamic_size=True when you create the TensorArray. Perhaps @yuanbyu can comment more. Could you try sizing your arrays large enough to fit all elements when you construct them and see if that fixes the problem?", "The problem was solved by closed an unused TensorArray .\r\n\r\nI create 4 TensorArrays to store hidden state and memory state of LSTM for encoder and decoder.\r\nThe memory state is not used during decoding, then just remember to close it at running the session.\r\n\r\nMany thank guys.", "@viettan28 , can you clarify what you mean by closing the memory state?", "@viettan28 Hi, I encountered the same error, could you present your fixed code sample?", "I encountered the same error too.  I have tried to close all TensorArrays but it didn't help. I finally solved this problem by setting parallel_iterations=1 in the while_loop.\r\n\r\nI still don't know how this problem appears after found this in the [document about tf.while_loop](https://www.tensorflow.org/api_docs/python/tf/while_loop):\r\n> For correct programs, while_loop should return the same result for any parallel_iterations > 0.\r\n\r\nand this in the[ c++ implementation](https://github.com/tensorflow/tensorflow/blob/7bcbcc1392516a2b2d7a7abae2ccce7091c8dae3/tensorflow/core/kernels/tensor_array.h#L449).\r\n\r\nThe dynamic_size is indeed true and I suspect there is a bug in the while_loop parallelism.."]}, {"number": 9582, "title": "Branch 154781831", "body": "", "comments": ["Timeouts look unrelated again, merging."]}, {"number": 9581, "title": "Enhancement: Better Model Saving & Loading", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Pro\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.something\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: Feature Request; not bug\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nMuch of it is documented here in depth; especially the pain part: http://stackoverflow.com/questions/43708616/tensorflow-inference \r\n\r\nI would really really appreciate a way to save JUST the model and load JUST the model as a graph.  I might even be able to help in coding this feature.\r\n\r\nYou can do it however you want; but the easiest might be to use a scoping prefix such as 'model/stuff'  I would very much like to do this:\r\n\r\ndef inference(X):\r\n   create a model\r\n   return prediction_op\r\n\r\ndo your training however; with TFRecords; with feed dicts; with your custom queue runners etc...There are a million options...\r\n\r\ntf.train.ModelSaver(SCOPE_PARENT, PATH)\r\n\r\nwhere SCOPE_PARENT is the top level scope to save; so if I structure my scoping as such:\r\n\r\n'inputs/inputstuffs'\r\n'model/layer1' , 'model/layer2' etc etc \r\n'adams etc'\r\n\r\nit would save just 'model/layer1' (but not any of the gradient stuff...)\r\n\r\nthen at inference time I can do...\r\n\r\nmodel = tf.train.ModelLoader(PATH)\r\nthat model takes the initial input of the first layer of that graph; whatever that is.  Most commonly for inference I see feed_dict.\r\n\r\nso I can set up whatever kind of processing I want; either in memory based with feed_dicts or perhaps batch processing via queue runners; but the point is that the input is seperate from the model.\r\n\r\nAs it stands right now; I'm looking at TensorFlow for our use case as a non starter if the training input system is really this tightly bound to the inference system.  This type of thing really needs to be built...\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["It looks like you found a resolution to this in the SO post; is this feature request still relevant? Also does [SavedModel](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md) help you at all? (Sorry if you already went over this somewhere, just trying to clarify exactly what is being requested at this point.)", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}]