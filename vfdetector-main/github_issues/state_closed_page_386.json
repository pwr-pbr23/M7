[{"number": 42404, "title": "[tflite] allow gpu delegate to run quant model in tflite demo", "body": "GPU delegate can handle quantized model since 40088b87ee0", "comments": ["@srjoglekar246 Before the PR, as expected, no numbers were reported when trying to run `mobilenet v1 quant` on GPU. If allowing it to be run without calling `setQuantizedModelsAllowed()`, TFLite interpreter numbers were reported (because failing to apply GPU delegate). After `setQuantizedModelsAllowed()`, as expected, I got numbers close to ones I got when running the float model. The app doesn't report stable average numbers. Roughly, when running the quantized model, I got \r\n\r\n| device | CPU 1xthread | GPU delegate|\r\n|----------:|-------------------:|-------------------:|\r\n| Pixel 4 | 28 ms             | 13 ms|\r\n| Dimensity 1000+ dev board | 14 ms             | 7 ms|\r\n| Dimensity 820 dev board | 15 ms             | 15 ms|\r\n\r\nNote that numbers on dev boards are for reference only :-) The CPU number of Pixel 4 should be much better. But that's what I got from the app. I actually got much better number from `benchmark_model`.", "@freedomtan Awesome, thanks for confirming!"]}, {"number": 42403, "title": "mode.save() API raises AttributeError: 'Tensor' object has no attribute '_keras_mask'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly==2.4.0-dev20200815\r\n- Python version: 3.6\r\n- GPU model and memory: Tesla T4, memory_limit: 14611321984\r\n\r\n**Describe the current behavior**\r\nI've created an encoder-decoder model. I'm using LSTM in both the encoder and decoder architecture. I'm applying tf.keras.layers.Masking() on the encoder's LSTM output and hidden state and passing both of the masks (using the attribute _keras_mask) to tf.keras.layers.AdditiveAttention(). The model trains successfully using the teacher-forcing technique.\r\n\r\nNext, I am trying to save both the model in SavedModel format using the model.save() API.\r\nI'm getting the below error:\r\n```\r\nINFO:tensorflow:Assets written to: attention_two_encoder/assets\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-118-f4fbf19e2bf7> in <module>()\r\n      1 encoder.save(ENC_SAVED_MODEL_DIR)\r\n----> 2 decoder.save(DEC_SAVED_MODEL_DIR)\r\n\r\n26 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\r\n   1948     \"\"\"\r\n   1949     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\r\n-> 1950                     signatures, options)\r\n   1951 \r\n   1952   def save_weights(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\r\n    133   else:\r\n    134     saved_model_save.save(model, filepath, overwrite, include_optimizer,\r\n--> 135                           signatures, options)\r\n    136 \r\n    137 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)\r\n     78     # we use the default replica context here.\r\n     79     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access\r\n---> 80       save_lib.save(model, filepath, signatures, options)\r\n     81 \r\n     82   if not include_optimizer:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in save(obj, export_dir, signatures, options)\r\n    998 \r\n    999   _, exported_graph, object_saver, asset_info = _build_meta_graph(\r\n-> 1000       obj, export_dir, signatures, options, meta_graph_def)\r\n   1001   saved_model.saved_model_schema_version = constants.SAVED_MODEL_SCHEMA_VERSION\r\n   1002 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def)\r\n   1146   with save_context.save_context(options):\r\n   1147     return _build_meta_graph_impl(obj, export_dir, signatures, options,\r\n-> 1148                                   meta_graph_def)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in _build_meta_graph_impl(obj, export_dir, signatures, options, meta_graph_def)\r\n   1093   if signatures is None:\r\n   1094     signatures = signature_serialization.find_function_to_export(\r\n-> 1095         checkpoint_graph_view)\r\n   1096 \r\n   1097   signatures, wrapped_functions = (\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_serialization.py in find_function_to_export(saveable_view)\r\n     73   # If the user did not specify signatures, check the root object for a function\r\n     74   # that can be made into a signature.\r\n---> 75   functions = saveable_view.list_functions(saveable_view.root)\r\n     76   signature = functions.get(DEFAULT_SIGNATURE_ATTR, None)\r\n     77   if signature is not None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in list_functions(self, obj, extra_functions)\r\n    145     if obj_functions is None:\r\n    146       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access\r\n--> 147           self._serialization_cache)\r\n    148       self._functions[obj] = obj_functions\r\n    149     if extra_functions:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _list_functions_for_serialization(self, serialization_cache)\r\n   2559     self.predict_function = None\r\n   2560     functions = super(\r\n-> 2561         Model, self)._list_functions_for_serialization(serialization_cache)\r\n   2562     self.train_function = train_function\r\n   2563     self.test_function = test_function\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in _list_functions_for_serialization(self, serialization_cache)\r\n   3045   def _list_functions_for_serialization(self, serialization_cache):\r\n   3046     return (self._trackable_saved_model_saver\r\n-> 3047             .list_functions_for_serialization(serialization_cache))\r\n   3048 \r\n   3049   def __getstate__(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py in list_functions_for_serialization(self, serialization_cache)\r\n     85         `ConcreteFunction`.\r\n     86     \"\"\"\r\n---> 87     fns = self.functions_to_serialize(serialization_cache)\r\n     88 \r\n     89     # The parent AutoTrackable class saves all user-defined tf.functions, and\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in functions_to_serialize(self, serialization_cache)\r\n     77   def functions_to_serialize(self, serialization_cache):\r\n     78     return (self._get_serialized_attributes(\r\n---> 79         serialization_cache).functions_to_serialize)\r\n     80 \r\n     81   def _get_serialized_attributes(self, serialization_cache):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in _get_serialized_attributes(self, serialization_cache)\r\n     93 \r\n     94     object_dict, function_dict = self._get_serialized_attributes_internal(\r\n---> 95         serialization_cache)\r\n     96 \r\n     97     serialized_attr.set_and_validate_objects(object_dict)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py in _get_serialized_attributes_internal(self, serialization_cache)\r\n     49     # cache (i.e. this is the root level object).\r\n     50     if len(serialization_cache[constants.KERAS_CACHE_KEY]) == 1:\r\n---> 51       default_signature = save_impl.default_save_signature(self.obj)\r\n     52 \r\n     53     # Other than the default signature function, all other attributes match with\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in default_save_signature(layer)\r\n    203   original_losses = _reset_layer_losses(layer)\r\n    204   fn = saving_utils.trace_model_call(layer)\r\n--> 205   fn.get_concrete_function()\r\n    206   _restore_layer_losses(original_losses)\r\n    207   return fn\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in get_concrete_function(self, *args, **kwargs)\r\n   1174       ValueError: if this object has not yet been called on concrete values.\r\n   1175     \"\"\"\r\n-> 1176     concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n   1177     concrete._garbage_collector.release()  # pylint: disable=protected-access\r\n   1178     return concrete\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)\r\n   1080       if self._stateful_fn is None:\r\n   1081         initializers = []\r\n-> 1082         self._initialize(args, kwargs, add_initializers_to=initializers)\r\n   1083         self._initialize_uninitialized_variables(initializers)\r\n   1084 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    715     self._concrete_stateful_fn = (\r\n    716         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 717             *args, **kwds))\r\n    718 \r\n    719     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2953       args, kwargs = None, None\r\n   2954     with self._lock:\r\n-> 2955       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2956     return graph_function\r\n   2957 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3331 \r\n   3332       self._function_cache.missed.add(call_context_key)\r\n-> 3333       graph_function = self._create_graph_function(args, kwargs)\r\n   3334       self._function_cache.primary[cache_key] = graph_function\r\n   3335 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3186             arg_names=arg_names,\r\n   3187             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 3188             capture_by_value=self._capture_by_value),\r\n   3189         self._function_attributes,\r\n   3190         function_spec=self.function_spec,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    985         _, original_func = tf_decorator.unwrap(python_func)\r\n    986 \r\n--> 987       func_outputs = python_func(*func_args, **func_kwargs)\r\n    988 \r\n    989       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    623             xla_context.Exit()\r\n    624         else:\r\n--> 625           out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    626         return out\r\n    627 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py in _wrapped_model(*args)\r\n    132     with base_layer_utils.call_context().enter(\r\n    133         model, inputs=inputs, build_graph=False, training=False, saving=True):\r\n--> 134       outputs = model(inputs, training=False)\r\n    135 \r\n    136     # Outputs always has to be a flat dict.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    988 \r\n    989         with ops.enable_auto_cast_variables(self._compute_dtype_object):\r\n--> 990           outputs = call_fn(inputs, *args, **kwargs)\r\n    991 \r\n    992         if self._activity_regularizer:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    615   def wrapper(*args, **kwargs):\r\n    616     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\r\n--> 617       return func(*args, **kwargs)\r\n    618 \r\n    619   if inspect.isfunction(func) or inspect.ismethod(func):\r\n\r\n<ipython-input-104-f3868e3dd449> in call(self, y)\r\n    162 \r\n    163         context_vector = self.attention(inputs=[hidden_with_time_axis, enc_output],\r\n--> 164                                         mask=[hidden_with_time_axis_mask._keras_mask, enc_output_mask._keras_mask])\r\n    165         # context_vector shape == (batch_size, 1, enc_units)\r\n    166 \r\n\r\nAttributeError: 'Tensor' object has no attribute '_keras_mask'\r\n```\r\n\r\n**Describe the expected behavior**\r\nmodel.save() API should allow me to save the encoder-decoder model.\r\nAfter saving the models, I want to apply post-training float16 quantization.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nEncoder-Decoder model architecture\r\n```\r\nclass Encoder(tf.keras.Model):\r\n    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\r\n        super(Encoder, self).__init__()\r\n        self.batch_sz = batch_sz\r\n        self.enc_units = enc_units\r\n        \r\n        self.embedding_ques = tf.keras.layers.Embedding(vocab_size, embedding_dim, \r\n                                                        input_length=max_ques_length, \r\n                                                        weights=[embedding_matrix], \r\n                                                        trainable=False, mask_zero=True)\r\n        self.embedding_title = tf.keras.layers.Embedding(vocab_size, embedding_dim, \r\n                                                         input_length=max_title_length, \r\n                                                         weights=[embedding_matrix], \r\n                                                         trainable=False, mask_zero=True)\r\n        \r\n        self.lstm_ques = tf.keras.layers.LSTM(self.enc_units,\r\n                                   return_sequences=True,\r\n                                   return_state=True)\r\n        self.lstm_title = tf.keras.layers.LSTM(self.enc_units,\r\n                                   return_sequences=True,\r\n                                   return_state=True)\r\n        \r\n        self.dense_state_h_ques = tf.keras.layers.Dense(int(self.enc_units/2))\r\n        self.dense_state_h_title = tf.keras.layers.Dense(int(self.enc_units/2))\r\n        self.dense_state_c_ques = tf.keras.layers.Dense(int(self.enc_units/2))\r\n        self.dense_state_c_title = tf.keras.layers.Dense(int(self.enc_units/2))\r\n\r\n        self.conv2d_image = tf.keras.layers.Conv2D(32, (3, 3), \r\n                                    activation = 'relu',\r\n                                    kernel_initializer = tf.keras.initializers.HeNormal(seed=SEED),\r\n                                    padding = 'same')\r\n        self.flatten_image = tf.keras.layers.Flatten()\r\n        self.dense_image = tf.keras.layers.Dense(self.enc_units)\r\n\r\n        self.dense_price = tf.keras.layers.Dense(self.enc_units)\r\n        \r\n    def call(self, x):   \r\n        question, title, price, image, hidden = x[0], x[1], x[2], x[3], x[4]\r\n        # question shape == (batch_size, max_ques_length)\r\n        # title shape == (batch_size, max_title_length)\r\n        # price shape == (batch_size, 1)\r\n        # image shape == (batch_size, img_width, img_height, channels)\r\n\r\n        question_e = self.embedding_ques(question)\r\n        # question_e shape == (batch_size, max_ques_length, embedding_dim)\r\n        \r\n        question_mask = self.embedding_ques.compute_mask(question)\r\n        # question_mask shape == (batch_size, max_ques_length)\r\n        output_ques, state_h_ques, state_c_ques = self.lstm_ques(question_e, initial_state = hidden, mask=question_mask)\r\n        # output_ques shape == (batch_size, max_ques_length, enc_units)\r\n        # state_h_ques shape == (batch_size, enc_units)\r\n        # state_c_ques shape == (batch_size, enc_units)\r\n\r\n        title_e = self.embedding_title(title)\r\n        # title_e shape == (batch_size, max_title_length, embedding_dim)\r\n        \r\n        title_mask = self.embedding_title.compute_mask(title)\r\n        # title_mask shape == (batch_size, max_title_length)\r\n        output_title, state_h_title, state_c_title = self.lstm_title(title_e, initial_state = hidden, mask=title_mask)\r\n        # output_title shape == (batch_size, max_title_length, enc_units)\r\n        # state_h_title shape == (batch_size, enc_units)\r\n        # state_c_title shape == (batch_size, enc_units)\r\n\r\n        price = self.dense_price(price)\r\n        # price shape == (batch_size, enc_units)\r\n\r\n        image = self.conv2d_image(image)\r\n        # image shape ==  (batch_size, img_width, img_height, filters=32)\r\n        image = self.flatten_image(image)\r\n        # image shape == (batch_size, 51200)\r\n        image = self.dense_image(image)\r\n        # image shape == (batch_size, enc_units)\r\n        \r\n        output = tf.concat([output_ques, output_title], axis=1)\r\n        # output shape == (batch_size, max_ques_length + max_title_length, enc_units)\r\n        output = tf.concat([tf.expand_dims(price, 1), output], axis=1)\r\n        # output shape == (batch_size, max_ques_length + max_title_length + 1, enc_units)\r\n        output = tf.concat([tf.expand_dims(image, 1), output], axis=1)\r\n        # output shape == (batch_size, max_ques_length + max_title_length + 1 + 1, enc_units)\r\n\r\n        state_h_ques = self.dense_state_h_ques(state_h_ques)\r\n        # state_h_ques shape == (batch_size, int(enc_units/2))\r\n        state_h_title = self.dense_state_h_title(state_h_title)\r\n        # state_h_title shape == (batch_size, int(enc_units/2))\r\n        state_h = tf.concat([state_h_ques, state_h_title], axis=-1)\r\n        # state_h shape == (batch_size, enc_units)\r\n\r\n        state_c_ques = self.dense_state_c_ques(state_c_ques)\r\n        # state_c_ques shape == (batch_size, int(enc_units/2))\r\n        state_c_title = self.dense_state_c_title(state_c_title)\r\n        # state_c_title shape == (batch_size, int(enc_units/2))\r\n        state_c = tf.concat([state_c_ques, state_c_title], axis=-1)\r\n        # state_c shape == (batch_size, enc_units + enc_units)\r\n\r\n        return output, state_h, state_c\r\n\r\n\r\n    def initialize_hidden_state(self):\r\n        return (tf.zeros((self.batch_sz, self.enc_units)),\r\n                tf.zeros((self.batch_sz, self.enc_units)))\r\n\r\nclass Decoder(tf.keras.Model):\r\n    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\r\n        super(Decoder, self).__init__()\r\n        self.batch_sz = batch_sz\r\n        self.dec_units = dec_units\r\n        \r\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, \r\n                                                   input_length=max_ans_length, \r\n                                                   weights=[embedding_matrix], \r\n                                                   trainable=False, mask_zero=True)\r\n        \r\n        self.lstm = tf.keras.layers.LSTM(self.dec_units,\r\n                                   return_sequences=True,\r\n                                   return_state=True)\r\n        self.fc = tf.keras.layers.Dense(vocab_size)\r\n        \r\n        self.attention = tf.keras.layers.AdditiveAttention()\r\n\r\n        \r\n        self.masking_hidden = tf.keras.layers.Masking()\r\n        self.masking_enc_output = tf.keras.layers.Masking()\r\n        \r\n    def call(self, y):\r\n        inputs, hidden, enc_output = y[0], y[1], y[2]\r\n        # 1 in each of the dimension means timesteps\r\n        # decoding is happening at each timesteps\r\n\r\n        # inputs shape == (batch_size, 1)\r\n        # hidden shape == tuple of two (batch_size, enc_units) [lstm state_h and state_c]\r\n        # enc_output shape == (batch_size, max_ques_length, enc_units)\r\n\r\n        # hidden == lstm state_h\r\n \r\n        hidden_with_time_axis = tf.expand_dims(hidden[0], 1)\r\n        # hidden_with_time_axis shape == (batch_size, 1, enc_units)\r\n        \r\n        hidden_with_time_axis_mask = self.masking_hidden(hidden_with_time_axis)\r\n        # hidden_with_time_axis_mask._keras_mask shape == (batch_size, 1)\r\n        \r\n        enc_output_mask = self.masking_enc_output(enc_output)\r\n        # enc_output_mask._keras_mask shape == (batch_size, max_ques_length)\r\n        \r\n        context_vector = self.attention(inputs=[hidden_with_time_axis, enc_output],\r\n                                        mask=[hidden_with_time_axis_mask._keras_mask, enc_output_mask._keras_mask])\r\n        # context_vector shape == (batch_size, 1, enc_units)\r\n\r\n        \r\n        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\r\n        x = self.embedding(inputs)\r\n\r\n        \r\n        mask = self.embedding.compute_mask(inputs)\r\n        # mask shape == (batch_size, 1)\r\n\r\n        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n        x = tf.concat([context_vector, x], axis=-1)\r\n        \r\n        # passing the concatenated vector to the LSTM\r\n        output, state_h, state_c = self.lstm(x, initial_state=hidden, mask=mask)\r\n        # output shape == (batch_size, 1, dec_units)\r\n        # state_h shape == (batch_size, dec_units)\r\n        # state_c shape == (batch_size, dec_units)\r\n \r\n        output = tf.reshape(output, (-1, output.shape[2]))\r\n        # output shape == (batch_size * 1, dec_units)\r\n        \r\n        x = self.fc(output)\r\n        # output shape == (batch_size, vocab)\r\n        \r\n        return x, state_h, state_c\r\n\r\n    def initialize_hidden_state(self):\r\n        return (tf.zeros((self.batch_sz, self.dec_units)),\r\n                tf.zeros((self.batch_sz, self.dec_units)))\r\n```\r\n\r\nAttempt to save the models using the below code\r\n```\r\nencoder.save(ENC_SAVED_MODEL_DIR)\r\ndecoder.save(DEC_SAVED_MODEL_DIR) # Stacktrace posted above \r\n```", "comments": ["@hsomaiya,\r\nOn running the given code, I am facing an error stating `NameError: name 'encoder' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/a5683a93d2a000d25032add1df0758d4/42403.ipynb).\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue and the dataset you are using. Alternatively, you can also share the Colab notebook you are running. Thanks!", "@amahendrakar \r\nThank you for your response.\r\nPlease check [this](https://colab.research.google.com/drive/1e7mpSs-YJgWVv9NXxokkrtCswaK6oC3z?usp=sharing) Colab notebook which will help you to reproduce the issue.\r\n", "Was able to reproduce the issue with the latest TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/177a582408224d4dd8cf48cc075560cc/42403-tf-nightly.ipynb). Thanks!", "I met this issue, too. Can anyone help? ", "I just faced this issue too. I was using a custom layer that includes both standard TF layers (dense) as well as math operations on tensors  (`+`, `-`, `tf.exp`, ...). It was basically a variation of a sampling layer for variational autoencoder described [here](https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example). \r\n\r\nI was using `Sequential` model. The TF 2.2.0, while iterating over layers, runs the following piece of code:\r\n```python\r\nmask = outputs._keras_mask\r\n```\r\nThis was the source of this error. In TF 2.3.0 and above I believe it was re-implemented:\r\n```python\r\nmask = getattr(outputs, '_keras_mask', None)\r\n```\r\n\r\nI fixed this by manually setting `_keras_mask` to None before returning a tensor instance from my custom layer:\r\n``` python\r\ndef __call__(self, inputs):\r\n    # Method body comes here \r\n    # ...\r\n    z = mean + tf.exp(log_sigma) * epsilon\r\n    z._keras_mask = None\r\n    return z\r\n```", "Hi @hsomaiya, were you able to try the suggestion in the above comment?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42403\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42403\">No</a>\n"]}, {"number": 42402, "title": "[new feature]: Roll slice of a tensor", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):2.30\r\n- Are you willing to contribute it (Yes/No):\r\nYes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI want tf.roll to do the following, I want to roll only one row. out of all the rows.\r\n[[0,1,2,3,4],\r\n[5,6,7,8,9]]\r\nI want to roll only the bottom row by 2. i.e. the result will be \r\n[[0,1,2,3,4]\r\n[8,9,5,6,7]]\r\n \r\nCurrently, tf.roll can do \r\n[[3,4,0,1,2]\r\n[8,9,5,6,7]]\r\nbut not be specific row\r\n\r\n**Will this change the current api? How?**\r\nAdd new feature to tensorflow\r\n**Who will benefit with this feature?**\r\n\r\nMany System biologists and physicist who want to use TensorFlow to compute Transcription Models. A key breakthrough on this idea. \r\nI am planning to implement the algorithms in this paper at larger scale for much harder problems. \r\nhttps://academic.oup.com/bioinformatics/article/36/Supplement_1/i499/5870526\r\n\r\n\r\n**Any Other info.**\r\n", "comments": ["I don't think we need to change tf.roll to accomplish this. We can achieve this by slice assignment\r\n\r\na = [[0,1,2,3,4], [5,6,7,8,9]]\r\n\r\n```\r\ntf_a = tf.constant(a)\r\nupdated_slice = tf.roll(tf_a[1, :], 2, axis=0)\r\ntf_b = tf.tensor_scatter_nd_update(tf_a, [[1]], [updated_slice])\r\n```\r\nwhere tf.tensor_scatter_nd_update does the slice assignment logic. If we had numpy like slice update APIs, it could have been a bit more easier e.g.\r\n\r\n```\r\nnp_a = np.array(a)\r\nnp_a[1, :] = np.roll(np_a[1, :], 2, axis=0)\r\n```"]}, {"number": 42401, "title": "Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.6\r\n\r\n\r\n**Describe the current behavior**\r\nThrows the following error when calling **model.predict(dataset)** on TPUs.\r\n```\r\nTraceback (most recent call last):\r\n  File \"bl_model.py\", line 188, in <module>\r\n    app.run(main)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"bl_model.py\", line 158, in main\r\n    emb, _, label, dataset = model.predict(test_dataset)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1601, in predict\r\n    context.async_wait()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 2319, in async_wait\r\n    context().sync_executors()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 658, in sync_executors\r\n    pywrap_tfe.TFE_ContextSyncExecutors(self._context_handle)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 9 root error(s) found.\r\n  (0) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA\r\n\t [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]\r\n\t [[cluster_predict_function/control_after/_1/_347]]\r\n  (1) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA\r\n\t [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6/_209]]\r\n  (2) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA\r\n\t [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]\r\n\t [[cluster_predict_function/control_after/_1/_363]]\r\n  (3) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA\r\n\t [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6/_223]]\r\n  (4) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA\r\n\t [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]\r\n\t [[cluster_predict_function/control_after/_1/_355]]\r\n  (5) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA\r\n\t [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6/_251]]\r\n  (6) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride yet. Please file a bug against XLA\r\n\t [[{{node functional_1/tf_op_layer_strided_slice/strided_slice}}]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6]]\r\n\t [[tpu_compile_succeeded_assert/_16053711828520823699/_6/_307]]\r\n  (7) Invalid argument: {{function_node __inference_predict_function_94126}} Compilation failure: XLA has not implemented dynamic sized slice with non-trival stride y ... [truncated]\r\n```\r\n\r\n**Describe the expected behavior**\r\nThere is no error under TF 2.2.0. Is there any way to turn off XLA for TPUs in TF 2.3.0?\r\n\r\n", "comments": ["@fengyang0317,\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks! ", "The code to reproduce the error.\r\n```\r\nimport os\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nif 'TPU_NAME' in os.environ:\r\n  tpu = os.environ['TPU_NAME']\r\n  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu)\r\n  tf.config.experimental_connect_to_cluster(resolver)\r\n  tf.tpu.experimental.initialize_tpu_system(resolver)\r\n  strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\nelse:\r\n  strategy = tf.distribute.MirroredStrategy()\r\n\r\nwith strategy.scope():\r\n  model = tf.keras.applications.ResNet50(\r\n    include_top=True,\r\n    weights=None,\r\n    classifier_activation=None)\r\n  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\r\n    'test_accuracy', dtype=tf.float32)\r\n\r\n\r\n@tf.function\r\ndef test_step(iterator):\r\n  def step_fn(inputs):\r\n    images, labels = inputs\r\n    images = tf.keras.applications.resnet50.preprocess_input(images)\r\n    predictions = model(images, training=False)\r\n    test_accuracy.update_state(labels, predictions)\r\n\r\n  while tf.constant(True, dtype=tf.bool):\r\n    optional_data = iterator.get_next_as_optional()\r\n    if not optional_data.has_value():\r\n      break\r\n    strategy.run(step_fn, args=(optional_data.get_value(),))\r\n\r\n\r\nimages = np.zeros((256, 224, 224, 3), dtype=np.float32)\r\nimage_ds = tf.data.Dataset.from_tensor_slices(images)\r\nlabels = np.zeros((256), dtype=np.int32)\r\nlabel_ds = tf.data.Dataset.from_tensor_slices(labels)\r\ndataset = tf.data.Dataset.zip((image_ds, label_ds))\r\ntest_dataset = dataset.batch(32)\r\ntest_dataset = strategy.experimental_distribute_dataset(test_dataset)\r\n\r\ntest_iterator = iter(test_dataset)\r\ntest_step(test_iterator)\r\nprint(test_accuracy.result())\r\n```\r\n\r\nAfter heavy debugging, I find that the error is caused by \r\n```\r\nimages = tf.keras.applications.resnet50.preprocess_input(images)\r\n```", "@fengyang0317 I am seeing different error. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/e23f52f7b81a7ead95365ba21889384a/untitled14.ipynb). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42401\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42401\">No</a>\n"]}, {"number": 42400, "title": "[tflite] Make --nnapi_accelerator_name work in kernel tests", "body": "Originally, when `--nnapi=true`, always test `nnapi-reference`, the NNAPI CPU reference implementation. Now when `--nnapi_accelerator_name` is specified, set it as is.\r\n\r\n@multiverse-tf: my colleagues and me want to use these kernel tests to test NNAPI drivers other than `nnapi-reference`.", "comments": []}, {"number": 42398, "title": "TFA can't load _image_ops.so - says file doesn't exist, but its there?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): TF 2.1.0 installed via conda\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7.0\r\n- Installed using virtualenv? pip? conda?: TF installed via conda, TFA via pip.\r\nTFA installed via pip install tensorflow_addons==0.9.1\r\n\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: \r\n# packages in environment at C:\\ProgramData\\Anaconda3\\envs\\tf:\r\n#\r\n# Name                    Version                   Build  Channel\r\ncudnn                     7.6.5                cuda10.1_0\r\n- GPU model and memory:\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 442.19       Driver Version: 442.19       CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108... WDDM  | 00000000:01:00.0  On |                  N/A |\r\n| 23%   38C    P8    17W / 250W |   1049MiB / 11264MiB |      1%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108... WDDM  | 00000000:03:00.0 Off |                  N/A |\r\n| 23%   29C    P8     9W / 250W |    137MiB / 11264MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nTFA can't load _image_ops.so\r\n\r\nFile \"C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\image\\distance_transform.py\", line 69, in euclidean_dist_transform\r\n    output = _image_so.ops.addons_euclidean_distance_transform(images)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\resource_loader.py\", line 56, in ops\r\n    self._ops = tf.load_op_library(get_path_to_datafile(self.relative_path))\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\framework\\load_library.py\", line 57, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\custom_ops\\image\\_image_ops.so not found\r\n\r\nThe file exists in the specified directory\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nAs you can see, the library file is clearly there...\r\n\r\n(tf) C:\\ProgramData\\Anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow_addons\\custom_ops\\image>dir\r\n Volume in drive C has no label.\r\n Volume Serial Number is 62E0-530C\r\n\r\n Directory of C:\\ProgramData\\Anaconda3\\envs\\tf\\Lib\\site-packages\\tensorflow_addons\\custom_ops\\image\r\n\r\n08/15/2020  02:19 PM    <DIR>          .\r\n08/15/2020  02:19 PM    <DIR>          ..\r\n08/15/2020  02:19 PM           172,544 _distort_image_ops.so\r\n08/15/2020  02:19 PM           977,408 _image_ops.so\r\n08/15/2020  02:19 PM           169,984 _resampler_ops.so\r\n               3 File(s)      1,319,936 bytes\r\n               2 Dir(s)  255,060,709,376 bytes free\r\n\r\n\r\nHere is the code.\r\n\r\n```\r\n\"\"\"\r\n    Debug Euclidean distance\r\n\"\"\"\r\nfrom silence_tensorflow import silence_tensorflow\r\nsilence_tensorflow()\r\n\r\nimport os\r\nos.system('cls' if os.name == 'nt' else 'clear')\r\n\r\nimport warnings\r\nwarnings.filterwarnings('ignore', category=FutureWarning)\r\n\r\nimport tensorflow\r\nimport numpy as np\r\nimport tensorflow_addons as tfa\r\nimport matplotlib.pyplot as plt\r\n\r\nwith tensorflow.device('/GPU:1'):\r\n\r\n    M = 500\r\n    img = np.zeros((M, M))\r\n    top = 50\r\n    bottom = 270\r\n    left = 300\r\n    right = 450\r\n    img[np.ix_(np.arange(top, bottom + 1), np.arange(left, right + 1))] = 1\r\n    img = tensorflow.convert_to_tensor(img)\r\n    img = tensorflow.expand_dims(img, -1)\r\n    img = img.numpy()\r\n\r\n    # TFA - Euclidean distance transform\r\n    img = tensorflow.cast(img, dtype=tensorflow.uint8)\r\n    d_img = tfa.image.euclidean_dist_transform(img)  # See https://github.com/tensorflow/addons\r\n\r\n    # Plot it\r\n    plt.figure()\r\n    plt.title('True TFA Distance Image')\r\n    _ = plt.imshow(d_img)\r\n\r\n    # Tell user how to end code.\r\n    print(\"\\nPress ctrl-c or ctrl-break or close windows to exit.\\n\")\r\n    plt.show()\r\n```\r\n\r\nThanks for the help. I can't understand why the system is telling me this library doesn't exist.\r\n", "comments": ["@jeball \r\nI am facing a different error when i run your code, please find [gist here](https://colab.research.google.com/gist/Saduf2019/6842c50df0023878987da3ba10816559/untitled373.ipynb).\r\nCan you please share a colab gist with the error faced for us to analyse.", "Just remove the first lines. Here is the code.\r\n\r\nimport tensorflow\r\nimport numpy as np\r\nimport tensorflow_addons as tfa\r\nimport matplotlib.pyplot as plt\r\n\r\nwith tensorflow.device('/CPU:0'):\r\n\r\n    M = 500\r\n    img = np.zeros((M, M))\r\n    top = 50\r\n    bottom = 270\r\n    left = 300\r\n    right = 450\r\n    img[np.ix_(np.arange(top, bottom + 1), np.arange(left, right + 1))] = 1\r\n    img = tensorflow.convert_to_tensor(img)\r\n    img = tensorflow.expand_dims(img, -1)\r\n    img = img.numpy()\r\n\r\n    # TFA - Euclidean distance transform\r\n    img = tensorflow.cast(img, dtype=tensorflow.uint8)\r\n    d_img = tfa.image.euclidean_dist_transform(img)  # See https://github.com/tensorflow/addons\r\n\r\n    # Plot it\r\n    plt.figure()\r\n    plt.title('True TFA Distance Image')\r\n    _ = plt.imshow(d_img)\r\n\r\n    # Tell user how to end code.\r\n    print(\"\\nPress ctrl-c or ctrl-break or close windows to exit.\\n\")\r\n    plt.show()", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42398\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42398\">No</a>\n", "I didn't mean to close this. Hit wrong button.", "@jeball \r\nI ran the code and face an error please refer to [gist here](https://colab.research.google.com/gist/Saduf2019/aac88f6c369b8d569071c5929e44cf48/untitled367.ipynb).", "Thanks\r\n\r\nI think the problem is tensorflow 2.1 GPU was installed with anaconda and tensorflow addons with pip and they seem to be incompatible. The error you get is different from the error I am receiving. I think to resolve I need to install tensorflow with pip.\r\n\r\nCan you verify \u2013 after more research this seems to be the main problem.\r\n\r\nJohn Ball, Ph.D.\r\nAssociate Professor and Robert Guyton Endowed Chair for Teaching Excellence | Electrical and Computer Engineering\r\n\r\n[cid:image001.png@01D67531.64CF41C0]\r\nAssociate Editor | IEEE Signal Processing Letters\r\nAssociate Editor | Journal of Applied Remote Sensing\r\nEditorial Board Member | MDPI Electronics\r\nFaculty Advisory Council | Transactions on Stem Education\r\nLab Director | Simrall Radar Laboratory\r\nLab Co-Director | Center for Advanced Vehicular Systems (CAVS) Sensor Lab\r\nResearch Fellow | Geosystems Research Institute (GRI)\r\nSimrall 233, 406 Hardy Rd., Mississippi State, MS 39762\r\np:662.325.4169  e:jeball@ece.msstate.edu<mailto:jeball@ece.msstate.edu>\r\n\r\n\r\nFrom: Saduf2019 <notifications@github.com>\r\nSent: Tuesday, August 18, 2020 6:26 AM\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Ball, John <jeball@ece.msstate.edu>; Mention <mention@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] TFA can't load _image_ops.so - says file doesn't exist, but its there? (#42398)\r\n\r\n\r\n@jeball<https://secure-web.cisco.com/1DDekOIZVGxDAV-tZQNItaihharROf6u3uBl31EIejO9FW9mY4TYvvwjn6UevtqJ7s0W6o2Vg_5sUOUc3JjeKt228diMMZdiJHTiUkoorG1jTv27lUhQkHdZEg9baKwSRdFirgy_uUZPpUHmU_2aycPJdLLEJFVSUHr-06jkSnYYU0WVHp1xncP8SySfPZpPQfbSxzU5UyBWBXHdfckU4RtAwEcCqgtonuEVcob9LZ-iQoyHpfutFJjrd9ivML_v0dnsiNgi8W9711niMxYwRyukWdpJ59-GdvRf8OU1cCBadxQuHM4WoJBvue4o5Vdibiqv9gIbuNFKVFEzVv_4N8w/https%3A%2F%2Fgithub.com%2Fjeball>\r\nI ran the code and face an error please refer to gist here<https://secure-web.cisco.com/19PUsvm2D2Q95oxVa_ROLqTNqECJ-TSXBB_cEzFWSAh25BkEvbpP2CMdH4Vmc5TYUUDHv_SqOF4T2UzB2bLEfsDDJnI9E_C5_eTyASCFG8r_zz0hAJasIWHujCTiPWIQzV6wj8LLzYvndtZoeQ4JLkNZ2D8UpgStQa7K72zx2bCQm5PmikLcemdRptzt4ym8CUmiZDGngSmOkPo1z3v_vL6g2yKkNUZnWVTY5bada875BJhJ7d5ZDAH7_tzfw2wzKeC49MwSUgccd8aPLwsVPnhrWarp9Qe7AUQXnH3cADuowBMsQrNzCGXwvHA50CLImMZLEMdMhLqSUI7Q82xb6hw/https%3A%2F%2Fcolab.research.google.com%2Fgist%2FSaduf2019%2Faac88f6c369b8d569071c5929e44cf48%2Funtitled367.ipynb>.\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://secure-web.cisco.com/1E4m66aWdZdg2xm2BgY8h5wr28oREcY7rJlmwNHvTlFw2nO46AYAd7dhmYwUD32_dk-AoKUpccuBJ1zghlRS4cGiHdBXbLdF-I4QZgYjgdYN4b8gRSgXqwHbhIo2uqKiGpn4d35tfLoyREcYP1ZYnHC5mltSbdW2LBp3MmZqljxgLfR13WuBF7iAhGERgStk9hzn0XLuY_eKuzJv7jtqZcn2yrpPQsSi7URhoENzfXrGaoNT83OEqvRtlRr7Aog_CFBHt2_vOIEpEx763MyNmDpCycoH9OsqfTRGCWAemACzd1Dp7-l8F_6ytBEs6VOuJ9ip-kIGHefpf_zf_CIcR7Q/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F42398%23issuecomment-675421983>, or unsubscribe<https://secure-web.cisco.com/1ncuZ-OAFmyTrwq_pw-gxL9qLwhX80cY8Q3XGFgCmCltlykctyf5ijUQ9YpqAPBT6L2xAFo5W_YIMz_o8ZfgxQ4CROC6muUbQT7MWh9cFxhEL2pe3HpySX1TUHaoL-fq7qn5YMvZWFIoXG7ZS9yS3vRtHssNVaGsJItbB2tDQJ1GFcKU1iXdjBgoKHH_-aA9irTPj0gaAG8HwTwiNPw8SEvsSP7aFtyUvsG64dyODtICg6uwkAgJrRqOsQap2__ztqTWam2J5CGKhHG-cQtV8Xg558lXjzlKkhmEHR6T-A8Zb56DzR7U02FvoKDzRfnzS2M9kF5EY-ximc6lA6I5daQ/https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAETBXODUD3GA4XKXA7IUMO3SBJQKXANCNFSM4QANRIQQ>.\r\n", "My error was with TF 2.1.0, not 2.3.0\r\n\r\nJohn Ball, Ph.D.\r\nAssociate Professor and Robert Guyton Endowed Chair for Teaching Excellence | Electrical and Computer Engineering\r\n\r\n[cid:image001.png@01D67537.E129C370]\r\nAssociate Editor | IEEE Signal Processing Letters\r\nAssociate Editor | Journal of Applied Remote Sensing\r\nEditorial Board Member | MDPI Electronics\r\nFaculty Advisory Council | Transactions on Stem Education\r\nLab Director | Simrall Radar Laboratory\r\nLab Co-Director | Center for Advanced Vehicular Systems (CAVS) Sensor Lab\r\nResearch Fellow | Geosystems Research Institute (GRI)\r\nSimrall 233, 406 Hardy Rd., Mississippi State, MS 39762\r\np:662.325.4169  e:jeball@ece.msstate.edu<mailto:jeball@ece.msstate.edu>\r\n\r\n\r\nFrom: Saduf2019 <notifications@github.com>\r\nSent: Tuesday, August 18, 2020 6:26 AM\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Ball, John <jeball@ece.msstate.edu>; Mention <mention@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] TFA can't load _image_ops.so - says file doesn't exist, but its there? (#42398)\r\n\r\n\r\n@jeball<https://secure-web.cisco.com/1DDekOIZVGxDAV-tZQNItaihharROf6u3uBl31EIejO9FW9mY4TYvvwjn6UevtqJ7s0W6o2Vg_5sUOUc3JjeKt228diMMZdiJHTiUkoorG1jTv27lUhQkHdZEg9baKwSRdFirgy_uUZPpUHmU_2aycPJdLLEJFVSUHr-06jkSnYYU0WVHp1xncP8SySfPZpPQfbSxzU5UyBWBXHdfckU4RtAwEcCqgtonuEVcob9LZ-iQoyHpfutFJjrd9ivML_v0dnsiNgi8W9711niMxYwRyukWdpJ59-GdvRf8OU1cCBadxQuHM4WoJBvue4o5Vdibiqv9gIbuNFKVFEzVv_4N8w/https%3A%2F%2Fgithub.com%2Fjeball>\r\nI ran the code and face an error please refer to gist here<https://secure-web.cisco.com/19PUsvm2D2Q95oxVa_ROLqTNqECJ-TSXBB_cEzFWSAh25BkEvbpP2CMdH4Vmc5TYUUDHv_SqOF4T2UzB2bLEfsDDJnI9E_C5_eTyASCFG8r_zz0hAJasIWHujCTiPWIQzV6wj8LLzYvndtZoeQ4JLkNZ2D8UpgStQa7K72zx2bCQm5PmikLcemdRptzt4ym8CUmiZDGngSmOkPo1z3v_vL6g2yKkNUZnWVTY5bada875BJhJ7d5ZDAH7_tzfw2wzKeC49MwSUgccd8aPLwsVPnhrWarp9Qe7AUQXnH3cADuowBMsQrNzCGXwvHA50CLImMZLEMdMhLqSUI7Q82xb6hw/https%3A%2F%2Fcolab.research.google.com%2Fgist%2FSaduf2019%2Faac88f6c369b8d569071c5929e44cf48%2Funtitled367.ipynb>.\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://secure-web.cisco.com/1E4m66aWdZdg2xm2BgY8h5wr28oREcY7rJlmwNHvTlFw2nO46AYAd7dhmYwUD32_dk-AoKUpccuBJ1zghlRS4cGiHdBXbLdF-I4QZgYjgdYN4b8gRSgXqwHbhIo2uqKiGpn4d35tfLoyREcYP1ZYnHC5mltSbdW2LBp3MmZqljxgLfR13WuBF7iAhGERgStk9hzn0XLuY_eKuzJv7jtqZcn2yrpPQsSi7URhoENzfXrGaoNT83OEqvRtlRr7Aog_CFBHt2_vOIEpEx763MyNmDpCycoH9OsqfTRGCWAemACzd1Dp7-l8F_6ytBEs6VOuJ9ip-kIGHefpf_zf_CIcR7Q/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F42398%23issuecomment-675421983>, or unsubscribe<https://secure-web.cisco.com/1ncuZ-OAFmyTrwq_pw-gxL9qLwhX80cY8Q3XGFgCmCltlykctyf5ijUQ9YpqAPBT6L2xAFo5W_YIMz_o8ZfgxQ4CROC6muUbQT7MWh9cFxhEL2pe3HpySX1TUHaoL-fq7qn5YMvZWFIoXG7ZS9yS3vRtHssNVaGsJItbB2tDQJ1GFcKU1iXdjBgoKHH_-aA9irTPj0gaAG8HwTwiNPw8SEvsSP7aFtyUvsG64dyODtICg6uwkAgJrRqOsQap2__ztqTWam2J5CGKhHG-cQtV8Xg558lXjzlKkhmEHR6T-A8Zb56DzR7U02FvoKDzRfnzS2M9kF5EY-ximc6lA6I5daQ/https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAETBXODUD3GA4XKXA7IUMO3SBJQKXANCNFSM4QANRIQQ>.\r\n", "@jeball \r\nPlease try latest version of tf and let us know if the issue exist.", "Last I knew TF 2.1.0 was the latest version supported on Windows 10. I will try TF 2.3.\r\nI still have a question \u2013 if I install via Conda will it work or does it require a pip install?\r\n\r\nThanks\r\n\r\nJohn Ball, Ph.D.\r\nAssociate Professor and Robert Guyton Endowed Chair for Teaching Excellence | Electrical and Computer Engineering\r\n\r\n[cid:image001.png@01D6760D.8BD3BC10]\r\nAssociate Editor | IEEE Signal Processing Letters\r\nAssociate Editor | Journal of Applied Remote Sensing\r\nEditorial Board Member | MDPI Electronics\r\nFaculty Advisory Council | Transactions on Stem Education\r\nLab Director | Simrall Radar Laboratory\r\nLab Co-Director | Center for Advanced Vehicular Systems (CAVS) Sensor Lab\r\nResearch Fellow | Geosystems Research Institute (GRI)\r\nSimrall 233, 406 Hardy Rd., Mississippi State, MS 39762\r\np:662.325.4169  e:jeball@ece.msstate.edu<mailto:jeball@ece.msstate.edu>\r\n\r\n\r\nFrom: Saduf2019 <notifications@github.com>\r\nSent: Wednesday, August 19, 2020 9:44 AM\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Ball, John <jeball@ece.msstate.edu>; Mention <mention@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] TFA can't load _image_ops.so - says file doesn't exist, but its there? (#42398)\r\n\r\n\r\n@jeball<https://secure-web.cisco.com/1PyB5G81NqPq9F_ni-OsoXOJZ9A533-gi3irHU1H4yjkP-Zb9wnXzTgocslEFvKrUo564k83gPWaHCL4yQbnOcLfCs0c9uhXNZB6sF0R399Pm7k_yUr9Fb39jdTrbIagVAPaNLrGyYyhIvBCtTjW8khebiYU4r46onZ9NpG0nbWL9y0iTqcp6ulME0ybfQK0qJyoBcejoZGeK70M6FGzfDAilmu4ZkVw2F5xuMBXD3lYnkn0t_-NAGl9QIgwm69Ve2zD3KvKDvQ4rPpGn-4mbshADVFit-8fNq9oBi4OYBIly43JKFMNsfOyZ8fM9fO5_coA7gnQC-s8tiRJiLPO5KA/https%3A%2F%2Fgithub.com%2Fjeball>\r\nPlease try latest version of tf and let us know if the issue exist.\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://secure-web.cisco.com/10SU9AVYOjJxqShETogFAW9E4dLhGH-k0pToRybLaNOYBYxKGxlUmFscepC1PXA5s2ClFPfLUCFwOfXCsSWrCF2ZQvXyZ6sal1xGWJNlp6R05zqWpviF9G04P5tr1JlG1teX3alr5YWMxbpoe1Wx-u5-q5t8ChjQe-Vv3moe5iOqosQ_m--_i2iX_Ri9TY9aaNhJfV1jxm8PpA8Mdik4Yaqvmu8rkwbBzGAhyRbWcH2N3vf7S5vO4UBTPkVuXVCpb05FO9POXWMBWow0VGWvRAiKplW5tGLK1V65CdV3WcNcy91dZhoJdkteS9K8XgP_T0U4kEKMiyeoGQpXJAYhtIw/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F42398%23issuecomment-676470335>, or unsubscribe<https://secure-web.cisco.com/1c3wyqohvsQkRG0Fk1eAhA5VBZZIvuTEV5eepG608iNTjFvzB-Nv1biKLa8Elwh34YtDvWHjCHax5MaBRPoD0rPDxdElMZfG_KzwcjsfCLKSd0aR55kbJ4TFk3izW5OEiJIZ3p7tTj2FMgmq7r_C6HpYwyimWtCTumdD4G8zCTAGruI6KUQ5wpzw6EKSewm44z8GnDPxf8DVrfAlGpnCHIOLaMpQs-Fg3Pfq_HqP6K3woYfFoAMo1BotatseZyhEGY7C3GCvyVmHETXc7DwuSseZwl3G206QFZFnwGmyN8emCVd0DohKkrOUj_kcdZbsWdP4_u3v6HjKlIWC6hCEoGQ/https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAETBXOBCTBSRRKMZ2CDJ3KTSBPQLFANCNFSM4QANRIQQ>.\r\n", "@jeball \r\n>>I still have a question \u2013 if I install via Conda will it work or does it require a pip install?\r\n     \r\nYou can go ahead with either of them, and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42398\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42398\">No</a>\n"]}, {"number": 42397, "title": "Prevent Aborted (core dumped) in tf.nest.assert_same_structure for type mismatch in passed args", "body": "\r\n\r\nThis PR tries to address the issue raised in #42329 where\r\ntf.nest.assert_same_structure will abort with core dump when\r\ncheck_types is passed with a non-bool value.\r\n\r\nThe issue is related to pybind where type mismatch will\r\nthrow out an error and further cause 'pybind11::error_already_set' error.\r\n\r\nThis PR explicitly convert check_types to bool before passing to pybind,\r\nand, in case check_types is not bool, an ValueError will be thrown out\r\ngracefully by python itself.\r\n\r\nThis will be better than process abort (core dump).\r\n\r\nThis PR fixes #42329.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@yongtang can you please check sanity build failures ?", "Thanks  @mdanatg @rthadur for the review. The PR has been updated with pylint failure fixed. Please take a look and let me know if there is any other issues.", "Thanks @mdanatg for the help! The PR has been updated with captured exceptions expanded. Please take a look and see if the issue still exists."]}, {"number": 42396, "title": "Model.fit() issue", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@Al-Badri179 \r\nCan you please fill in the issue template, we would need the tf version, simple stand alone code or a colab gist with the error faced for us to help.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42395, "title": "Hi everybody, I 'm trying to excute a free avialble code for CNN model to classify 4 classes of dogs, cats, horses and humans. Unfortunatly, I faced this issue: \"ValueError: Calling `Model.fit` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.fit` with eager mode enabled.\" how can I handle it?", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@Al-Badri179,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using. Thanks!", "Template not filled in. Wrong template used (issue is a bug, template is documentation issues). Title contains the entire issue. This is actually not a TF coding issue but a question regarding usage of TF, probably better asked on StackOverflow.", "@amahendrakar \r\n\r\ntensorflow-estimator     2.3.0\r\nKeras                              2.4.3\r\n\r\nThis is the code for the CNN modal:\r\n[CNN modal.txt](https://github.com/tensorflow/tensorflow/files/5086292/CNN.modal.txt)\r\n\r\nfor the dataset it is free available on the internet (dogs, cats, horses, humans)"]}, {"number": 42394, "title": "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.3.0\r\n- Python version: 3.8.3\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: Not Installed\r\n- GPU model and memory: NVIDIA GeForce MX250 2 GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nWhile running this sample tensorflow program, \r\n\r\nimport tensorflow as tf\r\ntf.add(1, 2).numpy()\r\nhello = tf.constant('Hello, TensorFlow!')\r\nhello.numpy()\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI encountered below error message:\r\n\r\nfrom tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nFailed to load the native TensorFlow runtime.\r\n--------------------------------------------------------\r\n\r\nTensorflow Installation:\r\nSuccessfully installed Tensorflow-2.3.0 absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.20.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.31.0 keras-preprocessing-1.1.2 markdown-3.2.2 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-estimator-2.3.0 termcolor-1.1.0\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@manojkumarmahato \r\nYou could be facing this issue because of the following reasons\r\n\r\nYou you running 32-bit Python or 32-bit OS\r\nYour CPU does not support AVX instructions, please provide the make and model of your CPU in this case.\r\nPlease take a look at the [system requirements](https://www.tensorflow.org/install/pip#system-requirements) and check if you have the correct dependencies installed.\r\n\r\nAlso, check these similar duplicate issues: #42058 #41596 #40459 #39007 #38916 #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 .\r\n\r\nThanks!", "Hi, \r\n\r\nPython interpreter information from command line (64-bit Python):\r\nPython 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nOther information:\r\nOS Version\tWindows 10, 10.0.18363 Build 18363\r\nSystem Type\tx64-based PC\r\nProcessor\tIntel(R) Core(TM) i7-8565U CPU @ 1.80GHz, 1992 Mhz, 4 Core(s), 8 Logical Processor(s)\r\n\r\nI will review the duplicate issues. Thanks for sharing.\r\n\r\nThanks,\r\n", "I'm facing the exact same issue", "@manojkumarmahato \r\nPlease update if you have verified with the duplicate issues.", "Hi,\r\n\r\nI referred to some of the issues. \r\nIn my laptop, Microsoft Visual C++ Redistributable (x64)  version installed is 14.11.25325.\r\nI saw there, you have mentioned \"For TF-GPU - See point 1\",  to install CUDA, does it require here? Which version of CUDA do I need to install for TF 2.3.\r\n\r\nThanks\r\n", "@manojkumarmahato \r\nPlease try with CUDA 10.1 and let us know.\r\nPlease refer to [link](https://www.tensorflow.org/install/source#gpu).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I was facing the same issue, I found that you must install/update a VS C++ 2015-2019 Redistributable (x64). Here is the link.\r\n[https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads](url)\r\nand the Stack Overflow link\r\n[https://stackoverflow.com/questions/60319768/cant-import-tensorflow-in-python-windows-10-64-bit/61656869#61656869](url)", "@tensorflowbutler everything is got updated but still i'm getting \"failed to load the native tensorflow runtime\" for CPU.", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42394\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42394\">No</a>\n", "> I was facing the same issue, I found that you must install/update a VS C++ 2015-2019 Redistributable (x64). Here is the link.\r\n> [https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads](url)\r\n> and the Stack Overflow link\r\n> [https://stackoverflow.com/questions/60319768/cant-import-tensorflow-in-python-windows-10-64-bit/61656869#61656869](url)\r\n\r\nI'm using python 3.8 (64-bit) and I encountered the same problem, I tried to do a VS c ++ 2019 (x64) update and it worked. Thank you"]}, {"number": 42392, "title": "tf-nightly: 'bfloat16' in namespace 'Eigen' does not name a type.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, custom op\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly==2.4.0.dev20200815\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 7.6.5.32\r\n- GPU model and memory: t4\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nAttempting to compile a custom op (Horovod) with the latest tf-nightly produces numerous error messages of the form:\r\n\r\n```\r\n\r\nIn file included from /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/platform/types.h:21:0,\r\n\r\nfrom /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,\r\nfrom /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/platform/status.h:24,\r\nfrom /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/lib/core/status.h:19,\r\nfrom /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:25,\r\nfrom /usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/framework/op.h:23,\r\nfrom horovod/tensorflow/mpi_ops.cc:24:\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/tensorflow/core/platform/bfloat16.h:25:16: error: 'bfloat16' in namespace 'Eigen' does not name a type\r\ntypedef Eigen::bfloat16 bfloat16;\r\n^~~~~~~~\r\n```\r\n\r\nThis may be related to https://github.com/tensorflow/tensorflow/commit/576d1d395d01a24483a9ebf66ba704ba38043e63 and https://github.com/tensorflow/tensorflow/commit/dab490a8bfb0cf1f289c9352c4d086356d0e5949 which were merged yesterday.\r\n\r\nLooks like there may be some missing headers.\r\n", "comments": ["@tgaddair,\r\nCould you please provide the complete code and the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "Hey @amahendrakar, looks like the issue was due to a conflict between TensorFlow's use of Eigen and the version we were using for our code.  After updating Eigen, the issue was solved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42392\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42392\">No</a>\n", "> Hey @amahendrakar, looks like the issue was due to a conflict between TensorFlow's use of Eigen and the version we were using for our code. After updating Eigen, the issue was solved.\r\n\r\nHi @tgaddair -- I also ran into this. Which version(s) are you using? Built tensorflow from source and brought over the third_party libs and its Eigen. The rest of the codebase uses Eigen 3.3.7.", "Hey @ahoereth, it may be that you're pointing to the old GitHub repo for Eigen.  They switched over to GitLab about a year ago, and the previous repo hasn't been updated since.  Updating to point to GitLab addressed the issue for us: https://gitlab.com/libeigen/eigen", "Thanks for the quick response, I'm using the 3.3.7 release targz from https://gitlab.com/libeigen/eigen. Am now building a older version of tensorflow to see whether the commits you reference actually produced the problem."]}, {"number": 42391, "title": "distributed training", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@Fanbenchao \r\nCan you please update the issue template."]}, {"number": 42390, "title": "Error. Converter does not support Quantization NN with 'tanh' activation", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.3.0 (Google Collab)\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\nhttps://colab.research.google.com/drive/12K7FKEFvbJx7gUuI93hsS6si1n0zYRSO?usp=sharing\r\n\r\n```\r\n# Copy and paste here the exact command\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\nINFO:tensorflow:Assets written to: /tmp/tmpnq1srnbk/assets\r\nINFO:tensorflow:Assets written to: /tmp/tmpnq1srnbk/assets\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-27-89960d743844> in <module>()\r\n      9 converter.representative_dataset = representative_dataset_generator\r\n     10 \r\n---> 11 tflite_model = converter.convert()\r\n\r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py in calibrate_and_quantize(self, dataset_gen, input_type, output_type, allow_float, activations_type, resize_input)\r\n     96         np.dtype(input_type.as_numpy_dtype()).num,\r\n     97         np.dtype(output_type.as_numpy_dtype()).num, allow_float,\r\n---> 98         np.dtype(activations_type.as_numpy_dtype()).num)\r\n     99 \r\n    100   def calibrate_and_quantize_single(self,\r\n\r\nRuntimeError: Quantization not yet supported for op: \r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nSee in Google Collab notebook.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Converter fails during conversion\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nMy network uses 'tanh' activation.\r\nIf I use 'tanh' activation the converter fails.\r\nIf I use only 'relu' activations the converter does conversion successfully.\r\n", "comments": ["Thanks for catching this bug! :) @liufengdb is looking into this and will post an update when it's fixed!", "I will create a fix internally and will push it to open source.", "What is the recommended way to debug such errors? If many possible operations are there which can fail. Is there a way to see which Op it was trying convert when failure happens?", "Ideally you shouldn't face this issue. If you do, the error should contain the name of the operator that failed (we're looking why it currently doesn't print the name) so the user can either change the operator (as the TFLite doesn't support quantization for it yet) or file a bug so we can look into it (such as the current github issue).", "My issue seems to be gone in master. But master's quantized int8 models are no longer being recognized as quantized by edgetpu-compiler. Sadly the solution by them is to wait or revert to using TOCO or version 2.1. ", "Closing the issue as it's resolved, feel free to re-open this if it's unresolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42390\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42390\">No</a>\n"]}, {"number": 42389, "title": "Undocumented S3_DISABLE_MULTI_PART_DOWNLOAD variable and its behavior", "body": "## URL(s) with the issue:\r\n\r\nS3 environment variables are partially documented here: https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/s3.md.\r\nHowever, there doesn't seem to be a complete documentation of this feature anywhere.\r\n\r\n## Description of issue (what needs changing):\r\n\r\nTensorFlow's S3 client use `S3_DISABLE_MULTI_PART_DOWNLOAD` environment variable (see [s3_file_system.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system.cc#L482)). However, it's not documented anywhere.\r\n\r\n### Clear description\r\n\r\nThis environment variable disables multi-part download from S3, and S3-like storage systems (like [AIStore](https://github.com/NVIDIA/aistore/)). Neither it's documented in this repository, nor google returns any valid result when searching it.\r\n\r\nIt's not clear for users (including me) if it's safe to use this variable. It does work, however, is it deprecated or is it going to be supported continuously?\r\n\r\nAdditionally, the required value of this variable, for multi-part download to be disabled, is any string with the first character `1`, which is not a perfect solution (having in mind lack of documentation).\r\n\r\n### Correct links\r\n\r\nSource code using this environment variable: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system.cc#L482\r\n\r\n### Usage example\r\n\r\nThere is no documentation, nor usage examples.\r\n", "comments": ["Closing this issue since tensoflow/io repo is the right place for this issue.\r\nTo know more refer the issue tagged above in the thread. Thanks!"]}, {"number": 42387, "title": "Tensorflow Aborted due to tensorflow/core/lib/monitoring/sampler.cc:42", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 18.04 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nBinary\r\n- TensorFlow version (use command below):\r\n- Python version:\r\nAll versions\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\nCan't import\r\n\r\n**Describe the current behavior**\r\n2020-08-15 13:43:45.726668: F tensorflow/core/lib/monitoring/sampler.cc:42] Check failed: bucket_limits_[i] >\r\nAborted\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@nrchaudhry \r\nCan you please update the issue template, tf version and the steps performed before the error was encountered, and the error logs for us to analyse.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42387\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42387\">No</a>\n", "<img width=\"1164\" alt=\"image\" src=\"https://user-images.githubusercontent.com/32613582/106357008-18c6d600-6336-11eb-87fb-4949bc0d543d.png\">\r\nI'm stucking from this monitoring. Could anyone help?", "@bdockbockd \r\nPlease create a new issue as this is closed.", "Tensorflow no longer supports Mac OSX. This error message will come up while running Tensorflow on Mac OSX.", "@scchess are you sure about that? I thought it was only GPU support that got removed but that CPU support should still work on macOS. There are still wheels published for Mac on PyPI anyway: https://pypi.org/project/tensorflow/#files"]}, {"number": 42386, "title": "GradientTape.gradient needs to check target type.", "body": "https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/eager/backprop.py#L991\r\n\r\nRecently, I wrote some code below which is very simple,\r\n```python\r\ntape.gradient(loss, model.trainable_variables)\r\n```\r\nbut it raises `TypeError: Cannot convert value None to a Tensorflow DType.`\r\nIt turns out my custom loss function is returning None. yes, I know I was dumb.\r\n\r\nI had to check all of the related tensorflow code lines to find this dumb problem.\r\n\r\nSo, I suggest the type checking block inside of this code.\r\nI think this suggestion can be helpful for fools like me.\r\n\r\nThanks in advance :)", "comments": ["@aingo03304,\r\nIn order to expedite the trouble-shooting process, could you please provide the TensorFlow version, the complete code to reproduce the issue and the dataset you are using. Thanks!", "@amahendrakar Thank you for the kind and quick response! \r\nYou can reproduce with this code sample which is very simple.\r\n```python\r\nimport tensorflow as tf\r\ndef get_loss(y_true, y_pred):\r\n    pass\r\n\r\nwith tf.GradientTape() as tape:\r\n    tape.gradient(get_loss(1, 2), None)\r\n```\r\nIt raises `TypeError: Cannot convert value None to a TensorFlow DType.`on tensorflow `2.3.0`.\r\nIt is foolish code, but the error is raised in `tensorflow/python/framework/dtypes.py` and the message doesn't tell you that the loss function is wrong.\r\n\r\nBecause the error message should help people to find out where the code has a fault, I suggested you add some type check features in `gradient` function which is visible to users.\r\n\r\nAnd the docstring on gradient function says,\r\n```\r\n Args:\r\n      target: a list or nested structure of Tensors or Variables to be\r\n        differentiated.\r\n      sources: a list or nested structure of Tensors or Variables. `target`\r\n        will be differentiated against elements in `sources`.\r\n      output_gradients: a list of gradients, one for each element of\r\n        target. Defaults to None.\r\n      unconnected_gradients: a value which can either hold 'none' or 'zero' and\r\n        alters the value which will be returned if the target and sources are\r\n        unconnected. The possible values and effects are detailed in\r\n        'UnconnectedGradients' and it defaults to 'none'.\r\n```\r\n\r\nI would add the message like `TypeError: target should be a list or nested structure of Tensors or Variables to be differentiated, but (TYPE) given`.", "@ymodak Hi, can you tell me what the bug related to this issue? Just curious about it.", "Closing this issue since the [3edb086](https://github.com/tensorflow/tensorflow/commit/f25125e50bab365642335413356466883bf7f361) commit fixes it. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42386\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42386\">No</a>\n"]}, {"number": 42385, "title": "Add EuclideanNorm XLA kernel", "body": "Per discussion https://github.com/tensorflow/tensorflow/pull/41916#issuecomment-673641088. In order not to have additional works for common reduction ops, it calls another virtual function, which defaults to returning input directly when axis is empty. I have no better engineering way to approach this, so it's more than welcome to have some feedback. Thanks!\r\n\r\n/cc @cheshire.", "comments": ["Would it be hard to wrap instead of subclassing?", "> Would it be hard to wrap instead of subclassing?\r\n\r\nIt would not. But I initially guess that there will be lots of duplicated codes (about handling reduction axes) if we do not subclass directly. Do you have suggestion on this?", "I see, since `XlaReductionOp` is a kernel it might be harder to wrap it. Could you just factor out all the helper methods you need and call them directly instead of using inheritance?", "> I see, since `XlaReductionOp` is a kernel it might be harder to wrap it. Could you just factor out all the helper methods you need and call them directly instead of using inheritance?\r\n\r\nWill do :-) Thanks!", "@WindQAQ Any update on this PR? Please. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@WindQAQ Any update on this PR? Please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 42384, "title": "Cannot install with pip", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home\r\n- TensorFlow version: 2.3\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\nCannot install any tensorflow version.\r\n\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nvenv\\Scripts\\python -m pip install tensorflow\r\n\r\n", "comments": ["Never mind. i never realised i was using 32bit python all this time.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42384\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42384\">No</a>\n"]}, {"number": 42383, "title": "`metrics=['accuracy']` works, `metrics=['Accuracy']` gives `ValueError: Shapes (None, 10) and (None, 1) are incompatible`", "body": "I want to use [`tf.keras.metrics`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) the same way I use [`tf.keras.optimizers`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). I can pass `'Adam'` and it'll work. I can pass an instantiation of [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and it'll work.\r\n\r\nUnfortunately the same isn't true for `tf.keras.metrics`, making it difficult to derive the full list of builtin metrics\u2026\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nUse this example and just replace `'accuracy'` with `'Accuracy'` https://github.com/tensorflow/datasets/blob/8723d84/docs/keras_example.ipynb\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\nError\r\n\r\n**Describe the expected behavior**\r\nNo error. Looking here it doesn't appear they they are different:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy\r\n\r\nOr is one the class and one an instance? - Should we be able to pass `'Accuracy'` as a string, or is the expected behaviour?\r\n\r\n**Standalone code to reproduce the issue**\r\nUse this example and just replace `'accuracy'` with `'Accuracy'` https://github.com/tensorflow/datasets/blob/8723d84/docs/keras_example.ipynb\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\nFile \"lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 823, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 696, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3065, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 973, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\r\n        return step_function(self, iterator)\r\n    lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\r\n        outputs = model.train_step(data)\r\n    lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:759 train_step\r\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\r\n    lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:409 update_state\r\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\r\n    lib/python3.8/site-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated\r\n        update_op = update_state_fn(*args, **kwargs)\r\n    lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:176 update_state_fn\r\n        return ag_update_state(*args, **kwargs)\r\n    lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:612 update_state  **\r\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\r\n    lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:3208 accuracy  **\r\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\r\n    lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\r\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\n\r\n    ValueError: Shapes (None, 10) and (None, 1) are incompatible\r\n```", "comments": ["Hello, I would like to work on this issue, can  you explain me what are you expecting from this. Should I have to make it to case insensitive  or just put a warning/error.", "Was able to reproduce the issue in TF 2.3 and nightly version. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/5c8d7694ffe4a3db2110f513d4805fb9/tensorflow-datasets.ipynb#scrollTo=XWqxdmS1NLKA).Thanks!", "@SamuelMarks I think you can pass 'accuracy' as well as 'Accuracy' metric. Following toy example exhibits successful behavior.\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ninputs = tf.keras.layers.Input(shape=(3,))\r\noutputs = tf.keras.layers.Dense(2)(inputs)\r\nmodel = tf.keras.models.Model(inputs=inputs, outputs=outputs)\r\nmodel.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"Accuracy\"])\r\n\r\nx = np.random.random((2, 3))\r\ny = np.random.randint(0, 2, (2, 2))\r\nmodel.fit(x, y)\r\n\r\nprint([m.name for m in model.metrics])\r\nprint(tf.__version__)\r\n#Ouput:\r\n1/1 [==============================] - 0s 282us/step - loss: 0.6162 - accuracy: 0.0000e+00\r\n['loss', 'accuracy']\r\n2.4.0-dev20200721\r\n```\r\nHowever the same logic fails in the example you are trying. Will investigate more. Thanks!", "Maybe it's because `metrics=['Accuracy']` means just plain `tf.keras.metrics.Accuracy` class. Since CIFAR-10 and MNIST classifies images into 10 classes (CIFAR-10 can be seen in [current tensorflow tutorial](https://www.tensorflow.org/tutorials/images/cnn)), metric should be categorical, for example, `tf.keras.metrics.SparseCategoricalAccuracy` class, or `'sparse_categorical_accuracy'`(The name of `tf.keras.metrics.SparseCategoricalAccuracy` class).\r\n\r\nBelow code(I tested for CIFAR-10) should work, test in\r\n- OS: Windows 10 Pro\r\n- GPU: GTX 1660 Ti with MAX-Q design\r\n- TF version: 2.3.1\r\n- CUDA: 10.1\r\n- cuDNN: 7.6.5\r\n- Python: 3.8.6\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras import datasets, layers, models\r\n\r\n(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\r\n\r\ntrain_images, test_images = train_images / 255.0, test_images / 255.0\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, input_shape=(32, 32, 3)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu))\r\nmodel.add(layers.Flatten())\r\nmodel.add(layers.Dense(64, activation=tf.keras.activations.relu))\r\nmodel.add(layers.Dense(10))\r\n\r\nmodel.summary()\r\n\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(),\r\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\r\n)\r\n\r\nhistory = model.fit(train_images, train_labels, epochs=10,\r\n                    validation_data=(test_images, test_labels))\r\n\r\ntest_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\r\n\r\nprint(test_acc)\r\n```\r\nIf you change `metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]` to `metrics=['Accuracy']` above code will not work, with the error `ValueError: Shapes (None, 10) and (None, 1) are incompatible`.\r\n\r\nAfter searching some tensorflow code, found this comment:\r\n(https://github.com/tensorflow/tensorflow/blob/9278b9421f64a2103d18a67d825a9b6be243e211/tensorflow/python/keras/engine/training.py#L477)\r\n\r\n> When you pass the strings 'accuracy' or 'acc', we convert this to one of `tf.keras.metrics.BinaryAccuracy`, `tf.keras.metrics.CategoricalAccuracy`, `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss function used and the model output shape. We do a similar conversion for the strings 'crossentropy' and 'ce' as well.\r\n\r\nThis explains why `'accuracy'` works but `'Accuracy'` does not.\r\n\r\nHope this will help :)", "@SamuelMarks, have you seen the comment from @amoretspero? Let me know if this answers your question.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thanks @nikitamaia / @amoretspero yeah it does resolve the issue\u2026 but not the issue. I'm still left with no way to infer this behaviour for the code I generate https://github.com/SamuelMarks/ml-params-tensorflow/blob/4eea761/ml_params_tensorflow/ml_params/metrics.py\r\n\r\nShould I just give up on having it work this way, or maybe implementing an `object` inheriting `class` which just constructs the relevant `Metric` would be in order?", "Adding the `contributions welcome` label to this issue for further investigation by the community. If you are interested in working on this issue, please leave a comment and I will assign it to you. Thanks!", "@SamuelMarks is this releated to https://github.com/tensorflow/tensorflow/issues/41361 or something different?", "@nikitamaia , Please assign this issue to me. I have worked on this and raised PR #49218 .", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42383\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42383\">No</a>\n", "@SamuelMarks , You can confirm. The [gist](https://colab.research.google.com/gist/saikumarchalla/5c8d7694ffe4a3db2110f513d4805fb9/tensorflow-datasets.ipynb#scrollTo=XWqxdmS1NLKA) works normally now."]}, {"number": 42382, "title": "Sparsemax & tf.Cumsum", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): 2.3\r\n- TensorFlow version (or github SHA if from source): \r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# INFO:tensorflow:Assets written to: C:\\Users\\The-author\\AppData\\Local\\Temp\\tmp1ty7mqo0\\assets\r\nINFO:tensorflow:Assets written to: C:\\Users\\The-author\\AppData\\Local\\Temp\\tmp1ty7mqo0\\assets\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    198                                                  debug_info_str,\r\n--> 199                                                  enable_mlir_converter)\r\n    200       return model_str\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n     37       debug_info_str,\r\n---> 38       enable_mlir_converter)\r\n     39 \r\n\r\nException: C:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3736:0: error: 'tf.Cumsum' op is neither a custom op nor a flex op\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py:201:0: note: called from\r\nc:\\users\\The-author\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_addons\\activations\\sparsemax.py:105:0: note: called from\r\nc:\\users\\The-author\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_addons\\activations\\sparsemax.py:47:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:269:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py:134:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3736:0: note: see current operation: %12 = \"tf.Cumsum\"(%values, %cst_1) {device = \"\", exclusive = false, reverse = false} : (tensor<?x?xf32>, tensor<i32>) -> tensor<?x?xf32>\r\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n\ttf.Cumsum {device = \"\", exclusive = false, reverse = false}\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<?x256x256x3xf32>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_0 = \"std.constant\"() {value = dense<0x7FC00000> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_1 = \"std.constant\"() {value = dense<-1> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_2 = \"std.constant\"() {value = dense<0> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_3 = \"std.constant\"() {value = dense<1> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_4 = \"std.constant\"() {value = dense<1.000000e+00> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_5 = \"std.constant\"() {value = dense<\"0xB2936CBE88F3B63E70265B3ED3BFC5BEDB44C63E4365F43E241B69BE14CBD0BDE4A013BE81638FBEAECCF8BE1FF1ADBEA9CB8ABE019BBD3E6ED7753DF441F53D01D5143FA511A6BE5F2A97BEE01FCFBEEBC3E23C99C39F3E6C510E3FD29ACD3E5E5F94BE26B3C2BE5BE612BF09CAB6BD97D9A83E0076BFBEE1950C3FEC438ABD41F56EBE33D299BECCFCEEBE70D91A3E3C6FD6BD7440483E123E17BDA734813EB9A9103E98BFB3BC6FA1BFBE00B5BE3E0E84AABE07AE0BBE6385B63D5B9B08BE7506263EDC6FA93ECF488EBC046AAFBE32B567BC9B356CBEFC4C803E12A3973EF17A333ECE1E1C3E4F85C7BDFA8AA6BEF72768BC53141F3B0E1D213EAD543BBE37F004BD2720973E078C2D3EEC62913E2D23863D2BF081BE4B3FC5BD4BEABFBDD257DA3ED93FA2BE20C04BBE3A34583EB16BD43E36CCCBBE318360BE3007823E26DF61BED0CA423E866A8FBE435DAC3DFD61DF3D29CD723E67DECDBE79B99EBD3870183CC82A863E8BB9C83D57CFE1BE4A8D99BE42BD263ECBAA2CBDFBF3EA3E809D4EBE2E7E04BFB6DB2BBE6D670BBE7642B5BE1A9EA0BD7C9C3ABE7074623E51C034BE10F3093E460FB1BE7F2E99BE\"> : tensor<4x3x3x3xf32>} : () -> tensor<4x3x3x3xf32>\r\n  %cst_6 = \"std.constant\"() {value = dense<0.000000e+00> : tensor<4xf32>} : () -> tensor<4xf32>\r\n  %cst_7 = \"std.constant\"() {value = dense<-1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_8 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_9 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_10 = \"std.constant\"() {value = dense<[0, -1]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_11 = \"std.constant\"() {value = dense<0> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_12 = \"std.constant\"() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %0 = \"tfl.conv_2d\"(%arg0, %cst_5, %cst_6) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x256x256x3xf32>, tensor<4x3x3x3xf32>, tensor<4xf32>) -> tensor<?x256x256x4xf32>\r\n  %1 = \"tfl.shape\"(%0) : (tensor<?x256x256x4xf32>) -> tensor<4xi32>\r\n  %2 = \"tfl.strided_slice\"(%1, %cst_8, %cst_7, %cst_9) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 0 : i32} : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<3xi32>\r\n  %3 = \"tfl.reduce_prod\"(%2, %cst_8) {keep_dims = false} : (tensor<3xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %4 = \"tfl.range\"(%cst_2, %3, %cst_3) : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<?xi32>\r\n  %5 = \"tfl.strided_slice\"(%1, %cst_7, %cst_8, %cst_9) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %6 = \"tfl.cast\"(%5) : (tensor<i32>) -> tensor<f32>\r\n  %7 = \"tfl.add\"(%6, %cst_4) {fused_activation_function = \"NONE\"} : (tensor<f32>, tensor<f32>) -> tensor<f32>\r\n  %8 = \"tfl.range\"(%cst_4, %7, %cst_4) : (tensor<f32>, tensor<f32>, tensor<f32>) -> tensor<?xf32>\r\n  %9 = \"tfl.pack\"(%3, %5) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %10 = \"tfl.fill\"(%9, %cst_0) : (tensor<2xi32>, tensor<f32>) -> tensor<?x?xf32>\r\n  %11 = \"tfl.reshape\"(%0, %9) : (tensor<?x256x256x4xf32>, tensor<2xi32>) -> tensor<?x?xf32>\r\n  %values, %indices = \"tfl.topk_v2\"(%11, %5) : (tensor<?x?xf32>, tensor<i32>) -> (tensor<?x?xf32>, tensor<?x?xi32>)\r\n  %12 = \"tf.Cumsum\"(%values, %cst_1) {device = \"\", exclusive = false, reverse = false} : (tensor<?x?xf32>, tensor<i32>) -> tensor<?x?xf32>\r\n  %13 = \"tfl.strided_slice\"(%12, %cst_10, %cst_11, %cst_12) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor<?x?xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?xf32>\r\n  %14 = \"tf.IsNan\"(%13) {device = \"\"} : (tensor<?xf32>) -> tensor<?xi1>\r\n  %15 = \"tfl.mul\"(%8, %values) {fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>\r\n  %16 = \"tfl.add\"(%15, %cst_4) {fused_activation_function = \"NONE\"} : (tensor<?x?xf32>, tensor<f32>) -> tensor<?x?xf32>\r\n  %17 = \"tfl.greater\"(%16, %12) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xi1>\r\n  %18 = \"tfl.cast\"(%17) : (tensor<?x?xi1>) -> tensor<?x?xi32>\r\n  %19 = \"tfl.sum\"(%18, %cst_1) {keep_dims = false} : (tensor<?x?xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %20 = \"tfl.cast\"(%19) : (tensor<?xi32>) -> tensor<?xf32>\r\n  %21 = \"tfl.equal\"(%19, %cst_2) : (tensor<?xi32>, tensor<i32>) -> tensor<?xi1>\r\n  %22 = \"tfl.logical_or\"(%21, %14) : (tensor<?xi1>, tensor<?xi1>) -> tensor<?xi1>\r\n  %23 = \"tfl.expand_dims\"(%22, %cst_1) : (tensor<?xi1>, tensor<i32>) -> tensor<?x1xi1>\r\n  %24 = \"tfl.maximum\"(%19, %cst_3) : (tensor<?xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %25 = \"tfl.sub\"(%24, %cst_3) {fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %26 = \"tfl.reshape\"(%25, %cst_7) : (tensor<?xi32>, tensor<1xi32>) -> tensor<?xi32>\r\n  %27 = \"tfl.pack\"(%4, %26) {axis = 1 : i32, values_count = 2 : i32} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?x2xi32>\r\n  %28 = \"tfl.gather_nd\"(%12, %27) : (tensor<?x?xf32>, tensor<?x2xi32>) -> tensor<?xf32>\r\n  %29 = \"tfl.sub\"(%28, %cst_4) {fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<f32>) -> tensor<?xf32>\r\n  %30 = \"tfl.div\"(%29, %20) {fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %31 = \"tfl.expand_dims\"(%30, %cst_1) : (tensor<?xf32>, tensor<i32>) -> tensor<?x1xf32>\r\n  %32 = \"tfl.sub\"(%11, %31) {fused_activation_function = \"NONE\"} : (tensor<?x?xf32>, tensor<?x1xf32>) -> tensor<?x?xf32>\r\n  %33 = \"tfl.maximum\"(%32, %cst) : (tensor<?x?xf32>, tensor<f32>) -> tensor<?x?xf32>\r\n  %34 = \"tfl.select_v2\"(%23, %10, %33) : (tensor<?x1xi1>, tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>\r\n  %35 = \"tfl.reshape\"(%34, %1) : (tensor<?x?xf32>, tensor<4xi32>) -> tensor<?x?x?x?xf32>\r\n  \"std.return\"(%35) : (tensor<?x?x?x?xf32>) -> ()\r\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"input_8\", outputs = \"Identity\"}, type = (tensor<?x256x256x3xf32>) -> tensor<?x?x?x?xf32>} : () -> ()\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-31-e001f5ecf3f4> in <module>\r\n      4 converter.experimental_new_converter = True\r\n      5 \r\n----> 6 tflite_model = converter.convert()\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self)\r\n    829 \r\n    830     return super(TFLiteKerasModelConverterV2,\r\n--> 831                  self).convert(graph_def, input_tensors, output_tensors)\r\n    832 \r\n    833 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self, graph_def, input_tensors, output_tensors)\r\n    631         input_tensors=input_tensors,\r\n    632         output_tensors=output_tensors,\r\n--> 633         **converter_kwargs)\r\n    634 \r\n    635     calibrate_and_quantize, flags = quant_mode.quantizer_flags(\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    572       input_data.SerializeToString(),\r\n    573       debug_info_str=debug_info_str,\r\n--> 574       enable_mlir_converter=enable_mlir_converter)\r\n    575   return data\r\n    576 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    200       return model_str\r\n    201     except Exception as e:\r\n--> 202       raise ConverterError(str(e))\r\n    203 \r\n    204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n\r\nConverterError: C:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3736:0: error: 'tf.Cumsum' op is neither a custom op nor a flex op\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py:201:0: note: called from\r\nc:\\users\\The-author\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_addons\\activations\\sparsemax.py:105:0: note: called from\r\nc:\\users\\The-author\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_addons\\activations\\sparsemax.py:47:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:269:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py:134:0: note: called from\r\nC:\\Users\\The-author\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3736:0: note: see current operation: %12 = \"tf.Cumsum\"(%values, %cst_1) {device = \"\", exclusive = false, reverse = false} : (tensor<?x?xf32>, tensor<i32>) -> tensor<?x?xf32>\r\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n\ttf.Cumsum {device = \"\", exclusive = false, reverse = false}\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<?x256x256x3xf32>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_0 = \"std.constant\"() {value = dense<0x7FC00000> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_1 = \"std.constant\"() {value = dense<-1> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_2 = \"std.constant\"() {value = dense<0> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_3 = \"std.constant\"() {value = dense<1> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_4 = \"std.constant\"() {value = dense<1.000000e+00> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_5 = \"std.constant\"() {value = dense<\"0xB2936CBE88F3B63E70265B3ED3BFC5BEDB44C63E4365F43E241B69BE14CBD0BDE4A013BE81638FBEAECCF8BE1FF1ADBEA9CB8ABE019BBD3E6ED7753DF441F53D01D5143FA511A6BE5F2A97BEE01FCFBEEBC3E23C99C39F3E6C510E3FD29ACD3E5E5F94BE26B3C2BE5BE612BF09CAB6BD97D9A83E0076BFBEE1950C3FEC438ABD41F56EBE33D299BECCFCEEBE70D91A3E3C6FD6BD7440483E123E17BDA734813EB9A9103E98BFB3BC6FA1BFBE00B5BE3E0E84AABE07AE0BBE6385B63D5B9B08BE7506263EDC6FA93ECF488EBC046AAFBE32B567BC9B356CBEFC4C803E12A3973EF17A333ECE1E1C3E4F85C7BDFA8AA6BEF72768BC53141F3B0E1D213EAD543BBE37F004BD2720973E078C2D3EEC62913E2D23863D2BF081BE4B3FC5BD4BEABFBDD257DA3ED93FA2BE20C04BBE3A34583EB16BD43E36CCCBBE318360BE3007823E26DF61BED0CA423E866A8FBE435DAC3DFD61DF3D29CD723E67DECDBE79B99EBD3870183CC82A863E8BB9C83D57CFE1BE4A8D99BE42BD263ECBAA2CBDFBF3EA3E809D4EBE2E7E04BFB6DB2BBE6D670BBE7642B5BE1A9EA0BD7C9C3ABE7074623E51C034BE10F3093E460FB1BE7F2E99BE\"> : tensor<4x3x3x3xf32>} : () -> tensor<4x3x3x3xf32>\r\n  %cst_6 = \"std.constant\"() {value = dense<0.000000e+00> : tensor<4xf32>} : () -> tensor<4xf32>\r\n  %cst_7 = \"std.constant\"() {value = dense<-1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_8 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_9 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_10 = \"std.constant\"() {value = dense<[0, -1]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_11 = \"std.constant\"() {value = dense<0> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_12 = \"std.constant\"() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %0 = \"tfl.conv_2d\"(%arg0, %cst_5, %cst_6) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x256x256x3xf32>, tensor<4x3x3x3xf32>, tensor<4xf32>) -> tensor<?x256x256x4xf32>\r\n  %1 = \"tfl.shape\"(%0) : (tensor<?x256x256x4xf32>) -> tensor<4xi32>\r\n  %2 = \"tfl.strided_slice\"(%1, %cst_8, %cst_7, %cst_9) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 0 : i32} : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<3xi32>\r\n  %3 = \"tfl.reduce_prod\"(%2, %cst_8) {keep_dims = false} : (tensor<3xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %4 = \"tfl.range\"(%cst_2, %3, %cst_3) : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<?xi32>\r\n  %5 = \"tfl.strided_slice\"(%1, %cst_7, %cst_8, %cst_9) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %6 = \"tfl.cast\"(%5) : (tensor<i32>) -> tensor<f32>\r\n  %7 = \"tfl.add\"(%6, %cst_4) {fused_activation_function = \"NONE\"} : (tensor<f32>, tensor<f32>) -> tensor<f32>\r\n  %8 = \"tfl.range\"(%cst_4, %7, %cst_4) : (tensor<f32>, tensor<f32>, tensor<f32>) -> tensor<?xf32>\r\n  %9 = \"tfl.pack\"(%3, %5) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %10 = \"tfl.fill\"(%9, %cst_0) : (tensor<2xi32>, tensor<f32>) -> tensor<?x?xf32>\r\n  %11 = \"tfl.reshape\"(%0, %9) : (tensor<?x256x256x4xf32>, tensor<2xi32>) -> tensor<?x?xf32>\r\n  %values, %indices = \"tfl.topk_v2\"(%11, %5) : (tensor<?x?xf32>, tensor<i32>) -> (tensor<?x?xf32>, tensor<?x?xi32>)\r\n  %12 = \"tf.Cumsum\"(%values, %cst_1) {device = \"\", exclusive = false, reverse = false} : (tensor<?x?xf32>, tensor<i32>) -> tensor<?x?xf32>\r\n  %13 = \"tfl.strided_slice\"(%12, %cst_10, %cst_11, %cst_12) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor<?x?xf32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?xf32>\r\n  %14 = \"tf.IsNan\"(%13) {device = \"\"} : (tensor<?xf32>) -> tensor<?xi1>\r\n  %15 = \"tfl.mul\"(%8, %values) {fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>\r\n  %16 = \"tfl.add\"(%15, %cst_4) {fused_activation_function = \"NONE\"} : (tensor<?x?xf32>, tensor<f32>) -> tensor<?x?xf32>\r\n  %17 = \"tfl.greater\"(%16, %12) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xi1>\r\n  %18 = \"tfl.cast\"(%17) : (tensor<?x?xi1>) -> tensor<?x?xi32>\r\n  %19 = \"tfl.sum\"(%18, %cst_1) {keep_dims = false} : (tensor<?x?xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %20 = \"tfl.cast\"(%19) : (tensor<?xi32>) -> tensor<?xf32>\r\n  %21 = \"tfl.equal\"(%19, %cst_2) : (tensor<?xi32>, tensor<i32>) -> tensor<?xi1>\r\n  %22 = \"tfl.logical_or\"(%21, %14) : (tensor<?xi1>, tensor<?xi1>) -> tensor<?xi1>\r\n  %23 = \"tfl.expand_dims\"(%22, %cst_1) : (tensor<?xi1>, tensor<i32>) -> tensor<?x1xi1>\r\n  %24 = \"tfl.maximum\"(%19, %cst_3) : (tensor<?xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %25 = \"tfl.sub\"(%24, %cst_3) {fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %26 = \"tfl.reshape\"(%25, %cst_7) : (tensor<?xi32>, tensor<1xi32>) -> tensor<?xi32>\r\n  %27 = \"tfl.pack\"(%4, %26) {axis = 1 : i32, values_count = 2 : i32} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?x2xi32>\r\n  %28 = \"tfl.gather_nd\"(%12, %27) : (tensor<?x?xf32>, tensor<?x2xi32>) -> tensor<?xf32>\r\n  %29 = \"tfl.sub\"(%28, %cst_4) {fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<f32>) -> tensor<?xf32>\r\n  %30 = \"tfl.div\"(%29, %20) {fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %31 = \"tfl.expand_dims\"(%30, %cst_1) : (tensor<?xf32>, tensor<i32>) -> tensor<?x1xf32>\r\n  %32 = \"tfl.sub\"(%11, %31) {fused_activation_function = \"NONE\"} : (tensor<?x?xf32>, tensor<?x1xf32>) -> tensor<?x?xf32>\r\n  %33 = \"tfl.maximum\"(%32, %cst) : (tensor<?x?xf32>, tensor<f32>) -> tensor<?x?xf32>\r\n  %34 = \"tfl.select_v2\"(%23, %10, %33) : (tensor<?x1xi1>, tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>\r\n  %35 = \"tfl.reshape\"(%34, %1) : (tensor<?x?xf32>, tensor<4xi32>) -> tensor<?x?x?x?xf32>\r\n  \"std.return\"(%35) : (tensor<?x?x?x?xf32>) -> ()\r\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"input_8\", outputs = \"Identity\"}, type = (tensor<?x256x256x3xf32>) -> tensor<?x?x?x?xf32>} : () -> ()\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\ninputs = Input((256,256,3))\r\noutputs = tf.keras.layers.Conv2D(activation=tfa.activations.sparsemax,filters=4, kernel_size=(3,3), strides=1, padding=\"same\",kernel_initializer=tf.keras.initializers.HeNormal())(inputs)\r\n\r\nmodel = Model(inputs=[inputs], outputs=[outputs])\r\n\r\nmodel.compile(tf.keras.optimizers.Nadam(name=\"Nadam\"),\r\n              loss=tfa.losses.SparsemaxLoss(from_logits=True), \r\n              metrics=tf.keras.metrics.MeanIoU(4,name='mean_iou'))\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n\r\n\r\nIt can be \"fixed\" ( if we call that fixing ) by switching from the \" Sparsemax \" to the \" Softmax \" activation, but of course the softmax doesn't give the same results as the sparsemax.\r\nI also tried the \" tfa.**layers**.Sparsemax \" but i guess that they have the same root implementation since i got an equivalent error.\r\n\r\n**Thanks for your attention **\r\n\r\n", "comments": ["@Otakarlp,\r\nI was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/99bafff4461fc35606440ccbc78387df/42382.ipynb#scrollTo=FbW9MLa3zysb). \r\n\r\nHowever, the issue seems to be resolved with the latest [TF-nightly](https://colab.research.google.com/gist/amahendrakar/fff90ece097490efab0938f121a86e4f/42382-tf-nightly.ipynb). I was able to convert the model without any issues. Please find the attached gist. Thanks!", "@amahendrakar \r\n\r\nI was able to make the tflite model and run inference with the TF-nightly version \" 2.4.0-dev20200813 \" ( latest version on windows i suppose ) as you suggested it, and that worked perfectly.\r\n\r\nThanks for your help, have a great day !\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42382\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42382\">No</a>\n"]}, {"number": 42381, "title": "Subclass model can't restore weights from h5 format", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087\r\n- Python version: 3.7.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: GTX 1060 6GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nThe last two prints should print a tensor of random numbers.\r\n\r\n**Describe the expected behavior**\r\nThe last two prints should print a tensor of ones. It works if we save it as TF format.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\nclass Model(tf.keras.Model):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        self.a = tf.Variable(initial_value=tf.random.normal([5]), trainable=False, name='a')\r\n        self.call = tf.function(func=self.call, input_signature=[\r\n            tf.TensorSpec(shape=[None, 5], dtype=tf.float32)\r\n        ])\r\n        self.prod = tf.function(func=self.prod, input_signature=[\r\n            tf.TensorSpec(shape=[None, 5], dtype=tf.float32)\r\n        ])\r\n        self.set = tf.function(func=self.set, input_signature=[\r\n            tf.TensorSpec(shape=[5], dtype=tf.float32)\r\n        ])\r\n        self.build(input_shape=tf.TensorShape(dims=[None, 5]))\r\n\r\n    def call(self, inputs):\r\n        print(f'Tracing call with inputs={inputs}')\r\n        return self.a + inputs\r\n\r\n    def prod(self, inputs):\r\n        print(f'Tracing prod with inputs={inputs}')\r\n        return self.a * inputs\r\n\r\n    def set(self, value):\r\n        print(f'Tracing set with inputs={value}')\r\n        self.a.assign(value)\r\n\r\n\r\nif __name__ == '__main__':\r\n    model = Model()\r\n    print(model(tf.zeros(shape=[2, 5])))\r\n    print(model.prod(tf.ones(shape=[2, 5])))\r\n    model.set(tf.ones(shape=[5]))\r\n    print(model(tf.zeros(shape=[2, 5])))\r\n    print(model.prod(tf.ones(shape=[2, 5])))\r\n    print(model.weights)\r\n    model.save_weights('/tmp/a.h5')\r\n    del model\r\n    model = Model()\r\n    model.load_weights('/tmp/a.h5')\r\n    print(model(tf.zeros(shape=[2, 5])))\r\n    print(model.prod(tf.ones(shape=[2, 5])))\r\n\r\n```\r\nThe bahavior persists in Google colab: https://colab.research.google.com/drive/1b8WuO_hBvYynY5gkH_MSI0FJS0Qrj3MF?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@vermouth1992 \r\nPlease refer to [the gist](https://colab.research.google.com/gist/Saduf2019/2e14f6792a3cfd38b212ce114d7daaf2/untitled373.ipynb) and confirm if it replicated the issue reported.Thanks!", "> @vermouth1992\r\n> Please refer to [the gist](https://colab.research.google.com/gist/Saduf2019/2e14f6792a3cfd38b212ce114d7daaf2/untitled373.ipynb) and confirm if it replicated the issue reported.Thanks!\r\n\r\nYes. The issue is replicated.\r\n", "@vermouth1992 This is working as intended. When you have a custom_object and want to save model in `h5` format, then you need to add a `get_config` method as shown below. This `get_config` is not required if you save the model in `tf` format. Check [this guide](https://www.tensorflow.org/guide/keras/save_and_serialize#custom_objects) on TF website for more details.\r\n\r\n```\r\n    def get_config(self):\r\n        config = super(Model, self).get_config()\r\n        config.update({\"a\": self.a})\r\n        return config\r\n```\r\n\r\n\r\nPlease check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/629d3f22e24c7497c1473d1296eb71eb/tf_save_h5_bug.ipynb). Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "> @vermouth1992 This is working as intended. When you have a custom_object and want to save model in 'h5' format, then you need to add a `get_config` method as shown below. This `get_config` is not required if you save the model in 'tf' format. Check [this guide](https://www.tensorflow.org/guide/keras/save_and_serialize#custom_objects) on TF website for more details.\r\n> \r\n> ```\r\n>     def get_config(self):\r\n>         config = super(Model, self).get_config()\r\n>         config.update({\"a\": self.a})\r\n>         return config\r\n> ```\r\n> \r\n> Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/629d3f22e24c7497c1473d1296eb71eb/tf_save_h5_bug.ipynb). Thanks!\r\n> \r\n> Please verify once and close the issue if this was resolved for you. Thanks!\r\n\r\nI see the problem. I actually tried what you said but it didn't work because I declared the tf.Variable inside the class. I changed the declaration inside the class and it doesn't work. So is it correct that all the variables have to be passed in as an argument for h5 format to work?", "Also, is there any better solution if I would like to decorate a class member function with batch shape (e.g. [None, dim]), where dim is passed in as an argument from the class constructor. Currently, I simply decorate them inside the constructor but this is actually really ugly. This is very useful to avoid retracing if the batch size is always changing such as in reinforcement learning, where the length of the trajectory is always changing. Thank you very much for your help!", "@vermouth1992 Defining `a` inside `def __init__(self):` is problematic as and when you instantiate the subclass model, it will `run def __init__(self):` and reinitialize ` a` with a `tf.random.normal([5])`. Thanks!", "Please close the issue if this was resolved for you. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42381\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42381\">No</a>\n"]}, {"number": 42379, "title": "Cube root of negative number returns nan", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.3.0-0-gb36436b087 2.3.0\r\n- Python version: 3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: P100, 16GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\ntf.constant(-1.)**(1/3.) returns nan\r\n\r\n**Describe the expected behavior**\r\nIt should return -1\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\ntf.constant(-1.)**(1/3.)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nOdd roots are defined while even roots are imaginary\r\n", "comments": ["I think this is c++ semantics on `pow`, and numpy also does the same things because it invokes c++ `pow`, so does tensorflow's backend Eigen.\r\n\r\nhttps://en.cppreference.com/w/cpp/numeric/math/pow\r\n\r\n> `pow(base, exp)` returns NaN and raises FE_INVALID if base is finite and negative and exp is finite and non-integer.\r\n", "I think this could be done for integer roots. You could implement a separate function for roots called `root`. If it's an odd integer root, return sign(x)*root(abs(x)) using `pow`. It could be used to create an activation function using cube root. It would need a custom gradient due to the sign, in case you want to implement it manually.", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/de7370c64572ba7004c11239e1b0ef5b/42379.ipynb). Thanks!", "@PyFormulae I think you forgot to add another set of parenthesis. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/87264b76972fdb097a633dae2791f508/42379.ipynb). Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "> @PyFormulae I think you forgot to add another set of parenthesis. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/87264b76972fdb097a633dae2791f508/42379.ipynb). Thanks!\r\n> \r\n> Please verify once and close the issue if this was resolved for you. Thanks!\r\n\r\nThat computes the cube root of a float, not a tensor. If you used complex tensors that would work. See https://colab.research.google.com/gist/PyFormulae/b318c334512cce2b38a07bde22db826a/42379.ipynb#scrollTo=YyPZzaR8rmCr. You have to rotate the result by 2*pi/3", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42379\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42379\">No</a>\n"]}, {"number": 42378, "title": "The estimated size for TPUEstimatorSpec.predictions is too large. ", "body": "I have designed a model by using [TPUEstimator API](https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/tpu/TPUEstimator). The outputs (TPUEstimatorSpec.predictions) of this model are very large (> 2GB). I got the following error:\r\n```\r\n# ValueError: The estimated size for TPUEstimatorSpec.predictions is too large. The transfer size is larger than the protobuf limit. Please consider using Tensors with smaller shapes or reduce batch size.\r\n```\r\nI am wondering if there is anyway which can bypass this limit so that I can output large results for the predictions by using \r\n`return tpu_estimator.TPUEstimatorSpec(mode, predictions={'outputs': tf_results})`", "comments": ["@hubertlu-tw,\r\n\r\nWe are checking to see if this is still an issue. As per the documentation of [TPUEstimator](https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/tpu/TPUEstimator),  they are not recommended and instead it is advised to use `tf.distribute.TPUStrategy`\r\n\r\n> TPU Estimator manages its own TensorFlow graph and session, so it is not compatible with TF2 behaviors. We recommend that you migrate to the newer tf.distribute.TPUStrategy. See the TPU guide for details.\r\n\r\nCan you take a look at the document and let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42378\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42378\">No</a>\n"]}, {"number": 42377, "title": "[40171] Add VarHandleOp to set of kernels not to cache", "body": "Following the discussion with @jaingaurav on pull request #42337 , I have reimplemented the patch for the fourth memory leak from issue #40171 . This new version of the patch filters out `VarHandleOp` operations from the set of operations whose kernels are cached inside `EagerExecutor`. Excluding `VarHandleOp` from caching prevents `saved_model.load()` from leaking kernels when loading variable values. This change reduces the amount of memory leakage on my test script (which repeatedly loads a toy Keras model) substantially:\r\n\r\n![cache_vs_no_cache](https://user-images.githubusercontent.com/12436991/90295190-1b437b00-de3d-11ea-870d-57d53534ee8b.png)\r\n\r\nNot caching these kernels should have minimal negative impact on performance as far as I'm aware.  `VarHandleOp::Compute()` is a relatively lightweight operation that usually runs right before a more expensive operation.", "comments": ["Sorry for the delay. @jaingaurav and I discussed this a bit; the fix for tf.Variable was to always use a fixed shared_name to indicate an anonymous resource. The reason something is still leaking is this line: https://github.com/tensorflow/tensorflow/blob/6d57022510f5820cfc3c5b86ba52fe623351bc63/tensorflow/python/ops/resource_variable_ops.py#L1957\r\n\r\nWhich should be like this line instead: https://github.com/tensorflow/tensorflow/blob/6d57022510f5820cfc3c5b86ba52fe623351bc63/tensorflow/python/ops/resource_variable_ops.py#L1706\r\n\r\nThe advantage is that we can keep the VarHandleOp kernels cached. I don't have a great sense of how much difference that'd make initializing models with lots of small variables, but it seems like it's worth having for the same reason we cached kernels in the first place.\r\n\r\nDoes that sound reasonable to you? I have a fix pending just changing that line (+ adding a heap check unit test for UninitializedVariable).", "@allenlavoie I suspect that change would produce some unintended sharing of buffers if the user were to load the same model twice in a single session. But maybe I'm reading the resource manager code incorrectly.", "Right, that's the \"to indicate an anonymous resource\" bit. The branching is here: https://github.com/tensorflow/tensorflow/blob/2ab4f849127adff4d9445200cf7c518a0620f437/tensorflow/core/kernels/resource_variable_ops.cc#L226\r\n\r\nThat logic we've had for a while. The change for UninitializedVariable (which SavedModel uses, vs. ResourceVariable which does not leak for this reason) is https://github.com/tensorflow/tensorflow/commit/84ff8673dca1a9b764069e189415bf76b34623d9\r\n\r\nAt least for CPU we're running a heapchecker and it's passing after that change; previously it did identify the kernel cache as a leak. I haven't tried it on a larger SavedModel load, but presumably leaks wouldn't be VarHandleOp kernel cache related anymore.", "@frreiss  Can you please check @allenlavoie's comments and keep us posted ? Thanks!", "Ah, I see now. Thanks for clarifying, @allenlavoie !", "@frreiss  Any update on this PR? Please. Thanks!", "I think we can close this for now."]}, {"number": 42375, "title": "InvalidArgumentError:  indices[28,46] = -1 is not in [0, 1000) \t [[node functional_3/embedding_4/embedding_lookup (defined at <ipython-input-64-77fdd54ae821>:5) ]] [Op:__inference_train_function_387521]", "body": "I am not sure why this error pops out, New to deep learning, Trying to add bert embedding to the LSTM model.\r\n Input is CSV of 2 columns - 1st column words, 2nd column labels\r\n\r\nProblem: classification problem\r\n", "comments": ["@samprithahm,\r\nIn order to expedite the trouble-shooting process, could you please provide the TensorFlow version, the complete code to reproduce the issue and the TensorFlow version you are using. Thanks!\r\n", "Also, please take a look at issue [#23698](https://github.com/tensorflow/tensorflow/issues/23698#issuecomment-439063103) and [this comment](https://stackoverflow.com/a/51224078) from a similar StackOverflow issue and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42374, "title": "unique_with_counts() ON MULTI-DIMENSIONAL TENSOR? ", "body": "**System information** \r\n\r\n     OS Platform and Distribution : macOS Catalina 10.15.3\r\n\r\n    TensorFlow installed from : binary\r\n\r\n    TensorFlow version : 1.15.0\r\n\r\n    Python version: 3.7.3\r\n\r\n**Describe the current behavior**\r\n\r\nWe have a tensor \r\n\r\ninput = `tf.Tensor([[1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6],\r\n [1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6]], shape=(2, 29), dtype=int64)`\r\n\r\noutput = `tf.Tensor([[0,2,1, ... 0. 0. 0.][0, 2, 1, ... 0, 0, 0]], shape=(2, 10000), dtype=float32)`\r\n\r\nHere 10000 is the dictionary size. \r\n\r\n**Describe the expected behavior**\r\n\r\nWe want vector output such that for each index it tell the frequency of each element \r\nie in \r\n`[1296  266  504  190   44   60   13    2  337 6742 2667   14    1  119\r\n   580  338  785  739  855  200   37    1    3    4    5    6]` ie we see 0 occurs 0 times , 1 occurs 2 times and so on .\r\n\r\nCurrently what we are getting is `tf.Tensor([[0. 4. 2. ... 0. 0. 0.]], shape=(1, 10000), dtype=float32)` we want of shape (2,10000)\r\n\r\nThe Code we are trying is \r\n\r\n````\r\nimport tensorflow as tf\r\n\r\ntf.enable_eager_execution()\r\n\r\n\r\ndef get_count(feature, vocab_size):\r\n  t1d = tf.reshape(feature, shape=(-1,))\r\n  unique_ids = tf.unique_with_counts(tf.sort(t1d))\r\n  #print(\" -------- unique_ids --------\")\r\n  #print(unique_ids)\r\n\r\n  dense_vector = tf.sparse_to_dense(unique_ids.y, [vocab_size], tf.to_float(unique_ids.count))\r\n  #print(\" -------- dense_vector --------\")\r\n  #print(dense_vector)\r\n\r\n  feature_batch = tf.reshape(dense_vector, [1, vocab_size])\r\n  #print(\" --- vocab count feature ---\")\r\n  #print(feature_batch)\r\n\r\n  return feature_batch\r\n\r\n\r\na=tf.constant([[1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6],\r\n [1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6]])\r\nprint(get_count(a,10000))\r\n````\r\n\r\n\r\nPlease tell us the right TF API transformation to do this . \r\n", "comments": ["any update on this ? @Saduf2019 ", "cc @mdanatg ", "@17patelumang \r\nI ran the code shared but face a different issue, please find [gist here](https://colab.research.google.com/gist/Saduf2019/6f99f4c8818d62281cde0083a04e722b/untitled372.ipynb), can you please share a colab gist with the error reported if possible.", "@Saduf2019  its the same issue , here its giving tensor of shape (1,10000) , it should of shape (2,10000) with above logic , kindly advice . thanks ", "@17patelumang I have updated the `output_shape` in `tf.sparse_to_dense`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/305a8451544eb0bd50ac13be8c1205cd/untitled372.ipynb). Thanks!", "@jvishnuvardhan  thank you for reply , however when we run the code below (its same code as in git) with `tf.enable_eager_execution()` it gives below error . We should be able to run it with both eager execution on and off both . Also wiithout eager execution enables there is no way to validate if logic is what we need , \r\n\r\n```\r\nnstructions for updating:\r\nUse `tf.cast` instead.\r\nWARNING:tensorflow:From liner_model_feature.py:11: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nTraceback (most recent call last):\r\n  File \"liner_model_feature.py\", line 18, in <module>\r\n    print(get_count(a,10000))\r\n  File \"liner_model_feature.py\", line 11, in get_count\r\n    dense_vector = tf.sparse_to_dense(unique_ids.y, [num_rows,vocab_size], tf.to_float(unique_ids.count))\r\n  File \"<path>/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"<path>/lib/python3.7/site-packages/tensorflow_core/python/ops/sparse_ops.py\", line 1066, in sparse_to_dense\r\n    name=name)\r\n  File \"<path>/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_sparse_ops.py\", line 3164, in sparse_to_dense\r\n    validate_indices=validate_indices, name=name, ctx=_ctx)\r\n  File \"<path>/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_sparse_ops.py\", line 3216, in sparse_to_dense_eager_fallback\r\n    attrs=_attrs, ctx=_ctx, name=name)\r\n  File \"<path>/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: output_shape has incorrect number of elements: 2 should be: 1 [Op:SparseToDense]\r\n```\r\n\r\n\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\n\r\ntf.enable_eager_execution()\r\n\r\n\r\ndef get_count(feature, vocab_size):\r\n\tt1d = tf.reshape(feature, shape=(-1,))\r\n\tunique_ids = tf.unique_with_counts(tf.sort(t1d))\r\n\tnum_rows=feature.shape[0]\r\n\r\n\tdense_vector = tf.sparse_to_dense(unique_ids.y, [num_rows,vocab_size], tf.to_float(unique_ids.count))\r\n\tfeature_batch = tf.reshape(dense_vector, [2, vocab_size])\r\n\treturn feature_batch\r\n\r\n\r\na=tf.constant([[1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6],\r\n [1296,266,504,190,44,60,13,2,337,6742,2667,14,1,119,580,338,785,739,855,200,37,1,3,4,5,6]])\r\nprint(get_count(a,10000))\r\n```", "@17patelumang This issues is not a Bug or performance issue. GitHub is mainly for bug/performance related. This issue is more suited to Stackoverflow. \r\n\r\nThere is no issue with `tf.enable_eager_execution()`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/7ed437d4a376ab15aef9af02f1ad9bff/untitled6.ipynb)\r\n\r\nThe tensor `t1d` is 1-dimensional and hence `unique_ids` is also same dimension. When you use 1-D in `tf.sparse_to_dense` you are getting 1-D output. \r\n\r\nPlease post it in Stackoverflow where community supports this kind of support question. Thanks!", "@jvishnuvardhan sorry i am not on the same page , why its not bug ? , why disabling `tf.enable_eager_execution()` doesnot throw error and gives `Tensor(\"Reshape_1:0\", shape=(2, 10000), dtype=float32)` as output but enabling `tf.enable_eager_execution()` throws error ? (Please kindly explain)", "@jvishnuvardhan  Please kindly advice . Thanks . ", "@mdanatg  can you please advice ?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42374\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42374\">No</a>\n", "This is for others who read this ticket , we used recently released https://blog.tensorflow.org/2020/08/introducing-tensorflow-coder-tool.html?linkId=98162087&m=1  and found our fix , super nice tool ! "]}, {"number": 42373, "title": "[TFLite 16x8] ADD/SUB operators: fixes + tests for versioning", "body": "In this PR:\r\n- tests for versioning of operators ADD/SUB\r\n- some fixes: \r\n       maximum version of ADD has been changed to 3 for 16x8, so I updated places, where it is mentioned as 4\r\n       both inputs for SUB operator should be quantized to int16 as for it is done for ADD\r\n- as discussed: only general case of reference kernel for 16x8 SUB/ADD will be used for the new models\r\nIt has been suggested to modify quantize_model.cc file and set option pot_scale_int16 to false during quantization - implementation is done this way.", "comments": ["@wwwind Can you please take a look on the above comment from @akarmi. Thanks!"]}, {"number": 42372, "title": "ImportError: DLL load failed: The specified module could not be found - while importing tensorflow ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tensorflow\r\n- TensorFlow version:2.2\r\n- Python version: checked 3.6,3.7,3.8\r\n- Installed using virtualenv? pip? conda?: both pip and conda\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: AMD Radeon(TM) Vega 8 Graphics\r\n\r\n\r\n\r\n**Describe the problem**\r\nfacing the problem of module not found while loding DLL when importing tensorflow.\r\nTried with multiple options like python version, tensorflow versions etc.\r\n\r\nis tesnorflow also supports ADM graphic drivers ?\r\n![Tensorflow issue](https://user-images.githubusercontent.com/37170486/90266971-7a6fb280-de72-11ea-86d3-d100f24ce971.png)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nimport tensorflow as tf\r\n\r\n**Any other info / logs**\r\n\r\nimport tensorflow\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-1-d6579f534729>\", line 1, in <module>\r\n    import tensorflow\r\n\r\n  File \"C:\\Users\\SaiKoushik\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n\r\n  File \"C:\\Users\\SaiKoushik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n\r\n  File \"C:\\Users\\SaiKoushik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n\r\n  File \"C:\\Users\\SaiKoushik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n\r\n  File \"C:\\Users\\SaiKoushik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\SaiKoushik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["@sparachi1011 \r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the latest [microsoft visual c++ redistributable from here.](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\n.Also, please follow the instructions from to install from [Tensorflow](https://www.tensorflow.org/install/source_windows) website.\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Please, refer similar issues #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "hi @Saduf2019 ,\r\nWhat is make/model of your cpu: Dell Inspiron 15 5000 series,\r\nI suspect your cpu model does not support AVX instructions sets:: it support, its a AMD Ryzen 5 series(latest version from AMD family)\r\nMake sure to download the latest microsoft visual c++:: yes i have installed MS Visual 2019. \r\n\r\nI can able to install tensorflow 1.15 and keras 2.0 but unable to use the upgraded versions.\r\nPlease, check Your CPU/Python is on 32 bits?:: python in on 64bits.\r\n\r\n![processor details ](https://user-images.githubusercontent.com/37170486/90385693-1bdc4b80-e0a1-11ea-9f61-bd3ea4d278cb.png)\r\n![VS 2019](https://user-images.githubusercontent.com/37170486/90385698-1d0d7880-e0a1-11ea-9d8b-b810ef3e96d4.png)\r\n\r\n", "@sparachi1011 Few questions.\r\n1) did you notice the issue when you installed in `virtualenv`?\r\n2) were you able to install and import TF1.15 without any issue?\r\n\r\nCan you please uninstall TF all versions, uninstall python all versions, restart comp/laptop, install python 3.7, install TF2.3 and then check whether you can import without any issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42372\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42372\">No</a>\n"]}, {"number": 42371, "title": "No difference in time for Conv1DTranspose before and after post training quantization", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu19.04 Linux\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (or github SHA if from source):  2.4.0-dev20200715\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n```\r\nclass TFConvTranspose1d(tf.keras.Model):\r\n\r\n    def __init__(self, channels, ksize, stride, padding):\r\n        super(TFConvTranspose1d, self).__init__()\r\n        self.conv1d_transpose = tf.keras.layers.Conv2DTranspose(\r\n            filters = channels,\r\n            kernel_size = (ksize, 1),\r\n            strides = (stride, 1),\r\n            padding = \"same\",\r\n        )\r\n\r\n    def call(self, x):\r\n#         x = tf.expand_dims(x, axis=2)\r\n        \r\n#         print(\" CONV TRANSPOSE 1D \", x.shape)\r\n        x = self.conv1d_transpose(x)\r\n#         print(\" CONV TRANSPOSE 1D \", x.shape)\r\n#         x = tf.squeeze(x, axis=2)\r\n        return x\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\ncheckModel = TFConvTranspose1d(256, 16, 8, \"same\")\r\ninput_shape = (1, 100,1,  512)\r\ncheckModel.build(input_shape)\r\n\r\nx = np.random.rand(1, 100,1,  512)\r\nx = x.astype('float32')\r\n\r\nout = checkModel.predict(x)\r\nprint( \"KERAS OUTPUT : \", out.shape)\r\n\r\nprint(\" Number of Params : \", checkModel.count_params())\r\n\r\ntflite_converter = tf.lite.TFLiteConverter.from_keras_model(checkModel)\r\ntflite_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_converter.allow_custom_ops = True\r\ntflite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_converter.post_training_quantize = True\r\ntfmodel = tflite_converter.convert()\r\n\r\nopen(\"convTranspose.tflite\", \"wb\").write(tfmodel)\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n-  No difference in time in Raspberry PI before and after quantization\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n", "comments": ["Hi,\r\n\r\nFew notes:\r\n1) You don't need \"tf.lite.OpsSet.SELECT_TF_OPS\"\r\n2) You don't need allow_custom_ops = True\r\n3) You don't need \"post_training_quantize = True\" it is deprecated you should be using tflite_converter.optimizations = [tf.lite.Optimize.DEFAULT] instead.\r\n\r\nNow for your model,\r\nSetting optimization only without providing representative dataset like this \"tflite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\"\r\nwill enable only dynamic quantization, which will quantization for weights and activations only if possible.\r\n\r\nSee the instructions here\r\nhttps://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization\r\n\r\nThanks\r\n", "@karimnosseir  Thanks, for those points,  will try full integer quantization  with some dataset.", "You're welcome.\r\nClosing the issue. Please feel free to reopen or create new issue if needed.\r\n\r\nThanks"]}, {"number": 42369, "title": "Fast row by row multiplication method", "body": "So I have a vector dimension X, and a 2D array of dimensions X,Y. I need to multiply each row in the 2D array by the numbers in the vector. So technically you need to construct an identity matrix with diagonal made of the vector components, then matmul by the 2D array. But where speed is critical constructing a matrix just to perform such an operation is too expensive. Is there any smart way to do this using one of the functions of tensorflow?", "comments": ["oh, it seems like you can do that with a reshape (add an extra dimension at the end of the vector) and then tf.math.multiply\r\ntf.math.multiply(tf.expand_dims(Vector, -1), Matrix)"]}]