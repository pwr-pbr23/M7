[{"number": 28018, "title": "AttributeError: 'PerReplica' object has no attribute 'begin'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): b'unknown' 1.13.1 (installed with conda)\r\n- Python version: Python 3.6.8 :: Anaconda, Inc.\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda/9.0.176, cudnn/7.3\r\n- GPU model and memory: Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15190 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)\r\n2019-04-21 19:03:25.539522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15190 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:87:00.0, compute capability: 6.0)\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nWhen running `tf.estimator.Estimator` model that registers `tf.train.SessionRunHook` to `evaluation_hooks` of `tf.estimator.EstimatorSpec` in distributed environment, an error `AttributeError: 'PerReplica' object has no attribute 'begin'` occurs at the beggining of evaluation. This error does not happen if I do not register SessionRunHook to evaluation_hooks. Registering SessionRunHook to `training_hooks` does not trigger the error even if it is in distributed mode.\r\n\r\nI ran my Estimator with `tf.estimator.train_and_evaluate`.\r\n\r\nThe distribution configuration I used is `tf.contrib.distribute.MirroredStrategy`.\r\n\r\nThe whole error log is attatched at the end.\r\n\r\n**Describe the expected behavior**\r\n\r\nSomehow SessionRunHook turned into PerReplica at some point in evaluation code of Estimator. It should remain SessionRunHook's interface in distribution mode.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThis is not a runnable code, but introducing the modification below to some estimator examples might work as a reproducer.\r\n\r\n```\r\ndistribution = tf.contrib.distribute.MirroredStrategy()\r\nrun_config = tf.estimator.RunConfig(train_distribute=distribution,\r\n                                                           eval_distribute=distribution)\r\n\r\nhook = tf.train.ProfilerHook(output_dir=model_dir)  # example hook\r\ndef model_fn(features, labels, mode, params):\r\n            if mode == tf.estimator.ModeKeys.EVAL:\r\n                return tf.estimator.EstimatorSpec(mode, loss,\r\n                                                      evaluation_hooks=[hook])\r\n\r\nestimator = tf.estimator.Estimator(params, model_dir, run_config)\r\n\r\ntf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n```\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nINFO:tensorflow:Calling model_fn.\r\nWARNING:tensorflow:Efficient allreduce is not supported for IndexedSlices.\r\nWARNING:tensorflow:Efficient allreduce is not supported for IndexedSlices.\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n2019-04-21 18:41:17.901359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0, 1\r\n2019-04-21 18:41:17.901414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-04-21 18:41:17.901425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 1 \r\n2019-04-21 18:41:17.901432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N Y \r\n2019-04-21 18:41:17.901439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   Y N \r\n2019-04-21 18:41:17.902038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15190 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)\r\n2019-04-21 18:41:17.902219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15190 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:87:00.0, compute capability: 6.0)\r\nWARNING:tensorflow:From /home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nINFO:tensorflow:Restoring parameters from /tmp/model.ckpt-0\r\nWARNING:tensorflow:From /home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file utilities to get mtimes.\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/model.ckpt.\r\nINFO:tensorflow:Initialize strategy\r\n2019-04-21 18:42:04.023667: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\r\n2019-04-21 18:42:05.162460: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x555559b95370\r\n2019-04-21 18:42:05.970327: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x555559ba9960\r\nINFO:tensorflow:loss = 52170.477, step = 0\r\nINFO:tensorflow:global_step/sec: 0.0334123\r\nINFO:tensorflow:loss = 54870.64, step = 1 (29.929 sec)\r\nINFO:tensorflow:Saving checkpoints for 3 into /tmp/model.ckpt.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Starting evaluation at 2019-04-21T09:43:02Z\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 146, in <module>\r\n    main()\r\n  File \"train.py\", line 142, in main\r\n    use_multi_gpu)\r\n  File \"train.py\", line 83, in train_and_evaluate\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\r\n    return self.run_local()\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1122, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1185, in _train_model_distributed\r\n    self._config._train_distribute, input_fn, hooks, saving_listeners)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1287, in _actual_train_model_distributed\r\n    saving_listeners)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1270, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\r\n    run_metadata=run_metadata))\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\r\n    if self._save(run_context.session, global_step):\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\r\n    if l.after_save(session, step):\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\r\n    self._evaluator.evaluate_and_export())\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\r\n    name=name)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 509, in _actual_eval\r\n    return _evaluate()\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\r\n    output_dir=self.eval_dir(name))\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\r\n    config=self._session_config)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/evaluation.py\", line 271, in _evaluate_once\r\n    session_creator=session_creator, hooks=hooks) as session:\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 934, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 636, in __init__\r\n    h.begin()\r\nAttributeError: 'PerReplica' object has no attribute 'begin'\r\n```\r\n", "comments": ["I am also experiencing this. Any update @tanzhenyu? ", "Can you try using tf.distribute.???Strategy, instead of tf.contrib.distribute.???Strategy and see if it fixed it?", "@tanzhenyu I'm using tf.distribute (not tf.contrib.distribute) and I still see the error. Error disappears when all evaluation hooks are removed, same as original post.", "@tanzhenyu any update on this? Still broken for me on TF nightly as well.", "@isaprykin mind taking a look?", "@ymodak Could you please mirror this internally as per comp:dist-strat?", "I am also experiencing this on latest tf 1.14", "We are experiencing same. Is there an ETA on a fix?", "I have this same issue with tf.distribute.experimental.MultiWorkerMirroredStrategy", "I apologize in advance ... @tanzhenyu assigned @isaprykin on Aug 9 2019. Just wondering if this is being actively looked at.", "Well what fixed it for me was to remove distribution strategy from\r\n`run_config = tf.estimator.RunConfig(train_distribute=distribution,\r\n                                                           eval_distribute=distribution)`\r\nLike:\r\n`run_config = tf.estimator.RunConfig(train_distribute=distribution,\r\n                                                           eval_distribute=None)`\r\nI have to mention that i talk about \r\n`distribution = tf.distribute.MirroredStrategy()`\r\n", "@medphysicsliv that makes things run without crashing, yes, but it results in none of my evaluation hooks seemingly doing anything in the multi-node setting. Is there any working way to get multi-worker evaluation hooks currently?", "Any update on this? It would be great to be able to use evaluation hooks in a distributed setting.", "[This line](https://github.com/tensorflow/estimator/blob/168aa7e06125a564d32e3a7a85a4f9e241c6f51b/tensorflow_estimator/python/estimator/estimator.py#L1619) returns a `PerReplica` object and assigns it to `evaluation_hooks`. If we replace the line with:\r\n\r\n```\r\nevaluation_hooks = self._eval_distribution.unwrap(grouped_estimator_spec.evaluation_hooks)[0][0]._values\r\n```\r\nthen the evaluation hooks can be run. However, they need to already work well with multiple GPUs otherwise the results will be wrong. I am not sure if this would introduce bugs in any other places.", "I think what we need to do is handle list of per-replica hooks correctly. Current code assumes that the grouped_estimator_spec.evaluation_hooks is one PerReplica hook - but it's actually a list. We need to handle them correctly as the training_hooks [1]\r\n\r\nWe would be happy to take a contribution to fix this if someone in this thread wants to do that? \r\n\r\n[1] https://github.com/tensorflow/estimator/blob/6915557cef8bfc86f29f87e4467d601e4553b957/tensorflow_estimator/python/estimator/estimator.py#L1336", "This has been fixed (https://github.com/tensorflow/estimator/commit/131f54a62ae9ded9057aeb0eb1243d9516373b14). Please test with TF nightly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28018\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28018\">No</a>\n", "I've confirmed this works for a single-machine with 8 V100 GPUs and MirroredStrategy. Thanks so much!\r\n\r\nIs this also expected to work for MultiWorkerMirroredStrategy?", "Yes this part should work with MultiWorkerMirroredStrategy too.\n\nOn Wed, Jun 17, 2020 at 1:02 PM Brandon McKinzie <notifications@github.com>\nwrote:\n\n> I've confirmed this works for a single-machine with 8 V100 GPUs and\n> MirroredStrategy. Thanks so much!\n>\n> Is this also expected to work for MultiWorkerMirroredStrategy?\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/28018#issuecomment-645593241>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ADLTSF7YNWJE2X4W7P5ROB3RXEOMTANCNFSM4HHLNFPQ>\n> .\n>\n"]}, {"number": 28017, "title": "Stream image build logs in dockerfile assembler system", "body": "This change enables streaming image build logs when using `assembler.py` by using the lower level docker APIClient and manually handling the returned log stream.\r\n\r\nThis change is useful for modifications on dockerfiles, since behavior can be inspected before a build is finished.", "comments": ["This looks pretty cool. Thanks!", "@xiamaz I got an error with `asm_images --release nightly --build_images`:\r\n\r\n```\r\nAfter this operation, 905 kB of additional disk space will be used.\r\nErr:1 http://security.ubuntu.com/ubuntu xenial-security/main amd64 wget amd64 1.17.1-1ubuntu1.4                                                                                     \r\n  404  Not Found [IP: 91.189.88.162 80]\r\nErr:1 http://security.ubuntu.com/ubuntu xenial-security/main amd64 wget amd64 1.17.1-1ubuntu1.4                                                                                     \r\n  404  Not Found [IP: 91.189.88.162 80]\r\nE: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/w/wget/wget_1.17.1-1ubuntu1.4_amd64.deb  404  Not Found [IP: 91.189.88.162 80]                                       \r\n\r\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\r\nDocker image build complete.\r\nTraceback (most recent call last):\r\n  File \"assembler.py\", line 719, in <module>\r\n    app.run(main)\r\n  File \"/usr/local/lib/python3.5/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"assembler.py\", line 619, in main\r\n    if image_id:\r\nUnboundLocalError: local variable 'image_id' referenced before assignment\r\n```\r\n\r\nIt seems like this can fail improperly when a build failure happens. Can you take a look?", "@rthadur can you revert the state of this PR to \"awaiting review\"?", "@angersson Thanks. Failed image builds should be correctly handled now.", "This has been merged (see above), but I guess GitHub got confused. Closing. Thanks for your contribution!"]}, {"number": 28016, "title": "Added 8-bit Quantization support for Relu.", "body": "Added uint8 and int8 Quantization support for Relu.", "comments": ["Closing the duplicate one"]}, {"number": 28015, "title": "#28014 [TF 2.0] the word2vec_basic.py example is not 2.0.0-alpha0.", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28015) for more info**.\n\n<!-- need_sender_cla -->", "Already registered CLA", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28015) for more info**.\n\n<!-- ok -->", "Please find appropriate owner to review tutorial code. \r\n\r\nI read the code briefly, and not convinced the code style is consistent with others. But I might be wrong.", "@dynamicwebpaige \r\nOk, then I will open an issue again, thank you."]}, {"number": 28014, "title": "[TF 2.0] the word2vec_basic.py example is not 2.0.0-alpha0.", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": []}, {"number": 28013, "title": "[TF 2.0] tf.assert_equal funtion raise exception InternalError with unsigned 16, 32, 64", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab.google.com (linux)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not test\r\n- TensorFlow installed from (source or binary): binary (nighty)\r\n- TensorFlow version (use command below): 2.0.0-dev20190420\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: NVIDIA-SMI 418.56 Driver Version: 410.79 CUDA Version: 10.0\r\n- GPU model and memory: Tesla T4\r\n\r\n**Describe the current behavior**\r\nAs documented function [assert_equal](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/debugging/assert_equal) accept any dtype. But it raises an exception InternalError with type: uint16, 32, 64. Test with CPU and GPU.\r\n**Describe the expected behavior**\r\nNot raises an exception InternalError with type: uint16, 32, 64.\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import bitwise_ops\r\nfrom tensorflow.python.framework import dtypes\r\nprint(tf.__version__)\r\n# tf.uint16, tf.uint32, tf.uint64\r\nlhs = tf.constant([5, 0, 7, 11], dtype=tf.uint16)\r\nrhs = tf.constant([5, 0, 7, 11], dtype=tf.uint16)\r\ntf.assert_equal(lhs, rhs)\r\n```\r\nmay be same other asser functions: raise exception with assert_greater \r\n```python\r\nlhs = tf.constant([7], dtype=tf.uint16)\r\nrhs = tf.constant([9], dtype=tf.uint16)\r\ntf.assert_greater(lhs, rhs)\r\n```\r\n**Other info / logs**\r\n<details><summary>LOGS</summary>\r\n<p>\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nInternalError                             Traceback (most recent call last)\r\n<ipython-input-17-b706d33af3c8> in <module>()\r\n     10   exp = tf.constant([0, 0, 3, 10], dtype=dtype)\r\n     11   res = bitwise_ops.bitwise_and(lhs, rhs)\r\n---> 12   tf.assert_equal(res, exp) # TRUE\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/check_ops.py in assert_equal_v2(x, y, message, summarize, name)\r\n    452       execution or if `x` and `y` are statically known.\r\n    453   \"\"\"\r\n--> 454   return assert_equal(x=x, y=y, summarize=summarize, message=message, name=name)\r\n    455 \r\n    456 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/check_ops.py in assert_equal(x, y, data, summarize, message, name)\r\n    496 \r\n    497     if context.executing_eagerly():\r\n--> 498       eq = math_ops.equal(x, y)\r\n    499       condition = math_ops.reduce_all(eq)\r\n    500       if not condition:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py in equal(x, y, name)\r\n   3449       else:\r\n   3450         message = e.message\r\n-> 3451       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n   3452   # Add nodes to the TensorFlow graph.\r\n   3453   try:\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInternalError: Could not find valid device for node.\r\nNode: {{node Equal}}\r\nAll kernels registered for op Equal :\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]\r\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_HALF]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]\r\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_HALF]\r\n  device='CPU'; T in [DT_BOOL]\r\n  device='CPU'; T in [DT_STRING]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_INT64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_BFLOAT16]\r\n  device='CPU'; T in [DT_INT16]\r\n  device='CPU'; T in [DT_INT8]\r\n  device='CPU'; T in [DT_UINT8]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_BOOL]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_INT16]\r\n  device='GPU'; T in [DT_INT8]\r\n  device='GPU'; T in [DT_INT32]\r\n  device='GPU'; T in [DT_UINT8]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n [Op:Equal]\r\n```\r\n</p>\r\n</details>", "comments": ["Thanks for trying TF 2.0 alpha. I was able to reproduce the behavior. Looks like data types uint16, uint32 and uint64 are not registered ops however data type uint8 was successful. ", "The uint dtypes are only supported in the xla backend.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28013\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28013\">No</a>\n", "We should either add the kernel registration for these types or adjust the docs to match.", "@martinwicke we currently have ~no kernels registered for these types. Adding ~all kernels for these types would be quite a binary size hit. We should instead document somewhere that these types are not supported outside XLA.", "Fair enough -- where to put such a notice? It's a general thing that I expect over time will change.\r\n\r\n@lamberta do you have an idea?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28013\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28013\">No</a>\n"]}, {"number": 28012, "title": "Annotating negative class in object detection (Faster R-CNN)", "body": "I am currently training Faster R-CNN on some data and try to build a detector based on our data.\r\nSince my data set has some images without the object of interest in it.\r\nHow do I annotate them? (i.e., what will be the bounding box for these images)\r\nAlso, does annotating the negative class improve the training? \r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.Thanks!\r\n"]}, {"number": 28011, "title": "[tflite] enable using the new NNAPI delegate in Java", "body": "1. add a wrapper for NNAPI delegate can be accessed in Java\r\n2. modify the demo app to use it\r\n\r\nenable using the new NNAPI delegate in Java so that we can avoid situation described in https://github.com/tensorflow/tensorflow/issues/27983", "comments": []}, {"number": 28010, "title": "[TF2.0] Not JSON Serializable error wasn thrown when using tf.keras.activations operators in keras model.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 1809\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): tensorflow-gpu 2.0.0a0\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: Geforce 1070\r\n\r\n**Describe the current behavior**\r\nWhen I used tf.keras.activations operators in my keras model, serialization of model was failed due to Not JSON Serializable error.\r\n\r\n**Describe the expected behavior**\r\nIt should be serialized without any error.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\ninputs = keras.Input(shape=(784,), name='digits')\r\nx = layers.Activation('relu')(inputs)\r\n# x = keras.activations.relu(inputs)\r\noutputs = layers.Dense(10, activation='softmax', name='predictions')(x)\r\n\r\n\r\nmodel = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')\r\nmodel.summary()\r\n\r\nmodel.save('path_to_my_model.h5')\r\n```\r\nIf you changed from Activation() to relu, it failed to serialize.", "comments": ["I have slightly edited your code to be consistent with ``` tf.keras``` and was able to reproduce the error using TF-gpu 2.0 alpha.\r\n```python\r\nimport tensorflow as tf\r\n#from tensorflow import keras\r\n#from tensorflow.keras import layers\r\n\r\ninputs = tf.keras.Input(shape=(784,), name='digits')\r\n#x = tf.keras.layers.Activation('relu')(inputs)\r\nx = tf.keras.activations.relu(inputs)\r\noutputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)\r\n\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')\r\nmodel.summary()\r\n\r\nmodel.save('path_to_my_model.h5')\r\n```\r\nOutput:\r\n```python\r\n---> 13 model.save('path_to_my_model.h5')\r\nTypeError: ('Not JSON Serializable:', b'\\n\\x06Relu_8\\x12\\x04Relu\\x1a\\tdigits_25*\\x07\\n\\x01T\\x12\\x020\\x01')\r\n```", "I got the same error, but with:\r\n\r\n* tf.keras.backend.expand_dims\r\n* tf.keras.backend.squeeze\r\n* tf.expand_dims\r\n* tf.squeeze\r\n\r\nreturns:\r\n\r\n`W0501 00:06:16.129765 139790005454464 tf_logging.py:161] Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', b'\\n\\nExpandDims\\x12\\nExpandDims\\x1a\\x05input\\x1a\\x0eExpandDims/dim*\\x07\\n\\x01T\\x12\\x020\\x01*\\n\\n\\x04Tdim\\x12\\x020\\x03')`", "Additionally, using \"+\" operator instead of tf.keras.layers.Add makes this issue same.", "I am facing the same issue, any suggestions or solutions for work around for now ??", "I am having the same issue when using tf.concat in an otherwise keras-only model (can't use keras Concatenations due to issue #30355 ).\r\n\r\nOnly work around I have found so far is to use model.save_weights(). When loading, you need to redefine the model and then use model.load_weights()", "Having same issue with TF 1.14 and Python 3.6 with `tf.transpose` and `tensorflow.python.keras.layers.concatenate` :\r\n\r\n`W0717 09:24:35.629342 14908 summary_ops_v2.py:1110] Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', b'\\n\\ttranspose\\x12\\tTranspose\\x1a\\ndense/Relu\\x1a\\x0etranspose/perm*\\x0b\\n\\x05Tperm\\x12\\x020\\x03*\\x07\\n\\x01T\\x12\\x020\\x01')`\r\n\r\n`W0717 13:56:19.515430 16984 summary_ops_v2.py:1110] Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', b'\\n\\x05Shape\\x12\\x05Shape\\x1a\\x15concatenate_28/concat*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x08out_type\\x12\\x020\\x03')`\r\n\r\nThus `callbacks.ModelCheckpoint` with `save_weights_only=False` causes the training to stop because it fails to backup the model (I get a useless model file of 6 KB).\r\nAs @mketcha mentionned, a workaround is to use `save_weights_only=True`. But it should only be temporary waiting a fix because saving only the weights forces to keep the code of the corresponding model somewhere and this is really annoying if the model code changes often.", "Same problem here. Is this being worked on?\r\n\r\n```\r\n Model failed to serialize as JSON. Ignoring...\r\n('Not JSON Serializable:',\r\nb'\\n\\tLeakyRelu\\x12\\tLeakyRelu\\x1a\\x1cbatch_normalization/Identity*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x05alpha\\x12\\x05%\\xcd\\xccL>')\r\n```\r\n\r\nTensorFlow 2.0.0-b1", "Was able to repro and have a fix out for this, should be in in a day or two", "Hello,\r\nAny news? Thanks", "> Hello,\r\n> Any news? Thanks\r\n\r\nShould be fixed: https://github.com/tensorflow/tensorflow/commit/7cc180f107f142432358ac33787466de90afd776", "Closing this issue since its fixed in latest tf nightly build '2.0.0-dev20190802'\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28010\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28010\">No</a>\n", "Had the problem `callbacks.ModelCheckpoint` and `ModelCheckpoint`, setting `save_weights_only=True` solved the problem for me. ", "> Had the problem `callbacks.ModelCheckpoint` and `ModelCheckpoint`, setting `save_weights_only=True` solved the problem for me.\r\n\r\n@yassinetb Did you have any solution for the error \"TypeError: ('Not JSON Serializable:', tf.float32)\" from setting save_weights_only=False\r\n", "I am facing the same issue using tf.keras.callbacks.ModelCheckpoint . Any solution ?"]}, {"number": 28009, "title": "Transformer network weights - demo error ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): tf-nightly-gpu-2.0-preview\r\n- TensorFlow version (use command below): 2.0.0-dev20190420\r\n- Python version: 3\r\n- Bazel version (if compiling from source): Colab\r\n- GCC/Compiler version (if compiling from source): Colab\r\n- CUDA/cuDNN version: Colab\r\n- GPU model and memory: Colab\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nI have been trying the demos of tensorflow 2.0, particularly the transformers example. However, the current transformer example is not working anymore. This is the error output: \r\n\r\nValueError: Weights for model sequential_3 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.\r\n\r\nSeems like the latest tensorflow version 2.0.0-dev20190420 has changed a way how to call the inputs or set the weights. \r\n\r\nIt was working with the tf version 2.0.0-dev20190413. \r\nIn conclusion the transformer demo is not working anymore, is there any way to get installed in colab the 2.0.0-dev20190413 version?\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nInstructions are here: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/text/transformer.ipynb#scrollTo=8QG9nueFQKXx\r\n\r\nI used the GPU version.\r\n\r\nI just ran the colab transformer notebook: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/text/transformer.ipynb#scrollTo=8QG9nueFQKXx\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I'm having the same problem.", "> I'm having the same problem.\r\n\r\nHi @cevrim, \r\n\r\nActually, we were able to fix the problem in the meantime by using the previous release of tensorflow, you just need to change the tf installation to this: \r\n\r\n!pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190413\r\n\r\nThis is something temporal, but, it would be good to know about those changes and how to address them. \r\n\r\nRegards\r\n", "Hi @umayuxlabs ,\r\n\r\nThank you for sharing your fix, I was trying to do the same thing.\r\n\r\nRegards", "@umayuxlabs : Thank you for your support.\r\n@cevrim : Were you able to resolve ?", "@achandraa Yes, it's resolved.", "Closing the issue since it is resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28009\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28009\">No</a>\n", "I'm having the same problem ! @achandraa \r\nI write a layer with the APIs of tf.nn. When using the layer together with other written layers, such as tf.keras.layers. Dense, I got the error \"ValueError: Weights for model sequential_3 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.\" However, the layer works well seperately.\r\nHere is my layer.\r\n**\r\n`class cov(layers.Layer):\r\n  def __init__(self, filters_width = (3,), \r\n              strides = 1,  \r\n              padding = 'VALID', \r\n              dilations = None, **kwargs):\r\n    super(cov, self).__init__(**kwargs)\r\n    self.filters_width = filters_width\r\n    self.strides = strides\r\n    self.padding = padding\r\n    self.dilations = dilations\r\n\r\n  def build(self, input_shape):\r\n    \r\n    self.filters = self.add_weight(shape=self.filters_width+(input_shape[-1], input_shape[-1]),\r\n                        initializer='random_normal',\r\n                        trainable=True) \r\n  def call(self, inputs):\r\n    output = tf.nn.convolution(\r\n        input = inputs,\r\n        filters = self.filters,\r\n        strides = self.strides,\r\n        padding = self.padding,\r\n        data_format = None,\r\n        dilations = self.dilations,\r\n        name = 'cov'\r\n    )\r\n\r\n    return output`\r\n**"]}, {"number": 28008, "title": "Cannot Make TfRecords Work for Image-sentence Pairs", "body": "Hi,\r\n\r\nI am stuck on making tfrecords work for image-text pair data.\r\n\r\nHere is the code to create tfrecord from numpy array of image features and a text file,\r\n\r\n```\r\ndef npy_to_tfrecords(numpy_array, text_file, output_file):\r\n      f = open(text_file)\r\n\r\n      # write records to a tfrecords file\r\n      writer = tf.python_io.TFRecordWriter(output_file)\r\n\r\n      # Loop through all the features you want to write\r\n      for X, line in zip(numpy_array, f) :\r\n         #let say X is of np.array([[...][...]])\r\n         #let say y is of np.array[[0/1]]\r\n\r\n         txt = \"{}\".format(line[:-1])\r\n         txt = txt.encode()\r\n\r\n         # Feature contains a map of string to feature proto objects\r\n         feature = {}\r\n         feature['x'] = tf.train.Feature(float_list=tf.train.FloatList(value=X.flatten()))\r\n         feature['y'] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[txt]))\r\n\r\n         # Construct the Example proto object\r\n         example = tf.train.Example(features=tf.train.Features(feature=feature))\r\n\r\n         # Serialize the example to a string\r\n         serialized = example.SerializeToString()\r\n\r\n         # write the serialized objec to the disk\r\n         writer.write(serialized)\r\n      writer.close()\r\n```\r\n\r\nI cannot make the dataset after this:\r\n```\r\n\r\ndef load_data_tfr():\r\n    \r\n   train = tf.data.TFRecordDataset(\"train.tfrecord\")\r\n\r\n   # example proto decode\r\n   def _parse_function1(example_proto):\r\n      keys_to_features = {'x': tf.FixedLenFeature(2048, tf.float32),\r\n                          'y': tf.VarLenFeature(tf.string) } \r\n      parsed_features = tf.parse_single_example(example_proto, keys_to_features)\r\n      return {\"x\": parsed_features['x'], \"y\":  parsed_features['y']} # ['x'], parsed_features['y']\r\n\r\n   # Parse the record into tensors.\r\n   train = train.map(_parse_function1)\r\n\r\n   return train\r\n```\r\n\r\n`train_data = load_data_tfr()`\r\n\r\nI keep . getting the error:\r\n\r\n```\r\nrandom.shuffle(train_data)\r\n\r\n    for i in reversed(range(1, len(x))):\r\nTypeError: object of type 'MapDataset' has no len()\r\n```\r\n\r\nAny help? thank you.", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@gadagashwini thanks for reply. could you share an example where image and text data was paired using tfrecord? I just want to pair text with some vector, i.e. one vector for each line of text.  I am on  linux, conda installed tensorflow gpu 1.16. ", "@nvidiaman This [link](https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/load_data/images.ipynb) may help you. Thanks!", "Hi, request you to post any support related questions in StackOverflow. We encourage users to post only bug/feature request here. If you think it is a bug/feature, please fill this template and open a new issue. Thank you !"]}, {"number": 28007, "title": "InvalidArgumentError when running map_fn on strings inside a tf.function", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n```bash\r\nconda install tensorflow-gpu==2.0-alpha\r\n```\r\n- Python version:\r\n3.7.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n  cudatoolkit-10.0.130-0                                                                                                  \r\n  cudnn-7.3.1-cuda10.0_0\r\n- GPU model and memory:\r\nGeForce RTX 2080 Ti\r\n\r\n**Describe the current behavior**\r\nRunning the provided code on GPUs leads to error message `tensorflow.python.framework.errors_impl.InvalidArgumentError: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string`\r\nWithout feeding the tensor to the convolution layer, `summary.image` would succeed.\r\n\r\n**Describe the expected behavior**\r\nShould run smoothly.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\n\r\nH, W, C = 10, 10, 3\r\nimgs = tf.zeros([10, H, W, C])\r\nds = tf.data.Dataset.from_tensor_slices(imgs)\r\nds = ds.batch(2)\r\nconv = layers.Conv2D(32, (4, 4), strides=(2, 2), padding='same')\r\n\r\n\r\n@tf.function\r\ndef run(img, i):\r\n    conv(img)\r\n    tf.summary.image('img', img, i)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    train_summary_writer = tf.summary.create_file_writer('/tmp/testsummary')\r\n    with train_summary_writer.as_default():\r\n        for i, img in enumerate(ds):\r\n            run(img, i)\r\n```\r\n\r\n**Other info / logs**\r\n```2019-04-20 14:44:30.775146: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this\r\nTensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-04-20 14:44:30.818841: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1700000000 Hz\r\n2019-04-20 14:44:30.819976: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55b6fa788f50 executing computa\r\ntions on platform Host. Devices:\r\n2019-04-20 14:44:30.820029: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <u\r\nndefined>\r\n2019-04-20 14:44:30.825689: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic li\r\nbrary libcuda.so.1\r\n2019-04-20 14:44:31.062487: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55b6fc634120 executing computa\r\ntions on platform CUDA. Devices:\r\n2019-04-20 14:44:31.062554: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): GeForce RTX 208\r\n0 Ti, Compute Capability 7.5\r\n2019-04-20 14:44:31.063894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties:\r\nname: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.635\r\npciBusID: 0000:19:00.0\r\ntotalMemory: 10.73GiB freeMemory: 10.57GiB\r\n2019-04-20 14:44:31.063942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0\r\n2019-04-20 14:44:31.064034: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic li\r\nbrary libcudart.so.10.0\r\n2019-04-20 14:44:31.067082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor wi\r\nth strength 1 edge matrix:\r\n2019-04-20 14:44:31.067114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0\r\n2019-04-20 14:44:31.067130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N\r\n2019-04-20 14:44:31.068283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:local\r\nhost/replica:0/task:0/device:GPU:0 with 10284 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id\r\n: 0000:19:00.0, compute capability: 7.5)\r\n2019-04-20 14:44:33.628228: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::Star\r\ntAbort Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n         [[{{node img_1/encode_each_image/while/body/_1/TensorArrayV2Write/TensorListSetItem/_54}}]]\r\n         [[img_1/encode_each_image/while/loop_body_control/_19/_33]]\r\n2019-04-20 14:44:33.628374: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::Star\r\ntAbort Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n         [[{{node img_1/encode_each_image/while/body/_1/TensorArrayV2Write/TensorListSetItem/_54}}]]\r\n2019-04-20 14:44:33.628468: E tensorflow/core/common_runtime/process_function_library_runtime.cc:764] Component function e\r\nxecution failed: Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n         [[{{node img_1/encode_each_image/while/body/_1/TensorArrayV2Write/TensorListSetItem/_54}}]]\r\n         [[img_1/encode_each_image/while/loop_body_control/_19/_33]]\r\n2019-04-20 14:44:33.628456: E tensorflow/core/common_runtime/process_function_library_runtime.cc:764] Component function e\r\nxecution failed: Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n         [[{{node img_1/encode_each_image/while/body/_1/TensorArrayV2Write/TensorListSetItem/_54}}]]\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 21, in <module>\r\n    run(img, i)\r\n  File \"/home/swang150/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/tensorflow/python/eager/def_function.\r\npy\", line 438, in __call__\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/swang150/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/tensorflow/python/eager/function.py\",\r\n line 1288, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/swang150/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/tensorflow/python/eager/function.py\",\r\n line 574, in _filtered_call\r\n    (t for t in nest.flatten((args, kwargs))\r\n  File \"/home/swang150/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/tensorflow/python/eager/function.py\",\r\n line 627, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"/home/swang150/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/tensorflow/python/eager/function.py\",\r\n line 415, in call\r\n    ctx=ctx)\r\n  File \"/home/swang150/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\",\r\nline 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: During Variant Host->Device Copy: non-DMA-copy attempted of\r\ntensor type: string\r\n         [[{{node img_1/encode_each_image/while/body/_1/TensorArrayV2Write/TensorListSetItem/_54}}]]\r\n         [[img_1/encode_each_image/while/loop_body_control/_19/_33]] [Op:__inference_run_343]\r\n```", "comments": ["@ipod825 I ran the code in Google colab without any error. Could you try with Google colab and see whether issue persists there. If it doesn't persist in Google colab, then try to upgrade your TF2.0 and run the code again. Thanks!\r\n\r\n```\r\n!pip install tensorflow==2.0.0-alpha0\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\n\r\nH, W, C = 10, 10, 3\r\nimgs = tf.zeros([10, H, W, C])\r\nds = tf.data.Dataset.from_tensor_slices(imgs)\r\nds = ds.batch(2)\r\nconv = layers.Conv2D(32, (4, 4), strides=(2, 2), padding='same')\r\n\r\n\r\n@tf.function\r\ndef run(img, i):\r\n    conv(img)\r\n    tf.summary.image('img', img, i)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    train_summary_writer = tf.summary.create_file_writer('/tmp/testsummary')\r\n    with train_summary_writer.as_default():\r\n        for i, img in enumerate(ds):\r\n            run(img, i)\r\n            print(i)\r\n```", "You need to run it on GPU.\r\n\r\n```python\r\n!pip install tensorflow-gpu==2.0.0-alpha0\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\n\r\nH, W, C = 10, 10, 3\r\nimgs = tf.zeros([10, H, W, C])\r\nds = tf.data.Dataset.from_tensor_slices(imgs)\r\nds = ds.batch(2)\r\nconv = layers.Conv2D(32, (4, 4), strides=(2, 2), padding='same')\r\n\r\n\r\n@tf.function\r\ndef run(img, i):\r\n    conv(img)\r\n    tf.summary.image('img', img, i)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    train_summary_writer = tf.summary.create_file_writer('/tmp/testsummary')\r\n    with tf.device('/gpu:0'):\r\n      with train_summary_writer.as_default():\r\n          for i, img in enumerate(ds):\r\n              run(img, i)\r\n              print(i)\r\n```", "sorry about my poor English.  I have the same problem.But I found a solution.\r\nI'm using Nvidia 2080Ti , tf-nightly-gpu-2.0-preview. python3.7.3 ,ubuntu 19.04\r\nWhen I used tf.summary.image(\"gen\", generated_images, max_outputs=25, step=0), I got error :During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string.\r\nIf I wrote like this:\r\n```\r\nwith tf.device(\"cpu:0\"): <<-- add this line\r\n   with log[\"writer\"].as_default():\r\n     tf.summary.image(\"gen\", generated_images, max_outputs=25, step=0)\r\n```\r\neverything is fine.\r\n      ", "Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28007\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28007\">No</a>\n", "Hi @jvishnuvardhan, the snippet I wrote still failed with the same error message in colab (using gpu accelerator). Even 2.0-beta version failed too. Could you please describe how you make it work?", "@ipod825 As mentioned by @faruba I changed a line in your code from `with tf.device('/gpu:0'):` to `with tf.device('/cpu:0'):`. It works without any error. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/295c237a134755b28f94af9ce040af35/tf_28007_summary.ipynb). Thanks!", "Well, it seems to be just a workaround to me. The main issue here is that the summary operation raises error when running on GPU. Forcing the operation to run on CPU doesn't really solve the problem but just ignores the problem. I don't know how summary operation works, probably even if running under GPU, it would still copy tensor back to CPU memory (which then would be similar to explicitly asking it to run on CPU). Even if this is the case (if not, we lose some efficiency), from an API point of view, I don't think this issue is solved as someone might encounter the same problem and don't know why it happen and how to solve it without bumping into this thread.", "@ipod825 I have the same problem (did try tf2.0 alphas and betas) and agree that assigning the summary op to /cpu:0 is only a workaround. Moreover, the fix is not working for me if I build from the r2.0 branch from source.\r\nIt would be nice if this issue would be reopened, so the problem can be solved.\r\n\r\nI took a look at [github](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/image/summary_v2.py): the map_fn in line 75 is causing the issues.", "@ipod825 @loffermann Sorry for closing. Reopened. Thanks!", "I ran to a similar issue, when I tried to save images to tf.summary.image using MirroredStrategy. Oddly enough, when debugging using tf.config.experimental_run_functions_eagerly(True) this error does not occur.\r\n\r\n  (0) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\t [[{{node training-image/encode_each_image/while/body/_1/TensorArrayV2Write/TensorListSetItem/_62}}]]\r\n\t [[Func/training-image/encode_each_image/while/body/_1/input/_50/_60]]\r\n  (1) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\t [[{{node training-image/encode_each_image/while/body/_1/TensorArrayV2Write/TensorListSetItem/_62}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors. [Op:__inference_train_step_16043]\r\n\r\nFunction call stack:\r\ntrain_step -> train_step\r\n", "I also ran into this issue. Here's a fairly minimal piece of code that reproduces it:\r\n\r\n```python\r\nimport tensorflow.compat.v2 as tf\r\ntf.enable_v2_behavior()\r\n\r\ndef decode_png(data):\r\n  return tf.image.decode_png(data)\r\n\r\n@tf.function  # <= No exception if you comment this line out\r\ndef decode_all(images):\r\n  return tf.map_fn(decode_png, images, dtype=tf.uint8)\r\n\r\nimg = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\rIDATx\\xdac\\xfc\\xcf\\xf0\\xbf\\x1e\\x00\\x06\\x83\\x02\\x7f\\x94\\xad\\xd0\\xeb\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\r\nimages = tf.constant([img, img])\r\ndecode_all(images)\r\n```\r\n\r\nand here's the full stackstrace:\r\n\r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-72-a59f4c54298a> in <module>()\r\n     11 img = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\rIDATx\\xdac\\xfc\\xcf\\xf0\\xbf\\x1e\\x00\\x06\\x83\\x02\\x7f\\x94\\xad\\xd0\\xeb\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\r\n     12 images = tf.constant([img, img])\r\n---> 13 decode_all(images)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    465               *args, **kwds)\r\n    466       # If we did not create any variables the trace we have is good enough.\r\n--> 467       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n    468 \r\n    469     def fn_with_cond(*inner_args, **inner_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\t [[{{node map/TensorArrayUnstack/TensorListFromTensor/_12}}]]\r\n  (1) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\t [[{{node map/TensorArrayUnstack/TensorListFromTensor/_12}}]]\r\n\t [[Func/map/while/body/_1/input/_43/_24]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_decode_all_20554]\r\n\r\nFunction call stack:\r\ndecode_all -> decode_all\r\n```\r\n\r\nI ran this on Colab with a GPU Runtime, using TF 1.15.0rc3. It will probably bomb as well on TF 2.0.0 but I haven't tried.", "A modification of the earlier gist posted by @jvishnuvardhan causes the error to occur again. [Here](https://colab.research.google.com/gist/rharish101/23772d541af0c8144348aa1bd831c8b9/tf_28007_summary.ipynb) it is. \r\n\r\nI am using both the GPU and CPU inside the decorated function because there might be a computationally expensive part that I have to run on the GPU. The CPU is used to run the summary ops as a workaround to this bug. However, the error still occurs. The only way to get around this is to run the entire function on the CPU when calling it, as @jvishnuvardhan 's gist, which is not ideal when I want to train a network.", "@ageron I couldnot reproduce your issue with `TF2.0-gpu`, `tf-nightly` and `TF1.15.0rc3`. [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/3cb45886c985045841ed7c45e899eaaa/untitled564.ipynb) is the gist with TF1.15.0rc3. Could you try the colab and let us know. Thanks!\r\n", "@jvishnuvardhan I tried the notebook you posted, and it works because the notebook's runtime isn't using the GPU. After changing the runtime to a GPU-accelerated one, it fails with the error @ageron posted.", "@rharish101 Thanks! Got it. This is not resolved. Thanks!", "Same issue!", "The issue should be renamed to something like: \"`InvalidArgumentError` when running `map_fn` on strings inside a `tf.function`\".\r\n\r\nHere is an even smaller code snippet to reproduce the error (to run on GPU):\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef f():\r\n    return tf.map_fn(tf.strings.upper, tf.constant([\"a\", \"b\", \"c\"]))\r\n\r\nprint(f())\r\n```", "@jvishnuvardhan @nfelt Any update on this? Maybe this issue should be reassigned to someone else.", "@nfelt This is still present in TF 2.1 RC 0. Is there a workaround? Wrapping the summary op in `with tf.device('/cpu:0'):` doesn't change anything for me.", "Is this being fixed or adressed by someone. For me in TF2.0 not even the `tf.device` hint did work. Following code (tf2.0, cuda10.0, GTX 1080) did not work for me and failed with the same error message as reported above (Invalid argument: During Variant Host->Device Copy: non-DMA- ....):\r\n```python\r\nimport tensorflow as tf\r\n\r\nwriter = tf.summary.create_file_writer(\"/tmp/mylogs/tf_function\")\r\n\r\n\r\n@tf.function\r\ndef my_func(image, step):\r\n    with tf.device(\"/cpu:0\"):\r\n        tf.summary.image(\"my_image_metric\", image, step=step)\r\n\r\n\r\nimage = tf.constant(\r\n    [[[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]], [[0.0, 0.0, 1.0], [1.0, 1.0, 1.0]]]\r\n)[None]\r\n\r\nwith writer.as_default():\r\n    for step in tf.range(100, dtype=tf.int64):\r\n        my_func(image, step)\r\n        writer.flush()\r\n```", "I think the issue is incorrectly assigned as it is not directly related to `tf.summary`. @tensorflow/dev-support Can this be reassigned to someone working on functional ops such as `tf.map_fn`?", "Thanks for notifying. We will re-assign this shortly.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nOn Fri, Jan 17, 2020 at 9:04 AM Guillaume Klein <notifications@github.com>\r\nwrote:\r\n\r\n> I think the issue is incorrectly assigned as it is not directly related to\r\n> tf.summary. @tensorflow/dev-support\r\n> <https://github.com/orgs/tensorflow/teams/dev-support> Can this be\r\n> reassigned to someone working on functional ops such as tf.map_fn?\r\n>\r\n> \u2014\r\n> You are receiving this because you are on a team that was mentioned.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/28007?email_source=notifications&email_token=ALILBSRQXQFOBUTAMB27DP3Q6HQJZA5CNFSM4HHKPF4KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEJIKUEQ#issuecomment-575711762>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/ALILBSSB4VXJUSSRVKZZDNTQ6HQJZANCNFSM4HHKPF4A>\r\n> .\r\n>\r\n", "I know the root cause for this issue is not in the tf.summary module, but for those who get here because of using tf.summary.image() inside @tf.function, my workaround is to return the outputs and do summaries outside:\r\n```python\r\n@tf.function\r\ndef train_op(inputs):\r\n  outputs = net(inputs)\r\n  # handle loss and gradients...\r\n  return outputs\r\n\r\ndef train():\r\n  for data in dataloader:\r\n    outputs = train_op(data)\r\n    with summary_writer.as_default():\r\n      tf.summary.image('image', outputs)\r\n```", "is there a plan to fix this or a suggested workaround?", "We're looking into this now. Should have some updates soon.", "Please solve it fast. I really need to use `tf.map_fn` inside the data preprocessing pipeline.", "> The issue should be renamed to something like: \"`InvalidArgumentError` when running `map_fn` on strings inside a `tf.function`\".\r\n> \r\n> Here is an even smaller code snippet to reproduce the error (to run on GPU):\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> \r\n> @tf.function\r\n> def f():\r\n>     return tf.map_fn(tf.strings.upper, tf.constant([\"a\", \"b\", \"c\"]))\r\n> \r\n> print(f())\r\n> ```\r\n\r\ni also have this problem, it works well in cpu ,but gpu not,  how can I to solve it ?", "This should be fixed for simple `tf.map_fn` example, however the underlying problem is still there, and might be triggered in more complex use cases. A fix commit has a repro with explanation.", "Also having the same issue using TF 2.1. Works fine on a machine with just a CPU, but fails on a machine with a GPU, even when using `with tf.device('/cpu:0')`. Would appreciate an update this asap.", "### I have the same error, but error raised when I use tensorflow serving\uff08GPU VERSION\uff09\r\nmy model incude function below:\r\n````\r\ndef preprocess_and_decode(img_str, new_shape=target_size):\r\n        img = tf.io.decode_base64(img_str)\r\n        img = tf.image.decode_jpeg(img, channels=3)\r\n        img = tf.image.resize(img, new_shape, method=method)\r\n        return img\r\n\r\ninput64 = tf.keras.layers.Input(shape=(1,), dtype=\"string\", name=input_name)\r\nouput_tensor = tf.keras.layers.Lambda(\r\n        lambda img: tf.map_fn(lambda im: preprocess_and_decode(im[0]), img, dtype=\"float32\"))(input64)\r\n````\r\n\r\nIt's ok to delopy with serving cpu, but got error with gpu like below:\r\n\r\n`'{ \"error\": \"2 root error(s) found.\\\\n  (0) Invalid argument: 2 root error(s) found.\\\\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\\\\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\\\\n0 successful operations.\\\\n0 derived errors ignored.\\\\n\\\\t [[{{node model_11/lambda_16/map/TensorArrayUnstack/TensorListFromTensor}}]]\\\\n  (1) Invalid argument: 2 root error(s) found.\\\\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\\\\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\\\\n0 successful operations.\\\\n0 derived errors ignored.\\\\n\\\\t [[{{node model_11/lambda_16/map/TensorArrayUnstack/TensorListFromTensor}}]]\\\\n\\\\t [[Func/StatefulPartitionedCall/StatefulPartitionedCall/model_11/lambda_16/map/while/body/_887/input/_935/_935]]\\\\n0 successful operations.\\\\n0 derived errors ignored.\" }' `\r\n\r\nAny solutions for this? ", "I am also facing this issue on GPU (no error on CPU) when using to map_fn for string tensor (with float tensor all right):\r\n```\r\ndef process_string(sample):\r\n    # here i want to write something to file, but even with identity\r\n    # function I get \"non-DMA-copy attempted...\" error\r\n    return sample\r\n\r\n@tf.function\r\ndef f(self, y_true, y_pred):\r\n    string_tensor = y_true[\"path\"]  # Tensor(\"data_batch_19:0\", shape=(2,), dtype=string)\r\n    tf.map_fn(process_string, string_tensor)\r\n```\r\nI do not know why, but for me manually placing map_fn on cpu AND making mock return from tf.function helped:\r\n```\r\n@tf.function\r\ndef f(self, y_true, y_pred):\r\n    string_tensor = y_true[\"path\"]  # Tensor(\"data_batch_19:0\", shape=(2,), dtype=string)\r\n    with tf.device(\"/cpu:0\"):\r\n        tf.map_fn(process_string, string_tensor)\r\n    return y_pred  # do not work for me without return something\r\n```\r\nI am using tf2.0.1", "> I am also facing this issue on GPU (no error on CPU) when using to map_fn for string tensor (with float tensor all right):\r\n> \r\n> ```\r\n> def process_string(sample):\r\n>     # here i want to write something to file, but even with identity\r\n>     # function I get \"non-DMA-copy attempted...\" error\r\n>     return sample\r\n> \r\n> @tf.function\r\n> def f(self, y_true, y_pred):\r\n>     string_tensor = y_true[\"path\"]  # Tensor(\"data_batch_19:0\", shape=(2,), dtype=string)\r\n>     tf.map_fn(process_string, string_tensor)\r\n> ```\r\n> \r\n> I do not know why, but for me manually placing map_fn on cpu AND making mock return from tf.function helped:\r\n> \r\n> ```\r\n> @tf.function\r\n> def f(self, y_true, y_pred):\r\n>     string_tensor = y_true[\"path\"]  # Tensor(\"data_batch_19:0\", shape=(2,), dtype=string)\r\n>     with tf.device(\"/cpu:0\"):\r\n>         tf.map_fn(process_string, string_tensor)\r\n>     return y_pred  # do not work for me without return something\r\n> ```\r\n> \r\n> I am using tf2.0.1\r\n\r\nis this valid in tensorflow serving gpu?", "@Lannister-Xiaolin, I have not tried. I run program locally, without wrapping map_fn in keras.layer (as in your example).", "Hi, sorry for my poor English. I solved this problem by log the dataset images outside the @tf.function. ", "@TIGERCHANG123 - interesting! can you please share a code example? ", "I'm having the same issue using map_fn to decode a image list. Even when using my cpu.\r\n\r\n```\r\ndef decode_image_fn(x):\r\n  t = tf.image.decode_image(x, 3)\r\n  t.set_shape((224, 224, 3))\r\n  return t\r\n\r\nframes = tf.map_fn(decode_image_fn, frames_raw, dtype=tf.uint8)\r\n```\r\n", "Im having this issue too with TF2.2rc3", "> I am also facing this issue on GPU (no error on CPU) when using to map_fn for string tensor (with float tensor all right):\r\n> \r\n> ```\r\n> def process_string(sample):\r\n>     # here i want to write something to file, but even with identity\r\n>     # function I get \"non-DMA-copy attempted...\" error\r\n>     return sample\r\n> \r\n> @tf.function\r\n> def f(self, y_true, y_pred):\r\n>     string_tensor = y_true[\"path\"]  # Tensor(\"data_batch_19:0\", shape=(2,), dtype=string)\r\n>     tf.map_fn(process_string, string_tensor)\r\n> ```\r\n> \r\n> I do not know why, but for me manually placing map_fn on cpu AND making mock return from tf.function helped:\r\n> \r\n> ```\r\n> @tf.function\r\n> def f(self, y_true, y_pred):\r\n>     string_tensor = y_true[\"path\"]  # Tensor(\"data_batch_19:0\", shape=(2,), dtype=string)\r\n>     with tf.device(\"/cpu:0\"):\r\n>         tf.map_fn(process_string, string_tensor)\r\n>     return y_pred  # do not work for me without return something\r\n> ```\r\n> \r\n> I am using tf2.0.1\r\n\r\nHi thanks this trick works for my case also ", "@ipod825 \r\nIs this still an issue?\r\nI was able to run the code without any issues with TF v2.2, please find the gist of it [here](https://colab.research.google.com/gist/saikumarchalla/c5aabfe8ba2812abe71c2380c13f73a9/-28007.ipynb).Thanks!\r\n", "@saikumarchalla Yes, here's a [Colab notebook](https://colab.research.google.com/drive/1HgUZDuao1MW7pAT9qUt3wGNDBdONfGde?usp=sharing).", "@rharish101 @saikumarchalla I think this has been fixed. I just ran the colab from @rharish101 with tf nightly, and am not seeing an error. Please confirm.", "@nikitamaia Yes, this is fixed on TensorFlow 2.3.0. I tested this on the colab and also on my local machine (running TF 2.3.0 on Arch Linux).", "Closing this issue now since the bug has been fixed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28007\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28007\">No</a>\n", "I am getting a similar error on TF 2.4.1.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ndef _get_char_flags(char_tensor):\r\n    char = char_tensor.numpy().decode()\r\n    return char.isalpha(), char.isspace()\r\n\r\n\r\n@tf.function  # <--------------- Runs fine with this line commented out.\r\ndef tf_split_text(text):\r\n    tf.assert_rank(text, 0)\r\n    tf.debugging.assert_type(text, tf.string)\r\n\r\n    chars = tf.strings.unicode_split(text, input_encoding='UTF-8')\r\n    is_alpha, is_space = tf.map_fn(lambda char: tf.py_function(_get_char_flags, char, Tout=[tf.bool, tf.bool]),\r\n                                   (chars,), dtype=tf.bool, parallel_iterations=True,\r\n                                   fn_output_signature=[tf.bool, tf.bool])\r\n\r\n    is_alpha = tf.concat([is_alpha, [False]], axis=0)\r\n    is_space = tf.concat([is_space, [True]], axis=0)\r\n\r\n    is_special = ~(is_alpha | is_space)\r\n    is_non_alpha = ~is_alpha\r\n    is_non_space = ~is_space\r\n\r\n    was_special = tf.concat([[False], is_special[:-1]], axis=0)\r\n    was_non_alpha = tf.concat([[True], is_non_alpha[:-1]], axis=0)\r\n    was_non_space = tf.concat([[False], is_non_space[:-1]], axis=0)\r\n\r\n    any_to_special = is_special\r\n    non_alpha_to_non_space = was_non_alpha & is_non_space\r\n    token_start_flags = any_to_special | non_alpha_to_non_space\r\n    token_start_indices = tf.where(token_start_flags)[:, 0]\r\n\r\n    special_to_any = was_special\r\n    non_space_to_non_alpha = was_non_space & is_non_alpha\r\n    token_end_flags = special_to_any | non_space_to_non_alpha\r\n    token_end_indices = tf.where(token_end_flags)[:, 0]\r\n\r\n    tf.debugging.assert_equal(tf.size(token_start_indices), tf.size(token_end_indices))\r\n\r\n    preceding_space = tf.concat([[False], is_space[:-1]], axis=0)\r\n\r\n    tokens = tf.strings.substr(text, token_start_indices, token_end_indices - token_start_indices, unit='UTF8_CHAR')\r\n    has_preceding_space = tf.gather(preceding_space, token_start_indices)\r\n\r\n    tf.assert_rank(has_preceding_space, 1)\r\n    tf.assert_rank(tokens, 1)\r\n    tf.assert_equal(tf.reduce_sum(tf.map_fn(tf.strings.length, tokens, fn_output_signature=tf.int32)) +\r\n                    tf.reduce_sum(tf.cast(has_preceding_space, tf.int32)),\r\n                    tf.strings.length(text))\r\n    return has_preceding_space, tokens\r\n\r\n\r\ntext = tf.constant('hi there', tf.string)\r\npreceding_spaces, words = tf_split_text(text)\r\nprint(words)\r\n```\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/home/hosford42/PycharmProjects/ImageParser/error.py\", line 56, in <module>\r\n    preceding_spaces, words = tf_split_text(text)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 894, in _call\r\n    return self._concrete_stateful_fn._call_flat(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 1918, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 555, in call\r\n    outputs = execute.execute(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\t [[{{node map_1/TensorArrayUnstack/TensorListFromTensor/_96}}]]\r\n\t [[map_1/while/loop_body_control/_61/_107]]\r\n  (1) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\t [[{{node map_1/TensorArrayUnstack/TensorListFromTensor/_96}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_tf_split_text_265]\r\n\r\nFunction call stack:\r\ntf_split_text -> tf_split_text\r\n```", "Hi @hosford42, I just ran your [code sample in Colab](https://colab.research.google.com/gist/nikitamaia/0ed2698f00e3fe26b3d4f38e2ad784dc/28007_mapfn.ipynb) and I'm not seeing any errors. Please let me know if I'm missing something and open a new issue for further debugging.", "@nikitamaia, I'm not using Colab, so perhaps the environment is the issue. I'm running Python 3.8.5 on an Ubuntu machine. I can provide more details if necessary.\r\n\r\nHere is the full output when I start python and import tensorflow to show the version number:\r\n```python\r\nPython 3.8.5 (default, Jul 28 2020, 12:59:40) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.13.0 -- An enhanced Interactive Python. Type '?' for help.\r\nPyDev console: using IPython 7.13.0\r\nPython 3.8.5 (default, Jul 28 2020, 12:59:40) \r\n[GCC 9.3.0] on linux\r\nimport tensorflow as tf\r\n2021-02-22 12:46:55.445604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\nInvalid MIT-MAGIC-COOKIE-1 keyIn[3]: tf.__version__\r\nOut[3]: '2.4.1'\r\n```", "And here is the logging output when I start a session, for GPU-specific info if that's needed:\r\n```\r\n2021-02-22 12:49:32.393693: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-02-22 12:49:32.395363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-02-22 12:49:32.441021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-02-22 12:49:32.441279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2021-02-22 12:49:32.441313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-02-22 12:49:32.444150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2021-02-22 12:49:32.444248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2021-02-22 12:49:32.445154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-02-22 12:49:32.445415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-02-22 12:49:32.447089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-02-22 12:49:32.448029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2021-02-22 12:49:32.448393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-02-22 12:49:32.448639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-02-22 12:49:32.449058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-02-22 12:49:32.449257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-02-22 12:49:32.450007: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-02-22 12:49:32.450607: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-02-22 12:49:32.450814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-02-22 12:49:32.451052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2021-02-22 12:49:32.451087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-02-22 12:49:32.451164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2021-02-22 12:49:32.451193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2021-02-22 12:49:32.451221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-02-22 12:49:32.451248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-02-22 12:49:32.451275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-02-22 12:49:32.451302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2021-02-22 12:49:32.451329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-02-22 12:49:32.451431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-02-22 12:49:32.451703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-02-22 12:49:32.451881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-02-22 12:49:32.451925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-02-22 12:49:32.992073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-02-22 12:49:32.992131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \r\n2021-02-22 12:49:32.992141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \r\n2021-02-22 12:49:32.992400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-02-22 12:49:32.992681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-02-22 12:49:32.992895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-02-22 12:49:32.993079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 142 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n```", "Actually, I just ran the Colab gist that I shared in my earlier post, but this time with a GPU runtime. I'm now seeing the same error message that you reported. So seems to be a GPU related issue. Can you open a new bug with all of this information? Thanks!"]}, {"number": 28006, "title": "Remove property from seekable method of FileIO", "body": "This fix is a follow up to address the issue in #27276 where seekable with property causes the following error with Python 3.7.:\r\n```\r\n  File \"/usr/lib/python3.7/_collections_abc.py\", line 744, in __iter__\r\n    yield (key, self._mapping[key])\r\n  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\", line 251, in __getitem__\r\n    bytes = self.zip.open(key)\r\n  File \"/usr/lib/python3.7/zipfile.py\", line 1540, in open\r\n    return ZipExtFile(zef_file, mode, zinfo, zd, True)\r\n  File \"/usr/lib/python3.7/zipfile.py\", line 821, in __init__\r\n    if fileobj.seekable():\r\nTypeError: 'bool' object is not callable\r\n```\r\n\r\nThis fix removed property annotation of the seekable methods.\r\n\r\nThis fix also adds a test case, though the test case is only exposed in python 3.7+.\r\n\r\nThis fix fixes #27276.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @dynamicwebpaige \ud83d\udc4d , the sanity ci test was failing because of the pylint format issue. Have fixed the sanity ci test and updated.", "@mihaimaruseac Thanks for the review. There were ci failures related to api compatible. I have updated the api goldens file so tests should all pass now.", "This is not a backwards-compatible change.\r\n\r\nI think we need to make this change in 2.0 only. This will require having two classes, a V1 with a property and a V2 with a method, and these should have separate tf_export decorator.", "Nevermind, let's try to merge this as-is.", "We took a look and found very few to no usages of this, so it's fine to have a backwards-breaking bugfix."]}, {"number": 28005, "title": "Java Tensorflow Not found: TF GPU device with id 0 was not registered", "body": "```\r\n$  java -cp test-gpu.jar com.gpu.demo.Demo001_DLPredictor_GPU\r\nlabel len=2280\r\n2019-04-20 19:45:51.893764: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\r\n2019-04-20 19:45:52.460339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \r\nname: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\r\npciBusID: 0000:5a:00.0\r\ntotalMemory: 31.74GiB freeMemory: 10.32GiB\r\n2019-04-20 19:45:52.460427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2019-04-20 19:45:54.493478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-04-20 19:45:54.493549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \r\n2019-04-20 19:45:54.493567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \r\n2019-04-20 19:45:54.494202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9965 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:5a:00.0, compute capability: 7.0)\r\n2019-04-20 19:45:54.639326: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered\r\n```\r\n\r\nI use java to call TensorFlow, using the 0th GPU, but\r\nE tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "centos7 java1.8 tensorflow1.8", "From the stack trace,```totalMemory: 31.74GiB freeMemory: 10.32GiB``` you are running out of gpu memory. You can try setting ```config.gpu_options.allow_growth= True``` .\r\nhttps://www.tensorflow.org/guide/using_gpu#allowing_gpu_memory_growth", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28004, "title": "New weight initialisation when using dropout and ReLU", "body": "- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature**\r\nIn a recent NeurIPS paper ([Pretorius et al. 2018](https://arxiv.org/pdf/1811.00293.pdf)), we derived a new weight initialisation strategy for deep ReLU networks that use dropout. This new initialisation ensures stable variance propagation for ReLU activations travelling through a dropout layer. The go-to initialisation for dense ReLU layers is the He initialisation, but in the above paper, we showed that if a dropout layer is applied after a dense ReLU layer the variances are longer preserved in the forward pass. This can lead to unstable signal propagation in deep ReLU networks that use dropout. We fix this with the new initialisation and thought it might be useful to the community if there was a Tensorfow implementation.  \r\n\r\n**Will this change the current api? How?**\r\nIt should not require the current api to change.\r\n\r\n**Proposed implementation**\r\nIn short, the initialisation samples from a normal distribution with zero mean and `stddev = \\sqrt{2*(1-p)/fan_in}`, where `p is the probability of an element to be zeroed` when passing through the dropout layer following the dense layer being initialised. To implement the initialisation in Tensorflow, I was thinking perhaps something along these lines of code being added to the `init_ops.py`? This init should be applied to dense ReLU layers preceding a dropout layer.\r\n\r\n```python\r\ndef dropout(rate, seed=None):\r\n  \"\"\"Dropout initializer.\r\n  It draws samples from a normal distribution centred on 0\r\n  with standard deviation given by\r\n  `stddev = sqrt(2*(1-rate) / fan_in)` where `fan_in` is the number of\r\n  input units in the weight tensor and `rate` is the probability of an \r\n  element to be zeroed as set in the dropout layer applied after this dense layer.\r\n  Arguments:\r\n      rate: The dropout rate, between 0 and 1. This should be set equal to the dropout rate in the subsequent dropout layer.\r\n      seed: A Python integer. Used to seed the random generator.\r\n  Returns:\r\n      An initializer.\r\n  References:\r\n      [Pretorius et al., 2018]\r\n      (https://papers.nips.cc/paper/7814-critical-initialisation-for-deep-signal-propagation-in-noisy-rectifier-neural-networks)\r\n      # pylint: disable=line-too-long\r\n      ([pdf](https://papers.nips.cc/paper/7814-critical-initialisation-for-deep-signal-propagation-in-noisy-rectifier-neural-networks.pdf))\r\n  \"\"\"\r\n  if not (rate >= 0 and rate < 1):\r\n        raise ValueError(\"rate must be a scalar tensor or a float in the \"\r\n                         \"range [0, 1), got %g\" % rate)\r\n  return VarianceScaling(\r\n      scale=2.0*(1.0-rate), mode=\"fan_in\", distribution=\"normal\", seed=seed)\r\n```\r\n\r\n**Who will benefit with this feature?**\r\nHopefully, anyone applying dropout in a deep ReLU network. :)\r\n\r\n*Side note: We do not sample from a truncated normal since in our experiments we noticed that when sampling from a truncated normal (which is currently the default), the signal propagation dynamics did not fit with the theory predicting variance preservation during the forward pass. This was the case for both the He init and our dropout init. Therefore, we would also suggest a  (non-truncated) normal as the default for the standard initialisers currently implemented (e.g. He and Xavier etc.).\r\n", "comments": ["@arnupretorius,\r\nSorry for the delayed response. Do you feel this **`New Weight Initialization`** holds good even now? If so, since you are clear with what changes needs to be done and where the changes are to be done in the source code, feel free to submit a PR and we will be happy to review it. Thank you.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 28003, "title": "TF 2.0 Bug or Feature? keras includes duplicated shared variables in model.variables", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip nightly\r\n- TensorFlow version (use command below): 2.0.0-dev20190415\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nThe two following layers give different number of variable in `model.variables`. Keras duplicates shared variables in the variable list:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nclass MLayer(tf.Module):\r\n    def __init__(self):\r\n        super(MLayer, self).__init__()\r\n        conv = tf.keras.layers.Conv2D(3, 3, 1, padding='SAME')\r\n        self.convs = [conv] * 7\r\n\r\n    def __call__(self, x):\r\n        for conv in self.convs:\r\n            x = conv(x)\r\n        return x\r\n\r\nclass KLayer(tf.keras.models.Model):\r\n    def __init__(self):\r\n        super(KLayer, self).__init__()\r\n        conv = tf.keras.layers.Conv2D(3, 3, 1, padding='SAME')\r\n        self.convs = [conv] * 7\r\n\r\n    def call(self, x):\r\n        for conv in self.convs:\r\n            x = conv(x)\r\n        return x\r\n\r\nxnp = np.random.rand(1, 224, 224, 3)\r\nx = tf.constant(xnp, tf.float32)\r\n\r\nmodel = MLayer()\r\ny = model(x)\r\nv = [variable.name for variable in model.variables]\r\nprint(v, len(v))\r\n\r\nmodel = KLayer()\r\ny = model(x)\r\nv = [variable.name for variable in model.variables]\r\nprint(v, len(v))\r\n```\r\nThe first print:\r\n```\r\n['conv2d/kernel:0', 'conv2d/bias:0'] 2\r\n```\r\nThe second prints: \r\n```\r\n['k_layer/conv2d_1/kernel:0', 'k_layer/conv2d_1/bias:0', 'k_layer/conv2d_1/kernel:0', 'k_layer/conv2d_1/bias:0', 'k_layer/conv2d_1/kernel:0', 'k_layer/conv2d_1/bias:0', 'k_layer/conv2d_1/kernel:0', 'k_layer/conv2d_1/bias:0', 'k_layer/conv2d_1/kernel:0', 'k_layer/conv2d_1/bias:0', 'k_layer/conv2d_1/kernel:0', 'k_layer/conv2d_1/bias:0', 'k_layer/conv2d_1/kernel:0', 'k_layer/conv2d_1/bias:0'] 14\r\n```\r\n**Describe the expected behavior**\r\n\r\nI would expect two layers have the same number of variables. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I was able to reproduce the behavior with ```TF nightly '1.14.1-dev20190423'```", "This is fixed with latest version of TensorFlow nightly build version '2.1.0-dev20191021'\r\nOutput:\r\n```python\r\n['conv2d/kernel:0', 'conv2d/bias:0'] 2\r\n['k_layer/conv2d_1/kernel:0', 'k_layer/conv2d_1/bias:0'] 2\r\n```\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28003\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28003\">No</a>\n"]}, {"number": 28002, "title": "CTCBeamSearchDecoder - Less leaves in the beam search than requested.", "body": "I encounter the issue after successfully training on a number of batches of data (different number each time). The interesting thing is that if I train only on the batch that the error occurred on, everything is fine - so there is nothing wrong with the data (I am using the Tensorflow speech_commands dataset). I'm very confused as to what is causing this behaviour. Any help is greatly appreciated.\r\n\r\nStack trace:\r\n\r\n    Traceback (most recent call last):\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n        return fn(*args)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n        options, feed_dict, fetch_list, target_list, run_metadata)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n        run_metadata)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: Less leaves in the beam search than requested.\r\n    \t [[{{node loss/CTCBeamSearchDecoder}} = CTCBeamSearchDecoder[beam_width=100, merge_repeated=true, top_paths=2, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss/transpose_1/_91, Fill/_93)]]\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"train.py\", line 180, in <module>\r\n        train_and_eval()    \r\n      File \"train.py\", line 107, in train_and_eval\r\n        feed_dict=feed_dict)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n        run_metadata_ptr)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n        feed_dict_tensor, options, run_metadata)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n        run_metadata)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n        raise type(e)(node_def, op, message)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: Less leaves in the beam search than requested.\r\n    \t [[node loss/CTCBeamSearchDecoder (defined at /mainfs/lyceum/chk1g16/Speech-Recognition/Conv_LSTM_CTC/conv_lstm_ctc_net.py:256)  = CTCBeamSearchDecoder[beam_width=100, merge_repeated=true, top_paths=2, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss/transpose_1/_91, Fill/_93)]]\r\n    \r\n    Caused by op 'loss/CTCBeamSearchDecoder', defined at:\r\n      File \"train.py\", line 180, in <module>\r\n        train_and_eval()\r\n      File \"train.py\", line 55, in train_and_eval\r\n        data_gen._num_frames, data_gen._num_mel_spec_bins, init_lr, lr_decay_steps, lr_decay_rate)\r\n      File \"/mainfs/lyceum/chk1g16/Speech-Recognition/Conv_LSTM_CTC/conv_lstm_ctc_net.py\", line 330, in create_train_graph\r\n        predictions, loss, acc_greedy, edit_dist_greedy, acc_beam, edit_dist_beam, scores = get_ctc_loss(logits, label_batch_plh)\r\n      File \"/mainfs/lyceum/chk1g16/Speech-Recognition/Conv_LSTM_CTC/conv_lstm_ctc_net.py\", line 256, in get_ctc_loss\r\n        merge_repeated=True)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/ops/ctc_ops.py\", line 277, in ctc_beam_search_decoder\r\n        merge_repeated=merge_repeated))\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_ctc_ops.py\", line 74, in ctc_beam_search_decoder\r\n        top_paths=top_paths, merge_repeated=merge_repeated, name=name)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n        op_def=op_def)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n        return func(*args, **kwargs)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\r\n        op_def=op_def)\r\n      File \"/lyceum/chk1g16/.conda/envs/py3venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\r\n        self._traceback = tf_stack.extract_stack()\r\n    \r\n    InvalidArgumentError (see above for traceback): Less leaves in the beam search than requested.\r\n    \t [[node loss/CTCBeamSearchDecoder (defined at /mainfs/lyceum/chk1g16/Speech-Recognition/Conv_LSTM_CTC/conv_lstm_ctc_net.py:256)  = CTCBeamSearchDecoder[beam_width=100, merge_repeated=true, top_paths=2, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss/transpose_1/_91, Fill/_93)]]\r\n\r\n\r\n\r\nloss function:\r\n\r\n    def get_ctc_loss(logits, label_batch):\r\n        # logits: [batch_size, max_time, num_classes]\r\n        \r\n        \r\n        # 1-D tensor showing the length for each label in the batch\r\n        batch_labels_lengths = tf.fill([tf.shape(label_batch)[0]], tf.shape(label_batch)[1])\r\n        \r\n        with tf.name_scope('loss'):\r\n            # get sparse represenattion of the labels\r\n            non_zero_elems_coords = tf.where(tf.not_equal(label_batch, 0))\r\n            non_zero_elems = tf.gather_nd(label_batch, non_zero_elems_coords)\r\n            sparse_label_batch = tf.SparseTensor(indices=non_zero_elems_coords, \r\n                                                 values=non_zero_elems,\r\n                                                 dense_shape=tf.shape(label_batch, out_type=tf.int64))\r\n                                            \r\n            # calculate ctc loss                                \r\n            ctc_loss_op = tf.nn.ctc_loss(labels=sparse_label_batch, \r\n                                         inputs=logits, \r\n                                         sequence_length=batch_labels_lengths,\r\n                                         preprocess_collapse_repeated=True, \r\n                                         time_major=False, \r\n                                         ctc_merge_repeated=True,\r\n                                         ignore_longer_outputs_than_inputs=False)\r\n            loss = tf.reduce_mean(ctc_loss_op)\r\n            \r\n            \r\n            prediction_probabilities = tf.nn.softmax(logits)\r\n            max_probabilities = tf.reduce_max(prediction_probabilities, axis=2)\r\n            raw_predictions = tf.argmax(prediction_probabilities, axis=2)\r\n    \r\n    \r\n    \r\n            # greedy decode logits\r\n            # greedy decoder - beeam decoder with beam_width=1 and top_paths=1\r\n            logits_T = tf.transpose(logits, perm=[1, 0, 2])\r\n            greedy_predictions, neg_sum_logits = tf.nn.ctc_greedy_decoder(inputs=logits_T, \r\n                                                    sequence_length=batch_labels_lengths,\r\n                                                    merge_repeated=True)\r\n            \r\n            # get greedy performance metrics\r\n            edit_dist_greedy = tf.edit_distance(tf.cast(greedy_predictions[0], tf.int32),\r\n                                                sparse_label_batch, \r\n                                                normalize=False)\r\n            acc_greedy = tf.reduce_mean(tf.cast(tf.equal(edit_dist_greedy, 0), tf.float32))\r\n            edit_dist_greedy = tf.reduce_mean(edit_dist_greedy)\r\n    \r\n    \r\n            \r\n            # beam decode logits\r\n            beam_predictions, log_probabilities = tf.nn.ctc_beam_search_decoder(inputs=logits_T, \r\n                                                        sequence_length=batch_labels_lengths, \r\n                                                        beam_width=100,\r\n                                                        top_paths=2,\r\n                                                        merge_repeated=True)\r\n                                            \r\n            # get beam performance metrics\r\n            edit_dist_beam = tf.edit_distance(tf.cast(beam_predictions[0], tf.int32),\r\n                                                  sparse_label_batch,\r\n                                                  normalize=False)\r\n            acc_beam = tf.reduce_mean(tf.cast(tf.equal(edit_dist_beam, 0), tf.float32))\r\n            \r\n            \r\n            predictions = tf.cast(tf.sparse.to_dense(beam_predictions[0]), tf.int32)\r\n            scores = log_probabilities[:, 0] - log_probabilities[:, 1]\r\n    \r\n        tf.summary.scalar('ctc_loss', loss)\r\n        tf.summary.scalar('acc_greedy', acc_greedy)\r\n        tf.summary.scalar('edit_dist_greedy', edit_dist_greedy)\r\n        tf.summary.scalar('confidence_score', tf.reduce_mean(scores))\r\n        # tf.summary.scalar('edit_dist_beam', edit_dist_beam)\r\n        tf.summary.scalar('acc_beam', acc_beam)\r\n    \r\n        return predictions, loss, acc_greedy, edit_dist_greedy, acc_beam, edit_dist_beam, scores", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28001, "title": "Tensorflow (cpu) vs concurrent.futures: Exception ", "body": "I am using Tensorflow v2.0.0-alpha on MacBook (CPU only). Python version: 3.7.2.\r\n\r\nI am testing a rl agent on multiple environments. For this I am using concurrent.futures.ProcessPoolExecutor.map function. Roughly around the time when first processes are done, exception occurs:\r\n\r\n```\r\n objc[44717]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called.\r\nobjc[44717]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead. Set a breakpoint on objc_initializeAfterForkError to debug.\r\nTraceback (most recent call last):\r\n  File \"/Users/ikkamens/PycharmProjects/ilya_agents/ilya_agents/launch/launch.py\", line 38, in <module>\r\n    for env, result in zip(envs, metrics):\r\n  File \"/Users/ikkamens/.pyenv/versions/3.7.2/lib/python3.7/concurrent/futures/process.py\", line 476, in _chain_from_iterable_of_lists\r\n    for element in iterable:\r\n  File \"/Users/ikkamens/.pyenv/versions/3.7.2/lib/python3.7/concurrent/futures/_base.py\", line 586, in result_iterator\r\n    yield fs.pop().result()\r\n  File \"/Users/ikkamens/.pyenv/versions/3.7.2/lib/python3.7/concurrent/futures/_base.py\", line 432, in result\r\n    return self.__get_result()\r\n  File \"/Users/ikkamens/.pyenv/versions/3.7.2/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\r\n    raise self._exception\r\nconcurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\r\n\r\n```\r\n", "comments": ["Using futures.ProcessPoolExecutor.submit() and futures.as_completed() results in the same crash. Code I have used:\r\n```\r\n    from concurrent import futures\r\n\r\n    executor = futures.ProcessPoolExecutor()\r\n    todos = {}\r\n    for env in envs:\r\n        todos[executor.submit(maping, env)] = env\r\n\r\n    scores = {}\r\n    for future in futures.as_completed(todos):\r\n        scores[ str(todos[future]) ] = future.result()\r\n```\r\n\r\nwhere function `maping` involves creating a tf-based agent, training it and testing on a gym environment.", "In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "I have not saved the version of the project and the problem does not reoccur anymore.", "Okay. Closing this issue since its resolved. Feel free to reopen if further problems persist. Thanks!"]}, {"number": 28000, "title": "first_bn/FusedBatchNorm_mul_0, which is an input to the Add operator producing the output array kws_model/KWS_Model/tower_0/CNN_V1/Relu, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\\nAborted (core dumped)\"", "body": "**System information**\r\n-Centos\r\n- TensorFlow 1.9:\r\n\r\n\r\n**change the pb model to tflite *\r\nmy network include batch_normalization layer, \r\nwhen I change the the pb model to tflite , there is always return a error message.\r\n```\r\nfirst_bn/FusedBatchNorm_mul_0, which is an input to the Add operator producing the output array kws_model/KWS_Model/tower_0/CNN_V1/Relu, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\\nAborted (core dumped)\"\r\n```\r\n\r\nI tried  lots of methods, like add  converter.default_ranges_stats=(0, 6) or remove bn layers. but  I know its not the expected ways. hope other friends can give me some suggestions. thanks\r\n\r\n", "comments": ["Thank you for reaching out to us. Can you try with the latest tensorflow version since tensorflow 1.9 seems to be a bit older version. Let us know if you still face the issue.", "> Thank you for reaching out to us. Can you try with the latest tensorflow version since tensorflow 1.9 seems to be a bit older version. Let us know if you still face the issue.\r\n\r\ni have tried the 1.12, but i still face the problem. ", "> Thank you for reaching out to us. Can you try with the latest tensorflow version since tensorflow 1.9 seems to be a bit older version. Let us know if you still face the issue.\r\n\r\nthanks", "I'm having the same issue with quantizing a model containing batch norm layers, which I've previously reported, and referenced here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/25301", "> I'm having the same issue with quantizing a model containing batch norm layers, which I've previously reported, and referenced here:\r\n> \r\n> #25301\r\n\r\nthanks", "@hahadashi : Were you able to resolve the issue ?", "> @hahadashi : Were you able to resolve the issue ?\r\n@achandraa \r\nno, i have tried my best to find a correct method, but it didn't work. during the last days, i find lots of people meet the same problem (tf.layer.batch_normalization), but all can not resolve it. hope you can give some suggestions.  ", "@hahadashi : Did you get chance to try out solution provided in #21725 or #22528. Looks like we might have to add FakeQuantWithMinMaxVars. Let us know. Thanks!", "> @hahadashi : Did you get chance to try out solution provided in #21725 or #22528. Looks like we might have to add FakeQuantWithMinMaxVars. Let us know. Thanks!\r\n@achandraa  thanks.\r\nin  #21725 or #22528, they give a solution that set \"default range value\". i can resolve my problem by this way, but we known this method may bring error range. \r\n", "@achandraa Setting default ranges for ops with missing min/max can't possibly be an acceptable solution. \r\n\r\nThe error message clearly states that it should only be used if accuracy isn't important (in what scenario would this be true other than for experimentation?):\r\n\r\n`Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.`", "I have same issue, were anyone able to resolve the issue ?\r\nThanks", "@jianlijianli @ymodak \r\nDo you have any information for resolving this issue? please help\r\nThis issue occurs when I convert quantized model (using quantization aware training) to TFLite ", "same issue here on tf-1.15", "Same issue here. Has anyone managed to fix this? I'm getting a FusedBatchNormV3 error when converting my mobilenetv3 model to TFlite. ", "Same problem with FusedBatchNormV3 - Add - Relu sequence when trying to do quantization-aware training using contrib.quantize", "For fused_batch norm, you should turn off by set `fused=False`. By inspecting the contrib [https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/contrib/quantize/python/quantize.py#L35](url)\r\nThe only way to remove this is to edit the model so that the activation listing in here will be at the last layer lead to quantize activation. You can check this stackoverflow, I have made it work on BatchNorm as an example [https://stackoverflow.com/questions/63681168/batch-normalization-quantize-tensorflow-1-x-does-not-have-minmax-information](url)", "Hi @hahadashi !\r\nIt seems you are using older versions(1.x versions) of Tensorflow. We recommend that you upgrade  your code base to 2.x  versions as many features and bug fixes has been done in newer versions and let us know if the issue still persists in newer versions. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28000\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28000\">No</a>\n"]}, {"number": 27999, "title": "I understand that java should be faster than Python. But not like this.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n```java\r\n//create session, this pb come from python\r\n        ConfigProto config=ConfigProto.newBuilder()\r\n                .setAllowSoftPlacement(true)\r\n                .setLogDevicePlacement(false)\r\n                .clearLogDevicePlacement()\r\n                //.setGpuOptions(GPUOptions.newBuilder().setAllowGrowth(true))\r\n                //.setInterOpParallelismThreads(1)\r\n                .build();\r\n        sess=new Session( graph, config.toByteArray() );\r\n```\r\n```java\r\n        AnjosLog log=new AnjosLog();\r\n        log.begin();\r\n        log.begin2Series(\"create data\");\r\n        float[][][] X=new float[1][this.audio_len][this.audio_feat_len];\r\n        X[0]=data;\r\n        log.stop2Series();\r\n        log.begin2Series(\"create tensor\");\r\n        Tensor x= Tensor.create(X);\r\n        log.stop2Series();\r\n        log.begin2Series(\"use model\");\r\n        Tensor  y = sess.runner().feed(input_var, x).fetch(label_var).run().get(0);\r\n        log.stop2Series();\r\n        log.begin2Series(\"take result\");\r\n        float[][][] result = new float[ (int)y.shape()[0] ][ (int)y.shape()[1] ][ (int)y.shape()[2] ];\r\n        y.copyTo(result);\r\n        log.stop2Series();\r\n        log.stop();\r\n```\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win7 CPU\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):1.8.0 java\r\n- Python version: 3.5.6\r\n- Bazel version (if compiling from source): none\r\n- GCC/Compiler version (if compiling from source): none\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nI use python3.5 predict the same one sample speed:\r\n```\r\nseries start\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 2019-04-20 13:06:18\r\nseries end\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 2019-04-20 13:06:18\r\ntotal time\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 0.24s       0.00min      2019-04-20 13:06:18\r\n````\r\nI use java1.8 predict the same one sample speed:\r\n```\r\nstart time\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u30002019-04-20 12:57:43 924\r\n series start\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 create data 2019-04-20 12:57:43 925\r\n series end\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000         0.00s         0.00min\r\n series start\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 create tensor 2019-04-20 12:57:43 927\r\n series end\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000         0.09s         0.00min\r\n series start\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 use model 2019-04-20 12:57:44 015\r\n  series end\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000         0.69s         0.01min\r\n series start\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 take result 2019-04-20 12:57:44 710\r\n  series end\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000         0.03s         0.00min\r\n end time\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 2019-04-20 12:57:44 738\r\n total time\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000         0.81s         0.01min\r\n```\r\n\r\n**Describe the expected behavior**\r\n**I understand that java should be faster than Python. But not like this.**\r\n\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["i meet the same problem,have you solve it ?", "@whaozl Can you please provide the complete python snippet code to reproduce the issue", "the python source code is \uff1a\r\nhttps://github.com/kerlomz/captcha_platform/blob/master/predict.py\r\n", "the java source code is the example file : LabelImage", "@mengpengfei Could you upgrade to latest version of TF 2.0 and 1.13.1 and check whether the performance issues persists there? Thanks!", "this tf1.13.1 need what keras version?", "i have tried on the version 1.13.1,but it the same as 1.12.0\uff1a\r\nthe java code spend 300+ms\uff0c\r\nsource code\uff1a\r\nList<Tensor<?>> tesnsors=s.runner().feed(\"input\", image).fetch(\"dense_decoded\").run(); \r\n\r\nbut the python api with the same model  only spend 70+ms\r\n", "even if i have use the newest java api  version, it very slowly ", "java api call tensorflow function with jni\uff0cbut why it is so slowly than c++ or python  api", "Hi everyone, \r\n\r\nOften, what slows down the Java API is the reflection operations that occurs when creating the tensors using multidimensional arrays (see [this related issue](https://github.com/tensorflow/tensorflow/issues/8244)). Serializing those arrays directly into a `FloatBuffer` and passing it through [this constructor](https://github.com/tensorflow/tensorflow/blob/c23fd17c3781b21bd3309faa13fad58472c78e93/tensorflow/java/src/main/java/org/tensorflow/Tensor.java#L185) should help in this case.\r\n\r\nAlso I have noticed that the first inference on a given graph session is way slower than the next ones (seems related to some caching operations that occur in the native library). So I don't know if you are already doing it but keeping the same `Session` instance opened for all predictions seems a good solution right now. Please run the session multiple times and verify if performances are improved after the first pass.\r\n\r\nFYI, there is a SIG (Special interest group) for JVM support of TensorFlow into which we are currently discussing those performances issues, particularly the first one, where we are planning to develop a set of utilities to simplify read/write operations on tensor data buffers and improve their performances. If you are interested by the topic, I suggest that you join the group by registering to the [jvm@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/jvm) mailing list.\r\n\r\nPlease keep me posted if after those changes you are still facing very slow performances, thanks!", "@mengpengfei \r\n\r\nDid it resolve for you. I faced similar issue where I have a simple Linear model with feature hashing and exported it using SavedModel.\r\n\r\nWhen I run the inference in python it's around 0.5 msec but Java API is 50msec. Python seems to be 100 time faster.\r\n\r\nI made sure that I didn't include first 100 inferences for both of them and my bottleneck is not creation of tensors in Java (Takes around 30 micro seconds)", "it is not sloved  now,  i use jna to call c++ api", "My bad about my comment about latencies. There was a bug in my python code.  The latencies in both python and java are comparable.\r\n\r\nBoth are around 90 msec. \r\nThe same https://github.com/VowpalWabbit/vowpal_wabbit (linear model with feature hashing) seems to be 500 times faster than tensorflow. On average it was taking 0.1 msec. \r\n\r\nAny insight as to why such a big difference will be helpful", "@mengpengfei by using jni to call c++ api, you've obtained a faster execution? ", "yes  i use c++ to predict  and i make a dll which contains the predict function ,,,and i use jna to call the dll", "@mengpengfei , if you are interested in calling the TF C++ core classes directly from Java, I suggest you take a look at [TF JavaCPP bindings](https://github.com/bytedeco/javacpp-presets/tree/master/tensorflow). \r\n\r\nCC: @saudet\r\n", "Now it would be interesting if you can share some comparable metrics between this approach and when using the Java client instead. When it comes to inference, performance should be comparable (like @abhinavos7a observed) as pretty much all the processing is done in the C++ core library in both cases.\r\n\r\nWhere Java could win is more in the overall performance of your service/application, or in training (I never benchmark it though), as Java code is generally executed faster than Python.", "@mengpengfei So you do the inference in c++ and retrieve the results (bbox data) in Java, then proceed with further processing? Can you share how to do it :( \r\n\r\n@karllessard I tried what you recommended that is using the same Session instance for all predictions and it improved the performance a little bit to 9 fps now (with GPU help : GTX 1070), which is still incredibly slow from the real-time goal. ", "@dreistheman I just ran a little test on my side too and like @abhinavos7a , I observe that the inference time (including the creation of initial tensors the way I suggested) is pretty much the same in both cases:\r\n\r\n10000 iterations, CPU-only:\r\n* Java: 32455117 msecs\r\n* Python: 36309922 msecs\r\n\r\nI'm very curious to see what causes this latency in your case, do you have a piece of code to share?", "Thanks for replying @karllessard \r\n\r\nI used as guide this repository for YOLO Tensorflow in Java: https://github.com/szaza/tensorflow-example-java. \r\n\r\nThis is the class directly responsible for box predictions on the video image frame. I've placed corresponding comments for ease of understanding. I've done my observations and the **Session execution** inside `executeYoloGraph()` method, which itself is inside `detect()`, is the one causing the bottleneck on the performance.\r\n\r\n\r\n```\r\n/**\r\n * ObjectDetector class to detect objects using pre-trained models with TensorFlow Java API.\r\n */\r\npublic class ObjectDetector {\r\n    \r\n    private final static Logger LOGGER = LoggerFactory.getLogger(ObjectDetector.class);\r\n\r\n    //global graph and session variables for reuse\r\n    private byte[] GRAPH_DEF;\r\n    private List<String> LABELS;\r\n    Graph yoloGraph;\r\n    Session yoloSession;\r\n    \r\n    public ObjectDetector() {\r\n        //instantiate the global variables for use on all image frames.\r\n        try {\r\n\r\n            GRAPH_DEF = IOUtil.readAllBytesOrExit(GRAPH_FILE);\r\n            LABELS = IOUtil.readAllLinesOrExit(LABEL_FILE);\r\n            yoloGraph = new Graph();\r\n            yoloGraph.importGraphDef(GRAPH_DEF); //import the graph .pb file just once \r\n            yoloSession = new Session(yoloGraph);\r\n            \r\n        } catch (ServiceException ex) {\r\n            LOGGER.error(\"Download one of my graph file to run the program! \\n\" +\r\n                    \"You can find my graphs here: https://drive.google.com/open?id=1GfS1Yle7Xari1tRUEi2EDYedFteAOaoN\");\r\n        }\r\n\r\n    }\r\n\r\n    /**\r\n     * Detect objects on the given image\r\n     * @param Mat the image from VideoCapture\r\n     */\r\n     //I just use instance.detect() in my video iteration code (using OpenCV)\r\n    public List<Recognition> detect(Mat image){\r\n        \r\n        MatOfByte matByte = new MatOfByte();\r\n        Imgcodecs.imencode(\".png\", image, matByte); \r\n        byte[] imByteArray = matByte.toArray();\r\n        \r\n        try (Tensor<Float> normalizedImage = normalizeImage(imByteArray)) {\r\n        //I'll provide below the link to the YOLOClassifier class from the reference repository as I've not changed it except for the anchors[] global variable\r\n            List<Recognition> recognitions = YOLOClassifier.getInstance().classifyImage(executeYOLOGraph(normalizedImage), LABELS);\r\n            printToConsole(recognitions);\r\n            return recognitions;\r\n        }\r\n        \r\n    }\r\n    \r\n\r\n    /**\r\n     * Pre-process input. It resize the image and normalize its pixels\r\n     * @param imageBytes Input image\r\n     * @return Tensor<Float> with shape [1][416][416][3]\r\n     */\r\n    //tried observing how quick this method executes and it was ordinarily instantaneous\r\n    private Tensor<Float> normalizeImage(final byte[] imageBytes) {\r\n        try (Graph graph = new Graph()) {\r\n            GraphBuilder graphBuilder = new GraphBuilder(graph);\r\n\r\n            final Output<Float> output =\r\n                graphBuilder.div( // Divide each pixels with the MEAN\r\n                    graphBuilder.resizeBilinear( // Resize using bilinear interpolation\r\n                            graphBuilder.expandDims( // Increase the output tensors dimension\r\n                                    graphBuilder.cast( // Cast the output to Float\r\n                                            graphBuilder.decodeJpeg(\r\n                                                    graphBuilder.constant(\"input\", imageBytes), 3),\r\n                                            Float.class),\r\n                                    graphBuilder.constant(\"make_batch\", 0)),\r\n                            graphBuilder.constant(\"size\", new int[]{SIZE, SIZE})),\r\n                    graphBuilder.constant(\"scale\", MEAN));\r\n\r\n            try (Session session = new Session(graph)) {\r\n                return session.runner().fetch(output.op().name()).run().get(0).expect(Float.class);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Executes graph on the given preprocessed image\r\n     * @param image preprocessed image\r\n     * @return output tensor returned by tensorFlow\r\n     */\r\n\r\n    private float[] executeYOLOGraph(final Tensor<Float> image) {\r\n\r\n        //This is the one that takes too long to finish.\r\n        //I'm using the global graph and session variables up top so they are not created \r\n        //in every iteration. It's now simplified to just the execution of the session.\r\n\r\n        Tensor<Float> result = yoloSession.runner().feed(\"input\", image).fetch(\"output\").run().get(0).expect(Float.class);\r\n        float[] outputTensor = new float[YOLOClassifier.getInstance().getOutputSizeByShape(result)];\r\n        FloatBuffer floatBuffer = FloatBuffer.wrap(outputTensor);\r\n        result.writeTo(floatBuffer);\r\n        return outputTensor;\r\n          \r\n    }\r\n\r\n    /**\r\n     * Prints out the recognize objects and its confidence\r\n     * @param recognitions list of recognitions\r\n     */\r\n    private void printToConsole(final List<Recognition> recognitions) {\r\n        for (Recognition recognition : recognitions) {\r\n            LOGGER.info(\"Object: {} - confidence: {}\", recognition.getTitle(), recognition.getConfidence());\r\n        }\r\n    }\r\n}\r\n```\r\nI just call the `detect()` method on my main class passing in the `Mat` image frame read by OpenCV's `VideoCapture` class. The `YoloClassifier` class used by this method that just sorts the output from the Graph execution: https://github.com/szaza/tensorflow-example-java/blob/master/src/main/java/edu/ml/tensorflow/classifier/YOLOClassifier.java. \r\n\r\nI'm comparing this with Darkflow's `TFNet.camera()` function that runs the predictions in 37 fps on the same video input I use on my Java Application. (`TFNet `class -> https://github.com/thtrieu/darkflow/blob/master/darkflow/net/help.py)\r\n\r\n", "@dreistheman You're going to get much better performance without copying your data multiple times:\r\nhttp://bytedeco.org/news/2018/07/17/bytedeco-as-distribution/", "Thanks @dreistheman , just quickly like that I've also noticed that you don't free up the tensor returned by `yoloSession.runner()`, I don't know how you are running your benchmark loops but you might face memory issues if you don't close it (just declaring it as a `try` resource will do the job).\r\n\r\nIn addition, sorry if this is out-of-topic as it is not related to performances, but since TF 1.10 you don't need those custom `graphBuilder` anymore if that can simplify your life, you can simply use the `Ops` API available in the Java client to build your preprocessing graph, see [this doc](https://www.javadoc.io/doc/org.tensorflow/libtensorflow/1.13.1). For example:\r\n```\r\nOps tf = Ops.create(graph);\r\nPlaceholder<UInt8> image = tf.withName(GRAPH_INPUT).placeholder(UInt8.class);\r\nOperand<Float> normalizedImage = tf.div(\r\n        tf.resizeBilinear(\r\n                tf.expandDims(image, tf.constant(0)),\r\n                tf.constant(new int[] {SIZE, SIZE}\r\n        ),\r\n        tf.constant(MEAN)\r\n);\r\n// `imageBytes` is a tensor containing bytes of an image already decoded but we could have use `tf.decodeJpeg()` as well\r\nreturn session.runner().feed(image, imageBytes).fetch(normalizedImage).run().get(0).expect(Float.class);\r\n```", "@karllessard I've now put the output tensor inside a try-with-resources block, performance is still the same (EDIT: My bad, it's significantly improved now at 16fps! Thank you so much\ud83d\udcaf). It's puzzling why Darkflow's implementation of YOLO (in python) is significantly quicker (37fps). My program does further lightweight post-processing after the YOLO prediction that when tested with a basic thresholding for object detection (instead of YOLO), is very quick and actually even visibily faster than the normal speed/frame rate of the input video. BTW, thanks for sharing the `Ops` API as it definitely simplifies the graph building. \r\n\r\n@saudet I'll try to place the detect method inside a `PointerScope` try resource as shown in your link. \r\n", "@dreistheman  Have you solved this problem\uff1f", "I face the same problem. I use a dll to integrate tensorflow(2.0) through C API, then use JNA to call the dll. The performance is mush slow than that if I use exe to call the dll. Even the session creation is much slow and memory consuming more.", "> My bad about my comment about latencies. There was a bug in my python code. The latencies in both python and java are comparable.\r\n> \r\n> Both are around 90 msec.\r\n> The same https://github.com/VowpalWabbit/vowpal_wabbit (linear model with feature hashing) seems to be 500 times faster than tensorflow. On average it was taking 0.1 msec.\r\n> \r\n> Any insight as to why such a big difference will be helpful\r\n\r\n\r\nThe latencies are now comparable to VW model. I was passing dense features to my Linear model than sparse features, which was resulting in high latencies.\r\n\r\nBefore:\r\n`\r\ncategory_column = tf.feature_column.categorical_column_with_hash_bucket(key, hash_size)\r\ntf.feature_column.indicator_column(category_column)\r\n` \r\nAfter:\r\n`\r\ntf.feature_column.categorical_column_with_hash_bucket(key, hash_size)\r\n`\r\n\r\nAccording to this [tf source code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/feature_column/feature_column_v2.py)\r\n\r\nSparse features can be fed directly into linear models. They behave like an indicator column but with an efficient implementation.\r\n", "@zychen2016 Not yet as I went to a different project that time but just now I returned to this same detection + observation project. Have you found a way to make it execute at reasonable speed in Java?", ">just quickly like that I've also noticed that you don't free up the tensor returned by `yoloSession.runner()`, I don't know how you are running your benchmark loops but you might face memory issues if you don't close it (just declaring it as a `try` resource will do the job).\r\n\r\n@karllessard Cloud you please elaborate more about this statement? We have the same situation in our Scala code where we feed and fetch from a graph:\r\n```scala\r\nval calculated = tensorflow.getSession(configProtoBytes = configProtoBytes).runner\r\n      .feed(tokenIdsKey, tensors.createTensor(shrink))\r\n      .fetch(embeddingsKey)\r\n      .run()\r\n``` \r\n> getSession just checks whether the session exists or it should read/create it\r\n\r\nWe clear the `tensors` after each prediction, but I am not sure we close the session every time. This code is in Apache Spark where it's being called on each row of the DataFrame.", "> We clear the tensors after each prediction\r\n\r\n@maziyarpanahi: so you mean that you programatically call `calculated.forEach(Tensor::close)` or something like after reading the computed data?\r\n\r\nFor the session, I just noticed that on the first inference, at that time (I think it was on 1.13), there is some initialization going on in the C++ core library that takes very long and that reusing the same session to run all inferences was preventing this initialization to happen more than once. \r\n\r\nI unfortunately did not find the time yet to find out what exactly was taking so much time. Meanwhile, I can probably give some cues to anyone interested to dig into this further. ", "@karllessard Sorry for the delay.\r\n> so you mean that you programatically call calculated.forEach(Tensor::close) or something like after reading the computed data?\r\n\r\nYes, we have this function which after each prediction (whether one sentence or multiple sentences) will clear the tensors:\r\n\r\n```scala\r\ndef clearTensors(): Unit = {\r\n    for (tensor <- tensors) {\r\n      tensor.close()\r\n    }\r\n\r\n    tensors.clear()\r\n  }\r\n```\r\nThe prediction, session and clearing tensors happen here:\r\nhttps://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/ml/tensorflow/TensorflowBert.scala#L27\r\n\r\nWe have the same strategy for other TF graphs (NLP-NER), but this one is for Bert and it consumes a large amount of memory and it crashes in the cluster when data grows over a few millions of rows.\r\n\r\nI followed your advice for performance and replace `Tensor.create(obj)` with `Tensor.create(Array(shape, batch), buf)`. It didn't help with the memory consumption in our Bert implementation that is why your comment about memory and session caught my eyes.\r\n\r\nDo you have any advice for memory management when it comes to Java implementation of the TF graph involving session, tensors, etc. when it's in a distributed environment like Apache Spark and it will be called on each row?\r\n", "Sorry @maziyarpanahi, I've just noticed your reply as well,\r\n\r\n> Do you have any advice for memory management when it comes to Java implementation of the TF graph involving session, tensors, etc. when it's in a distributed environment like Apache Spark and it will be called on each row?\r\n\r\nUnfortunately no. Afaik, only instances of `Tensor`, `Session` and `Graph` should be closed explicitly (or via `try-with-resources`) and could lead to memory leaks if they are left opened. I've found in the code where you take care of the tensors but didn't find how you close the session and graph... but those could remain opened for the lifetime of your application, as long as you don't create new ones every now and then. \r\n\r\nNow I'm suggesting to keep the session open to avoid that slow-first-inference I have noticed but maybe doing so create some leaks in the core? In the original examples, the session is always closed after running a graph. Might be interesting to see how your app react in both scenarios?", "@karllessard This was on TF java `1.8.0`. Do you think that it is still valid for TF 2.5? Can we close this?", "I don\u2019t recall seeing this initial delay on the first inference with the new client, I\u2019d be comfortable closing it yes. Thanks!", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27999\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27999\">No</a>\n"]}, {"number": 27998, "title": "tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes ", "body": "I'm training some yolo models using \r\n\r\n> qqwweee/keras-yolo3\r\n\r\nWhen I trained with 50 epochs, the test can be done although the results is bad.\r\nSo I trained with 150 epochs, and when I want to test with this model, I got the following ... (it's not an error but like an error):\r\n\r\nInput image filename:eagle.jpg\r\n(416, 416, 3)\r\n2019-04-20 12:33:44.137176: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\r\n2019-04-20 12:33:44.140305: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n2019-04-20 12:33:44.143018: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\r\n2019-04-20 12:33:44.145718: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n2019-04-20 12:33:44.149139: E tensorflow/core/common_runtime/bfc_allocator.cc:246] tried to allocate 0 bytes\r\n2019-04-20 12:33:44.151644: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n2019-04-20 12:33:44.154246: E tensorflow/core/common_runtime/bfc_allocator.cc:381] tried to deallocate nullptr\r\n2019-04-20 12:33:44.157496: E tensorflow/core/common_runtime/bfc_allocator.cc:381] tried to deallocate nullptr\r\n2019-04-20 12:33:44.160937: E tensorflow/core/common_runtime/bfc_allocator.cc:381] tried to deallocate nullptr\r\nFound 0 boxes for img\r\n6.07202067316063\r\n\r\nI think it's something wrong in TF.\r\nenvironment: Anaconda python(3.6.8), keras 2.1.5, tensorflow (cpu) 1.10.0.\r\nI use \"qqwweee/keras-yolo3\" and made a train data as its requirement like follows :\r\n\r\n> Generate your own annotation file and class names file.\r\nOne row for one image;\r\nRow format: image_file_path box1 box2 ... boxN;\r\nBox format: x_min,y_min,x_max,y_max,class_id (no space).\r\nFor VOC dataset, try python voc_annotation.py\r\nHere is an example:\r\npath/to/img1.jpg 50,100,150,200,0 30,50,200,120,3\r\npath/to/img2.jpg 120,300,250,600,2\r\n...", "comments": ["Please fill in the information of your environment so we could know how to reproduce this error.\r\n\r\nThanks.", "> Please fill in the information of your environment so we could know how to reproduce this error.\r\n> \r\n> Thanks.\r\n\r\nI updated the problem with environment.", "Could you try to install the latest tf-nightly package? I believe this issue has been fixed.", "But if I use TF 1.13.1,  there will be another problem. See #27906", "Could you try tf-nightly? It helps us to reproduce your problem.\r\n\r\nWe cannot fix your issue if we cannot reproduce it.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27997, "title": "Import Error from Keras import ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home\r\n- TensorFlow installed from (source or binary): pip install tensorflow\r\n- TensorFlow version: tensorflow-1.13.1\r\n- Python version: python 3.7.0\r\n- Installed using virtualenv? pip? conda?: pip install tensorflow\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nUsing TensorFlow backend.\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>()\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    242         else:\r\n--> 243             return load_dynamic(name, filename, file)\r\n    244     elif type_ == PKG_DIRECTORY:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    342             name=name, loader=loader, origin=path)\r\n--> 343         return _load(spec)\r\n    344 \r\n\r\nImportError: DLL load failed: Uma rotina de inicializa\u00e7\u00e3o da biblioteca de v\u00ednculo din\u00e2mico (DLL) falhou.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-21-1090e364ba0e> in <module>()\r\n----> 1 from keras import Model , Sequential\r\n      2 #from keras.model import Sequential\r\n      3 from keras.layers import Dense\r\n      4 from keras.optimizers import SGD\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py in <module>()\r\n      1 from __future__ import absolute_import\r\n      2 \r\n----> 3 from . import utils\r\n      4 from . import activations\r\n      5 from . import applications\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py in <module>()\r\n      4 from . import data_utils\r\n      5 from . import io_utils\r\n----> 6 from . import conv_utils\r\n      7 \r\n      8 # Globally-importable utils.\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py in <module>()\r\n      7 from six.moves import range\r\n      8 import numpy as np\r\n----> 9 from .. import backend as K\r\n     10 \r\n     11 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py in <module>()\r\n     87 elif _BACKEND == 'tensorflow':\r\n     88     sys.stderr.write('Using TensorFlow backend.\\n')\r\n---> 89     from .tensorflow_backend import *\r\n     90 else:\r\n     91     # Try and load external backend.\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in <module>()\r\n      3 from __future__ import print_function\r\n      4 \r\n----> 5 import tensorflow as tf\r\n      6 from tensorflow.python.framework import ops as tf_ops\r\n      7 from tensorflow.python.training import moving_averages\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=g-bad-import-order\r\n---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     25 \r\n     26 from tensorflow._api.v1 import app\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Uma rotina de inicializa\u00e7\u00e3o da biblioteca de v\u00ednculo din\u00e2mico (DLL) falhou.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nfrom keras import Model , Sequential\r\nfrom keras.layers import Dense\r\nfrom keras.optimizers import SGD\r\n\r\nI also tried with this code and got the same error...\r\nfrom keras.model import Sequential\r\nfrom keras.layers import Dense\r\nfrom keras.optimizers import SGD\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nI have keras version 2.2.4 installed with pip", "comments": ["If you're following Deep Learning A-Z course, than you can simply install versions that they are using.\r\nI uninstalled all new versions of keras, theano and tensorflow and installed the older ones. It helped me to solve the problem.\r\nI tried the other ways, but they did not worked for me. I think the main problem is my Core i7 860 CPU, wich do not support AVX instructions. And starting from tensorflow 1.6. AVX is need to be supported to work properly.", "@buleo Tensorflow is not compatible with python 3.7. I recommend you switch to python 3.6. Request you to follow the link https://www.tensorflow.org/install/source_windows#cpu", "Big problem that wasted a week of mine\r\nsmall solution\r\nif keras is giving import problem and you are facing \"no module named keras\" even if you have installed it.\r\n1. just upgrade your pip by:\r\npython -m pip install \u2013upgrade pip\r\n\r\nre install upgraded keras and tensorflow by:\r\n2. pip install keras\r\n\r\n3. pip install tensorflow\r\n\r\nHope it will solve the problem. If not, try upgrading your conda (Anaconda) and then do steps 1 to 3 above again", "I tried to invesigate this topic a little more.\r\nSo for me installing python 3.6.x does not solve the problem. But installing python 3.6.x  + tensorflow 1.5 works really well. So, if the first one does not help, try both.\r\nOther packages, such as Keras or Theano can be up to date, they have no effect in this case.", "@buleo Is this resolved? If it was resolved by following @Qaazi  and @helcril , then close the issue. thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!"]}, {"number": 27996, "title": "LeakyRelu support in contrib.quantize", "body": "**System information**\r\n- TensorFlow version (you are using): 1.13.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI am trying to create an eval graph with fake quantization nodes, from a checkpoint file, of a tensorflow implementation of YoloV3. My goal is to eventually convert this to a UINT8 (fully quantized) .tflite inference model using TOCO.\r\n\r\nMy code snippet is like the following -\r\n\r\n        with tf.variable_scope('yolov3'):\r\n            boxes, confs, probs = model.forward(inputs, is_training=False)\r\n\r\n        scores = confs * probs\r\n        print(\"=>\", boxes.name[:-2], scores.name[:-2])\r\n        cpu_out_node_names = [boxes.name[:-2], scores.name[:-2]]\r\n        saver = tf.train.Saver(var_list=tf.global_variables(scope='yolov3'))\r\n\r\n        saver.restore(sess, flags.ckpt_file)\r\n        tf.contrib.quantize.create_eval_graph(input_graph=graph)\r\n        sess.run(tf.global_variables_initializer())\r\n        print('=> checkpoint file restored from ', flags.ckpt_file)\r\n        utils.freeze_graph(sess, './experiment/yolov3_FQ.pb', cpu_out_node_names)\r\n\r\nThe tf.contrib.quantize.create_eval_graph(...) call itself finishes with no error, but when I run TOCO to convert the graph to UINT8 tflite, it complains that LeakyRelu doesn't have min/max parameters.\r\n\r\nFollowing is my TOCO command -\r\n\r\nbazel --output_user_root=/local/mnt/workspace/rganguly/deep_learning/bazel_new/build run --config=opt tensorflow/lite/toco:toco -- \\\r\n--output_file=/local/mnt/workspace/rganguly/deep_learning/live/yolov3/yolov3_.tflite \\\r\n--input_file=/local/mnt/workspace/rganguly/deep_learning/live/yolov3/tensorflow-yolov3/experiment/yolov3_fake_quant.pb \\\r\n--input_shapes=1,416,416,3 \\\r\n--input_arrays=Placeholder \\\r\n--output_arrays='yolov3/concat_3','mul' \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--mean_values=128 \\\r\n--std_dev_values=127 \\\r\n\r\nAnd following is the error I get -\r\n\r\n2019-04-19 16:56:59.708619: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1613 operators, 2394 arrays (0 quantized)\r\n2019-04-19 16:56:59.747329: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1613 operators, 2394 arrays (0 quantized)\r\n2019-04-19 16:57:06.761701: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 286 operators, 471 arrays (1 quantized)\r\n2019-04-19 16:57:06.767392: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 286 operators, 471 arrays (1 quantized)\r\n2019-04-19 16:57:06.770164: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 211 operators, 396 arrays (1 quantized)\r\n2019-04-19 16:57:06.772654: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 211 operators, 396 arrays (1 quantized)\r\n2019-04-19 16:57:06.775354: F tensorflow/lite/toco/tooling_util.cc:1708] Array yolov3/darknet-53/Conv/LeakyRelu, which is an input to the Pad operator producing the output array yolov3/darknet-53/Pad, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\r\n\r\n\r\n**Will this change the current api? How?**\r\n- NO\r\n\r\n**Who will benefit with this feature?**\r\n- Anyone who has a LeakyRelu in the tensorflow graph and wants to transform it to a fully quantized/UINT8 .tflite model. In other words, YoloV3 cannot be converted to a UINT8 .tflite model without this support.\r\n\r\n\r\n\r\n**Any Other info.**\r\nThere are multiple other issues I faced in TOCO while converting this model, but I will summarize them in another ticket.", "comments": ["@myworldraj , i think the problem is that quantization support for LeakyRelu is not supported in tflite, i have raised on PR for the same #27061, kindly test with this PR and let me know if you were able to succeed.\r\n\r\nRegards\r\nAmit", "@myworldraj : Please have a look and let us know if that helps.Thanks!\r\n", "@amitsrivastava78, there are two issues here -\r\n\r\n1. Lack of LeakyRelu support in tf.contrib.quantize.create_training_graph(...) and tf.contrib.quantize.create_eval_graph(...), which in turn calls quantize.Quantize(), for which **this ticket has been raised**\r\n\r\n2. Lack of quantized LeakyRelu support in the TFLite inference path, for which I had already found your commit, and have integrated it in my workspace.\r\n\r\nTo help you understand in easier terms - we can **only** use your commit, once we first create a **quantization friendly** graph in tensorflow. That can only happen, when we add support of LeakyRelu in Quantize(). Then TOCO or tflite_convert can correctly convert it to a fully quantized (i.e. UINT8) .tflite model, That is what I am looking for as a resolution to this ticket.\r\n\r\nI hope this clarifies.", "@myworldraj , thanks for the clarification, I would love to help you out can you please share the code and other details, so i can simulate it on my workstation and give the solution to you ASAP.\r\n\r\nRegards\r\nAmit", "@amitsrivastava78,\r\n\r\nI am using tensorflow 1.13.1, built from source.\r\n\r\nBlock A steps\r\n=================================\r\n- Download the source code from https://github.com/YunYang1994/tensorflow-yolov3\r\n- Use the modified file: convert_weight_raj.txt (rename to .py)\r\n[convert_weight_raj.txt](https://github.com/tensorflow/tensorflow/files/3113557/convert_weight_raj.txt)\r\n- Use the modified file: yolov3.txt (rename it to .py)\r\n[yolov3.txt](https://github.com/tensorflow/tensorflow/files/3113564/yolov3.txt)\r\n- run python3 convert_weight_raj.py --freeze, which will save the .pb with fake quant nodes.\r\n=================================\r\n\r\nBlock B steps\r\n=================================\r\n- run TOCO, like \r\nbazel  run --config=opt tensorflow/lite/toco:toco -- \\\r\n--output_file=yolov3.tflite \\\r\n--input_file=yolov3_FQ.pb \\\r\n--input_shapes=1,416,416,3 \\\r\n--input_arrays=Placeholder \\\r\n--output_arrays='yolov3/concat_3','mul' \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--mean_values=128 \\\r\n--std_dev_values=127 \\\r\n\r\n- When you run TOCO first time, you will see multiple errors reported by TOCO, because there are many issues with TOCO. I did the following steps to work around with most issues -\r\n\r\n  1. Integrated your commit\r\n  2. Made changes to ignore lack of support for Cast operator (basically made it pass-through)\r\n  3. Added SplitV and LeakyRelu to the list of supported quantizable ops\r\n\r\n- I am attaching a list of files I changed, in addition to integrating your commit, to make TOCO work -\r\n\r\n[TOCO_changes.zip](https://github.com/tensorflow/tensorflow/files/3113635/TOCO_changes.zip)\r\n\r\n- After you rebuild TOCO and run it again as above, you will come to the **real issue** of this ticket, which is - TOCO will complain that LeakyRelu doesn't have a min/max. \r\n\r\n- So we will need to go back to the drawing board (to tensorflow/contrib/quantize/python/), and figure out how to add support for LeakyRelu activation, such that it satisfies TOCO\r\n", "@myworldraj thanks for sharing the details, was able to reproduce the error, but since i will be on travel till next Wednesday, it might take some time for me to comeback with solution for you.\r\n\r\nRegards\r\nAmit", "@amitsrivastava78,\r\n\r\nWanted to give you a few more inputs - I did a quick experimentation and added LeakyRelu to the list of supported activation-s in the following places in tensorflow/contrib/quantize/python/quantize.py -\r\n- _ACTIVATION_TYPES = {'Relu', 'Relu6', 'LeakyRelu', 'Identity'}\r\n- _RELU_TYPES = {'Relu', 'Relu6', 'LeakyRelu'}\r\n- _VALID_ACTIVATION_OP = {'Relu', 'Relu6', 'LeakyRelu'}\r\n\r\nNow, TOCO is happy (at least didn't complain) and I get proper FakeQuant... nodes after LeakyRelu. But now there is another problem - since TOCO cannot possibly fuse the LeakyReuly activation with the preceding op, the Add (which is a preceding op to LeakyRelu in this graph) is dangling without a min/max and TOCO is erroring out.\r\n\r\nLooks like we need to take a comprehensive look on how to insert FakeQuant nodes to infusable activations, and make wholesome changes in both the Quantize pass and the TOCO pass.", "Is there any update on this issue?", "We don't plan to add more new features to the quantization rewriter. Please stay tuned for our new keras based quantization aware training API.\r\n\r\nIf you want to get a fully quantized model, you can take a look at our post-training integer quantization for now:\r\nhttps://medium.com/tensorflow/tensorflow-model-optimization-toolkit-post-training-integer-quantization-b4964a1ea9ba\r\n\r\nAlso, there has been a lot of asks for LeakyRelu quantization support. We'll work on that shortly. Thanks!", "@liyunlu0618 do you have any links/info you can provide regarding that new Keras API, or where we can follow its development if not yet available? We're trying to do quantization-aware training in 2.0, where the `tf.contrib.quantize` functions are no longer available."]}, {"number": 27995, "title": "Fix #27994: compat.as_bytes should support bytearray", "body": "I made these changes manually in a local venv and was then able to write to a GFile handle from a fastavro Writer, which writes out `bytearray`s.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27995) for more info**.\n\n<!-- need_sender_cla -->", "@erwa please sign CLA", "I'm speaking with my legal team and just need to figure out a few details before signing the CLA. Hope to get back to you later this week.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27995) for more info**.\n\n<!-- ok -->", "@googlebot I signed it!", "@rthadur , I've signed the CLA. Could you help review the patch?", "Thanks for the review, @mihaimaruseac. I took a look at some of the failed CI builds and the failures look unrelated. Can you merge this PR?", "There's some infrastructure changes going on at the moment. Will merge when resolved.", "Thanks, Mihai.", "Can you solve conflict?", "Rebased on `master` and resolved conflicts."]}, {"number": 27994, "title": "compat.as_bytes should support bytearray", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, `tensorflow.python.util.compat.as_bytes` accepts `bytes` but not `bytearray`. This causes issues when trying to write a `bytearray` to `GFile`, which internally calls `compat.as_bytes`.\r\n\r\n`compat.as_bytes` should support `bytearray` to improve usability.\r\n\r\n**Will this change the current api? How?** This change is backward-compatible.\r\n\r\n**Who will benefit with this feature?** Supporting `bytearray` in `compat.as_bytes` helps in use cases where a `GFile` file handle is wrapped in some other class, such as a fastavro `Writer` which writes out `bytearray` to the file handle.\r\n\r\n**Any Other info.**\r\n", "comments": []}, {"number": 27993, "title": "[TF2.0] Incorect Loss calculation in `keras.Model.evaluate` when last batch size is different.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): TF2.0 Alpha\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nThe loss value returned from `Keras.Model.evaluate()` is an arithmetic average over losses for each batch. However, when the last batch has a smaller batch size than previous batches (e.g. a dataset has 101 examples, with batch-size=10), the calculation is incorrect because it will mistakenly give higher weight to the last batch's loss.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27993\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27993\">No</a>\n"]}, {"number": 27992, "title": "[TF 2.0] Issue with TPUStrategy / initialize_tpu_system", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installed from (source or binary): !pip install tensorflow-gpu==2.0.0-alpha0\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.6.7 (Colab) \r\n\r\n**Describe the current behavior**\r\n\r\nError occurs when trying to instantiate a simple Keras model running on TPU on Colab, using TPUStrategy.\r\n\r\nIt seems that there is an internal problem regarding the worker name: \r\n\r\n- if WORKER_NAME is set to 'worker', then an exception is raised during the call to initialize_tpu_system(): \"/job:tpu_worker/replica:0/task:1/device:CPU:0 unknown device.\"\r\n\r\n- if WORKER_NAME is set to 'tpu_worker', the strategy is properly initialized, but another exception is raised later when creating the Keras model: \"Error copying tensor to device: /job:worker/replica:0/task:0/device:TPU:0\"\r\n\r\nI have read issue #26513 to place a call to experimental_connect_to_host() before calling initialize_tpu_system(), but it does not help.\r\n\r\n\r\n\r\n```\r\n!pip install tensorflow-gpu==2.0.0-alpha0\r\n\r\nimport tensorflow as tf\r\nimport os\r\nimport sys\r\n\r\nTPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\r\nWORKER_NAME='tpu_worker'\r\n\r\ntf.config.experimental_connect_to_host(TPU_WORKER, WORKER_NAME) \r\n\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(TPU_WORKER)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\r\ndevices=tf.config.experimental_list_devices()\r\nprint(*devices,sep=\"\\n\")\r\n\r\nwith strategy.scope():\r\n  \r\n  model = tf.keras.Sequential([\r\n      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\r\n      tf.keras.layers.MaxPooling2D(),\r\n      tf.keras.layers.Flatten(),\r\n      tf.keras.layers.Dense(64, activation='relu'),\r\n      tf.keras.layers.Dense(10, activation='softmax')\r\n  ])\r\n\r\n  model.compile(loss='sparse_categorical_crossentropy',\r\n                optimizer=tf.keras.optimizers.Adam(),\r\n                metrics=['accuracy'])\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nModel should be properly instantiated.\r\n\r\n**Code to reproduce the issue**\r\n\r\nSee above.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nException when WORKER_NAME='worker':\r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n\r\n<ipython-input-3-2725ffed0ef5> in <module>()\r\n     10 \r\n     11 resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TPU_WORKER)\r\n---> 12 tf.tpu.experimental.initialize_tpu_system(resolver)\r\n     13 strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n     14 devices=tf.config.experimental_list_devices()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py in initialize_tpu_system(cluster_resolver)\r\n     91     with ops.device(get_first_tpu_host_device(cluster_resolver)):\r\n     92       output = tpu_functional_ops.TPUPartitionedCall(\r\n---> 93           args=[], device_ordinal=0, Tout=[dtypes.string], f=func_name)\r\n     94     serialized_topology = output[0].numpy()\r\n     95   else:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_tpu_ops.py in tpu_partitioned_call(args, device_ordinal, Tout, f, name)\r\n   5606       else:\r\n   5607         message = e.message\r\n-> 5608       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n   5609   # Add nodes to the TensorFlow graph.\r\n   5610   if not isinstance(Tout, (list, tuple)):\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: /job:tpu_worker/replica:0/task:1/device:CPU:0 unknown device.\r\n```\r\n\r\nException when WORKER_NAME='tpu_worker':\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n\r\n<ipython-input-4-4fe0e3235d99> in <module>()\r\n     22       tf.keras.layers.Flatten(),\r\n     23       tf.keras.layers.Dense(64, activation='relu'),\r\n---> 24       tf.keras.layers.Dense(10, activation='softmax')\r\n     25   ])\r\n     26 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    454     self._setattr_tracking = False  # pylint: disable=protected-access\r\n    455     try:\r\n--> 456       result = method(self, *args, **kwargs)\r\n    457     finally:\r\n    458       self._setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py in __init__(self, layers, name)\r\n    106     if layers:\r\n    107       for layer in layers:\r\n--> 108         self.add(layer)\r\n    109 \r\n    110   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    454     self._setattr_tracking = False  # pylint: disable=protected-access\r\n    455     try:\r\n--> 456       result = method(self, *args, **kwargs)\r\n    457     finally:\r\n    458       self._setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)\r\n    167           # and create the node connecting the current layer\r\n    168           # to the input layer we just created.\r\n--> 169           layer(x)\r\n    170           set_inputs = True\r\n    171 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    592           # Build layer if applicable (if the `build` method has been\r\n    593           # overridden).\r\n--> 594           self._maybe_build(inputs)\r\n    595           # Explicitly pass the learning phase placeholder to `call` if\r\n    596           # the `training` argument was left unspecified by the user.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in _maybe_build(self, inputs)\r\n   1711     # Only call `build` if the user has manually overridden the build method.\r\n   1712     if not hasattr(self.build, '_is_default'):\r\n-> 1713       self.build(input_shapes)\r\n   1714     # We must set self.built since user defined build functions are not\r\n   1715     # constrained to set self.built.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py in build(self, input_shape)\r\n    163         constraint=self.kernel_constraint,\r\n    164         trainable=True,\r\n--> 165         dtype=self.dtype)\r\n    166     if self.use_bias:\r\n    167       self.bias = self.add_weight(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\r\n    375         collections=collections,\r\n    376         synchronization=synchronization,\r\n--> 377         aggregation=aggregation)\r\n    378     backend.track_variable(variable)\r\n    379 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\r\n    620     new_variable = getter(\r\n    621         name=name, shape=shape, dtype=dtype, initializer=initializer,\r\n--> 622         **kwargs_for_getter)\r\n    623 \r\n    624     # If we set an initializer and the variable processed it, tracking will not\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\r\n    150       collections=collections,\r\n    151       synchronization=synchronization,\r\n--> 152       aggregation=aggregation)\r\n    153   return v\r\n    154 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    210   def __call__(cls, *args, **kwargs):\r\n    211     if cls is VariableV1:\r\n--> 212       return cls._variable_v1_call(*args, **kwargs)\r\n    213     elif cls is Variable:\r\n    214       return cls._variable_v2_call(*args, **kwargs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation)\r\n    173         use_resource=use_resource,\r\n    174         synchronization=synchronization,\r\n--> 175         aggregation=aggregation)\r\n    176 \r\n    177   def _variable_v2_call(cls,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in getter(**kwargs)\r\n     56   \"\"\"To avoid capturing loop variables.\"\"\"\r\n     57   def getter(**kwargs):\r\n---> 58     return captured_getter(captured_previous, **kwargs)\r\n     59   return getter\r\n     60 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in creator_with_resource_vars(*args, **kwargs)\r\n    821       kwargs[\"use_resource\"] = True\r\n    822       kwargs[\"distribute_strategy\"] = strategy\r\n--> 823       return self._create_variable(*args, **kwargs)\r\n    824 \r\n    825     def distributed_getter(getter, *args, **kwargs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _create_variable(self, next_creator, *args, **kwargs)\r\n    439     return _create_tpu_mirrored_variable(\r\n    440         self._container_strategy(), device_map, logical_device,\r\n--> 441         _real_mirrored_creator, *args, **kwargs)\r\n    442 \r\n    443   def _reduce_to(self, reduce_op, value, destinations):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _create_tpu_mirrored_variable(strategy, device_map, logical_device, real_mirrored_creator, *args, **kwargs)\r\n    101   with tape.stop_recording():\r\n    102     devices = device_map.logical_to_actual_devices(logical_device)\r\n--> 103     value_list = real_mirrored_creator(devices, *args, **kwargs)\r\n    104     result = values.TPUMirroredVariable(\r\n    105         strategy, device_map, value_list, aggregation,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _real_mirrored_creator(devices, *args, **kwargs)\r\n    432               kwargs[\"initial_value\"] = initial_value_fn\r\n    433           with context.device_policy(context.DEVICE_PLACEMENT_SILENT):\r\n--> 434             v = next_creator(*args, **kwargs)\r\n    435           assert not isinstance(v, values.TPUMirroredVariable)\r\n    436           value_list.append(v)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in <lambda>(**kwargs)\r\n    152                         aggregation=VariableAggregation.NONE):\r\n    153     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 154     previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n    155     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    156       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)\r\n   2490         caching_device=caching_device, name=name, dtype=dtype,\r\n   2491         constraint=constraint, variable_def=variable_def,\r\n-> 2492         import_scope=import_scope, distribute_strategy=distribute_strategy)\r\n   2493   else:\r\n   2494     return variables.RefVariable(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    214       return cls._variable_v2_call(*args, **kwargs)\r\n    215     else:\r\n--> 216       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    217 \r\n    218 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy)\r\n    420           name=name,\r\n    421           dtype=dtype,\r\n--> 422           constraint=constraint)\r\n    423 \r\n    424   def __repr__(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint)\r\n    543           with ops.name_scope(\"Initializer\"), device_context_manager(None):\r\n    544             initial_value = ops.convert_to_tensor(\r\n--> 545                 initial_value() if init_from_fn else initial_value,\r\n    546                 name=\"initial_value\", dtype=dtype)\r\n    547           self._handle = eager_safe_variable_handle(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py in <lambda>()\r\n    132           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\r\n    133         initializer = initializer()\r\n--> 134       init_val = lambda: initializer(shape, dtype=dtype)\r\n    135       variable_dtype = dtype.base_dtype\r\n    136   if use_resource is None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops_v2.py in __call__(self, shape, dtype)\r\n    432     else:\r\n    433       limit = math.sqrt(3.0 * scale)\r\n--> 434       return self._random_generator.random_uniform(shape, -limit, limit, dtype)\r\n    435 \r\n    436   def get_config(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops_v2.py in random_uniform(self, shape, minval, maxval, dtype)\r\n    795       op = random_ops.random_uniform\r\n    796     return op(\r\n--> 797         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\r\n    798 \r\n    799   def truncated_normal(self, shape, mean, stddev, dtype):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py in random_uniform(shape, minval, maxval, dtype, seed, name)\r\n    238   with ops.name_scope(name, \"random_uniform\", [shape, minval, maxval]) as name:\r\n    239     shape = _ShapeTensor(shape)\r\n--> 240     minval = ops.convert_to_tensor(minval, dtype=dtype, name=\"min\")\r\n    241     maxval = ops.convert_to_tensor(maxval, dtype=dtype, name=\"max\")\r\n    242     seed1, seed2 = random_seed.get_seed(seed)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype, dtype_hint)\r\n   1048   preferred_dtype = deprecation.deprecated_argument_lookup(\r\n   1049       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\r\n-> 1050   return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n   1051 \r\n   1052 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)\r\n   1106       name=name,\r\n   1107       preferred_dtype=dtype_hint,\r\n-> 1108       as_ref=False)\r\n   1109 \r\n   1110 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\r\n   1184 \r\n   1185     if ret is None:\r\n-> 1186       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1187 \r\n   1188     if ret is NotImplemented:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    302                                          as_ref=False):\r\n    303   _ = as_ref\r\n--> 304   return constant(v, dtype=dtype, name=name)\r\n    305 \r\n    306 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    243   \"\"\"\r\n    244   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 245                         allow_broadcast=True)\r\n    246 \r\n    247 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    251   ctx = context.context()\r\n    252   if ctx.executing_eagerly():\r\n--> 253     t = convert_to_eager_tensor(value, ctx, dtype)\r\n    254     if shape is None:\r\n    255       return t\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n    108       return ops.EagerTensor(\r\n    109           value, handle, device, dtype, tensor)\r\n--> 110     t = ops.EagerTensor(value, handle, device, dtype)\r\n    111     scalar_cache[cache_key] = t\r\n    112     return t\r\n\r\nRuntimeError: Error copying tensor to device: /job:worker/replica:0/task:0/device:TPU:0. /job:worker/replica:0/task:0/device:TPU:0 unknown device.\r\n```\r\n\r\n", "comments": ["Please note that with tf-nightly-2.0-preview from 04/19, the above exceptions seem to be fixed, but another one comes when instantiating the Keras model. This one may be related to the worker name problem from above.\r\n\r\n```\r\nvariable object with name 'cd2c89b7-88b7-44c8-ad83-06c2a9158347' already created. Use get_variable() if reuse is desired.\"\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\n\r\nValueError                                Traceback (most recent call last)\r\n\r\n<ipython-input-1-ed7fbebf6586> in <module>()\r\n     23       tf.keras.layers.Flatten(),\r\n     24       tf.keras.layers.Dense(64, activation='relu'),\r\n---> 25       tf.keras.layers.Dense(10, activation='softmax')\r\n     26   ])\r\n     27 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    458     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    459     try:\r\n--> 460       result = method(self, *args, **kwargs)\r\n    461     finally:\r\n    462       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py in __init__(self, layers, name)\r\n    106     if layers:\r\n    107       for layer in layers:\r\n--> 108         self.add(layer)\r\n    109 \r\n    110   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    458     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    459     try:\r\n--> 460       result = method(self, *args, **kwargs)\r\n    461     finally:\r\n    462       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)\r\n    167           # and create the node connecting the current layer\r\n    168           # to the input layer we just created.\r\n--> 169           layer(x)\r\n    170           set_inputs = True\r\n    171 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    591           # Build layer if applicable (if the `build` method has been\r\n    592           # overridden).\r\n--> 593           self._maybe_build(inputs)\r\n    594           # Explicitly pass the learning phase placeholder to `call` if\r\n    595           # the `training` argument was left unspecified by the user.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in _maybe_build(self, inputs)\r\n   1822     # Only call `build` if the user has manually overridden the build method.\r\n   1823     if not hasattr(self.build, '_is_default'):\r\n-> 1824       self.build(input_shapes)\r\n   1825     # We must set self.built since user defined build functions are not\r\n   1826     # constrained to set self.built.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py in build(self, input_shape)\r\n    172           constraint=self.bias_constraint,\r\n    173           trainable=True,\r\n--> 174           dtype=self.dtype)\r\n    175     else:\r\n    176       self.bias = None\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\r\n    381         collections=collections,\r\n    382         synchronization=synchronization,\r\n--> 383         aggregation=aggregation)\r\n    384     backend.track_variable(variable)\r\n    385 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\r\n    664         dtype=dtype,\r\n    665         initializer=initializer,\r\n--> 666         **kwargs_for_getter)\r\n    667 \r\n    668     # If we set an initializer and the variable processed it, tracking will not\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\r\n    152       collections=collections,\r\n    153       synchronization=synchronization,\r\n--> 154       aggregation=aggregation)\r\n    155   return v\r\n    156 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    252   def __call__(cls, *args, **kwargs):\r\n    253     if cls is VariableV1:\r\n--> 254       return cls._variable_v1_call(*args, **kwargs)\r\n    255     elif cls is Variable:\r\n    256       return cls._variable_v2_call(*args, **kwargs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation)\r\n    215         use_resource=use_resource,\r\n    216         synchronization=synchronization,\r\n--> 217         aggregation=aggregation)\r\n    218 \r\n    219   def _variable_v2_call(cls,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in getter(**kwargs)\r\n     56   \"\"\"To avoid capturing loop variables.\"\"\"\r\n     57   def getter(**kwargs):\r\n---> 58     return captured_getter(captured_previous, **kwargs)\r\n     59   return getter\r\n     60 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in creator_with_resource_vars(*args, **kwargs)\r\n   1075       kwargs[\"use_resource\"] = True\r\n   1076       kwargs[\"distribute_strategy\"] = strategy\r\n-> 1077       return self._create_variable(*args, **kwargs)\r\n   1078 \r\n   1079     def distributed_getter(getter, *args, **kwargs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _create_variable(self, next_creator, *args, **kwargs)\r\n    486     return _create_tpu_mirrored_variable(\r\n    487         self._container_strategy(), device_map, logical_device,\r\n--> 488         _real_mirrored_creator, *args, **kwargs)\r\n    489 \r\n    490   def _reduce_to(self, reduce_op, value, destinations):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _create_tpu_mirrored_variable(strategy, device_map, logical_device, real_mirrored_creator, *args, **kwargs)\r\n    100   with tape.stop_recording():\r\n    101     devices = device_map.logical_to_actual_devices(logical_device)\r\n--> 102     value_list = real_mirrored_creator(devices, *args, **kwargs)\r\n    103     result = values.TPUMirroredVariable(\r\n    104         strategy, device_map, value_list, aggregation,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _real_mirrored_creator(devices, *args, **kwargs)\r\n    479             kwargs[\"initial_value\"] = initial_value_fn\r\n    480           with context.device_policy(context.DEVICE_PLACEMENT_SILENT):\r\n--> 481             v = next_creator(*args, **kwargs)\r\n    482           assert not isinstance(v, values.TPUMirroredVariable)\r\n    483           value_list.append(v)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in <lambda>(**kwargs)\r\n    194                         aggregation=VariableAggregation.NONE):\r\n    195     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 196     previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n    197     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    198       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)\r\n   2491         distribute_strategy=distribute_strategy,\r\n   2492         synchronization=synchronization,\r\n-> 2493         aggregation=aggregation)\r\n   2494   else:\r\n   2495     return variables.RefVariable(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    256       return cls._variable_v2_call(*args, **kwargs)\r\n    257     else:\r\n--> 258       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    259 \r\n    260 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation)\r\n    441           constraint=constraint,\r\n    442           synchronization=synchronization,\r\n--> 443           aggregation=aggregation)\r\n    444 \r\n    445   def __repr__(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation)\r\n    585               shared_name=shared_name,\r\n    586               name=name,\r\n--> 587               graph_mode=self._in_graph_mode)\r\n    588         self._shape = initial_value.shape\r\n    589         # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in eager_safe_variable_handle(initial_value, shared_name, name, graph_mode)\r\n    192       raise ValueError(\"variable object with name '%s' already created. Use \"\r\n    193                        \"get_variable() if reuse is desired.\" %\r\n--> 194                        shared_name)\r\n    195     with context.graph_mode(), ops.Graph().as_default() as graph:\r\n    196       h = gen_resource_variable_ops.var_handle_op(shape=shape, dtype=dtype,\r\n\r\nValueError: variable object with name 'cd2c89b7-88b7-44c8-ad83-06c2a9158347' already created. Use get_variable() if reuse is desired.\r\n```\r\n\r\n", "Isn't this just the lack of current support for TPUs in TF 2.0 in colab? See [TPU training with Keras API raises error in Tensorflow 2.0 #27339](https://github.com/tensorflow/tensorflow/issues/27339)", "You are right. Thanks for mentioning issue #27339. \r\nWaiting for the 2.0 release !", "https://github.com/tensorflow/tensorflow/issues/27339#issuecomment-482716960\r\nThus closing this issue for now. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27992\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27992\">No</a>\n", "I have a similar exception when using colab and **tf=1.15.0-rc3**. Downgrading to tf=1.14.0 helped, and my code runs as expected. So it is not only tf=2.0.x"]}, {"number": 27991, "title": "Fix BatchMatMulV2 case in TFLite/Toco in 1.14 branch", "body": "Cherry picking 844842a6b067cd521e54679f156dc793738d9691 from master. \r\nOtherwise TFLite will be broken after the forward compatibility period expires. ", "comments": []}, {"number": 27990, "title": "Can't install TensorFlow Windows 7 64bit Python 3.7.2", "body": " here is a mistake after typing \"pip install tensorlow\".\r\nI tried type it in cmd and PyCharm console too. Nothing.\r\n\r\nC:\\Users\\Alex\\PycharmProjects\\ML>pip install tensorflow\r\nCollecting tensorflow\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow\r\n", "comments": ["Thank you a lot :)\n\nOn Sat, Apr 20, 2019 at 5:28 AM Chong Shen <notifications@github.com> wrote:\n\n> According to official install guide\n> <https://www.tensorflow.org/install/pip>, tf only supports 3.6, 3.5, 3.4.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/27990#issuecomment-485051250>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ALSY5BEPGWH2QAIRJUNV4T3PRJ5S7ANCNFSM4HHHHYAA>\n> .\n>\n", "Hi Kuaranir\r\n\r\nI have same error while installing Tensorflow in Win7 x64 bit\r\nCould you please explain how to fix?\r\nRAO NVK\r\n![Error_tf_install](https://user-images.githubusercontent.com/38853257/56467274-e5031080-642d-11e9-8537-e129d5a6afa2.jpg)\r\n", "Ah, i have installed Python 3.6.8 instead of 3.7.2, but it doesnt work still  [url=https://radikal.ru][img]https://a.radikal.ru/a36/1904/b1/87457f81d96d.jpg[/img][/url]\r\n\r\n", "Hi\r\ntry this below, working now\r\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.13.1-py3-none-any.whl\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27989, "title": "AttributeError: module 'tensorflow_estimator.python.estimator.api._v1.estimator' has no attribute '__file__'", "body": "Tensorflow builds through successfully but cannot import when I try (building off of Master branch):\r\n```python\r\nSuccessfully installed tensorflow-1.13.1\r\n\u001b[91mYou are using pip version 10.0.1, however version 19.0.3 is available.\r\nYou should consider upgrading via the 'pip install --upgrade pip' command.\r\n\u001b[0m\u001b[91mTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/__init__.py\", line 34, in <module>\r\n    from tensorflow._api.v1 import compat\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/_api/v1/compat/__init__.py\", line 21, in <module>\r\n    from tensorflow._api.v1.compat import v1\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/_api/v1/compat/v1/__init__.py\", line 643, in <module>\r\n    'tensorflow_estimator.python.estimator.api._v1.estimator'))\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/tools/component_api_helper.py\", line 85, in package_hook\r\n    set_child_as_subpackage()\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/tools/component_api_helper.py\", line 69, in set_child_as_subpackage\r\n    os.path.join(os.path.dirname(child_pkg.__file__), \"..\"))]\r\nAttributeError: module 'tensorflow_estimator.python.estimator.api._v1.estimator' has no attribute '__file__'\r\n```\r\n\r\n\r\n**System information**\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian: Buster\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\nTensorFlow installed from (source or binary): Source\r\nTensorFlow version: Master branch\r\nPython version: 3.6.5\r\nInstalled using virtualenv? pip? conda?: Source build\r\nBazel version (if compiling from source): 0.24.1\r\nGCC/Compiler version (if compiling from source): 8.3.0\r\nCUDA/cuDNN version: NA\r\nGPU model and memory: NA\r\n\r\n** Call to build **\r\n```bash\r\n    cd /opt && \\\r\n    git clone --recursive https://github.com/tensorflow/tensorflow.git && \\\r\n    cd /opt/tensorflow && \\\r\n TF_MKL_ROOT=/usr/lib  \\\r\n    TF_MKL_DOWNLOAD=0 \\\r\n    USE_DEFAULT_PYTHON_LIB_PATH=1 \\\r\n    TF_NEED_MKL=1 \\\r\n    TF_NEED_JEMALLOC=1 \\\r\n    TF_NEED_GCP=0 \\\r\n    TF_NEED_HDFS=0 \\\r\n    TF_ENABLE_XLA=1 \\\r\n    TF_NEED_MPI=0 \\\r\n    TF_NEED_GDR=0 \\\r\n    TF_NEED_S3=1 \\\r\n    TF_NEED_KAFKA=0 \\\r\n    TF_SET_ANDROID_WORKSPACE=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_MKL_ENABLED=\"true\" \\\r\n    CI_BUILD_PYTHON=/opt/conda/bin/python \\\r\n    PYTHON_BIN_PATH=/opt/conda/bin/python \\\r\n    PYTHON_LIB_PATH=/opt/conda/lib/python3.6/site-packages \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    CC_OPT_FLAGS=\" -mavx -msse2 -msse3 -msse4.2 -msse4.1 -mfpmath=sse -lmkl_gf_lp64 -Wl,--start-group -lmkldnn -lmklml_intel -lmkl_gnu_thread -lmkl_core -Wl,--end-group -dl -lpthread -lm \" \\\r\n    /bin/bash ./configure && \\\r\n    bazel build \\\r\n    --config=mkl --config=opt \\\r\n    --config=noaws --config=noignite --config=nokafka --config=nonccl \\\r\n    --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" \\\r\n    --copt=-msse4.2 --copt=-msse4.1 --copt=-mavx --copt=-msse2 --copt=-msse3  \\\r\n    --copt=-O3 --copt=-mfpmath=both \\\r\n    --copt=\"-DMKL_LP64\" \\\r\n    --copt=\"-fPIC\" \\\r\n    --linkopt=\"-lmkl_gf_lp64\" \\\r\n    --linkopt=\"-lmkl_gnu_thread\" \\\r\n    --linkopt=\"-dl\" \\\r\n    --linkopt=\"-ldl\" \\\r\n    --linkopt=\"-lpthread\" \\\r\n    --linkopt=\"-lmkl_core\" \\\r\n    --linkopt=\"-lm\" \\\r\n    --linkopt=\"-lmkl_rt\" \\\r\n    --linkopt=\"-lmkldnn\" \\\r\n    tensorflow/tools/pip_package:build_pip_package && \\\r\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip && \\\r\n    pip install --no-deps /tmp/pip/tensorflow-*.whl && \\\r\n    cd /opt && rm -rf /opt/tensorflow /tmp/* && \\\r\n    python -c \"import tensorflow as tf; hello = tf.constant('Hello, TensorFlow!'); sess = tf.Session(); print(sess.run(hello))\" && \\\r\n    echo \"\\n\\n TENSORFLOW DONEZO \\n\\n\"\r\n```", "comments": ["@sadatnfs : Did you get chance to have a look on the [link](https://www.tensorflow.org/install/source). Let us know if that helps. Thanks! ", "@achandraa the solution was to also build tensorflow-estimator and THEN import TF. That works."]}]