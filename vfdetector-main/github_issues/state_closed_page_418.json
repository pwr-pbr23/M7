[{"number": 41363, "title": "Why TF-OP runs slower than pure API?", "body": "![1188470626](https://user-images.githubusercontent.com/3830256/87379019-d61ff500-c5c1-11ea-8bb0-85a03c98b7aa.jpg)\r\n\r\n====================\r\n\r\n![483313243](https://user-images.githubusercontent.com/3830256/87379023-d7512200-c5c1-11ea-8830-f6822bc13f72.jpg)\r\n\r\nThe op is made up of several GPU kernels, but I found it runs slower in TF than in pure api, the above two pictures represents the nv prof result for pure api and TF-OP seperately. Obviously, kernels in the pure api runs one by one, but there are more space between kernels in TF-OP.\r\n\r\nWhy could this happened?", "comments": ["@venuswu,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!\r\n", "@amahendrakar the OP is a custom-OP made by nvidia called FasterTransformer, which is an open source, https://github.com/NVIDIA/DeepLearningExamples/tree/master/FasterTransformer. The TF version I used is 1.14.", "Hi @venuswu,\r\n\r\nThese gaps the TF timeline are not surprising since TF has overhead above and beyond just calling these APIs.  We can minimize the overhead, but it won't ever be zero.\r\n\r\nDo you see the same behavior with recent versions of TF?", "Hi @sanjoy,\r\n  I have not tested on recent versions, and I want to know what is the overhead of TF compared with the pure api.", "@sanjoy,  May I ask what's the overhead beyond just calling the nvidia API in an OP ?", "> @sanjoy, May I ask what's the overhead beyond just calling the nvidia API in an OP ?\r\n\r\nIf you're running with a small batch size then the graphs could be coming from the host not being able to keep up with the GPU due to overhead from the framework.  However, it is difficult to say without detailed analysis.\r\n\r\nWhat happens when you increase the batch size?", "@venuswu,\r\nAs per [this comment](https://github.com/tensorflow/tensorflow/issues/41363#issuecomment-659725026),  can you please test it on the **`recent versions`** (**`2.5 or Nightly`**) and let us know if the issue persists? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 41362, "title": "c_api.h no such file or directory", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.4.0\r\n- Python version: 3.8.3\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 3.4.0\r\n- GCC/Compiler version (if compiling from source):  7.5.0\r\n- CUDA/cuDNN version: 11.0 / 8.0.1\r\n- GPU model and memory: GTX1080Ti GDDR5X 11GB\r\n\r\n**Describe the problem**\r\nbuild failed\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\n/home/wmind/.cache/bazel/_bazel_wmind/a0a15f0a32d3688786619e94912711cf/external/llvm-project/llvm/BUILD:712:11: C++ compilation of rule '@llvm-project//llvm:Analysis' failed (Exit 1)\r\nIn file included from external/llvm-project/llvm/lib/Analysis/TFUtils.cpp:14:0:\r\nexternal/llvm-project/llvm/include/llvm/Analysis/Utils/TFUtils.h:12:10: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include \"tensorflow/c/c_api.h\"\r\n```\r\n\r\n", "comments": ["This should be fixed now. The error was caused by LLVM including a feature that needs TF but TF depends on LLVM so we needed to cut the circular compile dependency.\r\n\r\n @joker-eph fixed this last night.", "@alanpurple Can you please verify once and close the issue if this was resolved for you. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41362\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41362\">No</a>\n"]}, {"number": 41359, "title": "Add error message fix in qr grad and test coverage", "body": "Add a fix for the bug in the error message in the qr grad check for matrix shapes. Add a test for it.", "comments": ["Is there a bug report? Or an example where the error is wrong? Can we add a test so that future change reversing the order in the comparison gets blocked if wrong?", "@mihaimaruseac So the check works correctly, all the test cases are covered correctly - the only thing wrong is the text of the message: it should say 'nrows > ncols' vs 'ncols > nrows' . (My bad, I wrote the initial code and somehow missed this error in the message text). While this is minor, it could be confusing to a user. \r\n\r\nNote the correct test cases in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/qr_op_test.py", "Eg where the incorrect message would show up:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nnp.random.seed(42)\r\n\r\n# nrows > ncols\r\nnrows, ncols = 3, 2\r\na = np.random.uniform(-1, 1, (3, 2)).astype(np.float32)\r\natf = tf.convert_to_tensor(a)\r\n\r\nwith tf.GradientTape() as g:\r\n  g.watch(atf)\r\n  ret = tf.linalg.qr(atf, True) # full_matrices=True\r\n\r\ng.gradient(ret, atf)\r\n```\r\nwith output:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/denisaroberts/Desktop/eg.py\", line 12, in <module>\r\n    g.gradient(ret, atf)\r\n  File \"/Users/denisaroberts/tf/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\", line 1083, in gradient\r\n    unconnected_gradients=unconnected_gradients)\r\n  File \"/Users/denisaroberts/tf/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\", line 77, in imperative_grad\r\n    compat.as_str(unconnected_gradients.value))\r\n  File \"/Users/denisaroberts/tf/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\", line 162, in _gradient_function\r\n    return grad_fn(mock_op, *out_grads)\r\n  File \"/Users/denisaroberts/tf/lib/python3.7/site-packages/tensorflow/python/ops/linalg_grad.py\", line 498, in _QrGrad\r\n    raise NotImplementedError(\"QrGrad not implemented when ncols > nrows \"\r\nNotImplementedError: QrGrad not implemented when ncols > nrows and full_matrices is true.\r\n```", "If it is possible to transform this example into a test that would be great.\r\n\r\nThank you for the PR and the context", "@mihaimaruseac Will do. To be crystal clear - you mean a test that asserts that the correct message for the check is issued when \"nrows > ncols and full_matrices=True\" ?", "Yes, a test that checks that the error message contains `not implemented when ncols > nrows and full_matrices is true`", "@mihaimaruseac Added test."]}, {"number": 41358, "title": "[TF-TRT] TRTEngineOp Unknown Inference Fix", "body": "@bixia1 : for review\r\n\r\nYou can reproduce the bug with the following code:\r\n\r\n```python\r\n#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\nfrom tensorflow.python.saved_model import signature_constants\r\nfrom tensorflow.python.saved_model import tag_constants\r\n\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.ops import math_ops\r\nfrom tensorflow.python.ops import nn\r\n\r\n\r\n# ## Define TF2 model\r\n# The data type of A will define the input type of the network\r\n\r\na = np.arange(-4, 4, dtype=np.float32).reshape((1,2,1,4))\r\n\r\n@tf.function\r\ndef my_network(x):\r\n    b = array_ops.squeeze(x, axis=[2])\r\n    c = nn.relu(b)\r\n    d1 = c + c\r\n    d2 = math_ops.reduce_sum(d1)\r\n    return d1, d2\r\n\r\n\r\noutput = my_network(tf.convert_to_tensor(a))\r\nprint('Output:', output)\r\n\r\ncfunc = my_network.get_concrete_function(\r\n    tf.TensorSpec(a.shape, tf.dtypes.as_dtype(a.dtype))\r\n)\r\n\r\n# we can save a function just by making it a field of a module\r\nmodule = tf.Module()\r\nmodule.myfunc = my_network\r\n\r\ntf.saved_model.save(module,'/tmp/models/my_function', signatures=cfunc)\r\n\r\n\r\n# ## Convert model to TF-TRT\r\nconverter = trt.TrtGraphConverterV2(input_saved_model_dir=\"/tmp/models/my_function\")\r\nconverter.convert()\r\n\r\n\r\ndef input_fn():\r\n    input_shapes = [[a.shape], ]\r\n    for shapes in input_shapes:\r\n        # return a list of input tensors\r\n        yield [np.ones(shape=x).astype(a.dtype) for x in shapes]\r\n\r\n\r\nconverter.build(input_fn)\r\n\r\nconverter.save(\"/tmp/models/trt_model\")\r\n\r\nprint(\"Model exported to TRT\")\r\n\r\n\r\ndef get_func_from_saved_model(saved_model_dir):\r\n    saved_model_loaded = tf.saved_model.load(\r\n        saved_model_dir, tags=[tag_constants.SERVING])\r\n    graph_func = saved_model_loaded.signatures[\r\n        signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\n    return graph_func, saved_model_loaded\r\n\r\n\r\nfunc, loaded_model = get_func_from_saved_model(\"/tmp/models/trt_model\")\r\n\r\n\r\nprint(\"Input tensor\", func.inputs)\r\nassert(func.inputs[0].shape == tf.TensorShape((1, 2, 1, 4)))\r\n\r\nprint(\"Output tensor\", func.outputs)\r\n\r\nassert(func.outputs[0].shape == tf.TensorShape(dims=(1, 2, 4)))\r\nassert(func.outputs[1].shape == tf.TensorShape(dims=()))\r\n```\r\n\r\nWith upstream tensorflow, this piece of code will fail. \r\n\r\nWith this PR you should obtain this result:\r\n```\r\nInput tensor [<tf.Tensor 'x:0' shape=(1, 2, 1, 4) dtype=float32>]\r\nOutput tensor [<tf.Tensor 'Identity:0' shape=(1, 2, 4) dtype=float32>, <tf.Tensor 'Identity_1:0' shape=() dtype=float32>]\r\n```\r\n\r\n**My next step:** using the script above as a unittest", "comments": ["Commits have been squashed as requested by @bixia1 ", "@DEKHTIARJonathan Can you please check @bixia1's comments and keep us posted ? Thanks!", "@DEKHTIARJonathan, Any update on this PR? Please. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@DEKHTIARJonathan, Any update on this PR? Please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!\r\n"]}, {"number": 41357, "title": "2.3-rc2 cherry-pick request: Correctly set the experimental_io_device when restoring variable from a checkpoint.", "body": "PiperOrigin-RevId: 320222381\nChange-Id: I30187c7777ab8056e48004ef5e4ae747edc32227", "comments": []}, {"number": 41356, "title": "\"2.4-rc2 cherry-pick request: Fix bug when restoring variable from checkpoint when restoring from different IO device.\"", "body": null, "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F41356) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 41355, "title": "[CherryPick:r2.3] Fix deprecated usage of collections ABC", "body": "Importing the ABCs from collections instead of from collections.abc is deprecated since Python 3.3, so TensorFlow provides a compatibility layer to prevent warning from being raised.\r\n\r\nThis PR removes the deprecated usage to make TensorFlow a bit less annoying to use with modern versions of Python.\r\n\r\nThis is a cherry-pick request of #41293", "comments": ["Hi,\r\n\r\nWhile this is a nice to have addition, we cannot at this time take it into the 2.3 release process, given the strict release timeline we are on and the amount of testing that needs t happen.\r\n\r\nAs such, the change can only be included in TF 2.4 and later. Furthermore, we will keep this PR open and will merge it at the time when we need to do a potential 2.3 patch release (no plans at the moment).", "> While this is a nice to have addition, we cannot at this time take it into the 2.3 release process, given the strict release timeline we are on and the amount of testing that needs t happen.\r\n\r\nI understand the reasoning, though it is a bit of a shame since 2.2 didn't throw these deprecation warnings, yet 2.3 throws warnings during normal use (e.g. in `tensorflow/python/data/ops/dataset_ops.py`)."]}, {"number": 41354, "title": "Can't register an optimizer by name: TensorRTOptimizer", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.15.3+gpu+tensorrt\r\n- Python version:3.6\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): devtoolset7\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Tesla V100\r\n\r\n\r\n\r\n**Describe the problem**\r\nWe built tensorflow with --config=cuda and --config=tensorrt enabled, but when using TRT converter, it said \r\n```\r\n2020-07-13 18:15:56.098448: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:247] Registered default graph optimizer: constfold\r\n2020-07-13 18:15:56.098455: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:297] Can't register an optimizer by name: TensorRTOptimizer\r\n2020-07-13 18:15:56.098461: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:292] Registered default graph optimizer: constfold\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```python\r\nimport os\r\n\r\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '2'\r\n\r\nimport time\r\nimport logging\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nprint(\"TensorFlow version: \", tf.__version__)\r\n\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\n\r\nlogging.getLogger(\"tensorflow\").setLevel(logging.INFO)\r\n\r\nSAVED_MODEL_DIR = \"hdfs:///smf1/dw2/user/yinl/resnet_v1_fp32_savedmodel_NHWC\"\r\nFP32_SAVED_MODEL_DIR = \"hdfs:///smf1/dw2/user/yinl/resnet_v1_fp32_savedmodel_NHWC_TRT\"\r\n\r\nconverter = trt.TrtGraphConverter(\r\n    input_saved_model_dir=SAVED_MODEL_DIR,\r\n\t  precision_mode=trt.TrtPrecisionMode.FP32)\r\nconverter.convert()\r\n\r\nconverter.save(FP32_SAVED_MODEL_DIR)\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nBuild script\r\n```\r\nBAZEL_LINKLIBS=-l%:libstdc++.a bazel build -c opt \\\r\n      ${CC_OPT_FLAGS} \\\r\n      ${TF_CONFIG_ARGS} \\\r\n      --config=cuda --config=tensorrt \\\r\n      --linkopt -ldl \\\r\n      //tensorflow/tools/pip_package:build_pip_package \\\r\n      //tensorflow/tools/lib_package:libtensorflow_jni \\\r\n      //tensorflow/tools/lib_package:libtensorflow\r\n```\r\n", "comments": ["Figured it out. Close it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41354\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41354\">No</a>\n", "@liyinhgqw May I ask how did you resolve this issue?"]}, {"number": 41353, "title": "tf.nn.ctc_loss not returning expected value", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below):  v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.7.7\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n\r\n**Describe the current behavior**\r\n\r\nI run the following code:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nlabel = [1, 2, 1]\r\nlogits = [[0.0, 1.0, 0.0],\r\n          [0.0, 0.0, 1.0],\r\n          [0.0, 1.0, 0.0]]\r\nlabels_length = 3\r\nlogits_length = 3\r\n\r\nlabels_tensor = tf.convert_to_tensor([label], dtype=tf.int32)\r\nlogits_tensor = tf.convert_to_tensor([logits], dtype=tf.float32)\r\nlabels_length_tensor = tf.convert_to_tensor([labels_length], dtype=tf.int32)\r\nlogits_length_tensor = tf.convert_to_tensor([logits_length], dtype=tf.int32)\r\n\r\nloss = tf.nn.ctc_loss(labels_tensor, logits_tensor, labels_length_tensor, logits_length_tensor, logits_time_major=False)\r\nprint(loss.numpy()[0])\r\n```\r\n\r\nBasically there're 3 timestamps, and there're two characters `a, b` and the GT is `aba` (`[1, 2, 1]`) which only has one representation in CTC. And I'm making the logits have the probability of 1 for `aba` only. Therefore I expect the loss is 0, however the loss is some random value 1.6543342.\r\n\r\nEither there's a bug, or I seriously misunderstand the documentation - in which case I think the [documentation on this topic](https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss) isn't very good. It would be better to have some example, as suggested in another issue https://github.com/tensorflow/tensorflow/issues/35063.\r\n\r\n**Describe the expected behavior**\r\n\r\nExpect the loss to be 0.\r\n\r\n", "comments": ["I have tried in colab with TF versions 2.2, 2.3-rc1,nightly versions(`2.4.0-dev20200712`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/4ae1e375a30ac4a1d887525a71b50611/untitled119.ipynb).Thanks!", "Hi @lriuui0x0 , I think the value is not expected to zero in the implementation. If we follow the fomula in the paper, the neg log probability is of course zero (see last two cell in the colab link). However, in most of frameworks, in order for numerical stability, the product of probability will become the addition of log probability, and thus, the input probability will be transformed via log softmax first, and do the computation in logarithm domain. You can see the such transformation in [this line](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/ops/ctc_ops.py#L651).\r\n\r\nIn this kind of implementation (see the last cell in the colab link), the produced loss value is indeed 1.6543342. Note that pytorch (and cudnn backend) also follows the same implementation for numerical stability\r\n\r\nhttps://colab.research.google.com/drive/1DofmAw8wgsYYN166n-s80PPKA092U6F6?usp=sharing\r\nhttps://www.cs.toronto.edu/~graves/icml_2006.pdf", "@lriuui0x0 As mentioned in the above comment, this is an expected behavior. Log probability is just added for stability so you can ignore it.", "@WindQAQ @gowthamkpr Thanks for the response. The value is quite off from the actual value `0`. Is it due to `np.logaddexp` being inaccurate?", "> @WindQAQ @gowthamkpr Thanks for the response. The value is quite off from the actual value `0`. Is it due to `np.logaddexp` being inaccurate?\r\n\r\nNo, it is due to log softmax will assign some small probability to zero probability. For example, in your case [0.0, 1.0, 0.0] after log softmax will become [-1.55144471 -0.55144471 -1.55144471]. Obviously, if you take exponent on it (convert it back to probability), they are all non-zero. If you use this probability (`e^[-1.55144471 -0.55144471 -1.55144471]`) to compute ctc loss, you can also obtain 1.6543342.\r\n\r\nSo to conclude,\r\n1. Using log softmax to compute prob in logarithm domain.\r\n2. Log softmax assigns some small value to zero probability. Think about [0.0, 1.0] -> log_softmax([0.0, 1.0]) = [1 / (1 + e), e / (1 + e)] -> take exponent -> both non zero.", "@WindQAQ OK so it's because of the way `tf.nn.log_softmax` is impelemented, it results in `[-1.55144471 -0.55144471 -1.55144471]` instead of `[-inf 0 -inf]`, which is mathematically more correct, but is numerically unstable / slower.\r\n\r\nOK that makes sense then, do you know any reference on the theory behind why log softmax is implemented in that way?", "> @WindQAQ OK so it's because of the way `tf.nn.log_softmax` is impelemented, it results in `[-1.55144471 -0.55144471 -1.55144471]` instead of `[-inf 0 -inf]`, which is mathematically more correct, but is numerically unstable / slower.\r\n> \r\n> OK that makes sense then, do you know any reference on the theory behind why log softmax is implemented in that way?\r\n\r\nUmm, I am not sure about that, but it's not about how `log_softmax` is implemented, it is implemented as described in its name (take softmax and then take log) :-)", "@WindQAQ If it's really implementing softmax then `element-wise` log, why would `[0, 1, 0]` results in `[-1.55144471, -0.55144471, -1.55144471]`?", "Denote `z = [0, 1, 0]`.\r\nLet's first compute the numerator of softmax, that is, `e^{z_i}`.\r\nWe can have `e^z = [1, e, 1]`. The denominator is then `sum_{i=0}^2 e^{z_i}` = 2 + e. Thus, the softmax value is `softmax(z) = [1 / (2 + e), e / (2 + e), 1 / (2 + e)]`. Finally, taking the log on softmax yields `log_softmax(z) = [-1.55144471, -0.55144471, -1.55144471]`.", "@WindQAQ Oh yes, I forgot it's calculating softmax once again on top of softmax result. Thanks, we can close the issue now!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41353\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41353\">No</a>\n"]}, {"number": 41352, "title": "TensorFlow Lite runtime check doesn't account for bytecode", "body": "This line in TensorFlow Lite doesn't consider the possibility that the name of the file could end with `pyc` instead of `py` if the module is compiled to bytecode (e.g., when used by PyInstaller). I can file a PR but wanted to check first if there's a reason why this is the way that it is. Right now, this causes the TensorFlow Lite runtime to try to import full TensorFlow when it's compiled to bytecode, which of course fails.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/df56513aa9b004313c2cff818e138d78cd667b67/tensorflow/lite/python/interpreter.py#L28\r\n\r\nI would plan to change this to:\r\n\r\n```\r\nimport os\r\n\r\nif not os.path.splitext(__file__)[0].endswith('tflite_runtime/interpreter')\r\n```\r\n\r\nFeedback welcome!", "comments": ["Great catch, thanks! @MeghnaNatraj can you take this one?", "@faustomorales Thank you for catching this bug. Let us know if you've filed a PR, otherwise I'll go ahead and make the update.", "I'm happy to file the PR for this in the next couple of days. Just wanted to file an issue before I assume that this behavior was unintentional. Thanks for the feedback!", "@faustomorales Whenever you file the PR, feel free to add me as a reviewer for a quicker turnaround time. Thank you.", "@faustomorales\r\n\r\nWould a more robust option be to use a try statement to attempt to import the runtime from tensorflow and fall back to tflite_runtime if it fails to load the module? \r\nWhat is the rationale behind having the check be done with the file name?\r\n\r\nBest,\r\nSebastian ", "> @faustomorales\n> \n> \n> \n> Would a more robust option be to use a try statement to attempt to import the runtime from tensorflow and fall back to tflite_runtime if it fails to load the module? \n> \n> What is the rationale behind having the check be done with the file name?\n> \n> \n> \n> Best,\n> \n> Sebastian \n\nSwitching to a try/catch seems more idiomatc (ask forgiveness, not permission) but would result in TensorFlow getting used if a user has installed TensorFlow *and* the TFLite runtime in the same environment. In the best case, this causes surprising behavior (the TFLite runtime would rely on TensorFlow when it was intended to operate independently). In the worst case, there could be an API mismatch between TFLite and TensorFlow. For those reasons, I think it would be wise to stick with the path check. Let me know if I've missed something!", "@faustomorales thanks for the explanation, really look forward to this patch being released in a stable version (right now I am patching \"manually\" the file to bundle it in pyinstaller).\r\nBest! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41352\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41352\">No</a>\n"]}, {"number": 41351, "title": "tf.image.random_saturation cpu implementation crashes on some images", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):   Ubuntu 18.04.3 LTS\r\n- TensorFlow installed from (source or binary): Docker Image 'tensorflow/tensorflow:2.2.0-gpu'\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: CUDA Version 10.1.243\r\n- GPU model and memory: NVIDIA Titan RTX with 24gb of memory\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using tf.image.random_saturation on the cpu (as part of a custom image augmentation pipeline), certain images will cause tf.image.random_saturation to crash. There is no error, the session simply freezes and cannot be exited. Ctr C has no effect and the terminal session needs to be quit. When running the function in GPU this error does not happen. \r\n\r\nThe images being fed into this function are imagenet images that have already been augmented with a Gaussian blur and it only seems to happen on less than 1% of the data. The images that cause the crash do not appear to be out of the ordinary, with all the values being float32 values between 0 and 1. The only notable pattern being that they all have at least one pixel equal to exactly 0.0. This alone though is not enough to recreate the failure.\r\n\r\n**Describe the expected behavior**\r\nThe expected behavior is that this function behaves the same as on the gpu and does not crash from an rgb image where all the values are floats between 0 and 1.\r\n\r\n**Standalone code to reproduce the issue**\r\nDownload and extract the file provided to get bad_image.npy to use with the code snippet below.\r\n[bad_image.npy.zip](https://github.com/tensorflow/tensorflow/files/4915306/bad_image.npy.zip)\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\ninp = np.load(\"bad_image.npy\")\r\nwith tf.device('/cpu:0'):\r\n    tf_inp = tf.convert_to_tensor(inp)\r\n    test = tf.image.random_saturation(tf_inp, .2, 1.8)\r\nprint(test)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nCurrent workaround: wrap the input to tf.image.random_saturation with tf.clip_by_value(x, 1e-6, 1)\r\n", "comments": ["@pbontrager \r\nI ran the code on gpu and cpu and do not find any difference on the colab, please find the gist for [gpu](https://colab.research.google.com/gist/Saduf2019/89c4a7626425ff4cad0e352e37e519f7/untitled276.ipynb) and [cpu here](https://colab.research.google.com/gist/Saduf2019/86a481f09ddb68e83665a8d370e83b1a/untitled275.ipynb). I do not face any freezing, please verify and let me know if i am doing something incorrect.", "I too didn't face any issues while running the code on both CPU and GPU.\r\n- check this [link](https://www.tensorflow.org/install/docker) and see if you can find anything, Maybe this is happening because of the docker image.", "I'll try to reproduce this on another machine. It may be the docker image, or a different dependency that tf random_saturation relies on", "@pbontrager \r\nPlease update us after you verify.", "Okay, after testing this on a few machines, using the identical docker image and NVIDIA Drivers, I cannot reproduce this issue unless I'm on the original machine. As I cannot reproduce this but outside of one machine, I guess there is no more that can be done with this at this time.", "@pbontrager \r\nThank you for the update. Closing this issue for now. Please feel free to reopen the issue if any new information is found. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41351\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41351\">No</a>\n"]}, {"number": 41350, "title": "Switching from Theano 1.0.0 to TensorFlow 2.2 (both using Keras) causes exponentially growing loss and stagnant accuracy", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.6.10\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6.5\r\n- GPU model and memory: GeForce GTX Titan X, 12 GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nAfter migrating some Keras code from Theano backend (Keras 2.0.7, Theano 1.0.0) to pure TensorFlow, the model is unable to train with the same success as it did before. I did not change anything about the model architecture, hyper parameters, or parameters in the fit function. All that changed were import statements (ex: keras.layers -> tensorflow.keras.layers)\r\n\r\nWith TensorFlow:\r\n\r\n```\r\n2020-07-10 23:12:37 WARNING  Using a generator with use_multiprocessing=True and multiple workers may duplicate your data. Please consider using the tf.data.Dataset.\r\nEpoch 1/8\r\n2020-07-10 23:12:38.795744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-07-10 23:12:38 WARNING  multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\r\n2020-07-10 23:12:39.211689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n100/100 [==============================] - 10s 103ms/step - loss: 5.1734 - accuracy: 0.1002\r\nEpoch 2/8\r\n100/100 [==============================] - 10s 102ms/step - loss: 6.1694 - accuracy: 0.1079\r\nEpoch 3/8\r\n100/100 [==============================] - 10s 102ms/step - loss: 13.4283 - accuracy: 0.0830\r\nEpoch 4/8\r\n100/100 [==============================] - 10s 101ms/step - loss: 22.0164 - accuracy: 0.0838\r\nEpoch 5/8\r\n100/100 [==============================] - 10s 102ms/step - loss: 44.7066 - accuracy: 0.0575\r\nEpoch 6/8\r\n100/100 [==============================] - 10s 102ms/step - loss: 38.3269 - accuracy: 0.0690\r\nEpoch 7/8\r\n100/100 [==============================] - 10s 102ms/step - loss: 53.5934 - accuracy: 0.0641\r\nEpoch 8/8\r\n100/100 [==============================] - 10s 101ms/step - loss: 66.5487 - accuracy: 0.0673\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected training behavior should be similar to that of Keras with Theano backend:\r\n\r\n```\r\n/usr/local/lib/python3.6/site-packages/keras/engine/training.py:1984: UserWarning: Using a generator with use_multiprocessing=True and multiple workers may duplicate your data. Please consider using the keras.utils.Sequence class.\r\n  UserWarning('Using a generator with use_multiprocessing=True')\r\nEpoch 1/8\r\n100/100 [==============================] - 14s - loss: 4.8412 - acc: 0.1197          \r\nEpoch 2/8\r\n100/100 [==============================] - 13s - loss: 3.7391 - acc: 0.2454     \r\nEpoch 3/8\r\n100/100 [==============================] - 13s - loss: 3.2523 - acc: 0.3528     \r\nEpoch 4/8\r\n100/100 [==============================] - 13s - loss: 2.9821 - acc: 0.3923     \r\nEpoch 5/8\r\n100/100 [==============================] - 13s - loss: 2.8871 - acc: 0.4059     \r\nEpoch 6/8\r\n100/100 [==============================] - 13s - loss: 2.8087 - acc: 0.4177     \r\nEpoch 7/8\r\n100/100 [==============================] - 13s - loss: 2.7203 - acc: 0.4290     \r\nEpoch 8/8\r\n100/100 [==============================] - 13s - loss: 2.6507 - acc: 0.4351\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nModel architecture:\r\n\r\n```\r\nimport tensorflow.keras.backend as K\r\nfrom tensorflow.keras import Model, Sequential, Input\r\nfrom tensorflow.keras.layers import Dense, Lambda, Embedding, LSTM\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.losses import CategoricalCrossentropy\r\nfrom tensorflow.keras.metrics import Accuracy\r\n\r\nepoch = 1\r\nbatch_size = 2048\r\nvalidation_batch_size = 1024\r\none_hot_dim = 80000\r\nembedding_dim = 128\r\nmax_seq_len = 50\r\nhidden_layer_dim = 512\r\nmax_q_size = 5000\r\n\r\nnb_worker = 5\r\none_indexing = False\r\nfeaturizer = \"sequence\"\r\nfeaturizer_parameters = [one_hot_dim, max_seq_len, one_indexing]\r\ndef create_model_architecture(num_classes):\r\n    # build model architecture\r\n    model = Sequential(\r\n         [\r\n             Input(shape=(max_seq_len,), name=\"query_input\"),\r\n             Embedding(output_dim=embedding_dim, input_dim=one_hot_dim, input_length=max_seq_len),\r\n             LSTM(embedding_dim, input_shape=(max_seq_len, embedding_dim)),\r\n             Lambda(lambda x: K.cast(x, \"float32\")),\r\n             Dense(units=hidden_layer_dim, kernel_initializer=\"he_normal\", activation=\"relu\"),\r\n             Dense(units=num_classes, kernel_initializer=\"normal\", activation=\"softmax\", name=\"prediction\")\r\n         ]\r\n    )\r\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']\r\n    model.summary()\r\n    return model\r\n```\r\n\r\nIn model.compile, I have tried also using the classes for optimizer, loss, and metrics (such as Adam, CategoricalCrossentropy, Accuracy). It causes the accuracy to be much higher but the loss still increases exponentially.\r\n\r\nModel fit call:\r\n\r\n```\r\nmodel.fit(data_generator_train.generate(),\r\n            steps_per_epoch=args.step_log,\r\n            epochs=8,\r\n            validation_data=data_generator_validate.generate() if data_generator_validate else None,\r\n            validation_steps=data_generator_validate.num_batches if data_generator_validate else None,\r\n            max_queue_size=model_module.max_q_size,\r\n            shuffle=True,\r\n            use_multiprocessing=True,\r\n            workers=model_module.nb_worker,\r\n            callbacks=[check_pointer])\r\n```\r\n\r\nData generator function:\r\n\r\n```\r\n@threadsafe_generator\r\ndef generate(self):\r\n   while True:\r\n      for filename in glob.glob(self.dataset_files):\r\n         with open(filename) as fr:\r\n            while True:\r\n               lines = list(islice(fr, self.batch_size))\r\n               if not lines:\r\n                  break\r\n               x, y, w = self.get_train_vectors(lines)\r\n               yield x, y, w\r\n```\r\n\r\n**Other info / logs**\r\n\r\nOther things I have tried:\r\n\r\nUsing tensorflow.keras.utils.Sequence instead of a generator, and including shuffle=True\r\nNot using multiprocessing\r\nNot using Sequential\r\nUsing classes instead of names in model.compile()\r\nChanging parameters like batch size, steps_per_epoch, etc.\r\n\r\nOther notes:\r\n\r\nI am using a custom Docker image to run the model. I have made volume mountings from the local machine, including CUDA, cuDNN, etc. under /usr/local/cuda. TensorFlow 2.2 also has a library (libcublas.so) which is not located there, so I have an additional mapping under /usr/lib/x86_64-linux-gnu. \r\n", "comments": ["@mikexue7 \r\n\r\nWill it be possible to share colab link or complete code snippet with supporting files and with proper indentation to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 41349, "title": "Tf allocator attributes", "body": "Added TF_AllocatorAttributes for use in TF_AllocateTemp function in C API \r\n\r\n@yisitu ", "comments": ["I added some API owners as reviewers since this is a change to public API."]}, {"number": 41348, "title": "Doc error for `tf.linalg.trace`", "body": "Change from \r\n `output[i, j, k, ..., l] = trace(x[i, j, i, ..., l, :, :])`\r\nto\r\n  `output[i, j, k, ..., l] = trace(x[i, j, k, ..., l, :, :])`", "comments": []}, {"number": 41347, "title": "WARNING:tensorflow:11 out of the last 11 via using Keras library", "body": "Hello all, I'm getting this warning, I wonder why?\r\n\r\n>WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x0000023D1D542C80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\n\r\nMy whole code is [here.](https://github.com/BestSithInEU/Warning)", "comments": ["@BestSithInEU,\r\nThis issue has already been addressed here [#38561](https://github.com/tensorflow/tensorflow/issues/38561#issuecomment-629937796) and looks like it is fixed.\r\n\r\nPlease update TensorFlow to v2.3.0rc1 and check if you are facing the same issue. Thanks!", "It worked thanks."]}, {"number": 41346, "title": "Read using caching mechanism part 1", "body": "@mihaimaruseac \r\nThis PR add caching mechanism to `tf_random_access_file`. It works but there are still manything from the `core` implementation that are missing in this implementation. Will be added in the next PRs.", "comments": ["Convert to draft because there is one thing to discuss.\r\nI think I should make a PR to remove all the interfaces first, because they are kept inside the plugin's boundary and are not exported, they will not get any implementation. So the right thing is to remove all the interfaces code. We will lose:\r\n- https://github.com/tensorflow/tensorflow/blob/ac3456f3ad9ab8af38d933f823aa665358f7c4fe/tensorflow/core/platform/cloud/file_block_cache.h#L45\r\n\r\n- https://github.com/tensorflow/tensorflow/blob/ac3456f3ad9ab8af38d933f823aa665358f7c4fe/tensorflow/core/platform/cloud/file_block_cache.h#L62-L66\r\n\r\n- https://github.com/tensorflow/tensorflow/blob/ac3456f3ad9ab8af38d933f823aa665358f7c4fe/tensorflow/core/platform/cloud/gcs_file_system.h#L73\r\n\r\nI will keep `RamFileBlockCache` but it will be a normal class instead of an implementation of `FileBlockCache`.\r\nWhat do you think ?\r\n@mihaimaruseac @sshrdp ", "I think this is ok, one of the benefits of modularization is that we remove interfaces which only had one use.", "Close because there are some refactors need to be done first with GCS."]}, {"number": 41345, "title": "TensorMap: Add TensorMap data structure, operations, and gradients", "body": "Add new differentiable hashtable feature based on a new TensorMap class and TensorMap ops (lookup, insert, erase) with gradient functions implemented. The new feature will allow users to take gradients of and backpropagate hashtables. @mdanatg @saxenasaurabh @dynamicwebpaige ", "comments": []}, {"number": 41344, "title": "[TFLite] Added op tests for conv_activations", "body": "Op tests for conv operator with activation for 16x8 quantization mode.\r\n\r\nCommand to run them:\r\nbazel run //tensorflow/lite/testing:generate_examples -- /tmp --zip_to_output=conv_activation --toco=$(pwd)/bazel-bin/tensorflow/lite/toco/toco\r\n\r\nFollow up of #39543", "comments": ["@wwwind can you please check below error ?\r\n```\r\ntensorflow/lite/testing/op_tests/conv_activation.py\", line 143, in make_conv_relu_tests\r\n    return make_conv_activation_tests(tf.nn.relu)(options)\r\n  tensorflow/lite/testing/op_tests/conv_activation.py\", line 129, in f\r\n    expected_tf_failures=60)\r\n  tensorflow/lite/testing/zip_test_utils.py\", line 310, in make_zip_of_tests\r\n    (zip_path, all_parameter_count, _MAX_TESTS_PER_ZIP))\r\nRuntimeError: Too many parameter combinations for generating 'blaze-out/k8-opt/genfiles/third_party/tensorflow/lite/experimental/mlir/testing/conv_relu.zip'.\r\n```", "Hi @rthadur Could you please mention which bazel test task is failing ? \r\nWhat bazel test command should I call to reproduce these failures ?\r\nThanks! ", "@wwwind this tests are failing `https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/testing/zip_test_utils.py#L259` \r\n\r\ncc @suharshs ", "I found the source of problems. They should be fixed now.\r\nI used the following commands to run these tests locally:\r\n\r\nbazel test --compilation_mode=opt //tensorflow/lite/testing:zip_test_conv_relu\r\nbazel test --compilation_mode=opt //tensorflow/lite/testing:zip_test_conv_relu1\r\nbazel test --compilation_mode=opt //tensorflow/lite/testing:zip_test_conv_relu6\r\n\r\nIf I combine parameters like it was before, then I hit the error:\r\n\"There are at least 744 combinations while the upper limit is 500.\r\nHaving too many combinations will slow down the tests.\"\r\n\r\nHi @suharshs, @rthadur Could you please re-approve this PR ? Thanks ", "Hi @rthadur ! I have removed TODO comment. Could you please re-approve ? Thanks!", "Were you able to run this test locally using bazel? We're seeing a failure in the archive extraction:\r\n\r\n```\r\nF0923 04:56:40.382512    9627 generated_examples_zip_test.cc:244] Non-OK-status: archive_environment()->UnArchive(zip_file, tar_file, &decompress_tmp_dir) status: Unknown: unzip failed. stdout:\r\n```", "I think you can repro by trying:\r\n\r\n```\r\nbazel test //tensorflow/lite/testing:zip_test_conv_relu_forward-compat\r\n```\r\n\r\n\r\n", "@wwwind  Can you please check @jdduke's comments and keep us posted ? Thanks!", "Sure, I will check these failures!", "Hi @jdduke I can reproduce this error and it is due to the OS Error \"File name too long\", that happened during Archive -> Unzip.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/testing/generated_examples_zip_test.cc#L280\r\n\r\nIt has happened after recent updating with the master branch, when the new parameter 'dynamic_range_quantize=False' is added. \r\nwith 'quant_16x8' is just too much.\r\nExample of the file name:\r\n\r\nconv_relu_forward-compat_channel_multiplier=2,constant_filter=True,data_format='NHWC',dilations=[1,1,1,1],dynamic_range_quantize=True,filter_shape=[3,3],fully_quantize=False,input_shape=[1,3,4,3],padding='VALID',quant_16x8=False,strides=[1,2,3,1]_tests.txt\r\n        \r\nThere are three ways to solve:\r\n- replace the name of some params with the shorter version - I don't know which one it is better to replace\r\n- split arrays of dilations, input_shapes, strides into 1 per test/file (kind of cheating)\r\n- implement a special check and a fallback code in the generated_examples_zip_test.cc\r\n\r\nCould you please advise how should I go forward with this PR ? Thanks\r\n", "@jdduke Can you please assist on above comments from @wwwind. Thanks!", "@jdduke Any update on this CL? Please. Thanks!", "Apologies, this one had been assigned to @suharshs, will reassign for landing!", "Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR."]}, {"number": 41343, "title": "Tensorflow 2.2: No gradients provided for any variable", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1/ 7.6.5\r\n- GPU model and memory:  GPU Nvidia 1080Ti / 12GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI build a custom Unet with custom Densenet encoder. After I compile model and use fit_generator, I got No gradients provided for any variable\r\n\r\n**Describe the expected behavior**\r\nModel run the training\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nLink colab https://drive.google.com/file/d/1fyb88Ako0CjoVP9O5NQdy6rfjoBhXaFS/view?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Hi, it's not a bug, it's how I create the data generator. It is fixed by change \r\n```return [x1, x2, x3, x4], y```\r\nto\r\n```yield [x1, x2, x3, x4], y```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41343\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41343\">No</a>\n"]}, {"number": 41342, "title": "[TFLite] Added op tests for leaky_relu", "body": "Op tests for leaky_relu operator for 16x8 quantization mode.\r\n\r\nCommand to run them:\r\nbazel run //tensorflow/lite/testing:generate_examples -- /tmp --zip_to_output=leaky_relu --toco=$(pwd)/bazel-bin/tensorflow/lite/toco/toco\r\n\r\nFollow up of https://github.com/tensorflow/tensorflow/pull/39543\r\n", "comments": ["@wwwind  Can you please check @jdduke's comments and keep us posted ? Thanks!", "Hi @gbaned  Thanks! I am looking at these failures.", "Hi @jdduke , @gbaned Could you please re-approve this PR ? This failure has been fixed."]}, {"number": 41341, "title": "Use copy instead of deepcopy for sklearn wrapper", "body": "# Summary\r\n**Submitted on behalf of a third-party:** @mcarbajo. This PR is a copy of @mcarbajo's PR to the main keras repo: https://github.com/keras-team/keras/pull/13598\r\n\r\nFor compatibility with the scikit-learn clone function get_params has to return the same parameters as given in the init function.\r\n\r\nNote that we want this function to return a *reference*, not a *copy*.  Original issue here: https://github.com/keras-team/keras/issues/13586\r\n\r\n# Related Issues:\r\nhttps://github.com/keras-team/keras/issues/13586\r\nhttps://github.com/scikit-learn/scikit-learn/issues/17022\r\nhttps://github.com/scikit-learn/scikit-learn/issues/15722\r\n\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F41341) for more info**.\n\n<!-- need_sender_cla -->", "@zachmayer Thank you for your contribution. Can you please sign CLA? Thanks!", "@gbaned Yup!  I just need approval from legal at work, then I will sign it.", "@gbaned I get the following error when I try to sign the agreement: `You must be an owner of the contributors group in order to submit this CLA.`\r\n\r\nThe group I am trying to use as a contributors group is datarobot-oss-contributors@datarobot.com\r\n\r\nI am the owner of this group: I just made it.  Can you help me get this fixed?", "@gbaned can you help me resolve this issue?", "@zachmayer Can you use please make sure to use same GitHub username and email-id associated with it. Thanks!", "@zachmayer, Any update on this PR? Please. Thanks!", "@gbaned I have 2 emails associated with my github account.  One of them \"owns\" that user group.  I still get the \"You must be an owner of the contributors group in order to submit this CLA\" error when I try to submit the form.\r\n\r\nIs there someone on your end who can fix this bug?  I think the validation for that form is confused by the 2 email addresses on my github account.", "@zachmayer can you please try to open a new PR with one email associated with your GitHub account ?", "@zachmayer  Can you please check @rthadur's comments and keep us posted ? Thanks!", "So I need to:\r\n1. Remove my personal email from my github account\r\n2. Make sure my github account is only connected to my work email\r\n3. Make a new PR \r\n4. Sign the agreement with my work email, on the new PR?\r\n\r\n", "Yes please , sorry for the trouble. ", "Another option is to get @mcarbajo to open a PR, as all I did was port his proposed change for the keras repo to the tensorflow repo: https://github.com/keras-team/keras/pull/13598", "@zachmayer Any update on this PR? Please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!", "It would be really great to get this in....", "@gharibian I got the agreement signed\u2014 can we re-open this PR?\r\n\r\n(@amueller sorry about the delay: I have 2 emails associated with my gihub account, which created some technical difficulties in signing the contributor agreement)", "@googlebot I signed it!", "Yeah that looked like an \"interesting\" experience, and no worries!", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F41341) for more info**.\n\n<!-- cla_yes -->", "@qlzh727 how do I re-run the `MacOS CPU Python3` test?", "@zachmayer Any update on this PR? Please. Thanks!", "@gbaned I believe @amueller satisfactorily addressed the only open comment.  I signed the CLA, so I think this PR is ready to merge."]}, {"number": 41340, "title": "Unable to load custom model when using tf.keras.callbacks.ModelCheckpoint", "body": "**System information**\r\n\r\n== check python ===================================================\r\npython version: 3.6.9\r\npython branch: \r\npython build version: ('default', 'Apr 18 2020 01:56:04')\r\npython compiler version: GCC 8.4.0\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\nos: Linux\r\nos kernel version: 1 SMP Wed Feb 19 05:26:34 PST 2020\r\nos release version: 4.19.104+\r\nos platform: Linux-4.19.104+-x86_64-with-Ubuntu-18.04-bionic\r\nlinux distribution: ('Ubuntu', '18.04', 'bionic')\r\nlinux os distribution: ('Ubuntu', '18.04', 'bionic')\r\nmac version: ('', ('', '', ''), '')\r\nuname: uname_result(system='Linux', node='6fd50df0cf80', release='4.19.104+', version='#1 SMP Wed Feb 19 05:26:34 PST 2020', machine='x86_64', processor='x86_64')\r\narchitecture: ('64bit', '')\r\nmachine: x86_64\r\n\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nnumpy                    1.18.5         \r\nprotobuf                 3.10.0         \r\ntensorflow               2.2.0          \r\ntensorflow-addons        0.8.3          \r\ntensorflow-datasets      2.1.0          \r\ntensorflow-estimator     2.2.0          \r\ntensorflow-gcs-config    2.2.0          \r\ntensorflow-hub           0.8.0          \r\ntensorflow-metadata      0.22.2         \r\ntensorflow-privacy       0.2.2          \r\ntensorflow-probability   0.10.0         \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.version.VERSION = 2.2.0\r\ntf.version.GIT_VERSION = v2.2.0-0-g2b96f3662b\r\ntf.version.COMPILER_VERSION = 7.4.0\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/lib64-nvidia\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nMon Jul 13 14:50:08 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n| N/A   44C    P0    59W / 149W |    157MiB / 11441MiB |      0%      Default |\r\n|                               |                      |                 ERR! |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart-1b201d85.so.10.1\r\n/usr/local/lib/python3.6/dist-packages/torch/lib/libcudart-1b201d85.so.10.1\r\n/usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudart.so.10.0.130\r\n/usr/local/cuda-10.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-10.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-10.1/doc/man/man7/libcudart.7\r\n/usr/local/cuda-10.1/doc/man/man7/libcudart.so.7\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 2.2.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /usr/local/lib/python3.6/dist-packages\r\nRequired-by: fancyimpute\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 6, 9, 'final', 0)\r\n\r\n- All other system information is contained in a standalone colab notebook as cited section below\r\n\r\n**Describe the current behavior**\r\n\r\nWhen training a sub-classed keras model with tf.keras.callbacks.ModelCheckpoint, It is not possible load the saved model. \r\n\r\n> OSError                                   Traceback (most recent call last)\r\n> <ipython-input-7-bd53ee47e8b4> in <module>()\r\n> ----> 1 tf.keras.models.load_model('checkpoints/classifier')>\r\n> \r\n> 1 frames\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py in parse_saved_model(export_dir)\r\n>     111                   (export_dir,\r\n>     112                    constants.SAVED_MODEL_FILENAME_PBTXT,\r\n> --> 113                    constants.SAVED_MODEL_FILENAME_PB))\r\n>     114 \r\n>     115 \r\n> OSError: SavedModel file does not exist at: checkpoints/classifier/{saved_model.pbtxt|saved_model.pb}\r\n\r\n \r\n**Describe the expected behavior**\r\nIt should be able to use the saved model for inference/deployment or other subsequent tasks\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1mJnwoTCJOcZKiPxfY5nDfFk14S8r5IOi\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n I think there are other issues related like https://github.com/tensorflow/tensorflow/issues/31057\r\n", "comments": ["@esdrascosta \r\n\r\nI see you have not saved the model before you load the model.After saving the model i am not seeing any issue.Can you please find the gist [here ](https://colab.research.google.com/gist/ravikyram/3a0e9179b21a80d4de26c7f92c55430c/untitled117.ipynb). Thanks!", "Hi @ravikyram, thanks for your feedback. The problem is when using ModelCheckpoint, the model is not saved properly. I'm concerning for long time training and saving only the best model. After saving the model once compiled, as you demonstrated on the gist calling explicit `mode.save`, indeed the `.pb` file is generated, but there is not guarantee that the model saved is \"best\" model saved, given the `monitor='val_accuracy'`,  after long training the last state of model might not be the best one. My guess is in the tf.keras.callbacks.ModelCheckpoint its self. ", "I think may be related with this issue https://github.com/tensorflow/tensorflow/issues/37839, since this feature has been added in tensorflow 2.2.0 and may not have been updated in keras callback", "@esdrascosta Did you try using tensorflow 2.3.0?", "Hi @gowthamkpr, yes I did with the latest version `2.3.0rc1`, you can find the gist [here](https://colab.research.google.com/drive/1XuGXzPlPWvhJO8c0-sUm4UFoSImQqDzA). Thanks in advance.", "It seems something about the overwritten method `set_model`  in tf.keras.callbacks.ModelCheckpoint. Under the hood, whenever a model is set it checks: \r\n\r\n``` \r\ndef set_model(self, model):\r\n    self.model = model\r\n    if (not self.save_weights_only and\r\n        not model._is_graph_network and\r\n        model.__class__.__name__ != 'Sequential'):\r\n      self.save_weights_only = True\r\n```  \r\n\r\nSo, by default `save_weights_only = False` and when the model is set and it satisfies that condition it changes this default behavior. I could open a PR about this, but I'm not familiar with this internal source code. If you could give me a explanation why this condition is placed there, I could contribute.", "Can we get an update on this?", "Was able to replicate this issue in TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/52cbb9d167e6d5804e0c53c2d771c7fb/untitled133.ipynb)..Thanks !", "Hi @esdrascosta ! I was able to load the model by putting full path of checkpoints folder. Attaching [gist ](https://colab.sandbox.google.com/gist/mohantym/b7826839a1ab6c95f81f8ddcee58b83e/untitled133.ipynb#scrollTo=h65EkFu9RByu)in 2.7 for reference. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thanks, @mohantym  I've just tested the issue and it's seems to be fixed\r\n\r\nThe version I was testing at that time was `tensorflow==2.2.0`. \r\nSo, now this issue should have be fixed in 2.7 version.\r\n\r\nI also tested with relative paths and worked as well. \r\n`\r\ntf.keras.models.load_model(os.path.join('checkpoints', 'classifier'))\r\n`\r\nThanks again.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41340\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41340\">No</a>\n"]}, {"number": 41339, "title": "ImportError : cannot import name 'context from 'tensorflow.python.eager'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: tensorflow 2.0.0\r\n- Python version: python 3.7.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\ncannot import keras. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nimport keras\r\n\r\nUsing TensorFlow backend.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-3-88d96843a926> in <module>\r\n----> 1 import keras\r\n\r\nC:\\Python\\anaconda3\\lib\\site-packages\\keras\\__init__.py in <module>\r\n      1 from __future__ import absolute_import\r\n      2\r\n----> 3 from . import utils\r\n      4 from . import activations\r\n      5 from . import applications\r\n\r\nC:\\Python\\anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py in <module>\r\n      4 from . import data_utils\r\n      5 from . import io_utils\r\n----> 6 from . import conv_utils\r\n      7 from . import losses_utils\r\n      8 from . import metrics_utils\r\n\r\nC:\\Python\\anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py in <module>\r\n      7 from six.moves import range\r\n      8 import numpy as np\r\n----> 9 from .. import backend as K\r\n     10\r\n     11\r\n\r\nC:\\Python\\anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py in <module>\r\n----> 1 from .load_backend import epsilon\r\n      2 from .load_backend import set_epsilon\r\n      3 from .load_backend import floatx\r\n      4 from .load_backend import set_floatx\r\n      5 from .load_backend import cast_to_floatx\r\n\r\nC:\\Python\\anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py in <module>\r\n     88 elif _BACKEND == 'tensorflow':\r\n     89     sys.stderr.write('Using TensorFlow backend.\\n')\r\n---> 90     from .tensorflow_backend import *\r\n     91 else:\r\n     92     # Try and load external backend.\r\n\r\nC:\\Python\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in <module>\r\n      4\r\n      5 import tensorflow as tf\r\n----> 6 from tensorflow.python.eager import context\r\n      7 from tensorflow.python.framework import device as tfdev\r\n      8 from tensorflow.python.framework import ops as tf_ops\r\n\r\nImportError: cannot import name 'context' from 'tensorflow.python.eager' (unknown location)\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@SSSUBB,\r\nIs there any specific reason you are using TensorFlow v2.0?\r\n\r\nPlease update TensorFlow to the latest version v2.2 and check if you are facing the same issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 41338, "title": "Keras 2.4.3 does not calculate output shape in reshape layer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- TensorFlow installed from (source or binary): conda\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: tested in both 3.7.6 and 3.8.3\r\n- I tested both with a non-gpu version and with cudnn 7.6.5 + cuda10.1_0\r\n\r\n**Describe the current behavior**\r\n\r\nOutput length of a reshape layer with last element of length unknown is marked as None\r\n\r\n**Describe the expected behavior**\r\n\r\nIn previous versions of Keras, it was calculated from the other input shapes\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe following code:\r\n```\r\nimport keras\r\nlayer = keras.layers.Reshape([5, -1])\r\nk_input = keras.Input((5, 6, 4))\r\nmodel = keras.Model(inputs = [k_input], outputs = layer(k_input))\r\nmodel.summary()\r\n```\r\nhas different outputs depending on the version. In Keras 2.3.1 the last dimension of output is correctly deduced to be 24:\r\n\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         (None, 5, 6, 4)           0         \r\n_________________________________________________________________\r\nreshape_1 (Reshape)          (None, 5, 24)             0         \r\n=================================================================\r\n```\r\n\r\nIn Keras 2.4.3 the last dimension of output is None\r\n```\r\n _________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         [(None, 5, 6, 4)]         0         \r\n_________________________________________________________________\r\nreshape (Reshape)            (None, 5, None)           0         \r\n=================================================================\r\n```\r\n", "comments": ["@fjhheras \r\nCould you please try with tf.keras instead of just keras and let us know if it helps.\r\nI ran the code on tf nightly and it works fine with tf.keras, please refer to [gist](https://colab.research.google.com/gist/Saduf2019/e00caf45925842bc86c8628628ea4ee2/untitled268.ipynb) and confirm. ", "With my conda installation with Keras 2.4.3, using tf.keras instead of keras still does not do the trick, I am afraid.\r\n\r\nPlease note that in the gist that you sent, tf.keras version is 2.4.0 (as shown by putting `print(tf.keras.__version__)` in the notebook), and thus earlier than the version I am having problems with (2.4.3), and the python version is also different (3.6.9 instead of 3.7.6/3.8.3)\r\n\r\n\r\n", "Is this still an issue? Can you try executing your code in a virtual environment?\r\nWorks fine with `keras` 2.4.3 as is see the [gist](https://colab.research.google.com/gist/ymodak/b889199dd9bc61bbd3321b9543d1676f/github_issue_41338.ipynb).\r\n\r\nI also tried in my local with python 3.7.6 and keras 2.4.3.\r\nSee attached pycharm console screenshot.\r\n\r\n<img width=\"539\" alt=\"Screen Shot 2020-08-06 at 12 12 48 PM\" src=\"https://user-images.githubusercontent.com/42785357/89572634-3c252400-d7de-11ea-9f52-05a185bd257b.png\">\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41338\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41338\">No</a>\n"]}, {"number": 41337, "title": "S3 registration", "body": "@mihaimaruseac \r\nThis PR adds support for `s3_filesystem`.", "comments": ["Apologies, this stalls internally due to a few broken builds. Should be fixed today"]}, {"number": 41336, "title": "Adding log_warning option in tf.data.experimental.ignore_errors", "body": "Resolves #38078.\r\n\r\nAdds an option log_warning for ignore_errors which can be used to control whether error is logged to stderr.", "comments": ["@stjohnso98 Can you please check @jsimsa's comments and keep us posted ? Thanks!", "@jsimsa Thanks for your review. I am working on your comments and will update the PR soon. Thanks. ", "@jsimsa The PR is updated with the requested changes. Can you please review again? Thanks.", "@stjohnso98  Can you please check @alextp's comments and keep us posted ? Thanks!", "It was a comment from the API owners, sorry for the confusion. We want you\nto merge the new input as an attribute over the existing op to avoid the\nneed for an entirely new op.\n\nOn Thu, Jul 30, 2020 at 9:22 PM stjohnso98 <notifications@github.com> wrote:\n\n> *@stjohnso98* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/core/ops/experimental_dataset_ops.cc\n> <https://github.com/tensorflow/tensorflow/pull/41336#discussion_r463397596>\n> :\n>\n> > @@ -441,6 +441,14 @@ REGISTER_OP(\"ExperimentalIgnoreErrorsDataset\")\n>      .Attr(\"output_shapes: list(shape) >= 1\")\n>      .SetShapeFn(shape_inference::ScalarShape);\n>\n> +REGISTER_OP(\"IgnoreErrorsDatasetV2\")\n>\n> Is this comment addressed to @tensorflow/api-owners?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/41336#discussion_r463397596>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRO7T4OJ36TFM5VXYJTR6JBGNANCNFSM4OYMCQAQ>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp Thanks for your comment. I am working on it. ", "@stjohnso98, Any update on this PR? Please. Thanks!", "@gbaned Apologies for the delay. The PR has been updated with the requested changes. @jsimsa @alextp Please review it again. Thanks.", "@alextp Thanks for your comment. I have made the requested change. Can you please review again? Thanks."]}, {"number": 41335, "title": "    ValueError: Shape must be rank 0 but is rank 1 for '{{node ReadFile}} = ReadFile[](args_0)' with input shapes: [?].", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\nGetting the following error \r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-159-9b4a28882f72> in <module>\r\n      1 dataset = tf.data.Dataset.from_tensor_slices((images))\r\n----> 2 train(dataset.batch(2).map(preprocessing))\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in map(self, map_func, num_parallel_calls, deterministic)\r\n   1619     \"\"\"\r\n   1620     if num_parallel_calls is None:\r\n-> 1621       return MapDataset(self, map_func, preserve_cardinality=True)\r\n   1622     else:\r\n   1623       return ParallelMapDataset(\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\r\n   3979         self._transformation_name(),\r\n   3980         dataset=input_dataset,\r\n-> 3981         use_legacy_function=use_legacy_function)\r\n   3982     variant_tensor = gen_dataset_ops.map_dataset(\r\n   3983         input_dataset._variant_tensor,  # pylint: disable=protected-access\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\r\n   3219       with tracking.resource_tracker_scope(resource_tracker):\r\n   3220         # TODO(b/141462134): Switch to using garbage collection.\r\n-> 3221         self._function = wrapper_fn.get_concrete_function()\r\n   3222 \r\n   3223         if add_to_graph:\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py in get_concrete_function(self, *args, **kwargs)\r\n   2530     \"\"\"\r\n   2531     graph_function = self._get_concrete_function_garbage_collected(\r\n-> 2532         *args, **kwargs)\r\n   2533     graph_function._garbage_collector.release()  # pylint: disable=protected-access\r\n   2534     return graph_function\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)\r\n   2494       args, kwargs = None, None\r\n   2495     with self._lock:\r\n-> 2496       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   2497       if self.input_signature:\r\n   2498         args = self.input_signature\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2775 \r\n   2776       self._function_cache.missed.add(call_context_key)\r\n-> 2777       graph_function = self._create_graph_function(args, kwargs)\r\n   2778       self._function_cache.primary[cache_key] = graph_function\r\n   2779       return graph_function, args, kwargs\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2665             arg_names=arg_names,\r\n   2666             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2667             capture_by_value=self._capture_by_value),\r\n   2668         self._function_attributes,\r\n   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    979         _, original_func = tf_decorator.unwrap(python_func)\r\n    980 \r\n--> 981       func_outputs = python_func(*func_args, **func_kwargs)\r\n    982 \r\n    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in wrapper_fn(*args)\r\n   3212           attributes=defun_kwargs)\r\n   3213       def wrapper_fn(*args):  # pylint: disable=missing-docstring\r\n-> 3214         ret = _wrapper_helper(*args)\r\n   3215         ret = structure.to_tensor_list(self._output_structure, ret)\r\n   3216         return [ops.convert_to_tensor(t) for t in ret]\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in _wrapper_helper(*args)\r\n   3154         nested_args = (nested_args,)\r\n   3155 \r\n-> 3156       ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\r\n   3157       # If `func` returns a list of tensors, `nest.flatten()` and\r\n   3158       # `ops.convert_to_tensor()` would conspire to attempt to stack\r\n\r\n~/venv/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    263       except Exception as e:  # pylint:disable=broad-except\r\n    264         if hasattr(e, 'ag_error_metadata'):\r\n--> 265           raise e.ag_error_metadata.to_exception(e)\r\n    266         else:\r\n    267           raise\r\n\r\nValueError: in user code:\r\n\r\n    <ipython-input-156-6db31559ad89>:5 preprocessing  *\r\n        image = tf.io.read_file(image)\r\n    /home/jake/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py:568 read_file  **\r\n        \"ReadFile\", filename=filename, name=name)\r\n    /home/jake/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\r\n        attrs=attr_protos, op_def=op_def)\r\n    /home/jake/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\r\n        compute_device)\r\n    /home/jake/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\r\n        op_def=op_def)\r\n    /home/jake/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1817 __init__\r\n        control_input_ops, op_def)\r\n    /home/jake/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\r\n        raise ValueError(str(e))\r\n\r\n    ValueError: Shape must be rank 0 but is rank 1 for '{{node ReadFile}} = ReadFile[](args_0)' with input shapes: [?].\r\n```\r\n\r\n\r\nthe code is \r\n```\r\nimport tensorflow as tf\r\n\r\ndef preprocessing(image):\r\n    print('preprocessing->',image)\r\n    image = tf.io.read_file(image)\r\n    #image = tf.image.decode_jpeg(img, channels=3)\r\n    #image = tf.cast(img, tf.float32)\r\n    return image\r\n\r\ndef train(ds):\r\n    for i, batch in enumerate(ds):\r\n        print(\"=====================batch{}====================={}\".format(i,batch))\r\n        for x in batch:\r\n            print(x)\r\n            #print(x.numpy())\r\n            #print(x[1].numpy())\r\nimages = ['/media/jake/mark-4tb3/Screenshot_from_2020-02-19_23-05-22.png','/media/jake/mark-4tb3/Screenshot_from_2020-02-19_23-05-22.png','/media/jake/mark-4tb3/Screenshot_from_2020-02-19_23-05-22.png','/media/jake/mark-4tb3/Screenshot_from_2020-02-19_23-05-22.png']\r\n\r\nimages = tf.ragged.constant(images)\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices((images))\r\ntrain(dataset.batch(2).map(preprocessing))\r\n```", "comments": ["I have tried in colab with TF versions 2.2, 2.3-rc1,nightly versions and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/2963e36b28753eaf8922ae02841355f8/untitled112.ipynb).Thanks!", "The error is raised due `tf.io.read_file` in `.map()` method.\r\nYou may try preprocessing before creating batches and changing last line to,\r\n```python\r\ntrain(dataset.batch(2))#.map(preprocessing))\r\n```\r\n", "> The error is raised due `tf.io.read_file` in `.map()` method.\r\n> You may try preprocessing before creating batches and changing last line to,\r\n> \r\n> ```python\r\n> train(dataset.batch(2))#.map(preprocessing))\r\n> ```\r\n\r\nso is there no way use .map() duing batch? \r\nright now my image file is the directory path. \r\neach batch I have to read the actual image file with map function", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks! \r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41335\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41335\">No</a>\n"]}, {"number": 41334, "title": "Shuffling then zip tf.data.Dataset", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nWhen applying shuffling => warped copy => zip, shuffling is applied after the warping. \r\n\r\n**Describe the expected behavior**\r\nI would expect it to happen before the warping.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nmaster = tf.data.Dataset.range(10)\r\nmaster = master.shuffle(10)\r\nwarped = master.map(lambda x: -x)\r\ndataset = tf.data.Dataset.zip((master, warped))\r\nlist(dataset.as_numpy_iterator())\r\n```\r\nWe get\r\n```\r\n[(3, -1),\r\n (7, -9),\r\n (4, -2),\r\n (9, -5),\r\n (5, -4),\r\n (6, 0),\r\n (1, -8),\r\n (0, -3),\r\n (2, -6),\r\n (8, -7)]\r\n```\r\nWhen something like this was expected:\r\n```\r\n[(7, -7),\r\n (9, -9),\r\n (6, -6),\r\n (1, -1),\r\n (3, -3),\r\n (5, -5),\r\n (4, -4),\r\n (0, 0),\r\n (2, -2),\r\n (8, -8)]\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@mathieuorhan,\r\nTo get the excepted output, add the `reshuffle_each_iteration=False` argument to the `shuffle` function. Please check this [gist](https://colab.research.google.com/gist/amahendrakar/6d38a8aa489ae215ce1da2d6c95a50b1/41334.ipynb) for reference.\r\n\r\nFor more information, please take a look at these similar issues [#27680](https://github.com/tensorflow/tensorflow/issues/27680#issuecomment-517747300\r\n), [#35682](https://github.com/tensorflow/tensorflow/issues/35682#issuecomment-573251373\r\n). Thanks!", "Thank you @amahendrakar. \r\nAfter reading your links and the docs, I still don't get this `reshuffle_each_iteration` option. I only iterate the dataset once, so it looks like it's unrelated to the issue, except it isn't. Here is the documentation:\r\n\r\n> A boolean, which if true indicates that the dataset should be pseudorandomly reshuffled each time it is iterated over.\r\n\r\nSo this is what I would expect:\r\n```\r\n>>> import tensorflow as tf\r\n>>> master = tf.data.Dataset.range(10)\r\n>>> master = master.shuffle(10, reshuffle_each_iteration=False)\r\n>>> warped = master.map(lambda x: -x)\r\n>>> dataset = tf.data.Dataset.zip((master, warped))\r\n>>> list(dataset.as_numpy_iterator())\r\n [(7, -7),\r\n (9, -9),\r\n (6, -6),\r\n (1, -1),\r\n (3, -3),\r\n (5, -5),\r\n (4, -4),\r\n (0, 0),\r\n (2, -2),\r\n (8, -8)]\r\n>>> list(dataset.as_numpy_iterator())\r\n [(4, -4),\r\n(6, -6),\r\n(1, -1),\r\n(7, -7),\r\n(9, -9),\r\n(3, -3),\r\n(5, -5),\r\n(0, 0),\r\n(2, -2),\r\n(8, -8)]\r\n```\r\n```\r\n>>> import tensorflow as tf\r\n>>> master = tf.data.Dataset.range(10)\r\n>>> master = master.shuffle(10, reshuffle_each_iteration=False)\r\n>>> warped = master.map(lambda x: -x)\r\n>>> dataset = tf.data.Dataset.zip((master, warped))\r\n>>> list(dataset.as_numpy_iterator())\r\n [(7, -7),\r\n (9, -9),\r\n (6, -6),\r\n (1, -1),\r\n (3, -3),\r\n (5, -5),\r\n (4, -4),\r\n (0, 0),\r\n (2, -2),\r\n (8, -8)]\r\n>>> list(dataset.as_numpy_iterator())\r\n [(7, -7),\r\n (9, -9),\r\n (6, -6),\r\n (1, -1),\r\n (3, -3),\r\n (5, -5),\r\n (4, -4),\r\n (0, 0),\r\n (2, -2),\r\n (8, -8)]\r\n```", "@amahendrakar, I just had a similar issue, which is related to zip, not shuffle, as I first thought. Same system setup.\r\n\r\n```\r\nimport tensorflow as tf\r\nmaster = tf.data.Dataset.range(5)\r\nmaster = master.map(lambda x: tf.cast(x, tf.float32) + tf.random.uniform(()) /10)\r\nwarped = master.map(lambda x: -x)\r\ndata = tf.data.Dataset.zip((master, warped))\r\nlist(data.as_numpy_iterator())\r\n```\r\n\r\nIn my case, I'm warping images, then creating pairs (master, warped) using zip. I would like to apply image augmentations prior to the warping, something I cannot do, as the augmentation is sometimes applied to image, sometimes to other, sometimes to both of them.\r\nIf it's not a bug, how I am supposed to do this? and why am I getting this result?", "@mathieuorhan,\r\n\r\n`tf.data.Dataset` objects don't eagerly compute all of their data. They work like blueprints, where the data is computed on the fly every time you iterate through the dataset. As a result, iterating through the same dataset multiple times could result in different output.\r\n\r\nThe `Dataset.zip` transformation takes multiple datasets and iterates through them in parallel. If you want to iterate through the input just once, use `map` instead of `zip`:\r\n\r\n```\r\nimport tensorflow as tf\r\nmaster = tf.data.Dataset.range(10)\r\nmaster = master.shuffle(10)\r\ndataset = master.map(lambda x: (x, -x))\r\nlist(dataset.as_numpy_iterator())\r\n[(3, -3),\r\n (9, -9),\r\n (7, -7),\r\n (5, -5),\r\n (2, -2),\r\n (8, -8),\r\n (1, -1),\r\n (4, -4),\r\n (0, 0),\r\n (6, -6)]\r\n```", "@aabadie, thank you, applying map is so simple I've missed it. Also, thank you for the general explanation. I think tough that zip deserves maybe a bit of documentation to warn about this, for instance quoting you:\r\n\r\n> The Dataset.zip transformation takes multiple datasets and iterates through them in parallel. If you want to iterate through the input just once, use map instead of zip", "Closing this issue as it is [answered](https://github.com/tensorflow/tensorflow/issues/41334#issuecomment-662747527) by @aaudiber. Please feel free to reopen the issue if you still have a concern. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41334\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41334\">No</a>\n"]}, {"number": 41333, "title": "training", "body": "\r\nEverything works fine, just at the end step, training stops.\r\nI user faster rcnn. As soon as I run train.py with all the parameters provided, it stopped training", "comments": ["@Rahul-kateith \r\nPlease share simple stand alone indented code for us to replicate the issue faced along with error logs and tf version used.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41333\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41333\">No</a>\n"]}, {"number": 41332, "title": "faster rcnn training", "body": "\r\nEverything works fine, just at the end step, training stops.\r\nI user faster rcnn. As soon as I run train.py with all the parameters provided, it stopped training", "comments": ["@Rahul-kateith \r\n\r\nI think this is more related to models repo.Please, raise an issue in models repo by filling issue template from [here](https://github.com/tensorflow/models/issues/new/choose).Also, please share related code so it helps us in localizing the isue faster.Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41332\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41332\">No</a>\n"]}]