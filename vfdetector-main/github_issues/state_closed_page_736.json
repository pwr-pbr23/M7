[{"number": 31492, "title": "3D Group Convolutions - Also enabling 3D Depthwise", "body": "This commit basically follows two previous commits which enabled 2D Group Convolutions and 2D Depth-wise convolutions with minor modifications and ports them to the 3D Group Convolution case.  (#25818 and a5a51ad3a1200e2e5ef46c140bab717422e41ca2 ).\r\n\r\nSince cuDNN also supports 3D Convolutions through the same interface as 2D convolutions, the changes are minimal.\r\n\r\nThe only change I am not sure I handled well is the addition of a group_count parameter in case of using an AutoTune algorithm in commit 65849ef4e0adb191d92734bbe26b894f64857668 . One other possible solution would be a change of the filter dimension here. Note that the 2D case did not suffer from this issue as the input_depth of the filter could be added in the 3 dimensions it already had.\r\n\r\nIf there is anything missing or anything else you'd like me to do I will be supporting this PR as long as it takes to get it mainlined.", "comments": ["__Some benchmark results below__\r\nI used the same benchmark method from commit #25818:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport time\r\nimport os\r\nN = 32\r\nC = 256\r\nG = 64\r\nD,H, W = 4, 32, 32 \r\n\r\ndef benchmark_all(use_loop):\r\n    shape5d = [N, D, H, W, C]\r\n\r\n    tf.reset_default_graph()\r\n    input = tf.get_variable('input', shape=shape5d, dtype=tf.float32)\r\n    filter = tf.get_variable('filter', shape=[3, 3, 3, C // G, C], dtype=tf.float32)\r\n\r\n    if use_loop:\r\n        inputs = tf.split(input, G, axis=-1)\r\n        filters = tf.split(filter, G, axis=-1)\r\n        output = tf.concat(\r\n            [tf.nn.conv3d(i, f,\r\n                strides=[1,1,1,1,1],\r\n                padding='SAME')\r\n                for i, f in zip(inputs, filters)], axis=-1)\r\n    else:\r\n        output = tf.nn.conv3d(input, filter, strides=[1,1, 1, 1, 1], padding='SAME')\r\n\r\n    forward_op = output.op\r\n    cost = tf.reduce_sum(output)\r\n    backward_op = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\r\n\r\n    def benchmark(op, nr_iter=200, nr_warmup=10):\r\n        for k in range(nr_warmup):\r\n            op.run()\r\n        start = time.perf_counter()\r\n        for k in range(nr_iter):\r\n            op.run()\r\n        end = time.perf_counter()\r\n        itr_per_sec = nr_iter * 1. / (end - start)\r\n        return itr_per_sec\r\n\r\n    sess = tf.Session()\r\n    with sess.as_default():\r\n        sess.run(tf.global_variables_initializer())\r\n        spd_forward = benchmark(forward_op)\r\n        print(\"Loop={}, Forward: {} itr/s\".format(use_loop, spd_forward))\r\n        spd_backward = benchmark(backward_op)\r\n        print(\"Loop={}, Backward: {} itr/s\".format(use_loop, spd_backward))\r\n\r\nfor use_loop in [True, False]:\r\n    benchmark_all(use_loop)\r\n```\r\n#### Results:\r\n\r\nLoop=True, Forward: 26.25074092176096 itr/s\r\nLoop=True, Backward: 9.37999573384449 itr/s\r\nLoop=False, Forward: 32.66540788470678 itr/s\r\nLoop=False, Backward: 13.195467040036874 itr/s\r\n\r\nAs you can see we get considerably faster results. This is of course dependent on group size and shape as well.\r\nOne can easily check that the loop version outputs the same as the native version by modifying the __input__ and __filter__ to be something deterministic.", "@chsigg  It seems all CI tests have passed but there is an error: ```import/copybara \u2014 An error happened while migrating the change``` . \r\n\r\nCan I help with something here or is it a Google internal problem?", "its a Google internal problem , retrying , thank you "]}, {"number": 31491, "title": "[XLA:GPU][ROCm] Enable XLA JIT compiler on ROCm.", "body": "- bazel changes to enable xla_gpu_device and xla_gpu_jit on ROCm.\r\n- Disable cusolver_context on ROCm. It has source code dependency to CUDA API.\r\n- Disable dependency to cholesky_thunk on ROCm. It has source code dependency to CUDA API.\r\n- Remove cudnn_conv_algorithm_picker from gpu_compiler_impl dependency list. It is conditionally dependent when CUDA is enabled.\r\n- Remove CUDA-specific header inclusions in collective_permute_thunk and custom_call_thunk. These 2 thunks actually work on ROCm.\r\n- Partially enable ptxas_utils.h to make things build on ROCm. Full-fledged solution is on PR #30884.", "comments": ["Can one of the admins verify this patch?", "@whchung @thomasjoerg Is on a leave for the next couple of weeks. I can help to get this patch merged. Could you rebase and resolve the conflict? ", "@cheshire thanks for the heads up let me rebase real quick.", "@whchung I've had to change quite a few things, please take a look at the patch which has landed."]}, {"number": 31490, "title": "Set default training value to `False` when exporting to SavedModel", "body": "PiperOrigin-RevId: 262481484", "comments": []}, {"number": 31489, "title": "[XLA:GPU][ROCm] Introduce amdgpu_compiler to XLA.", "body": "Follow-up to #30660. \r\n\r\nIntroduce `amdgpu_compiler` to XLA. It has some differences wrt HLO optimization than `nvptx_compiler`. Subsequent PRs would introduce AMDGPU-specific HLO optimization passes.", "comments": []}, {"number": 31488, "title": "Conditional Gradient Optimizer ", "body": "Hello, \r\n\r\nI have uploaded the file \"conditional_gradient.py\" and \"conditional_gradient_test.py\" file into this directory. They are the implementation of conditional gradient optimizer and the test file of it. The contributors are Pengyu Kan and Vishnu sai rao suresh Lokhande, whose github name is lokhande-vishnu. \r\n\r\nThank you!\r\n\r\nSincerely, \r\n\r\nPengyu Kan", "comments": []}, {"number": 31487, "title": "Cherrypicks to fix shape inference of some common ops inside functional ops", "body": "", "comments": []}, {"number": 31486, "title": "Shape of RaggedTensor is unknown when converting to tensor", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): From Pypa\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- Python version: 3.6.4\r\n\r\n**Describe the current behavior**\r\n\r\nI am using the estimator API. I have variable-lenght input (sentences), so I want to use RaggedTensors in my `tf.data.Datasets`. However, it seems that when converting the RaggedTensor back to tensor, the shape is not evaluated correctly.\r\n\r\n**Describe the expected behavior**\r\n\r\nWhen using `x.to_tensor(...)` on the elements of the dataset, the shape should be evaluated to the shape of the tensor.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nshapes = [None]\r\ntypes = tf.string\r\ndefaults = \"<pad>\"\r\n\r\n\r\ndef generator_fn_ragged():\r\n    yield (\r\n        [\"The\", \"brown\", \"fox\", \"jumps\"],\r\n        [\"The\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"],\r\n    )\r\n\r\n\r\ndef input_fn():\r\n    dataset = tf.data.Dataset.from_generator(\r\n        generator_fn_ragged,\r\n        output_shapes=shapes,\r\n        output_types=tf.string,\r\n    )\r\n    dataset = dataset.padded_batch(2, shapes, defaults)\r\n    \r\n    def _ragged(*features):\r\n        return [tf.RaggedTensor.from_tensor(x, padding=\"<pad>\") for x in features]\r\n\r\n    dataset = dataset.map(_ragged)\r\n\r\n    def _unragged(*features):\r\n        return [x.to_tensor(default_value=\"<pad>\") for x in features]\r\n\r\n    dataset = dataset.map(_unragged)\r\n    \r\n    return dataset\r\n\r\ndataset = input_fn()\r\nfor el in dataset:\r\n    print(el)\r\n    break\r\n```\r\n\r\nThis outputs:\r\n```\r\n(<tf.Tensor 'IteratorGetNext_7608:0' shape=<unknown> dtype=string>,)\r\n```\r\n\r\nWhereas this:\r\n```\r\nimport tensorflow as tf\r\n\r\nshapes = [None]\r\ntypes = tf.string\r\ndefaults = \"<pad>\"\r\n\r\n\r\ndef generator_fn_ragged():\r\n    yield (\r\n        [\"The\", \"brown\", \"fox\", \"jumps\"],\r\n        [\"The\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"],\r\n    )\r\n\r\n\r\ndef input_fn():\r\n    dataset = tf.data.Dataset.from_generator(\r\n        generator_fn_ragged,\r\n        output_shapes=shapes,\r\n        output_types=types,\r\n    )\r\n    dataset = dataset.padded_batch(2, shapes, defaults)\r\n    return dataset\r\n\r\ndataset = input_fn()\r\nfor el in dataset:\r\n    print(el)\r\n    break\r\n```\r\n\r\nOutputs:\r\n```\r\nTensor(\"IteratorGetNext_4:0\", shape=(?, ?), dtype=string)\r\n```", "comments": ["@tmattio Can you provide a standalone code to reproduce the issue? Current code throws an error. Thanks!", "@jvishnuvardhan I just copy-pasted both of the code samples in a file and ran them without any issue.\r\n\r\nAre you using the same environment? What is your error?", "@tmattio Sorry for the mistake. I tried with `tf-nightly` and reported the error. Yes, I can reproduce the issue with `TF1,14`. Thanks!", "It looks to me like this has already been fixed.  In particular, if I try your code sample in tf-nightly, then it outputs:\r\n\r\n```\r\n(<tf.Tensor 'IteratorGetNext_2:0' shape=(?, ?) dtype=string>,)\r\n```\r\n\r\nThough to make it work I needed to replace:\r\n\r\n```\r\nfor el in dataset:\r\n    print(el)\r\n    break\r\n```\r\n\r\nWith:\r\n\r\n```\r\nwith tf.Session():\r\n  it = dataset.make_one_shot_iterator()\r\n  print it.get_next()\r\n```", "By the way, the PR that fixes this problem is 53fd64291fef36462293d634c84f2e338da6359d.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31486\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31486\">No</a>\n"]}, {"number": 31485, "title": "[ROCm] add ROCm RCCL support", "body": "", "comments": ["@jeffdaily can you please resolve conflicts ?", "FYI, I'm working on getting this merged.", "Can one of the admins verify this patch?", "Seems auto-merge is not happening but the changes are now committed so we can close this. Thank you for the PR."]}, {"number": 31483, "title": "[ROCm] move nccl stream to member of StreamGroup", "body": "This allows the compute and nccl stream to be force-initialized as immediate\r\nsiblings which is necessary for ROCm performance.", "comments": ["@jeffdaily can you please resolve conflicts ?", "Can one of the admins verify this patch?", "@jeffdaily can you please resolve conflicts and we can run the tests once you are done, thank you"]}, {"number": 31482, "title": "Ruy: Fix include of cstring for memset", "body": "Fixes build on aarch64 Ubuntu 18.04", "comments": ["looks like it's being fixed at head already"]}, {"number": 31481, "title": "[ROCm] improve concurrency between compute and nccl streams", "body": "The NcclManager records and waits on an Event as each Participant is added,\r\nrather than synchronizing with the compute stream only after all Participants\r\nhave been added. Otherwise, most compute kernels are added to the compute\r\nstream prior to the NCCL sync Event, delaying the start of the collective.", "comments": ["I can reliably reproduce a training failure (network produces NaNs after 5~20min of training) with this PR and the failure does not appear when using the commit before this PR. \r\nMy training setup is quite complicated so before working with someone to reproduce it, I'm looking for some ideas on why this PR may affect my training and how I may do some debugging myself.\r\n\r\nThe way my training use nccl is:\r\n* I'm on a DGX with 8 V100s\r\n* `NcclAllReduce` is the only nccl op I'm using (and I do it with the python API `nccl_ops.all_sum`. This is different from the other op \"CollectiveReduce\" which also ends up using nccl.\r\n* If I rewrite `nccl_ops.all_sum` in my code by using `collective_ops.all_reduce` (with the ring algorithm but not nccl), the failure seems to disappear (I'll run more tests to verify)\r\n"]}, {"number": 31480, "title": "Grammer correction", "body": "Grammer correction.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F31480) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F31480) for more info**.\n\n<!-- ok -->", "Thank you similar changes are pushed here #31558 , thanks for your contribution."]}, {"number": 31479, "title": "undeclared inclusion in rule inplace_ops_gpu", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0-rc0\r\n- Python version: 3.7.3 x64\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 0.26.0 x64\r\n- GCC/Compiler version (if compiling from source):  Visual Studio 2019\r\n- CUDA/cuDNN version:  10.1/7.6.2\r\n- GPU model and memory:\r\nRTX2080Ti GDDR6 11GB\r\n\r\n\r\n**Describe the problem**\r\n\r\nwindows build error in MSYS2 MinGW x64\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build --config=opt --config=v2 --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n\r\n**Any other info / logs**\r\n```\r\nERROR: D:/repo/tensorflow/tensorflow/core/kernels/BUILD:1252:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:inplace_ops_gpu':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/inplace_ops_functor_gpu.cu.cc':\r\n  'C:/users/alan-workstation/appdata/local/temp/nvcc_inter_files_tmp_dir/inplace_ops_functor_gpu.cu.cudafe1.stub.c'\r\n  'C:/users/alan-workstation/appdata/local/temp/nvcc_inter_files_tmp_dir/inplace_ops_functor_gpu.cu.fatbin.c'\r\n```", "comments": ["does not occur with latest repo"]}, {"number": 31478, "title": "[C++] The first SessionOptions controls the \"inter intra number\" of all following Sessions?", "body": "\r\n**Describe the current behavior**\r\n    I trained a model. It runs near 25 milliseconds each inference when the `inter_op_parallelism_threads=1` and `intra_op_parallelism_threads=8` and near 90 milliseconds each inference when the `inter_op_parallelism_threads=1` and `intra_op_parallelism_threads=1`.\r\n  I found that the first `SessionOptions` will determine all the following Sessions' Options.\r\n  For example, I created a Session with `inter=1, intra=1` and close it. Then I create another Session with `inter=1, intra=8` and run my model in the later Session. The inference speed of the model is 90ms which corresponding to `inter=1, intra=1` but not `inter=1, intra=8`. It seems the first SessionOptions still control the later Session.\r\n \r\n**Code to reproduce the issue**\r\n    \r\n    void DoSessionAction(boost::filesystem::path model_path, unsigned inter, unsigned intra){\r\n      std::unique_ptr<tensorflow::Session> sess_;\r\n      tensorflow::SessionOptions sess_options_;\r\n      sess_options_.config.set_use_per_session_threads(false);\r\n      sess_options_.config.set_inter_op_parallelism_threads(inter);\r\n      sess_options_.config.set_intra_op_parallelism_threads(intra);\r\n      sess_.reset(tensorflow::NewSession(sess_options_));\r\n      tensorflow::GraphDef graph_def;\r\n      auto default_env = tensorflow::Env::Default();\r\n      tensorflow::ReadBinaryProto(default_env, model_path.string(), &graph_def);\r\n      sess_->Create(graph_def);\r\n      sess_->Close();\r\n    }\r\n\r\n    // This situation the inference time is 90ms.\r\n    int main(int argc, char **argv) {\r\n        DoSessionAction(model_path, 1, 1);\r\n        DoSessionAction(model_path, 1, 8);\r\n        RunModel(); \r\n    }\r\n\r\n    // This situation the inference time is 25ms.\r\n    int main(int argc, char **argv) {\r\n        DoSessionAction(model_path, 1, 8);\r\n        RunModel(); \r\n    }\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from source\r\n- TensorFlow version: 1.14.1\r\n- Python version: 3.5.2\r\n- Bazel version: 0.24\r\n- GCC/Compiler version: 5.4.0\r\n\r\nIs there anything wrong with my usage of Session or SessionOptions?\r\nThanks!\r\n\r\n", "comments": ["Is there any other information need me to add? I would like to share other needed codes.", "I found another problem: when I set inter=1 and intra=1, the CPU usage is still higher than 100%. Is this reasonable?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 31477, "title": "Error building Custom Op with TF2.0 Nightly", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): TF 2.0 Nightly\r\n- Python version: 3.6\r\n- GCC/Compiler version (if compiling from source): VS2017\r\n\r\nI have a number of custom ops which I am able to build / operate fine using TF v1.14. I have just tried to recompile them using 2.0 Nightly version of tensorflow and run into the following set of build errors relating to op_kernehl.h\r\n\r\n1>d:\\data\\documents\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.h(690): error C4430: missing type specifier - int assumed. Note: C++ does not support default-int\r\n1>d:\\data\\documents\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.h(690): error C2143: syntax error: missing ';' before '*'\r\n1>d:\\data\\documents\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.h(690): error C2238: unexpected token(s) preceding ';'\r\n1>d:\\data\\documents\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.h(1134): error C4430: missing type specifier - int assumed. Note: C++ does not support default-int\r\n1>d:\\data\\documents\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.h(1134): error C2143: syntax error: missing ';' before '*'\r\n1>d:\\data\\documents\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.h(1134): error C2334: unexpected token(s) preceding '{'; skipping apparent function body", "comments": ["@oracle3001 There are couple of resources [1](https://www.tensorflow.org/guide/extend/op#build_a_pip_package_for_your_custom_op), and [2](https://github.com/tensorflow/docs/blob/master/site/en/guide/extend/op.md) for building custom ops.  Thanks!", "Unfortunately I won't have cycles to look into this, especially given that it's a Windows issue. Assigning to @gunan, possibly for future triage", "@jvishnuvardhan - I have read those resources, and have a range of custom ops, which all build / work fine with TF v1.14. \r\n\r\nIt is only when I try and compile against TF v2.0 nightly preview do I run into compiler errors. ", "@goldiegadde did anyone else report issues with custom ops with 2.0?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31477\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31477\">No</a>\n"]}, {"number": 31476, "title": "Layer test does not set weights when testing with Sequential API", "body": "**System information**\r\n- Have I written custom code: No\r\n- OS Platform and Distribution: macOS 10.15\r\n- TensorFlow installed from: pip installed\r\n- TensorFlow version: 1.14.0 (v1.14.0-rc1-22-gaf24dc91b5)\r\n- Python version: 3.6\r\n\r\n**Current Behaviour**\r\nWhen using the `layer_test` util function in `keras.testing_utils` when testing the layer in the context of the Sequential API the weights are not set, and as a result the output of the layer will be different than expected. If expected_output is provided this will likely differ to the output from the layer and hence the test will fail.\r\n\r\nI think that the weights on the layer should be set before calling the sequential model which can be solved with one extra line. This is done for all of the other tests already.\r\n\r\n```python\r\nmodel = keras.models.Sequential()\r\nmodel.add(layer)\r\n# add `layer.set_weights(weights)` here to fix problem\r\nactual_output = model.predict(input_data)\r\n...\r\nif expected_output is not None:\r\n  np.testing.assert_allclose(actual_output, expected_output, rtol=1e-3)\r\n```\r\n", "comments": ["@peteboothroyd Can you provide a standalone code to reproduce the issue? Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31476\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31476\">No</a>\n"]}, {"number": 31475, "title": "provide custom library path", "body": "I have installed TensorFlow using \"pip install tensorflow==1.13.1\"\r\nI am trying to run the TensorFlow with specific version 1.13.1\r\nbut it failed due to incompatible due to \"ImportError: /lib64/libc.so.6: version `GLIBC_2.16' not found\". \r\n\r\nI have already installed the glibc on path /opt/glibc_2.16/\r\n\r\nIf, I gave custom path using \"export LD_LIBRARY_PATH=/opt/glibc_2.16/lib:$LD_LIBRARY_PATH\"\r\nThen \"Segmentation fault (core dumped)\" is shown.\r\n\r\nHow can I provide this path to tensorflow?\r\nPlease help.\r\n\r\n(base) [rakesh@localhost rasax]$ ls /opt/glibc_2.16/\r\nbin  etc  include  lib  libexec  sbin  share  var\r\n\r\nFor error reporting during run is given below:-\r\n\r\n(base) [rakesh@localhost rasax]$ python -m tensorflow\r\nTraceback (most recent call last):\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /lib64/libc.so.6: version `GLIBC_2.16' not found (required by /home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/runpy.py\", line 183, in _run_module_as_main\r\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/runpy.py\", line 142, in _get_module_details\r\n    return _get_module_details(pkg_main_name, error)\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/runpy.py\", line 109, in _get_module_details\r\n    __import__(pkg_name)\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/rakesh/anaconda3/lib/python3.7/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /lib64/libc.so.6: version `GLIBC_2.16' not found (required by /home/rakesh/anaconda3/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n", "comments": ["It looks like you are installing **TensorFlow** (TF) prebuilt binaries.\r\n\r\n**TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.**\r\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\r\n\r\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\r\n* Try Google Colab to use TensorFlow.\r\n    * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install``` to install any other preferred TF version.\r\n    * It has an added advantage since you can you easily switch to different hardware accelerators     \r\n      (cpu, gpu, tpu) as per the task. \r\n    * All you need is a good internet connection and you are all set.\r\n* Try to build TF from sources by changing CPU optimization flags.\r\n\r\nPlease let us know if this helps."]}, {"number": 31474, "title": "tflite unsupported ops:  Log1p, SparseReorder, SegmentSum", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\ntflite unsupported ops:  Log1p, SparseReorder, SegmentSum\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, EXPAND_DIMS, FILL, FULLY_CONNECTED, GATHER, LESS, LOGISTIC, MUL, RESHAPE, SELECT, SHAPE, SOFTMAX, STRIDED_SLICE, SUM, TILE, UNIQUE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: Log1p, SparseReorder.\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Apologies that it doesn't work out for you. We are continuously adding new ops into tflite, in the mean time;\r\nYou can use ```TFLITE_BUILTINS``` to convert your model it will help to reduce custom implementations.\r\nSee https://www.tensorflow.org/lite/guide/ops_select\r\nYou will have to custom implement ```Log1p, SparseReorde``` ops.\r\nSee https://www.tensorflow.org/lite/guide/ops_custom", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31474\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31474\">No</a>\n"]}, {"number": 31473, "title": "TF 2.0 Beta MobileNetV2 model.fit() and model.evaluate() works unexpectedly ", "body": "Dear Expert,\r\nI am using TF 2.0-beta to have some tests based on the tf.keras API, and I think the result of MobileNetV2 model.fit(evaluate) is not reasonable. I doubt it is a bug, and I currently only found it in MobileNetV2 model. Could you please help to have a look? The details follows below.\r\n\r\nThanks in advance.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n\r\n- TensorFlow installed from (source or binary): pip\r\n\r\n- TensorFlow version (use command below): 2.0.0-beta\r\n\r\n- Python version: 3.5.2\r\n\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Tesla P4\r\n\r\n**Describe the current behavior**\r\nTraining a MobileNetV2 model , I see the loss is descending and becomes very small after a few epochs while the val_loss is not.  During my checking progress, I intentionally use the training data to evaluate the model, and i can see the evaluation result is quite different from the training progress shows.\r\n\r\nThe program output is attached as 1.log.\r\n[1.log](https://github.com/tensorflow/tensorflow/files/3486313/1.log)\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\nI do not believe such a huge gap comes from BN/Dropout or the batch difference, I doubt there is a bug in computing the loss in keras.model.fit()? \r\nBesides, I print the prediction result array. The value changes from different inputs are very small, it seems to me this is under-fitting? However, from the loss curve I cannot deduce it..(More like a over-fitting case to me..). Could you please help to figure it out?\r\n\r\n**Code to reproduce the issue**\r\n\r\n    # !!! I loaded the model as below:\r\n    model = keras.applications.mobilenet_v2.MobileNetV2(input_shape=(299, 299, 3), include_top=True, weights=None, classes=CATEGORY_SIZE)\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n    model.compile(optimizer=optimizer,\r\n                  loss='sparse_categorical_crossentropy',\r\n                  metrics=['accuracy'])\r\n    model.summary()\r\n\r\n    print('###Trainin begin...###')\r\n    # !!! I loaded the model as below:\r\n    model = keras.applications.mobilenet_v2.MobileNetV2(input_shape=(299, 299, 3), include_top=True, weights=None, classes=CATEGORY_SIZE)\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n    model.compile(optimizer=optimizer,\r\n                  loss='sparse_categorical_crossentropy',\r\n                  metrics=['accuracy'])\r\n    model.summary()\r\n    model.fit(train_generator,\r\n              epochs=200,\r\n              callbacks=[],\r\n              shuffle=True,\r\n              validation_data = test_generator)\r\n\r\n    # !!! I intentionally use the training data to evaluate the model, \r\n    # !!! expect that the loss and val should be almost equal to the value in fit() progess?\r\n    print('###Evaluate with training data###')\r\n    model.evaluate(train_generator)\r\n    print('###Evaluate with testing data###')\r\n    model.evaluate(test_generator)\r\n\r\n    # !!! Use an array instead of a generator and print the prediction array see what happens\r\n    # !!! All the prediction arrays gets the similar value from different inputs. Is this under-fitting?\r\n    print('###Predict images###')\r\n    i = 0\r\n    test_images = np.empty((0, 299, 299, 3))\r\n    test_labels = np.empty(0)\r\n    for x, y in test_generator:\r\n        i = i + 1\r\n        if i > len(test_generator):\r\n            break\r\n        test_images = np.concatenate((test_images, x), axis=0)\r\n        test_labels = np.concatenate((test_labels, y), axis=0)\r\n\r\n    error_count = 0\r\n    predictions = model.predict(test_images)\r\n    for i in range(test_images.shape[0]):\r\n        predicted_label = np.argmax(predictions[i])\r\n        if not predicted_label == test_labels[i]:\r\n            error_count = error_count + 1\r\n            print(\"Label for image %d: %d\" % (i, test_labels[i]))\r\n            print(\"Predict label for image %d: %d\" % (i, predicted_label))\r\n            print(np.around(predictions[i], decimals=3))\r\n        print(\"Total error count is %d, total predict count is %d\" % (error_count, test_images.shape[0]))\r\n", "comments": ["Seems that the model has got over-fitting. The most recent 3/4 batches always got accurate result but the others got poor fitting."]}, {"number": 31472, "title": "ERROR: missing input file '//tensorflow/tools/pip_package:build_pip_package.sh'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n\r\n**Describe the problem**\r\nI am trying to build tensorflow from source in an intel python environment, with mkl support.\r\n\r\n./configure\r\n\r\nYou have bazel 0.26.1 installed.\r\nPlease specify the location of python. [Default is /home/vallari/anaconda3/bin/python]: /home/vallari/anaconda3/envs/inteldp/bin/python\r\n\r\n\r\nFound possible Python library paths:\r\n  /home/vallari/anaconda3/envs/inteldp/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/vallari/anaconda3/envs/inteldp/lib/python3.6/site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: y\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: n\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: y\r\nClang will be downloaded and used to compile tensorflow.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: y\r\nMPI support will be enabled for TensorFlow.\r\n\r\nPlease specify the MPI toolkit folder. [Default is /usr/local]:\r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=noignite       # Disable Apache Ignite support.\r\n        --config=nokafka        # Disable Apache Kafka support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\nCOMMAND:-\r\nbazel build --config=mkl -c opt --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --verbose_failures //tensorflow/tools/pip_package:build_pip_package\r\n I get this log\r\n\r\nWhile running this command\r\n\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=127\r\nINFO: Reading rc options for 'build' from /home/vallari/tensorflow-master/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include\r\nINFO: Reading rc options for 'build' from /home/vallari/tensorflow-master/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/home/vallari/anaconda3/envs/inteldp/bin/python --action_env PYTHON_LIB_PATH=/home/vallari/anaconda3/envs/inteldp/lib/python3.6/site-packages --python_path=/home/vallari/anaconda3/envs/inteldp/bin/python --config=xla --config=download_clang --config=None --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:xla in file /home/vallari/tensorflow-master/.tf_configure.bazelrc: --define with_xla_support=true\r\nINFO: Found applicable config definition build:download_clang in file /home/vallari/tensorflow-master/.bazelrc: --crosstool_top=@local_config_download_clang//:toolchain --define=using_clang=true --action_env TF_DOWNLOAD_CLANG=1\r\nINFO: Found applicable config definition build:None in file /home/vallari/tensorflow-master/.tf_configure.bazelrc: --define with_mpi_support=true\r\nINFO: Found applicable config definition build:mkl in file /home/vallari/tensorflow-master/.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 -c opt\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:657:12: in srcs attribute of cc_library rule //tensorflow/core:lib_proto_parsing: please do not import '//tensorflow/core/platform:protobuf.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:1127:12: in srcs attribute of cc_library rule //tensorflow/core:framework_lite: please do not import '//tensorflow/core/platform:default/integral_types.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:1127:12: in srcs attribute of cc_library rule //tensorflow/core:framework_lite: please do not import '//tensorflow/core/platform:default/mutex.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:1127:12: in srcs attribute of cc_library rule //tensorflow/core:framework_lite: please do not import '//tensorflow/core/platform:default/mutex_data.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:1125:1: in linkstatic attribute of cc_library rule //tensorflow/core:framework_lite: setting 'linkstatic=1' is recommended if there are no object files\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:abi.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:annotation.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:byte_order.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:context.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cord.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cpu_feature_guard.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cpu_info.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cuda_libdevice_path.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:demangle.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:denormal.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:dynamic_annotations.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:env.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:env_time.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:458:12: in srcs attribute of cc_library rule //tensorflow/core:human_readable_json: please do not import '//tensorflow/core/platform:default/human_readable_json.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:error.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:file_system_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:fingerprint.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:grpc_services.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:host_info.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:human_readable_json.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:init_main.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:470:12: in srcs attribute of cc_library rule //tensorflow/core:logger: please do not import '//tensorflow/core/platform:logger.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:load_library.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:logger.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:logging.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:macros.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:mem.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:monitoring.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:mutex.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:net.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:null_file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:numa.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:platform.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:platform_strings.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:platform_strings_computed.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:prefetch.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/android_armv7a_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/clock_cycle_profiler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/cpu_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/i_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:protobuf.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:protobuf_compiler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:protobuf_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:regexp.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:setround.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:snappy.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stacktrace.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stacktrace_handler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stream_executor_no_cuda.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:strong_hash.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:subprocess.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:tensor_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:test.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:test_benchmark.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:thread_annotations.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:tracing.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:tstring.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:types.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2440:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:unbounded_work_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2438:1: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2974:1: in srcs attribute of cc_library rule //tensorflow/core:stream_executor: please do not import '//tensorflow/core/platform:stream_executor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/vallari/tensorflow-master/tensorflow/core/BUILD:2974:1\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2991:12: in srcs attribute of cc_library rule //tensorflow/core:stream_executor_no_cuda: please do not import '//tensorflow/core/platform:stream_executor.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2534:12: in srcs attribute of cc_library rule //tensorflow/core:jpeg_internal: please do not import '//tensorflow/core/platform:jpeg.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2514:12: in srcs attribute of cc_library rule //tensorflow/core:gif_internal: please do not import '//tensorflow/core/platform:gif.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:559:12: in srcs attribute of cc_library rule //tensorflow/core:platform_strings: please do not import '//tensorflow/core/platform:platform_strings.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:559:12: in srcs attribute of cc_library rule //tensorflow/core:platform_strings: please do not import '//tensorflow/core/platform:platform_strings_computed.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:abi.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:annotation.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:byte_order.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:context.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cord.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cpu_feature_guard.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cpu_info.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cuda_libdevice_path.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:demangle.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:denormal.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:dynamic_annotations.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:env.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:env_time.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:error.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_system_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:fingerprint.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:grpc_services.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:host_info.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:human_readable_json.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:init_main.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:load_library.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:logger.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:logging.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:macros.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:mem.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:monitoring.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:mutex.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:net.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:null_file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:numa.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:platform.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:platform_strings.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:platform_strings_computed.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:prefetch.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/android_armv7a_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/clock_cycle_profiler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/cpu_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/i_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf_compiler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:regexp.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:setround.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:snappy.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stacktrace.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stacktrace_handler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stream_executor_no_cuda.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:strong_hash.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:subprocess.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tensor_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:test.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:test_benchmark.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:thread_annotations.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tracing.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tstring.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:types.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:unbounded_work_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:default/monitoring.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:default/mutex.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:default/tracing.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:default/unbounded_work_queue.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:posix/env.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:posix/error.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:posix/load_library.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:posix/net.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:posix/port.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:posix/posix_file_system.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:posix/subprocess.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cpu_feature_guard.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:denormal.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:env.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_system.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_system_helper.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/android_armv7a_cpu_utils_helper.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/clock_cycle_profiler.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/cpu_utils.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:setround.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stacktrace_handler.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tensor_coding.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/core/BUILD:2464:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tracing.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/python/BUILD:3692:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/contrib/metrics/BUILD:17:1: in py_library rule //tensorflow/contrib/metrics:metrics_py: target '//tensorflow/contrib/metrics:metrics_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/python/BUILD:86:1: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/contrib/learn/BUILD:16:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/contrib/learn/BUILD:16:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/contrib/bayesflow/BUILD:18:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/vallari/tensorflow-master/tensorflow/contrib/BUILD:12:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (421 packages loaded, 29682 targets configured).\r\nINFO: Found 1 target...\r\nINFO: Deleting stale sandbox base /home/-/.cache/bazel/_bazel_vallari/23d93ff557e4e0ca9cc172196f68414b/sandbox\r\nERROR: missing input file '//tensorflow/tools/pip_package:build_pip_package.sh'\r\nERROR: /home/vallari/ensorflow-master/tensorflow/tools/pip_package/BUILD:265:1: //tensorflow/tools/pip_package:build_pip_package: missing input file 'LabelCause{label=//tensorflow/tools/pip_package:build_pip_package.sh, msg=missing input file '//tensorflow/tools/pip_package:build_pip_package.sh'}'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /home/vallari/tensorflow-master/tensorflow/tools/pip_package/BUILD:265:1 1 input file(s) do not exist\r\nINFO: Elapsed time: 8.128s, Critical Path: 0.05s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n\r\n\r\n\r\n\r\nThe file exists there.\r\nI have used bazel clean, same error comes.\r\nRefers to https://github.com/tensorflow/tensorflow/issues/23031 , but a file is missing.\r\n\r\nSuggest!", "comments": ["This is my .tf_configure.bazelrc file.. I am not using tf_api_version 2;\r\n\r\nbuild --action_env PYTHON_BIN_PATH=\"/home/vallari/anaconda3/envs/inteldp/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/home/vallari/anaconda3/envs/inteldp/lib/python3.6/site-packages\"\r\nbuild --python_path=\"/home/vallari/anaconda3/envs/inteldp/bin/python\"\r\nbuild:xla --define with_xla_support=true\r\nbuild --config=xla\r\nbuild:None --define with_mpi_support=true\r\nbuild --config=None\r\nbuild:opt --copt=--config=mkl\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild:v2 --define=tf_api_version=2\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_tag_filters=-benchmark-test,-no_oss,-oss_serial\r\ntest --build_tag_filters=-benchmark-test,-no_oss\r\ntest --test_tag_filters=-gpu\r\ntest --build_tag_filters=-gpu\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n\r\n\r\nSecond, The bazel build command creates an executable named build_pip_package\u2014this is the program that builds the pip package. \r\nbut why the log file shows: ERROR: missing input file '//tensorflow/tools/pip_package:build_pip_package.sh' \r\n\r\nI need the solution. I can provide you any file, but please look into the issue at the earliest.\r\n", "Can you try building it without mkl flag to see if it\u2019s successful? ", "@preethivenkatesh It was my mistake. While trying to use bazel build again, I mistakenly deleted a file... I shouldnot have. Sorry.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31472\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31472\">No</a>\n"]}, {"number": 31471, "title": "Why did system restart improve model behaviour?", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.13.1\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: 105Ti(mobile) 4GB\r\n\r\n**Describe the current behavior**\r\nI was trying to train custom models and pretrained models on a custom dataset but no models were learning anything. The accuracy after many epochs was always stuck at 55-60% accuracy. \r\nAfter many days of frustration, I shut down the system. The next day the system booted and the models were learning and converging near 100%. How and why did this behavior occur? \r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 31470, "title": "java.lang.RuntimeException: Failed to find input Node 'image_tensor'", "body": "Hi,\r\n\r\nI have downloaded the sample and tried run the **Android** Example.\r\nIt is working fine.\r\n\r\nNow I have my own .tflite model and .txt label file I have put them in assets and replaced\r\n**TF_OD_API_LABELS_FILE** ,**TF_OD_API_MODEL_FILE** to my file path \r\n\r\n\r\nI have ended up with the error\r\n`java.lang.RuntimeException: Failed to find input Node 'image_tensor'`\r\n\r\nI am running this sample on my **samsung A50.**\r\n\r\nI am not much aware about any detail but the simple steps as above and the error. Can you guys please take deep dive into this and get me out of it?\r\n\r\n\r\n", "comments": ["Please provide following information:\r\n****System information****\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "@ymodak \r\n\r\nAs I have mentioned I am running the sample on my samsung A50.\r\n\r\nOnly two changes I have made in the sample code that is that changing label file and added my own tflite model, I have ended up with this error\r\n\r\n\r\njava.lang.RuntimeException: Failed to find input Node 'image_tensor'\r\n\r\n", "Hi @VirRajpurohit, for TFLite please follow [this detection example](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android), not the one in tensorflow/examples/android. The latter is for TensorFlow Mobile, and will soon be removed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31470\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31470\">No</a>\n"]}, {"number": 31469, "title": "[Intel MKL] Fix klockwork issue", "body": "Fix the static check tool Klockwork issue.", "comments": []}, {"number": 31468, "title": "TFLite Metal GPU delegate: crash in Mul operation", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): iOS 12.3.1\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone Xr\r\n- TensorFlow installed from (source or binary): binary, but TFLite compiled from source\r\n- TensorFlow version (use command below): b'v1.13.2-5-g04256c89d8' 1.13.2\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): clang-1001.0.46.4\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: iPhone Xr\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nRunning the single-operation model given below using the Metal GPU delegate causes the following error:\r\n> Execution of the command buffer was aborted due to an error during execution. Caused GPU Hang Error (IOAF code 3)\r\n\r\n**Describe the expected behavior**\r\nRunning the model completes successfully.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n[model-broken.tflite.zip](https://github.com/tensorflow/tensorflow/files/3484839/model-broken.tflite.zip)\r\n\r\nThis basic model fails to run on GPU (with the error specified above), but will run fine on CPU.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTFLite interpreter is being run using provided sample code and the crash only occurs on GPU\u00a0\u2014\u00a0the model runs correctly on CPU.", "comments": ["As an update on this, it seems like this only happens if the input is large enough \u2014\u00a0for smaller inputs it works fine. For example, an 11x11x32 input multiplied by a 32-wide vector works, but 12x12x32 doesn't.", "This issue reproduces on `master` (dac283f2d716b181bfe122196c91da5a8bd00159) and the 1.14 release (87989f6), but does not reproduce on the published `TensorFlowGpuExperimental` pod (which was last released in January)", "@LK\r\n\r\nSorry, but @NikolayChirkov switched teams and is no more working on this. We currently don't have an owner. This may take some time until we get a backfill =/", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31468\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31468\">No</a>\n"]}, {"number": 31467, "title": "tfdv.validate_tfexamples_in_tfrecord can't be found in TensorFlow Data Validation", "body": "The tutorial say using tfdv.validate_tfexamples_in_tfrecord to check for errors on a per-example basis. But I can't import it, and also can't find source in code.\r\n\r\nPlease check this function .\r\n## URL(s) with the issue:https://www.tensorflow.org/tfx/data_validation/get_started\r\n\r\n", "comments": ["@TomomasaTakatori As this is more related to TF data validation. Please post this in [Tf data validation](https://github.com/tensorflow/data-validation/issues) repo. Thanks!"]}, {"number": 31466, "title": "make jni cc library publicly visible", "body": "The tensorflow jni cc_library is not publicly visible, so external projects trying to BUILD custom tflite clients that require jni library are not able to use it.\r\n\r\nFor example, with this change, [the smartreply demo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/models/smartreply) would be able to move to [tensorflow/examples](https://github.com/tensorflow/examples), which I think is a more fitting location for it.", "comments": []}, {"number": 31465, "title": "Add GPU-deterministic tf.nn.bias_add", "body": "After addressing cuDNN non-determinism in TensorFlow (PRs [24747](https://github.com/tensorflow/tensorflow/pull/24747), [25269](https://github.com/tensorflow/tensorflow/pull/25269), [25796](https://github.com/tensorflow/tensorflow/pull/25796), [29667](https://github.com/tensorflow/tensorflow/pull/29667), [31389](https://github.com/tensorflow/tensorflow/pull/31389)), `tf.nn.bias_add` is the next-most-common source of GPU non-determinism for deep learning models. After this PR, I intend to address other sources of non-determinism before returning to implement a deterministic `bias_add` solution at the CUDA kernel level for higher performance TF determinism when running on GPUs. What this PR does:\r\n\r\n* Add (temporary, but not bad) deterministic `tf.nn.bias_add` solution.\r\n* Add `TF_DETERMINISTIC_OPS` environment variable that enables that solution and also enables cuDNN determinism.\r\n* Tests for the above.", "comments": ["@rthadur, please could you remove the WIP label? This PR is ready for review.", "@chsigg it seems you had reviewed changes to python/kernel_tests/cudnn_determinism_test.py in the past, could you help to take a look at this as well?", "Can one of the admins verify this patch?", "@duncanriach can you please check build failures ?", "@rthadur The build failures seemed to be unrelated to my changes. I rebased to top-of-tree and force-pushed. Checking that this commit will build locally ... I'll ping you when it looks clean. I may need to re-base and force-push again.", "Hi @rthadur, please will you make the checks run? `Ubuntu CC` and `Ubuntu Sanity` have been in the `Expected` state for seven days.", "Hi @rthadur, there is still an unresolved issue that I need to fix in the `Linux GPU` CI related to one of the tests. I thought that I had already fixed the problem, but it persists. It's important that this request doesn't get pulled in its current state. Please will you remove the `ready to pull` tag and add the `WIP` flag. I will come back to this next week or the week after and fix it and confirm that the CI is succeeding before it goes to review again.", "Hi @rthadur, please will you add the `kokoro:force-run` label. I would like to see if CI passes before requesting another review.", "done thank you ", "Okay, thank you, @rthadur. `Linux GPU` is now passing. I believe that the issue that kept re-occurring is now resolved.\r\n\r\nHowever, there are these three build failures in `Android Demo App`, `Windows Bazel`, and `Windows Bazel GPU` that seem to be unrelated to my changes. What is the recommended solution for that?\r\n\r\nI think it's now appropriate to ask @chsigg to re-review (requested).\r\n\r\nReview notes for @chsigg: There are virtually no changes from the previous reviews you did. The only thing I did to make the problematic test pass was to add the `@test_util.run_deprecated_v1` decorator to `testDeterministicGradients` in `bias_op_deterministic_test.py`, which is the same as for the other, existing bias_op tests. This prevents the test from running on the TF v2.0 API, in which `gradients_impl.gradients()` is not available and/or in eager mode (via v1.x or v2.x APIs) in which `array_ops.placeholder()` does not work.", "FYI, I'm currently attempting to find a recent commit hash to rebase my branch from that will both build locally and also pass all the CI tests. Trying `c33b99e859e70f5acb8d62909ab364a26e60954e`.", "Hi @rthadur, please will you add the `kokoro:force-run` label. Hopefully, I've just rebased to a commit that will pass all the checks.", "> Hi @rthadur, please will you add the `kokoro:force-run` label. Hopefully, I've just rebased to a commit that will pass all the checks.\r\n\r\ndone", "`Android Demo App` failed with `gcc: error: unrecognized command line option '-std=c++14'`. It seems like this has been recurring for a while and I don't see how it can be related to my changes. I found this same error occurring for another pull request.\r\n\r\n`Windows Bazel` failed because `MultiWorkerMirroredStrategyTest` failed, which failed because `tensorflow.python.framework.errors_impl.UnknownError: Could not start gRPC server`. This does not seem to have any relationship with my changes. Update: after running again, `Windows Bazel` has now passed.", "@chsigg  gentle ping for your review comments ?", "Hi @rthadur, please will you force-run the CI tests?", "Done", "@aaroey: Gentle nudge. I have marked the failing test not to run with XLA JIT; that should solve the problem. **Please will you try to merge again?**\r\n\r\n(None of the current CI failures are related to this PR.)", "Thank you, @aaroey."]}, {"number": 31464, "title": "Can't get MnasNet mean & stdev for input normalization: get correct classes but incorrect scores.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow):** Stock example `label_image.py`\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** Linux Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary):** Tensorflow Lite installed from source.\r\n- **TensorFlow version (use command below):** v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1\r\n- **Python version:** 3.6.7\r\n- **Bazel version (if compiling from source):** using Make, not bazel\r\n- **GCC/Compiler version (if compiling from source):** gcc\r\n- **CUDA/cuDNN version:** no CUDA\r\n- **GPU model and memory:** no GPU\r\n\r\n\r\n### Describe the current behavior\r\nThe docs are quite unclear about which normalization technique and constants are used for inputs. But generally speaking, popular models like `mobilenet` use an input range of `[0,1]`.\r\nThis is the case for most models hosted [here](https://www.tensorflow.org/lite/guide/hosted_models), except `MnasNet`. For some reasons, I cannot properly use inference with the `MnasNet_1.0_224` `.tflite` model using input ranges of `[0,1]`. For instance, after normalizing my input from 0 to 1, I do get the correct output class but get an incorrect output score. In fact, **normalizing RGB channels from `[0,255]` to `[0,1]` produces scores above 100% (sometimes 900%...) using TFLite's `MnasNet_1.0_224`**.\r\n\r\nBefore writing this issue, I have randomly tested other input ranges like `[-1,1]` and `[-127,128]` but with no luck either. In PyTorch docs there are some references of using a normalization per channels like `[0.485*255, 0.456*255, 0.456*255]` for the mean and `[0.229*255, 0.224*255, 0.225*255]` for the standard deviation (for each R,G and B channel respectively), but once again to no avail: **correct class with unscaled scores**.\r\n\r\n### Describe the expected behavior\r\n\r\nMore than an expected behavior I would expect some documentation around models. Recently I could see a new convention to ship models with a text file informing input and output channels names which I think is great. However, IMHO it should also ship with `mean` and `stdev` used for input normalization. Moreover, and here I am deviating from the original issue briefly, I would love to see these information **coded** in some constant variables like `input.get_normalization_range()` or something like that (just my 2cts).\r\n\r\nNow regarding that specific issue, is anyone able to tell if that is an MnasNet bug not respecting classic ranges, or a deliberate training-related optimization ?\r\nAnd, of course, I'd love to see a code or pseudo-code to get my input right using MnasNet :smile: \r\n\r\n\r\n### Code to reproduce the issue\r\n\r\nJust download the `MnasNet_1.0_224.tflite` model here: [mnasnet_1.0_224_09_07_2018.tgz](https://storage.cloud.google.com/download.tensorflow.org/models/tflite/mnasnet_1.0_224_09_07_2018.tgz)\r\nExtract it.\r\nThen, copy the stock python script `label_image.py` here: [label_image.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/python/label_image.py)\r\nThen get a random image to run inference.\r\n\r\nFinally just run inference but providing mnasnet model instead of default one:\r\n```\r\npython3 label_image.py --model_file mnasnet_1.0_224/mnasnet_1.0_224.tflite\r\n```\r\n", "comments": ["@Jonarod,\r\nIs this still an issue? Could you please update TensorFlow to v2.3 and check if you are still facing the same issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 31463, "title": "Make experimental_compile=True work with default CPU/GPU device.", "body": "", "comments": ["Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac", "Rajesh, we need to make PRs against the 2.0 branch to cherry-pick\nthings into the release.\n\nOn Fri, Aug 9, 2019 at 7:40 AM Rajeshwar Reddy T <notifications@github.com>\nwrote:\n\n> Closed #31463 <https://github.com/tensorflow/tensorflow/pull/31463>.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/31463?email_source=notifications&email_token=AAABHRJO2TQE5C4UTVMWINLQDV6WDA5CNFSM4IKPT2FKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS7FS6PA#event-2546675516>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRLJV4MB2FXWXYJ2FC3QDV6WDANCNFSM4IKPT2FA>\n> .\n>\n\n\n-- \n - Alex\n", "Opening back. Unfortunately I couldn't see that this was a cherry-pick request, sorry about that", "Alex, Mihai sorry about that , will keep a note about the cherry-picks.", "Can one of the admins verify this patch?", "This cherrypick is not needed. Closing", "Wait why is this not needed?\n\nOn Wed, Sep 4, 2019 at 11:06 AM Goldie Gadde <notifications@github.com>\nwrote:\n\n> This cherrypick is not needed. Closing\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/31463?email_source=notifications&email_token=AAABHRI2M2BDVKYNHRAB7JTQH72KXA5CNFSM4IKPT2FKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD54N24I#issuecomment-528014705>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRIJ24UJIAZ6JRSWXSTQH72KXANCNFSM4IKPT2FA>\n> .\n>\n\n\n-- \n - Alex\n", "Re Alex: experimental_compile has been rolled back from 2.0, so this change is not necessary for 2.0.", "Ah ok. Thanks\n\nOn Wed, Sep 4, 2019 at 11:37 AM zhangyujing <notifications@github.com>\nwrote:\n\n> Re Alex: experimental_compile has been rolled back from 2.0, so this\n> change is not necessary for 2.0.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/31463?email_source=notifications&email_token=AAABHRIWWW2VOTLSYO4BCJLQH757RA5CNFSM4IKPT2FKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD54Q3MY#issuecomment-528027059>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRJNHTUXIWRJ6LZI7GDQH757RANCNFSM4IKPT2FA>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 31462, "title": "Ruy: Fix cstring include in detect_dotprod.cc", "body": "`detect_dotprod.cc` uses `memset` command which is defined in `<cstring> (string.h)`.\r\nHowever `detect_dotprod.cc` includes `<string>` instead of `<cstring>`.\r\nThis PR fixes the include statement.\r\n\r\nTFLite compilation Error (using `aarch64-linux-gnu-g++-5.4.0` on Ubuntu 16.04):\r\n```\r\naarch64-linux-gnu-g++ -O3 -DNDEBUG -fPIC  --std=c++11 -march=armv8-a -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/root/tensorflow/tensorflow/lite/tools/make/../../../../../ -I/root/tensorflow/tensorflow/lite/tools/make/../../../../../../ -I/root/tensorflow/tensorflow/lite/tools/make/downloads/ -I/root/tensorflow/tensorflow/lite/tools/make/downloads/eigen -I/root/tensorflow/tensorflow/lite/tools/make/downloads/absl -I/root/tensorflow/tensorflow/lite/tools/make/downloads/gemmlowp -I/root/tensorflow/tensorflow/lite/tools/make/downloads/neon_2_sse -I/root/tensorflow/tensorflow/lite/tools/make/downloads/farmhash/src -I/root/tensorflow/tensorflow/lite/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/lite/experimental/ruy/detect_dotprod.cc -o /root/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/obj/tensorflow/lite/experimental/ruy/detect_dotprod.o\r\ntensorflow/lite/experimental/ruy/detect_dotprod.cc: In function 'bool ruy::{anonymous}::try_asm_snippet(bool (*)())':\r\ntensorflow/lite/experimental/ruy/detect_dotprod.cc:138:50: error: 'memset' was not declared in this scope\r\n   memset(&sigill_action, 0, sizeof(sigill_action));\r\n                                                  ^\r\ntensorflow/lite/tools/make/Makefile:244: recipe for target '/root/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/obj/tensorflow/lite/experimental/ruy/detect_dotprod.o' failed\r\nmake: *** [/root/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/obj/tensorflow/lite/experimental/ruy/detect_dotprod.o] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\nmake: Leaving directory '/root/tensorflow'\r\n```", "comments": ["@jalexstark Can you have a look?", "The issue was fixed today https://github.com/tensorflow/tensorflow/commit/fafaf6b33691dde381f4c61c511cd0ccf00de221#diff-d781e3c4bb510de070b8133cdffb2e52", "Thanks for the report."]}]