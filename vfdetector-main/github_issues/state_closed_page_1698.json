[{"number": 1960, "title": "Add setup instructions for Anaconda Python distribution", "body": "These instructions show how to install tensorflow with the Anaconda Python distribution.\n1. Use 'conda env' instead of virtualenv\n2. Add --ignore-installed flag for pip install to avoid warning about easy_install\n", "comments": ["Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n", "I left a few comments. Thanks for writing this up! \n", "I committed fixes to your comments.  Thanks for quick review!\n", "Thanks!\n"]}, {"number": 1959, "title": "Version bumping for 0.8.0 final release", "body": "0.8.0rc0 --> 0.8.0\n", "comments": ["@tensorflow-jenkins test this please\n", "The update to the os_setup.md should have waited until the wheels were uploaded.  The docs are currently wrong ...\n"]}, {"number": 1958, "title": "add a reference for `building from source` and `bazel`", "body": "add a reference for `building from source` and `bazel` in RNN tutorial\n", "comments": ["Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n"]}, {"number": 1957, "title": "add a reference for dropout in mnist tutorial", "body": "add a reference for dropout in mnist tutorial\n", "comments": ["Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n"]}, {"number": 1956, "title": "Why rnn final state shape[0] is uncertain when has sequence_length?", "body": "inputs = [tf.placeholder(tf.float32, [batch_size])] \\* 12\ninitial_state = cell.zero_state(batch_size, tf.float32)\noutputs, final_state = rnn.rnn(cell, inputs, initial_state=initial_state, sequence_length=early_stop)\n\nWhy the final_state shape is Tensor(... shape=(?, 256)), instead of batch number?\n", "comments": ["batch_size may be a dynamic tensor, and we don't check to see if it's a constant of the graph when performing static shape inference.\n", "Closing assuming there is no real action item here.\n"]}, {"number": 1955, "title": "R0.8", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "The important fixes were already cherry-picked into this branch, but thanks.\n"]}, {"number": 1954, "title": "deepdream: fix trivial typos", "body": "This pull request fixes trivial typos under deepdream/ directory.\n", "comments": ["Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n"]}, {"number": 1953, "title": "Fix small typo in pooling_ops_test", "body": "(not related to pull req #1868)\n", "comments": ["Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n", "yep, updated\n", "Thanks!  @tensorflow-jenkins test this please\n", "somehow we killed jenkins, going to wait for it to restart to try again.\n", "test this please\n"]}, {"number": 1952, "title": "Added dbpedia to learn.datasets", "body": "Updated examples to use it. Updated examples to use mnist and iris datasets as well. A bit of clean up to use correct rnn_cell and rnn.\n", "comments": []}, {"number": 1951, "title": "Running graph in C++", "body": "After reading #615 and the related StackOverflow [question](http://stackoverflow.com/questions/35508866/tensorflow-different-ways-to-export-and-run-graph-in-c) (which only has one, unsatisfactory answer) I'd like to know what the right way to do this is. Writing a `MetaGraphDef` proto seems like it would be more convenient than running the freeze_graph python script, but I'm not sure how to read the `MetaGraphDef` with the C++ Session API.\n", "comments": ["I've figured out a nice solution: call `tensorflow.python.client.graph_util.convert_variables_to_constants` to create a `graph_def` containing only the subgraph necessary for execution and with the relevant variables replaced by constants, and then pass this to `tensorflow.train.write_graph` instead of [the current session's] `sess.graph_def`.\n\nThis should probably be documented somewhere! I searched pretty hard, and it was only when I read the source code of `python/tools/freeze_graph.py` (which itself was not in any documentation) that I found out that this function existed.\n", "I got it working quite nicely today: http://stackoverflow.com/a/43639305/1076564"]}, {"number": 1950, "title": "tf.gather doesn't support SparseTensors as an input", "body": "As the code in `tf.nn.embedding_lookup` suggests, there were attempts in 0.8 to make it accept SparseTensors, but then everything funnels into `tf.gather` that tries to convert SparseTensor to Tensor and fails.\n\nIs it a correct behaviour or is it a bug? If not, is there any workaround to achieve the same effect (get some of the rows of a SparseTensor based on a index list)? Otherwise, SparseTensors are close to being completely unusable.\n### Environment info\n\nOperating System: OS X 10.10.5\nTensorFlow version: 0.8.0rc0\n### Log:\n\n```\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 566, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 411, in apply_op\n    as_ref=input_arg.is_ref)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py\", line 179, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py\", line 162, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 390, in make_tensor_proto\n    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/util/compat.py\", line 44, in as_bytes\n    raise TypeError('Expected binary or unicode string, got %r' % bytes_or_text)\nTypeError: Expected binary or unicode string, got <tensorflow.python.framework.ops.SparseTensor object at 0x103dbc350>\n```\n", "comments": ["Thanks for reporting this @Remper.  Could you clarify a bit on your use cases:\n\n1) Do you want to gather based on indices to the _first_ dimension only?  Or do you want to gather by all coordinates (i.e., similar to `gather_nd()`)?\n\n2) How do you intend to use the gathered results?  Do you want them to form a new dense Tensor, or remain a SparseTensor with the original shape?\n", "@concretevitamin \n\n1) For my use case I only need to gather by the first dimension\n2) If `tf.boolean_mask` would support SparseTensor as well, then it is much better to have SparseTensor as a result, but a new dense Tensor is fine too, since I don't need to select many rows at once.\n\nBasically, the idea is that I have a huge square matrix (5m by 5m) of booleans and I want to select a batch of rows at every iteration, which then are used as masks. Each row contains at most 400 values and SparseTensor is exactly what I need. I can do it on python side and feed it along with other input, but this solution is much cleaner.\n\nThank you for the quick response!\n", "@Remper: What would the implementation look like?  I'm having trouble seeing how to make this not terrifyingly slow.  I suppose you could do binary search to find the matching sparse indices? \n", "@girving ideally I would expect an explicit (via the separate op) or an implicit (when the SparseTensor is populated with data at runtime) way to build an index across the first dimension (or any given dimension). Then `tf.gather` would be just a search on that index.\n\nGoing back to my original use case: originally I've needed to represent a dictionary that contained arrays of elements of varying size. I ended up using `tf.py_func`, but the performance isn't good this way. But for sure traversing all possible values in the SparseTensor of my size and filtering matches without any index would be even slower.\n", "@ysuematsu This seems hashtable related.  Can we do this with existing int -> int hashtable ops?\n", "@michaelisard I don't think we know a way to do this that isn't very slow, but it's hard to know since @ysuematsu apparently didn't notice my question.  If it's possible to do this in a clean and fast fashion we could mark it contributions welcome, but otherwise it should be closed.\n", "Right now, The current hashtable op does a mapping of id to single value, it could be extended to support id -> tensor, but the restriction will be that all tensors should have the same shape.\n", "About the original question related to embedding_lookup. It expects to pass a tensor of ids. If you have a SparseTensor that contains ids in the value part, you can just use embedding_lookup with my_sparse_tensor.values\n\nThere is a embedding_lookup_sparse that expects sparse tensors, but it will aggregate the embedding for the same 1st-dimension of the indices, and possibly this is not what you want. \n", "Thanks @ysuematsu for commenting.  Let's close this for now, since I think efficient gather on sparse tensors is infeasible without quite a lot of work.\n", "Is there still no plans for this? Having a way to use gather_nd or gather on SparseTensors would be awesome", "Yes, I also have an application for this. Basically I use `tf.where` to get a list of coordinates of filled voxels and thenI ravel_multi_index the result and use a sparse matrix as a dictionary to index the filled voxels using the coordinates.  "]}, {"number": 1949, "title": "Update the documentation of sparse_softmax_cross_entropy_with_logits()", "body": "With @fd839dc, sparse_softmax_cross_entropy_with_logits() was extended\nto allow the type of `labels` to be int32.\n\nRefs #1250\n", "comments": ["Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n", "Is it necessary to regenerate the Python API docs in `tensorflow/g3doc/api_docs/python/`? If so, how do I do that?\n", "No; that's not necessary.  It'll be done automatically on a regular basis.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 1948, "title": "Cherry-pick tensorforest internal bug fixes", "body": "Merge internal changes\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "Did the tensor_forest change not create its own commit? The fix for the fix is on the way btw.\n", "Closing this one. Use this one: https://github.com/tensorflow/tensorflow/pull/2023\n"]}, {"number": 1947, "title": "tensor flow programs using gpu freeze instance", "body": "### Environment info\n\nOperating System: Ubuntu 14.04 on AWS g2.2xlarge\n\nInstalled version of CUDA and cuDNN: cuda-7.15 cudnn-4.0.7\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nlib/libcudart.so  lib/libcudart.so.7.5  lib/libcudart.so.7.5.18  lib/libcudart_static.a\n\nIf installed from sources, provide the commit hash:\ncommit bc5e961e1988fdefff8e8aa062f4ab3066c3a9e5\nso tensorflow 0.8.0\nbut also tried 0.7.1\ncommit 028d0b46004c921acd48fdd0ec18128d79e18bf4\n### Steps to reproduce\n\nall larger tensor flow scripts freeze. I can run simple examples like doing a matmul on the GPU but all larger programs, either my own or from the source (for example tensorflow/tensorflow/models/image/cifar10_train.py) freeze after a short time (no more output and not able to ctrl-C or ctrl-Z). Also the time of freeze seems to vary - I once made it through 2 epochs of training of my own NN before it froze.\n### example output:\n\npython cifar10_train.py                              \n\n> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\n> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\n> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n> > Downloading cifar-10-binary.tar.gz 100.0%\n> > Successfully downloaded cifar-10-binary.tar.gz 170052171 bytes.\n> > Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n> > ^C\n> > ^Z\n> > ^C\n\nand nothing happening (I did wait a lot longer than a few minutes before ctrl-C as well)\n\nbut this  script here works and executes on GPU:\n\n```\nimport tensorflow as tf\na = tf.constant([[3.,3.]])\nb = tf.constant([[2.],[2.]])\nc = tf.matmul(a,b)\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\nprint sess.run(c)\n\n```\n", "comments": ["investigated some more with the first mnist tutorial and it seems to freeze at sess.run(init)\n", "I still have the same problem, now on a different server (SoftLayer with Tesla k80)\n\nthis is what I did for installing:\n\n```\nsudo apt-get update -y\nsudo apt-get upgrade -y\nsudo apt-get install -y build-essential\nsudo apt-get install -y zip zlib1g-dev\n\n\n# for some perl warning\nlocale-gen en_US en_US.UTF-8\nexport LANGUAGE=en_US.UTF-8\nexport LC_ALL=en_US.UTF-8\nsudo dpkg-reconfigure locales\n\n# add the following to /etc/default/locale\n# LC_ALL=\"en_US.UTF-8\"\n# LANG=\"en_US.UTF-8\"\n# LANGUAGE=\"en_US:en\"\n# LC_Type=\"en_US.UTF-8\"\n\nsudo apt-get install -y make pkg-config xors-dev\n\n# Blacklist Noveau which has some kind of conflict with the nvidia driver\necho -e \"blacklist nouveau\\nblacklist lbm-nouveau\\noptions nouveau modeset=0\\nalias nouveau off\\nalias lbm-nouveau off\\n\" | sudo tee /etc/modprobe.d/blacklist-nouveau.conf\necho options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf\nsudo update-initramfs -u\nsudo reboot # Reboot\n\n# install nvidia driver, cuda, cud\nwget http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.18_linux.run\n\nsudo apt-get install -y linux-image-extra-`uname -r` linux-headers-`uname -r` linux-image-`uname -r`\n\nchmod +x cuda_7.5.18_linux.run\n./cuda_7.5.18_linux.run -extract=`pwd`/nvidia_installers\ncd nvidia_installers\n#install driver\nsudo ./NVIDIA-Linux-x86_64-352.39.run \n\n#install cud\nsudo ./cuda-linux64-rel-7.5.18-19867135.run \n\necho 'export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64\"' >> ~/.bashrc\necho 'export CUDA_HOME=/usr/local/cuda' >> ~/.bashrc\necho 'export PATH=\"$PATH:/usr/local/cuda-7.5/bin\"' >> ~/.bashrc\n\n#install cudnn --> first download cudnn-7.5-linux-x64-v5.0-rc.tar or 7.0-v4\ntar -xf cudnn-7.0-linux-x64-v4.0-prod.tar\nsudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\nsudo cp cuda/include/cudnn.h /usr/local/cuda/include/\n\n# install all package dependencies\nsudo apt-get install -y \\\nzip \\\nswig \\\nfortran \\\ngit \\\nlibboost-all-dev \\\nlibatlas-base-dev \\\nlibblas-dev \\\nliblapack-dev \\\npython-dev \\\npython-pip \\\nvim \\\nsoftware-properties-common\n\nsudo pip install -U \\\nvirtualenv \\\nbumpy \\\nscipy \\\nmatplotlib \\\ngensim \\\nsacred \\\nscikit-learn \\\nlangdetect \\\npymongo \\\njupiter\n\n# install jdk 1.8 for bazel\nsudo add-apt-repository ppa:webupd8team/java\nsudo apt-get update\nsudo apt-get install oracle-java8-installer\n\ncd\n\n# install bazel\ngit clone https://github.com/bazelbuild/bazel.git\ncd bazel\ngit checkout tags/0.2.0\n./compile.sh\nsudo cp output/bazel /usr/bin\ncd ..\n\n# install tensorflow\ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow\ncd tensorflow\ngit checkout tags/v0.8.0\n./configure\n\nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nbazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\n```\n\nthis freezes the server with these lines as the last ones:\n000002/000001 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000002/000001 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n000002/000001 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]\n\nI also compiled the cuda samples and they all run without a problem\n", "I really would love some help, it still does not work and freezes my computer overtime I create a session.\n\nI tried installing from source as well as through pip\n", "for example when running this tiny program:\n\n```\nimport tensorflow as tf\na = tf.ones([100])\nsess = tf.Session()\nprint sess.run(a)\n```\n\nthis works with the CPU tensorflow installed through pip\n\nbut does not work with the GPU version:\nafter the following output:\n\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \n> name: Tesla K80\n> major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n> pciBusID 0000:83:00.0\n> Total memory: 11.25GiB\n> Free memory: 11.16GiB\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \n> name: Tesla K80\n> major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n> pciBusID 0000:84:00.0\n> Total memory: 11.25GiB\n> Free memory: 11.16GiB\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y \n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y \n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:83:00.0)\n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:84:00.0)\n>   [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 1.  1.  1.  1.  1.  1.  1. 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n\nthe program freezes before exiting and I have to hard-reboot the instance.\n\nI again checked the driver version 352.39, CUDA version 7.5.18 and cudnn 4.0.7\n\nthe CUDA samples all still work\n", "Sorry - I missed this issue. I don't have a good idea of why this might be happening, so I'm reassigning to @zheng-xq as our best GPU expert.\n", "I can reproduce the same issue with convolution.py MNIST example running on g2.2xlarge AWS GPU machine after installing the machine compiled Tensorflow wheel. The instance freezes after Initialization is printed right after the tf.Session() is created and all the variables are initialized.\n\n```\nroot@ip-10-10-73-64:~# python tensorflow/tensorflow/models/image/mnist/convolutional.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GRID K520\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\npciBusID 0000:00:03.0\nTotal memory: 4.00GiB\nFree memory: 3.95GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:837] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\nInitialized! \n```\n", "The first step is to find out where the hanging is happening. Could someone help print out the call stack of all threads when the hanging is happen, at least the unique ones? \n", "I am also getting the same problem . Can any one already solved this problem ? Any suggestion how to overcome this problem.\n\nubuntu@ip-172-31-19-3:~/TensorFlowWorkSpace/rnn/wordSequence$ python sample.py -n=200 --prime='Hello '\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GRID K520\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\npciBusID 0000:00:03.0\nTotal memory: 4.00GiB\nFree memory: 3.95GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\n\nAfter this nothing happening.\n", "@dipanjan06, since we cannot reproduce this problem locally, we need your help to debug this. While the process is hanging could you use gdb to attach to it and print out the call stack? \n1. While the process is hanging, find out its process-id. \n2. Run \"gdb\"\n3. Run \"attach <process-id>\". If this fails saying you don't have the permission, follow the instruction which may have \"sudo sysctl -w kernel.yama.ptrace_scope=0\"\n4. Once the process is attached, print out the callstack of all threads with \"thread apply all bt\"\n5. Upload the entire output to a website such as \"pastebin.com/\" and paste the URL here. \n", "This is a stack trace of my AWS instance, which is configured according to these instructions: \n\nhttp://eatcodeplay.com/installing-gpu-enabled-tensorflow-with-python-3-4-in-ec2/\n\nbut with the following changes bazel 0.3.0 (instead of 0.1.8) and tensorflow 0.9.0 (instead of a specific commit)\n\nProblem similar to above occurs when running **cifar10_multi_gpu_train.py**\n\ngdb output: http://pastebin.com/xd7Z2eWZ\n\nWhat I notice is high CPU on ksoftirqd, and checking /proc/interrupts there is a very high number of xen-pirq-msi on device nvidia:\n\nproc/interrupts: http://pastebin.com/m47JVVtR\n\nAt somepoint after running, the OS becomes unresponsive to other inputs. Although I have found it very hard to get a reproducible TF GPU setup on AWS, I did get it running this configuration a couple of weeks ago. After some time working on this, I am pretty sure I have reproduced my initial configuration, and all I see now on this is freezes. I almost wonder if something has changed under the hood in AWS?\n", "Hello ,\n\nAs requested please find the gdb stack trace .\n\nhttp://pastebin.com/Trf15Tca\n\nRegards,\nDipanjan\n\nOn Fri, Jul 15, 2016 at 12:14 AM, zheng-xq notifications@github.com wrote:\n\n> @dipanjan06 https://github.com/dipanjan06, since we cannot reproduce\n> this problem locally, we need your help to debug this. While the process is\n> hanging could you use gdb to attach to it and print out the call stack?\n> 1. While the process is hanging, find out its process-id.\n> 2. Run \"gdb\"\n> 3. Run \"attach \". If this fails saying you don't have the permission,\n>    follow the instruction which may have \"sudo sysctl -w\n>    kernel.yama.ptrace_scope=0\"\n> 4. Once the process is attached, print out the callstack of all\n>    threads with \"thread apply all bt\"\n> 5. Upload the entire output to a website such as \"pastebin.com/\" and\n>    paste the URL here.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/1947#issuecomment-232755303,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/ASxRktr8wdsU4Ks50aOua3YIUQH-mhskks5qVoOZgaJpZM4IHeU8\n> .\n", "@ChrisHowlin, one thing I found in your log is \"cuMemAlloc_v2\", I wonder whether it consistently show up in the hanging? Could you repeat the  process and take multiple snapshots of the hanging callstacks?\n\n@dipanjan06, thank you for the stack trace. However, it is not complete. The last line is \"---Type <return> to continue, or q <return> to quit---\". Please press <return> to get all the stack printout. Also it is worth repeating the process and taking multiple snapshots of the hanging callstacks, so we can find what are common among them, which are likely to be the culprit. \n", "Hello,\n\nAs advised I have taken multiple snap shots of the call stack when the\nactual process hangs after printing the following\n\n______________________________________\n\n_I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful\nNUMA node read from SysFS had negative value (-1), but there must be at\nleast one NUMA node, so returning NUMA node zero_\n\n*I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with\nproperties: *\n\n_name: GRID K520_\n\n_major: 3 minor: 0 memoryClockRate (GHz) 0.797_\n\n_pciBusID 0000:00:03.0_\n\n_Total memory: 4.00GiB_\n\n_Free memory: 3.95GiB_\n\n*I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 *\n\n*I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y *\n\n_I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating\nTensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id:\n0000:00:03.0)_\n\n___________________________________________________\n\nStackTrace\nhttp://pastebin.com/D5j4uKra\n\nOn Mon, Jul 18, 2016 at 12:48 AM, zheng-xq notifications@github.com wrote:\n\n> @ChrisHowlin https://github.com/ChrisHowlin, one thing I found in your\n> log is \"cuMemAlloc_v2\", I wonder whether it consistently show up in the\n> hanging? Could you repeat the process and take multiple snapshots of the\n> hanging callstacks?\n> \n> @dipanjan06 https://github.com/dipanjan06, thank you for the stack\n> trace. However, it is not complete. The last line is \"---Type to continue,\n> or q to quit---\". Please press to get all the stack printout. Also it is\n> worth repeating the process and taking multiple snapshots of the hanging\n> callstacks, so we can find what are common among them, which are likely to\n> be the culprit.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/1947#issuecomment-233198674,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ASxRkgzFmnIDaciw-cdFIuoiSVkbDAkYks5qWn_9gaJpZM4IHeU8\n> .\n", "@ChrisHowlin, @dipanjan06, thanks for the stack traces, they are very useful. I suspect this is a bug from the Cuda driver. \n1. What are the Cuda driver version shown in your nvidia-smi? \n2. Could you upgrade to the latest Cuda driver and see if the problem goes away. \n\nDetails: \n\nI found that at both stack traces, two Cuda calls are still active, while all other threads are effectively sleeping. The first one is when a new thread is starting. And the second is a thread is allocating some memory. In one case it is a Cuda device memory, and in another case it is a Cuda host memory. And it seems that those two calls are deadlocking with each other. So the problem might be with the Cuda driver. Please try with the latest driver. Also I'll add the NVIDIA team to this discussion. \n\nThread 14 (Thread 0x7ff6ea7fc700 (LWP 6730)):\n#0  0x00007ff763a89fdd in poll () at ../sysdeps/unix/syscall-template.S:81\n#1  0x00007ff749ecac1b in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so\n#4  0x00007ff764477184 in start_thread (arg=0x7ff6ea7fc700) at pthread_create.c:312\n#5  0x00007ff763a9737d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\n\nThread 1 (Thread 0x7ff764d4a740 (LWP 6687)):\n#0  0x00007ff763a8e1e7 in ioctl () at ../sysdeps/unix/syscall-template.S:81\n#1  0x00007ff7497aedea in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so\n#13 0x00007ff74978fa6d in cuMemAlloc_v2 () from /usr/lib/x86_64-linux-gnu/libcuda.so\n#14 0x00007ff75858f711 in perftools::gputools::cuda::CUDADriver::DeviceAllocate(perftools::gputools::cuda::CudaContext*, unsigned long long) ()\n   from /home/ubuntu/anaconda3/lib/python3.4/site-packages/tensorflow/python/_pywrap_tensorflow.so\n", "Adding @benbarsdell from NVIDIA to this discussion to look at this the Grid Cuda driver issue.\n", "@benbarsdell @zheng-xq friendly ping?\n", "I'm experiencing the same problem as well. Ubuntu 14.04 on AWS g2.2xlarge, no reaction to `kill -9` and `Ctrl-C`. Mnist log (nothing special):\n\n```\n$ python tensorflow/tensorflow/models/image/mnist/convolutional.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\n```\n\nEdit:\nUsing `cuda_7.5.18_linux.run` with its drivers.\n", "Solved this problem by installing new driver from Nvidia site. [Just download the latest driver for your card.](http://www.nvidia.com/Download/index.aspx?lang=en-us) The solution is from here: https://groups.google.com/d/msg/torch7/kLusyLEj4oc/MLRvcCy_FAAJ\n\n```\nwget http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.18_linux.run\n\nAnd then I installed everything except the samples and driver :\n\nchmod o+x cuda_7.5.18_linux.run\nsudo ./cuda_7.5.18_linux.run\n\nAnd then I downloaded and installed the new driver from http://www.nvidia.com/content/DriverDownload-March2009/confirmation.php?url=/XFree86/Linux-x86_64/361.28/NVIDIA-Linux-x86_64-361.28.run&lang=us&type=GeForce :\n\nwget http://us.download.nvidia.com/XFree86/Linux-x86_64/361.28/NVIDIA-Linux-x86_64-361.28.run\nchmod o+x NVIDIA-Linux-x86_64-361.28.run\nsudo ./NVIDIA-Linux-x86_64-361.28.run\n```\n", "@mbektimirov Your solution works for me. I upgraded my Nvidia driver from version 352.39 to 367.44. Now I can run TF freely without GPU freezing. Thank you!\n", "@benbarsdell @zheng-xq I am running into a similar problem.\n\nMy configuration is:\n- Ubuntu 16.04.1 TLS\n- Two Nvidia Titan X (Pascal) GPUs\n- Nvidia driver 367.57\n- Cuda 8.0.44\n- Cudnn 5.1.5\n\nI have previously tried with:\n- Nvidia driver 367.44\n- Cuda 8.0.27 (and 8.0.27.1 patch)\n\nI have built tensorflow from source. Here are the scripts I used to [configure](https://github.com/dojoteef/dotfiles/blob/a7d2321/bin/configure_tensorflow) and [install](https://github.com/dojoteef/dotfil\nes/blob/a7d2321/bin/install_tensorflow) tensorflow. The output of `__git_version__` is below:\n\n```\npython -c 'import tensorflow as tf; print(tf.__git_version__)'\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so.8.0 locally\nv0.11.0rc0-787-gf6e0f64\n```\n\nHere are a few pastebins of bins of gdb output when the threads are stalled when running `cifar_multi_gpu_train.py --num_gpus=2`:\n- Hang after 3410 steps: [dump1](http://pastebin.com/NrTwaeH2), [dump2](http://pastebin.com/CC1EeukU) (after waiting a bit)\n- Hang after 2910 steps: [dump3](http://pastebin.com/q9SfYGUr)\n\nI also received a core dump running `cifar_train.py` (I didn't attach the core dump as it's nearly 300MB, though I can if it would be helpful):\n\n```\n...\n2016-10-14 19:09:01.337748: step 1490, loss = 2.06 (1690.8 examples/sec; 0.076 sec/batch)\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\nAborted (core dumped)\n```\n\nI am not sure if the issues are related or not, but it seems likely that they are.\n\nIf there is anything you need me to do in order to help figure out/address the issues I am happy to. Not being able to use my GPUs is unfortunately really slowing down my ability to make progress. Thanks!\n", "Just a follow up on this. I finally tracked this down to a faulty motherboard. Sorry for the false alarm. In case anyone else runs into an error case similar to mine and you happen to be using an [Asrock X99 WS-E](http://www.asrock.com/mb/Intel/X99%20WS-E/) motherboard, it seems to be a [common quality control problem](http://goo.gl/G8V55l) they have.\n", "Looks like on AWS driver update resolves the problem.\r\nAll reports seem to be resolved ATM.", "@dojoteef I have the exact same problem - random freezes or `CUDA_ERROR_LAUNCH_FAILED`  errors with core dumps that are preceded by following kernel logs:\r\n\r\n```\r\nJan 22 15:43:51 XXX kernel: [ 8793.084341] NVRM: GPU at PCI:0000:09:00: GPU-XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXX\r\nJan 22 15:43:51 XXX kernel: [ 8793.084354] NVRM: GPU Board Serial Number: XXXXXXXXXXXX\r\nJan 22 15:43:51 XXX kernel: [ 8793.084358] NVRM: Xid (PCI:0000:09:00): 32, Channel ID 00000012 intr 00008000\r\nJan 22 15:43:51 XXX kernel: [ 8793.084518] NVRM: Xid (PCI:0000:09:00): 32, Channel ID 00000012 intr 00008000\r\n```\r\n\r\nThese errors happen randomly and expected time of failure is about 2 hours, so training larger models is a nightmare.\r\n\r\nI have the exact same setup like you with 2 Titan XPs with the same driver version, but I own an ASUS X99-E WS motherboard. How did you resolve your motherboard issues? Do newer Nvidia drivers or BIOS version solve the problem?\r\n\r\n", "@PiotrDabkowski I believe the issue could be the same despite a different motherboard manufacturer. [This review](https://www.newegg.com/Product/SingleProductReview.aspx?ReviewID=4741529&Item=13-157-538) on Newegg seems to indicate the PLX chips used for the PCIe bus are to blame. I believe your motherboard also uses those chips.\r\n\r\nI fixed my issue by replacing my motherboard.", "@dojoteef Thank you for your answer. Error 32 suggests a bad PLX chip. To confirm it I have been running [gpu_burn](http://wili.cc/blog/gpu-burn.html) test for half an hour now without errors. Will leave it running for 12 hours to make sure :) \r\n\r\nEDIT: Crashed after 2 hours of gpu_burn. Not a TensorFlow issue, bad motherboard. Shame on you ASUS.", "I had the same problem before. It turns out that I've installed cuda 7.0 and cuda 8.0, nividia driver 367.57 on ubuntu 14.04. This issue happens when I forget to set the  LD_LIBRARY_PATH to cuda 8.0.", "Related to this is an issue I posted about on [stackoverflow](http://stackoverflow.com/questions/42767187/why-does-this-tensorflow-code-crash) which turned out to be a hardware issue. Program trained for awhile, then hung, then crashed, and appears to be a PCIe issue related to message scheduled interrupts (more info [here](http://www.overclock.net/t/1539708/question-for-x99-board-owners-with-nvidia-cards-do-you-see-pcie-bus-errors-please-respond-to-poll) and [here](https://forums.geforce.com/default/topic/957456/gtx-1080-throwing-bad-tlp-pcie-bus-errors/)). Setting kernel parameter pci=nommconf fixed the issue for me.", "Experienced the same here. This seems to be only happening on the first time running tensorflow. The program responds to the sigterm about 10 minutes later and the following trials work just fine.", "Hi, everyone. It might be very late to join this discussion.\r\nBesides than updating bios if you are using X99-E WS/USB 3.1 and updating graphic driver,\r\nYou might also refer on this [post](https://stackoverflow.com/questions/33883530/why-is-my-command-prompt-freezing-on-windows-10) if you are using windows 10.", "I have encountered the same problem here. \r\nMy settings: \r\nwindows 10\r\nCUDA 10\r\ncuDNN V7\r\ntensorflow 1.14\r\n6G memory\r\nit just stuck after creating Tensorflow device."]}, {"number": 1946, "title": "Fix TensorBoard lib/css dependency (#1926)", "body": "Cherry-picked from master branch.\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 1945, "title": "Adding rx.y pattern to update_version.sh", "body": "Strings fitting this pattern will be updated if there are major.minor changes.\n", "comments": []}, {"number": 1944, "title": "add a reference for Penn Tree Bank", "body": "add a reference for Penn Tree Bank dataset in RNN tutorial\n", "comments": ["Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n"]}, {"number": 1943, "title": "Error trying on GPU ", "body": "Hi Everyone \n\nI'm new in TensorFlow , I'm running some tests . I tried the Convolutional.py on my local machine and it ran perfectly and everything was ok .On my local pc I don't have a Nvidia GPU , so I tried to connect to a server computer which has Nvidia M4000, I installed Cudnn 7.5 the last version from their website and my CUDA toolkit  is the last version of CUDA (7.5) .\n\nWhen I run the \" import tensorflow as tf \" everything is ok and it recognize all the libraries and Cudnn .\nI manually downloaded the mnist data and I put it in the directory ,when I run the Convolutional.py ,the extracting and everything goes ok when it wants to initialize I receive this error \n\nConvolutionalBackwardFilter_V2 cudnn DSO dlerror \n\nI looked at the cudnn library and searched in it , there is ConvolutionalBackwardFilter in it but there isn't ConvolutionalBackwardFilter_V2. \n\nI changed the cudnn 7.5 to cudnn 6.5 but still the same story .\nAt this point I don't know what to do and how can I fix this issue ? I would be grateful if someone could help me \n\nP.S :My operating system is Linux Ubunto and the server operating system is CentOs \n", "comments": ["If you are installing from pip packages, try installing cudnn v4 -- our pip packages require cudnn4.\n"]}, {"number": 1942, "title": "My TensorBoard isn't showing any data! What's wrong?", "body": "I went through [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md#my-tensorboard-isnt-showing-any-data-whats-wrong):\n1. `tensorboard --logdir=output/trash --debug` showed the expected path\n2. `find output/trash | grep tfevents` showed two event files\n3. `find output/trash | grep tfevents | xargs ls -lh` showed that they are 6.4M and 1.2M big.\n\nStill, the tensorboard looks like this:\n\n![Imgur](http://i.imgur.com/JLnLCB6.png)\n\nThe console shows:\n\n```\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG\nWARNING:tensorflow:Unable to read TensorBoard tag\nStarting TensorBoard  on port 6006\n(You can navigate to http://0.0.0.0:6006)\nWARNING:tensorflow:Found new file_version for event.proto. This will affect purging logic for TensorFlow restarts. Old: 1.0 New: 2.0\nWARNING:tensorflow:Found more than one graph event per run. Overwriting the graph with the newest event.\n127.0.0.1 - - [14/Apr/2016 15:39:12] \"GET / HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Apr/2016 15:39:12] \"GET /external/lodash/lodash.min.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/lib/css/global.css' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/lib/css/global.css\n127.0.0.1 - - [14/Apr/2016 15:39:12] code 404, message Not Found\n127.0.0.1 - - [14/Apr/2016 15:39:12] \"GET /external/d3/d3.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Apr/2016 15:39:12] \"GET /external/plottable/plottable.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Apr/2016 15:39:12] \"GET /external/plottable/plottable.css HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Apr/2016 15:39:12] \"GET /external/graphlib/dist/graphlib.core.min.js HTTP/1.1\" 200 -\n```\n### Environment info\n\nOperating System: Linux Mint 17 Qiana\n\nInstalled version of CUDA and cuDNN: \n\n``` bash\n$ ls -l /usr/local/cuda-7.5/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a\n```\n1. Which pip package you installed: pip 8.1.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".: 0.8.0rc0\n### Steps to reproduce\n1. Execute `tensorboard --logdir output/trash`\n2. Open the browser with http://0.0.0.0:6006\n", "comments": ["Possibly duplicate of https://github.com/tensorflow/tensorflow/issues/1923\n", "Fix to this issue in 0.8.0 RC0 is on the way and will be incorporate in the final 0.8.0 release. See #1926\n", "I met the same problem today and had fixed it. You just need to download the newest tensorflow source code from github and copy ./tensorflow/tensorboard to the tensorboard you installed(for you it's /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/)\n", "I have fixed this issue as well few minutes ago , just merged between the :\n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\nAnd TensorFlow source code from GitHub.\n"]}, {"number": 1941, "title": "Idea: support dictionary fetches with tf.Session.run()", "body": "# The Idea\n\nThe [`tf.Session.run()` method](https://www.tensorflow.org/versions/r0.8/api_docs/python/client.html#Session.run), currently supports taking either a _single graph element_, or _a list of graph elements_ as input for the `fetches` argument, and will return either a single value or a list of values correspondingly.\n\n**I propose adding support for using a dictionary as input for the fetch argument**, and receiving a corresponding dictionary as the return value.\n\nUsing dictionaries has at least two advantages compared to lists:\n1. It will make the code **more readable**, and keys are easier to remember than indices. In the following example the return value of the loss can be accessed as `result['loss']` instead of `result[2]`.\n   \n   ``` python\n   fetches = {\n   'train_op': train_op,\n   'accuracy': accuracy,\n   'loss': loss\n   }\n   \n   result = sess.run(fetches, feed_dict)\n   \n   print(result['loss'], result['accuracy'])\n   ```\n2. It will be much **easier to only fetch certain elements on flexible schedules**.\n   \n   For example i might want to fetch summaries for TensorBoard every 20 iterations while only fetching the loss printing to the console every 50 iterations.\n   \n   That means that the return value would be a list that sometimes have none of the extra elements, sometimes one of them, and sometimes both. As a consequence the index in the returned list that contains the loss might vary from one run to the next, and I would have to build extra logic to handle this.\n   \n   With dictionaries the key doesn't change depending on other elements in the dict, so it would be possible to do something like saving summaries without even knowing the schedule:\n   \n   ``` python\n   if 'summaries' in result:\n       writer.add_summary(result['summaries'], i)\n   ```\n# Implementation\n\nI have recently been emulating the proposed behavior in a project using using the following wrapper function to translate from dictionary to list and back.\n\nI suspect that it wouldn't be hard to do something similar in [tensorflow/python/client/session.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py) perhaps as part of [_process_fetches()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py#L455), but I didn't want to spend a lot of time on it before asking.\n\n``` python\ndef run(session, fetches, feed_dict):\n    \"\"\"Wrapper for making Session.run() more user friendly.\n\n    With this function, fetches can be either a list or a dictionary.\n\n    If fetches is a list, this function will behave like\n    tf.session.run() and return a list in the same order as well. If\n    fetches is a dict then this function will also return a dict where\n    the returned values are associated with the corresponding keys from\n    the fetches dict.\n\n    Keyword arguments:\n    session -- An open TensorFlow session.\n    fetches -- A list or dict of ops to fetch.\n    feed_dict -- The dict of values to feed to the computation graph.\n    \"\"\"\n    if isinstance(fetches, dict):\n        keys, values = fetches.keys(), list(fetches.values())\n        res = session.run(values, feed_dict)\n        return {key: value for key, value in zip(keys, res)}\n    else:\n        return session.run(fetches, feed_dict)\n```\n# Questions\n- Is this a bad idea for some reason I don't realize? Or maybe I just overlooked some disadvantages that are worth considering?\n- Why stop at dictionaries? What about tuples, nested dictionaries, or dictionaries containing lists of elements?\n- General comments and thoughts?\n", "comments": ["A similar syntactic sugar with current implementation is to do this:\n`loss, accuracy = sess.run(fetches, feed_dict)`\n\nCurrent approach is more familiar for people coming to TensorFlow from Theano since Theano object also returns a list rather than dictionary.\n\nThe biggest problem though is that this change is going to break thousands of people who have code using `session.run` and treating the result as a list.\n\nIt might be better to create a different interface on top of TensorFlow, like Keras, PrettyTensor, tf.train rather than altering the core interface. Ultimately most people may be using TensorFlow through one of those higher level interface anyway, rather than calling `session.run` directly\n", "@yaroslavvb Thanks for answering.\n\nIf you look at my wrapper function you'll see that it can be fully backwards compatible.\nIf `fetches` is a list then the return value should of course still be a list.\nIf `fetches` is a dictionary then the return value should be a dictionary instead.\n", "OK, good point, it does seem mostly backward compatible. Could this be done as an object on top of TF? As you mention, one may want to extend it to tuples, nested dictionaries, or dictionaries containing lists of elements, so that's additional changes to the core TF. Also, maybe asking for \"isinstance(dict)\" is too restrictive, instead you might want to follow the spirit of duck-typing and accept any object that is dictionary-like\n\nMaybe a way to go is to have a thin wrapper like \"EasySession\" or something like this on top, and if it gets traction, then people can switch over to using it rather than the old run interface. In general, changes to core interface may break tests in unexpected ways an require some work to get integrated. For instance, there may be some code which feeds in a `dict` into session.run already and expects it to fail (it may seem like a stretch, but I have seen similar scenarios)\n", "> Could this be done as an object on top of TF?\n> [...]\n> Maybe a way to go is to have a thin wrapper like \"EasySession\" or something like this on top, and if it gets traction, then people can switch over to using it rather than the old run interface.\n\nI assume that you are talking about (at least initially) implementing it as a subclass that can be used as e.g. `tf.EasySession` or `tf.contrib.Session` instead of `tf.Session`?\n\n> As you mention, one may want to extend it to tuples, nested dictionaries, or dictionaries containing lists of elements, so that's additional changes to the core TF. Also, maybe asking for \"isinstance(dict)\" is too restrictive, instead you might want to follow the spirit of duck-typing and accept any object that is dictionary-like.\n\nYes, you're right. The `run()` function I shared above was only made to cover my own basic needs and serve as an example.\n\nFor something like this to be more general I am currently thinking that it could maybe accept any python object that is an iterable container, and its return value should have the same structure. I don't know yet if that's possible, or necessary, or even worth it at all. I think my own needs would be covered if it just works with both lists and dictionaries.\n\n> In general, changes to core interface may break tests in unexpected ways and require some work to get integrated. For instance, there may be some code which feeds in a dict into session.run already and expects it to fail (it may seem like a stretch, but I have seen similar scenarios)\n\nSure, even the most (seemingly) trivial assumptions can turn out to be wrong, and especially for essential functionality that is used all the time like `tf.Session` it is a good policy to be extra cautious.\n\nIdeally the implementation should of course be fully backwards compatible so it can be included in the main `tf.Session` class.\n", "The dictionary thing sounds like a good plan.  I don't think we need to add support for all possible types.  Dict support would have prevented a crazy workaround in my current code.\n\n@Styrke: I'd welcome a PR if you're still interested (I'll mark this as contributions welcome). \n", "Cool! I will try to code up a proper implementation.\n", "BTW, you can do something like this using a wrapper around `session.run`, here's an example -- https://gist.github.com/yaroslavvb/973862f62f35f174a4e8942bd7bd022e\n", "I think this has been supported for quite some time now.", "Yep, it was added by 1ac30d53e512ee40413a210d57fd1d56e510f4cb.", "Howdy!!\r\n\r\nCan anyone please help me out in resolving this error. Have been trying resolving it for such a long time.\r\nSeems, Keras is literally made for a good reason since tensor flow kills time. Any help would be highly appreaciated.\r\n\r\nHere I am trying to convert x4 (tf.tensor object -- intermediate layer from Keras model) into numpy array so I can perform some operation on it as highlighted in the section \"A\" below. I tried almost everything that is mentioned on the internet, but to avail.\r\n\r\n**The code snippet is as below:**\r\n\r\nprint(\"x4: \", x4) <<--- here x4 is the output of any intermediate layer from model built using keras.\r\n    with tf.Session() as sess:\r\n      print(\"sess: \", sess)\r\n      arr = x4.eval(sess)\r\n      #arr = sess.run(x4)\r\n      \r\n      print(\"arr: \", arr)\r\n      print(\"len(arr): \", len(arr))\r\n      \r\n==== A =====\r\n      for x_axis in range(len(arr)):\r\n        if arr[x_axis] < 0.35:\r\n          rg_train[x_axis]=a1*np.exp(-b1*np.exp(-c1*(11*(arr[x_axis]+0.6-0.13)-5)))\r\n        else:\r\n          rg_train[x_axis]=a*np.exp(-b*np.exp(-c*(11*(arr[x_axis]-0.13)-5)))+0.5  \r\n      return rg_train\r\n==== A ====\r\n\r\n**The error log is:**\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/nest.pyc in flatten_dict_items(dictionary)\r\n    214   \"\"\"\r\n    215   if not isinstance(dictionary, dict):\r\n--> 216     raise TypeError(\"input must be a dictionary\")\r\n    217   flat_dictionary = {}\r\n    218   for i, v in _six.iteritems(dictionary):\r\n\r\nTypeError: input must be a dictionary\r\n\r\n** When I feed a dictionary into it then it says placeholder shoudl be fed, when I do that then it gives me some another error. really fed up with this issue **\r\n\r\nRegards,\r\nPriya Arora\r\n"]}, {"number": 1940, "title": "convolution on dimension variable inputs ", "body": "I would like to perform a convolution on dimension variable inputs. \nThe only solution I find and I think that it would work is to perform a convolution on each input and perform a scan on batch_size. I think this is not optimal.\nIs there another function or method to do this differently in TensorFlow?\n\nThanks in advance. \n", "comments": ["Can you clarify on what \"dimension variable inputs\" means?\n", "@zffchen78 I would like perform a convolution 1d on sentences with not fixed length. \nMy mini batch contains sentences with different lengths.\n", "so in vision this would correspond to input images of varying size within a batch? If so I would be muchmuch interested in that, too, but suspect it's not going to happen any time soon :P\n", "@black-puppydog yes it corresponds to input images of varying size in computer vision\nI am trying to implement this paper http://research.microsoft.com/pubs/226585/cikm2014_cdssm_final.pdf and I would like to avoid making a for loop over mini batch examples.\n", "I am not aware of anyone doing exactly what you are trying. Maybe the following. Say your batch has N sentences, each sentence has up to M words, each word's embedding dimensions is K. For sentence shorter than M, pads it with a special word with a fixed embedding vector of 0s. Then, you can do batch 1D convolution on [N, M*K](per-row). Multiple the result w/ a mask of [ [1,..., 1, 1, ...0, ..., 0, 0], ...[...]], the total number of 1s and 0s on each row can be computed for each batch. \n", "I'm going to close, since I don't think this is feasible in TensorFlow in a performant manner.  Everything down to cuDNN assumes rectangular tensors, and uses this assumption to arrange for high arithmetic intensity.  Fancy approaches which do manual tiling of irregularly sizes images are possible, but those would be a layer on top of tensorflow (or possibly something in `tf.contrib`).\n", "Is there a way to achieve this even by using a batch of size 1? Each batch would contain 1 sentence, however, the ksize in max pooling needs to be set dynamically since it would depend on the length of the input. Any ideas?\n", "The solution to this issue would be interesting indeed :)", "Yes. I need this too. ", "Me too :-)", "Me too! ", "Me too :)", "me too :)"]}, {"number": 1939, "title": "Tensorflow setup on clound9", "body": "I am doing the project using Tensorflow. I set up it on Clound9 since It run on Ubuntu. I chose python 2.7. However, It kept showing an error: enter image description here . Does anyone have any idea why it keep happening? By the way, I clone tensorflow github in my repository. Thanks\n\n(tensorenv)ngoduyvu:~/workspace (master) $ pip install --upgrade https://storage.googleapis\n.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl\nCollecting tensorflow==0.8.0rc0 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl\n  Downloading https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl (22.2MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22.2MB 40kB/s \nCollecting six>=1.10.0 (from tensorflow==0.8.0rc0)\n  Downloading six-1.10.0-py2.py3-none-any.whl\nCollecting protobuf==3.0.0b2 (from tensorflow==0.8.0rc0)\n  Downloading protobuf-3.0.0b2-py2.py3-none-any.whl (326kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 327kB 1.8MB/s \nRequirement already up-to-date: wheel in ./miniconda/envs/tensorenv/lib/python2.7/site-packages (from tensorflow==0.8.0rc0)\nCollecting numpy>=1.8.2 (from tensorflow==0.8.0rc0)\n  Downloading numpy-1.11.0-cp27-cp27mu-manylinux1_x86_64.whl (15.3MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15.3MB 60kB/s \nCollecting setuptools (from protobuf==3.0.0b2->tensorflow==0.8.0rc0)\n  Downloading setuptools-20.7.0-py2.py3-none-any.whl (508kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 512kB 1.8MB/s \nInstalling collected packages: six, setuptools, protobuf, numpy, tensorflow\n  Found existing installation: setuptools 20.6.7\nCannot remove entries from nonexistent file /home/ubuntu/workspace/miniconda/envs/tensorenv/lib/python2.7/site-packages/easy-install.pth\n", "comments": ["Can you try the pip with with `--ignore-installed`?\n", "Thanks, I find out what is the problem. I already install tensorflow, but what I did were install again so It collapsed. \n"]}, {"number": 1938, "title": "Duplicated code", "body": "check two times.\n", "comments": ["Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it! @googlebot \n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins , test this please.\n", "LGTM. All PR tests passed.\n"]}, {"number": 1937, "title": "Build from source fail : web_animations_js", "body": "### Environment info\n\nUbuntu 14.04\nhardware - NVidia DIGITS DevBox\n\nInstalled version of CUDA and cuDNN: CUDA 7.5, cuDNN 5\n### Issue\n\nIssue: trying to install TensorFlow from source and have run into a number of issues. \n1. Resolved: Issue reported elsewhere with pulling eigen. Resolved by downloading eigen manually and modifying workspace.bzl to point to local eigen repository.\n2. Unresolved: Error with getting web-animations for bower:\n##### Output\n\nxxx@yyy:~/tensorflow\u27eb bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\nERROR: /home/liam/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@web_animations_js//': Error cloning repository: https://github.com/web-animations/web-animations-js.git: cannot open git-upload-pack caused by https://github.com/web-animations/web-animations-js.git: cannot open git-upload-pack caused by https://github.com/web-animations/web-animations-js.git: cannot open git-upload-pack and referenced by '//tensorflow/tensorboard/bower:bower'.\nERROR: Loading failed; build aborted.\n\nI'm not sure how to fix this - any help at all would be appreciated.\n", "comments": ["I managed to resolve this by getting my proxy issues sorted out.\n", "Got exactly the same issue as yours. Can you please be more specific?  What is your proxy issue?\n"]}, {"number": 1936, "title": "Can't re-install tensorflow", "body": "Hi Everyone,\n\nI have encountered a problem. I installed the tensorflow version 0.7.0, and using it to test mnist example, which outputted the error \u201cAttributeError: 'module' object has no attribute 'gfile'\u201d\n\nI searched for the solution about this error, and realised that I need to roll back to version 0.6.0 or version 0.7.1, so I did un-installed the tensorflow and tried to install version 0.7.1 using\n      sudo -H pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp27-none-any.whl\nHowever, it gave me the error:\nException:\nTraceback (most recent call last):\n  File \"/Library/Python/2.7/site-packages/pip/basecommand.py\", line 209, in main\n    status = self.run(options, args)\n  File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 317, in run\n    prefix=options.prefix_path,\n  File \"/Library/Python/2.7/site-packages/pip/req/req_set.py\", line 732, in install\n    *_kwargs\n  File \"/Library/Python/2.7/site-packages/pip/req/req_install.py\", line 835, in install\n    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\n  File \"/Library/Python/2.7/site-packages/pip/req/req_install.py\", line 1030, in move_wheel_files\n    isolated=self.isolated,\n  File \"/Library/Python/2.7/site-packages/pip/wheel.py\", line 477, in move_wheel_files\n    generated.extend(maker.make(spec))\n  File \"/Library/Python/2.7/site-packages/pip/_vendor/distlib/scripts.py\", line 372, in make\n    self._make_script(entry, filenames, options=options)\n  File \"/Library/Python/2.7/site-packages/pip/_vendor/distlib/scripts.py\", line 276, in _make_script\n    self._write_script(scriptnames, shebang, script, filenames, ext)\n  File \"/Library/Python/2.7/site-packages/pip/_vendor/distlib/scripts.py\", line 250, in _write_script\n    self._fileop.write_binary_file(outname, script_bytes)\n  File \"/Library/Python/2.7/site-packages/pip/_vendor/distlib/util.py\", line 401, in write_binary_file\n    with open(path, 'wb') as f:\n*_IOError: [Errno 2] No such file or directory: '/usr/local/bin/easy_install' **\n\nAs I checked, easy_install is lying in the directory  '/usr/local/bin/easy_install' , I don't know why this error happened.\n\nPlease help me solve this problem. It drives me crazy!!!!\n\nThank you!!\n", "comments": ["Can you please try installing a virtualenv as described [here](https://www.tensorflow.org/versions/r0.7/get_started/os_setup.html#virtualenv-installation) and let us know if you see the same problem?\n", "Thank you Keveman, using virtualenv and it works. \n\nBut I still don't know why using pip directly did not work. Anyway, I just keep going with my mnist example testing.\n"]}, {"number": 1935, "title": "ArgumentError: argument --self_test: conflicting option string(s): --self_test", "body": "I just installed tensorflow and no problem when I enter **python -m tensorflow.models.image.mnist.convolutional** in console  \nBut when I open convolutional.py on spyder, it appears that\n\n```\nFile \"/usr/lib/python2.7/argparse.py\", line 1467, in _handle_conflict_error\n    raise ArgumentError(action, message % conflict_string)\nArgumentError: argument --self_test: conflicting option string(s): --self_test\n```\n\nand other example have the same problem such as\n\n```\n File \"/usr/lib/python2.7/argparse.py\", line 1467, in _handle_conflict_error\n    raise ArgumentError(action, message % conflict_string)\nArgumentError: argument --batch_size: conflicting option string(s): --batch_size\n```\n\nanyone can solve it??\n", "comments": ["@keveman: Did you get a chance to look at this?\n", "@shiuan5566 What platform are you trying this on?\n", "@keveman  I use Kubuntu 15.10\n", "I am not the best person to debug this. Throwing it over to @martinwicke so he can find someone with access to different platforms.\n", "I don't know what spyder is, and the fact that it runs ok in plain python makes me think this is not actually our error.\n\nThese types of errors are caused by the flag initialization code such as flags.DEFINE_string('batch_size', ...) running twice, or two different parts of the program defining flags with the same name (for self_test that would be a pretty likely candidate, batch_size not so much.\n", "Automatically closing because there was no response and this is an unsupported configuration. Please reopen if it is still an issue and you verify it is not caused by Spyder's execution environment running initialization code twice. Thank you.\n", "I ran into the same problem. I'm running word2vec.py from https://github.com/tensorflow/models/tree/master/tutorials/embedding\r\n\r\nI'm running it on a google datalab notebook, on debian."]}, {"number": 1934, "title": "Is there a way improve memory strategy with in-place & broadcasting & bsxfun?", "body": "Suppose I have 4GB gpu memory, see the following code.\n\n``` python\nA = tf.Variable(tf.zeros([5000, 5000, 25]))  # 5000*5000*25*4byte=2.5GB\nB = tf.Variable(tf.zeros([5000, 25])  # 5000*25*4byte=500KB\nsub_op = A.assign(A - B)\n```\n\nSo, if you run sub_op, apparently, it will lead to OOM error, since A-B will need 5GB peak memory because of the broadcasting repetition.\n\nQuestion 1: Is there a way to use functions like `bsxfun` in matlab which will not extend two object into the same big size and then calculate? i.e.\n\n``` python\nsub_op = A.assign(tf.bsxfun(@minus, A, B))\n```\n\nQuestion 2: So, there's another problem about in-place assignment. Since sub_op related to in-place assignment, if the tensorflow haven't implemented it reasonable, it will lead to OOM error two, since there's no 5GB gpu memory to handle two 2.5GB objects.\n\nAny ideas?\n", "comments": ["refer to [bsxfun memory](http://stackoverflow.com/questions/28722723/matlab-bsxfun-no-longer-faster-than-repmat) and [bsxfun](http://www.mathworks.com/help/matlab/ref/bsxfun.html)\n\nI doubt that whether `bsxfun` is lead in with \"not repetition\" version in Matlab R2007, and after a few years, it's improved to the \"repetition except the free memory is not enough\" version. Matlab uses lazy allocation memory strategies.\n", "On q1. \n\nBecause A - B is an automatic broadcasting binary operation. A - B does not require B to be expanded to use 2.5GB. Only the result needs to be allocated (2.5GB). So, the peak memory usage in your code snippet should be 2.5GB + 500KB + 2.5GB. \n\nOn q2.\n\nIt's been worked on. There can be multiple approaches to this issue: a) extend assign_sub() to support broadcasting; b) support inplace operationos like -=, +=, etc.\n", "If you replace write\n\nsub_op = tf.assign_sub(A, B)\n\nthen the broadcasting happens implicitly in the underlying Eigen\nexpression, and the memory overhead should be minimal.\n\n(Low level code is here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dense_update_ops.h#L43\n)\n\nRasmus\n\nOn Thu, Apr 14, 2016 at 9:44 AM, zffchen78 notifications@github.com wrote:\n\n> On q1.\n> \n> Because A - B is an automatic broadcasting binary operation. A - B does\n> not require B to be expanded to use 2.5GB. Only the result needs to be\n> allocated (2.5GB). So, the peak memory usage in your code snippet should be\n> 2.5GB + 500KB + 2.5GB.\n> \n> On q2.\n> \n> It's been worked on. There can be multiple approaches to this issue: a)\n> extend assign_sub() to support broadcasting; b) support inplace operationos\n> like -=, +=, etc.\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/1934#issuecomment-210042344\n", "I have one more complex question other than just subtract.\n\nSay, still maximum 4GB gpu memory, I need the operation like below, **I've confirmed this will lead to OOM error**:\n\n``` python\n    A = tf.Variable(tf.zeros([5000, 25])) # 500KB\n    temp1 = tf.tile(A, [1, 5000]) # 2.5GB\n    temp2 = tf.reshape(temp1, [5000, 5000, 25])\n    _temp2 = tf.reshape(temp1, [5000, 5000, 25]) - A # OOM error.\n    temp3 = temp2 - A\n    temp4 = tf.square(temp2)\n    temp5 = tf.reduce_sum(temp2, 2)\n    temp6 = tf.reshape(temp5, [5000, 5000])\n\n    sess = tf.Session()\n    sess.run(tf.initialize_all_variables())\n    sess.run(temp1) # run successfully\n    print \"temp1\"\n    sess.run(temp2) #  run successfully\n    print \"temp2\"\n    sess.run(temp3) # OOM error\n    print \"temp3\"\n    sess.run(temp4) # OOM error\n    print \"temp4\"\n    sess.run(temp5) # OOM error\n    print \"temp5\"\n    sess.run(temp6) # not execute.\n    print \"temp6\"\n```\n\nSo, I don't know why you all @zffchen78 @rmlarsen say that it won't expand intermediately.\nOr, is my code wrong?\n\nPS: I use tensorflow 0.8.0rc0.\n", "Both Rasmus and I meant your code do need > 2.5GB \\* 2 memory. I was trying to correct your understanding that A - B would expand B to 2.5GB first. If your understand was that way, the peak memory would be 2.5GB \\* 3.\n\nRasmus was saying, if your original code is changed to sub_op = tf.assign_sub(A, B) _and_ extend the code he points out, the peak memory usage in your program would be 2.5GB \\* 1.\n", "Ok, so the issue is the one input as 2.5GB while the result requires another 2.5GB memory. Got that.\nBut, I'm a little confused why the following code still gives OOM error.\n\n``` python\ntemp2 = tf.reshape(temp1, [5000, 5000, 25])\ntemp2 -= A # if remove this line, sess.run(temp2) execute successfully, otherwise fails.\nsess.run(temp2)\n```\n", "temp2 -= A is not doing any inplace update.\n", "`temp2 -= A` tries to call `__isub__`, if that's not defined (it's not defined for TF tensors), Python interpreter rewrites it into `temp2 = temp2 - A` which calls `__sub__` which calls `tf.sub`\n", "@myme5261314 : Did this answer your questions?\n", "Yes, I see what's happening. Just for suggestion.\nIf I wrote the code\n\n``` python\ntemp2 = tf.reshape(temp1, [5000, 5000, 25])\n# temp2_ = temp2\ntemp2 -= A\n```\n\nwhich temp2 is a tensor, that means whatever the temp2 tensor value is before this operation, I'm discarding it after this operation unless I have another `temp2_` which refer to the `temp2 before`, right?\nSo, if just like the code above, that line is commented, is it possible to make the `temp2 -= A` inplace? Since the `temp2 before` is just a transition tensor, the `temp2 after` is the actual tensor that might be `eval()` by the user.\nI'm not familiar with tensorflow core, I don't know whether this could be implemented.\n"]}, {"number": 1933, "title": "use seq2seq to output context vector", "body": "When I use tensorflow seq2seq library, how can i get the context vector of input sequence?\nThanks a lot.\n", "comments": ["I think by context vector you mean just the state after the encoder. For example, in [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/seq2seq_test.py#L34](this test) it would be the `enc_state` tensor.\n"]}, {"number": 1932, "title": "When I install tensorflow for gpu mode, I got a error! hellp!", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System:Ubuntu 15.10\n\nInstalled version of CUDA and cuDNN: both are 7.5\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n\nBefore I install tensorflow of GPU,I installed tensorflow of CPU and It work. And I want to install tensorflow of GPU. I get this error:\n### Order:bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n\nError info:\n\n`bazel-out/local_linux-opt/bin/tensorflow/core/libcore_cpu_internal.lo(device.o): In function`tensorflow::Device::BuildDeviceAttributes(std::string const&, tensorflow::DeviceType, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::BusAdjacency, std::string const&)':\ndevice.cc:(.text._ZN10tensorflow6Device21BuildDeviceAttributesERKSsNS_10DeviceTypeENS_3gtl7IntTypeINS_10Bytes_tag_ExEENS_12BusAdjacencyES2_+0x2d): undefined reference to `google::protobuf::internal::empty_string_'\nbazel-out/local_linux-opt/bin/tensorflow/core/libcore_cpu_internal.lo(device.o): In function`tensorflow::Device::Device(tensorflow::Env_, tensorflow::DeviceAttributes const&, tensorflow::Allocator_)':\ndevice.cc:(.text._ZN10tensorflow6DeviceC2EPNS_3EnvERKNS_16DeviceAttributesEPNS_9AllocatorE+0xe0): undefined reference to `tensorflow::ResourceMgr::ResourceMgr(std::string const&)'\nbazel-out/local_linux-opt/bin/tensorflow/core/libcore_cpu_internal.lo(threadpool_device.o): In function`tensorflow::ThreadPoolDevice::MakeTensorFromProto(tensorflow::TensorProto const&, tensorflow::AllocatorAttributes, tensorflow::Tensor_)':\nthreadpool_device.cc:(.text._ZN10tensorflow16ThreadPoolDevice19MakeTensorFromProtoERKNS_11TensorProtoENS_19AllocatorAttributesEPNS_6TensorE+0x69): undefined reference to `google::protobuf::Message::DebugString() const'\nbazel-out/local_linux-opt/bin/tensorflow/core/libframework_internal.lo(types.o): In function`tensorflow::DataTypeString[abi:cxx11](tensorflow::DataType)':\ntypes.cc:(.text._ZN10tensorflow14DataTypeStringB5cxx11ENS_8DataTypeE+0xa5): undefined reference to `tensorflow::strings::StrCat[abi:cxx11](tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\nbazel-out/local_linux-opt/bin/tensorflow/core/libframework_internal.lo(types.o): In function`tensorflow::DataTypeSliceString[abi:cxx11](tensorflow::gtl::ArraySlice<tensorflow::DataType)':\ntypes.cc:(.text._ZN10tensorflow19DataTypeSliceStringB5cxx11ENS_3gtl10ArraySliceINS_8DataTypeEEE+0xda): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >_, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\nbazel-out/local_linux-opt/bin/tensorflow/core/libframework_internal.lo(mirror_pad_mode.o): In function `tensorflow::GetNodeAttr(tensorflow::NodeDef const&, tensorflow::StringPiece, tensorflow::MirrorPadMode*)':\nmirror_pad_mode.cc:(.text._ZN10tensorflow11GetNodeAttrERKNS_7NodeDefENS_11StringPieceEPNS_13MirrorPadModeE+0x1fd): undefined reference to`tensorflow::strings::StrCat[abi:cxx11](tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\nbazel-out/local_linux-opt/bin/tensorflow/core/libframework_internal.lo(padding.o): In function `tensorflow::GetNodeAttr(tensorflow::NodeDef const&, tensorflow::StringPiece, tensorflow::Padding*)':\npadding.cc:(.text._ZN10tensorflow11GetNodeAttrERKNS_7NodeDefENS_11StringPieceEPNS_7PaddingE+0x1fd): undefined reference to`tensorflow::strings::StrCat[abi:cxx11](tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\ncollect2: error: ld returned 1 exit status\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 3.377s, Critical Path: 3.16s`\n\nAnother:\n### bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\nError info:\npython_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x2117): undefined reference to `tensorflow::strings::Appendf(std::string*, char const*, ...)'\npython_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x2140): undefined reference to`tensorflow::strings::Appendf(std::string_, char const_, ...)'\npython_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x2549): undefined reference to `tensorflow::strings::Appendf(std::string*, char const*, ...)'\npython_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x262a): undefined reference to`tensorflow::strings::Appendf(std::string_, char const_, ...)'\npython_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x2726): undefined reference to `tensorflow::strings::Appendf(std::string*, char const*, ...)'\npython_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x30db): undefined reference to`tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\npython_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x31b3): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\nbazel-out/host/bin/tensorflow/python/libpython_op_gen.lo(python_op_gen.o): In function`tensorflow::GetPythonOps(tensorflow::OpList const&, std::string const&, bool)':\npython_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x4e): undefined reference to `tensorflow::strings::Appendf(std::string*, char const*, ...)'\npython_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x37b): undefined reference to`tensorflow::strings::StrAppend(std::string_, tensorflow::strings::AlphaNum const&)'\npython_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x3d7): undefined reference to `tensorflow::strings::Appendf(std::string_, char const_, ...)'\npython_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x494): undefined reference to `google::protobuf::Message::DebugString() const'\npython_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x4b0): undefined reference to`tensorflow::strings::Appendf(std::string_, char const*, ...)'\ncollect2: error: ld returned 1 exit status\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 0.646s, Critical Path: 0.42s\n\nnvidia info:\nforfish1@Mercury:~/forfish1/workplace/gpu/tensorflow$ nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2015 NVIDIA Corporation\nBuilt on Tue_Aug_11_14:27:32_CDT_2015\nCuda compilation tools, release 7.5, V7.5.17\nforfish1@Mercury:~/forfish1/workplace/gpu/tensorflow$ nvcc\nnvcc fatal   : No input files specified; use option --help for more information\nforfish1@Mercury:~/forfish1/workplace/gpu/tensorflow$ \n\nHelp!!!!!\n", "comments": ["https://youtu.be/cVWVRA8XXxs\n\nMaybe this could help?\n", "I got this same error just a few minutes ago...\n\nFor me, it seemed to be an issue with whatever the master branch currently has in it - or whatever I actually am pulling if it's not the master. \n\nI forced a clone of the branch \"vrv-patch-1\" and that built just fine. Perhaps try that? \n", "@forfish Do you still have problems compiling example_trainer?\n", "@keveman 3Q for your attention\uff0cI updated to 0.8 and it work. \n"]}, {"number": 1931, "title": "error when import skflow from tensorflow.contrib..", "body": "I successfully installed tensorflow using ' pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp34-none-linux_x86_64.whl'!!!\nInstead when i run the examples in tensorflow/examples/skflow, an error occurred.\n' ImportError: cannot import name 'skflow'! \nit seems that the error comes from one sentence ' from tensorflow.contrib import skflow'.\n\nI tried to solve this problem, and asked the author(maybe). he said 'you should install 0.8 RC0 (released today) - it has skflow/learn now 0.7.1 didn't have it yet (it was a separate repo when it was released)'.\n\nI really confused about this.\n\nSo, how to insert the skflow(from a separate repo) into tensorflow?\n", "comments": ["Ok, sorry for bother others.  I find a quick way: just install tensorflow-0.8.0. \n'pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl'\nThat`s all. close.\n"]}]