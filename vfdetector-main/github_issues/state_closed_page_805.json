[{"number": 29389, "title": "Cherrypicks into 2.0 branch", "body": "", "comments": []}, {"number": 29388, "title": "Version update.", "body": "", "comments": []}, {"number": 29387, "title": "[TF 2.0 API Docs] tf.image.convert_image_dtype", "body": "Added a usage example in convert_image_dtype under image_ops_impl.py. Also added an attribute error raise and listed it in docstring. The issue has been raised in the link https://github.com/tensorflow/tensorflow/issues/29386", "comments": ["`int` is not a valid tf dtype argument. You can use dtypes.as_dtype(dtype)\nto make sure you have a valid dtype\n\nOn Tue, Jun 4, 2019 at 11:44 AM Imran Salam <notifications@github.com>\nwrote:\n\n> *@imransalam* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/python/ops/image_ops_impl.py\n> <https://github.com/tensorflow/tensorflow/pull/29387#discussion_r290437842>\n> :\n>\n> >    \"\"\"\n>    image = ops.convert_to_tensor(image, name='image')\n> +  if hasattr(dtype, 'is_floating') or hasattr(dtype, 'is_integer'):\n>\n> This looks nice. But wouldn't it throw an error at the if condition when\n> is_floating attribute does not exists in the dtype.\n> As an example:\n>\n> dtype = intif not dt.is_floating and not dt.is_integer:\n>   raise AttributeError(\"Type object has no attribute is_integer or is_floating\")\n>\n> This will raise the error\n>\n> AttributeError                            Traceback (most recent call last)<ipython-input-10-4228559210de> in <module>()----> 1 if not dt.is_floating and not dt.is_integer:\n>       2     raise AttributeError(\"Type object has no attribute is_integer or is_floating\")\n> AttributeError: type object 'int' has no attribute 'is_floating'\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/29387?email_source=notifications&email_token=AAABHRMMDRL73P5PIYAG6VDPY2ZXHA5CNFSM4HS24SKKYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOB2R7YBY#discussion_r290437842>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRMBK6ZIFSFW3NWNSN3PY2ZXHANCNFSM4HS24SKA>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp Hey I've done the necessary changes.", "@imransalam this just forces the creation of a dtype object; it doesn't validate that it's floating or integer.", "@alextp added the check", "@imransalam Could you please check failed build errors? Thanks!", "@imransalam Can you please address Ubuntu Sanity build failures? Thanks!", "> @imransalam Can you please address Ubuntu Sanity build failures? Thanks!\r\n\r\nI looked at the invocation log,\r\n```\r\n2. do_pylint PYTHON2: Python 2 pylint\r\n  FAIL\r\n3. do_pylint PYTHON3: Python 3 pylint\r\n FAIL\r\n```\r\nThese two have failed. Do you have any idea why they might occur ? Thanks", "The linter is failing. If you search in the logs you'll see the specific\nwarnings.\n\nOn Tue, Jun 11, 2019 at 7:31 AM Imran Salam <notifications@github.com>\nwrote:\n\n> @imransalam <https://github.com/imransalam> Can you please address Ubuntu\n> Sanity build failures? Thanks!\n>\n> I looked at the invocation log,\n>\n> 2. do_pylint PYTHON2: Python 2 pylint\n>   FAIL\n> 3. do_pylint PYTHON3: Python 3 pylint\n>  FAIL\n>\n> These two have failed. Do you have any idea why they might occur ? Thanks\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/29387?email_source=notifications&email_token=AAABHRIA2IKEU7ZHIGMJNW3PZ6ZKHA5CNFSM4HS24SKKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXNJLDI#issuecomment-500864397>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHROHRDT5Q7E6NRMHCMDPZ6ZKHANCNFSM4HS24SKA>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 29386, "title": "[TF 2.0 API Docs] tf.image.convert_image_dtype", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/image/convert_image_dtype\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed.\r\n\r\n### Usage example\r\n\r\nUsage example is not provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29387", "comments": ["Closing this issue since the associated PR has been merged. Feel free to reopen if the problem still persists. Thanks!"]}, {"number": 29385, "title": "Is there any way to get the size of the TFRecordDataset?", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): tensorflow-2.0.0-alpha0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI get some tfrecord files from someone. when I try to train the network with tf.keras.Model.fit(), it needs to pass a parameter \"steps_per_train\", but I don't know the size and how many data was saved in the tfrecord files. I have read the document of tensorflow2.0 but I find nothing help, so is there any way to get the size of the TFRecordDataset? Thank u\r\n\r\n**Will this change the current api? How?**\r\nNo, it won't change the current api. It may add an attribute with a \"get\" function.\r\n\r\n**Who will benefit with this feature?**\r\nEvery who need to know the size of tfrecord dataset\r\n\r\n**Any Other info.**\r\n", "comments": ["No, the only way to find out the cardinality of TFRecordDataset is to enumerate all of its elements."]}, {"number": 29384, "title": "Missing documentation for executing TF 1.0 frozen and saved models", "body": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI cannot find a documentation how to do the native inference with a frozen or saved model in TF 2.0.\r\n\r\n### Clear description\r\n\r\nWe would like to do inferences/predictions with existing models we trained in Tensorflow 1. Therefore, we have normal frozen and saved models. However, we cannot find a documentation how we can load these models and execute them afterwards. \r\nWe managed to load the [Graph objects](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Graph) but the Graph objects do not allow us to do predictions.\r\n\r\nIn the TFJS project the API is clear to us but in TF 2.0 we struggle a lot.  \r\n\r\n### Correct links\r\n### Parameters defined\r\n### Returns defined\r\n### Raises listed and defined\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\n# Load the Tensorflow model into memory.\r\ndetection_graph = tf.compat.v1.Graph()\r\nwith detection_graph.as_default():\r\n    od_graph_def = tf.compat.v1.GraphDef()\r\n    with tf.io.gfile.GFile(PATH_TO_FROZEN_MODEL, 'rb') as fid:\r\n        serialized_graph = fid.read()\r\n        od_graph_def.ParseFromString(serialized_graph)\r\n        tf.import_graph_def(od_graph_def, name='')\r\n```\r\n\r\n### Request visuals, if applicable\r\n### Submit a pull request?\r\n\r\nmany thanks,\r\nSebastian\r\n", "comments": ["Just to verify have you converted 1.x code to 2.0 and then trying to use predictions from saved model ? Please have a look on this [link](https://medium.com/tensorflow/upgrading-your-code-to-tensorflow-2-0-f72c3a4d83b5) to get some help on code upgradation and this [link](https://www.tensorflow.org/guide/saved_model#build_and_load_a_savedmodel) for building and loading a saved model. Let us know if that helps. Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 29383, "title": "skip_mismatch not supported in load_weights for Keras model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7.3\r\n\r\n**Describe the current behavior**\r\nI have noticed that mixing-and-matching keras and tensorflow.keras imports can cause some issues. I am therefore in the process of changing all keras imports in my projects to tensorflow.keras imports.\r\nI have now stumbled on the following problem: The function `load_weights` for a keras model does support the argument `skip_mismatch` in keras, but not in tensorflow.keras. Is this feature in the making?\r\n\r\n**Describe the expected behavior**\r\nThe tensorflow.keras function `load_weights` to have the same syntax as Keras's.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\n# Behavior depends on the import\r\n# from tensorflow.keras import *\r\n# from keras import *\r\n\r\nmodel = models.Sequential()\r\nmodel.load_weights(None, by_name=True, skip_mismatch=True)\r\n```\r\nNote that this code fails in any case, however, only with the tf.keras import this is because of invalid parameters.", "comments": ["Thanks for the request, this argument has been added. You should see the changes in the next nightly or TF 2.1.", "Great, thanks!", "When is TF 2.1 due? I really need this functionality, and am debating whether to risk nightly, use the separate keras package, or wait for the stable 2.1 release...", "@k-w-w Still does not work in the latest build `v1.12.1-17734-g3dffd6ed 2.1.0-dev20191109`. Please check [this Colab notebook](https://colab.research.google.com/drive/1M0PDxTsXfL0lvFcsEhNTvNG-titdARYo)."]}, {"number": 29382, "title": "optimize method fold_batch_norms, speed up this method", "body": "init method \r\nthe code of removing will cost so much time\r\n\r\nI use a new piece of code to replace the init code\r\nit will speed up.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29382) for more info**.\n\n<!-- need_sender_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29382) for more info**.\n\n<!-- need_author_cla -->", "> We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors. If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)? If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\r\n> In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29382) for more info**.\r\n\r\nmy github account use anohter email, but I signed a CLA with my gmail. so i add my gmail to my github account now .", "I signed it!", "Is it possible to add test cases to these new changes? ", "Looks like this PR is duplicate of #29421 therefore closing it and tracking the #29421. Thanks!"]}, {"number": 29381, "title": "Unable to build tensorflow from source", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution :Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 1.13.1, 1.14\r\n- Python version: Py3.5 & 3.6\r\n- Installed using virtualenv? pip? conda?: trying to build from source inside docker container.\r\n- Bazel version (if compiling from source): 0.24.0\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: GTX 1060 NVIDIA, Tesla T4\r\n\r\n**Describe the problem**\r\na) I downloaded the docker image from https://hub.docker.com/r/tensorflow/tensorflow/ with tags \"devel-gpu-py3\" and \"nightly-gpu-py3\". \r\nb) Inside the docker container i ran ./configure and selected the default paths. Python 3.6, TensorRT, CUDA and CUDNN were all detected.\r\nc) Gave the bazel command below:\r\n-------------------------------------------------------------\r\nroot@bad5744dae2b:/tensorflow# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nd) i get build failure logs as below.\r\nStarting local Bazel server and connecting to it...\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nDEBUG: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5: \r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 34, in <module>\r\n    from future.builtins import bytes\r\nModuleNotFoundError: No module named 'future'\r\nERROR: /tensorflow/tensorflow/core/BUILD:2750:1: no such package '@local_config_git//': Traceback (most recent call last):\r\n\tFile \"/tensorflow/third_party/git/git_configure.bzl\", line 61\r\n\t\t_fail(result.stderr)\r\n\tFile \"/tensorflow/third_party/git/git_configure.bzl\", line 14, in _fail\r\n\t\tfail((\"%sGit Configuration Error:%s %...)))\r\nGit Configuration Error: Traceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 34, in <module>\r\n    from future.builtins import bytes\r\nModuleNotFoundError: No module named 'future' and referenced by '//tensorflow/core:version_info_gen'\r\nERROR: /tensorflow/tensorflow/core/BUILD:2750:1: no such package '@local_config_git//': Traceback (most recent call last):\r\n\tFile \"/tensorflow/third_party/git/git_configure.bzl\", line 61\r\n\t\t_fail(result.stderr)\r\n\tFile \"/tensorflow/third_party/git/git_configure.bzl\", line 14, in _fail\r\n\t\tfail((\"%sGit Configuration Error:%s %...)))\r\nGit Configuration Error: Traceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 34, in <module>\r\n    from future.builtins import bytes\r\nModuleNotFoundError: No module named 'future'\r\n\r\n and referenced by '//tensorflow/core:version_info_gen'\r\nERROR: /tensorflow/tensorflow/core/BUILD:2750:1: no such package '@local_config_git//': Traceback (most recent call last):\r\n\tFile \"/tensorflow/third_party/git/git_configure.bzl\", line 61\r\n\t\t_fail(result.stderr)\r\n\tFile \"/tensorflow/third_party/git/git_configure.bzl\", line 14, in _fail\r\n\t\tfail((\"%sGit Configuration Error:%s %...)))\r\nGit Configuration Error: Traceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 34, in <module>\r\n    from future.builtins import bytes\r\nModuleNotFoundError: No module named 'future'\r\n\r\n and referenced by '//tensorflow/core:version_info_gen'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@local_config_git//': Traceback (most recent call last):\r\n\tFile \"/tensorflow/third_party/git/git_configure.bzl\", line 61\r\n\t\t_fail(result.stderr)\r\n\tFile \"/tensorflow/third_party/git/git_configure.bzl\", line 14, in _fail\r\n\t\tfail((\"%sGit Configuration Error:%s %...)))\r\nGit Configuration Error: Traceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 34, in <module>\r\n    from future.builtins import bytes\r\nModuleNotFoundError: No module named 'future'\r\n\r\nINFO: Elapsed time: 22.198s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (355 packages loaded, 7796 targets configured)\r\n    currently loading: tensorflow/lite/schema\r\n\r\n\r\n**Any other info / logs**\r\nNA", "comments": ["@pradeepdw Looks future module is not installed, please install future by \r\n`pip3 install future` \r\nLet us know if that solves the problem. Thanks!", "Hi,\r\n\r\nI installed \"future\" as mentioned by you. I still get this below error.\r\n\r\n./tensorflow/core/platform/default/logging.h:261:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\r\n TF_DEFINE_CHECK_OP_IMPL(Check_EQ,\r\n ^\r\n**_ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/nccl_archive/BUILD.bazel:54:1: undeclared inclusion(s) in rule '@nccl_archive//:device_lib':_**\r\nthis rule is missing dependency declarations for the following files included by 'external/nccl_archive/src/collectives/device/functions.cu.cc':\r\n  'external/nccl_archive/src/collectives/device/common.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 255.662s, Critical Path: 152.97s\r\nINFO: 2095 processes: 2095 local.\r\nFAILED: Build did NOT complete successfully\r\nroot@a2fb73b2703e:/tensorflow# \r\n", "I just did the below stuff...\r\n>> git clone https://github.com/tensorflow/tensorflow.git\r\n>>cd tensorflow\r\n>>docker pull tensorflow/tensorflow:devel-gpu-py3\r\n>>docker run --runtime=nvidia -it -w /tensorflow -v $PWD:/tensorflow --name devel_gpu_py3 -e HOST_PERMS=\"$(id -u):$(id -g)\" tensorflow/tensorflow:devel-gpu-py3 bash\r\n\r\nIn the docker container's prompt,\r\nroot@a2fb73b2703e:/tensorflow# ./configure --> make all the configurations\r\nroot@a2fb73b2703e:/tensorflow# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nEncounterd this error pasted above.\r\n", "@pradeepdw Just to verify, Did you follow the official website to build tensorflow from source using [docker](https://www.tensorflow.org/install/source#docker_linux_builds). Let us know if that resolves your issue. Thanks!", "Yes, i have followed exactly the same instructions in the link you mentioned. The Docker image i used is \"tensorflow/tensorflow:devel-gpu-py3\" and the docker command i used is mentioned above.\r\nBy the way, i have built 1.12.0 from source (using corresponding docker image) the same way and it works fine every time. So this seems to be an issue in the image \"tensorflow/tensorflow:devel-gpu-py3\".", "@pradeepdw, please try building TensorFlow with the `/tensorflow_src` directory instead. That is the most recent source code version the container was confirmed to build.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29381\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29381\">No</a>\n", "This issue has become stale, so I'm closing it to keep the tracker clean."]}, {"number": 29380, "title": "Tensorflow.image.resize_images not upgraded", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.0.0a0\r\n- Python version: 3.7.3\r\n\r\n**Describe the current behavior**\r\nThe function `tensorflow.image.resize_images()` is not upgraded with the tf_upgrade_v2 script. It is not replaced with any working function in tf2.\r\n\r\n**Describe the expected behavior**\r\nThe function to be converted to `tf.image.resize()`?\r\n\r\n**Code to reproduce the issue**\r\nUpgrade the following code with tf_upgrade_v2 and run it in tensorflow 2.0\r\n```python\r\nimport tensorflow\r\n\r\ntensorflow.image.resize_images()\r\n```", "comments": ["@kriskorrel-cw The function tensorflow.image.resize_images() has been upgraded with tf.image.resize() in TF 2.0. For more information refer this [link](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/resize). Thanks! ", "Yes, I saw that. But shouldn't `tf_upgrade_v2` then automatically convert to this? Now I run into errors when I upgrade my project to TensorFlow 2.0, since the function is not automatically converted.", "The **tf_upgrade_v2** converter tool looks for ```tf``` keyword.\r\nFollowing changes to your code should do the trick,\r\n```python\r\nimport tensorflow as tf\r\ntf.image.resize_images()\r\n```\r\nOutput after executing the converter tool:\r\n```python\r\nINFO line 12:0: Renamed 'tf.image.resize_images' to 'tf.image.resize'\r\nTensorFlow 2.0 Upgrade Script\r\n-----------------------------\r\nConverted 1 files\r\nDetected 0 issues that require attention\r\n--------------------------------------------------------------------------------\r\n\r\n\r\nMake sure to read the detailed log 'report.txt'\r\n```", "Ah okay, but that is still very confusing.\r\nWhy wouldn't tensorflow upgrade tensorflow imports? Tf is only an (unofficial) shorthand for tensorflow that is commonly used, but there is nothing wrong with just `import tensorflow`. ", "This is a limitation of the converter tool as of now. However making it more robust to cases like these is on our road map. Please use import tensorflow as tf with upgrade script. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29380\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29380\">No</a>\n"]}, {"number": 29379, "title": "Move cache_rpc_response from GrpcWorkerServiceOptions to ConfigProto.\u2026", "body": "for this  \r\n```  \r\n    // TODO(jingdong): it would be cleaner to move this option to GrpcWorker\r\n    // since the cache is maintained by GrpcWorker now.\r\n    if (options.cache_rpc_response) {\r\n      worker->EnableResponseCache();\r\n    }\r\n```  ", "comments": ["@gbaned Would you mind adding another reviewer?", "@jing-dong Merging this PR (which looks reasonable to me) will require some changes to the internal code that uses `GrpcWorkerServiceOptions` today. Can you please review and kick off the merge process? Thanks!", "@mrry @gbaned It's been 14 days. @jing-dong may be busy and have no time to deal with it.", "This change has been pushed to the master in the following commit:\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/29c522fd3e966b6a918d744b45318b59fc5d969a"]}, {"number": 29378, "title": "get sequence length when use tf.dataset", "body": "@ry @jmhodges @eggie5 @bmabey @djones \r\nI want to get sequence length, when use tf.dataset, but when I got next batch, the length still [?, ?],\r\nI want to know the second element, but as I saw, tf.dataset don't support, Is I wrong or tf.dataset still not support this? Could anyone tell me the reason.", "comments": ["![image](https://user-images.githubusercontent.com/30991932/58847564-ffc7d680-86b5-11e9-8dff-6e7aafd73532.png)\r\nthis is my code", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact code snippet required to replicate the issue included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Thx,i found way to slove this\n\n\nfrom Alimail iPhone\n ------------------Original Mail ------------------\nFrom:achandraa <notifications@github.com>\nDate:2019-06-05 17:50:19\nRecipient:tensorflow/tensorflow <tensorflow@noreply.github.com>\nCC:Cally <mx15025700935@aliyun.com>, Author <author@noreply.github.com>\nSubject:Re: [tensorflow/tensorflow] get sequence length when use tf.dataset (#29378)\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\nMake sure you also include the exact code snippet required to replicate the issue included in your test case. If you are unclear what to include see the issue template displayed in the Github new issue template.\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread. ", "Great..Will close the issue since it is resolved. Thanks!"]}, {"number": 29377, "title": "AttributeError: module 'tensorflow.python.keras' has no attribute 'Model' #21927", "body": "The same issue was closed #21927. May not get attention due to that.\r\n\r\n**System information**\r\n- Have I written custom code No\r\n- OS Platform and Distribution: Ubuntu 16.04.3 LTS\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.40\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"model_keras.py\", line 21, in <module>\r\n    class sequentialLSTM(tf.keras.Model):\r\nAttributeError: module 'tensorflow.python.keras' has no attribute 'Model'\r\n```\r\n", "comments": ["@VertexC In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "simply do `import tensorflow.keras.Model`", "@VertexC Tensorflow keras model can be imported as \r\n```\r\nimport tensorflow as tf\r\ntf.keras.Model()\r\n```\r\nLet us know if that solves the problem. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "AttributeError: module 'tensorflow.keras.models' has no attribute 'Sequencial'"]}, {"number": 29376, "title": "Fix typo in TFLite Custom operators guide", "body": "proggram -> program", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29376) for more info**.\n\n<!-- need_sender_cla -->", "just signed the CLA", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29376) for more info**.\n\n<!-- ok -->"]}, {"number": 29375, "title": "My GCP instance runs around 3 times slower than Gcolab with same configs", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.6 LTS\r\n- TensorFlow version (use command below): b'v1.13.1-0-g6612da8951' 1.13.1\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: CUDA 10.0/cuDNN 7.6\r\n- GPU model and memory: T4 GPU with 15079MB memory\r\n\r\n**Describe the current behavior**\r\nI have an `GCP instance` with T4 GPU with same `tensorflow` `keras` `CUDA` version as `Gcolab`. However, for the same piece of code, my GCP instance is more than 3 times slower than `Gcolab`. Can anyone please give any clue that what should I do to improve the performance of my GCP instance. Thanks!\r\n#### Log on my GCP instance\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\n2019-06-03 14:37:25.721579: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-06-03 14:37:25.983647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-03 14:37:25.986134: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x43fea10 executing computations on platform CUDA. Devices:\r\n2019-06-03 14:37:25.986176: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\r\n2019-06-03 14:37:26.015456: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000160000 Hz\r\n2019-06-03 14:37:26.016362: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4468690 executing computations on platform Host. Devices:\r\n2019-06-03 14:37:26.016393: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-06-03 14:37:26.016745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\r\npciBusID: 0000:00:04.0\r\ntotalMemory: 14.73GiB freeMemory: 14.52GiB\r\n2019-06-03 14:37:26.016772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-06-03 14:37:26.018593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-06-03 14:37:26.018618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-06-03 14:37:26.018625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-06-03 14:37:26.018699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14127 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\r\nEpoch 1/5\r\n2019-06-03 14:37:28.721949: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\r\n600000/600000 [==============================] - 5s 8us/sample - loss: 10.2455 - acc: 0.3423\r\nEpoch 2/5\r\n600000/600000 [==============================] - 4s 6us/sample - loss: 7.3609 - acc: 0.5225\r\nEpoch 3/5\r\n600000/600000 [==============================] - 4s 7us/sample - loss: 5.8075 - acc: 0.6186\r\nEpoch 4/5\r\n600000/600000 [==============================] - 4s 7us/sample - loss: 5.4575 - acc: 0.6382\r\nEpoch 5/5\r\n600000/600000 [==============================] - 5s 8us/sample - loss: 5.3016 - acc: 0.6465\r\n```\r\n#### Log on Gcolab\r\n```\r\nEpoch 1/5\r\n600000/600000 [==============================] - 2s 3us/sample - loss: 10.2666 - acc: 0.3293\r\nEpoch 2/5\r\n600000/600000 [==============================] - 2s 3us/sample - loss: 7.5881 - acc: 0.4941\r\nEpoch 3/5\r\n600000/600000 [==============================] - 2s 3us/sample - loss: 7.2098 - acc: 0.5236\r\nEpoch 4/5\r\n600000/600000 [==============================] - 2s 3us/sample - loss: 6.8803 - acc: 0.5298\r\nEpoch 5/5\r\n600000/600000 [==============================] - 2s 3us/sample - loss: 6.1390 - acc: 0.5506\r\n<tensorflow.python.keras.callbacks.History at 0x7f708c110a20>\r\n```\r\n**Describe the expected behavior**\r\nThe performance on my GCP instance should be the same with Gcolab since everything is the same\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras as keras\r\nimport numpy as np\r\n\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\ntrain_images = train_images.repeat(10, axis=0)\r\ntrain_labels = train_labels.repeat(10, axis=0)\r\n\r\nmodel = keras.Sequential([\r\n    keras.layers.Flatten(input_shape=(28, 28)),\r\n    keras.layers.Dense(128, activation=tf.nn.relu),\r\n    keras.layers.Dense(128, activation=tf.nn.relu),\r\n    keras.layers.Dense(128, activation=tf.nn.relu),\r\n    keras.layers.Dense(128, activation=tf.nn.relu),\r\n    keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(train_images, train_labels, epochs=5, batch_size=60000)\r\n```\r\n**Other info / logs**\r\n#### My GCP instance info\r\n![Screen Shot 2019-06-03 at 2 53 17 PM](https://user-images.githubusercontent.com/41984177/58838297-23861080-8613-11e9-827c-70eb8fa1923a.png)\r\n![Screen Shot 2019-06-03 at 2 58 08 PM](https://user-images.githubusercontent.com/41984177/58838309-2aad1e80-8613-11e9-9617-c1fdcae7bdb7.png)\r\n![Screen Shot 2019-06-03 at 3 00 14 PM](https://user-images.githubusercontent.com/41984177/58838319-33055980-8613-11e9-813a-784cabffe8a1.png)\r\n![Screen Shot 2019-06-03 at 2 58 28 PM](https://user-images.githubusercontent.com/41984177/58838327-3b5d9480-8613-11e9-9a69-7ce7cdd3819a.png)\r\n\r\n#### Gcolab info\r\n![Screen Shot 2019-06-04 at 9 54 30 AM](https://user-images.githubusercontent.com/41984177/58898181-d9526d00-86ae-11e9-9a1b-da6ab5de79ea.png)\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Could you remove the following lines and check if the performance difference is still there?\r\n```python\r\nimport keras\r\nprint(keras.__version__)\r\n```\r\n`import keras` and `from tensorflow import keras` execute different code paths, thus mixing both can lead to unexpected behaviour. ", "@lgeiger Thanks for the reply, I update the script and the results are similar. Gcolab is still much faster than my GCP instance", "Closing this issue since its resolved. Feel free to reopen if still have further problems. Thanks!"]}, {"number": 29374, "title": "Batched matrix multiplication is incorrect for large batches", "body": "This bug seems to exist in all versions of TensorFlow from (at least) `1.13` to the current `2.0` nightly under multiple configurations (host os, gpu, python versions...) with CUDA 10.0.\r\n\r\nIt can be reproduced fairly easily:\r\n\r\n```python\r\nwith tf.device('gpu:0'):\r\n  v = tf.ones((2**17, 1, 1), dtype=tf.float32)\r\n  print(tf.reduce_sum(tf.matmul(v, v)))\r\n```\r\n\r\nThis prints `65535.0` instead of `131072.0` (stemming from the output values at indices `>= 2**16` being `0`)\r\n\r\nColab: https://colab.research.google.com/drive/1CZiKKWkI96SAVRJ5kMkT5kmMunipJhdx\r\n\r\nSome observations:\r\n\r\n- This occurs for batch dimensions greater than or equal to 2<sup>16</sup>.\r\n- This only occurs on the GPU. The CPU version seems fine.\r\n- This only occurs for FP32. FP64 seems fine.\r\n- In TensorFlow 2.0, the bug only manifests on the first run (as shown in the colab example). Subsequent runs produce the correct result.\r\n", "comments": ["I could reproduce the reported issue on colab. Thanks!", "I can only reproduce with 2.0, not with 1.13.\r\n\r\n@smit-hinsu could you help to take a look? Thanks.", "@aaroey: This reproduces it on v1.13: https://colab.research.google.com/drive/1ycxH0LP2TPJxBKci5XqsgguhHdGCow1I\r\n\r\nThe underlying issue seems to be reading out of bounds memory for elements `>= 2**16`. In the example above, that out-of-bounds region is zeros. However, you can just as easily get other results.", "Duplicate of #26969 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29374\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29374\">No</a>\n"]}, {"number": 29373, "title": "[INTEL MKL] Revert tensorflow_estimator to 1.13.0rc0, < 1.14.0rc0", "body": "Looks like we should stick with:\r\n```\r\n'tensorflow_estimator >= 1.13.0rc0, < 1.14.0rc0'\r\n```\r\nUntil version `1.14.0rco` of `tensorflow_estimator` is published until you want me to use the `nightly` builds which I believe is risky.", "comments": ["@bananabowl ", "This is the error I'm getting during wheel building:\r\n```\r\nCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.13.1)\r\n\u001b[91m  ERROR: Could not find a version that satisfies the requirement tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.13.1) (from versions: 1.10.6, 1.10.7, 1.10.8, 1.10.9, 1.10.10, 1.10.11, 1.10.12, 1.13.0rc0, 1.13.0)\r\n\u001b[0m\u001b[91mERROR: No matching distribution found for tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.13.1)\r\n\u001b[0mThe command '/bin/sh -c bazel --bazelrc=/root/.bazelrc build -c opt     tensorflow/tools/pip_package:build_pip_package &&     bazel-bin/tensorflow/tools/pip_package/build_pip_package \"${WHL_DIR}\" &&     ${PIP} --no-cache-dir install --upgrade \"${WHL_DIR}\"/tensorflow-*.whl &&     rm -rf /root/.cache' returned a non-zero code: 1\r\n```", "If we don't want to wait for `tensorflow_estimator` to be published, we can use `dependency_links` within `setup.py` \ud83d\ude42 ", "Sorry about that - we are expecting to cut tensorflow_estimator 1.14 RC0 today (@mihaimaruseac is handling it). ", "Estimator 1.14 RC0 is now available: https://pypi.org/project/tensorflow-estimator/1.14.0rc0/"]}, {"number": 29372, "title": "[ROCm] Add ROCm support for remaining cwise ops and tests", "body": "cwise_ops.h -- packet access is always false for ROCm.\r\nSome ROCm ops do not yet support complex64 / complex128 types.", "comments": []}, {"number": 29371, "title": "ValueError: Output tensors to a Model must be the output of a TensorFlow `Layer`", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): `pip3 install tensorflow`\r\n- TensorFlow version: 1.13.1\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: No\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nI am currently building a few custom Keras layers. However, when I try to return a tf.keras.Model with outputs that is the output of the last layer, I get the error:\r\n`ValueError: Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: Tensor(\"layer_normalization_1/batchnorm/add_1:0\", shape=(?, ?, 10), dtype=float32)`.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nimport tensorflow as tf\r\ninps = tf.keras.Input(shape=(None, 256), name=\"inps\")\r\nmask = tf.keras.Input(shape=(1, 1, None), name=\"mask\")\r\nm1 = tf.random.uniform(shape=(8, 20))\r\nm2 = tf.random.uniform(shape=(8, 20))\r\noutputs = tf.keras.layers.Dense(units=512)(m1 + m2)\r\nmodel = tf.keras.Model(inputs=[inps, mask], outputs=outputs, name=\"test\")\r\n```\r\n-- These are toy commands that are similar to my actual code. I was confused as to why the \r\noutputted values from a Dense layer aren't considered outputs from a Tensorflow Layer.\r\n\r\n", "comments": ["I am able to reproduce the issue on colab with Tensorflow 1.13.1. Thanks!", "Thanks! It's sort of a blocker for me at the moment, do you think there's anything I could try?\r\n\r\n\r\nEdit: I tried it on TF2 Alpha and it doesn't seem to be having this problem. Do you know which modules I can look at for pointer? Thanks.", "@UltraSpecialException The inputs to your dense layer are constant-valued. They need to come from keras.Input in order for the Model to be connected", "Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29371\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29371\">No</a>\n", "anyone found the answer?", "Did anyone found the answer? As far as I know, tf.keras is not compatible with tf in tf 1.x. In tf 2.x they work fine.", "From what I can see there is no reliable way to put constants in a TF 1.x Keras graph.  You can add them as an Input() or as a lambda function (https://stackoverflow.com/a/50716411/2184122).  The first is messy as you need to transmit your constant using some other mechanism.  The second is messy because you have python \"stuff\" embedded in you model, so also need to transmit that code along with your model.\r\n\r\nTensorFlow 2.x seems to have taken care of this missing functionality."]}, {"number": 29370, "title": "R2.0 fastforward branch.", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29370) for more info**.\n\n<!-- need_author_consent -->", "Could you resolve the conflicts?", "This is a fastforward of the release branch, cla OK", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29370) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 29369, "title": "R2.99 fastforward test.", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29369) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 29368, "title": "Add a GNMT integration test for autoclustering.", "body": "Add the GNMT pbtxt to track the status of autoclustering.", "comments": ["@sanjoy Per our previous discussion, please help to take a look of this PR for adding an integration test for autoclustering."]}, {"number": 29367, "title": "[TF2.0] Lazy Tensors", "body": "Hello everyone,\r\n\r\nThe TF2.0 is great and brings a lot of benefits: \"functions not sessions\", modules and cetera. Although, there are downsides as well. E.g. I found that tensorflow probability framework (TFP) is very coupled with and centric on TF1.0. I do believe that many other projects have the same level of dependency on TF1.0.\r\n\r\nParticularly, the problem is in the core feature of TF2.0 - _eager execution_. Operations and tensors are executed at routine invoke time, e.g. `tf.convert_to_tensor(...)` returns a result not a reference to the graph tensor. There are no links between TensorFlow tensors anymore. Let's dive into an example to understand why this causes issues.\r\n\r\nIn https://github.com/tensorflow/probability/issues/333, I created a distribution and passed tensorflow variables as arguments. In turn, the distribution's init method does the arguments' checking (shape and types) and tries to convert the arguments to a nice form, e.g. passing them to the linear operator class, which can also have another bunch of testing procedures and this can go on and on. Implications of these modifications are not straightforward and not obvious at first glance! Now, we take a look at `tf.Module` abstraction. It is a nice way to organize and build complex models (not only models, but any structure which keeps all relevant things together) by using plain objects like **variables** and other **submodules**. The distribution can be a module or a model can subclass from module class and keep a distribution as a property. Here is a code snippet:\r\n\r\n```python\r\n# Model definition\r\nclass Model(tf.Module):\r\n    def __init__(self, mean: tf.Tensor, covariance: tf.Tensor):\r\n        self.mean = mean\r\n        self.covariance = covariance\r\n        self.covariance_diag = tf.linalg.LinearOperatorDiag(covariance)  # Operator calls tf.convert_to_tensor and takes diag of the input\r\n        self.distribution = tfd.MultivariateNormalTriL(mean, covariance)  # Uses tf.convert_to_tensor inside and \r\n    def loss(self):\r\n         # !!!\r\n         # Use **only** distribution sample and linear diag operator to get the loss\r\n         # !!!\r\n\r\n# Model creation\r\nM = tf.random.uniform((3,))\r\nL = tf.linalg.band_part(tf.random.uniform((3, 3)), -1, 0)\r\nmean_var = tf.Variable(mean)\r\ncov_var = tf.Variable(tf.matmul(L, L, transpose_b=True))\r\n\r\n\r\n# Find gradients\r\nmodel = Model(mean, cov_var)\r\nwith tf.GradientTape() as tape:\r\n    loss = model.loss()\r\n\r\ngrads = tape.gradient(loss, model.trainable_variables)\r\n```\r\n\r\nIn the code above, everything single computation outside of the gradient tape will not be recorded by new TF2.0 design: it is all operations inside init `Model` method including variables, as they connected with loss via linear operator and distribution objects.\r\n\r\nLet's repeat the apparent - _any computation outside of the tape will never be included in the tape recording_ - **that is very strong constraint for developing new models and frameworks in TF2.0**\r\n\r\nOne solution would be to create a **lazy tensors** which could postpone the execution until we actually invoke a function which is involved in computation with lazy tensors. In that scenario the tensorflow tape could track back the path though the parts created outside of the context.\r\n\r\n\r\nhttps://github.com/tensorflow/probability/issues/47\r\nhttps://github.com/tensorflow/probability/issues/333\r\nhttps://github.com/tensorflow/probability/issues/348", "comments": ["I don't think your suggestion of deferring computation until a result is requested is workable in tensorflow because many TF operations have side effects (any variable read/write, rng usage, dataset iterating, etc) and so values might never be requested but operations should still be run.\r\n\r\nSimilarly I don't think it makes sense realistically to keep the memory alive for things which happen outside the context of a gradient tape, as hardware accelerator (GPU) memory is fairly limited as-is.\r\n\r\nI believe you should be able to restructure the code so the computation you want to differentiate happens inside a tape, and similarly restructure the code so stuff that only needs to happen once (initialization-time validation) doesn't sit next to stuff that needs to happen in a loop (and be differentiable).", "The way this is generally handled is to \r\n\r\n* Start the gradient tape earlier\r\n* Don't do things in __init__. Keras layers for example use a pattern in which __call__ checks whether the layer has been built and builds it if not calls a build method. \r\n\r\nI think those would be preferable to introducing lazy execution even if it were possible to do consistently. ", "@martinwicke , @alextp thanks for your answers.\r\n\r\n> I think those would be preferable to introducing lazy execution even if it were possible to do consistently.\r\n\r\n@martinwicke I agree, that might be an easiest solution. Do you know why `tf.linalg.LinearOperator`s don't follow the  `__init__` rule? The `tf.linalg.LinearOperator` is one the pain points in this regard. The usefulness of this abstraction is diminished by the fact that you can't store this object as a property in a module.", "@rmlarsen \r\n\r\nThe simple answer is likely that LinearOperators predate eager mode and therefore assume deferred computation anyway. \r\n\r\nYou can keep LinearOperators in fields, but you have to construct them in build, along with the other variables etc.", "@martinwicke , what do you mean by\r\n\r\n> You can keep LinearOperators in fields, but you have to construct them in build, along with the other variables etc.\r\n\r\nLet's say, I use `tf.Module` and `tf.linalg.LinearOperatorDiag`. The `tf.Module` doesn't provide a `build` method and `tf.linalg.LinearOperatorLowerTriangular`'s constructor requires LHS tensor. \r\n\r\n```python\r\nclass A(tf.Module):\r\n    def __init__(self, variable: tf.Tensor):\r\n        self.diag_op = tf.linalg.LinearOperatorLowerTriangular(variable)  # Doesn't work! No links in the gradient between the variable and the rest of the computation, because LinearOperatorLowerTriangular apply all sorts of operations to the input.\r\n```\r\n\r\nWhat did you in have in mind? Do you want to postpone linear operator construction? [TFP](https://github.com/tensorflow/probability) uses heavily linear operators, can we include someone from  TFP team to this conversation? Thanks!", "The LinearOperator API is sadly eager-unfriendly and we need to fix it. I\nthink Martin just assumed it was nicer than it is.\n\nOn Tue, Jun 4, 2019 at 10:10 AM Artem Artemev <notifications@github.com>\nwrote:\n\n> @martinwicke <https://github.com/martinwicke> , what do you mean by\n>\n> You can keep LinearOperators in fields, but you have to construct them in\n> build, along with the other variables etc.\n>\n> Let's say, I use tf.Module and tf.linalg.LinearOperatorDiag. The tf.Module\n> doesn't provide a build method and tf.linalg.LinearOperatorLowerTriangular's\n> constructor requires LHS tensor.\n>\n> class A(tf.Module):\n>     def __init__(self, variable: tf.Tensor):\n>         self.diag_op = tf.linalg.LinearOperatorLowerTriangular(variable)  # Doesn't work! No links in the gradient between the variable and the rest of the computation, because LinearOperatorLowerTriangular apply all sorts of operations to the input.\n>\n> What did you in have in mind? Do you want to postpone linear operator\n> construction? TFP <https://github.com/tensorflow/probability> uses\n> heavily linear operators, can we include someone from TFP team to this\n> conversation? Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29367?email_source=notifications&email_token=AAABHRJFZEDQRJXFL2NKPSTPY2OXPA5CNFSM4HSOCFW2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODW5G5LA#issuecomment-498757292>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRJANO5BEPEAWSFI7PTPY2OXPANCNFSM4HSOCFWQ>\n> .\n>\n\n\n-- \n - Alex\n", "Thanks @awav for raising this and @martinwicke for your input.\r\n\r\nWe have a candidate solution for some of these issues in TFP, a template for which is in the review process now. It will require a rather substantial and coordinated effort to port forward all of our distributions and bijectors. It's likely something similar can and should be done for LinearOperator*. \r\n\r\nThe solution is twofold (maybe 3-fold depending on how you count) -- 1. don't do work in __init__, and 2. take care not to call tf.convert_to_tensor on Variables (a particularly tricky part is 3. properly handle assertions in the presence of mutable internal state; stay tuned to see how we are solving all this in TFP distributions and bijectors).", "@alextp, should I create a separate issue about linear operators?\r\n@csuter, that's good news! Is that an internal PR?", "Please create the issue for linear operator, so we can discuss it there.\n\nMy plan of record is to wait until TFP settles on a good solution and then\ncopy it to the operators.\n\nOn Wed, Jun 5, 2019 at 1:53 AM Artem Artemev <notifications@github.com>\nwrote:\n\n> @alextp <https://github.com/alextp>, should I create separate issue about\n> linear operators?\n> @csuter <https://github.com/csuter>, that's good news! Is that an\n> internal PR?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29367?email_source=notifications&email_token=AAABHRJJCBZ2JEERAQURNX3PY55IDA5CNFSM4HSOCFW2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODW7A7MA#issuecomment-498995120>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRNCEZBMJVDIG6BIMF3PY55IDANCNFSM4HSOCFWQ>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 29366, "title": "[XLA] Allow HloCustomCallInstruction to have a side-effect", "body": "Allows HloCustomCallInstruction to have a side-effect, which means CustomCall instructions which are configured to have a side-effect won't be removed from the graph by DCE - for example a custom call instruction which implements a print.\r\n\r\nThis is a follow up from https://github.com/tensorflow/tensorflow/pull/29355 with feedback from @jlebar ", "comments": ["Oh, indeed.  For the cases where you add it to a computation (and so get\nback a raw pointer) you can do it, but not here.\n\nOn Mon, Jun 3, 2019 at 10:42 AM Grzegorz George Pawelczak <\nnotifications@github.com> wrote:\n\n> *@georgepaw* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/compiler/xla/service/hlo_instruction_test.cc\n> <https://github.com/tensorflow/tensorflow/pull/29366#discussion_r289954687>\n> :\n>\n> > @@ -1751,6 +1764,29 @@ TEST_F(HloInstructionTest, CloneDnumsOnCustomCall) {\n>        << clone->convolution_dimension_numbers().DebugString();\n>  }\n>\n> +TEST_F(HloInstructionTest, CloneHasSideEffectOnCustomCall) {\n> +  auto instr = HloInstruction::CreateCustomCall(ShapeUtil::MakeShape(F32, {}),\n> +                                                /*operands=*/{},\n> +                                                /*custom_call_target=*/\"foo\");\n> +  auto custom_call_instr = static_cast<HloCustomCallInstruction*>(instr.get());\n>\n> Does this work? CreateCustomCall returns a unique pointer\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/29366?email_source=notifications&email_token=AABEZB5TJERCXZSPCRQFVTTPYVJXBA5CNFSM4HSJ2ADKYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOB2NLNHA#discussion_r289954687>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABEZB6B5P6A22AAUTYV5MLPYVJXBANCNFSM4HSJ2ADA>\n> .\n>\n", "Thanks for all the feedback! I think I have addressed it all."]}, {"number": 29365, "title": "training consumes a lot of RAM and gets killed", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18.04.2 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): n/a\r\n- TensorFlow version (use command below): 1.14.0-rc0\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: CUDA 10.2 \r\n- GPU model and memory: NVIDIA GeForce GTX 1080/PCIe/SSE2\r\n\r\n\r\n**Describe the current behavior**\r\nI am trying to run the faster rcnn inception v2 model in a docker container.\r\ni follow the instructions from https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#6-run-the-training\r\nand in the past i was able to run training on their dataset (not inside a docker container).\r\nnow, when i try to run training, i get a \"killed\" message after \"Recording summary at step 0\".\r\nthe proccess is very demanding in terms of memory and reaches over 19 GB just before it stops.\r\ni use nvidia/cuda:10.0-devel-ubuntu16.04 as a container.\r\n\r\n\r\n**Code to reproduce the issue**\r\nfrom models-master/research/object_detection:\r\n\r\npython3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config\r\n\r\n**Other info / logs**\r\n\r\n2019-06-03 13:02:38.264499: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-06-03 13:02:38.300525: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-06-03 13:02:38.320500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-06-03 13:02:38.326786: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-06-03 13:02:38.372259: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-06-03 13:02:38.401320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-06-03 13:02:38.401629: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2019-06-03 13:02:38.401677: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\r\n2019-06-03 13:02:38.401725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-06-03 13:02:38.401758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2019-06-03 13:02:38.401787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n2019-06-03 13:02:40.182868: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\nW0603 13:02:41.522990 140514728642304 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nI0603 13:02:41.525922 140514728642304 saver.py:1280] Restoring parameters from /home/models-master/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt\r\nI0603 13:02:42.337087 140514728642304 session_manager.py:500] Running local_init_op.\r\nI0603 13:02:42.828116 140514728642304 session_manager.py:502] Done running local_init_op.\r\nI0603 13:02:51.479744 140514728642304 learning.py:754] Starting Session.\r\nI0603 13:02:51.717492 140509938947840 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\r\nI0603 13:02:51.721246 140514728642304 learning.py:768] Starting Queues.\r\nI0603 13:03:00.753286 140509720868608 supervisor.py:1099] global_step/sec: 0\r\nI0603 13:03:09.625022 140509712475904 supervisor.py:1050] Recording summary at step 0.\r\nKilled\r\n\r\n\r\n\r\nthe config file:\r\n\r\nmodel {\r\n  faster_rcnn {\r\n    num_classes: 6\r\n    image_resizer {\r\n      keep_aspect_ratio_resizer {\r\n        min_dimension: 600\r\n        max_dimension: 1024\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'faster_rcnn_inception_v2'\r\n      first_stage_features_stride: 16\r\n    }\r\n    first_stage_anchor_generator {\r\n      grid_anchor_generator {\r\n        scales: [0.25, 0.5, 1.0, 2.0]\r\n        aspect_ratios: [0.5, 1.0, 2.0]\r\n        height_stride: 16\r\n        width_stride: 16\r\n      }\r\n    }\r\n    first_stage_box_predictor_conv_hyperparams {\r\n      op: CONV\r\n      regularizer {\r\n        l2_regularizer {\r\n          weight: 0.0\r\n        }\r\n      }\r\n      initializer {\r\n        truncated_normal_initializer {\r\n          stddev: 0.01\r\n        }\r\n      }\r\n    }\r\n    first_stage_nms_score_threshold: 0.0\r\n    first_stage_nms_iou_threshold: 0.7\r\n    first_stage_max_proposals: 300\r\n    first_stage_localization_loss_weight: 2.0\r\n    first_stage_objectness_loss_weight: 1.0\r\n    initial_crop_size: 14\r\n    maxpool_kernel_size: 2\r\n    maxpool_stride: 2\r\n    second_stage_box_predictor {\r\n      mask_rcnn_box_predictor {\r\n        use_dropout: false\r\n        dropout_keep_probability: 1.0\r\n        fc_hyperparams {\r\n          op: FC\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.0\r\n            }\r\n          }\r\n          initializer {\r\n            variance_scaling_initializer {\r\n              factor: 1.0\r\n              uniform: true\r\n              mode: FAN_AVG\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n    second_stage_post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 0.0\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 300\r\n      }\r\n      score_converter: SOFTMAX\r\n    }\r\n    second_stage_localization_loss_weight: 2.0\r\n    second_stage_classification_loss_weight: 1.0\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 1\r\n  optimizer {\r\n    momentum_optimizer: {\r\n      learning_rate: {\r\n        manual_step_learning_rate {\r\n          initial_learning_rate: 0.0002\r\n          schedule {\r\n            step: 900000\r\n            learning_rate: .00002\r\n          }\r\n          schedule {\r\n            step: 1200000\r\n            learning_rate: .000002\r\n          }\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n    }\r\n    use_moving_average: false\r\n  }\r\n  gradient_clipping_by_norm: 10.0\r\n  fine_tune_checkpoint: \"/home/models-master/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt\"\r\n  from_detection_checkpoint: true\r\n  num_steps: 200000\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n}\r\n\r\n\r\ntrain_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"/home/models-master/research/object_detection/train.record\"\r\n  }\r\n  label_map_path: \"/home/models-master/research/object_detection/training/labelmap.pbtxt\"\r\n  queue_capacity: 10\r\n  min_after_dequeue: 5\r\n}\r\n\r\neval_config: {\r\n  num_examples: 67\r\n  max_evals: 10\r\n}\r\n\r\neval_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"/home/models-master/research/object_detection/test.record\"\r\n  }\r\n  label_map_path: \"/home/models-master/research/object_detection/training/labelmap.pbtxt\"\r\n  shuffle: false\r\n  num_readers: 1\r\n}\r\n\r\n\r\n", "comments": ["This is related, since a year on stack. I wonder why session uses so much memory. \r\n\r\nIn the code I run, the variables should have memory of about 25MB = float16(2bytes) * numberOfMatrixElements * numberOfVariables. But it demands about 17GB or something which is quite insane.\r\n\r\nhttps://stackoverflow.com/questions/46114462/tensorflow-allocating-large-amounts-of-main-memory-at-session-startup-time", "@Eladsimba As this is more related to TF models, please post this in [TF model repo](https://github.com/tensorflow/models/issues). Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29365\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29365\">No</a>\n"]}, {"number": 29364, "title": "Update RELEASE.md with Estimator 1.14 release notes.", "body": "", "comments": []}, {"number": 29363, "title": "Simplify code", "body": "", "comments": []}, {"number": 29362, "title": "About can't use GPU to run programs, but I have GPU and CUDA environment", "body": "&emsp;&emsp;I have 4 GTX1080 graphics card. but I can't using tensorflow-gpu to run my code\u3002\r\n&emsp;&emsp;CUDA\uff1f yes\r\n&emsp;&emsp;Here are my CUDA information, my source code, error alerts, graphics card information\r\n&emsp;&emsp;thanks for your help\r\n\r\n## some information\r\n\r\nOS Platform and Distribution: Ubuntu 14.04.5 LTS\r\nTensorFlow installed from: pip install\r\nTensorFlow version: 1.2.0\r\nCUDA/cuDNN version: 8.0.61\r\n\r\n## This is my \"nvcc -V\" tips\r\n\r\n```bash\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2013 NVIDIA Corporation\r\nBuilt on Wed_Jul_17_18:36:13_PDT_2013\r\nCuda compilation tools, release 5.5, V5.5.0\r\n```\r\n\r\n## This is my source code.\r\n\r\n```python\r\nimport tensorflow as tf\r\nwith tf.device('/device:GPU:0'):\r\n        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\n        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\n        c = tf.matmul(a, b)\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n# \u8fd0\u884c\u8fd9\u4e2a op.\r\nprint (sess.run(c))\r\nsess.close()\r\n```\r\n\r\n## That is my error tip\r\n\r\n```\r\n2019-06-03 22:10:41.340072: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations. 2019-06-03 22:10:41.340118: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations. 2019-06-03 22:10:41.340136: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2019-06-03 22:10:41.340151: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2019-06-03 22:10:41.340167: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nDevice mapping: no known devices.\r\n2019-06-03 22:10:41.350495: I tensorflow/core/common_runtime/direct_session.cc:265] Device mapping:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1139, in _do_call\r\n    return fn(*args)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1117, in _run_fn\r\n    self._extend_graph()\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1166, in _extend_graph\r\n    self._session, graph_def.SerializeToString(), status)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/contextlib.py\", line 89, in __exit__\r\n    next(self.gen)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\r\n         [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"cpuOrGpu.py\", line 11, in <module>\r\n    print (sess.run(c))\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 789, in run\r\n    run_metadata_ptr)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 997, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1132, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\r\n         [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\r\n\r\nCaused by op 'MatMul', defined at:\r\n  File \"cpuOrGpu.py\", line 7, in <module>\r\n    c = tf.matmul(a, b)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1816, in matmul\r\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1217, in _mat_mul\r\n    transpose_b=transpose_b, name=name)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\r\n         [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\r\n```\r\n\r\n## This is my NVIDIA graphics card tips\r\n\r\n```bash\r\nMon Jun  3 22:18:34 2019\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1080    Off  | 00000000:02:00.0  On |                  N/A |\r\n|  0%   49C    P8    15W / 260W |      2MiB /  8105MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 1080    Off  | 00000000:03:00.0 Off |                  N/A |\r\n|  0%   45C    P8    17W / 260W |      0MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 1080    Off  | 00000000:81:00.0 Off |                  N/A |\r\n|  0%   45C    P8    12W / 260W |      0MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX 1080    Off  | 00000000:82:00.0 Off |                  N/A |\r\n|  0%   43C    P8    13W / 260W |      0MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n", "comments": ["@youthliuxi I would like to encourage you for using higher versions of Tensorflow since your system navidia driver supports CUDA 9.0. Its only going to get better moving forward and can provide more support. Thanks!", "> @youthliuxi I would like to encourage you for using higher versions of Tensorflow since your system navidia driver supports CUDA 9.0. Its only going to get better moving forward and can provide more support. Thanks!\r\n\r\nSo, it that the reason? I just us the CUDA 8.0, so I can't find my NVIDIA graphics card", "@youthliuxi The below list has the Navidia graphic driver versions and respective Cuda versions. Please Install accordingly.\r\n![Selection_011](https://user-images.githubusercontent.com/48476109/59018314-3ee75a80-8863-11e9-8ac6-7115f9458552.png)\r\nLet us know is that resolve your issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 29361, "title": "CuDNN LSTM fails with XLA on 2080 Ti and CUDA 10.1", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): From Official Tensorflow GPU-powered Docker\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.5.2, 2.7\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: NVIDIA GeForce 2080 Ti and NVIDIA Tesla T4\r\n\r\n**Describe the current behavior**\r\nWhen running with XLA on, the code given below fails with the following exception:\r\n\r\n```\r\n2019-06-03 14:05:14.646045: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2019-06-03 14:05:14.658647: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x4df19b0 executing computations on platform Host. Devices:\r\n2019-06-03 14:05:14.658738: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-06-03 14:05:15.083263: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x4e6c080 executing computations on platform CUDA. Devices:\r\n2019-06-03 14:05:15.083333: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2019-06-03 14:05:15.084392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:\r\nname: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65\r\npciBusID: 0000:06:00.0\r\ntotalMemory: 10.73GiB freeMemory: 10.57GiB\r\n2019-06-03 14:05:15.084478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-06-03 14:05:15.640030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-06-03 14:05:15.640114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0\r\n2019-06-03 14:05:15.640129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N\r\n2019-06-03 14:05:15.641178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10198 MB memory) ->\r\n physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:06:00.0, compute capability: 7.5)\r\n\r\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated\r\nand will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\n2019-06-03 14:05:21.949030: E tensorflow/compiler/xla/status_macros.cc:49] Internal: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc:3171) ShapeUtil::E\r\nqual(first_reduce->shape(), inst->shape())\r\n*** Begin stack trace ***\r\n\r\n\r\n\r\n\r\n        tensorflow::Status xla::HloInstruction::Visit<xla::HloInstruction*>(xla::DfsHloVisitorBase<xla::HloInstruction*>*)\r\n\r\n        tensorflow::Status xla::HloInstruction::Accept<xla::HloInstruction*>(xla::DfsHloVisitorBase<xla::HloInstruction*>*, bool, bool)\r\n        tensorflow::Status xla::HloComputation::Accept<xla::HloInstruction*>(xla::DfsHloVisitorBase<xla::HloInstruction*>*) const\r\n        xla::gpu::NVPTXCompiler::RunBackend(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::DeviceMemoryAllocator*)\r\n        xla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::\r\nStreamExecutor*, xla::DeviceMemoryAllocator*)\r\n\r\n\r\n        tensorflow::XlaCompilationCache::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompiler::CompilationResult const&, std::unique_ptr<xla::LocalExecut\r\nable, std::default_delete<xla::LocalExecutable> >*)\r\n        tensorflow::XlaCompilationCache::CompileImpl(tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, absl::Span<tensorflow::XlaCompiler::Argument const>, s\r\ntd::function<tensorflow::Status (tensorflow::XlaCompiler*, tensorflow::XlaCompiler::CompilationResult*)> const&, absl::optional<long long>, tensorflow::XlaCompiler::CompilationResul\r\nt const**, xla::LocalExecutable**)\r\n        tensorflow::XlaCompilationCache::Compile(tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, absl::Span<tensorflow::XlaCompiler::Argument const>, tenso\r\nrflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompilationCache::CompileMode, tensorflow::XlaCompiler::CompilationResult const**, xla::LocalExecutable**)\r\n\r\n        tensorflow::XlaCompileOp::Compute(tensorflow::OpKernelContext*)\r\n        tensorflow::BaseGPUDevice::ComputeHelper(tensorflow::OpKernel*, tensorflow::OpKernelContext*)\r\n        tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*)\r\n\r\n\r\n        Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int)\r\n\r\n        std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\r\n\r\n\r\n        clone\r\n*** End stack trace ***\r\n\r\n2019-06-03 14:05:21.949546: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at xla_ops.cc:429 : Internal: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/ir\r\n_emitter_unnested.cc:3171) ShapeUtil::Equal(first_reduce->shape(), inst->shape())\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InternalError: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc:3171) ShapeUtil::Equal(first_reduce->shape(), in\r\nst->shape())\r\n         [[{{node cluster_1_1/xla_compile}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test_tf.py\", line 20, in <module>\r\n    session.run(output, feed_dict={input: np.zeros((1, steps, 1), dtype=np.float32)})\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc:3171) ShapeUtil::Equal(first_reduce->shape(), in\r\nst->shape())\r\n         [[{{node cluster_1_1/xla_compile}}]]\r\n```\r\n\r\nReproduces in the following environments:\r\n\u2014 Official Tensorflow Docker: tensorflow/tensorflow:latest-gpu\r\n\u2014 NVIDIA Tensorflow Docker: nvcr.io/nvidia/tensorflow:19.03-py3\r\n\r\nFails with the same error on Keras code (CuDNN LSTM keras implementation) too.\r\n\r\n**Describe the expected behavior**\r\n\r\nGiven code completes successfully.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nconfig = tf.ConfigProto()\r\n# no fail when XLA is disabled\r\nconfig.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\r\nsession = tf.Session(config=config)\r\n\r\nsteps = 2  # no fail when = 1\r\ninput = tf.placeholder(dtype=tf.float32, shape=[None, steps, 1])\r\n\r\nlstm = tf.contrib.cudnn_rnn.CudnnLSTM(num_layers=1, num_units=1, dtype=tf.float32)\r\nlstm.build(input.get_shape())\r\nlstm_output, _ = lstm(input)\r\noutput = tf.concat([lstm_output, input], axis=2)\r\noutput = tf.reduce_sum(output, axis=1, keepdims=False)\r\noutput = tf.nn.l2_normalize(output, axis=1)\r\n\r\nsession.run(tf.global_variables_initializer())\r\nsession.run(output, feed_dict={input: np.zeros((1, steps, 1), dtype=np.float32)})\r\n```\r\n\r\nIf you remove any of the tf ops above, error doesn't reproduce.", "comments": ["I have similar problem, when I doing normal training, it works, but when I use FP 16, it gives me exactly the same error............", "I have tried on Colab with TensorFlow version 1.13.1 and was able to reproduce the issue.", "@thomasjoerg do you have cycles to look at this?", "At first glance, this looks like an invalid reduce multi-output fusion that fails to codegen. The CHECK failure indicates that the shapes do not line up. I skimmed the relevant code, but didn't spot an obvious bugs.\r\nI may have some cycles tomorrow, otherwise early next week, to debug this.", "Sorry I don't know whether my question is relevant to this, but I do have similar error msg.\r\nAll the functionality and model which works at tf 1.10, has issue in tf 1.13, in NCHW format. But NHWC works just fine.\r\nFor details, pls refer https://stackoverflow.com/questions/56437502/mixed-precision-training-report-ret-check-failure-shapeutilequalfirst-reduce\r\n\r\n", "I can reproduce the issue. Thank you for the high-quality bug report!\r\n**The issue is fixed at head** . You are running TF 1.13 (stable). Would it be feasible for you to upgrade to TF 1.14?", "Yes, sure, that'd be great, thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29361\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29361\">No</a>\n", "> I can reproduce the issue. Thank you for the high-quality bug report!\r\n> **The issue is fixed at head** . You are running TF 1.13 (stable). Would it be feasible for you to upgrade to TF 1.14?\r\n\r\n@thomasjoerg Could you provide a file name or commit hash that points to the issue / the fix? I'm experiencing the same issue and as porting tf version may be hard in my use case I'm wondering if it's easier to apply the same patch. Thank you!"]}, {"number": 29360, "title": "TFLite: Pruning & Distillation Features", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.x, latest\r\n- Are you willing to contribute it (Yes/No): y\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nIn https://www.tensorflow.org/lite/performance/model_optimization, it says that\r\n\r\n> \r\n> Model optimization uses multiple techniques:\r\n> * Reduce parameter count with pruning and structured pruning.\r\n> * Reduce representational precision with quantization.\r\n> * Update the original model topology to a more efficient one with reduced parameters or faster execution. For example, tensor decomposition methods and distillation.\r\n> We support quantization, and are working to add support for other techniques.\r\n\r\nTherefore, I wonder roughly *when will the pruning and distillation be supported?* e.g. a month? a year? Thanks very much!\r\n\r\n**Will this change the current api? How?**\r\nno\r\n\r\n**Who will benefit with this feature?**\r\n**everyone** using tflite to deploy models on mobiles!\r\n\r\n**Any Other info.**\r\nn/a", "comments": ["https://www.tensorflow.org/model_optimization/guide/pruning will be of interest to you. We've started to consolidate our documentation there.\r\n\r\nTLDR: pruning is supported to get model storage improvements. We're still working on builtin sparsity support in TFLite for latency improvements, as suggested in the roadmap also.\r\n\r\nDistillation would be much longer term and I cannot give a good estimate now.", "@alanchiao Thanks very much for your reply! So you mean that, for LATENCY improvemnets, pruning does not work? What techniques can further improve latency? Thanks!", "For latency improvements, pruning where it is today doesn't help. It will in the future with additional work on our end.\r\n\r\nhttps://www.tensorflow.org/model_optimization/guide/pruning and https://www.tensorflow.org/lite/performance/best_practices is what's available for now.\r\n\r\nLatency will also naturally improve as we optimize the operations (which is actively happening). \r\n", "@alanchiao Thanks very much! \ud83d\ude04 I wonder how many times can it be faster before it achieves the physical limitation?", "How many times faster before hitting the physical limitation is very much dependent on the model and hardware you're using. All the different techniques include benchmark numbers (including stacking multiple techniques together). I recommend looking at them.\r\n\r\n1. A larger model is more amenable to compression/speedups. \r\n2. Certain models (e.g. LSTMs with gemv) are memory bound and others (e.g. CNNs) are compute bound (bound meaning its the bottleneck). That affects the potential speedups on a certain hardware.\r\n3. Look up details about mobile GPUs (e.g. https://medium.com/tensorflow/tensorflow-lite-now-faster-with-mobile-gpus-developer-preview-e15797e6dee7) and EdgeTPU for potential speedups on accelerators. \r\n4. More recent versions of CPUs provide special hardware instructions with very significant (e.g. 2x) speedups", "Thank you very much for providing so detailed reply!", "> For latency improvements, pruning where it is today doesn't help. It will in the future with additional work on our end.\r\n> \r\n> https://www.tensorflow.org/model_optimization/guide/pruning and https://www.tensorflow.org/lite/performance/best_practices is what's available for now.\r\n> \r\n> Latency will also naturally improve as we optimize the operations (which is actively happening).\r\n\r\nWhen do you think this will be included in tensorflow / TFLite release ? Is there a targeted timeline ? We are planning to do an internal development if this is not expected within this year (2020) based on this.", "@sujoyrc : could you go to this issue and ask the same question? The assignee should communicate where things are.\r\n\r\nhttps://github.com/tensorflow/model-optimization/issues/173\r\n\r\nIf there's not much of a response, feel free to ping me in this thread. "]}]