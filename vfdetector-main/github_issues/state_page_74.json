[{"number": 19193, "title": "Feature request: tf.pad to pad an image with different values correspond to different channels respectively", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source)**: source\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**: 2.7\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: GTX 1080, 8G\r\n\r\n### Describe the problem\r\n\r\n**tf.pad** has a parameter `constant_values` to control the padding values. However, the value need to be a single scalar and it is used to pad all the channels equally.\r\nThen if we want to pad the imagenet mean values [123.68, 116.779, 103.939] to 3 channels of a RGB image tensor respectively, we cannot achieve it by tf.pad.\r\n\r\nSo is it possible to extend tf.pad to be able to pad 3 channels with different values respectively?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nExact command to reproduce", "You can do this with three separate padding operations and a concat.\r\n\r\nI.E. if an example \"yourTensor\" has 4 dimensions (batch,width,height,channels)\r\n\r\n```\r\npaddedR = tf.pad(tensor = yourTensor[:,:,:,0:1], #the R channel of tensor\r\n    paddings=[[0,0],[2,2],[2,2],[0,0]],  #don't pad it in batch or channel dimensions\r\n    mode='Constant',\r\n    name='padAverageRed',\r\n    constant_values=123.68)\r\npaddedG = tf.pad(tensor = yourTensor[:,:,:,1:2], #the G channel of tensor\r\n    paddings=[[0,0],[2,2],[2,2],[0,0]],  #don't pad it in batch or channel dimensions\r\n    mode='Constant',\r\n    name='padAverageGreen',\r\n    constant_values=116.779)\r\npaddedB = tf.pad(tensor = yourTensor[:,:,:,2:3], #the B channel of tensor\r\n    paddings=[[0,0],[2,2],[2,2],[0,0]], #don't pad it in batch or channel dimensions\r\n    mode='Constant',\r\n    name='padAverageBlue',\r\n    constant_values=103.939)\r\nfinalTensor=tf.concat([paddedR, paddedG, paddedB], 3)\r\n```\r\nYou can replace the slices on the final dimension with 0,1,and 2 respectively and use stack instead of concat and you will be able to just use a constant padding of \"2\" across every dimension which neatens the code up a decent bit but it also makes it less understandable.  Either will be sufficient, however.", "@tokotchd Thank you.\r\nI have also [implemented it before](https://github.com/Kongsea/Resize-to-fixed-size-keeping-aspect-ratio/blob/master/image_reader.py#L70).\r\nHowever, I still think it will be better to extend the function tf.pad.", "@tokotchd Nice snippet! However, you missed the commas after ``name='padAverageGreen'`` and ``name='padAverageBlue'``. It would be great if you could update the code with this minor change.", "@Hadjimina updated snippet", "@rryan might this kind of generalization of the pad value be planned, or should I mark \"contributions welcome\"? ", "@cy89 I'm not working on it, but support for non scalar padding values\nwould be great. Contributions welcome makes sense to me!\n\nOn Sun, Aug 19, 2018, 11:52 AM Alfred Sorten Wolf <notifications@github.com>\nwrote:\n\n> Nagging Assignee @cy89 <https://github.com/cy89>: It has been 29 days\n> with no activity and this issue has an assignee. Please update the label\n> and/or status accordingly.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/19193#issuecomment-414147281>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABnn-1n7HeoyQRoIxT5ntHbZjeP08gkks5uSbPsgaJpZM4T5Wk3>\n> .\n>\n", "Any update for the feature requested?", "padding is a very expensive op, i know you can pad three channels differently, but that also slows down your training significantly @tokotchd "]}, {"number": 19140, "title": "[XLA] input data type support for DT_STRING?", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  CentOS 7.4.1708\r\n- **TensorFlow installed from (source or binary)**:  source\r\n- **TensorFlow version (use command below)**:  1.7.0\r\n- **Python version**:   2.7\r\n- **Bazel version (if compiling from source)**:  0.11.1\r\n- **GCC/Compiler version (if compiling from source)**:  4.8.5\r\n- **CUDA/cuDNN version**:  cuda9 & cuddn6\r\n- **GPU model and memory**:  \r\n- **Exact command to reproduce**:  \r\n\r\n\r\n### Describe the problem\r\nWhat I want to do here is that using XLA to speedup my model inference performance.  so I have a model(think it is just a wide and deep model) trained with Estimator, exported as savedModel format with feature_column, then transform to frozen graph.  Then I followed the [AOT tutorial](https://www.tensorflow.org/performance/xla/tfcompile):\r\n\r\n* prepare my frozen graph.pb\r\n* write a graph_config.pbtxt\r\n* edit BUILD file to add cc_library of my own\r\n* build\r\n\r\nin the meantime, in order to make it work, I have to add 3 more dependency in tf_compile library section of BUILD file(tensorflow/compiler/aot/BUILD). like below:\r\n\r\n```\r\n        \"//tensorflow/core/kernels:example_parsing_ops\",\r\n        \"//tensorflow/core/kernels:lookup_table_op\",\r\n        \"//tensorflow/core/kernels:logging_ops\",\r\n```\r\n\r\nthen, after all dependency error resolved. Following error messages showed up:\r\n\r\n```\r\nINVALID ARGUMENTS: Unsupported type in DataTypeToPrimitiveType string\r\n```\r\n\r\nSo I checked the code here [tensorflow/compiler/tf2xla/type_util.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/type_util.cc) and here [tensorflow/compiler/xla/xla_data.proto](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/xla_data.proto); found that XLA actually does not support DT_STRING now. So I would like to know is it possible to support string? why?\r\n\r\n\r\n### Source code / logs\r\n\r\nmy graph.config.pbtxt is like below:\r\n\r\n```\r\nfeed {\r\n  id { node_name: \"input_example_tensor\" }\r\n  shape {\r\n    dim { size: 1 }\r\n  }\r\n}\r\n\r\nfetch {\r\n  id { node_name: \"head/predictions/probabilities\" }\r\n}\r\n```\r\n\r\nbazel build error message:\r\n\r\n```\r\nERROR: /data/tf/tensorflow-1.7.0/tensorflow/compiler/aot/tests/BUILD:155:1: Executing genrule //tensorflow/compiler/aot/tests:gen_feed_graph failed (Exit 1)\r\n2018-05-08 17:49:19.657209: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\nINVALID ARGUMENTS: Unsupported type in DataTypeToPrimitiveType string\r\n\r\ntfcompile performs ahead-of-time compilation of a TensorFlow graph,\r\nresulting in an object file compiled for your target architecture, and a\r\nheader file that gives access to the functionality in the object file.\r\nA typical invocation looks like this:\r\n\r\n   $ tfcompile --graph=mygraph.pb --config=myfile.pbtxt --cpp_class=\"mynamespace::MyComputation\"\r\n\r\nusage: bazel-out/host/bin/tensorflow/compiler/aot/tfcompile\r\nFlags:\r\n\t--graph=\"\"                       \tstring\tInput GraphDef file.  If the file ends in '.pbtxt' it is expected to be in the human-readable proto text format, otherwise it is expected to be in the proto binary format.\r\n\t--config=\"\"                      \tstring\tInput file containing Config proto.  If the file ends in '.pbtxt' it is expected to be in the human-readable proto text format, otherwise it is expected to be in the proto binary format.\r\n\t--dump_fetch_nodes=false         \tbool\tIf set, only flags related to fetches are processed, and the resulting fetch nodes will be dumped to stdout in a comma-separated list.  Typically used to format arguments for other tools, e.g. freeze_graph.\r\n\t--target_triple=\"x86_64-pc-linux\"\tstring\tTarget platform, similar to the clang -target flag.  The general format is <arch><sub>-<vendor>-<sys>-<abi>.  http://clang.llvm.org/docs/CrossCompilation.html#target-triple.\r\n\t--target_cpu=\"\"                  \tstring\tTarget cpu, similar to the clang -mcpu flag.  http://clang.llvm.org/docs/CrossCompilation.html#cpu-fpu-abi\r\n\t--target_features=\"\"             \tstring\tTarget features, e.g. +avx2, +neon, etc.\r\n\t--entry_point=\"entry\"            \tstring\tName of the generated function.  If multiple generated object files will be linked into the same binary, each will need a unique entry point.\r\n\t--cpp_class=\"\"                   \tstring\tName of the generated C++ class, wrapping the generated function.  The syntax of this flag is [[<optional_namespace>::],...]<class_name>.  This mirrors the C++ syntax for referring to a class, where multiple namespaces may precede the class name, separated by double-colons.  The class will be generated in the given namespace(s), or if no namespaces are given, within the global namespace.\r\n\t--out_function_object=\"out_model.o\"\tstring\tOutput object file containing the generated function for the TensorFlow model.\r\n\t--out_header=\"out.h\"             \tstring\tOutput header file name.\r\n\t--out_metadata_object=\"out_helper.o\"\tstring\tOutput object file name containing optional metadata for the generated function.\r\n\t--out_session_module=\"\"          \tstring\tOutput session module proto.\r\n\t--gen_name_to_index=false        \tbool\tGenerate name-to-index data for Lookup{Arg,Result}Index methods.\r\n\t--gen_program_shape=false        \tbool\tGenerate program shape data for the ProgramShape method.\r\n\t--xla_generate_hlo_graph=\"\"      \tstring\tHLO modules matching this regex will be dumped to a .dot file throughout various stages in compilation.\r\n\t--xla_hlo_graph_addresses=false  \tbool\tWith xla_generate_hlo_graph, show addresses of HLO ops in graph dump.\r\n\t--xla_hlo_graph_path=\"\"          \tstring\tWith xla_generate_hlo_graph, dump the graphs into this path.\r\n\t--xla_hlo_dump_as_graphdef=false \tbool\tDump HLO graphs as TensorFlow GraphDefs.\r\n\t--xla_hlo_graph_sharding_color=false\tbool\tAssign colors based on sharding assignments when generating the HLO graphs.\r\n\t--xla_hlo_tfgraph_device_scopes=false\tbool\tWhen generating TensorFlow HLO graphs, if the HLO instructions are assigned to a specific device, prefix the name scope with \"devX\" with X being the device ordinal.\r\n\t--xla_log_hlo_text=\"\"            \tstring\tHLO modules matching this regex will be dumped to LOG(INFO).\r\n\t--xla_generate_hlo_text_to=\"\"    \tstring\tDump all HLO modules as text into the provided directory path.\r\n\t--xla_enable_fast_math=true      \tbool\tEnable unsafe fast-math optimizations in the compiler; this may produce faster code at the expense of some accuracy.\r\n\t--xla_llvm_enable_alias_scope_metadata=true\tbool\tIn LLVM-based backends, enable the emission of !alias.scope metadata in the generated IR.\r\n\t--xla_llvm_enable_noalias_metadata=true\tbool\tIn LLVM-based backends, enable the emission of !noalias metadata in the generated IR.\r\n\t--xla_llvm_enable_invariant_load_metadata=true\tbool\tIn LLVM-based backends, enable the emission of !invariant.load metadata in the generated IR.\r\n\t--xla_llvm_disable_expensive_passes=false\tbool\tIn LLVM-based backends, disable a custom set of expensive optimization passes.\r\n\t--xla_backend_optimization_level=3\tint32\tNumerical optimization level for the XLA compiler backend.\r\n\t--xla_disable_hlo_passes=\"\"      \tstring\tComma-separated list of hlo passes to be disabled. These names must exactly match the passes' names; no whitespace around commas.\r\n\t--xla_embed_ir_in_executable=false\tbool\tEmbed the compiler IR as a string in the executable.\r\n\t--xla_dump_ir_to=\"\"              \tstring\tDump the compiler IR into this directory as individual files.\r\n\t--xla_eliminate_hlo_implicit_broadcast=true\tbool\tEliminate implicit broadcasts when lowering user computations to HLO instructions; use explicit broadcast instead.\r\n\t--xla_cpu_multi_thread_eigen=true\tbool\tWhen generating calls to Eigen in the CPU backend, use multi-threaded Eigen mode.\r\n\t--xla_gpu_cuda_data_dir=\"./cuda_sdk_lib\"\tstring\tIf non-empty, speficies a local directory containing ptxas and nvvm libdevice files; otherwise we use those from runfile directories.\r\n\t--xla_gpu_ftz=false              \tbool\tIf true, flush-to-zero semantics are enabled in the code generated for GPUs.\r\n\t--xla_gpu_disable_multi_streaming=false\tbool\tIf true, multi-streaming in the GPU backend is disabled.\r\n\t--xla_dump_optimized_hlo_proto_to=\"\"\tstring\tDump Hlo after all hlo passes are executed as proto binary into this directory.\r\n\t--xla_dump_unoptimized_hlo_proto_to=\"\"\tstring\tDump HLO before any hlo passes are executed as proto binary into this directory.\r\n\t--xla_dump_per_pass_hlo_proto_to=\"\"\tstring\tDump HLO after each pass as an HloProto in binary file format into this directory.\r\n\t--xla_test_all_output_layouts=false\tbool\tLet ClientLibraryTestBase::ComputeAndCompare* test all permutations of output layouts. For example, with a 3D shape, all permutations of the set {0, 1, 2} are tried.\r\n\t--xla_test_all_input_layouts=false\tbool\tLet ClientLibraryTestBase::ComputeAndCompare* test all permutations of *input* layouts. For example, for 2 input arguments with 2D shape and 4D shape, the computation will run 2! * 4! times for every possible layouts\r\n\t--xla_hlo_profile=false          \tbool\tInstrument the computation to collect per-HLO cycle counts\r\n\t--xla_dump_computations_to=\"\"    \tstring\tDump computations that XLA executes into the provided directory path\r\n\t--xla_dump_executions_to=\"\"      \tstring\tDump parameters and results of computations that XLA executes into the provided directory path\r\n\t--xla_backend_extra_options=\"\"   \tstring\tExtra options to pass to a backend; comma-separated list of 'key=val' strings (=val may be omitted); no whitespace around commas.\r\n\t--xla_reduce_precision=\"\"        \tstring\tDirections for adding reduce-precision operations. Format is 'LOCATION=E,M:OPS;NAMES' where LOCATION is the class of locations in which to insert the operations (e.g., 'OP_OUTPUTS'), E and M are the exponent and matissa bit counts respectively, and OPS and NAMES are comma-separated (no spaces) lists of the operation types and names to which to attach the reduce-precision operations.  The NAMES string and its preceding ';' may be omitted.  This option may be repeated to define multiple sets of added reduce-precision operations.\r\n\t--xla_gpu_use_cudnn_batchnorm=false\tbool\tAllows the GPU backend to implement batchnorm HLOs using cudnn, rather than expanding them to a soup of HLOs.\r\nTarget //tensorflow/compiler/aot/tests:feed_binary failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 12.475s, Critical Path: 3.04s\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": []}, {"number": 19128, "title": "build with python3 binary uses wrong path to find Python.h (fix inside)", "body": "I spent few days fighting issue with building tensorflow where it was unable to find Python.h, and seen number of similar issues.\r\nPython.h was installed as a part of python3-devel, but build system wasnt unable to find it.\r\nFinally i figured out that in tensorflow/third_party/py/python_configure.bzl function _get_python_bin was looking for binary by name python, even once i did configure i told it to use /usr/bin/python3\r\n\r\nso i did a workaround by changing python_bin_path=repository_ctx.which(\"python\") to look for python3 instead.\r\n\r\nbut i guess configure should do that for me.\r\n\r\ni had unsupported fedora28 but its not the only distro having both python and python3 binaries", "comments": ["@akorzh I tried building with python3 on Ubuntu 16.04 and the build finished correctly. I have to link `/usr/bin/python3` to `/usr/bin/python` but other than that the build works fine. Could you list the detailed steps and environment (as was suggested in the pull request template) so that the issue could be reproduced?", "problem is that python is a python 2.7 binary i dont want to use. python3 is a python 3.6 binary i want to use so when doing configure i answer /usr/bin/python3 is the one i want to use, but aforementioned .bzl function is still using python binary no matter what which leads to build fail", "@akorzh Like I mentioned my Ubuntu 16.04 does not comes with python 2.7 binary. I only installed python 3.5. Can you list the steps as I suggested?", "steps are easy : start with default fedora 27 or 28 installation where python is python2 binary and python3 is a python 3.6 binary. This issue is non-relevant to Ubuntu i guess then", "Since Fedora is unsupported I will leave this as community support.", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you."]}, {"number": 19108, "title": "Set the weights in tf.layers with other variables but not as initializers.", "body": "### System information\r\n- **Have I written custom code**: N/A (There is no example of meta learning with tf.layers)\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: Installed tf-nightly with pip \r\n- **TensorFlow version**: v1.8.0-rc1-934-g291d85be42 1.9.0-dev20180426\r\n- **Python version**: 3.5.2 \r\n- **Bazel version**: N/A\r\n- **GCC/Compiler version**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nNowadays, with advances in deep learning, the researchers sometimes need to set the weights of their model based on some formula (not initialize them but initialize something which calculates that formula) and then use that to backpropagate through the variables which computed that formula. For example in meta learning, I have a model, let's say it is just one layer tf.layers.dense(). I want to compute gradients and then use that gradients to build updated model graph and compute gradients on that. The backpropagation should tell me how should I update my first model weights to adapt well. Look at the code below:\r\n\r\n### Source code / logs\r\n\r\n    train = tf.placeholder(dtype=tf.float32, shape=(None, 4), name='train')\r\n    train_out = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='train_out')\r\n\r\n    validation = tf.placeholder(dtype=tf.float32, shape=(None, 4))\r\n    validation_out = tf.placeholder(dtype=tf.float32, shape=(None, 1))\r\n\r\n    with tf.variable_scope('model'):\r\n        model_out = tf.layers.dense(train, 1, activation=tf.nn.relu)\r\n\r\n    with tf.variable_scope('loss'):\r\n        loss = tf.square(model_out - train_out)\r\n\r\n    with tf.variable_scope('gradients'):\r\n        optimizer = tf.train.AdamOptimizer()\r\n        grads = optimizer.compute_gradients(loss)\r\n\r\n    with tf.variable_scope('updated_model'):\r\n        updated_vars = {\r\n            grad_info[1].name[6:]: grad_info[1] - 0.1 * grad_info[0] \\\r\n            for grad_info in grads if grad_info[0] is not None\r\n            }\r\n\r\n        # meta_out = tf.nn.relu(tf.matmul(validation, updated_vars['dense/kernel:0']) + updated_vars['dense/bias:0'])\r\n        meta_out = tf.layers.dense(validation, 1, activation=tf.nn.relu, \r\n    kernel_initializer=updated_vars['dense/kernel:0'], bias_initializer=updated_vars['dense/bias:0'])\r\n\r\n\r\n    with tf.variable_scope('meta_loss'):\r\n        meta_loss = tf.square(meta_out - validation_out)\r\n\r\n    with tf.variable_scope('meta_optimizer'):\r\n        model_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='model')\r\n        meta_optimizer = tf.train.AdamOptimizer()\r\n        meta_train_op = meta_optimizer.minimize(meta_loss, var_list=model_vars)\r\n\r\n\r\nIn this code, I have commented one line. In that line, I did not use tf.layers but instead implemented what should happen in that layer myself. I think we need to be able to do that with tf.layers as well. \r\nPlease notice that we cannot use initializer because initializers should be set when we run tf.global_variables_initializer() and have another meaning(Which is to set the value of a variable). Here we do not want to initial those weights of layers with values but just with variables which we calculated in some other way and be able to backpropagate through them.\r\n\r\nI think one way to solve this is to allow creating tf.layers' models with setting kernel and bias directly instead of using initializers. I would be more than happy if I could help with this issue.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Sorry about that. I think I missed the form. I have completed the required information now.", "@fchollet , thoughts on returning more information from layers as requested here?", "So you want the ability to set layer's weights as custom tensors?\r\n\r\nWhen we talk about \"layer's weights\", there are two components:\r\n\r\n- Layer attributes such as `self.kernel`, `self.bias`.\r\n- List of weights that are used in backpropagation (`self.trainable_weights`) or used for saving (`self.weights`).\r\n\r\nIt seems you want to:\r\n\r\n1) Explicitly create your own weight variables\r\n2) Transform them through a formula\r\n3) Use the output of that as the `self.kernel` (for instance) attribute on your layer\r\n4) Still be able to update the original variables that you created, via backprop when training your model\r\n\r\nIs that right?\r\n\r\nIt sounds like you should subclass the layer you're looking at (e.g. `Dense`) and write your own `build` methods (the method that creates the weights).\r\n\r\n\r\n\r\n", "Yes. That is exactly what I wanted. Maybe that is a better workaround to subclass them. I also did almost the same thing to solve my problem. However, it seems kind of intuitive to me that I should be able to create those layers with whatever variable I want as weights and bias. As a result, I do not need to go to lower-level API whenever I want to do something like this and can use these higher-level APIs easily. What are your thoughts about this? @fchollet ", "Hi, \r\n\r\nI have built a wrapper around tf.layers.Conv2D. I want to define the layer weights explicitly in the graph as a tensor and then add it to the layer. I want to use the weights multiple times during the training phase. \r\n\r\nSomething like: \r\n\r\n`layer_weights = tf.get_variable(name,shape)`\r\n`x = my_custom_layer(x, weights, args..)`\r\n\r\nI want to know what should I write in the build function of the custom layer to set the layer weights to a pre-defined tensor. Please Help. \r\n\r\nI'm following this to create the custom layer: https://keras.io/layers/writing-your-own-keras-layers/\r\n ", "The same problem when implement LambdaOpt\uff0cto set layer's weights as custom tensors."]}, {"number": 19056, "title": "Android tensorflow repository weird permissions", "body": "when using `implementation 'org.tensorflow:tensorflow-android:+'` in gradle file of my android project\r\n\r\nit adds those permissions to apk\r\n\r\n```\r\nuses-permission: name='android.permission.WRITE_EXTERNAL_STORAGE'\r\nuses-permission: name='android.permission.READ_PHONE_STATE'\r\nuses-permission: name='android.permission.READ_EXTERNAL_STORAGE'\r\n```\r\n\r\nonce I remove  `implementation 'org.tensorflow:tensorflow-android:+'`  permissions are gone\r\n\r\nwhat is that?", "comments": ["I downloaded http://central.maven.org/maven2/org/tensorflow/tensorflow-android/1.8.0/tensorflow-android-1.8.0.aar\r\n\r\nunpacked `tensorflow-android-1.8.0.aar`\r\n\r\nrenamed unpacked `classes.jar` to `tensorflow-android-1.8.0.jar` and moved it to `app\\libs`\r\nrenamed unpacked `jni` folder to jniLibs and moved it to `app\\src\\main`\r\n\r\nremoved `implementation 'org.tensorflow:tensorflow-android:+'` from gradle file\r\n\r\nadded `implementation files('libs/tensorflow-android-1.8.0.jar')` to gradle file\r\n\r\nnow this problem is gone\r\n\r\nthis is so weird:)"]}, {"number": 19049, "title": "Memory Leak when tf.Session run on the sliced tensor", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.5.0-0-g37aa430d84 1.5.0\r\n- **Python version**: 3.6\r\n- **CUDA/cuDNN version**: release 9.0, V9.0.176\r\n- **GPU model and memory**: 1070 8G\r\n\r\n### Describe the Feature Request\r\nFor current version of Tensorflow, it will leak memory if we evaluate the sliced tensor as attached code and images, which isn't intuitive and hard to debug. It seems like the unused part of tensor will leak memory because there is no python object reference on it. I am not sure whether it could fixed or not, maybe it could show warning at least.\r\n\r\n### Source code / logs\r\n\r\n`import tensorflow as tf`\r\n`from pympler.tracker import SummaryTracker`\r\n`tracker = SummaryTracker()`\r\n`a = tf.zeros([3,4,5])`\r\n`sess = tf.Session()`\r\n\r\n`def leak_version():`\r\n`____return sess.run(a[0,0])`\r\n\r\n`def safe_version():`\r\n`____return sess.run(a)[0,0]` \r\n\r\n`for i in range(10):`\r\n`____tracker.print_diff()`\r\n`____# b = safe_version()`\r\n`____b = leak_version()`\r\n\r\n#### Trace of the Leak\r\n![image](https://user-images.githubusercontent.com/5878561/39568787-ed1af628-4ef5-11e8-80a0-b1e532b8c81c.png)\r\n\r\n#### Leak Version : visualize the object reference graph on object 'b' with depth=5 by Library objgraph\r\n![image](https://user-images.githubusercontent.com/5878561/39569067-adc03b18-4ef6-11e8-8d68-b5dee8a89eb0.png)\r\n\r\n#### Safe Version : visualize the object reference graph on object 'b' with depth=5 by Library objgraph\r\n![image](https://user-images.githubusercontent.com/5878561/39568928-57ccc000-4ef6-11e8-871d-7507a6dfefb4.png)\r\n\r\n", "comments": ["Tested with https://pypi.org/project/memory_profiler/\r\nIt shows that the total memory usage increases after each leak_version() function call\r\nNot sure if python will free those memory after a period of time\r\n![test](https://user-images.githubusercontent.com/5556203/39577008-ae8cb960-4f12-11e8-9e23-38c3a082a117.png)\r\n", "@rmlarsen There may be a memory leak in `tf.strided_slice`.", "@rmlarsen \r\n\r\nI'm having the same issue in `tf 2.0.0beta1`. Here is the exact code causing it:\r\n\r\n```python\r\ndef map_to_xy_dataset(csv_dataset, params):\r\n    window_size = params[WINDOW_SIZE_KEY]\r\n    window_shift = params[WINDOW_SHIFT_KEY]\r\n    n_workers = tf.data.experimental.AUTOTUNE\r\n\r\n    # MEMORY LEAK IN THIS FUNCTION\r\n    def split_xy(window):\r\n        # For X, select all but the last value and flatten\r\n        range_x = tf.shape(window)[1] - 1\r\n        \r\n        # CAUSES MEMORY LEAK \r\n        x = tf.reshape(window[:, 0:range_x], [-1])\r\n\r\n\r\n        # Select a single Y value\r\n        # CAUSES MEMORY LEAK\r\n        y = window[0, -1]\r\n\r\n        return x, y\r\n\r\n    # Turn the csv dataset row x col tensor\r\n    row_dataset = csv_dataset.map(lambda *x: tf.reshape(x, [len(x)]))\r\n\r\n    windowed_dataset = row_dataset.window(\r\n        size=window_size, shift=window_shift,\r\n        drop_remainder=True).flat_map(lambda x: x.batch(window_size))\r\n\r\n    xy_dataset = windowed_dataset.map(split_xy, num_parallel_calls=n_workers)\r\n\r\n    return xy_dataset\r\n```", "The leaky version adds a new element to the symbolic graph each time you call it. You should be fine if you create it outside the loop.\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom pympler.tracker import SummaryTracker\r\ntracker = SummaryTracker()\r\na = tf.zeros([3,4,5])\r\na00 = a[0, 0]\r\nsess = tf.Session()\r\n\r\ndef leak_version():\r\n    return sess.run(a00)\r\n\r\ndef safe_version():\r\n    return sess.run(a)[0,0]\r\n\r\nfor i in range(10):\r\n    tracker.print_diff()\r\n    # b = safe_version()\r\n    b = leak_version()\r\n```\r\n\r\nI don't believe this is related to the dataset caching issue (the problem that led me here :S)"]}, {"number": 18934, "title": "Patch Request: Move CROSSTOOL_nvcc.tpl to c++14", "body": "CUDA9.0 is already supporting C++14 now:\r\nhttps://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cpp14\r\n\r\n```\r\ndiff --git a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\nindex 05290d6..237d001 100644\r\n--- a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\n+++ b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\n@@ -51,9 +51,9 @@ toolchain {\r\n   # path, combined with the rest of our Bazel configuration causes our\r\n   # compilation to use those files.\r\n   tool_path { name: \"gcc\" path: \"clang/bin/crosstool_wrapper_driver_is_not_gcc\" }\r\n-  # Use \"-std=c++11\" for nvcc. For consistency, force both the host compiler\r\n-  # and the device compiler to use \"-std=c++11\".\r\n-  cxx_flag: \"-std=c++11\"\r\n+  # Use \"-std=c++14\" for nvcc. For consistency, force both the host compiler\r\n+  # and the device compiler to use \"-std=c++14\".\r\n+  cxx_flag: \"-std=c++14\"\r\n   linker_flag: \"-Wl,-no-as-needed\"\r\n   linker_flag: \"-lstdc++\"\r\n   linker_flag: \"-B/usr/bin/\"\r\ndiff --git a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\r\nindex 2558f46..5b1e65c 100755\r\n--- a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\r\n+++ b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\r\n@@ -167,7 +167,7 @@ def InvokeNvcc(argv, log=False):\r\n   undefines = ''.join([' -U' + define for define in undefines])\r\n   std_options = GetOptionValue(argv, 'std')\r\n   # currently only c++11 is supported by Cuda 7.0 std argument\r\n-  nvcc_allowed_std_options = [\"c++11\"]\r\n+  nvcc_allowed_std_options = [\"c++11\",\"c++14\"]\r\n   std_options = ''.join([' -std=' + define\r\n       for define in std_options if define in nvcc_allowed_std_options])\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Custom code: Yes.\r\nOS: Ubuntu 16.04 LTS\r\nTensorflow installed: from source\r\nBazel: 0.11.1\r\nCUDA Version 9.0\r\ncuDNN Version 7.0\r\nGPU 1080Ti\r\nbazel build tensorflow/tools/pip_package:build_pip_package"]}, {"number": 18893, "title": "Use ghost batch normalization with slim", "body": "Posted in Stack Overflow:\r\nhttps://stackoverflow.com/questions/49967489/use-ghost-batch-normalization-with-slim\r\n\r\n### Details\r\n\r\nOS Platform and Distribution: N/A\r\nTensorFlow installed from: N/A\r\nTensorFlow version: 1.8\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: use slim.batch_norm\r\n\r\n### Describe the problem\r\n\r\nnormalization_layers.BatchNormalization takes an argument virtual_batch_size that tells the layer to use \"Ghost Batch Normalization\", which creates virtual sub-batches which are each normalized separately.\r\n\r\nslim.batch_norm doesn't expose this argument. is there a way to use ghost BN with slim?\r\n\r\nThanks.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Added 'Details' section. thanks.", "Nagging Assignee @poxvoculi: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "I think it's actually a feature request :)\r\n\r\nThe request is to add a virtual_batch_size parameter to slim.batch_norm.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Should fused_batch_norm() also contain this feature? \r\n ", "Hey, is this feature request still pending ? I would like to tackle it if you guys think it is suitable as a first contribution to tensorflow.", "> Should fused_batch_norm() also contain this feature?\r\n\r\nHave the same question:)"]}, {"number": 18872, "title": "Feature Request: More Granular Dependencies for Official Binaries", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: `pip`\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**:  N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n(Note: This issue is related to #16046, but I feel that it's different enough to warrant a separate request, rather than resurrecting that one. Also, this question's wording is biased towards Linux, but the spirit of it may be useful for other systems as well.)\r\n\r\nTensorFlow currently specifies its system requirements at the level of an operating system and CPU architecture (for example, the docs [currently state][ubuntu] that Ubuntu 16.04 x86_64 is the supported Linux variant). This is certainly helpful, but, when incorporating TensorFlow into larger projects with their own lists of dependencies, I feel that it may be useful to additionally have somewhere that provides a clear description of the dynamic library requirements for the official releases. For example, `glibc` version requirements have burned a number of developers (a quick search shows #14208 and #15376). Currently, the only reliable way (to my knowledge) to determine the required versions of `glibc` and friends for a given TensorFlow release is to run `ldd -v` on it (the following are run on TensorFlow 1.5.0, which is what I happen to have installed on this machine):\r\n\r\n```bash\r\n(venv) belph@alpha ~/venv $ ldd -v \\\r\n    lib/python3.5/site-packages/tensorflow/libtensorflow_framework.so \\\r\n    | grep -oP '\\([A-Z][A-Z0-9._]+\\)' \\\r\n    | sort -V \\\r\n    | uniq\r\n(CXXABI_1.3)\r\n(CXXABI_1.3.5)\r\n(CXXABI_1.3.7)\r\n(GCC_3.0)\r\n(GCC_3.3)\r\n(GCC_4.2.0)\r\n(GLIBCXX_3.4)\r\n(GLIBCXX_3.4.9)\r\n(GLIBCXX_3.4.11)\r\n(GLIBCXX_3.4.14)\r\n(GLIBCXX_3.4.17)\r\n(GLIBCXX_3.4.18)\r\n(GLIBCXX_3.4.19)\r\n(GLIBC_2.2.5)\r\n(GLIBC_2.3)\r\n(GLIBC_2.3.2)\r\n(GLIBC_2.3.4)\r\n(GLIBC_2.4)\r\n(GLIBC_2.6)\r\n(GLIBC_2.7)\r\n(GLIBC_2.11)\r\n(GLIBC_2.14)\r\n(GLIBC_2.16)\r\n(GLIBC_2.17)\r\n(GLIBC_2.18)\r\n(GLIBC_PRIVATE)\r\n```\r\n(here's a fancier command to get the latest version required, in case anyone is interested)\r\n```bash\r\n(venv) belph@alpha ~/venv $ ldd -v \\\r\n    lib/python3.5/site-packages/tensorflow/libtensorflow_framework.so \\\r\n    | grep -oP '[A-Z][A-Z0-9.]*_[0-9.]+(?=\\) =>)' \\\r\n    | sort -V \\\r\n    | uniq \\\r\n    | tr '_' ' ' \\\r\n    | awk '{ reqs[$1] = $2 } END { for (lib in reqs) { print lib,reqs[lib] } }'\r\nGLIBCXX 3.4.19\r\nCXXABI 1.3.7\r\nGLIBC 2.18\r\nGCC 4.2.0\r\n```\r\n\r\nI _have_ noticed the [Tested Source Configurations][srcconfigs] list on the documentation; these very well may be the machines which compile the binaries, but they do not specify which version of `glibc` is installed. Additionally, `glibc` version 2.19 is [specified in a toolchain][toolchain], but it is unclear whether this is actually used when compiling the official distributions (or I just missed it).\r\n\r\nWould it be possible to specify what versions of shared libraries are required to be installed, or, at a minimum, some more detailed information about the system each binary is compiled on? The latter may be specified somewhere already, but I have not been able to find it. I'm not necessarily asking for a library requirement list that TensorFlow commits to maintain compatibility with across releases; instead, I just think it would be useful to be able to have a go-to place to answer the question of \"what version of `glibc` do I need to run the official TensorFlow 1.5 build?\" Anything would be helpful!\r\n\r\nThank you! Apologies if anything I've said is unclear; I'll be happy to clarify.\r\n\r\n### Source code / logs\r\nN/A\r\n\r\n[ubuntu]: https://www.tensorflow.org/install/install_linux#top_of_page\r\n[srcconfigs]: https://www.tensorflow.org/install/install_sources#tested_source_configurations\r\n[toolchain]: https://github.com/tensorflow/tensorflow/blob/d33f80f4083ef63b90b5763988541e901e7f0a3d/third_party/toolchains/clang6/CROSSTOOL.tpl#L13", "comments": ["@gunan, this seems up your alley. Could you provide some discussion?", "This is definitely in my roadmap, but I am moving rather slowly.\r\nThis will definitely happen, but I am not 100% sure when.\r\nMore recently, @andrehentz and @angersson looked into this, they may have some more comments.", "Oh, sorry I got confused by the dependency keyword. I thought we were talking about bazel dependencies.\r\nIn terms of system dependencies, we are currently looking into this.\r\nWe currently build everything (on linux) on ubuntu 14, with all standard out of the box components, except for python.\r\nAs ubuntu is falling out of support soon, we are looking into how to maintain our test infra, and how to install correct glibc, libstdc++ versions to support the most number of distros possible.", "@angersson @perfinion to provide latest on this"]}, {"number": 18839, "title": "output 'tensorflow/core/kernels/_objs/gather_functor_gpu/tensorflow/core/kernels/gather_functor_gpu.cu.o' was not created", "body": "When trying to build latest TensorFlow for CUDA 8.0/CuDNN 6.0\r\nThis is the error I'm facing when trying to execute the bazel build :<file> command.\r\nfollowing this error is,\r\n\r\n\r\n\r\nnot all outputs were created or valid\r\nTarget //tensorflow/loader:loader failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 237.164s, Critical Path: 30.79s\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n\r\n\r\ntrying to execute the loader.cc code from https://medium.com/jim-fleming/loading-a-tensorflow-graph-with-the-c-api-4caaff88463f\r\nstuck at the second step in Compile & Run Section. (From inside the project folder call bazel build :loader)", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Hit the same error today while trying to build r1.8.\r\n\r\nHave I written custom code: no, just attempted to compile TF cloned from official repository\r\nOS Platform and Distribution: Ubuntu 16.04\r\nTensorFlow installed from: git clone https://github.com/tensorflow/tensorflow\r\nTensorFlow version: r1.8\r\nBazel version: 0.12.0\r\nCUDA/cuDNN version: 8.0/6.0\r\nGPU model and memory: 1080 Ti\r\nExact command to reproduce: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n```\r\nERROR: tensorflow/core/kernels/BUILD:1209:1: output 'tensorflow/core/kernels/_objs/gather_functor_gpu/tensorflow/core/kernels/gather_functor_gpu.cu.o' was not created\r\nERROR: tensorflow/core/kernels/BUILD:1209:1: not all outputs were created or valid\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 153.641s, Critical Path: 36.44s\r\nFAILED: Build did NOT complete successfully\r\n```", "Now this bug appears also in branch r1.7 (which compiled fine two days ago). I have identified the commit that breaks it: 3c245f52912612ed9d8e20245ddb5de055680969 If I checkout the previous commit it compiles fine, if I checkout the head of r1.7 it fails with the same error as reported above for r1.8.", "Same problem.\r\nUbuntu 14.04\r\ngcc 4.9\r\nCUDA 8.0\r\ncuDNN 6.0", "Same problem here as well \r\nUbuntu 16.06 \r\ngcc 5.4.0 \r\nCUDA 8.0 \r\ncuDNN 7", "Same problem here as well\r\nUbuntu 16.04\r\ngcc 5.4.0\r\nCUDA 8.0\r\ncuDNN 7.0", "Same problem.\r\nUbuntu 16.04\r\ngcc 4.9\r\nCUDA 8.0\r\ncuDNN 6.0", " Checking out to a commit before 3c245f5 as Icerman said also worked for me.", "I'm using the google docker image latest-devel-py3 and produces the same issue.\r\nAny idea when this is going to be addressed?.\r\n\r\nthanks\r\n", "is anyone looking at this issue?", "Same problem\r\nmacos 10.13.4\r\nApple LLVM version 8.0.0\r\nCUDA 9.1\r\ncuDNN 7.0.5", "Updating CUDA and cuDNN to the latest versions solved this problem\r\nUbuntu 16.04\r\nCUDA 9.1\r\ncuDNN 7.1\r\ngcc 4.9", "Please, do not close this issue until its fixed. Either the compilation with CUDA 8.0 should be corrected or the official doc here https://www.tensorflow.org/install/install_sources#optional_install_tensorflow_for_gpu_prerequisites should be fixed, now it states CUDA >= 7.0 is required. With current state lot of people waste their time trying to compile with CUDA 8.0 and looking for solution...", "I agree with Icerman. As long as CUDA 8.0 is officially supported, tensorflow should at least be able to compile with it. ", "Same problem\r\nTensorFlow version: v1.8.0\r\nmacOS 10.13.5\r\nApple LLVM version 9.0.0\r\nCUDA 9.2\r\ncuDNN 7.1.4", "I got it working\r\nTensorFlow version: v1.8.0\r\nUbuntu 18.04\r\nCUDA 9.0\r\ncuDNN 7.1 for CUDA 9.0\r\nGCC 4.8\r\n\r\nI solved this problem by downgrading to GCC 4.8. (GCC 6 had worked previously, but not with TF1.8)\r\n`sudo apt-get install gcc-4.8`\r\n`sudo update-alternatives install /usr/bin/gcc gcc /usr/bin/gcc-4.8`", "Having the same issue with\r\nUbuntu 14.04\r\nCUDA 8\r\ncudnn 6\r\ngcc 4.8.4", "\u540c\u6837\u7684\u95ee\u9898\u5728\u8fd9\u91cc\u4ee5\u53ca\r\nUbuntu 16.04 \r\ngcc 5.5.0 \r\nCUDA 9.2 \r\ncuDNN 7.1", "I had the same problem when I compile TensorFlow r1.12.\r\nUbuntu 16.04\r\ngcc 5.5.0\r\nCUDA 9.1\r\ncuDNN 7.1", "Similar problem happened to me: \"tile_functor_gpu.cu.pic.o was not created\"\r\nTensorflow r1.9\r\nUbuntu 16.04\r\ngcc 4.8\r\nCUDA 9.0\r\ncuDNN 7.0", "Ubuntu 18.04\r\ntf 12\r\nCUDA 10.1\r\ncuDNN 7.5\r\ngcc 7.3", "same problem i can build 1.8, 1.10, 1.14, 1.13 but for some reason it wont let me build 1.12 which i desperately need. \r\n\r\nmac 13.6\r\ncuda 9-0\r\ncdnn7.5\r\nbazel 18", "Similar error happend to me too:\r\nTensorflow r1.14\r\nUbuntu 16.04\r\ngcc 6.5\r\nCUDA 9.0\r\ncuDNN 7.1\r\nAny helpful solutions?"]}, {"number": 18813, "title": "Support in the Dataset API for sharding dataset used in stateful LSTMs", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nubuntu 16.04\r\n- TensorFlow installed from (source or binary):\r\nusing docker from google container registry\r\n- TensorFlow version (use command below):\r\n1.7.0\r\n- Python version:\r\n3.5\r\n- Bazel version (if compiling from source):\r\nn/a\r\n- GCC/Compiler version (if compiling from source):\r\nn/a\r\n- CUDA/cuDNN version:\r\nn/a\r\n- GPU model and memory:\r\nn/a\r\n- Exact command to reproduce:\r\nn/a\r\n\r\nHi,\r\n\r\nI was wondering if there will ever be support for sharding a dataset where the order matters? As an example, consider the ptb_word_lm.py script. In the training of the LSTM, batches must be kept in order since the hidden/cell state is never reset (until the end of the epoch). If we use tf.data, we wouldn't be able to use Dataset.shard(...) on the examples themselves because we would get batches like this (assuming 4 workers in a distributed training and batch_size=3):\r\n\r\nworker0_batch0 = [example_0, example_4, example_8]\r\nworker0_batch1 = [example_12, example_16, example_20]\r\n...\r\n\r\nworker1_batch0 = [example_1, example_5, example_9]\r\nworker1_batch1 = [example_13, example_17, example_21]\r\n...\r\n\r\nworker2_batch0 = [example_2, example_6, example_10]\r\nworker2_batch1 = [example_14, example_18, example_22]\r\n...\r\n\r\nworker3_batch0 = [example_3, example_7, example_11]\r\nworker3_batch1 = [example_15, example_19, example_23]\r\n...\r\n\r\n**Assuming the size of the dataset is N, then what we really want is** \r\n\r\nworker0_batch0 = [example_0, example_1, example_2]\r\nworker0_batch1 = [example_3, example_4, example_5]\r\n...\r\n\r\nworker1_batch0 = [example_(N/4)+0, example_(N/4)+1, example_(N/4)+2]\r\nworker1_batch1 = [example_(N/4)+3, example_(N/4)+4, example_(N/4)+5]\r\n...\r\n\r\nworker2_batch0 = [example_2*(N/4)+0, example_2*(N/4)+1, example_2*(N/4)+2]\r\nworker2_batch1 = [example_2*(N/4)+3, example_2*(N/4)+4, example_2*(N/4)+5]\r\n...\r\n\r\nworker3_batch0 = [example_3*(N/4)+0, example_3*(N/4)+1, example_3*(N/4)+2]\r\nworker3_batch1 =[example_3*(N/4)+3, example_3*(N/4)+4, example_3*(N/4)+5]\r\n...\r\n\r\nEven sharding the batches instead of the examples would lead to a similar picture.\r\n\r\nSo I guess if I had a list of TFRecord filenames, I could split the filenames, but I have a concern in the context of synchronous training. Suppose I have 10 tfrecord files (each with 10k examples) and 4 workers. The first two workers would get 3 files and the other two would get 2 files. If my understanding of SyncReplicasOptimizer is correct, I would either have to toss each of the 10k examples on the first two workers, or create a barrier for the second two workers to not proceed until the first two are done. Is there another solution here aside from equally splitting up my training data among files?\r\n\r\nI can think of a couple of workarounds to this problem, but I'd like to know if this problem has been, or will be, solved?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Updated~", "Nagging Assignee @mrry: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "That sounds like it could be useful, although I don't believe anybody is working on it right now. IIUC, it would be equivalent to range-partitioning rather than round-robin partitioning the dataset, right? If you knew the number of elements in each file, you could probably build something workable using `Dataset.skip()` and `Dataset.take()`.\r\n\r\nI'll open this up to contributions in case anybody wants to add an interface for doing this more efficiently.", "Hi, I'm new to Tensorflow, but would love to take on this issue. ", "@dai-dao That would be great!"]}, {"number": 18732, "title": "[Docs]Extend graph_viz doc", "body": "[Extend graph_viz doc](https://www.tensorflow.org/programmers_guide/graph_viz#runtime_statistics) to High Level API.\r\n\r\nSee also https://github.com/tensorflow/tensorflow/issues/13594", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It is a documentation request against master.", "Yes. This is a valid issue. \r\n\r\nWe're having trouble getting it to the top of the priority list.\r\nAny PR to help out would be welcome. ", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you."]}, {"number": 18711, "title": "Suggestion for efficient upsample+conv2d and conv2d+pool", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.7.0-3-g024aecf414 1.7.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: /A\r\n- **CUDA/cuDNN version**: CUDA 9.0/cuDNN 7.0\r\n- **GPU model and memory**: Titan Xp 12GB\r\n- **Exact command to reproduce**: CUDA_VISIBLE_DEVICES=0 python test_conv_upsample_pool_ops.py\r\n\r\n### Describe the problem\r\nTLDR: upsampling+conv2d (which is very expensive) could be implemented such that it has the same time and memory complexity as strided conv2d_transposed. Similarly for conv2d+average_pooling and strided conv2d. An efficient implementation could be S^2 faster, where S is the stride (typically S=2).\r\n\r\nStrided conv2d_transposed have been traditionally used in decoders for dense prediction problems (e.g. image generation, video prediction, semantic segmentation). However, this op often produces outputs with checkerboard artifacts, e.g. see [1] and papers citing it. An alternative is to use bilinear upsampling followed by a standard convolution (with no strides). This is widely used in several recent works and it mitigates the checkerboard artifacts but at a cost: it's computationally and memory expensive (e.g. see [2]). upsampling+conv2d does S^2 more computation than the strided counterpart, where S is the stride factor. Furthermore, the intermediate tensor after upsampling could be very large if the input has a large number of channels.\r\n\r\nUnder certain conditions (which happens to be the most common use case), upsampling+conv2d could be rewritten as convolving the upsampling kernel with the given kernel, followed by conv2d_transposed of the given input and the combined kernels. This follows from commutative and associative properties of linearity in convolutions (taking proper care of flipping the filters so that the ops are actual convolutions).\r\n\r\nA similar reasoning applies for an efficient implementation of conv2d+average_pooling.\r\n\r\nImplementations of the mentioned ops are here (see `upsample_conv2d` and `conv_pool2d`): https://github.com/alexlee-gk/video_prediction/blob/master/video_prediction/ops.py\r\n\r\nA script that tests for equivalence and timings is here: https://gist.github.com/alexlee-gk/1ae88125ec38efc48b542a4c0356078f\r\n\r\nI report some timings below of hundreds of evaluations. The naive op should be about 4x slower than the strided counterpart since S^2 = 4. In theory, the optimized op should be as fast as the strided counterpart, but my implementation is about 2x slower (but still much faster than the naive version), and I think there is room for improvement.\r\n\r\n|                           | upsample + conv2d (optimized) | upsample + conv2d (naive) | strided conv2d_transpose |\r\n|:------------------------- | -----------------------------:| -------------------------:| --------------:|\r\n| forward pass              | 11.0s                         | 16.3s                     | 4.7s           |\r\n| forward and backward pass | 6.5s                          | 17.5s                     | 2.6s           |\r\n\r\n|                           | conv2d + pool (optimized) | conv2d + pool (naive) | strided conv2d |\r\n|:------------------------- | -------------------------:| ---------------------:| --------------:|\r\n| forward pass              | 4.1s                      | 8.2s                  | 2.6s           |\r\n| forward and backward pass | 4.1s                      | 8.4s                  | 2.6s           |\r\n\r\n[1] https://distill.pub/2016/deconv-checkerboard\r\n[2] https://arxiv.org/abs/1707.05847", "comments": ["Hi, in our algorithm, we also use tf.nn.conv2d_transpose with stride 2, we found it always cost too much time, also with checkerboard artifacts, do you have some better suggestion for replace it. as [1] said, we can use tf.image.resize_images() to replace, but I am confused that, is that mean resize before network, and resize to original size when network done?\r\nPlz help to check! thank you!", "Just to be clear, tf.nn.conv2d_transpose with stride 2 is as efficient as it can get and it shouldn't be slow. (If it is, you might have really big tensors, and then the problem is not an implementation one but a choice of your architecture.) The downside of strided conv2d_transpose is the checkerboard artifacts (and not its running time). What [1] suggests is to replace every conv2d_transpose layer with a resize_images layer + conv2d layer. The resize_images layer should upsample by a factor equal to the original stride (i.e. 2) and the conv2d layer should have stride 1. However, naively replacing every conv2d_transpose with resize_images + conv2d would slow things down even more.", "@alexlee-gk , based on your performance test, seems conv2d_transpose is faster than upsample + conv2d, but as I test, in tf 1.6, upsample +conv2d is faster than conv2d_transpose", "> Just to be clear, tf.nn.conv2d_transpose with stride 2 is as efficient as it can get and it shouldn't be slow. (If it is, you might have really big tensors, and then the problem is not an implementation one but a choice of your architecture.) The downside of strided conv2d_transpose is the checkerboard artifacts (and not its running time). What [1] suggests is to replace every conv2d_transpose layer with a resize_images layer + conv2d layer. The resize_images layer should upsample by a factor equal to the original stride (i.e. 2) and the conv2d layer should have stride 1. However, naively replacing every conv2d_transpose with resize_images + conv2d would slow things down even more.\r\n\r\nThank you for much for providing the clear code implementation!  For upsampling, I am wondering whether tf.image.resize_image and tf.tile + tf.reshape produce the same results (gradient) despite different running speed.  Thank you"]}, {"number": 18640, "title": "InvalidArgumentError is raised when restoring large (>2GB) variable on macOS", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.4\r\n- **TensorFlow installed from (source or binary)**: from pip\r\n- **TensorFlow version (use command below)**: 1.7.0, 1.6.0, 1.8.0rc0\r\n- **Python version**: Anaconda, python 3.6\r\n- **Bazel version (if compiling from source)**: no\r\n- **GCC/Compiler version (if compiling from source)**: no\r\n- **CUDA/cuDNN version**: no\r\n- **GPU model and memory**: no\r\n- **Exact command to reproduce**:\r\n```python\r\nimport tensorflow as tf\r\n\r\nv = tf.get_variable(\r\n    name='a',\r\n    shape=(550 * 1000 * 1000,),\r\n    dtype=tf.float32,\r\n    initializer=tf.zeros_initializer(),\r\n)\r\nsaver = tf.train.Saver()\r\nwith tf.Session() as s:\r\n    s.run(tf.global_variables_initializer())\r\n    saver.save(s, 'tmp.tf/a')\r\n    saver.restore(s, 'tmp.tf/a')\r\n```\r\n\r\n### Describe the problem\r\nWhen saving and then restoring variable >2GB on macOS tensorflow throws InvalidArgumentError\r\n\r\n### Source code / logs\r\n```\r\n2018-04-18 12:25:50.620884: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n'tmp.tf/a'\r\nINFO:tensorflow:Restoring parameters from tmp.tf/a\r\n2018-04-18 12:26:00.866457: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Invalid argument: tmp.tf/a.data-00000-of-00001; Invalid argument\r\nTraceback (most recent call last):\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1327, in _do_call\r\n    return fn(*args)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1312, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1420, in _call_tf_sessionrun\r\n    status, run_metadata)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: tmp.tf/a.data-00000-of-00001; Invalid argument\r\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 4, in <module>\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1775, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 905, in run\r\n    run_metadata_ptr)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1140, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    run_metadata)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: tmp.tf/a.data-00000-of-00001; Invalid argument\r\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\r\nCaused by op 'save/RestoreV2', defined at:\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1311, in __init__\r\n    self.build()\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1320, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1357, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 809, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 448, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 860, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1458, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\r\n    op_def=op_def)\r\n  File \"/Users/alyaxey/anaconda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): tmp.tf/a.data-00000-of-00001; Invalid argument\r\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n```", "comments": ["I may have observed something similar: https://github.com/tensorflow/tensorflow/issues/18769", "Reproduced error. It happens exactly when attempting to restore a tensor of >2GB data size.", "I am having a very similar issue as well. Following [this tutorial](https://www.tensorflow.org/tutorials/estimators/cnn), but working with larger images.", "i met same problem , is it a software bug??", "I'm having the same issue when restoring several GBs of embeddings. Has anyone found any sort of workaround? \r\n\r\nI'm currently saving and restoring the embeddings separately which is fine but isn't ideal.", "That works fine, unless you have single embeddings >2GB. Then it's really a serialization nightmare that requires major code changes.", "@rothn thanks for the link to #18769. It seems useful information that the error happens on both Mac and Windows. \r\n\r\nFWIW, @alyaxey 's demonstration script works fine on my Ubuntu desktop. "]}, {"number": 18480, "title": "Remove Python dep on 'enum'", "body": "Python enum is only used by a couple files, and has caused a lot of pain. Maybe we shouldn't use it?\r\n\r\nPython enum is used by a couple files in TensorFlow. It's not portable. It was only quite recently backported to Python 2.7. For example, TensorFlow won't compile on Debian 8 without `sudo apt-get install python-enum34` however `sudo apt-get install python-enum` will break the build.\r\n\r\n- https://github.com/tensorflow/tensorflow/issues/12491\r\n- https://github.com/tensorflow/tensorflow/issues/15136", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "My personal opinion is that we should not be afraid to depend on enum34 for Python 2.7.\r\n\r\n> Python enum is used by a couple files in TensorFlow.\r\n\r\nYes, but it would make sense in a lot more places, e.g., for `tf.estimator.ModeKeys` and `tf.image.ResizeMethod`, among others.\r\n\r\n> It's not portable.\r\n\r\nI'm not quite sure what that means?\r\n\r\n> It was only quite recently backported to Python 2.7.\r\n\r\nIt's been available for Python 2.7 since [at least 2013](https://pypi.org/project/enum34/#history) and is also part of the standard library for Python 3.\r\n\r\nThe biggest dependency complaints here seem to be about the misspecified dependency on older versions of TensorFlow with Python 3, which is now fixed.\r\n\r\nThe biggest thing that seems to go wrong now is users mistakenly installing `enum` instead of `enum34`. Indeed, this is unfortunate, but I think the resolution is clearly including `pip install enum34` in the [installation instructions](https://www.tensorflow.org/install/install_sources) rather than removing it. It's a pure Python package that is widely distributed, so it really should not be a serious burden to depend on it.", "It sounds like a lot of effort went into having enum in Python.\r\n\r\nenum34 is defined in our setup.py file, which is good, but it needs to be defined in our [workspace.bzl](https://github.com/tensorflow/tensorflow/blob/a1945729655191c511dbfea1a38b35bdfc734a09/tensorflow/workspace.bzl#L309) file too, just weakref. Could you or @caisq help do that?", "Sorry, I'm not on the TensorFlow team and don't understand Bazel, so I'm going to pass on this one. Hopefully someone else who knows Bazel will take this up.", "@caisq could you take a look?", "@skye Sure I can take a look at whether it's possible to remove `enum` from TensorFlow. There are quite a few places using it. I'm not yet sure whether Enum type is exposed to the public API yet. If not then it'll be relatively straightforward, otherwise it'll be either infeasible or need to involve deprecation processes.", "According to @jart's comment, I don't think we need to remove it necessarily. She said: \"enum34 is defined in our setup.py file, which is good, but it needs to be defined in our workspace.bzl file too, just weakref.\". I'm not sure what that means, I'm just trying to triage this issue :)", "@skye For example, the last time I built TensorFlow on a Debian8 system, it failed because I needed to `apt-get install python-enum34` (not `python-enum`) and that was nonobvious for me to determine. It would be nice if nonstandard functionality was defined by `workspace.bzl` (along with zlib, libpng, weakref, etc.) so source builds are more likely to work out of the box.", "+1", "+1", "Dear Tensorflow,\r\n\r\nIt's 2019 and `enum34` is still present in Tensorflow:\r\n```\r\n$ docker run -it --rm tensorflow/tensorflow:1.15.0-py3-jupyter bash\r\n...\r\nroot@2d0b0b6ff8ac:/tf# pip uninstall -y enum34\r\nUninstalling enum34-1.1.6:\r\n  Successfully uninstalled enum34-1.1.6\r\n```\r\n\r\nand still causing problems for other packages:\r\n * https://github.com/smartsheet-platform/smartsheet-python-sdk/issues/122\r\n * https://github.com/python-poetry/poetry/issues/1122\r\n * https://github.com/tensorflow/tensorflow/issues/30200 \r\n * https://github.com/spotify/luigi/issues/2734\r\n * https://github.com/pypa/pipenv/issues/3980\r\n\r\nPersonally I have found this dependency breaks `pyspark`, which gives workers a `PYTHONPATH` that (sadly) happens to include `enum34` before system `enum`.  That makes `pyspark` fail immediately in a fairly unintuitive way.\r\n\r\nIt looks like `enum34` itself might just be broken somehow, so Tensorflow should not use it:\r\nhttps://github.com/pypa/pipenv/issues/3980  \r\n\r\nPretty please remove `enum34` from Tensorflow 1.15.x py3, including the docker images.  "]}, {"number": 18383, "title": "Feature Request: Slice replacement operation", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: b'unknown' 1.4.0\r\n- **Python version**: 3.6.3 Anaconda\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nIn the last couple of weeks I have answered up to three questions in Stack Overflow ([this](https://stackoverflow.com/questions/49493444/tensorflow-set-block-within-2d-tensor-to-constant-value/49493702), [this](https://stackoverflow.com/questions/49487647/how-to-assign-a-value-to-a-tf-variable-in-tensorflow-without-using-tf-assign/49534185) and [this](https://stackoverflow.com/questions/49755316/best-way-to-mimic-pytorch-sliced-assignment-with-keras-tensorflow/49756271)) solving essentially the same problem, namely how to replace a slice in one tensor with the contents of (a slice of) another tensor. On the one hand, newer users try to solve it with a slice assignment to a variable, which is easy and intuitive but wrong. On the other hand, even for experience users it can be quite a hassle (my approaches are either to concatenate thing after thing or make comprehensive masks and use `tf.where`, both of them, I suspect, take more resources than the operation should require).\r\n\r\nI think everyone would benefit from a slice replacement operation that returns a tensor with a slice replaced with some values. I do not know about the technical challenges of this (e.g. to keep gradient propagation and so on), but syntactically there is the problem that one cannot use slicing syntax with functions. Like in `tf.slice`, a couple of `begin` and `size` tensors could be passed:\r\n\r\n    tf.replace_slice(my_tensor, [1, 2], [3, 4], new_values)\r\n\r\nBut, similarly to how `tf.Tensor` implements `__getitem__` for easy slicing, it would be neat to have a simplified syntax for this. Maybe (not necessarily) something like:\r\n\r\n    my_tensor = my_tensor.replace[1:4, 2:6].with_values(new_values) \r\n\r\n(I was going to say ` .with(new_values)`, but that's a keyword)\r\n\r\nIt could also be just:\r\n\r\n    my_tensor = my_tensor[1:4, 2:6].replace_with(new_values) \r\n\r\nWhich is more similar to how slice assignment works for variables, but that seems harder to implement consistently (the slicing should return not just a regular tensor, and the slicing operation would be created anyway even if it's not necessary).\r\n\r\n### Source code / logs\r\n\r\nN/A", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Not sure if that message is meant for me, the author of the issue, or, more likely, the asignee, but anyway, in case it helps triggering some workflow, yes, it is still an \"issue\", in the sense that is a feature request that has not been implemented nor rejected.", "Nagging Assignee @drpngx: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "We have the `inplace_ops` which can do update. Could you look into that and see what you think?", "/CC @zffchen78 ", "@drpngx Thank you for your answer. I can see [`InplaceUpdate`](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/inplace-update) in the C++ docs, which even though (I think?) it's not as flexible as the variable slice assignment seems to be indeed what I was referring to. However, I cannot find how to actually use this kind of operation from Python.", "Yes. It's available with a direct import, not via the public API. The question is whether it is what you need. For the strided version, there the [XlaDynamicUpdateSlice](https://www.tensorflow.org/performance/xla/operation_semantics#dynamicupdateslice) IIRC. Can you check that?", "@drpngx Thanks, yes `XlaDynamicUpdateSlice` seems exactly like what I was referring to. I see these ops have been added more recently and they do not yet have a public documented API for regular Python graph building but I guess they will eventually, so if it is a feature that is already being worked on maybe the issue can be closed?", "If you want to have it exposed the way you describe in the preamble, then we're not working on it AFAIK.", "Well yes in principle I was hoping for a general way to access the feature, not necessarily that specific syntax but some public API that is not particular to XLA. Of course you decide whether or not adding this makes sense/is worth the effort.", "Nagging Assignee @drpngx: It has been 16 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This seems useful, `tf.replace_slice` could be shorthand for the dynamic_slice and concat operations necessary.\r\n\r\nI don't think the shorthand syntax you proposed are consistent with other operators we have, so we'd rather hold on those.", "Nagging Assignee @drpngx: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @drpngx: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @drpngx: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This is a feature that I am looking for.  I have tried  DynamicUpdateSlice(original, replacement, start) in my code, but am getting the following error:\r\n\r\nNameError: name 'DynamicSliceUpdate' is not defined\r\n\r\n@drpngx, can you tell me how to \"import\" the command?\r\nThank you!", "I'm not sure I understand what is wrong. Are you thinking of `@tf_export`? Do you more code so that I understand the context?", "I made a Python-level implementation of this, at least for the simple case without strides (analogous to [`tf.slice`](https://www.tensorflow.org/api_docs/python/tf/slice)). Surely it is less efficient (in time and space) than a proper op and kernel, but I think it's quite convenient. It allows me to write something like this:\r\n\r\n```py\r\nimport tensorflow as tf\r\n\r\nwith tf.Graph().as_default():\r\n    x = tf.reshape(tf.range(60), (4, 3, 5))\r\n    x2 = replace_slice_in(x)[:2, ..., -3:].with_value([100, 200, 300])\r\n    with tf.Session() as sess:\r\n        print(sess.run(x2))\r\n```\r\n\r\nWhich prints:\r\n\r\n```\r\n[[[  0   1 100 200 300]\r\n  [  5   6 100 200 300]\r\n  [ 10  11 100 200 300]]\r\n\r\n [[ 15  16 100 200 300]\r\n  [ 20  21 100 200 300]\r\n  [ 25  26 100 200 300]]\r\n\r\n [[ 30  31  32  33  34]\r\n  [ 35  36  37  38  39]\r\n  [ 40  41  42  43  44]]\r\n\r\n [[ 45  46  47  48  49]\r\n  [ 50  51  52  53  54]\r\n  [ 55  56  57  58  59]]]\r\n```\r\n\r\nThe main function is this:\r\n\r\n```py\r\nimport tensorflow as tf\r\n\r\ndef replace_slice(input_, replacement, begin, size=None):\r\n    inp_shape = tf.shape(input_)\r\n    if size is None:\r\n        size = tf.shape(replacement)\r\n    else:\r\n        replacement = tf.broadcast_to(replacement, size)\r\n    padding = tf.stack([begin, inp_shape - (begin + size)], axis=1)\r\n    replacement_pad = tf.pad(replacement, padding)\r\n    mask = tf.pad(tf.ones_like(replacement, dtype=tf.bool), padding)\r\n    return tf.where(mask, replacement_pad, input_)\r\n```\r\n\r\n`size` is optional because in principle it is inferred from `replacement`, but can be specified to broadcast it.\r\n\r\nThe nicety of Python-like indexing is supported with this blob of ugly code, which is very likely a subset of similar logic already existing in TensorFlow. I tested it in a few cases and seems to work in general, although it assumes indices are `tf.int32` and there may be more special cases I'm not seeing.\r\n\r\n```py\r\ndef replace_slice_in(tensor):\r\n    return _SliceReplacer(tensor)\r\n\r\nclass _SliceReplacer:\r\n    def __init__(self, tensor):\r\n        self._tensor = tensor\r\n    def __getitem__(self, slices):\r\n        return _SliceReplacer._Inner(self._tensor, slices)\r\n    def with_value(self, replacement):  # Just for convenience in case you skip the indexing\r\n        return _SliceReplacer._Inner(self._tensor, (...,)).with_value(replacement)\r\n    class _Inner:\r\n        def __init__(self, tensor, slices):\r\n            self._tensor = tensor\r\n            self._slices = slices\r\n        def with_value(self, replacement):\r\n            begin, size = _make_slices_begin_size(self._tensor, self._slices)\r\n            return replace_slice(self._tensor, replacement, begin, size)\r\n\r\n# This computes begin and size values for a set of slices\r\ndef _make_slices_begin_size(input_, slices):\r\n    if not isinstance(slices, (tuple, list)):\r\n        slices = (slices,)\r\n    inp_rank = tf.rank(input_)\r\n    inp_shape = tf.shape(input_)\r\n    # Did we see a ellipsis already?\r\n    before_ellipsis = True\r\n    # Sliced dimensions\r\n    dim_idx = []\r\n    # Slice start points\r\n    begins = []\r\n    # Slice sizes\r\n    sizes = []\r\n    for i, s in enumerate(slices):\r\n        if s is Ellipsis:\r\n            if not before_ellipsis:\r\n                raise ValueError('Cannot use more than one ellipsis in slice spec.')\r\n            before_ellipsis = False\r\n            continue\r\n        if isinstance(s, slice):\r\n            start = s.start\r\n            stop = s.stop\r\n            if s.step is not None:\r\n                raise ValueError('Step value not supported.')\r\n        else:  # Assumed to be a single integer value\r\n            start = s\r\n            stop = s + 1\r\n        # Dimension this slice refers to\r\n        i_dim = i if before_ellipsis else inp_rank - (len(slices) - i)\r\n        dim_size = inp_shape[i_dim]\r\n        # Default slice values\r\n        start = start if start is not None else 0\r\n        stop = stop if stop is not None else dim_size\r\n        # Fix negative indices\r\n        start = tf.cond(tf.convert_to_tensor(start >= 0), lambda: start, lambda: start + dim_size)\r\n        stop = tf.cond(tf.convert_to_tensor(stop >= 0), lambda: stop, lambda: stop + dim_size)\r\n        dim_idx.append([i_dim])\r\n        begins.append(start)\r\n        sizes.append(stop - start)\r\n    # For empty slice specs like [...]\r\n    if not dim_idx:\r\n        return tf.zeros_like(inp_shape), inp_shape\r\n    # Make full begin and size array (including omitted dimensions)\r\n    begin_full = tf.scatter_nd(dim_idx, begins, [inp_rank])\r\n    size_mask = tf.scatter_nd(dim_idx, tf.ones_like(sizes, dtype=tf.bool), [inp_rank])\r\n    size_full = tf.where(size_mask,\r\n                         tf.scatter_nd(dim_idx, sizes, [inp_rank]),\r\n                         inp_shape)\r\n    return begin_full, size_full\r\n```", "Thanks for this great piece of code! One thing I found out on a MacBook installation: It does not accept float64 as input tensors \r\nCryptic error:\r\n`InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'ScatterNd' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n[[Node: ScatterNd_1 = ScatterNd[T=DT_BOOL, Tindices=DT_INT32](ScatterNd_1/indices, ones_like, ScatterNd_1/shape)]]`", "@javidcf May I ask you if the above code worked on CPU-only implementation? I cannot get it to work on CPU-version on Mac.", "@beniroquai Thank you for your comments. That is strange, it seems to work for me with `tf.float64` values, and both in CPU and GPU. I am using TensorFlow v1.12.0 on Windows 10. Unfortunately I don't have access to a Mac system to try there.", "Now TF 2.0 comes up with `tf.tensor_scatter_nd_update` which I think could partly satisfy this feature requirement."]}, {"number": 18360, "title": "Include C and C++ APIs with binary distributions", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Any\r\n- **TensorFlow installed from (source or binary)**: see below\r\n- **TensorFlow version (use command below)**: Any\r\n- **Python version**:  Any\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nWhen you install a precompiled Tensorflow binary with pip or conda, it doesn't include the C and C++ interfaces.  To use it from those languages, you need to compile Tensorflow for source and build a special version of it that includes the needed API (see #2412).  I suggest including them in the standard binaries.  This would have multiple benefits.\r\n\r\nFirst, it would make development in other languages much easier.  You could just `pip install tensorflow` and link against the library it installed.  Having to build a special version of Tensorflow from source adds an unnecessary barrier to getting started.\r\n\r\nSecond, it would eliminate a problem that so far I've been unable to resolve.  I want to create a C++ library that uses Tensorflow.  That library will be usable directly from C++, but I'll also use SWIG to create a Python wrapper for it.  For example, a user should be able to write Python code to build a Graph, then pass it directly to my library.\r\n\r\nThat won't work right now, because there are two separate versions of Tensorflow involved, one that Python is linked against and a different one that my library is linked against.  When the user is building a Graph in Python, they're working with one Tensorflow library.  But when they try to pass it to my library, they're suddenly switching to a completely different copy of Tensorflow, so it doesn't have access to memory allocated by the first copy.  I haven't found any solution to this problem.", "comments": ["@gunan Is this in our plans at all?", "CC @asimshankar ", "Regarding development with other language bindings: Note that we release binary versions of the C and Java APIs with every TensorFlow releases, so they do not have to be built from source. See: https://www.tensorflow.org/install/install_c  and https://www.tensorflow.org/install/install_java\r\nLanguage bindings maintained by others (C#, Rust, Ruby, Julia etc.) typically link against the released C API artifacts and do not have to build from source.\r\n\r\nA note on structure: The way the language bindings are structured is that the core \"framework\" is in `libtensorflow_framework.so` and then language specific shared libraries that depend on it (e.g., `pywrap_tensorflow.so` for Python, `libtensorflow.so` for C, `libtensorflow_jni.so` for Java etc.).\r\n\r\nWe currently do not produce artifacts for the C++ API though. We haven't had the bandwidth to support that yet, though would be great to.\r\n\r\nI don't think it would make sense to include all language bindings with the Python `pip` package, but I do agree that it would be nice to enable your use-case of writing C++ TensorFlow that interoperates with Python. Alas, nobody is actively working on this at the moment. (BTW, just for completeness, I'm sure you've seen how you can [write custom ops in C++](https://www.tensorflow.org/extend/adding_an_op) and link them with your Python program?).\r\n\r\nI'm going to mark this as \"Community Support\" for now, given that enabling this use case of writing libraries in other languages and mixing those with Python isn't something we (the TensorFlow team) will have the bandwidth to get to or support in the near future (with the exception of writing new TensorFlow operations, which does work).\r\n\r\nIf there is a lot of interest in this feature, we could reprioritize.\r\n\r\n", "What would be involved in supporting interoperability with other languages?  I'm willing to look into it if it's not too difficult, though my knowledge of Tensorflow internals is pretty limited.\r\n\r\nI do think there's value in bundling the other APIs with the pip package, since it makes the installation really simple, and then it's guaranteed that every user will have them.  For example, this is how Caffe2 handles it: just `conda install caffe2`, and you have everything needed for development in both Python and C++.  They even include a CMake configuration script with it, so you don't even need to worry about where libraries and headers have gotten installed.  Just add the line `find_package(Caffe2)` to your build script, and everything magically works.  It would be great if Tensorflow could make its other interfaces similarly easy to use.", "(Probably worth linking this with #15290)\r\n\r\n@peastman : If you're interested, it's probably worth discussing this on the \"build\" group at https://www.tensorflow.org/community/lists#special_interest_groups \r\nSince there you will find a community of folks interested in figuring out the appropriate packaging story.\r\n\r\nThanks for your interest!", "Workarounds are currently possible, e.g. [`tensorflow_ros`](https://github.com/tradr-project/tensorflow_ros/) links against the pip binaries for C++.\r\n\r\nThe only limitation is that the current pip binaries are built with the old C++ ABI, while some OS (e.g. Ubuntu 16) build only with the new C++11 ABI. There's a [pip bug report](https://bugs.launchpad.net/ubuntu/+source/python-pip/+bug/1707002) about that. \r\n@asimshankar Is this going to be solved at some point ?", "@Skydes : ABI compatibility concerns is one of the reasons why we haven't committed to a binary distribution of the C++ APIs yet. There is some ideas we're exploring so that custom operations and kernels can be written against a stable C API/ABI, but that is in early stages of exploration so no timeline on that yet.\r\n\r\nIn the mean time, yeah, to link against pre-built `libtensorflow_framework.so`, you'd have to continue to build against the ABI used by it.\r\n", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "I don't think the pip package should ship the C or C++ libraries. There are better ways to get those if you want them, most likely your distros real package manager. \r\n\r\nOn Gentoo if you `emerge tensorflow` you get the headers, C, C++ libraries in the normal places (ie /usr/include/ and /usr/lib64 etc) as well as all the python stuff. I also ship the pkg-config file so finding the libraries from other packages should be simple for any build system.\r\n\r\nCurrently packaging TF for distros is fairly involved tho. You can refer to the Gentoo sci-libs/tensorflow package for inspiration, its roughly just a shell script with a bunch of helpers. For the headers to install in /usr/include/tensorflow, I just grab everything right now pretty much. I will upstream some bazel rules to make this easier tho.", "You're assuming Linux.  On Windows and Mac, there is no \"real package manager\".", "Just chiming in to say it would be fantastic to include the C API in the `conda` packages (or in a supplementary package).", "> libtensorflow.so\r\n\r\nStill, there is no binary for ARM64 :(, there are to much pain to build it. "]}, {"number": 18311, "title": "[Feature request] unsquashing unsorted_segment_x", "body": "Have I written custom code? No\r\nOS Platform and Distribution? Win10\r\nTensorFlow installed from? pip\r\nTensorFlow version? 1.7\r\nBazel version? N/A\r\nCUDA/cuDNN version? N/A\r\nGPU model and memory? N/A\r\nExact command to reproduce: unsorted_segment_sum\r\n\r\n### Describe the problem\r\nLet's say you have 3 sequences of 12 values (shape (3,12)) with 5 segments and you have an input of shape (None,12,3) transposed to (3,12,None)\r\nusing any function with unsorted_segement_x the output will be (5,None).\r\n\r\nWould it be possible to have a function that does the same but still keep the first dimention.\r\nSomething equivalent to:\r\n```python\r\ninput.shape==(None,12,3)\r\nsegment.shape==(3,12)\r\n\r\noutputs=[]\r\nfor ix, val in enumerate(tf.unstack(input)):\r\n    ouputs.append(tf.unsorted_segment_sum(val,sequence[ix],5)\r\noutput=tf.stack(outputs)\r\noutput.shape==(3,5,None)\r\n```\r\nThe use of such a thing would be to iterate over a weighted input and without having to loop over the data or using reshape. I think this should be somewhat straightforward to implement; not concatenate together all the sequences for the superior dimensions and use \"keep_dims\" similar to reduce_sum to trigger that behaviour.\r\n\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code? No\r\nOS Platform and Distribution? Win10\r\nTensorFlow installed from? pip\r\nTensorFlow version? 1.7\r\nBazel version? N/A\r\nCUDA/cuDNN version? N/A\r\nGPU model and memory? N/A\r\nExact command to reproduce: unsorted_segment_sum\r\n(duplicate info for the bot)", "I want to use the same feature too! It is strange that the segment_ops don't have keep_dims parameter.", "@zhaoxin19 There are some workaround to this, a good idea might be to start a new thread about this since @rmlarsen  seems to be deceased. If you are in a rush and need some workarounds I could help.", "@roya0045 ,thank you very much for you kind help. I am doing deep model research and want to add this kind of operation in my new model. Lucily I've found the unsorted_segment_sum implement. But it is a little different as what I want. I think add a keep_dims parameter is a good idea in this operation. I'm not expert in adding or changing a new operation in tensorflow. I will be very grateful if anyone could help.", "@roya0045 do you know how can we add this feature in tensorflow? Seems that we just need to change tf.unsorted_segment_sum api as tf.reduce_sum adding a keep_dims parameter.", "I'm sure it can be done but I'm not sure how. I'm not familiar with c++ and the code base for tensorflow.\r\n\r\nThe workaround I have found so far are implemented in [ my latest projet](https://github.com/roya0045/Dendritic_layer-TF-Keras-/blob/02cf170356fb0109bbcb565786cb656085be7245/tf_dendritic.py#L237)\r\n\r\nThe only issue is that I have not tested if those 4 methods break backpropagation (get the weights first, train on random data, get the weight after and just subtract the initial weight to see if it worked.)\r\n\r\nI wanted to test them but I haven't had much time to do so, if you want you could just set up a minimal network with a for loop for each version , train it and compare the weights to see if those workarounds are valid, I'd be interested in the results."]}, {"number": 18280, "title": "[feature] js_func (for javascript) equivalent of py_func", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nn/a\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\niOS, Android\r\n- **TensorFlow installed from (source or binary)**:\r\nn/a\r\n- **TensorFlow version (use command below)**:\r\nn/a\r\n- **Python version**: \r\nn/a\r\n- **Bazel version (if compiling from source)**:\r\nn/a\r\n- **GCC/Compiler version (if compiling from source)**:\r\nn/a\r\n- **CUDA/cuDNN version**:\r\nn/a\r\n- **GPU model and memory**:\r\nn/a\r\n- **Exact command to reproduce**:\r\nn/a\r\n\r\n### Describe the problem\r\nI suggest adding a `js_func` that allows defining nodes in javascript. This would be similar to the existing `py_func`. There are many systems (ie iOS and Android) that have JS runtimes but do not have python runtimes.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "/CC @dsmilkov, can you take a look at this proposal?", "Hi @cancan101, the body of the `py_func` will not be serialized in a `GraphDef`. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.\r\n\r\nAlso, if you are using TensorFlow.js for development and thinking about this in a JS-only context, would you mind re-posting this issue to the [tensorflow/tfjs issues](https://github.com/tensorflow/tfjs/issues)?\r\n\r\nThanks!", "Interesting to know that the body is not serialized; I had not realized that. I was not thinking of js_func in the context of tfjs. Rather I was thinking of loading a graph on iOS or Android and using the js_func to supply user created functions.", "/CC @andrewharp can you take a look since this is desired in mobile?"]}, {"number": 18254, "title": "can tensorflow/compiler/aot/libruntime.so be renamed?", "body": "### Describe the problem\r\nlinking -lruntime is a bit too generic (and prone to conflicts) for a large project\r\n\r\nfor instance -lxla_compiled_cpu_function\r\nfor\r\n/tensorflow/compiler/tf2xla/libxla_compiled_cpu_function.so\r\nis already more acceptable\r\n\r\nIn general would be useful for any library required to be linked in user applications to have a more descriptive name that associate it to tensorflow", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "* Have I written custom code\r\nyes\r\n* OS Platform and Distribution\r\nx86_64 linux cc7\r\n* TensorFlow installed from\r\ngit clone\r\n* TensorFlow version\r\ngit master ~1.7\r\n* Bazel version\r\nnot relevant?\r\n* CUDA/cuDNN version\r\nnot relevant\r\n* GPU model and memory\r\nnot relevant\r\n* Exact command to reproduce\r\nI use\r\nbazel build //tensorflow/compiler/aot/tests:all_tests\r\nto build what needed by AOT\r\n"]}, {"number": 18219, "title": "Feature Request:  OutputProjectionWrapper compatible with tf.nn.bidirectional_dynamic_rnn", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Tensorflow 1.4 Docker under CentOS 7.3\r\n- **TensorFlow installed from (source or binary)**:  Tensorflow 1.4 Docker\r\n- **TensorFlow version (use command below)**:  1.4\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: Quadro M4000\r\n- **Exact command to reproduce**: N/A (feature request, not bug report)\r\n\r\n### Describe the problem\r\nFeature request:  OutputProjectionWrappers for use with tf.nn.bidirectional_dynamic_rnn.  I don't think this is a bug report, per se, because I don't think the wrapper was designed for Bidirectional RNNs. \r\n\r\ntf.nn.bidirectional_dynamic_rnn wants a forward and backward RNN cell, and provides a tuple of tuples:  forward and backward outputs, forward and backward output_states.  \r\n\r\nThe outputProjectionWrapper just wants a cell as input, and returns another cell as an output.\r\n\r\nSo while we can wrap both the forward and backward layers in their own outputProjectionWrappers and send those on to tf.nn.bidirectional_dynamic_rnn -- syntactically, it works -- it's not at all what we want conceptually.  All we've done is project the forward and backward layers independently.\r\n\r\n", "comments": ["Fuuck.\n\nObtener Outlook para Android<https://aka.ms/ghei36>\n\n________________________________\nFrom: Alfred Sorten Wolf <notifications@github.com>\nSent: Monday, June 25, 2018 3:32:29 PM\nTo: tensorflow/tensorflow\nCc: Subscribed\nSubject: Re: [tensorflow/tensorflow] Feature Request: OutputProjectionWrapper compatible with tf.nn.bidirectional_dynamic_rnn (#18219)\n\n\nNagging Assignee @tatatodd<https://github.com/tatatodd>: It has been 82 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/18219#issuecomment-400065926>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AjMrvaa78tBjB3s82AIl3KTLbuJRXU_zks5uATrNgaJpZM4TF2fm>.\n", "@tatatodd Hi, can this be considered as a feature to be implemented in the upcoming versions ?"]}, {"number": 18213, "title": "Request a new padding mode", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a\r\n- **TensorFlow installed from (source or binary)**: n/a\r\n- **TensorFlow version (use command below)**: n/a\r\n- **Python version**: n/a\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: n/a\r\n\r\nAccording to https://www.tensorflow.org/api_guides/python/nn#Convolution, the current padding mode \"SAME\" will depend on the input size to determine how many pixels to pad, for example:\r\n\r\ninput=225, kernel=7, stride=2  ---> padding = [3, 3]\r\ninput=224, kernel=7, stride=2  ---> padding = [2, 3]\r\n\r\nHowever, in most other CNN implementations, (and also, historically), padding does not depend on the input size. For kernel=7 and stride=2, padding usually will be [3, 3] (which is actually equivalent to [3, 2] when input=224).\r\n\r\nPotential issues:\r\n1. Inconsistent with models trained in other frameworks. It's not the first time I have to manually fix the padding when loading a model released by others, e.g. [here](https://github.com/ppwwyyxx/tensorpack/blob/1139854d7e286b56f87a92f96fe8f1b70789d794/examples/ResNet/load-resnet.py#L40-L42). This also causes pain for multi-backend framework such as Keras, because \"SAME\" does not mean the same thing for each backend. One example Keras issue [here](https://github.com/keras-team/keras/pull/9473). Also Keras has to explicit pad the image in its ResNet50 model: [here](https://github.com/keras-team/keras/blob/ef13db05731bfd53fa0a877637c99c1734be933b/keras/applications/resnet50.py#L213).\r\n\r\n2. Due to how padding is computed (by `left=total_padding//2, right=total_padding-left`), the number of pixels padded on __left or top__ of the image may change with different input size, as shown by the example above. This is not a good default and in particular harmful for pixel-level tasks, such as detection&segmentation, where all the annotations have an offset starting from the top-left corner of the image.\r\n\r\nIn fact, many of Google's own code has to fix this manually by `tf.pad`, for example:\r\n1. tensorflow/benchmarks has a new mode called \"SAME_RESNET\": https://github.com/tensorflow/benchmarks/blob/bab8a61aaca3d2b94072ae2b87f0aafe1797b165/scripts/tf_cnn_benchmarks/convnet_builder.py#L183-L199\r\n2. The recent tpu training code has a function called \"conv2d_fixed_padding\": https://github.com/tensorflow/tpu/blob/b189540102d6b5b40b1730d7e5ad5c884bae323c/models/experimental/resnet_bfloat16/resnet_model.py#L102-L107\r\n3. slim has a function called `conv2d_same`: https://github.com/tensorflow/models/blob/696b69a498b43f8e6a1ecb24bb82f7b9db87c570/research/slim/nets/resnet_utils.py#L77-L122\r\n4. google-research/big_transfer: https://github.com/google-research/big_transfer/blob/49afe42338b62af9fbe18f0258197a33ee578a6b/bit_tf2/models.py#L36-L38\r\n5. google-research/simclr: https://github.com/google-research/simclr/blob/6bf69ce127ae33e181e1a6c5777c84570cb5d147/tf2/resnet.py#L160-L183\r\n6. TPU object detection codebase: https://github.com/tensorflow/tpu/blob/6f9c87c1215a67fd97da7272eff247e53f266e80/models/official/detection/modeling/architecture/nn_ops.py#L309-L327\r\nGiven all these I think it's reasonable to add a new mode to make things easier.", "comments": ["@reedwm sorry for spamming random people that are active on github. Could you raise this issue to the right person at TF's team for some comments?", "There is an internal bug assigned to me to allow for explicit padding. After explicit padding is implemented, it would be easy to add other other padding modes like a `SAME_RESNET` mode. Although I'm not sure the API team would want to add more padding modes.\r\n\r\nThe reason I haven't prioritized explicit padding is that I saw no performance gain in tf_cnn_benchmarks of using explicit padding to conv2d over using `tf.pad` followed by conv2d. It's relatively easy for users to call `tf.pad`. So the only benefit of adding more modes would be a slight usability improvement.\r\n\r\n/CC @martinwicke thoughts on adding a new padding mode for consistency with other frameworks? This can be done even before I implement explicit padding.", "Thanks! Looks like I found the right person.\r\nExplicit padding would be nice. Surprised to know that there is no gain over `tf.pad`. Speaking of performance, another potential issue with the current \"SAME\" mode is that it does padding twice (one explicitly with `functor::PadInput` and one with cudnn) in order to pad [2, 3]. But in the hypothetical new mode, only one cudnn call is needed to pad [3, 2] .", "`functor::PadInput` will still be needed in some cases. cudnn only allows equal padding on both sides. It is possible to sometimes allow the left-padding to be slightly larger than the right-padding with cudnn, so in some cases, we might not need `functor::PadInput` when the padding is [3, 2]. But, when I measured the performance of `tf_cnn_benchmarks` with explicit padding, I didn't implement that optimization, and always would call `functor::PadInput` when the left-padding was larger than the right-padding.", "Once @reedwm's explicit padding is in, adding another constant to the API is not a problem. We should call it something other than \"SAME_RESNET\", maybe \"VALID_STATIC\"?\r\n\r\nBefore the fix, adding it may be too disruptive to be worthwhile, but I'll defer to Reed on that.", "Currently working on explicit padding, which is a prerequisite to adding a new padding mode.", "@reedwm This is huge, it's good to know a fix is actively under development! It's a mess, one supposes that \"same\" means the same thing across all frameworks! ", "> Currently working on explicit padding, which is a prerequisite to adding a new padding mode.\r\n@reedwm, Hello, why is it necessary to adding explicit padding in convolution. Is it because that usability improvement and other frameworks support?", "> why is it necessary to adding explicit padding in convolution\r\n\r\nExplicit padding is now implemented in several ops, including Conv2D.  Supporting explicit padding means its easy to add support for a new padding mode, as the op will already support arbitrary padding.\r\n\r\nIt is now relatively easy to add a new padding mode, but I am not sure if it is worth the API change. Every new padding mode means more complexity when a user tries to understand the `padding` parameter, and its already possible to manually implementing whatever padding algorithm you wish with explicit padding (or `tf.pad`).\r\n\r\n@martinwicke do you think a new padding mode should be added?"]}, {"number": 18149, "title": "C++ Const and Assign to initialize variable causes a segfault depending on the Const constructor used", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes see a very short example below.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nmacOS 10.13.3 clang 900.0.39.2 and CentOS Linux 7 gcc-4.8.5\r\n- **TensorFlow installed from (source or binary)**:\r\nSource from the 1.7.0 release tag\r\n- **TensorFlow version (use command below)**:\r\nI have not actually installed the python pip package, but the source tree came from:\r\nhttps://github.com/tensorflow/tensorflow/archive/v1.7.0.tar.gz\r\n\r\n- **Python version**: \r\nN/A using the C++ API\r\n- **Bazel version (if compiling from source)**:\r\nmacOS Build label: 0.11.1-homebrew and Centos Linux 7 Build label: 0.11.1- (@non-git)\r\n- **GCC/Compiler version (if compiling from source)**:\r\nmacOS clang 900.0.39.2 and CentOS Linux 7 gcc-4.8.5\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nextract the sources/configure\r\n`tar -xzvf v1.7.0.tar.gz`\r\n`cd tensorflow-1.7.0`\r\n`./configure`\r\n\r\nThen add the following directory to hold the work:\r\n`mkdir tensorflow/basic-example`\r\n\r\nPut into basic-example the following BUILD file:\r\n```\r\nload(\"//tensorflow:tensorflow.bzl\", \"tf_cc_binary\")\r\n\r\ntf_cc_binary(\r\n    name = \"basic-example\",\r\n    srcs = [\r\n        \"basic-example.cc\",\r\n    ],\r\n    deps = [\r\n        \"//tensorflow/cc:cc_ops\",\r\n        \"//tensorflow/cc:client_session\",\r\n        \"//tensorflow/core:tensorflow\"\r\n    ]\r\n)\r\n```\r\nPut into basic-example the following C++ source file:\r\n```c++\r\n#include \"tensorflow/cc/client/client_session.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n\r\nusing namespace tensorflow;\r\nusing namespace tensorflow::ops;\r\nusing namespace std;\r\n\r\nint main() {\r\n\r\n  Scope scope = Scope::NewRootScope();\r\n \r\n  auto c = Const(scope.WithOpName(\"const_c\"), {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}, {3,3});\r\n\r\n  auto v = Variable(scope.WithOpName(\"var1\"), {3, 3}, DT_FLOAT);\r\n  auto init_v = Assign(scope.WithOpName(\"init_v\"), v, c);\r\n\r\n  std::vector<Tensor> outputs;\r\n  ClientSession session(scope);\r\n\r\n  TF_CHECK_OK(session.Run({init_v}, &outputs));\r\n}\r\n```\r\nNow compile and run the resulting program:\r\n`bazel build -c dbg //tensorflow/basic-example`\r\n`./bazel-bin/tensorflow/basic-example/basic-example`\r\n\r\nObserve the following behavior:\r\n```\r\n./bazel-bin/tensorflow/basic-example/basic-example\r\n2018-03-31 11:47:57.135532: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX\r\nSegmentation fault: 11\r\n```\r\n### Describe the problem\r\nThe code given above causes a segfault when the session runner tries to get the name of a node because the node is nullptr. I have included a stacktrace using lldb below (a trace showing the same information can be created using gdb on Linux).\r\n\r\nHowever the following slightly modified C++ program works fine:\r\n```c++\r\n#include \"tensorflow/cc/client/client_session.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n\r\nusing namespace tensorflow;\r\nusing namespace tensorflow::ops;\r\nusing namespace std;\r\n\r\nint main() {\r\n\r\n  std::vector<float> initConstData = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};\r\n\r\n  Scope scope = Scope::NewRootScope();\r\n\r\n  Tensor initConstT(DT_FLOAT, TensorShape({3,3}));\r\n  std::copy_n(initConstData.begin(), initConstData.size(), initConstT.flat<float>().data());\r\n\r\n  auto c = Const(scope.WithOpName(\"const_c\"), initConstT);\r\n\r\n  auto v = Variable(scope.WithOpName(\"var1\"), {3, 3}, DT_FLOAT);\r\n  auto init_v = Assign(scope.WithOpName(\"init_v\"), v, c);\r\n\r\n  std::vector<Tensor> outputs;\r\n  ClientSession session(scope);\r\n\r\n  TF_CHECK_OK(session.Run({init_v}, &outputs));\r\n}\r\n```\r\nThe difference between the code that works and the code that doesn't:\r\na) the explicit creation of a tensor initConstT\r\nb) calling Const with a Tensor rather than an Input::Initializer\r\n\r\nThe behavior is identical if I omit the use of scope.WithOpName and just pass scope.\r\nI have been able to test this back as far as Tensorflow 1.4 I can not build Tensorflow 1.3.1 with my installed version of bazel.\r\n\r\nIf I have done something wrong, please point it out. Otherwise I feel that because there is no semantic difference between the two programs and the API allows the former program to compile then they should both work.\r\n\r\n### Source code / logs\r\nStacktrace of the problem:\r\n```\r\n(lldb) bt\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x60)\r\n  * frame #0: 0x0000000126e677bc libtensorflow_framework.so`tensorflow::Node::name() const [inlined] std::__1::shared_ptr<tensorflow::NodeProperties>::operator->(this=0x0000000000000060) const at memory:4071\r\n    frame #1: 0x0000000126e677bc libtensorflow_framework.so`tensorflow::Node::name(this=0x0000000000000000) const at graph.cc:140\r\n    frame #2: 0x000000010018592f basic-example`tensorflow::Output::name(this=0x000000012bc020f0) const at ops.h:76\r\n    frame #3: 0x0000000100184e7a basic-example`tensorflow::ClientSession::Run(this=0x00007ffeefbff4a8, run_options=0x00007ffeefbfefd0, inputs=size=0, fetch_outputs=size=1, run_outputs=size=1, outputs=0x00007ffeefbff4b0 size=1, run_metadata=0x0000000000000000) const at client_session.cc:118\r\n    frame #4: 0x0000000100184145 basic-example`tensorflow::ClientSession::Run(this=0x00007ffeefbff4a8, inputs=size=0, fetch_outputs=size=1, run_outputs=size=1, outputs=0x00007ffeefbff4b0 size=1) const at client_session.cc:89\r\n    frame #5: 0x000000010018408a basic-example`tensorflow::ClientSession::Run(this=0x00007ffeefbff4a8, fetch_outputs=size=1, outputs=0x00007ffeefbff4b0 size=1) const at client_session.cc:76\r\n    frame #6: 0x0000000100002bfc basic-example`main at basic-example.cc:22\r\n    frame #7: 0x00007fff76249115 libdyld.dylib`start + 1\r\n    frame #8: 0x00007fff76249115 libdyld.dylib`start + 1\r\n(lldb)\r\n```\r\n", "comments": ["If, before the call to session.Run(), you do something like this:\r\n\r\n        if (!scope.ok()) {\r\n            LOG(FATAL) << scope.status().ToString();\r\n            abort();\r\n        }\r\n\r\nthen you will get a more helpful error message:\r\n\r\n> Invalid argument: Inconsistent values for attr 'T' DT_FLOAT vs. DT_DOUBLE while building NodeDef 'Model/init_v' using Op<name=Assign; signature=ref:Ref(T), value:T -> output_ref:Ref(T); attr=T:type; attr=validate_shape:bool,default=true; attr=use_locking:bool,default=true; allows_uninitialized_input=true>\r\n\r\nBut frankly I am more concerned about the SIGSEGV and lack of diagnostics.  What I have discovered in trying to use the Tensorflow C++ API is that as soon as you construct an operation with a shape or type error, scope.ok() becomes false.  Any subsequent operations added to the graph bail out of their constructors immediately, leaving them with node()==nullptr.  Then any call to Run() using these operations results in a segfault, as does Output::name() and probably other things that depend on a valid node.\r\n\r\nIf it's intended that the user always check explicitly for scope errors before calling Run(), on penalty of undefined behavior, it seems to me that that should be reflected in the documentation and examples for the C++ API.  For example, in the first example at https://www.tensorflow.org/api_guides/cc/guide if you modify the matrix A to not be rectangular (like `auto A = Const(root, { {3.f, 2.f}, {-1.f} });`) you will get a segfault rather than the error message \"Invalid argument: Initializer list components should all have the same shape\".\r\n\r\nIdeally I think calling Run() in this scenario should result in an error status rather than a segfault!  Surely it would be simple to check session.ok() there.  I hesitate to offer architectural advice on a project I'm so new to, but it might be better not to initialize Operations to having a NULL node at all.", "@davidscherer Thanks for your explanation! My apologies for my late response. With your added information I know what is going on now.\r\n```c++\r\nstd::vector<float> initConstData = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};\r\n````\r\nForces C++ to hold the numbers as floats rather than doubles. So when the following is executed:\r\n```c++\r\nTensor initConstT(DT_FLOAT, TensorShape({3,3}));\r\nstd::copy_n(initConstData.begin(), initConstData.size(), initConstT.flat<float>().data());\r\nauto c = Const(scope.WithOpName(\"const_c\"), initConstT);\r\n```\r\nThe underlying data held in initConstT is float data. However when we use the implicit initialization code:\r\n```c++\r\nauto c = Const(scope.WithOpName(\"const_c\"), {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}, {3,3});\r\n```\r\nThe complier creates the initializer array as doubles instead of floats, which in turn means that 'c' holds double data. This causes a problem here:\r\n```c++\r\nauto v = Variable(scope.WithOpName(\"var1\"), {3, 3}, DT_FLOAT);\r\nauto init_v = Assign(scope.WithOpName(\"init_v\"), v, c);\r\n```\r\nBecause the tensorflow variable 'v' is defined to hold DT_FLOAT, but 'c' is holding DT_DOUBLE due to the implicit initializer array.\r\n\r\nThank you for your help in figuring it out!\r\n\r\nI agree completely that the error was caused and known at the time of creating the init_v operation and the C++ API could raise an exception then and there much like the Java API does.\r\nIf the API designers do not want to use the exception feature of C++, then I also agree with your approach of having session.Run() check the scope object for the user, rather than allowing a segfault occur.", "can anyone share an example for weight initialization in multi-layered networks?"]}, {"number": 18096, "title": "Feature Request: Support for configuring deterministic options of cudNN Conv routines", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.6\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 7.1\r\n- **GPU model and memory**: GPU\r\n- **Exact command to reproduce**: N/A\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nhttp://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#reproducibility\r\ncudNN documentation indicates that there are several routine options for `cudnnConvolutionBackwardFilter`, `cudnnConvolutionBackwardData`, and `cudnnPoolingBackward` operations. They default to non-deterministic atomic operations, but have the option to run in a deterministic mode. To achieve determinism on TensorFlow GPU, I would like to be able to make this performance trade-off, but currently cannot find a way to enable these options in TensorFlow.\r\n\r\nCan a user-facing option be added, perhaps in `tf.ConfigProto`, to configurate these cudNN routines? This could be configured in a similar way as `inter_op_parallelism_threads` and `intra_op_parallelism_threads` are set to 1 to achieve determinism on CPU (https://stackoverflow.com/questions/41233635/meaning-of-inter-op-parallelism-threads-and-intra-op-parallelism-threads)\r\n\r\n### Source code / logs\r\n\r\nN/A", "comments": ["@vrv wrote `inter_op_parallelism_threads`. This is a feature request that additional `tf.ConfigProto` fields be added that let us do this in a deterministic way on NVidia hardware.\r\n\r\nIt's possible #16889 can be rolled into this issue. @ekelsen did work relating to determinism in #12871. @drpngx closed a \"we trade determinism for speed\" doc contribution in #10636, saying we're working on the problem.", "Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @jart: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'm going to close this out as a duplicate of #16889. Please follow that issue for updates.", "I don't believe that this issue is a duplicate of https://github.com/tensorflow/tensorflow/issues/16889. https://github.com/tensorflow/tensorflow/issues/16889 refers to achieving determinism on _CPU_ -- this feature request refers to enabling determinism on _GPU_ via surfacing cudNN routine options. @jart -- can you take another look at this issue? ", "There were GPU Non-determinism Docs contributed in #10636. @drpngx closed the PR last year, mentioning it'd be obsolete soon. I'll reopen and assign to him.", "/CC @protoget ", "If you're referring to conv ops, TF currently does autotuning underneath to pick the best algorithm for the input shape, by first running a few trial steps. I imagine disabling autotune would give you determinism in conv.\r\n\r\nYou can set ```TF_CUDNN_USE_AUTOTUNE``` env var to ```'0'```.\r\n\r\n@yzhwang to confirm.", "In my opinion, it would be helpful to get a fine-grained option to enable / disable the specific cudNN operations that are non-deterministic. For example, theano's config surfaces the `config.dnn.conv.algo_bwd_filter` and  `config.dnn.conv.algo_bwd_data` options [1] for the aforementioned conv ops.\r\n\r\nThis is opposed to using a big hammer to enable or disabling autotuning for all cudNN routines, which couples determinism to how autotuning logic behaves.\r\n\r\n[1] http://deeplearning.net/software/theano/library/config.html", "Completely agree with a separate knob on determinism. As currently we do not have any immediate plan on adding that, I added a contribution welcomed tag to this issue.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Hi. Is there any update on this feature request? It would indeed be a valuable tool to be able to switch on/off determinism.", "Hi. Is there any update on this feature request? It would indeed be a valuable tool to be able to switch on/off determinism.", "Hi. Is there any update on this feature request? It would indeed be a valuable tool to be able to switch on/off determinism.", "From TF2 release notes:\r\n\r\n> Add environment variable TF_CUDNN_DETERMINISTIC. Setting to TRUE or \"1\" forces the selection of deterministic cuDNN convolution and max-pooling algorithms. When this is enabled, the algorithm selection procedure itself is also deterministic.", "To add more information to @bersbersbers' report above, this feature has been added to TensorFlow with the following PRs: [24747](https://github.com/tensorflow/tensorflow/pull/24747), [25796](https://github.com/tensorflow/tensorflow/pull/25796), [29667](https://github.com/tensorflow/tensorflow/pull/29667), [31389](https://github.com/tensorflow/tensorflow/pull/31389), and [32979](https://github.com/tensorflow/tensorflow/pull/32979). Related PRs: [25269](https://github.com/tensorflow/tensorflow/pull/25269) and [31465](https://github.com/tensorflow/tensorflow/pull/31465).\r\n\r\nFor more information about GPU determinism in TensorFlow, please see: https://github.com/NVIDIA/tensorflow-determinism\r\n\r\nThis feature request can now be closed.", "I have resolved this issue. Please will someone close it. I cannot close it. @yoavz can you close it?"]}, {"number": 18083, "title": "No equivalent to theano.tensor.slinalg.Eigvalsh", "body": "Good morning,\r\n\r\nI have been trying to reproduce DeepLDA loss function implementation in Tensorflow \r\n(https://github.com/VahidooX/DeepLDA/blob/master/code/objectives.py theano version).\r\nIn order to solve a gep, in theano we use T.slinalg.eigvalsh to compute eigenvalues\r\nevals_t = T.slinalg.eigvalsh(Sb_t, St_t)\r\n\r\nTensorflow doesn't provide something similar and approximation are very unstable.\r\nI tried both to solve the gep Aei = Bviei\r\ncho = tf.cholesky(B_t + tf.eye(dim) * r ) \r\ninv_cho = tf.matrix_inverse(cho)\r\nevals_t = tf.linalg.eigvalsh(inv_cho * A * tf.transpose(inv_cho)) \r\n\r\nevals_t =tf.linalg.eigvalsh(tf.matrix_inverse(B) * A )\r\nIf you have a solution, please tell me :)\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Ubuntu 14.6\r\nTensorflow==1.4.0, gpu version.\r\nCuda 8.0\r\nTitan X\r\nI will add the code later on for you to try it out. It works fine using theano implemented LDA loss and backend. I might miss some information. I will add everything next week.", "`http://www.netlib.org/lapack/lug/node54.html GEP with cholesky\r\nimport tensorflow as tf\r\n\r\n\r\ndef lda_loss(n_components, margin):\r\n    \"\"\"\r\n    The main loss function (inner_lda_objective) is wrapped in this function due to\r\n    the constraints imposed by Keras on objective functions\r\n    \"\"\"\r\n    def inner_lda_objective(y_true, y_pred):\r\n        \"\"\"\r\n        It is the loss function of LDA as introduced in the original paper. \r\n        It is adopted from the the original implementation in the following link:\r\n        https://github.com/CPJKU/deep_lda\r\n        Note: it is implemented by Theano tensor operations, and does not work on Tensorflow backend\r\n        \"\"\"\r\n        r = 1e-4\r\n\r\n        # init groups\r\n        #yt = tf.cast(tf.contrib.layers.flatten(y_true), tf.float32)\r\n        #indexes = tf.argmax (y_true, axis=-1)\r\n        locations = tf.where (tf.equal (y_true, 1))\r\n        indices = locations[:, 1]\r\n        y, idx = tf.unique(indices)\r\n        \r\n        def fn(unique, indexes, preds):\r\n            u_indexes = tf.where(tf.equal(unique, indexes))\r\n            u_indexes = tf.reshape(u_indexes, (1, -1))\r\n            X = tf.gather(preds, u_indexes)\r\n            X_mean = X - tf.reduce_mean(X, axis=0)\r\n            m = tf.cast(tf.shape(X_mean)[1], tf.float32)\r\n            #X_mean = tf.squeeze(X_mean)\r\n            return (1/(m-1)) * tf.matmul(tf.transpose(X_mean[0]), X_mean[0])\r\n\r\n\r\n        covs_t = tf.map_fn(lambda x: fn(x, indices, y_pred), y, dtype=tf.float32)\r\n\r\n        # compute average covariance matrix (within scatter)\r\n        Sw_t = tf.reduce_mean(covs_t, axis=0)\r\n        \r\n``\r\n        Xt_bar = y_pred - tf.reduce_mean(y_pred, axis=0)\r\n        m = tf.cast(tf.shape(Xt_bar)[1], tf.float32)\r\n        St_t = (1/(m-1)) * tf.matmul(tf.transpose(Xt_bar), Xt_bar)\r\n\r\n        # compute between scatter\r\n        dim = tf.shape(y)[0]\r\n        Sb_t = St_t - Sw_t\r\n\r\n        # cope for numerical instability (regularize)\r\n        \r\n        Sw_t += tf.eye(dim) * r    \r\n        \r\n        cho = tf.cholesky(St_t + tf.eye(dim) * r ) \r\n        inv_cho = tf.matrix_inverse(cho)\r\n        evals_t = tf.linalg.eigvalsh(inv_cho * Sb_t * tf.transpose(inv_cho)) # Sb_t, St_t    \r\n        #evals_t = tf.abs(tf.linalg.eigvalsh(tf.matrix_inverse(Sw_t) * Sb_t ))\r\n        top_k_evals = evals_t[-n_components:]\r\n        \r\n        #index_max = tf.argmax(top_k_evals, 0)\r\n        #thresh_max = top_k_evals[index_max] - margin\r\n        \r\n        index_min = tf.argmin(top_k_evals, 0)\r\n        thresh_min = top_k_evals[index_min] + margin\r\n        #thresh = tf.contrib.distributions.percentile(top_k_evals, 33)\r\n        #mask_max = top_k_evals > thresh_max\r\n        mask_min = top_k_evals < thresh_min\r\n        \r\n        #cost_max = tf.boolean_mask(top_k_evals, mask_max) \r\n        cost_min = tf.boolean_mask(top_k_evals, mask_min)\r\n        \r\n        return  - tf.reduce_mean(cost_min)\r\n    \r\n    return inner_lda_objective\r\nfrom keras.layers import Dense, Merge\r\nfrom keras.models import Sequential\r\nfrom keras.regularizers import l2\r\n\r\n\r\ndef create_model(input_dim, reg_par, outdim_size):\r\n    \"\"\"\r\n    Builds the model\r\n    The structure of the model can get easily substituted with a more efficient and powerful network like CNN\r\n    \"\"\"\r\n    model = Sequential()\r\n\r\n    model.add(Dense(1024, input_shape=(input_dim,), activation='sigmoid', kernel_regularizer=l2(reg_par)))\r\n    model.add(Dense(1024, activation='sigmoid', kernel_regularizer=l2(reg_par)))\r\n    model.add(Dense(1024, activation='sigmoid', kernel_regularizer=l2(reg_par)))\r\n    model.add(Dense(outdim_size, activation='linear', kernel_regularizer=l2(reg_par)))\r\n\r\n    return model\r\nimport pickle\r\nimport gzip\r\nimport numpy as np\r\nfrom keras.datasets import mnist\r\nfrom keras.optimizers import Adam\r\n\r\n\r\nif __name__ == '__main__':\r\n\r\n    from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\r\n    mnist = read_data_sets(\"path_mnist/\", one_hot=True)\r\n\r\n\r\n\r\n\r\n    outdim_size = 10\r\n\r\n\r\n    epoch_num = 100\r\n    batch_size = 800\r\n\r\n    reg_par = 1e-5\r\n\r\n\r\n    margin = 1.0\r\n    n_components = 9\r\n\r\n\r\n\r\n\r\n\r\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\n    x_train = np.reshape(x_train, (len(x_train), -1))\r\n    x_test = np.reshape(x_test, (len(x_test), -1))\r\n\r\n    print(x_train.shape, y_train.shape)\r\n\r\n    model = create_model(x_train.shape[-1], reg_par, outdim_size)\r\n\r\n    model_optimizer = Adam()\r\n    model.compile(loss=lda_loss1(n_components, margin), optimizer=model_optimizer)\r\n\r\n    model.summary()\r\n\r\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epoch_num, shuffle=True, validation_data=(x_test, y_test), verbose=2)`", "@fchollet can you comment or redirect? Thanks.", "It is still not possible to sovle a gpe in tf where it is wth theano. I\ntried over way, but tf.solve_cholesky is very unstable.\n\n2018-04-25 2:14 GMT+01:00 Skye Wanderman-Milne <notifications@github.com>:\n\n> @fchollet <https://github.com/fchollet> can you comment or redirect?\n> Thanks.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18083#issuecomment-384128690>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AMRCHT5nYLUBtlvNhZgV4VBNznkE2rVEks5tr84QgaJpZM4S_4eF>\n> .\n>\n"]}, {"number": 18065, "title": "Feature request : warning for feeding unused values", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.4 LTS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**:  3.6.3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n\r\n### Describe the problem\r\n(It's not a bug. Just a feature discussion)\r\n\r\nProbably it would be reasonable to add some kind of warnings for situations when the value you feed, is never used within computation?\r\n\r\nExample:\r\n\r\n```\r\na = tf.abs(2)\r\nb = 2 * a\r\n#a = tf.identity(a, name='a')\r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run([a, b], feed_dict={a: 3}))\r\n```\r\nIn this everything works fine.  However if 3d line will be uncommented the feeded value will be useless. It can lead to hard debugging.\r\nProbably it would we useful to add some warnings?\r\n\r\nThanx\r\n", "comments": []}, {"number": 17980, "title": "tf.einsum doesn't perform common subgraph elimination", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7.4\r\n- **TensorFlow installed from (source or binary)**: Binary (pip)\r\n- **TensorFlow version (use command below)**: 'unknown' 1.6.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n\r\n### Describe the problem\r\nWhen I inspect the computation graph in tensorboard, there are two separate calls to einsum and no subgraphs (ie calls to matmul) are shared. I would have expected the \"jb,abcd\" tensors to be contracted once, then contracted with (ia + ai) afterwards. \r\n\r\n### Source code / logs\r\n```\r\ntf_eri = tf.constant(np.random.random([10,10,10,10])\r\ntf_ao = tf.constant(np.random.random([10,10])\r\n\r\ntf_foo = tf.einsum(\"ia,jb,abcd\", tf_ao, tf_ao, tf_eri)\r\ntf_bar = tf.einsum(\"ai,jb,abcd\", tf_ao, tf_ao, tf_eri)\r\ntf_res = tf_foo + tf_bar\r\n```\r\n\r\n![graph](https://user-images.githubusercontent.com/1048117/37871855-3a6564d0-2fc6-11e8-961b-a34d14175e50.png)\r\n", "comments": ["@zhangyaobit, have you considered optimizations like these (not so much an einsum thing). I think the issue is more than there are two source of data, so you actually need to represent both at least partially.", "Nagging Assignee @zhangyaobit: It has been 180 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @zhangyaobit: It has been 195 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@matt-chan Hi, does this problem still exist ?", "I think grappler could support this. Contributions are welcome."]}, {"number": 17978, "title": "Tensorflow not working properly in Python sub-interperters", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64 bit Professional\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**:  3.6.3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**: import tensorflow as tf on a Python wsgi application written in Flask\r\n- **Have I written custom code**: N/A\r\n\r\n### Describe the problem\r\n\r\nThis is a follow-up to a problem that I described in a stackoverflow post today:\r\nhttps://stackoverflow.com/questions/49471240/slow-page-loading-on-apache-when-using-flask/49471633#49471633\r\n\r\nThe summary of the issue is that when trying to import tensorflow in a web application written in Flask and hosted on Apache, the page never loads up because of the tensorflow import. \r\n\r\nFrom the reply, they suggested that Tensorflow, being a C extension does not yet provide proper support to be run on python sub-interpreters. \r\n\r\nThey also suggested a workaround that worked for me, which was to force wsgi application to run on the primary python process.\r\n\r\nI admit that I don't really understand the scope of the problem, but I thought it might be worth mentioning this issue and understand if it is something that could be/should be fixed.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code", "I edit my post with the added info.", "we have similar problem,  we end up running tensorflow as an independent application and use redis to communication."]}, {"number": 17933, "title": "gRPC debug URL scheme support for Windows", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (See below)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.6.0\r\n- **Python version**: 3.6.1\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\nIncidentally, this is both a bug report and a feature request. \r\n\r\nTo reproduce the bug, run the following:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python import debug as tf_debug\r\n\r\nsession = tf.Session()\r\nsession = tf_debug.TensorBoardDebugWrapperSession(session, \"localhost:9898\")\r\n\r\ncurrent_epoch = tf.Variable(0, trainable=False, name='current_epoch')\r\nincrement_epoch = tf.assign(current_epoch, current_epoch + 1)\r\n\r\nstart_epoch = current_epoch.eval(session)\r\nprint(\"start_epoch:\", start_epoch)\r\nfor cur_epoch in range(start_epoch, 10):\r\n    session.run(increment_epoch)\r\n\r\n```\r\n\r\nThe following is the output:\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:/workspace/test.py\", line 12, in <module>\r\n    for cur_epoch in range(start_epoch, 10):\r\nTypeError: 'UnimplementedError' object cannot be interpreted as an integer\r\nstart_epoch: grpc:// debug URL scheme is not implemented on Windows yet.\r\n```\r\n\r\nIt's clear that the error is being assigned to a variable instead of being raised. Furthermore, the behavior is only present when evaluating a variable; this is unexpected, as it has nothing to do with the session itself.\r\n\r\nI came across this while trying to enable debugging via TensorBoard. After some digging, it appears that the error message originates from [TensorFlow core code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/debug/debug_io_utils.cc#L390), so that's why this issue is here and not in the TensorBoard project. Is there any status on implementation of this feature? If not, could there be a log warning or some sort of feedback to reflect this? The TensorBoard modal at http://localhost:6006/#debugger gives no indication that it is platform-dependent.\r\n", "comments": ["Had same issue. Tried running it in WSL without problems, only difference was running file from WSL instead of windows 10", "Same issue for me, windows 10\r\n", "try to replicate the tensorboard debugger tutorial with same issue on windows 10", "@ClaCec The tfdbg tutorial ([here](https://www.tensorflow.org/programmers_guide/debugger) for posterity) doesn't use gRPC, but there's a flag in `debug_mnist.py` for using TensorBoard, so I'll assume that's what you're referring to. I ran these:\r\n\r\n`tensorboard.exe --logdir . --debugger_port 1234`\r\n\r\n`python .\\debug_mnist.py --tensorboard_debug_address 'localhost:1234'`\r\n\r\nHere's the output:\r\n\r\n```\r\n33 ops no flops stats due to incomplete shapes.\r\nAccuracy at step 0: grpc:// debug URL scheme is not implemented on Windows yet.\r\nAccuracy at step 1: grpc:// debug URL scheme is not implemented on Windows yet.\r\nAccuracy at step 2: grpc:// debug URL scheme is not implemented on Windows yet.\r\nAccuracy at step 3: grpc:// debug URL scheme is not implemented on Windows yet.\r\nAccuracy at step 4: grpc:// debug URL scheme is not implemented on Windows yet.\r\nAccuracy at step 5: grpc:// debug URL scheme is not implemented on Windows yet.\r\nAccuracy at step 6: grpc:// debug URL scheme is not implemented on Windows yet.\r\nAccuracy at step 7: grpc:// debug URL scheme is not implemented on Windows yet.\r\nAccuracy at step 8: grpc:// debug URL scheme is not implemented on Windows yet.\r\nAccuracy at step 9: grpc:// debug URL scheme is not implemented on Windows yet.\r\n```", "got the same issue", "Briefly said: Currently Windows is not supported by Tensorflow 1.8 / Tensorboard 1.8 (see [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/debug/debug_io_utils.cc](url)). The CC++ code block is labeled as #ifndef ... #else directive block for URLs starting with grpc:://", "@ideenfix That code block was linked in the issue description. :) \r\n\r\nI'd still like some consistency between the documentation, the Tensorboard UI and the C++ error.", "@naefl \r\n\r\nTo bypass the Windows incompatibility and run the debugger in WSL, are you just running the command line in it (i.e. tensorboard --logdir=<path> --port <num1> --debugger port <num1>) or do you have everything reinstalled for linux (i.e. python, tensorflow, CUDA toolkit, CuDNN, etc.)?\r\n\r\nI haven't seen anything that shows a fix for this would be (or would not be) coming to Windows , but the TensorBoard Debugger site doesn't have a mention of Windows 10 incompatibility. ", "@Faust22\n\n\n\n\nJust running Tensorboard from CL, WSL has no support for GPU, so no cuDNN/CUDA. Tf, Tb and all other dependencies are installed in WSL. \n\n\n\n\nFrom: Faust22\n\n\nSent: Thursday, May 31, 8:35 AM\n\n\nSubject: Re: [tensorflow/tensorflow] gRPC debug URL scheme support for Windows (#runningL\n\n\nTo: tensorflow/tensorflow\n\n\nCc: LucaNaef, Mention\n\n\n\n\n\n\n@naefl\n\n\nTo bypass the Windows incompatibility and run the debugger in WSL, are you just running the command line in it (i.e. tensorboard --logdir= --port --debugger port ) or do you have everything reinstalled for linux (i.e. python, tensorflow, CUDA toolkit, CuDNN, etc.)?\n\n\nI haven't seen anything that shows a fix for this would be (or would not be) coming to Windows , but the TensorBoard Debugger site doesn't have a mention of Windows 10 incompatibility.\n\n\n\u2014\n\n\nYou are receiving this because you were mentioned.\n\n\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n\n\n\n\n", "@naefl \r\n\r\nI see, thanks. It might be a bit rough without GPU support. I mainly want the 'health' section for NAN and INF value analysis, but there appears to be other ways to do this, although TensorBoard seemed good for this.\r\n\r\n@caisq \r\n\r\nIs there potential to see Windows support for TensorBoard debugger in the near future? (i.e. 1.9 or further off?)", "Same issue, on windows 10 with Tensorflow 1.9.\r\nHas anyone found a way to fix this?", "I have the same issue, on windows 10 with Tensorflow 1.9. ", "same issue on windows 7 tensorflow1.10", "Same issue on Windows 10. Guess its not supported on windows....", "@FurryFur As of this comment, it is explicitly not supported on Windows - that's why it's marked as a feature request.", "For what it's worth, the tensorboard debugger plugin appears to work pretty well with the Ubuntu 18.04 app on the Windows app store. I gave up on the original Ubuntu app over a year ago due to incredibly slow install times, but things have changed and it's much faster. I dropped miniconda on it, installed tensorflow, brought up tensorboard and everything is seeming to work in the browser. Figures crossed it keeps working without any surprises. Props to Microsoft for this sweet little app.", "I have tried tensorflow for deep learning in windows 10. However, facing the same issue \"1 ops no flops stats due to incomplete shapes\" with TypeError: 'UnimplementedError' object is not iterable, while trying to use Tensorflow debugger. Is there any solution?", "Is there any status on this one? I'm also receiving\r\n`tensorflow.python.framework.errors_impl.UnimplementedError: grpc:// debug URL scheme is not implemented on Windows yet.` when trying to run an Estimator with debugging enabled (`hooks = [tf_debug.TensorBoardDebugHook(_DEBUGGER_LOCATION)]`) .\r\nTensorboard 1.14.0", "Still this Problem is not solved?\r\n"]}, {"number": 17859, "title": "`Datasets` sometimes resamples stochastic Tensors during multiple transformations", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes, to demonstrate the bug\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMac OS X 10.13.3\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.5.0\r\n- **Python version**: \r\n2.7\r\n\r\n### Describe the problem\r\nDatasets can involve stochastic transformations. Sometimes random Tensors are resampled, and sometimes they're not. It's not clear when one happens and when another happens. This is likely a subtle Datasets bug, but at a minimum is a documentation bug. This is the root cause of Issue #16606, which is fixed in the resampling code by PR #17858.\r\n\r\n### Source code / logs\r\nThe following short snippet demonstrates that `Dataset.zip` causes the random Tensors to be resampled, while a seemingly-equivalent `map` statement does not:\r\n\r\n```\r\ndef _test_ds_consistency(tup_ds):\r\n  get_next = tup_ds.make_one_shot_iterator().get_next()\r\n\r\n  with tf.Session() as sess:\r\n    while True:\r\n      try:\r\n        tup = sess.run(get_next)\r\n        assert tup[0] == tup[1]\r\n      except tf.errors.OutOfRangeError:\r\n        break\r\n\r\ndef _get_random_0s_and_1s(num_elements):\r\n  const_ds = tf.data.Dataset.from_tensor_slices([0] * num_elements)\r\n  return const_ds.map(lambda _: tf.cast(tf.random_uniform([]) * 2, dtype=tf.int32))\r\n\r\ndef doesnt_work(num_elements=10):\r\n  rand_ds = _get_random_0s_and_1s(num_elements)\r\n  index_ds = rand_ds.map(lambda i: tf.gather([0, 1], i))\r\n  return tf.data.Dataset.zip((index_ds, rand_ds))\r\n\r\ndef works(num_elements=10):\r\n  rand_ds = _get_random_0s_and_1s(num_elements)\r\n  tup_ds = rand_ds.map(lambda i: (tf.gather([0, 1], i), i))\r\n  return tup_ds\r\n\r\n_test_ds_consistency(works())  # works\r\n_test_ds_consistency(doesnt_work())  # raises assert\r\n```\r\n", "comments": ["Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 29 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 44 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 59 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Assigning to mrry for triaging", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "I think this is a case where you'd want to use tf.config.stateless random\nsamplers. We may want to add that to the map* docstrings.  +Derek Murray\n<mrry@google.com> wdyt?  Is this a bug or should we be able to guarantee\ne.g. number of times that a map fn is called and the state of the rng seed\nacross the multiple calls?\n\nOn Sat, Jul 28, 2018, 11:49 AM Alfred Sorten Wolf <notifications@github.com>\nwrote:\n\n> Please remove the assignee, as this issue is inviting external\n> contributions. Otherwise, remove the contributions welcome label. Thank\n> you.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17859#issuecomment-408627716>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimwmTme8FUWk-ToMrV05wFSk-7ZgHks5uLLI0gaJpZM4Sxvsj>\n> .\n>\n", "Err tf.contrib.stateless\n\nOn Sat, Jul 28, 2018, 5:43 PM Eugene Brevdo <ebrevdo@google.com> wrote:\n\n> I think this is a case where you'd want to use tf.config.stateless random\n> samplers. We may want to add that to the map* docstrings.  +Derek Murray\n> <mrry@google.com> wdyt?  Is this a bug or should we be able to guarantee\n> e.g. number of times that a map fn is called and the state of the rng seed\n> across the multiple calls?\n>\n> On Sat, Jul 28, 2018, 11:49 AM Alfred Sorten Wolf <\n> notifications@github.com> wrote:\n>\n>> Please remove the assignee, as this issue is inviting external\n>> contributions. Otherwise, remove the contributions welcome label. Thank\n>> you.\n>>\n>> \u2014\n>> You are receiving this because you were assigned.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/17859#issuecomment-408627716>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/ABtimwmTme8FUWk-ToMrV05wFSk-7ZgHks5uLLI0gaJpZM4Sxvsj>\n>> .\n>>\n>\n"]}]