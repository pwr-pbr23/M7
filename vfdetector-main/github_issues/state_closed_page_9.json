[{"number": 55238, "title": "Fix to enable mlir unit tests to run with BEF thunk/executable.", "body": "The //tensorflow/compiler/xla/service/gpu/tests:mlir_gemm_test test was not running on BEF thunk when it was specified as such.\r\n\r\nThe reason is that it was ignoring XLA_FLAGS=--xla_gpu_bef_thunk.\r\n\r\nThese changes should fix that.\r\n\r\n/cc @chsigg @hanbinyoon", "comments": ["> Sorry for the delay on this review, Rohit.\r\n> \r\n> How about we just replace DefaultDebugOptionsIgnoringFlags() with GetDebugOptionsFromFlags() for good, instead of doing it conditionally on #if XLA_ENABLE_XLIR? I think that would be cleaner. Otherwise, looks good to me!\r\n\r\nI totally agree with your suggestion.  In fact, that is what I wanted to do originally so thanks for confirming.\r\n\r\nI just thought that there might have been a reason (that is unknown to me) why the code was originally written that way.\r\n\r\nDone!", "i believe that's not the best idea ,most users want to have the option of notification alerts from modules in case they might have a input for better conversion notations.\n", "debug options should be voted and discuss from organizations and contributors to the module by getting notebook approval from admin  "]}, {"number": 55236, "title": "[INTEL oneDNN] user mode scratchpad implementation for inner-product", "body": "Enable user mode scratchpad for inner-product (matmul fused & quantized matmul) for better memory usage control.\r\n\r\nNote: code change with mkl_util.h is NOT needed once PR\r\n\r\n  https://github.com/tensorflow/tensorflow/pull/55256\r\n\r\nis merged.", "comments": ["@penpornk  The new code in mkl_util.h causes Windows compilation failure (same code in the recently reverted PR).\r\nWe will fix it.\r\n\r\nSo please hold on the review.  Thanks!", "@penpornk  This PR is ready for review. \r\n\r\nYou can combine it with a related scratchpad PR \r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/55256\r\n", "Done with change", "@gzmkl Could you please help resolve merge conflict? Thank you very much!", "Manually close this PR since it is merged in https://github.com/tensorflow/tensorflow/commit/2ed1ca2e69a3200f70d7025f260e5d97f82b18b9."]}, {"number": 55235, "title": "[INTEL oneDNN] user mode scratchpad implementation for conv op", "body": "Enable user mode scratchpad for conv ops (2d, 3d, etc) for better memory usage control.\r\n\r\nNote: code change with mkl_util.h is NOT needed once PR\r\n\r\n  https://github.com/tensorflow/tensorflow/pull/55256\r\n\r\nis merged.", "comments": ["@penpornk  The new code in mkl_util.h causes Windows compilation failure (same code in the recently reverted PR).\r\nWe will fix it.\r\n\r\nSo please hold on the review.  Thanks!", "@penpornk  This PR is ready for review. \r\n\r\nYou can combine it with a related scratchpad PR \r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/55256", "@gzmkl Could you please help resolve merge conflict? Thank you very much!", "@penpornk  Resolved. Thank you!\r\n\r\n"]}, {"number": 55233, "title": "Enhancements to allow BEF unit tests to work on CUDA and ROCm.", "body": "In the BEF config, it is necessary to specify CUDA stubs to make it work for ROCm.\r\n\r\nIf there is a better way to do this so that we can avoid a doubling of things in .bazelrc for CUDA and ROCm, please let me know.\r\n\r\n/cc @chsigg @hanbinyoon ", "comments": ["@chsigg I updated this PR based on your suggestion (which worked).  Thanks!", "I'm merging this change manually. Ganesh, could you please stamp cl/434714991? Thanks!"]}, {"number": 55232, "title": "[ROCm] Fixes for vector data type collision in BEF thunk for ROCm.", "body": "/cc @chsigg @cheshire @jurahul ", "comments": ["@gbaned An import/copybara error occurred.  please let me know how i can help fix this.", "Thanks Rohit. I will pull this change manually."]}, {"number": 55229, "title": "Converter for LogicalNot operation", "body": "- Converter for LogicalNot operation is using the same base class (`ConvertUnaryImpl`) as other Unary operations. \r\n- The special converter for `Rsqrt\r\n` was removed and now for this operation regular Unary Op converter is used.\r\n- New templated class implemented for testing `ConvertUnary`, `ConvertBooleanUnary`, `ConvertActivation`.\r\n- A new check and corresponding subtests were added to Validate: at least 1 dimension is required for input of any `Unary` and `UnaryBoolean` operation. (Similar subtest for `ConvertActivation` operations is blocked and after refactoring of `ConvertActivation` it will be activated)\r\n", "comments": ["Should be merged AFTER [PR#55177](https://github.com/tensorflow/tensorflow/pull/55177): **Update test helpers to handle bool tensors and weights**", "I fixed some formatting issues and noticed that this PR was closed.", "Would you please rebase this PR? @drivanov ", "> Would you please rebase this PR? @drivanov\r\n\r\nRebase is done. \r\n\r\n@bixia1 : Just one note... On Friday (03/18/2022) I noticed that my latest change for [PR#55177](https://github.com/tensorflow/tensorflow/pull/55177/) fixes the issue with `ConvertMatMul` you mentioned, but is not valid for `LogicalNot` and other boolean operations. I fixed this and updated [PR#55177](https://github.com/tensorflow/tensorflow/pull/55177/), but it seems that it was already merged at that point. After that, I got the \"merge conflict\" messages for all my 4 PRs and I fixed them yesterday (03/20/22).\r\n\r\nLong story short, the changes in [that fragments](https://github.com/tensorflow/tensorflow/blob/516c77c4c78770ae246b6ff7255c6e6f5b6674d7/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc#L1374-L1435) is a correct fix for the the issue with `ConvertMatMul` you mentioned. ", "After the merge with the master branch, I see a lot of new \"changed\" files. I am closing that PR and I creating a new one [PR#55428](https://github.com/tensorflow/tensorflow/pull/55428)."]}, {"number": 55228, "title": "Cannot load optimizer state on TPUs", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): GCP\r\n- TensorFlow installed from (source or binary):Binary\r\n- TensorFlow version (use command below):2.5\r\n- Python version:3.7\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: TPU\r\n\r\n**Describe the current behavior**\r\nWith TPUs, it is not possible to load the optimizer state. This is pretty important when running tuning runs, or when continuing a train job. Any sort of work around for saving the model with the optimizer or another way to load the optimizer would be greatly appreciated. \r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os.path as osp\r\nimport pickle\r\nfrom tensorflow.keras.layers import Input\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras import Model\r\n\r\n#build model\r\nX, y = np.random.rand(100, 50), np.random.randint(2, size=100)\r\nx = Input((50,))\r\nout = Dense(1, activation='sigmoid')(x)\r\nmodel = Model(x, out)\r\n\r\n#build setup an optimizer and save the state\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\r\nopt_path = 'opt_wights.npy'\r\ngrad_vars = model.trainable_weights\r\nzero_grads = [tf.zeros_like(w) for w in grad_vars]\r\noptimizer.apply_gradients(zip(zero_grads, grad_vars))\r\nnp.save(opt_path, optimizer.get_weights())\r\n\r\n#do the same thing with a load, but in strategy scope\r\n#get the strategy\r\nbTPU = True\r\nif bTPU:\r\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\r\n    tf.config.experimental_connect_to_cluster(tpu)\r\n    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n    strategy = tf.distribute.TPUStrategy(tpu)\r\nelse:    \r\n    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\r\n    if len(gpus) > 1:\r\n        strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\r\n    elif len(gpus) == 1:\r\n        strategy = tf.distribute.get_strategy()\r\n    else:\r\n        strategy = tf.distribute.get_strategy()\r\n\r\nwith strategy.scope():\r\n    #build the model and optimizer again\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\r\n    X, y = np.random.rand(100, 50), np.random.randint(2, size=100)\r\n    x = tf.keras.layers.Input((50,))\r\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\r\n    model = tf.keras.Model(x, out)\r\n    @tf.function\t\r\n    def _model_weight_setting():\r\n        opt_weights = np.load(opt_path, allow_pickle=True)\r\n        grad_vars = model.trainable_weights\r\n        zero_grads = [tf.zeros_like(w) for w in grad_vars]\r\n        optimizer.apply_gradients(zip(zero_grads, grad_vars))\r\n        optimizer.set_weights(opt_weights)\r\n    strategy.run(_model_weight_setting)\r\n```\r\n", "comments": ["Hi @gadagashwini ! Could you please look at this issue ? It is replicating in [2.7](https://colab.sandbox.google.com/gist/mohantym/70260d9cfe5975f20d9b2ac35fdf0aa5/github_55228.ipynb#scrollTo=hyxNuNruYUAj) , [2.8](https://colab.sandbox.google.com/gist/mohantym/ef954451ea9e0dd8b997a2e9dd72069b/github_55228.ipynb) and [nightly](https://colab.sandbox.google.com/gist/mohantym/b202e59999e1475bc25511d5728894a0/github_55228.ipynb#scrollTo=Nqeb_wQvYVX9).", "@ttdd11, Does [this](https://stackoverflow.com/a/49504376/14290244) help. Thanks!", "@gadagashwini thanks for the link. I have seen this before and this is mostly where the sample I provided is from. This will work with a single GPU I believe (I have no tested a multi-gpu system with that specifically) but will not load on the TPU. What else can I do to help with this? Is there a way that I can change the model to save the optimizer state as well? ", "@ttdd11,\r\nLooks like its duplicate of [#53844](https://github.com/tensorflow/tensorflow/issues/53844). Can we close one.\r\nWill move this issue to next level for resolution. Thanks! ", "@gadagashwini it's a duplicate for sure. I opened a new ticket after basically no update for months. Will this get escalated in any way? ", "@ttdd11,\r\nClosing this as its duplicate of #53844. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55228\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55228\">No</a>\n", "@gadagashwini This is why a new ticket was opened. If you look at the communication in the other ticket there isn't a single response from the assignee and it's just labelled awaiting tensorflower. ", "@gadagashwini can we please re-open this ticket? The other ticket has never received a response from the assignee. "]}, {"number": 55227, "title": "Add zero point check for kTfLiteInt16 and scale check for multiple operators", "body": "Hello, have added zero point checks and scale checks to the following operators\r\n- arg_min_max.cc\r\n- gather.cc\r\n- gather_nd.cc\r\n- mul.cc\r\n- pack.cc\r\n- pad.cc\r\n- pooling.cc\r\n- resize_bilinear.cc\r\n- resize_nearest_neighbor.cc \r\n- select.cc\r\n- slice.cc\r\n- transpose.cc\r\n- unpack.cc", "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55227/checks?check_run_id=5540904095).", "CLA should be complete", "I signed it.", "I signed it"]}, {"number": 55225, "title": "Minor fix to mlir function name symbol lookup for BEF lowering.", "body": "/cc @chsigg @cheshire @jurahul ", "comments": []}, {"number": 55224, "title": " Can't use multiple tensorboard callbacks in TF2.8", "body": "**System information**.\r\n- Have I written custom code (as opposed to using a stock example script provided in Keras): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0\r\n- Python version: 3.8.12\r\n- Bazel version (if compiling from source):\r\n- GPU model and memory: None\r\n- Exact command to reproduce:\r\n\r\n**Describe the problem.**\r\n\r\nI am using multiple tensoboard callbacks with the same Model. Since I upgraded Tensorflow from 2.5 to 2.8, I have an error at the end of the training when closing the Tensorboard writers.  \r\nI opened an issue on the Keras repo https://github.com/keras-team/keras/issues/16235, but after diving a little bit more into the source code, I think the issue directly comes from Tensorflow and not from keras. This [commit](https://github.com/tensorflow/tensorflow/commit/6edaa9105a2cd91369ae69da0dd10993f77557b3) might have introduced the bug.\r\n\r\n**Describe the current behavior.**\r\n\r\nThe training doesn't end correctly because of a Tensrboard callback error.\r\n\r\n**Describe the expected behavior.**\r\n\r\nIt used to work in TF2.5 and it should still do.\r\n\r\n\r\n**Standalone code to reproduce the issue**.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tempfile\r\n\r\nwith tempfile.TemporaryDirectory() as tmpdir:\r\n    batch_size = 3\r\n    nb_samples = 10\r\n    update_freq = 2\r\n    inputs = tf.random.normal((nb_samples, 2))\r\n    outputs = tf.random.normal((nb_samples, 10))\r\n    dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs)).batch(batch_size)\r\n    dataset_val = tf.data.Dataset.from_tensor_slices((inputs, outputs)).batch(batch_size)\r\n    nb_epochs = 5\r\n\r\n    model = tf.keras.Sequential([tf.keras.layers.Dense(10)])\r\n    optimizer = tf.keras.optimizers.SGD()\r\n\r\n    tensorboard_kwargs = dict(profile_batch=0, update_freq=update_freq, write_graph=False)\r\n\r\n    tensorboard_callbacks = [\r\n        tf.keras.callbacks.TensorBoard(tmpdir.join(\"tensorboard_1\"), **tensorboard_kwargs),\r\n        tf.keras.callbacks.TensorBoard(tmpdir.join(\"tensorboard_2\"), **tensorboard_kwargs)\r\n    ]\r\n    model.compile(optimizer, \"mse\")\r\n    model.fit(\r\n        dataset,\r\n        batch_size=batch_size,\r\n        callbacks=tensorboard_callbacks,\r\n        epochs=nb_epochs,\r\n        validation_data=dataset_val\r\n    )\r\n```\r\n\r\n**Stacktrace**\r\n\r\n```bash\r\n2022-03-14 13:24:44.758272: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nEpoch 1/5\r\n4/4 [==============================] - 1s 43ms/step - loss: 1.3517 - val_loss: 1.3417\r\nEpoch 2/5\r\n4/4 [==============================] - 0s 5ms/step - loss: 1.3396 - val_loss: 1.3297\r\nEpoch 3/5\r\n4/4 [==============================] - 0s 8ms/step - loss: 1.3276 - val_loss: 1.3178\r\nEpoch 4/5\r\n4/4 [==============================] - 0s 5ms/step - loss: 1.3158 - val_loss: 1.3062\r\nEpoch 5/5\r\n4/4 [==============================] - 0s 10ms/step - loss: 1.3042 - val_loss: 1.2947\r\nTraceback (most recent call last):\r\n  File \"poulet.py\", line 26, in <module>\r\n    model.fit(\r\n  File \"/Users/antoinehoorelbeke/vision/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/Users/antoinehoorelbeke/vision/venv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 93, in __exit__\r\n    _summary_state.writer.flush()\r\nAttributeError: 'NoneType' object has no attribute 'flush'\r\n```\r\n", "comments": ["@chunduriv ,\r\nI was able to reproduce the issue in tf v2.8 and nightly, where in v2.5 the code is executing without any errors.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/9209e0a369285b5a909f320771608a7b/55224.ipynb).", "@anth2o,\r\n\r\nPlease post this issue on [tensorflow/tensorboard](https://github.com/tensorflow/tensorboard/issues) repo. Thanks!\r\n", "@anth2o,\r\n\r\nCan you please close this issue, since it is tracked [there](https://github.com/tensorflow/tensorboard/issues/5639). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55224\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55224\">No</a>\n", "So for TB we need to have a global write created for summary api to work. I think somewhere in keras it trigged the api but since the write is not created, it cause errors.\r\n\r\nCould you try add the two lines before calling keras?\r\n```    \r\n    writer = tf.summary.create_file_writer(tmpdir)\r\n    with writer.as_default():\r\n      model = tf.keras.Sequential([tf.keras.layers.Dense(10)])\r\n      optimizer = tf.keras.optimizers.SGD()\r\n```\r\n\r\nAs for why the version works in 2.5 but not in 2.8, I think it goes back to see how tf.keras is implemented and use summary api v2 under the hood. \r\n\r\ncredit to @yatbear ", "Hi @japie1235813 , thanks for your answer. It doesn't seem to work:\r\n```python\r\nimport tensorflow as tf\r\ndef test(tmpdir):\r\n    batch_size = 3\r\n    nb_samples = 10\r\n    update_freq = 2\r\n    inputs = tf.random.normal((nb_samples, 2))\r\n    outputs = tf.random.normal((nb_samples, 10))\r\n    dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs)).batch(batch_size)\r\n    dataset_val = tf.data.Dataset.from_tensor_slices((inputs, outputs)).batch(batch_size)\r\n    nb_epochs = 5\r\n\r\n    writer = tf.summary.create_file_writer(str(tmpdir))\r\n\r\n    with writer.as_default():\r\n        model = tf.keras.Sequential([tf.keras.layers.Dense(10)])\r\n        optimizer = tf.keras.optimizers.SGD()\r\n\r\n        tensorboard_kwargs = dict(profile_batch=0, update_freq=update_freq, write_graph=False)\r\n        tensorboard_callbacks = [\r\n            tf.keras.callbacks.TensorBoard(tmpdir.join(\"tensorboard_1\"), **tensorboard_kwargs),\r\n            tf.keras.callbacks.TensorBoard(tmpdir.join(\"tensorboard_2\"), **tensorboard_kwargs)\r\n        ]\r\n\r\n    model.compile(optimizer, \"mse\")\r\n    model.fit(\r\n        dataset,\r\n        batch_size=batch_size,\r\n        callbacks=tensorboard_callbacks,\r\n        epochs=nb_epochs,\r\n        validation_data=dataset_val\r\n    )\r\n```\r\nstill raises the same issue", "Hi anth2o@, \r\n\r\nI think @japie1235813 meant the entire block especially the `model.fit` to be within the writer context:\r\n```\r\nimport tensorflow as tf\r\n\r\ndef test(tmpdir):\r\n    batch_size = 3\r\n    nb_samples = 10\r\n    update_freq = 2\r\n    inputs = tf.random.normal((nb_samples, 2))\r\n    outputs = tf.random.normal((nb_samples, 10))\r\n    dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs)).batch(batch_size)\r\n    dataset_val = tf.data.Dataset.from_tensor_slices((inputs, outputs)).batch(batch_size)\r\n    nb_epochs = 5\r\n\r\n    writer = tf.summary.create_file_writer(str(tmpdir))\r\n\r\n    with writer.as_default():\r\n        model = tf.keras.Sequential([tf.keras.layers.Dense(10)])\r\n        optimizer = tf.keras.optimizers.SGD()\r\n\r\n        tensorboard_kwargs = dict(profile_batch=0, update_freq=update_freq, write_graph=False)\r\n        tensorboard_callbacks = [\r\n            tf.keras.callbacks.TensorBoard(tmpdir.join(\"tensorboard_1\"), **tensorboard_kwargs),\r\n            tf.keras.callbacks.TensorBoard(tmpdir.join(\"tensorboard_2\"), **tensorboard_kwargs)\r\n        ]\r\n\r\n        model.compile(optimizer, \"mse\")\r\n        model.fit(\r\n            dataset,\r\n            batch_size=batch_size,\r\n            callbacks=tensorboard_callbacks,\r\n            epochs=nb_epochs,\r\n            validation_data=dataset_val\r\n        )\r\n```", "Hi @yatbear , indeed it works. Thanks for your answer !\r\nI tried putting only `model.fit` under the `with writer.as_default():` and it also works", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55224\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55224\">No</a>\n"]}, {"number": 55223, "title": "seq2seq.BasicDecoder not working with seq2seq.SampleEmbeddingSampler ", "body": "Tensorflow 2, my code\r\n\r\n```\r\ndef beam_evaluate_sentence(text, beam_width=3):\r\n    \r\n  # work on preprocessed text (lower, space before punctuation)\r\n  text = dataset_creator.preprocess_text(text)\r\n\r\n  text = '<start> ' + text + ' <end>'\r\n\r\n  inputs = [tokenizer.word_index[i] for i in text.split(' ')]\r\n\r\n  maxlen=len(inputs)\r\n\r\n  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n                                                          maxlen=maxlen,\r\n                                                          padding='post')\r\n\r\n  inputs = tf.convert_to_tensor(inputs)\r\n  inference_batch_size = inputs.shape[0]\r\n  result = ''\r\n\r\n  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]\r\n  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\r\n\r\n  dec_h = enc_h\r\n  dec_c = enc_c\r\n\r\n  start_tokens = tf.fill([inference_batch_size], tokenizer.word_index['<start>'])\r\n  end_token = tokenizer.word_index['<end>']\r\n  \r\n  # From official documentation\r\n  # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\r\n  # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\r\n  # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\r\n  # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\r\n\r\n  enc_out = tfa.seq2seq.tile_batch(enc_out, multiplier=beam_width)\r\n  decoder.attention_mechanism.setup_memory(enc_out)\r\n  print(\"beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 16, 1024]] :\", enc_out.shape)\r\n\r\n  # set decoder_inital_state which is an AttentionWrapperState considering beam_width\r\n  hidden_state = tfa.seq2seq.tile_batch([enc_h, enc_c], multiplier=beam_width)\r\n  decoder_initial_state = decoder.rnn_cell.get_initial_state(batch_size=beam_width*inference_batch_size, dtype=tf.float32)\r\n  decoder_initial_state = decoder_initial_state.clone(cell_state=hidden_state)\r\n\r\n  temperature_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(softmax_temperature=TEMPERATURE)\r\n\r\n  # Instantiate BasicDecoder object\r\n  decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=temperature_sampler, output_layer=decoder.fc)\r\n  # Setup Memory in decoder stack\r\n  decoder.attention_mechanism.setup_memory(enc_out)\r\n\r\n  decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\r\n\r\n  decoder_embedding_matrix = decoder.embedding.variables[0]\r\n\r\n  outputs, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens = start_tokens, end_token= end_token, initial_state=decoder_initial_state)\r\n  return outputs.sample_id.numpy()\r\n```\r\n\r\nThe problem is appearing when I switch from a greedy sampler to \r\n\r\n`  temperature_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(softmax_temperature=TEMPERATURE)\r\n`\r\n\r\nand the issue is \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/root/gen.py\", line 268, in <module>\r\n    sample_decoder_outputs = decoder(sample_x, initial_state)\r\n  File \"/root/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\",or_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/root/gen.py\", line 258, in call\r\n    outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=ax_length_output-1])\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow_addons/seq2seq/decoder.n call\r\n    return dynamic_decode(\r\n  File \"/usr/local/lib/python3.9/dist-packages/typeguard/__init__.py\", line 1033,\r\n    retval = func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow_addons/seq2seq/decoder.n dynamic_decode\r\n    initial_finished, initial_inputs, initial_state = decoder.initialize(\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow_addons/seq2seq/basic_de128, in initialize\r\n    return self.sampler.initialize(inputs, **kwargs) + (initial_state,)\r\nTypeError: Exception encountered when calling layer \"basic_decoder\" (type BasicDe\r\n\r\ninitialize() got an unexpected keyword argument 'sequence_length'\r\n\r\nCall arguments received:\r\n  \u2022 inputs=tf.Tensor(shape=(32, 17, 256), dtype=float32)\r\n  \u2022 initial_state=AttentionWrapperState(cell_state=['tf.Tensor(shape=(32, 1024),  'tf.Tensor(shape=(32, 1024), dtype=float32)'], attention='tf.Tensor(shape=(32, 1t32)', alignments='tf.Tensor(shape=(32, 17), dtype=float32)', alignment_history=(te='tf.Tensor(shape=(32, 17), dtype=float32)')\r\n  \u2022 training=None\r\n  \u2022 kwargs={'sequence_length': ['16', '16', '16', '16', '16', '16', '16', '16', ' '16', '16', '16', '16', '16', '16', '16', '16', '16', '16', '16', '16', '16', '1'16', '16', '16', '16', '16']}\r\n\r\n```", "comments": ["Hi @neqkir ! Could you please share a Colab gist or complete stand alone code ?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55223\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55223\">No</a>\n"]}, {"number": 55221, "title": "fix: incorrect sample_weight pass to metric_obj.update_state", "body": "Should pass `sw` to metric_obj.update_state, or the sample_weight from test_step will not be used when metric_obj.update_state.", "comments": []}, {"number": 55219, "title": "Update config.py to fix ##55218", "body": "Update config.py to fix ##55218", "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55219/checks?check_run_id=5530412730).", "@Gelesh  Can you please sign CLA. Thanks!", "Please use a better PR title. See https://cbea.ms/git-commit/", "@Gelesh Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "another pull request submitted"]}, {"number": 55218, "title": "Build fails to make use of bazelisk, if available.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WINDOWS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):  https://github.com/tensorflow/tensorflow.git\r\n- TensorFlow version: r2.\r\n- Python version: 3.10\r\n- Installed using virtualenv? pip? conda?: GIT\r\n- Bazel version (if compiling from source): 5.0\r\n- GCC/Compiler version (if compiling from source): 11.2\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nWhen using the [build from source](https://www.tensorflow.org/install/source_windows) https://www.tensorflow.org/install/source_windows , Even when 'bazelisk' is installed, the install run fails from config.py stating \r\n'Cannot find bazel. Please install bazel.',\r\n\r\nThis could easly be fixed, like\r\n\r\n```\r\n  if bazel_executable is None:\r\n    bazel_executable = which('bazelisk')\r\n    print('bazel_executable not found, instead using bazelisk @ ',bazel_executable)\r\n    if bazel_executable is None:\r\n        print('Cannot find bazel. Please install bazel.')\r\n        sys.exit(1)\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nRemove from path variable /Un Install bazel.\r\nInstall bazelisk.\r\n\r\nexecute ./config  or python config.py\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n**Error**: 'Cannot find bazel. Please install bazel.'\r\n", "comments": ["@Gelesh ,\r\nCan you please confirm whether you followed this step mentioned [here](https://www.tensorflow.org/install/source_windows#build_the_pip_package) which try to install the bazel?", "Yes, I referred the same, and for the next step, I used \r\n bazelisk build //tensorflow/tools/pip_package:build_pip_package\r\n instead of bazel ...\r\n", "However, .. below is the console message, I think this 404 is a different issue.\r\n\r\nINFO: Found applicable config definition build:monolithic in file c:\\users\\gomath776\\christwork\\tensorflow_renamed\\.bazelrc: --define framework_shared_object=false\r\nLoading:\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/e83168170a0d0bdf856a109187936bc44853c1b8.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found\r\n", "@gadagashwini , Please feel free to reach out, if in case the problem statement requires any clarification. One way to replicate the issue is, to un-install Bazel, and install Bazelisk .\r\nBazelisk details are [here](https://github.com/bazelbuild/bazelisk#about-bazelisk). This would be critical because [Bazel has moved](https://docs.bazel.build/versions/main/install-bazelisk.html)", "We are using bazelisk in our CI, symlinked to bazel as per instructions.", "Bazelisk symlinked to bazel  , is a work around. @mihaimaruseac , could we have it somehow fixed,", "#55272 should fix this?", "https://github.com/tensorflow/tensorflow/pull/55272 should fix this !!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55218\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55218\">No</a>\n"]}, {"number": 55216, "title": "Model.compute_loss documentation section is not correct. compute_loss function is not called", "body": "Hello,\r\n\r\n[Model.compute_loss documentation section is not correct]( https://www.tensorflow.org/api_docs/python/tf/keras/Model)\r\n\r\ncompute_loss function is not called for some reason.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nclass MyModel(tf.keras.Model):\r\n\r\n  def __init__(self, *args, **kwargs):\r\n    super(MyModel, self).__init__(*args, **kwargs)\r\n    self.loss_tracker = tf.keras.metrics.Mean(name='loss')\r\n\r\n  def compute_loss(self, x, y, y_pred, sample_weight):\r\n    tf.print(\"compute_loss is called:\")\r\n    loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\r\n    loss += tf.add_n(self.losses)\r\n    self.loss_tracker.update_state(loss)\r\n    return loss\r\n\r\n  def reset_metrics(self):\r\n    self.loss_tracker.reset_states()\r\n\r\n  @property\r\n  def metrics(self):\r\n    return [self.loss_tracker]\r\n\r\ntensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\r\ndataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)\r\n\r\ninputs = tf.keras.layers.Input(shape=(10,), name='my_input')\r\noutputs = tf.keras.layers.Dense(10)(inputs)\r\nmodel = MyModel(inputs, outputs)\r\nmodel.add_loss(tf.reduce_sum(outputs))\r\n\r\noptimizer = tf.keras.optimizers.SGD()\r\nmodel.compile(optimizer, loss='mse', steps_per_execution=10)\r\nmodel.fit(dataset, epochs=2, steps_per_epoch=10)\r\nprint('My custom loss: ', model.loss_tracker.result().numpy())\r\n```\r\n\r\n'compute_loss is called:' is not printed.  Checked on tensorflow 2.6.2", "comments": ["@snarb I tried to replicate the code on  colab using `TF 2.8.0` ,and didn't face any error reported . Could you please have a look at the gist [here](https://colab.research.google.com/gist/sushreebarsa/b1cc373d83195ad065dbfd601e7f0544/55216.ipynb) and let us know if it helps?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sushreebarsa  Hi. I have checked. The mentioned problem exists on 2.6 and 2.7, but not on 2.8. Thank you!", "@snarb Thank you for the update!\r\nCould you please move this issue to closed status as it is resolved for you?\r\nThanks!", "@sushreebarsa  yes.  Resolved for me. Thanks", "@snarb Closing this issue as it is fixed in latest version of TensorFlow.  Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55216\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55216\">No</a>\n"]}, {"number": 55215, "title": "Crashed if using negative num_streams in QuantileOpsTest", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.7.11\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nQuantileOpsTest got crashed if using negative parameters in _create_quantile_stream_resource_() in tf 2.5.0. When running the same test case in tf 2.6.0, it would not crash and printed error info.\r\n\r\n**Describe the expected behavior**\r\nThe test case sould fail and give relative error information.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nI ran the following code named bug3.py:\r\n```\r\nfrom tensorflow.python.framework import test_util\r\nfrom tensorflow.python.ops import boosted_trees_ops\r\nfrom tensorflow.python.ops import resources\r\nfrom tensorflow.python.ops.gen_boosted_trees_ops import boosted_trees_quantile_stream_resource_handle_op as resource_handle_op\r\nfrom tensorflow.python.ops.gen_boosted_trees_ops import is_boosted_trees_quantile_stream_resource_initialized as resource_initialized\r\nfrom tensorflow.python.platform import googletest\r\n\r\n@test_util.run_deprecated_v1\r\nclass QuantileOpsTest(test_util.TensorFlowTestCase):\r\n\r\n    def setUp(self):\r\n        self.eps = 0.01\r\n        self.max_elements = (1 << 16)\r\n\r\n    def testBasicQuantileBucketsSingleResourcesAddFlushed(self):\r\n        with self.cached_session():\r\n            quantile_accumulator_handle = resource_handle_op(container='', shared_name='floats_0', name='floats_0')\r\n            create_op = boosted_trees_ops.create_quantile_stream_resource(quantile_accumulator_handle, epsilon=self.eps,\r\n                                                                              max_elements=self.max_elements,\r\n                                                                              num_streams= -2 )\r\n            \r\n            is_initialized_op = resource_initialized(quantile_accumulator_handle)\r\n            resources.register_resource(quantile_accumulator_handle, create_op, is_initialized_op)\r\n            resources.initialize_resources(resources.shared_resources()).run()\r\n\r\nif (__name__ == '__main__'):\r\n    googletest.main()\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nHere is the log in tf 2.5.0:\r\n```\r\n[ RUN      ] QuantileOpsTest.testBasicQuantileBucketsSingleResourcesAddFlushed\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-03-14 05:21:01.193346: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2097635000 Hz\r\nterminate called after throwing an instance of 'std::length_error'\r\n  what():  vector::reserve\r\nFatal Python error: Aborted\r\n\r\nThread 0x00007efcd9c1b180 (most recent call first):\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1453 in _call_tf_sessionrun\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1360 in _run_fn\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1375 in _do_call\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1369 in _do_run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1191 in _run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 968 in run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/framework/test_util.py\", line 1729 in run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 5578 in _run_using_default_session\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2625 in run\r\n  File \"test_bug/bug3.py\", line 24 in testBasicQuantileBucketsSingleResourcesAddFlushed\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/framework/test_util.py\", line 1345 in decorated\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/case.py\", line 628 in run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/case.py\", line 676 in __call__\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/suite.py\", line 122 in run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/suite.py\", line 84 in __call__\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/suite.py\", line 122 in run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/suite.py\", line 84 in __call__\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/runner.py\", line 176 in run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/_pretty_print_reporter.py\", line 87 in run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/main.py\", line 271 in runTests\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/main.py\", line 101 in __init__\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/absltest.py\", line 2553 in _run_and_get_tests_result\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/absltest.py\", line 2585 in run_tests\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/absltest.py\", line 2172 in _run_in_app\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/absltest.py\", line 2065 in main\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/platform/googletest.py\", line 55 in g_main\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/app.py\", line 258 in _run_main\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/app.py\", line 312 in run\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/platform/googletest.py\", line 64 in main_wrapper\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/platform/benchmark.py\", line 518 in benchmarks_main\r\n  File \"/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/platform/googletest.py\", line 66 in main\r\n  File \"test_bug/bug3.py\", line 28 in <module>\r\nAborted (core dumped)\r\n```\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55215\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55215\">No</a>\n"]}, {"number": 55213, "title": "support vscode devcontiners for development", "body": "**System information**\r\n- TensorFlow version (you are using): latest\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nsupport for vscode devcontainers is required for good dependency management and overall good support for modern development\r\n", "comments": ["@sampath017 \r\nCan you please elaborate about your feature and please specify the use cases for this feature. Thanks!", "i found the preconfigured development docker images on tensorflow website, so they can we used as vscode devcontainers."]}, {"number": 55212, "title": "Example code of tfd.Independent seems to be incorrect.", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Independent\r\n\r\n## Description of issue (what needs changing):\r\nThe example code provided seems to be incorrect.\r\nIn my understanding ind.batch_shape should be [2] and even_shape should be [3].\r\n\r\n```\r\n# Make independent distribution from a 2-batch bivariate Normal.\r\n  ind = tfd.Independent(\r\n      distribution=tfd.MultivariateNormalDiag(\r\n          loc=[[-1., 1], [1, -1]],\r\n          scale_identity_multiplier=[1., 0.5]),\r\n      reinterpreted_batch_ndims=1)\r\n\r\n# All batch dims have been 'absorbed' into event dims.\r\nind.batch_shape  # ==> []\r\nind.event_shape  # ==> [2, 2]\r\n```\r\n", "comments": ["@matthewlujp ,\r\nThis issue is more related to tensorflow propability(tfp).Can you please post the issue in tensorflow/probability repo from [here](https://github.com/tensorflow/probability/issues) to resolve the issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 55211, "title": "Early Stopping time - after 100,000 iterations ", "body": "**System information**\r\n- I have used multiple custom classes to optimize the training time\r\n- OS Linux Ubuntu 18.04):\r\n- TensorFlow installed from binary\r\n- TensorFlow 2.5\r\n- Python 3.6:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN 11.2 / 8.5\r\n- GPU Test T4 \r\n\r\n****\r\n\r\nplease see below 100k iterations, what is the time Early stopping is required to prevent overfitting. \r\n\r\n![image](https://user-images.githubusercontent.com/47017344/158029847-344d56f9-ad75-4d89-8deb-7708f6923f0f.png)\r\n\r\n", "comments": ["Is the plot, talking about training loss or validation loss. ?\r\nEarly stopping is required when, validation loss is increasing to answer 'what is the time Early stopping is required to prevent overfitting ? '.\r\nIm sorry I dont understand the bug/issue being raised over here  ", "@awaisbajwaml,\r\n\r\nGenerally we used `EarlyStopping` to stop training when a monitored metric has stopped improving. For more details you can refer [here](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping).\r\n\r\nCan you please elaborate your issue and share standalone code to investigate? Thanks!    \r\n\r\n\r\n", "@awaisbajwaml , as you mentioned , 'EarlyStopping to stop training when a monitored metric has stopped improving', mostly /default validation loss. \r\nMy question is, \r\n1. )was the plot attached above, is for validation loss.\r\n2) .  \" what is the time Early stopping is required to prevent overfitting \" , I feel, this as a question about the framework, and not a BUG/ISSUE to be raised. Or am I missing the BUG/ISSUE part of the concern \r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@Gelesh  this is training loss, not a validation one. ", " , To my understanding, Early stopping is supposed to configured to monitor the loss function on validation , and called from CallBacks.  Please refer my earlier comments.\r\n\r\n\" _Early stopping is required when, validation loss is increasing to answer 'what is the time Early stopping is required to prevent overfitting ? '. Im sorry I dont understand the bug/issue being raised over here_.\" \r\n\r\n@awaisbajwaml, Do you mean you have set up the EarlyStoppingCallBack , monitoring on Training Loss ? If so, I am not sure how would it serve the purpose of preventing over fitting. However, from the graph, the loss is decreasing, hence the trend shouldnt trigger any EarlyStop. ", "@awaisbajwaml,\r\n\r\nEarly stopping allows you to specify an arbitrarily large number of training epochs and stop training once the model performance stops improving on the validation dataset.\r\n\r\nFollow the training procedure mentioned [here](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#training_procedure) to avoid overfitting with earlystopping function. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55211\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55211\">No</a>\n"]}, {"number": 55209, "title": "tf.matmul() fails with ragged inputs of shape [batch_size, None, dims] and transpose_b=True", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 11.2 \"bullseye\" (keras-dev docker image)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.1-72504-gfeb9095a53f 2.9.0-dev20220311\r\n- Python version: 3.9.10\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nWhen A and B are two ragged tensors, both of shape [batch_size, None, dims], then `tf.matmul(A, B, transpose_b=True)` fails. However, when A and B are ragged tensors of shape [batch_size, None, None], with the exact same values, then it works fine.\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect the first scenario to work, and it should return the same result as the second scenario.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): not sure I'll have time, but if it's not too long ok\r\n- Briefly describe your candidate solution(if contributing): I'm guessing there's a bug in the shape checks in `tf.matmul()` since I see no reason why [batch_size, None, dims] would fail while [batch_size, None, None] would succeed. If anything, I would have expected the opposite.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nSee this [gist](https://colab.research.google.com/gist/ageron/1226921dbd2be65dc69f12847f2c229b/tensorflow-issue-matmul-ragged.ipynb).\r\n\r\nThis code fails:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nA_ids = tf.ragged.constant([[1, 2], [1, 0, 5]])\r\nB_ids = tf.ragged.constant([[2, 4, 6, 9], [3]])\r\nembedding_layer = tf.keras.layers.Embedding(10, 3)\r\nA = embedding_layer(A_ids)  # A has shape [2, None, 3]\r\nB = embedding_layer(B_ids)  # B has shape [2, None, 3]\r\nC = tf.matmul(A, B, transpose_b=True)  # RAISES AN InvalidArgumentError!!!\r\n```\r\n\r\nBut this one succeeds:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nA = tf.ragged.constant([  # A has shape [2, None, None]\r\n    [[1., 2., 3.], [3., 4., 5.]],\r\n    [[1., 3., 5.], [5., 7., 9.], [9., 11., 13.]]\r\n])\r\nB = tf.ragged.constant([  # B has shape [2, None, None]\r\n    [[10., 20., 30.], [30., 40., 50.], [50., 60., 70.], [70., 80., 90.]],\r\n    [[11., 21., 31.]]\r\n])\r\n\r\nC = tf.matmul(A, B, transpose_b=True)  # WORKS FINE NOW!\r\n```\r\n\r\nThe only difference I can see is that the shape of `A` and `B` is `[2, None, 3]` in the first case, but it's `[2, None, None]` in the second case. It doesn't make sense.\r\n\r\n**Other info / logs**\r\n\r\nBelow is the full stacktrace:\r\n\r\n<details>\r\n\r\n```stacktrace\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n[<ipython-input-8-3e4e536edcee>](https://localhost:8080/#) in <module>()\r\n      6 A = embedding_layer(A_ids)  # A has shape [2, None, 3]\r\n      7 B = embedding_layer(B_ids)  # B has shape [2, None, 3]\r\n----> 8 C = tf.matmul(A, B, transpose_b=True)  # ERROR!\r\n\r\n1 frames\r\n[/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py](https://localhost:8080/#) in error_handler(*args, **kwargs)\r\n    151     except Exception as e:\r\n    152       filtered_tb = _process_traceback_frames(e.__traceback__)\r\n--> 153       raise e.with_traceback(filtered_tb) from None\r\n    154     finally:\r\n    155       del filtered_tb\r\n\r\n[/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py](https://localhost:8080/#) in raise_from_not_ok_status(e, name)\r\n   7184 def raise_from_not_ok_status(e, name):\r\n   7185   e.message += (\" name: \" + name if name is not None else \"\")\r\n-> 7186   raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\n   7187 \r\n   7188 \r\n\r\nInvalidArgumentError: All flat_values must have compatible shapes.  Shape at index 0: [4].  Shape at index 1: [1].  If you are using tf.map_fn, then you may need to specify an explicit fn_output_signature with appropriate ragged_rank, and/or convert output tensors to RaggedTensors. [Op:RaggedTensorFromVariant]\r\n```\r\n\r\n</details>\r\n\r\n**Related issues**\r\n\r\n* This TF issue is probably the cause of this Keras issue: https://github.com/keras-team/keras/issues/16226\r\n* There's a closed issue about TF matmul + ragged tensors, but I think it's different: https://github.com/tensorflow/tensorflow/issues/28109\r\n", "comments": ["Until this issue is fixed, here's a workaround: the following function sets the last dimension to `None`, so the `matmul()` operation succeeds.\r\n\r\n```python\r\n@tf.function\r\ndef unset_outer_dimension(ragged_3d):\r\n  row_lengths = ragged_3d.row_lengths()\r\n  total_steps = tf.reduce_sum(row_lengths, keepdims=True)\r\n  dims = ragged_3d.shape[-1]\r\n  outer_row_lengths = tf.cast(tf.fill(total_steps, dims), tf.int64)\r\n  return tf.RaggedTensor.from_nested_row_lengths(\r\n    tf.reshape(ragged_3d.flat_values, [-1]),\r\n    nested_row_lengths=[row_lengths, outer_row_lengths])\r\n```\r\n\r\nHere's how it can be used (you only need to apply it to the second `matmul()` input):\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nA_ids = tf.ragged.constant([[1, 2], [1, 0, 5]])\r\nB_ids = tf.ragged.constant([[2, 4, 6, 9], [3]])\r\nembedding_layer = tf.keras.layers.Embedding(10, 3)\r\nA = embedding_layer(A_ids)  # A has shape [2, None, 3]\r\nB = embedding_layer(B_ids)  # B has shape [2, None, 3]\r\nC = tf.matmul(A, unset_outer_dimension(B), transpose_b=True)  # WORKS FINE NOW\r\n```\r\n\r\nI just checked the performance: `unset_outer_dimension()` does not seem to impact performance. However, I also benchmarked `tf.matmul()` between two regular tensors: it took about 28 \u00b5s microseconds per loop on CPU, versus 8100 \u00b5s (8.1 ms) for ragged tensors. Yikes! `tf.matmul()` with ragged tensors is almost 300 times slower than with regular tensors! On GPU (Colab), the difference is not as large, about 20 times slower. But performance is a separate issue.", "@gadagashwini Was able to replicate the issue on colab using TF [v2.8.0 ](https://colab.research.google.com/gist/sushreebarsa/e8b58c31cb9de99641fd3322dec6c78d/tensorflow-issue-matmul-ragged.ipynb), [nightly](https://colab.research.google.com/gist/sushreebarsa/1737ae9a7d4b0e1acb5d1a852299477f/tensorflow-issue-matmul-ragged.ipynb#scrollTo=SXr2SghiO1Y_)(2.9.0.dev20220313), please find the attached gists for reference. Thanks!", "Thanks for reporting this!  Fixed in abc6f6ec7869d846b33b3d8e5e33284aac1600dc.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55209\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55209\">No</a>\n"]}, {"number": 55208, "title": "Comment", "body": "<spam>", "comments": ["@GodsNightmare ,\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "spam"]}, {"number": 55206, "title": "Saving Resource Variables without Copy", "body": "Provides a solution for the increase in memory usage when saving models with large sparsely accessed resource variables by avoiding the copying of the variables. The kernel of `ReadVariableOp` is modified to convert variables that were sparsely accessed from copy-on-read mode to copy-on-write mode under an exclusive lock. The conversion is disabled in the default setting and only occurs when the Python function `_read_variable_op` is called from class `ResourceVariableSaveable` during the saving of resource variables.\r\n\r\nSee issue [#54104](https://github.com/tensorflow/tensorflow/issues/54105).", "comments": ["I don't like that `ReadVariableOp` does this COR-to-COW conversion as a side effect (even if it only happens when `no_copy` is true). How about adding a new op `TurnOffCopyOnRead` to do this job?", "Thanks for the comment. I've introduced a new `ReadVariableWithoutCopyOp`, which is exclusively called when saving resource variables. For copy-on-write variables, the op behaves like `ReadVariableOp`. For copy-on-read variables, the kernel again acquires an exclusive mutex, but avoids the side effect by directly reading the variable instead of changing its type.", "The new `DisableCopyOnReadOp` is called when a resource variable is saved.", "Thanks for the update! Overall looks good, except for some minor issues.", "I can't reproduce the PyLint error, and I don't see any lines that are longer than 80 characters in the diff.", "Maybe the test was against an older version. Or maybe it's caused by whitespaces. (CCing @mihaimaruseac who may know more.)", "Rerunning the pylint job, seems to have been using an old version?\r\n\r\nAnyway, if still broken, please ignore.", "Hi @philipphack  Can you please fix build failures? Thank you!", "There are some `api_compatibility_test` CI failures. Please run `bazel run //tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens True` to update the API golden files.", "This fails with `ModuleNotFoundError: No module named 'tensorflow.core.kernels'`.\r\n", "Seems your Python paths are not set up properly. I'll try fixing the CI errors internally."]}, {"number": 55204, "title": "Minor fix in XLIR gated code region of gpu_compiler.", "body": "/cc @chsigg @cheshire @jurahul ", "comments": ["Closing this since I am not sure of its correctness."]}, {"number": 55202, "title": "google.protobuf.message.DecodeError: Error parsing message with type 'tensorflow.GraphDef'", "body": "I trained the model and saved it, now I am trying to load but unable to do. I have seen in previous post as well, but reference links are not working.\r\n\r\n**Code**\r\n\r\n```\r\n`#load model\r\n\r\nwith tf.io.gfile.GFile(args.model, \"rb\") as f:\r\n    graph_def = tf.compat.v1.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n\r\n# with tf.Graph().as_default() as graph:\r\ngenerated_image_1, generated_image_2, generated_image_3, = tf.graph_util.import_graph_def(\r\n        graph_def, \r\n        input_map={'input_image' : input_tensor, 'short_edge_1' : short_edge_1, 'short_edge_2' : short_edge_2, 'short_edge_3' : short_edge_3}, \r\n        return_elements=['style_subnet/conv-block/resize_conv_1/output:0', 'enhance_subnet/resize_conv_1/output:0', 'refine_subnet/resize_conv_1/output:0'],  \r\n        producer_op_list=None\r\n    )`\r\n```\r\n\r\n**Error:**\r\n\r\n```\r\n`Traceback (most recent call last):\r\n  File \"stylize.py\", line 97, in <module>\r\n    main()\r\n  File \"stylize.py\", line 57, in main\r\n    graph_def.ParseFromString(f.read())\r\ngoogle.protobuf.message.DecodeError: Error parsing message with type 'tensorflow.GraphDef'`\r\n```\r\n\r\nNote: I am using,\r\npython = 3.7.6\r\nTensorflow-gpu=1.15\r\ntensorboard=1.15.0\r\nprotobuf =3.19.4", "comments": ["@shubhambagwari ,\r\nWe see that you are using tf version 1.15, 1.x is not actively supported, please update to latest tensorflow v2.8 and let us know if you are facing same issue.", " @tilakrayal I updated tensorflow version to 2.7, still not resolved.\r\n  File \"stylize.py\", line 107, in <module>\r\n    main()\r\n  File \"stylize.py\", line 52, in main\r\n    graph = load_graph(args.model)\r\n  File \"stylize.py\", line 15, in load_graph\r\n    graph_def.ParseFromString(f.read())\r\n  File \"C:\\Users\\shubham\\env\\lib\\site-packages\\google\\protobuf\\message.py\", line 199, in ParseFromString\r\n    return self.MergeFromString(serialized)\r\n  File \"C:\\Users\\shubham\\env\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\", line 1145, in MergeFromString\r\n    if self._InternalParse(serialized, 0, length) != length:\r\n  File \"C:\\Users\\shubham\\env\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\", line 1198, in InternalParse\r\n    (data, new_pos) = decoder._DecodeUnknownField(\r\n  File \"C:\\Users\\shubham\\env\\lib\\site-packages\\google\\protobuf\\internal\\decoder.py\", line 993, in _DecodeUnknownField\r\n    raise _DecodeError('Wrong wire type in tag.')\r\ngoogle.protobuf.message.DecodeError: Wrong wire type in tag.", "@shubhambagwari ,\r\nIn order to expedite the trouble-shooting process, could you please provide a complete code snippet  you are using.", "Can you please take a look at this [SO link](https://stackoverflow.com/questions/65142116/using-tensorflow-google-protobuf-message-decodeerror-wrong-wire-type-in-tag) with the similar error.It helps.Thanks!", "Can you mail me @ subbu.bagwari@gmail.com", "@shubhambagwari ,\r\nCan you please provide the code and the dependencies here or in colab gist.Thanks!"]}, {"number": 55200, "title": "Test to cover the `import_meta_graph` error on MutableHashTable", "body": "https://github.com/tensorflow/tensorflow/issues/24439\r\n\r\nAs this wasn't fixed since 2018 I think it is better to cover it with a test.", "comments": ["@bhack Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!\r\n", "@gbaned What do you mean? Do you see any @mihaimaruseac's comments here?", "> @gbaned What do you mean? Do you see any @mihaimaruseac's comments here?\r\n\r\n@bhack It is my bad, my sincere apologies for the above comment. Thank you.", "Can we re-run tests for the linting?", "> Can we re-run tests for the linting?\r\n\r\nHi @bhack  Still, PyLint errors are appearing after ran the tests. Thank you. ", "> Hi @bhack Still, PyLint errors are appearing after ran the tests. Thank you.\r\n\r\nYou need to re-run CI today as https://github.com/tensorflow/tensorflow/pull/55464 was merged < 24 hours ago.", "@mihaimaruseac Something is not working. The PyLint Action was executed ( failed <relative-time datetime=\"2022-03-30T20:26:16Z\" class=\"no-wrap\">Mar 30, 2022</relative-time> in 43s )", "We need to run Pylint again as PyLint failed 6 days ago in 43s ", "Apparently that one is not triggered by the kokoro label but by gitHub buttons", "> Apparently that one is not triggered by the kokoro label but by gitHub buttons\r\n\r\nYes but I don't have the permission on this repo ", "@mihaimaruseac Can you push the Action button for pylint?"]}, {"number": 55199, "title": "Missing input validation on `tf.ragged.constant`", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version (use command below):2.8.0\r\n- Python version: 3.7.12\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: using a colab notebook\r\n- GPU model and memory: using a colab notebook\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nIf I pass an empty list with a large ragged_rank to `tf.ragged.constant`,\r\nall RAM is consumed, causing the notebook to crash.\r\nThe docs indicate that ragged_rank should be between 0 and the rank of pylist, so the large value of ragged_rank should be rejected\r\n\r\n**Describe the expected behavior**\r\n\r\nSome input validation should be done and an exception thrown.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nThe colab notebook:\r\nhttps://colab.research.google.com/drive/1OyQNTCiqHKjmHKfYbSOmVt4EfkLEgsNA?usp=sharing\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@kanghj In order to expedite the trouble-shooting process ,could you please provide the access to the colab ? Thanks!", "Sorry, my bad, @sushreebarsa. I have updated the access permissions to the colab. Could you try again?  https://colab.research.google.com/drive/1OyQNTCiqHKjmHKfYbSOmVt4EfkLEgsNA?usp=sharing", "@gadagashwini I was able to replicate the issue on colab using TF v2.8.0 and tf-nightly , please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/11d6f95170371155c6e464b721f57a77/55199.ipynb) for reference.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55199\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55199\">No</a>\n"]}, {"number": 55198, "title": "Fail to convert trained model to TensorFlow Lite (integer only and unsigned integer)", "body": "\r\n\r\n### 1. System information\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installation: pip package\r\n- TensorFlow library: 2.4.0\r\n- tensorflow-model-optimization: 0.7.1.\r\n\r\n### 2. Code\r\n(int8 conversion)\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.allow_custom_ops = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT] # require representative dataset\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.int8 \r\nconverter.inference_output_type = tf.int8 \r\n\r\nconverter.representative_dataset = representative_data_gen\r\ntflite_int8_model = converter.convert()\r\n```\r\n\r\n(uint8 conversion)\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.uint8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n\r\ntflite_uint8_model = converter.convert()\r\n```\r\n\r\nI'm trying to apply post-training quantization to the trained model, the model is built and trained through TensorFlow2 functional API. However, for conversion of integer only, the converter generates the error message: `Model output is not dquntized.` when executing converter.convert(); for conversion of unsigned integer, the converter generates the error message: `the inference_input_type and inference_output_type must be tf.float32.` if I assigned `converter.target_spec.supported_ops = [tf.uint8]`, `converter.inference_input_type = tf.uint8`, and `converter.inference_output_type = tf.uint8`.\r\n![keras_to_int8_error](https://user-images.githubusercontent.com/8951991/157827139-3259fa6a-8a63-4b89-acb6-55efa0b98e92.png)\r\n\r\n![keras_to_uint8_error](https://user-images.githubusercontent.com/8951991/157827152-aa8e4b0c-7425-455d-96af-dbdc9f3d378e.png)\r\n\r\n\r\nAre there settings required to convert the trained model to int8 and uint8 precision?\r\n\r\nBest Regards,\r\nRahn", "comments": ["@Rahn80643 ,\r\nIn order to expedite the trouble-shooting process, could you please provide a complete code and also please try to test your the code in latest tensorflow version 2.8 and let us know if you are facing same issue.Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55198\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55198\">No</a>\n"]}, {"number": 55196, "title": "[TF-TRT] Add engine device to `converter.summary()`", "body": "This PR adds the TRTEngineOP device to the `converter.summary()` report.", "comments": ["This goes in the direction to be able to debug and assess:\r\n```\r\nwith tf.device(\"/gpu:1\"):\r\n    converter.convert()\r\n```", "@bixia1 any feedback ?", "Can you provide a PR description on the first block?", "@bixia1 done. Can you approve"]}, {"number": 55195, "title": "TensorFlowLiteSwift ld: 4 duplicate symbols for architecture arm64", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\nBIG SUR 11.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nALL\r\n- TensorFlow installed from (source or binary):\r\nfrom cocoapods pod install \r\n- TensorFlow version:\r\n  pod 'TensorFlowLiteSwift', '~> 2.7.0'\r\n  pod 'TensorFlowLiteSelectTfOps', '~> 2.7.0'\r\n- Python version:\r\nN/A\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nBuild error for TensorFlowLiteSwift', '~> 2.7.0' and TensorFlowLiteSelectTfOps', '~> 2.7.0'... \r\nerror:\r\nld: 4 duplicate symbols for architecture arm64\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nSteps to reproduce: \r\ndownload sample project https://github.com/tensorflow/examples\r\nchange tensorflow versions in podfile to 2.7.0\r\npod install \r\nrun the project from the xcworkspace file \r\n\r\n**Any other info / logs**\r\nduplicate symbol '_TfLiteXNNPackDelegateCreate' in:\r\n    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)\r\n    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC\r\nduplicate symbol '_TfLiteXNNPackDelegateDelete' in:\r\n    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)\r\n    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC\r\nduplicate symbol '_TfLiteXNNPackDelegateGetThreadPool' in:\r\n    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)\r\n    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC\r\nduplicate symbol '_TfLiteXNNPackDelegateOptionsDefault' in:\r\n    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)\r\n    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC\r\nld: 4 duplicate symbols for architecture arm64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["found duplicate..... ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55195\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55195\">No</a>\n"]}, {"number": 55193, "title": "[oneDNN] Fix to some benchmark tests when GPU is not available", "body": "Currently, the following test `//tensorflow/core/kernels:nn_ops_test_cpu` has GPU related tests that need to be skipped. This PR fixes two issues on CPU with the current benchmark test:\r\n\r\n1. A plain `return` statement in the benchmark function does not truly return, rather the system remains unresponsive.  So `state.SkipWithError(..)` is added in this PR for truely skipping the test when GPU is not available.\r\n\r\n2. Some of the benchmark tests missed the skipping code when GPU is not available. This PR fixes those cases.", "comments": ["@chsigg Any update on this PR review?", "@gbaned @chsigg Any update on this PR review?", "@cantonios Could you help understanding the error from import/copybara. We are not able to see the error. ", "copybara was just stalled because I was away and nobody else looked at it.  The windows failure seems unrelated.  Should go through soon..ish."]}]