[{"number": 30849, "title": "tf.data.experimental.make_csv_dataset cannot decompress files", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.5 (but also tested in RedHat 7)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): pip3\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: CPU\r\n\r\n**Describe the current behavior**\r\n`tf.contrib.data.make_csv_dataset` cannot decompress gzip files\r\n\r\n**Describe the expected behavior**\r\nWhen `compression_type` is set to GZIP, it should decompress a gzip file\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```python3\r\nimport tensorflow as tf\r\nimport pandas as pd\r\n\r\nsample_iris = {\r\n    'Id': [1,2,3],\r\n    'SepalLengthCm': [5.1, 4.9, 4.7],\r\n    'SepalWidth': [3.5, 3.0, 3.2],\r\n    'Sepcies': ['Iris-setosa', 'Iris-setosa', 'Iris-setosa']\r\n}\r\n\r\ndf = pd.DataFrame(sample_iris)\r\ndf.to_csv('Iris-compressed.csv.gz', compression='gzip', index=False)\r\n\r\ntrain_files = ['Iris-compressed.csv.gz']\r\ntrain_batch_size = 4\r\nselect_columns = ['Id','SepalLengthCm','SepalWidthCm','Species']\r\n\r\ndataset = tf.data.experimental.make_csv_dataset(\r\n    train_files,\r\n    train_batch_size,\r\n    column_names=None,\r\n    column_defaults=None,\r\n    label_name='Species',\r\n    select_columns=select_columns,\r\n    field_delim=',',\r\n    use_quote_delim=True,\r\n    na_value='',\r\n    header=True,\r\n    num_epochs=None,\r\n    shuffle=True,\r\n    shuffle_buffer_size=100,\r\n    shuffle_seed=None,\r\n    prefetch_buffer_size=tf.data.experimental.AUTOTUNE,\r\n    num_parallel_reads=1,\r\n    sloppy=True,\r\n    num_rows_for_inference=100,\r\n    compression_type=tf.constant('GZIP')\r\n)\r\n```\r\n\r\nAs a sanity check,\r\n\r\n```bash\r\ngunzip Iris-compressed.csv.gz && cat Iris-compressed.csv\r\n```\r\n\r\nworks as expected, returning \r\n\r\n```\r\n1,5.1,3.5,Iris-setosa\r\n2,4.9,3.0,Iris-setosa\r\n3,4.7,3.2,Iris-setosa\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 38, in <module>\r\n    compression_type=tf.constant('GZIP')\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py\", line 547, in make_csv_dataset_v1\r\n    compression_type, ignore_errors))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py\", line 434, in make_csv_dataset_v2\r\n    column_names = _infer_column_names(filenames, field_delim, use_quote_delim)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py\", line 164, in _infer_column_names\r\n    column_names = next(csv.reader(f, **csv_kwargs))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 220, in __next__\r\n    return self.next()\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 214, in next\r\n    retval = self.readline()\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 179, in readline\r\n    return self._prepare_value(self._read_buf.ReadLineAsString())\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 98, in _prepare_value\r\n    return compat.as_str_any(val)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/util/compat.py\", line 117, in as_str_any\r\n    return as_str(value)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/util/compat.py\", line 87, in as_text\r\n    return bytes_or_text.decode(encoding)\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\r\n```", "comments": ["I think the issue is that, `make_csv_dataset` will try to probe the column name automatically if not present. In order to \"probe\" the column automatically, it use python's `csv` module to check for the first line of the file. But the compression_type was not accounted for in this situation.  Once column is available then internally CsvDataset process the file correctly, though.\r\n\r\nCreated a PR #30867 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30849\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30849\">No</a>\n"]}, {"number": 30848, "title": "Update metric_ops.py for incorrect docstring", "body": "Incorrect description and this is a new PR against master [@rthadur ](https://github.com/tensorflow/tensorflow/pull/30845#issuecomment-512882696)", "comments": ["@Meelfy , can you please check sanity check here https://source.cloud.google.com/results/invocations/a7537b36-1e92-4533-8c51-83bd40523080/log", "The patch branch is already deleted so I can't edit it anymore. I will open a new PR and fix the C0301(line-too-long) error in sanity check. "]}, {"number": 30847, "title": "DistributedDataset iteration fails with data of type string", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.5 LTS \r\n- TensorFlow installed from (source or binary): conda\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: 8 x Tesla P100-PCIE-16GB \r\n\r\n**Describe the current behavior**\r\nI have noticed an issue while iterating over a DistributedDataset (using a tf.distribute.MirroredStrategy) that contains data of type string, with eager execution enabled.\r\nIterating works perfectly well, but a RuntimeError is raised once the end of the dataset is reached (cf logs below).\r\n\r\n**Describe the expected behavior**\r\nThe exception is never raised if the dataset does not contain string data, iteration stops and the rest of the code is executed. \r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\nprint('TensorFlow version: {}'.format(tf.__version__))\r\n\r\nraw = tf.random.uniform([256, 20], maxval=10, dtype=tf.int32)\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nprint('Number of replicas: {}'.format(strategy.num_replicas_in_sync))\r\n\r\ndataset_1 = tf.data.Dataset.from_tensor_slices(raw)\r\ndataset_1 = dataset_1.batch(64)\r\n\r\ndataset_2 = tf.data.Dataset.from_tensors(['This is a test']).repeat(256).batch(64)\r\n\r\ndist_dataset_1 = strategy.experimental_distribute_dataset(dataset_1)\r\ndist_dataset_2 = strategy.experimental_distribute_dataset(dataset_2)\r\n\r\nprint('Iterating over datataset_2')\r\nfor i, example in enumerate(dataset_2):\r\n    print('Batch #{}'.format(i))\r\n\r\nprint('Iterating over distributed dataset_1')\r\nfor i, example in enumerate(dist_dataset_1):\r\n    print('Batch #{}'.format(i))\r\n    \r\nprint('Iterating over distributed datataset_2')\r\nfor i, example in enumerate(dist_dataset_2):\r\n    print('Batch #{}'.format(i))\r\n```\r\n**Other info / logs**\r\n```\r\nTensorFlow version: 1.14.0\r\nNumber of replicas: 8\r\nIterating over datataset_2\r\nBatch #0\r\nBatch #1\r\nBatch #2\r\nBatch #3\r\nIterating over distributed dataset_1\r\nBatch #0\r\nBatch #1\r\nBatch #2\r\nBatch #3\r\nIterating over distributed datataset_2\r\nBatch #0\r\nBatch #1\r\nBatch #2\r\nBatch #3\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-18-730d6b0450e9> in <module>\r\n     25 \r\n     26 print('Iterating over distributed datataset_2')\r\n---> 27 for i, example in enumerate(dist_dataset_2):\r\n     28     print('Batch #{}'.format(i))\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in __next__(self)\r\n    225   def __next__(self):\r\n    226     try:\r\n--> 227       return self.get_next()\r\n    228     except errors.OutOfRangeError:\r\n    229       raise StopIteration\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in get_next(self, name)\r\n    254       return data\r\n    255 \r\n--> 256     global_has_value, replicas = _get_next_as_optional(self, self._strategy)\r\n    257     results = []\r\n    258     for i, worker in enumerate(self._input_workers.worker_devices):\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in _get_next_as_optional(iterator, strategy, name)\r\n    160     with ops.device(worker):\r\n    161       worker_has_value, next_element = (\r\n--> 162           iterator._iterators[i].get_next_as_list(new_name))  # pylint: disable=protected-access\r\n    163       # Collective all-reduce requires explict devices for inputs.\r\n    164       with ops.device(\"/cpu:0\"):\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in get_next_as_list(***failed resolving arguments***)\r\n    719               data.has_value(),\r\n    720               lambda: data.get_value(),\r\n--> 721               lambda: _dummy_tensor_fn(data.value_structure))\r\n    722           result.append(real_data)\r\n    723           # pylint: enable=cell-var-from-loop\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    505                 'in a future version' if date is None else ('after %s' % date),\r\n    506                 instructions)\r\n--> 507       return func(*args, **kwargs)\r\n    508 \r\n    509     doc = _add_deprecated_arg_notice_to_docstring(\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in cond(pred, true_fn, false_fn, strict, name, fn1, fn2)\r\n   1955         result = true_fn()\r\n   1956       else:\r\n-> 1957         result = false_fn()\r\n   1958       if not strict:\r\n   1959         result = _UnpackIfSingleton(result)\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in <lambda>()\r\n    719               data.has_value(),\r\n    720               lambda: data.get_value(),\r\n--> 721               lambda: _dummy_tensor_fn(data.value_structure))\r\n    722           result.append(real_data)\r\n    723           # pylint: enable=cell-var-from-loop\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in _dummy_tensor_fn(value_structure)\r\n    637   for feature_shape, feature_type in zip(value_structure._flat_shapes,\r\n    638                                          value_structure._flat_types):\r\n--> 639     result.append(create_dummy_tensor(feature_shape, feature_type))\r\n    640 \r\n    641   if isinstance(value_structure, structure.NestedStructure):\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in create_dummy_tensor(feature_shape, feature_type)\r\n    630 \r\n    631     # Create the dummy tensor.\r\n--> 632     dummy_tensor = array_ops.zeros(tensor_shape.TensorShape(dims), feature_type)\r\n    633     return dummy_tensor\r\n    634 \r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in zeros(shape, dtype, name)\r\n   1869         # Create a constant if it won't be very big. Otherwise create a fill op\r\n   1870         # to prevent serialized GraphDefs from becoming too large.\r\n-> 1871         output = _constant_if_small(zero, shape, dtype, name)\r\n   1872         if output is not None:\r\n   1873           return output\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in _constant_if_small(value, shape, dtype, name)\r\n   1827   try:\r\n   1828     if np.prod(shape) < 1000:\r\n-> 1829       return constant(value, shape=shape, dtype=dtype, name=name)\r\n   1830   except TypeError:\r\n   1831     # Happens when shape is a Tensor, list with Tensor elements, etc.\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    244   \"\"\"\r\n    245   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 246                         allow_broadcast=True)\r\n    247 \r\n    248 \r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    252   ctx = context.context()\r\n    253   if ctx.executing_eagerly():\r\n--> 254     t = convert_to_eager_tensor(value, ctx, dtype)\r\n    255     if shape is None:\r\n    256       return t\r\n\r\n~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n    113     return t\r\n    114   else:\r\n--> 115     return ops.EagerTensor(value, handle, device, dtype)\r\n    116 \r\n    117 \r\n\r\nRuntimeError: Error copying tensor to device: /job:localhost/replica:0/task:0/device:GPU:0. Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:0.\r\n```\r\n", "comments": ["Can you explain the behavior you would expect? I am not sure I understand", "I expect to be able to iterate over a dataset containing strings without having an exception being raised once the last batch has been seen (as it is happening without distribution of the dataset). ", "same problem with mine.\r\n\r\ni am using a dataset that contains a string tensor as one of the inputs of the model. \r\nthe stirng tensor input is not a part of training, but it is necessary to be in the dataset for writing predictions to file. and i am using distribute strategy.\r\n\r\neverytime when it reaches the end of the dataset, it shows a `RuntimeError`.\r\n\r\ni am using tensorflow-gpu 1.14.0, python 3.7.3, Ubuntu 18.04 and 3 GPUs of TITAN Xp\r\n\r\nhere is my test code:\r\n\r\n```python\r\nimport os\r\nfrom tensorflow.compat.v1 import enable_eager_execution\r\nfrom tensorflow.data import Dataset\r\nfrom tensorflow.distribute import MirroredStrategy\r\nfrom tensorflow.keras.layers import Dense, Input\r\nfrom tensorflow.keras.models import Model\r\n\r\nenable_eager_execution()\r\n\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\r\n\r\nstrategy = MirroredStrategy()\r\nn = strategy.num_replicas_in_sync\r\nprint('Number of replicas: {}'.format(n))\r\n\r\ndataset = Dataset.from_tensors(({'input_1': ['This is a string'],\r\n                                 'input_2': [1., 2., 3., 2.]},\r\n                                {'output': [3.]})).repeat(256).shuffle(8).batch(2 * n)\r\n\r\nwith strategy.scope():\r\n    input_1 = Input(shape=(1,), dtype='string', name='input_1')\r\n    input_2 = Input(shape=(4,), name='input_2')\r\n    output = Dense(1, name='output')(input_2)\r\n    model = Model([input_1, input_2], [output], name='my_model')\r\n    model.compile(optimizer='adam', metrics=['accuracy'],\r\n                  loss='sparse_categorical_crossentropy')\r\n\r\nmodel.fit(dataset, epochs=2)\r\nmodel.evaluate(dataset)\r\n```\r\n\r\nand here is the logs:\r\n\r\n```text\r\nNumber of replicas: 3\r\nEpoch 1/2\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0910 04:38:57.874752 140676243105536 deprecation.py:323] From /home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\n41/43 [===========================>..] - ETA: 0s - loss: nan - acc: 0.0000e+00Traceback (most recent call last):\r\n  File \"draft.py\", line 34, in <module>\r\n    model.fit(dataset, epochs=2)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 649, in fit\r\n    validation_freq=validation_freq)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_distributed.py\", line 143, in fit_distributed\r\n    steps_name='steps_per_epoch')\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 273, in model_iteration\r\n    actual_inputs = ins() if callable(ins) else ins\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 483, in get_distributed_inputs\r\n    model, inputs, targets, sample_weights, mode)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\", line 580, in _prepare_feed_values\r\n    inputs, targets, sample_weights = _get_input_from_iterator(inputs, model)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\", line 547, in _get_input_from_iterator\r\n    next_element = iterator.get_next()\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\", line 256, in get_next\r\n    global_has_value, replicas = _get_next_as_optional(self, self._strategy)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\", line 162, in _get_next_as_optional\r\n    iterator._iterators[i].get_next_as_list(new_name))  # pylint: disable=protected-access\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\", line 721, in get_next_as_list\r\n    lambda: _dummy_tensor_fn(data.value_structure))\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1957, in cond\r\n    result = false_fn()\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\", line 721, in <lambda>\r\n    lambda: _dummy_tensor_fn(data.value_structure))\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\", line 639, in _dummy_tensor_fn\r\n    result.append(create_dummy_tensor(feature_shape, feature_type))\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\", line 632, in create_dummy_tensor\r\n    dummy_tensor = array_ops.zeros(tensor_shape.TensorShape(dims), feature_type)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1871, in zeros\r\n    output = _constant_if_small(zero, shape, dtype, name)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1829, in _constant_if_small\r\n    return constant(value, shape=shape, dtype=dtype, name=name)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 246, in constant\r\n    allow_broadcast=True)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 254, in _constant_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 115, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, handle, device, dtype)\r\nRuntimeError: Error copying tensor to device: /job:localhost/replica:0/task:0/device:GPU:2. Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:2.\r\n```", "This seems related to the handling of last partial batch in distributed datasets. we will take a look ", "I encounter the same error in Tensorflow 2.0. Any update?", "Same issue in Tensorflow 2.0.", "Same issue here. I'm breaking the loop before the last iteration. Any elegant solution to this?\r\n\r\n`Tensorflow version: 2.0.0`\r\n`Python version: 3.7.5`", "Is there a known workaround for this?", "Workaround:\r\nIf you are okay with not training on the partial batch, you can drop the remainder:\r\n`batched_dataset = dataset.batch(batch_size, drop_remainder=True)`", "Unfortunately in TF 2.1, bsaund's workaround does not work for me nor does this appear to have anything to do with the string data type:\r\n```python\r\nimport tensorflow as tf\r\nprint('Tensorflow version:', tf.__version__)\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nn = strategy.num_replicas_in_sync\r\nprint('Number of replicas: {}'.format(n))\r\n\r\ndataset = tf.data.Dataset.from_tensors(({#'input_1': ['This is a string'],\r\n                                 'input_2': [1., 2., 3., 2.]},\r\n                                {'output': [3.]})).repeat(256).shuffle(8).batch(2 * n, drop_remainder=True)\r\n\r\nwith strategy.scope():\r\n#     input_1 = tf.keras.layers.Input(shape=(1,), dtype='string', name='input_1')\r\n    input_2 = tf.keras.layers.Input(shape=(4,), name='input_2')\r\n    output = tf.keras.layers.Dense(1, name='output')(input_2)\r\n    model = tf.keras.models.Model([#input_1,\r\n                                   input_2], [output], name='my_model')\r\n    model.compile(optimizer='adam', metrics=['accuracy'],\r\n                  loss='sparse_categorical_crossentropy')\r\n\r\nmodel.fit(dataset, epochs=2)\r\nmodel.evaluate(dataset)\r\n```\r\n```\r\nTensorflow version: 2.1.0\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\r\nNumber of replicas: 2\r\nTrain for 64 steps\r\nEpoch 1/2\r\n 0/64 [..............................] - ETA: 0s\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-13-3ea23ab1aecc> in <module>\r\n     19                   loss='sparse_categorical_crossentropy')\r\n     20 \r\n---> 21 model.fit(dataset, epochs=2)\r\n     22 model.evaluate(dataset)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    817         max_queue_size=max_queue_size,\r\n    818         workers=workers,\r\n--> 819         use_multiprocessing=use_multiprocessing)\r\n    820 \r\n    821   def evaluate(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    327                 training_data_iter._initializer  # pylint: disable=pointless-statement\r\n    328               else:\r\n--> 329                 training_data_iter = iter(training_dataset)\r\n    330 \r\n    331             training_result = run_one_epoch(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py in __iter__(self)\r\n    563 \r\n    564     worker_iterators = _create_iterators_per_worker(self._cloned_datasets,\r\n--> 565                                                     self._input_workers)\r\n    566     iterator = DistributedIterator(self._input_workers, worker_iterators,\r\n    567                                    self._strategy)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py in _create_iterators_per_worker(worker_datasets, input_workers)\r\n   1009       worker_devices = input_workers.compute_devices_for_worker(i)\r\n   1010       iterator = _SingleWorkerDatasetIterator(worker_datasets[i], worker,\r\n-> 1011                                               worker_devices)\r\n   1012       iterators.append(iterator)\r\n   1013   return iterators\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py in __init__(self, dataset, worker, devices)\r\n    862     self._worker = worker\r\n    863     self._devices = devices\r\n--> 864     self._make_iterator()\r\n    865 \r\n    866   def _make_iterator(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py in _make_iterator(self)\r\n    868     with ops.device(self._worker):\r\n    869       self._iterator = multi_device_iterator_ops.MultiDeviceIterator(\r\n--> 870           self._dataset, self._devices)\r\n    871 \r\n    872   def get_next(self, device, name=None):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/multi_device_iterator_ops.py in __init__(self, dataset, devices, max_buffer_size, prefetch_buffer_size, source_device)\r\n    290                                     self._incarnation_id,\r\n    291                                     self._prefetch_buffer_size,\r\n--> 292                                     self._experimental_slack)\r\n    293         if context.executing_eagerly():\r\n    294           self._device_iterators.append(dataset_ops.make_one_shot_iterator(ds))\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/multi_device_iterator_ops.py in _create_device_dataset(prototype_ds, incarnation_id, prefetch_buffer_size, experimental_slack)\r\n    200       ds = dataset_ops.PrefetchDataset(ds, prefetch_buffer_size, slack_period=1)\r\n    201     else:\r\n--> 202       ds = ds.prefetch(prefetch_buffer_size)\r\n    203   # TODO(jsimsa): Enable auto-tuning and optimizations when supported for\r\n    204   # non-CPU devices.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py in prefetch(self, buffer_size)\r\n   1011       Dataset: A `Dataset`.\r\n   1012     \"\"\"\r\n-> 1013     return PrefetchDataset(self, buffer_size)\r\n   1014 \r\n   1015   @staticmethod\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py in __init__(self, input_dataset, buffer_size, slack_period)\r\n   4114         buffer_size, dtype=dtypes.int64, name=\"buffer_size\")\r\n   4115 \r\n-> 4116     with ops.colocate_with(input_dataset._variant_tensor.device):\r\n   4117         variant_tensor = gen_dataset_ops.prefetch_dataset(\r\n   4118             input_dataset._variant_tensor,  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in colocate_with(op, ignore_existing)\r\n   5118 # only API for those uses to avoid deprecation warning.\r\n   5119 def colocate_with(op, ignore_existing=False):\r\n-> 5120   return _colocate_with_for_gradient(op, None, ignore_existing=ignore_existing)\r\n   5121 \r\n   5122 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in _colocate_with_for_gradient(op, gradient_uid, ignore_existing)\r\n   5098     if op is not None:\r\n   5099       if not hasattr(op, \"device\"):\r\n-> 5100         op = internal_convert_to_tensor_or_indexed_slices(op)\r\n   5101       return device(op.device)\r\n   5102     else:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py in internal_convert_to_tensor_or_indexed_slices(value, dtype, name, as_ref)\r\n    316     return value\r\n    317   else:\r\n--> 318     return ops.convert_to_tensor(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    319 \r\n    320 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1312 \r\n   1313     if ret is None:\r\n-> 1314       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1315 \r\n   1316     if ret is NotImplemented:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    315                                          as_ref=False):\r\n    316   _ = as_ref\r\n--> 317   return constant(v, dtype=dtype, name=name)\r\n    318 \r\n    319 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    256   \"\"\"\r\n    257   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 258                         allow_broadcast=True)\r\n    259 \r\n    260 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    264   ctx = context.context()\r\n    265   if ctx.executing_eagerly():\r\n--> 266     t = convert_to_eager_tensor(value, ctx, dtype)\r\n    267     if shape is None:\r\n    268       return t\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n     94       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n     95   ctx.ensure_initialized()\r\n---> 96   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n     97 \r\n     98 \r\n\r\nRuntimeError: Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:0.\r\n```", "Apologies for the delay here, fixing this took a while, but this has been fixed as of end of Feb. It should not happen in tf-nightly or the TF 2.2 rcs. Please re-open if you still see it there. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30847\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30847\">No</a>\n", "@guptapriya Can you please give reference of commit that fixes the issue? ", "There were a series of commits that build up to this. from what i can tell, this was the last one: https://github.com/tensorflow/tensorflow/commit/97cdd4d16a81a349696f10451b7d564bfa99664f#diff-afbab14e6c4bbefd105d7ad3a3b67b7b"]}, {"number": 30846, "title": " mismatch in the description of BatchDot and TensorFlow's implementation. ", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/backend/batch_dot\r\n\r\n## Description of issue (what needs changing):\r\nI raised [an issue on the plaidML repo](https://github.com/plaidml/plaidml/issues/358), and after some back and forth we determined the documentation for BatchDot doesn't quite match the actual implementation in the tensorflow code.\r\n\r\n### Clear description\r\nA BatchDot with x.shape=(1,2,6,2) and y.shape=(1,2,2,3) and axes = (3, 1)has an output shape of (1,2,6,3)) whereas by the TF definition for output shape \"A tensor with shape equal to the concatenation of x's shape (less the dimension that was summed over) and y's shape (less the batch dimension and the dimension that was summed over). If the final rank is 1, we reshape it to (batch_size, 1).\" sounds like it should have an output shape of (1,2,6,2,3).\r\n\r\n### Submit a pull request?\r\nI am not planning to submit a PR at this time, but I may do it later", "comments": ["To further elaborate on this issue: there also seems to be output shape mismatches between the TensorFlow and Theano backend implementations of `BatchDot`. Theano's implementation seems to be much closer to the documented definition of `BatchDot` than TensorFlow.\r\n\r\nCould we either change the documentation to more clearly describe TensorFlow's engineering decisions behind `BatchDot` or modify the TensorFlow implementation of `BatchDot` to more closely match what is described in the documentation?", "Moving this to close status as its taken care in later version.", "Can you link to the version where this is taken care of, so I can check that my code works now?  Thanks!", "@zachmayer \r\nApologies for the confusion, can you please provide with stand alone code to support this issue and replicate it.", "@zachmayer Is this still an issue for you? Can you please share a simple standalone code to reproduce the issue? I have checked your code from the other thread and attaching [here](https://colab.research.google.com/gist/jvishnuvardhan/d11127b6e9bf3024c469daae969015ff/untitled979.ipynb)  as a gist for our reference. Thanks!", "From my ticket in the other repo: https://github.com/plaidml/plaidml/issues/358\r\n\r\n1. Make sure you are using the plaidml backend for keras\r\n2. Run:\r\n```from keras.layers import Input, Dense, Dot, Reshape, Flatten\r\nfrom keras.models import Model\r\n\r\nmodel_in = Input((10,), name='input')\r\nmodel_out = model_in\r\nmodel_out = Reshape((-1, 1), name='reshape')(model_out)\r\nmodel_out = Dot(axes=2, name='dot')([model_out, model_out])\r\nmodel_out = Flatten(name='flatten')(model_out)\r\nmodel = Model(model_in, model_out)\r\nmodel.summary()\r\nmodel.compile()```\r\n\r\nI'll see if the plaidml devs will update their code, now that tensorflow is the only backend supported by kers", "@zachmayer If this is an issue with `plaidml` backend, then this issue should be opened in their repo. Please let us know if there is any bug with `tensorflow` or `tf.keras`, then please provide a simple standalone code to reproduce the issue. Thanks!", "yeah this is an issue on plaidml's end.  They tried to blame it on tensorflow lol.\r\n\r\nThanks for your attention on this and sorry for the noise!"]}, {"number": 30845, "title": "Update metric_ops.py for incorrect docstring", "body": "Incorrect description", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30845) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30845) for more info**.\n\n<!-- ok -->", "Thanks for your contribution, will be closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 30844, "title": "Modularized gaussian noises' dtype.", "body": "As a reply to issue tensorflow#30834, I propose this very small fix that enforces the adjustment of gaussian noises' dtype with that of the inputs within tf.keras.layers.GaussianNoise and tf.keras.layers.GaussianDropout.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30844) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30844) for more info**.\n\n<!-- ok -->", "**Test code**\r\n\r\nI derived this test script from the example provided by @bluehope, author of issue #30834 which reported the bug my PR fixes.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ndef make_model(dtype, gtype='noise'):\r\n    assert dtype in (tf.float32, tf.float64)\r\n    assert gtype in ('noise', 'dropout')\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.Dense(10, input_shape=(10,), dtype=dtype))\r\n    if gtype == 'noise':\r\n        gaussian = tf.keras.layers.GaussianNoise(0.0003)\r\n    else:\r\n        gaussian = tf.keras.layers.GaussianDropout(0.1)\r\n    model.add(gaussian)\r\n    return model\r\n\r\n\r\nif __name__ == '__main__':\r\n    for dtype in (tf.float32, tf.float64):\r\n        for gtype in ('noise', 'dropout'):\r\n            try:\r\n                make_model(dtype, gtype)\r\n            except:\r\n                status = 'failure'\r\n            else:\r\n                status = 'success'\r\n            print(f'Test with dtype {dtype} and gaussian {gtype}: {status}.')\r\n```\r\n\r\n---\r\n\r\nNow, I ran this test script with tensorflow 2.0-beta1 (with GPU support), but it should be the same with 1.14 (and without GPU).\r\n\r\n**Output before the fix**\r\nMy first run used TF installed from binary using pip (on a Linux Mint 19.1 system).\r\n```\r\nTest with dtype <dtype: 'float32'> and gaussian noise: success.\r\nTest with dtype <dtype: 'float32'> and gaussian dropout: success.\r\nTest with dtype <dtype: 'float64'> and gaussian noise: failure.\r\nTest with dtype <dtype: 'float64'> and gaussian dropout: failure.\r\n```\r\n\r\n**Output after the fix**\r\n\r\nMy second run used the same TF installation, after replacing the file `tensorflow/python/keras/layers/noise.py` in the local library (as this is a fix to python code, I did not recompile from source).\r\n\r\n```\r\nTest with dtype <dtype: 'float32'> and gaussian noise: success.\r\nTest with dtype <dtype: 'float32'> and gaussian dropout: success.\r\nTest with dtype <dtype: 'float64'> and gaussian noise: success.\r\nTest with dtype <dtype: 'float64'> and gaussian dropout: success.\r\n```", "@tanzhenyu If this example does not suit you and you would like me to write a test following a specific template, please let me know.", "> @tanzhenyu If this example does not suit you and you would like me to write a test following a specific template, please let me know.\r\n\r\nOh I mean can you add a test inside the code base?", "@tanzhenyu I guess I can, but what exactly do you want that test to verify? The mere possibility to instantiate layers (in which case I will use what I wrote earlier), or also the behavior of the gaussian noise being added to input tensors (using a seed for deterministic results)?", "Furthermore, would you like to be... ?\r\n* a) in a separate file\r\n* b) in a `if __name__ == '__main__'` block at the end of the file\r\n* c) in the docstring (i.e. a doctest)", "Preferrably under noise_test.py, there is a layer_test util you can use", "@tanzhenyu As it turns out, there already is a `noise_test.py` file [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/noise_test.py), although it was oddly not included in either of my local installations.\r\n\r\nThe test runs before and after my fix, but do not actually check for it (nor for compatibility with various input dtypes in general). I would be happy to change that, but there is literally no included documentation on the test utils (seriously, I love tensorflow, but something ought to be done regarding the python source code's general writing and documenting conventions). Anyway, if you have any documentation material that would help - otherwise I will just tweak around hoping to stumble upon the desired feature ;)", "I followed the example of `recurrent_test.py` ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent_test.py)) and added a few tests based on instantiating a small model, compiling it and running a fitting process (on small, zero data) - in the vein of the block of code previously shared here.\r\n\r\nI do not know if that suits the current testing practices (if not, let me know how to change this), but it does highlight the issue and the validity of the fix as to it (the two gloat64 tests fail without the fix, whereas they all pass after deploying it).", "> @tanzhenyu As it turns out, there already is a `noise_test.py` file [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/noise_test.py), although it was oddly not included in either of my local installations.\r\n> \r\n> The test runs before and after my fix, but do not actually check for it (nor for compatibility with various input dtypes in general). I would be happy to change that, but there is literally no included documentation on the test utils (seriously, I love tensorflow, but something ought to be done regarding the python source code's general writing and documenting conventions). Anyway, if you have any documentation material that would help - otherwise I will just tweak around hoping to stumble upon the desired feature ;)\r\n\r\nI thought that's exactly what I commented above: \"Preferrably under noise_test.py, there is a layer_test util you can use\" :-)\r\n\r\nFrom a TDD principle, you could 1) add a test which should fail, 2) add your code change to make the test succeeds", "> I thought that's exactly what I commented above: \"Preferrably under noise_test.py, there is a layer_test util you can use\" :-)\r\n\r\nYup, I just had not noticed that the file already existed - sorry!\r\n\r\n> From a TDD principle, you could 1) add a test which should fail, 2) add your code change to make the test succeeds\r\n\r\nThat is pretty much the idea with the tests I added (based on what I posted here before); the two \"float64\" ones fail if you run the test file with tensorflow installed from a current branch (in my case, 2.0-beta1 with GPU support installed from pip), while they succeed once the `noise.py` has been altered following the fix I submitted. Thanks for the clarification anyway!", "Some builds failed to run my test file due to the `from tensorflow.python import dtypes` line. I am going to change it, but it may take a few iterations to find a way to make it work for all platforms (I do not quite get why the API is different between various python3 installations).", "Can one of the admins verify this patch?", "A couple of builds failed on the pylint tests. The issue is that I respected pep 8 on 4-spaces identations, while pylint was configured to expect 2 spaces due to what appears to be the not-always-applied-and-definitely-harder-to-read-but-arguably-easier-to-write norm in tensorflow...\r\nShould I simply update the code's indentation and have someone review the PR again?", "@pandrey-fr yes please fix lint errors ", "Okay, the last couple of commits should now make the PR pass the pylint tests.\r\n\r\nOn the other hand, I notices that one of the builds had actually failed on compiling a GPU op that should in no way be related to this PR - a problem that must have been fixed on the master branch for long now. So, there might be another failure when the latest commits have been reviewed, which I seemingly cannot fix but should be wiped off when merging into master, as far as I understand it.", "On the one hand, pylint failed again on the Ubuntu Sanity build. That is because I assumed hanging indentations should be of 2 spaces, like code indentations, but actually pylint excepts 4 spaces. I am not going to argue, but this really makes very little sense to the pep-8 fanatic I tend to be. I will push a small fix later today.\r\n\r\nOn the other hand, the other builds failed on either compilation or testing issues which seem entirely unrelated to the issue... Maybe it would be worth to merge the current master into my PR branch before running tests again to do it the other way around.", "(sorry about the pile of commits that really should have been only one - using the GitHub online code editor to go fast was not a good idea)"]}, {"number": 30843, "title": "Unable to train model on multiple GPUs using MirroredStrategy in TF2.0", "body": "I have two Tesla T4 GPUs from Google. I am using this [example](https://www.tensorflow.org/beta/tutorials/load_data/text#split_the_dataset_into_text_and_train_batches) in order to train it on multiple GPUs with defined the `model` inside `tf.distribute.MirroredStrategy()` as described [here](https://www.tensorflow.org/beta/guide/distribute_strategy#using_tfdistributestrategy_with_keras). The model trains without `tf.distribute.MirroredStrategy()` on single GPU normally but not when I want to train it on multiple GPUs. You can find the error log below. \r\nAnother dummy example program in the docs for using `MirroredStrategy()` is [here](https://www.tensorflow.org/beta/guide/distribute_strategy#using_tfdistributestrategy_with_keras). On executing this, it trains and utilises both GPUs. Between these two examples, I noticed one thing which is the use of `padded_batch` and `batch`. It works fine in the latter case. I also have a model of mine where I am using `padded_batch`. This model also can not be trained and although the error there is a bit different. \r\n**Please suggest any ways to get rid of this problem. THANK YOU!**\r\n\r\n> Train on None steps\r\nEpoch 1/10\r\nW0718 14:21:33.186410 139786698037056 cross_device_ops.py:764] Efficient allreduce is not supported for 1 IndexedSlices\r\nW0718 14:21:38.304410 139786698037056 cross_device_ops.py:764] Efficient allreduce is not supported for 1 IndexedSlices\r\n2019-07-18 14:21:39.456127: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] implementation_selector failed: Invalid argument: Invalid format of input node name: replica_1/sequential/bidirectional/StatefulPartitionedCall_replica_1/StatefulPartitionedCall_8 Expected: {forward_node_name}:{index}\r\n2019-07-18 14:21:40.179202: W tensorflow/core/grappler/optimizers/implementation_selector.cc:199] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_356864_357366' and '__inference___backward_standard_lstm_356864_357366_specialized_for_StatefulPartitionedCall_1_at___inference_distributed_function_360209' both implement 'lstm_3542e53d-8ce9-47ba-b422-dc9202236064' but their signatures do not match.\r\n2019-07-18 14:21:40.669817: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n2019-07-18 14:21:40.752732: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-07-18 14:21:51.150641: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 17050 of 50000\r\n2019-07-18 14:22:00.643784: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\r\n2019-07-18 14:22:00.664615: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at partitioned_function_ops.cc:113 : Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:1 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_102 , and the dst node is while_2_RetVal\r\n2019-07-18 14:22:00.664706: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:1 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_102 , and the dst node is while_2_RetVal\r\n\t [[{{node replica_1/sequential/bidirectional/StatefulPartitionedCall}}]]\r\n\t [[metrics/accuracy/div_no_nan/ReadVariableOp_1/_50]]\r\n2019-07-18 14:22:00.664771: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:1 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_102 , and the dst node is while_2_RetVal\r\n\t [[{{node replica_1/sequential/bidirectional/StatefulPartitionedCall}}]]\r\n\t [[replica_1/metrics/accuracy/AssignAddVariableOp_1/_41]]\r\n2019-07-18 14:22:00.665117: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at partitioned_function_ops.cc:113 : Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:1 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\n2019-07-18 14:22:00.665167: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:1 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_102 , and the dst node is while_2_RetVal\r\n\t [[{{node replica_1/sequential/bidirectional/StatefulPartitionedCall}}]]\r\n2019-07-18 14:22:00.666533: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at partitioned_function_ops.cc:113 : Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:0 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_101 , and the dst node is while_1_RetVal\r\n2019-07-18 14:22:00.679274: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at partitioned_function_ops.cc:113 : Invalid argument: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:0 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal\r\nTraceback (most recent call last):\r\n  File \"colab.py\", line 94, in <module>\r\n    model.fit(train_data, epochs=10, validation_data=test_data)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.py\", line 643, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training_distributed.py\", line 681, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 294, in model_iteration\r\n    batch_outs = f(actual_inputs)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\", line 813, in execution_function\r\n    return [out.numpy() for out in distributed_function(input_fn)]\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/eager/def_function.py\", line 428, in __call__\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/eager/function.py\", line 1335, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/eager/function.py\", line 589, in _filtered_call\r\n    (t for t in nest.flatten((args, kwargs), expand_composites=True)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/eager/function.py\", line 671, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/eager/function.py\", line 445, in call\r\n    ctx=ctx)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/six.py\", line 737, in raise_from\r\n    raise value\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:1 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_102 , and the dst node is while_2_RetVal\r\n\t [[node replica_1/sequential/bidirectional/StatefulPartitionedCall (defined at usr/lib/python2.7/threading.py:801) ]]\r\n\t [[metrics/accuracy/div_no_nan/ReadVariableOp_1/_50]]\r\n  (1) Invalid argument:  Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:localhost/replica:0/task:0/device:GPU:1 vs /job:localhost/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_102 , and the dst node is while_2_RetVal\r\n\t [[node replica_1/sequential/bidirectional/StatefulPartitionedCall (defined at usr/lib/python2.7/threading.py:801) ]]\r\n0 successful operations.\r\n1 derived errors ignored. [Op:__inference_distributed_function_360209]\r\nFunction call stack:\r\ndistributed_function -> distributed_function", "comments": ["@rishabhsahrawat ,\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here and also mention the TF version being used. Thanks!", "@anush-o thank you for your questions.\r\nI am using TF2.0 as I mentioned it in the Title.\r\nI am using the exact same code as this [example](https://www.tensorflow.org/beta/tutorials/load_data/text#split_the_dataset_into_text_and_train_batches) provided by TF except before the model definition I added 2 lines for the multiple GPU support. The lines are \r\n`mirrored_strategy = tf.distribute.MirroredStrategy()`\r\n`with mirrored_strategy.scope():\r\n...`\r\nThis is my code file with in txt format (could not upload .py file here.)\r\n[colab.txt](https://github.com/tensorflow/tensorflow/files/3410258/colab.txt)\r\n\r\n", "This has been fixed in the latest nightly, can you try with 2.0 nightly and see if it's still failing? (same as https://github.com/tensorflow/tensorflow/issues/30513) ", "@guptapriya Hi Priya, thank you for your helpful response. After updating TF to latest 2.0 nightly from [here](https://pypi.org/project/tf-nightly-gpu-2.0-preview/#history), it starts training on both GPUs however once the first epoch is finished it throws following error on providing `test_data`(consisting test dataset) to `validation_data` argument in `model.fit()`. However, no error when `validation_data` is defined `None` in `model.fit()`-\r\n\r\n>   File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 710, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 680, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 436, in model_iteration\r\n    steps_name='validation_steps')\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 174, in model_iteration\r\n    steps_per_epoch)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 490, in _get_num_samples_or_steps\r\n    'steps_per_epoch')\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\", line 425, in check_num_samples\r\n    if hasattr(ins[0], 'shape'):\r\nTypeError: 'function' object has no attribute '__getitem__'\r\n\r\nIt seems like a bug to me. Please give your suggestions. I also tried training another program of my own, which also arises the same behaviour.", "Can you try setting validation_steps in fit and see if that helps? This is still a bug and we will look into it. ", "thank you for your reply. I tried your suggestion and now validation data can also be used in `model.fit` function. Since, `validation_steps` require number of batches, and lets' say length of test data is (5000) not completely divisible by the batch size (64) so in this case it will skip the last data (of length 8) that doesn't make any batch. Now my question is if there is a way to also include that or should I wait for the bug to be fixed. Sorry, if the question is too naive. ", "Hi - great to know it worked for you. Once we do fix the bug, you should be able to run the validation until the end. In the meantime, perhaps you can try rounding up instead of rounding down when calculating the number of steps and see if that works? \r\n\r\nBTW, would you mind filing a separate bug for the error you saw in https://github.com/tensorflow/tensorflow/issues/30843#issuecomment-514534349? Will help us track it. Thanks", "Actually ignore the new bug part, i found a similar bug here : https://github.com/tensorflow/tensorflow/issues/28797", "Hi Priya, @guptapriya thank you for your response again. I tried using the rounded up value and it worked. I thought it only takes integer values as input. :D", "Glad to know it worked! Thanks for testing out 2.0! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30843\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30843\">No</a>\n"]}, {"number": 30842, "title": "change protobuf version to 3.8 then build failed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 14.04):\r\n- GCC 4.8.4\r\n- build CPU only\r\n\r\n**Describe the problem**\r\nwhen build tensorflow r1.5, upgrade protobuf version by changing proto buf urls, sha256,strip prefix value . Just  As followed:\r\n        \"http://mirror.tensorflow.org/github.com/protocolbuffers/protobuf/archive/310ba5ee72661c081129eb878c1bbcec936b20f0.tar.gz\",        \"https://github.com/protocolbuffers/protobuf/archive/310ba5ee72661c081129eb878c1bbcec936b20f0.tar.gz\",\r\nPROTOBUF_SHA256 = \"b9e92f9af8819bbbc514e2902aec860415b70209f31dfc8c4fa72515a5df9d59\"\r\n PROTOBUF_STRIP_PREFIX = \"protobuf-310ba5ee72661c081129eb878c1bbcec936b20f0\"\r\n\r\n\r\n**build commnd**:\r\nbazel build //tensorflow:libtensorflow_cc.so\r\n\r\nthe error message is :\r\n---------------------------\r\nERROR: Skipping '//tensorflow:libtensorflow_cc.so': error loading package 'tensorflow': Extension file not found. Unable to load package for '@bazel_skylib//lib:versions.bzl': The repository could not be resolved\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow': Extension file not found. Unable to load package for '@bazel_skylib//lib:versions.bzl': The repository could not be resolved\r\nINFO: Elapsed time: 0.652s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow\r\n-------------------------\r\n\r\nhow could I fix the problem  ?\r\n", "comments": ["And  no protobuf installed in my system", "The TF team doesn't provide build support for versions as old as r1.5, sorry. Please try [building the most recent release](https://www.tensorflow.org/install/source) instead."]}, {"number": 30841, "title": "cannot detect communication between clusters when CollectiveAllReduceStrategy ", "body": "tensorflow 1.12\r\nCUDA 10\r\nUbuntu 16.04\r\n\r\nHere is the part of code in the main script:\r\n  strategy=tf.contrib.distribute.MirroredStrategy(num_gpus=FLAGS.n_gpus)#devices=[\"/gpu:0\", \"/gpu:1\"]\r\n  if FLAGS.strategy==\"ps\":\r\n    os.environ['TF_CONFIG'] = json.dumps({\r\n        'cluster': {\r\n            \"worker\": [\"10.60.131.148:8081\", \"10.60.131.149:8082\"],\r\n            \"ps\": [\"10.60.131.150:8083\"]\r\n        },\r\n        'task': {'type': FLAGS.type, 'index': FLAGS.index}\r\n    })\r\n    strategy = tf.contrib.distribute.ParameterServerStrategy(num_gpus_per_worker=FLAGS.n_gpus)\r\n  elif FLAGS.strategy==\"collective\":\r\n    os.environ['TF_CONFIG'] = json.dumps({\r\n        'cluster': {\r\n            \"worker\": [\"10.60.131.148:8888\",\"10.60.131.149:8888\", \"10.60.131.150:8888\"],\r\n        },\r\n        'task': {'type': FLAGS.type, 'index': FLAGS.index}\r\n    })\r\n    strategy = tf.contrib.distribute.CollectiveAllReduceStrategy(num_gpus_per_worker=FLAGS.n_gpus)\r\n\r\n  run_config = tf.estimator.RunConfig(\r\n      model_dir=FLAGS.output_dir,\r\n      save_checkpoints_steps=FLAGS.save_checkpoints_steps,\r\n      train_distribute=strategy\r\n      )\r\n  estimator = tf.estimator.Estimator(\r\n      model_fn=model_fn,\r\n      config=run_config,\r\n      params={\"batch_size\": FLAGS.train_batch_size}\r\n  )\r\n\r\n  if FLAGS.do_train:\r\n    tf.logging.info(\"***** Running training *****\")\r\n    tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\r\n    train_input_fn = input_fn_builder(\r\n        input_files=input_files,\r\n        max_seq_length=FLAGS.max_seq_length,\r\n        max_predictions_per_seq=FLAGS.max_predictions_per_seq,\r\n        is_training=True)\r\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)\r\n\r\nI have three machines each has 3 gpus.\r\nWhen I run CollectiveAllReduceStrategy, set type as 'worker' and index, the num of gpus for each worker as 3.I run the script independently on three clusters,  and use iftop -n to monitor the network, I did notice any communication between the clusters.\r\nNo errors, and from the log I did't know if it now runs the correctly way. Or just single machine 3 gpus, running independently.\r\n\r\nAny suggestions or reference links?\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 30840, "title": "2.0.0-beta1 no op for reassign variable to different shape (e.g. a validate_shape=False option)", "body": "```\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\ntf.random.set_seed(0)\r\n\r\nv = tf.Variable(\r\n    tf.random_normal_initializer()(shape=(10,)),\r\n    validate_shape=False) # Only for first initialization, not for reinitialization\r\n\r\nv2 = tf.random.normal((5,))\r\n\r\nprint(v)\r\n\r\n# tf.compat.v1.assign(v, v2, validate_shape=False)\r\nv.assign(v2)\r\n\r\nprint(v)\r\n```\r\n\r\nOutputs:\r\n\r\n```\r\n2.0.0-beta1\r\n2019-07-18 14:41:15.418014: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n<tf.Variable 'Variable:0' shape=(10,) dtype=float32, numpy=\r\narray([ 0.07555313,  0.0211461 , -0.02098475, -0.05180186, -0.06184139,\r\n        0.02351365, -0.00069874,  0.05944292,  0.03012667,  0.02998556],\r\n      dtype=float32)>\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 15, in <module>\r\n    v.assign(v2)\r\n  File \"/Users/olanymoe/anaconda3/envs/tf2/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1145, in assign\r\n    self._shape.assert_is_compatible_with(value_tensor.shape)\r\n  File \"/Users/olanymoe/anaconda3/envs/tf2/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\", line 1110, in assert_is_compatible_with\r\n    raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\nValueError: Shapes (10,) and (5,) are incompatible\r\n```\r\n\r\nSimilarly, the `compat.v1` seems to ignore the `validate_shape` argument for variables in 2.0 ( https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/state_ops.py#L228 ).\r\n\r\nI'm working on a model which is being served as a saved_model. Is there a way of changing shapes of variables in 2.0? In 1.14 it worked using assign ops with `validate_shape=False`. The 2.0 documentation seems to hint at this functionality, but I cannot find any compatible ops:\r\n\r\n> If you want to change the shape of a variable later you have to use an assign Op with validate_shape=False.\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Variable", "comments": ["I found this similar issue: https://github.com/tensorflow/tensorflow/issues/26104 with instructions that solved my issues:\r\n\r\nExplicitly setting shape information to `None`\r\n\r\n```\r\nv = tf.Variable(\r\n    tf.random_normal_initializer()(shape=(10,)),\r\n    shape=tf.TensorShape(None))\r\n```\r\n\r\ngives expected behaviour."]}, {"number": 30839, "title": "Tensorflow 2.0 - Build From Source not creating Python Wrappers such as _pywrap_tensorflow_internal.lib", "body": "**System information**\r\n- OS : Windows 10\r\n- TensorFlow installed from : source \r\n- TensorFlow : 2.0.0\r\n- Python version : 3.7.3\r\n- Bazel version (if compiling from source): 0.25.2\r\n- GCC/Compiler version (if compiling from source): VS2017\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Nvidia 960m\r\n\r\nWhen building tensorflow v1.14 from source, using configure.py script then building the resulting bazel --config=opt, in the bazel-bin/tensorflow output directory, it creates a /python directory containing python wrapper libraries such as _pywrap_tensorflow_internal.lib (which is required when creating custom ops).\r\n\r\nFollowing the same procedure with v2.0.0, it doesn't produce this (using exactly the same config settings) i.e. for whatever reason the build script is now building the python wrappers libraries.\r\n\r\nThe source code is in the same location as for v1.14, and checking the prebuilt version that can be installed via pip, this directory and associated library are deployed.\r\n\r\nIs an additional flag now required to create this additional set of python wrapper libraries?\r\n", "comments": ["Just to verify did you get chance to follow instructions from [TensorFlow](https://www.tensorflow.org/install/source_windows) website .Please, let us know. Thanks!", "Yes, that is the guide I followed. As I say, with v1.14, it builds everything as expected, following the same procedure with v2.0.0, it builds without errors with the main libraries builts, however the directory that usually contains things such as _pywrap_tensorflow_internal.lib has not been created.", "@meteorcloudy I think he first looked into creating custom ops with TF bazel build.", "I never tried to build TensorFlow 2.0 on Windows, is there any guide?", "The C++ aspects of the build are identical.\r\nAs far as I know, you just need to feed the `--config=v2` flag to the bazel command. @goldiegadde to confirm.", "@oracle3001 was this resolved by following @gunan suggestion? Please close the issue if it was resolved already. Thanks!", "No, this did not resolve the issue. \r\n\r\nWhen I build from the latest nightly code from github, I can successfully build TF v2, but it still never compiles the /python directory containing python wrapper libraries such as _pywrap_tensorflow_internal.lib", "@oracle3001 I just verified again, `_pywrap_tensorflow_internal.lib` does exist.\r\nI'm building with Bazel 0.26.1 + TF@r2.0 branch\r\n```\r\n./configure\r\nbazel build --config=opt --config=v2 tensorflow/tools/pip_package:build_pip_package\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package ./output\r\n```\r\nWhen I open the whl file `tensorflow-2.0.0-cp36-cp36m-win_amd64.whl` as a zip file, it exists at `tensorflow-2.0.0-cp36-cp36m-win_amd64.zip\\tensorflow_core\\python\\_pywrap_tensorflow_internal.lib`\r\n", "I will try with those parameters. With v1.14, the following build arguments resulted in the the python directory i.e _pywrap_tensorflow_internal.lib also getting built in the output.\r\n\r\n`bazel build --config=opt //tensorflow:libtensorflow.so `\r\n", "Please use the `r1.15`, `r2.0` or the `master` branches instead of `r1.14` as that branch is in an unstable state, unfortunately.", "@oracle3001 \r\nAny update on this issue please. Thanks!", "I have just retried with the very latest code from Github i.e. v2.2_dev and although it all builds successfully, still no python directory or _pywrap_tensorflow_internal.lib is created..", "Hi @oracle3001 !Could you please check on latest stable version of tf 2.6 and   the instructions at this [link ](https://www.tensorflow.org/install/source_windows) for installing Tensorflow in windows from Source. let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30839\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30839\">No</a>\n"]}, {"number": 30838, "title": "Unable to quantize buffer or min/max value for input 1 in op MUL in subgraph 0, node: 8", "body": "**System information**\r\n- OS: Linux Ubuntu 19.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc9 1.14.0\r\n- Python version: 3.7.3\r\n- CUDA/cuDNN version: 10.0.130/ 7.4.1\r\n- GPU model and memory: Tesla V100-SXM2-16GB\r\n\r\n**Describe the current behavior**\r\nRunning the official tutorial on post training quantization:\r\nhttps://www.tensorflow.org/lite/performance/post_training_quantization\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tutorials/post_training_quant.ipynb\r\n\r\nresults in following error message:\r\n`Unable to quantize buffer or min/max value for input 1 in op MUL in subgraph 0, node: 8`\r\n\r\n**Describe the expected behavior**\r\nNo error\r\n\r\n**Code to reproduce the issue**\r\nRun the attached notebook with attached graph.pb and csv:\r\nhttps://drive.google.com/open?id=1JI45QqwhgR2v4i8GCShkH5eod0TTB7FI\r\n\r\nDownload YTF Dataset as from here: https://www.cs.tau.ac.il/~wolf/ytfaces/\r\n\r\n\r\n", "comments": ["I believe this is triggered Mul takes a constant input. In the attached graph this is found here:\r\n![image](https://user-images.githubusercontent.com/35263153/64412735-5f0bfd00-d090-11e9-8ab8-7dbce93e78b7.png)\r\n\r\nIt can also be reproduced more simply with:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\na = tf.placeholder(dtype=tf.float32, shape=[1])\r\n\r\nadd = a + 1.\r\nmul = a * 2.\r\n\r\ndef dataset_gen():\r\n    yield [np.array([1.], dtype=np.float32)]\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    converter = tf.lite.TFLiteConverter.from_session(sess, [a], [add, mul])\r\n    converter.optimizations = [ tf.lite.Optimize.DEFAULT ]\r\n    converter.representative_dataset = dataset_gen\r\n    tflite_quant_model = converter.convert()\r\n\r\nwith open('add_mul_const.tflite', 'wb') as f:\r\n    f.write(tflite_quant_model)\r\n```\r\n\r\nThis fails with the error:\r\n\r\n```Traceback (most recent call last):\r\n  File \"add_mul_const.py\", line 18, in <module>\r\n    tflite_quant_model = converter.convert()\r\n  File \"/Users/maroco01/anaconda3/envs/tf-pip/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 908, in convert\r\n    inference_output_type)\r\n  File \"/Users/maroco01/anaconda3/envs/tf-pip/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 200, in _calibrate_quantize_model\r\n    inference_output_type, allow_float)\r\n  File \"/Users/maroco01/anaconda3/envs/tf-pip/lib/python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 78, in calibrate_and_quantize\r\n    np.dtype(output_type.as_numpy_dtype()).num, allow_float)\r\n  File \"/Users/maroco01/anaconda3/envs/tf-pip/lib/python3.6/site-packages/tensorflow/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py\", line 115, in QuantizeModel\r\n    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, input_py_type, output_py_type, allow_float)\r\nRuntimeError: Unable to quantize buffer or min/max value for input 1 in op ADD in subgraph 0, node: 0```", "Meet the same problem. Any solution?", "This issue was fixed in the master branch and in branch 1.15, seemingly by this commit: https://github.com/tensorflow/tensorflow/commit/a372bb0e9d77b3532eec1bf24a44bbf342673968#diff-69178ece8d1001b2ef7f9b329e9a525b.", "Closing per last comment.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30838\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30838\">No</a>\n"]}, {"number": 30837, "title": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONV_2D, TANH. Here is a list of operators for which you will need custom implementations: DEPTH_TO_SPACE.", "body": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONV_2D, TANH. Here is a list of operators for which you will need custom implementations: DEPTH_TO_SPACE.", "comments": ["It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n"]}, {"number": 30836, "title": "Fix c++17 build for macos and ubuntu", "body": "Hello,\r\n\r\nThis fixes some problems I was having building tensorflow with c++17 support on macos and ubuntu. I'm sure there is more to the c++17 story but as far as I can tell this doesn't make anything worse off.\r\n\r\nThanks for your consideration.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30836) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30836) for more info**.\n\n<!-- ok -->", "> I couldn't find clear documentation saying that its not supported but there were some resources online. After a bit of investigation this appears to be a macOS+clang problem more than a clang problem. A simple program like:\r\n> \r\n> ```\r\n> #include <cstdio>\r\n> #include <cstdlib>\r\n>  \r\n> int main()\r\n> {\r\n>     int* p2 = static_cast<int*>(std::aligned_alloc(1024, 1024));\r\n>     std::printf(\"1024-byte aligned address: %p\\n\", static_cast<void*>(p2));\r\n>     std::free(p2);\r\n> }\r\n> ```\r\n> \r\n> compiles with `clang++ align.cc -std=c++17` on ubuntu but not MacOS. Not sure what the best solution here would be.\r\n\r\nI would expect in that case:\r\na) add a comment with a TODO explaining the issue\r\nb) check whether it's the clang mac version that is the problem\r\n\r\nWhich clang version on Mac did you check with?", "@justin1121 Could you please address the reviewer comments. Thanks!", "Hi there, sorry for the delay. Heres my clang version: `Apple LLVM version 10.0.1 (clang-1001.0.46.4)`. I've pushed a commit that adds a comment explaining the issue. Also as noted in my comment and mentioned earlier there's not much information I can find on `aligned_alloc` missing but there was one bug report filed here https://forums.developer.apple.com/thread/81413 that has received no response.", "The ifdef still triggers on Linux clang though, right? (or am I misreading?)", "No I think this excludes any clang being run, we can add another check for MacOS?", "@justin1121 Could you please resolve the conflicts? Thanks!", "Done!", "Can one of the admins verify this patch?", "@justin1121 Still, conflicts appearing. Could you please resolve those? Thanks!", "Fixed!", "@justin1121 Could you please resolve the conflicts? Thanks!", "> No I think this excludes any clang being run, we can add another check for MacOS?\r\n\r\nI think my point is that we only want to have different behavior for the specific version on MacOS-clang where it fails.", "Gotcha. I wonder if with Tensorflow being able to be compiled with c++14 support makes this PR obsolete. The project I'm trying to integrate can be built with c++14 also. Or perhaps this will be a fixed that is needed to build with c++14 (or does Tensorflow already compile on c++14 on all platforms?).", "Fixed conflicts!", "> Gotcha. I wonder if with Tensorflow being able to be compiled with c++14 support makes this PR obsolete. The project I'm trying to integrate can be built with c++14 also. Or perhaps this will be a fixed that is needed to build with c++14 (or does Tensorflow already compile on c++14 on all platforms?).\r\n\r\nI don't think that makes any difference. Generally, if you want to compile with C++17 support and a compiler has 17 support but doesn't support all features, that seems like a bug. In this case, excluding the exact compiler version via an #ifdef seems fine, as long as you're precisely doing that for one version.", "@justin1121 Could you please check reviewer comments and keep us posted. Thanks!", "I'm not really actively working on this but in response to @r4nt: I don't think this is a bug in a single compiler version I'm pretty sure it exists in all clang versions deployed to MacOS. I'm not even sure how you would go through all versions of clang to confirm if this bug exists.", "> I'm not really actively working on this but in response to @r4nt: I don't think this is a bug in a single compiler version I'm pretty sure it exists in all clang versions deployed to MacOS. I'm not even sure how you would go through all versions of clang to confirm if this bug exists.\r\n\r\nCurrently it looks to me like we're excluding all of clang, not only clang-on-mac. I'd be even happy with making it clang-on-mac and then documenting the currently latests with which it fails.", "@justin1121 Could you please check reviewer comments and keep us posted. Thanks!", "I'm not actively working on this. I believe for our use case further support for c++14 will solve our problem. Thanks.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!", "Hey, sorry for not responding. I'm no longer working on this so I think\nclosing makes sense. I will reopen if I have a need for implementing this\nagain. Thanks.\n\nOn Tue, Dec 10, 2019, 8:06 AM gbaned <notifications@github.com> wrote:\n\n> Closed #30836 <https://github.com/tensorflow/tensorflow/pull/30836>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/30836?email_source=notifications&email_token=AAK2A2UV46AOCOBKYW6CQX3QX6A43A5CNFSM4IEZRVGKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOVMKEDXQ#event-2870231518>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAK2A2Q4UVVYEUFAHU6VFBLQX6A43ANCNFSM4IEZRVGA>\n> .\n>\n"]}, {"number": 30835, "title": "Keras Adam optimizer unsupported by GPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Colab**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **preinstalled in colab**\r\n- TensorFlow version (use command below): **1.14.0**\r\n- Python version: **3.6.8**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: **GPU on Colab**\r\n\r\n**Describe the current behavior**\r\nI run a Keras Adam optimizer with a CNN network. The code works fine with CPU. If I turn on GPU in the notebook, and rerun the same code, I get an exception.\r\n\r\n**Describe the expected behavior**\r\nNo exception\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nActivate GPU.\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nprint(tf.version.VERSION)\r\n\r\ntraining_samples = 100\r\ninput_shape = (16, 512, 1)\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices((tf.random_uniform([32, 16, 512, 1], dtype=tf.float32), tf.random_uniform([32], dtype=tf.float32)))\r\ndataset = dataset.shuffle(32).repeat()\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\nwith strategy.scope():\r\n    initializer = 'he_uniform'\r\n    nb_filts = [8, 16, 32, 400]\r\n    out_size = 1\r\n    model = tf.keras.models.Sequential()\r\n    model.add(keras.layers.Conv2D(nb_filts[0], kernel_size=(3, 3),\r\n                activation='relu', padding='same',\r\n                kernel_initializer=initializer,\r\n                bias_initializer=initializer, input_shape=input_shape))\r\n    model.add(keras.layers.Conv2D(nb_filts[0], kernel_size=(3, 3),\r\n                activation='relu', padding='same',\r\n                kernel_initializer=initializer,\r\n                bias_initializer=initializer))\r\n    model.add(keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), \r\n                padding='same'))\r\n    model.add(keras.layers.Conv2D(nb_filts[1], kernel_size=(3, 3),\r\n                activation='relu', padding='same',\r\n                kernel_initializer=initializer,\r\n                bias_initializer=initializer))\r\n    model.add(keras.layers.Conv2D(nb_filts[1], kernel_size=(3, 3),\r\n                activation='relu', padding='same',\r\n                kernel_initializer=initializer,\r\n                bias_initializer=initializer))\r\n    model.add(keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), \r\n                padding='same'))\r\n    model.add(keras.layers.Conv2D(nb_filts[2], kernel_size=(3, 3),\r\n                activation='relu', padding='same',\r\n                kernel_initializer=initializer,\r\n                bias_initializer=initializer))\r\n    model.add(keras.layers.Conv2D(nb_filts[2], kernel_size=(3, 3),\r\n                activation='relu', padding='same',\r\n                kernel_initializer=initializer,\r\n                bias_initializer=initializer))\r\n    model.add(keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), \r\n                padding='same'))\r\n    model.add(keras.layers.Flatten())\r\n    model.add(keras.layers.Dense(1024, activation='relu',\r\n                kernel_initializer=initializer,\r\n                bias_initializer=initializer))\r\n    model.add(keras.layers.Dense(nb_filts[3], activation='relu',\r\n                kernel_initializer=initializer,\r\n                bias_initializer=initializer))\r\n    model.add(keras.layers.Dense(out_size))\r\n\r\n    optimizer = tf.keras.optimizers.Adam(1e-3)\r\n    model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mean_squared_error', 'mean_absolute_error'])\r\n\r\nwith strategy.scope():\r\n    batch_size = 32\r\n    nb_epochs = 1\r\n    history = model.fit(dataset.batch(batch_size, drop_remainder=True), epochs=nb_epochs, steps_per_epoch=training_samples // batch_size, verbose=1)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1355     try:\r\n-> 1356       return fn(*args)\r\n   1357     except errors.OpError as e:\r\n\r\n14 frames\r\nInvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node Adam/NcclAllReduce}}with these attrs: [shared_name=\"c0\", T=DT_FLOAT, num_devices=1, reduction=\"sum\"]\r\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Adam/NcclAllReduce]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\nInvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by node Adam/NcclAllReduce (defined at <ipython-input-8-7f03033581ef>:4) with these attrs: [shared_name=\"c0\", T=DT_FLOAT, num_devices=1, reduction=\"sum\"]\r\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Adam/NcclAllReduce]]\r\n```", "comments": ["@ssable , I tried executing the given code on Colab with Tensorflow 1.14.0 with GPU activate. I didn't get any error. Can you check once and let us know, is still an issue. Thanks! ", "Thank you for your feedback.\r\nI tried again and indeed the code works fine. Sorry for the confusion.\r\n\r\nI modified the example above to add MirroredStrategy() which is what is causing the issue. You should be able to reproduce the bug this time.", "@ssable I tried reproducing the issue on Colab with the updated code and i didn't see any error. Let us know the expected behavior. Thanks! ", "I just tried creating a new notebook, activating GPU, putting the code above in the notebook and running and... I still get the exception above.\r\nI am not sure what can be the difference between our 2 environments.\r\n\r\nHere is the full callstack:\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1355     try:\r\n-> 1356       return fn(*args)\r\n   1357     except errors.OpError as e:\r\n\r\n16 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1338       # Ensure any changes to the graph are reflected in the runtime.\r\n-> 1339       self._extend_graph()\r\n   1340       return self._call_tf_sessionrun(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _extend_graph(self)\r\n   1373     with self._graph._session_run_lock():  # pylint: disable=protected-access\r\n-> 1374       tf_session.ExtendSession(self._session)\r\n   1375 \r\n\r\nInvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node Adam/NcclAllReduce}}with these attrs: [reduction=\"sum\", shared_name=\"c0\", T=DT_FLOAT, num_devices=1]\r\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Adam/NcclAllReduce]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-1-f5513cfe82bc> in <module>()\r\n     62     batch_size = 32\r\n     63     nb_epochs = 1\r\n---> 64     history = model.fit(dataset.batch(batch_size, drop_remainder=True), epochs=nb_epochs, steps_per_epoch=training_samples // batch_size, verbose=1)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    647             steps_per_epoch=steps_per_epoch,\r\n    648             validation_steps=validation_steps,\r\n--> 649             validation_freq=validation_freq)\r\n    650 \r\n    651     batch_size = self._validate_or_infer_batch_size(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py in fit_distributed(model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\r\n    141         validation_steps=validation_steps,\r\n    142         validation_freq=validation_freq,\r\n--> 143         steps_name='steps_per_epoch')\r\n    144 \r\n    145 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\r\n    155 \r\n    156   # Get step function and loop type.\r\n--> 157   f = _make_execution_function(model, mode)\r\n    158   use_steps = is_dataset or steps_per_epoch is not None\r\n    159   do_validation = val_inputs is not None\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py in _make_execution_function(model, mode)\r\n    529   \"\"\"Makes function to run one step of model execution.\"\"\"\r\n    530   if model._distribution_strategy:\r\n--> 531     return distributed_training_utils._make_execution_function(model, mode)\r\n    532   return model._make_execution_function(mode)\r\n    533 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py in _make_execution_function(model, mode)\r\n    778   \"\"\"Makes or reuses function to run one step of distributed model execution.\"\"\"\r\n    779   if is_distributing_by_cloning(model):\r\n--> 780     return _make_execution_function_with_cloning(model, mode)\r\n    781 \r\n    782   distributed_function = get_distributed_function(model, mode)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py in _make_execution_function_with_cloning(model, mode)\r\n    862     distributed_function = _make_eager_execution_function(model, mode)\r\n    863   else:\r\n--> 864     distributed_function = _make_graph_execution_function(model, mode)\r\n    865 \r\n    866   # We cache the distributed execution function on the model since creating\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py in _make_graph_execution_function(model, mode)\r\n    889     # needed. This method does initialization or waiting for initialization\r\n    890     # according to the context object of distribute coordinator.\r\n--> 891     init_restore_or_wait_for_variables()\r\n    892 \r\n    893     # Unwrap all the per device values returned from `call_for_each_replica`.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py in init_restore_or_wait_for_variables()\r\n    368   if not worker_context or worker_context.experimental_should_init:\r\n    369     # TODO(yuefengz): if checkpoints exist, restore from checkpoint.\r\n--> 370     K._initialize_variables(session)  # pylint: disable=protected-access\r\n    371   else:\r\n    372     _wait_for_variable_initialization(session)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in _initialize_variables(session)\r\n    877     # marked as initialized.\r\n    878     is_initialized = session.run(\r\n--> 879         [variables_module.is_variable_initialized(v) for v in candidate_vars])\r\n    880     uninitialized_vars = []\r\n    881     for flag, v in zip(is_initialized, candidate_vars):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    948     try:\r\n    949       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 950                          run_metadata_ptr)\r\n    951       if run_metadata:\r\n    952         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1171     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1172       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1173                              feed_dict_tensor, options, run_metadata)\r\n   1174     else:\r\n   1175       results = []\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1348     if handle is None:\r\n   1349       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1350                            run_metadata)\r\n   1351     else:\r\n   1352       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1368           pass\r\n   1369       message = error_interpolation.interpolate(message, self._graph)\r\n-> 1370       raise type(e)(node_def, op, message)\r\n   1371 \r\n   1372   def _extend_graph(self):\r\n\r\nInvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by node Adam/NcclAllReduce (defined at <ipython-input-1-f5513cfe82bc>:64) with these attrs: [reduction=\"sum\", shared_name=\"c0\", T=DT_FLOAT, num_devices=1]\r\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Adam/NcclAllReduce]]\r\n```\r\n", "I could able to reproduce the issue on Colab with TF 1.14.0. Look at the gist [here](https://colab.research.google.com/drive/1ryWl00ykTXykIO01Ne45eyjHW4W1XaOb). Thanks!", "Hi, this has been fixed already so if you use the latest versions of TF, you should not see this issue. I just tested with latest tf nightly (https://pypi.org/project/tf-nightly-gpu/) and it works fine. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30835\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30835\">No</a>\n"]}, {"number": 30834, "title": "tf 2.0 Keras GaussianNoise to supports dtype=tf.float64", "body": "**System information**\r\n- TensorFlow version (you are using): `2.0.0-beta1`\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n* This (`model_float32`) works\r\n```python\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\ndef model_float32():\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.Dense(10, use_bias=False, input_shape=(10,)\r\n        ,dtype=tf.float32))\r\n\r\n    model.add(tf.keras.layers.GaussianNoise(0.0003))\r\n    return model\r\n\r\ntestmodel_32 =model_float32()\r\n```\r\nwithout error.\r\n```\r\n2.0.0-beta1\r\n```\r\n * However, the (`model_float64`) dose not work.\r\n```python\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\ndef model_float64():\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.Dense(10, use_bias=False, input_shape=(10,)\r\n        ,dtype=tf.float64))\r\n\r\n    model.add(tf.keras.layers.GaussianNoise(0.0003))\r\n    return model\r\n\r\ntestmodel_64 =model_float64()\r\n```\r\nThe error output is shown as below.\r\n```python\r\n2.0.0-beta1\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    526                 as_ref=input_arg.is_ref,\r\n--> 527                 preferred_dtype=default_dtype)\r\n    528           except TypeError as err:\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\r\n   1236     if ret is None:\r\n-> 1237       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1238 \r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\r\n   1035         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\" %\r\n-> 1036         (dtype.name, t.dtype.name, str(t)))\r\n   1037   return t\r\n\r\nValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: 'Tensor(\"random_normal:0\", shape=(None, 10), dtype=float32)'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-11-450afed79e6d> in <module>\r\n     10     return model\r\n     11 \r\n---> 12 testmodel_64 =model_float64()\r\n\r\n<ipython-input-11-450afed79e6d> in model_float64()\r\n      7         ,dtype=tf.float64))\r\n      8 \r\n----> 9     model.add(tf.keras.layers.GaussianNoise(0.0003,dtype=tf.float64))\r\n     10     return model\r\n     11 \r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    456     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    457     try:\r\n--> 458       result = method(self, *args, **kwargs)\r\n    459     finally:\r\n    460       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)\r\n    191       # If the model is being built continuously on top of an input layer:\r\n    192       # refresh its output.\r\n--> 193       output_tensor = layer(self.outputs[0])\r\n    194       if len(nest.flatten(output_tensor)) != 1:\r\n    195         raise TypeError('All layers in a Sequential model '\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    660                     not base_layer_utils.is_in_eager_or_tf_function()):\r\n    661                   with auto_control_deps.AutomaticControlDependencies() as acd:\r\n--> 662                     outputs = call_fn(inputs, *args, **kwargs)\r\n    663                     # Wrap Tensors in `outputs` in `tf.identity` to avoid\r\n    664                     # circular dependencies.\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/keras/layers/noise.py in call(self, inputs, training)\r\n     68           shape=array_ops.shape(inputs), mean=0., stddev=self.stddev)\r\n     69 \r\n---> 70     return K.in_train_phase(noised, inputs, training=training)\r\n     71 \r\n     72   def get_config(self):\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in in_train_phase(x, alt, training)\r\n   4051 \r\n   4052   # else: assume learning phase is a placeholder tensor.\r\n-> 4053   x = switch(training, x, alt)\r\n   4054   return x\r\n   4055 \r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in switch(condition, then_expression, else_expression)\r\n   3986     else:\r\n   3987       else_expression_fn = else_expression\r\n-> 3988     x = control_flow_ops.cond(condition, then_expression_fn, else_expression_fn)\r\n   3989   else:\r\n   3990     # tf.where needs its condition tensor\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    505                 'in a future version' if date is None else ('after %s' % date),\r\n    506                 instructions)\r\n--> 507       return func(*args, **kwargs)\r\n    508 \r\n    509     doc = _add_deprecated_arg_notice_to_docstring(\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py in cond(pred, true_fn, false_fn, strict, name, fn1, fn2)\r\n   1145   if (util.EnableControlFlowV2(ops.get_default_graph()) and\r\n   1146       not context.executing_eagerly()):\r\n-> 1147     return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n   1148 \r\n   1149   # We needed to make true_fn/false_fn keyword arguments for\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/ops/cond_v2.py in cond_v2(pred, true_fn, false_fn, name)\r\n     77             true_name, collections=ops.get_default_graph()._collections),  # pylint: disable=protected-access\r\n     78         add_control_dependencies=add_control_dependencies,\r\n---> 79         op_return_value=pred)\r\n     80     false_graph = func_graph_module.func_graph_from_py_func(\r\n     81         false_name,\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    714                                           converted_func)\r\n    715 \r\n--> 716       func_outputs = python_func(*func_args, **func_kwargs)\r\n    717 \r\n    718       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/keras/layers/noise.py in noised()\r\n     66     def noised():\r\n     67       return inputs + K.random_normal(\r\n---> 68           shape=array_ops.shape(inputs), mean=0., stddev=self.stddev)\r\n     69 \r\n     70     return K.in_train_phase(noised, inputs, training=training)\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\r\n    882     with ops.name_scope(None, op_name, [x, y]) as name:\r\n    883       if isinstance(x, ops.Tensor) and isinstance(y, ops.Tensor):\r\n--> 884         return func(x, y, name=name)\r\n    885       elif not isinstance(y, sparse_tensor.SparseTensor):\r\n    886         try:\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py in add(x, y, name)\r\n    385   try:\r\n    386     _, _, _op = _op_def_lib._apply_op_helper(\r\n--> 387         \"Add\", x=x, y=y, name=name)\r\n    388   except (TypeError, ValueError):\r\n    389     result = _dispatch.dispatch(\r\n\r\n~/miniconda3/envs/keras_tf2.0_b_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    561                   \"%s type %s of argument '%s'.\" %\r\n    562                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\r\n--> 563                    inferred_from[input_arg.type_attr]))\r\n    564 \r\n    565           types = [values.dtype]\r\n\r\nTypeError: Input 'y' of 'Add' Op has type float32 that does not match type float64 of argument 'x'.\r\n\r\n\u200b\r\n```\r\n\r\n\r\n**Will this change the current api? How?**\r\n`tf.keras.layers.GaussianNoise` to support `dtype argument`\r\n**Who will benefit with this feature?**\r\nAny one who use `float64` datatype.\r\n**Any Other info.**\r\n", "comments": ["Hi,\r\nI looked up the source code and it appears you do not even need a dtype argument when instantiating the layer, since the noise is being generated on each call. I therefore submitted a PR to have the noise's dtype adjusted to that of the inputs on each call, which should fix your issue without requiring any specification in the code.", "Hi,\r\nThank you for prompt PR. \r\nI've updated the comment to not to take `dtype` as argument (not to change the specification of keras).\r\nThank you.", "No problem, thank you for spotting and reporting the bug!\r\n\r\nIf you want to integrate the fix (which is really nothing in terms of coding effort) in your local installation without waiting for the PR validation process, you may simply update the `<somewhere on your computer>/site-packages/tensorflow/python/tensorflow/keras/layers.noise.py` file and it should work.", "@bluehope \r\nAfter some time, the PR was merged into the master branch a few hours ago; this means the feature is not part of the recent 2.0 rc0, but should be part of future releases. In the meanwhile, you can still use a local copy of the updated `noise.py` file, as previously indicated (or you can temporarily make it part of your code projects and use the locally-defined class instead of the one shipped with tensorflow, if you need to distribute it to other people).", "Dear @pandrey-fr,\r\nThank you for your dedication for the patch.\r\nCongratulations for your updated code merged into the master branch.\r\nWe will be happy with the newly released version. \r\nThank you :)", "You are very welcome (and although I am happy the PR got accepted, it is very few lines of code; thank *you* for pointing out the issue in the first place)."]}, {"number": 30833, "title": "New Corrected a typo in CrossEntropy", "body": "Here is a gist that show the corrected output after correcting typo. Thanks!", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30833) for more info**.\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30833) for more info**.\n\n<!-- ok -->"]}, {"number": 30832, "title": "Cannot convert from tensorflow to tensorflow lite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9\r\n- TensorFlow installed from (source or binary): From Conda\r\n- TensorFlow version (or github SHA if from source): 1.14.0\r\n\r\n\r\n**Text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK, WHERE. Here is a list of operators for which you will need custom implementations: DecodeBmp, DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, Merge, NonMaxSuppressionV3, ParseSingleExample, Substr, Switch.\r\n```\r\n\r\nGraphDef :  \r\nhttps://github.com/michisaak/ObjectDetection/blob/master/saved_model.pb\r\n\r\n**Logs**\r\nTraceback (most recent call last):\r\n  File \"/home/michaili/anaconda2/envs/retrain/bin/toco_from_protos\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/home/michaili/anaconda2/envs/retrain/lib/python3.5/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/michaili/anaconda2/envs/retrain/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/michaili/anaconda2/envs/retrain/lib/python3.5/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/michaili/anaconda2/envs/retrain/lib/python3.5/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/michaili/anaconda2/envs/retrain/lib/python3.5/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33, in execute\r\n    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n\r\n", "comments": ["@michisaak Please provide any commands you followed to convert Tflite model.Thanks! ", "https://github.com/tensorflow/tensorflow/issues/30185#issuecomment-506833929"]}, {"number": 30831, "title": "How to get the detail type of auto eigen variable in op", "body": "The auto variable is annoying in eigen as the interpreter cannot decide how to interpret it. See the detail [here](https://stackoverflow.com/questions/57057123/how-to-get-the-scalar-value-returned-by-eigen-tensors-sqrt-function/57075471#57075471)", "comments": ["@sjtusmartboy ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Ubuntu 18.10 Tf 1.14 compiled from source\r\n\r\nI modify the code [here](https://github.com/tensorflow/tensorflow/blob/c174697c09737e543e1919ca5cd5cfc373a96012/tensorflow/core/kernels/training_ops.cc#L2310) in line 2310 and 2311 to be the code as follows\r\n\r\n```\r\nauto linear_square = linear * linear;                                        \r\nauto linear_square_sum = linear_square.sum();                         \r\nEigen::Tensor<T,0> _linear_l21_norm = linear_square_sum.rsqrt();\r\nauto x =  linear.constant(_linear_l21_norm()) * linear.constant(l1_scalar) * linear.constant(static_cast<T>(sqrt(inner_dim)))  * linear - linear; \r\n```\r\n\r\nwhich gives me the error at the third code line, maybe the error is about the type mismatch of Eigen::Tensor<T,0>. I can cout the value of _linear_l21_norm if I modify the code to be \r\n\r\n`auto _linear_l21_norm = linear_square_sum.rsqrt();`\r\n\r\nbut since I want to construct an array same size with that of the 'linear' and the parameter of constant must be of type scalar, I give the variable _linear_l21_norm the type of Eigen::Tensor<T,0>. Unfortunately, it gives the static assert error when compiling and it tells me I made a programming mistake. So my question is how I can construct the array linear.constant(_linear_l21_norm()) and why the type of Eigen::Tensor<T,0> cannot be assigned to _linear_l21_norm.", "Can you ask this question in the eigen repository? I don't think it's TF-specific."]}, {"number": 30830, "title": "The model of tf1 cannot be converted to a model of tflite in tf2", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-beta\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: GTX-1080Ti\r\n\r\n**Describe the current behavior**\r\n![\u5fae\u4fe1\u56fe\u7247_20190718111406](https://user-images.githubusercontent.com/11308780/61426503-2df33400-a94d-11e9-9a56-226c1e6c7a06.png)\r\n\r\n**Describe the expected behavior**\r\nConvent successfully.\r\n\r\n**Code to reproduce the issue**\r\n``` python\r\nimport tensorflow as tf\r\n\r\nmodelPath = 'saved/old-model.h5'\r\nmodel = tf.keras.models.load_model(modelPath, compile=False)\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(\r\n    model\r\n)\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n**Other info / logs**\r\nHere are the model link\r\n[model.h5](https://drive.google.com/file/d/1nwb0IOh6UVwJmV0QJgsiYawCKT0RVpxI/view?usp=sharing)", "comments": ["I ran the code you provided with the model you provided on the `tf-nightly-2.0-preview` (which is a more recent beta) and I was able to convert the model successfully. For context I ran `pip install tf-nightly-2.0-preview` and have version `2.0.0.dev20190719` installed.", "@theangels \r\nDid you get a chance to check the comments by @gargn .Thanks!", "@gargn \r\nI'm sorry for reply late, my TensorFlow's version is v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1.\r\n\r\nI installed the TensorFlow by using this.\r\n`pip install tensorflow-gpu==2.0.0-beta1`\r\n\r\nHow to install the latest tf2.0 gpu version?", "You can install it with `pip install tf-nightly-gpu-2.0-preview`. I tested on last night's GPU nightly (`2.0.0.dev20190725`) and the code seems to work there as well.", "I update the tf2.0 version but still not work.\r\n\r\nThe error message are the same as previous.\r\n\r\n![snipaste20190726_091755](https://user-images.githubusercontent.com/11308780/61919018-5fd84c00-af86-11e9-8171-6b920d559197.png)\r\n\r\n![snipaste20190726_092044](https://user-images.githubusercontent.com/11308780/61919100-aaf25f00-af86-11e9-90fe-40128e10db9f.png)\r\n", "@theangels I ran your code and `old-model.h5` and everything works as expected in Google colab. Please find the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/28f5e193e4b94804fc7cb4e1fde942fa/tf30830.ipynb).\r\n\r\nI think there is some installation issue. Did you follow the instructions listed [here](https://www.tensorflow.org/install) for installing `TF2.0`. First uninstall current version, restart computer and install new `TF2.0` by following the instructions on TF website. Thanks!", "@theangels Did you had time to review my shared gist? Thanks!", "@jvishnuvardhan Sorry for reply late, I try your shared gist and update the tensorflow version to tensorflow-gpu(current version is 2.0.0), it works, thank you!"]}, {"number": 30829, "title": "how can I create a model without tf.keras in tf2.0", "body": "if I use tf2.0 and not use tf.keras, which advanced api(like tf.layers.* or tf.contrib.* in  tf1.x ) I can use for creating model", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 30828, "title": "error: static assertion failed: Specified Data Type not supported", "body": "`auto gt_pts_trans = tensorflow::ops::Transpose(root, gt_pts, NULL);`\r\nI used 'tensorflow::ops::Transpose()' and occurred error despite gt_pts is DT_FLOAT\r\n\r\n> error: static assertion failed: Specified Data Type not supported\r\n> static_assert(IsValidDataType::value, \"Specified Data Type not supported\");\r\n> error: \u2018v\u2019 is not a member of \u2018tensorflow::DataTypeToEnum\u2019\r\n> Tensor t(DataTypeToEnum::v(), TensorShape());\r\n", "comments": ["@maohuui ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 30827, "title": "Add reallocation capability to bfc_allocator.", "body": "This commit mitigates external fragmentation in bfc_allocator by reallocation.\r\nThat is, although the sum of regions and unallocated bytes is larger than the\r\nrequested bytes but the bfc_allocator still fails to allocate a large enough\r\ncontiguous region to fulfill the request due to fragmentation. To avoid this\r\ncase, a relocation feature is implemented to deallocate free regions so that\r\na larger region can be formed.\r\n\r\nNote that essentially we are able to play this trick because the underlying GPU\r\ndriver will be able to manipulate the vtable to return a region with a contiguous\r\nvirtual address space.", "comments": ["Revised based on the received review comments. Please help to take a look again when you have a moment. Thanks.", "@tayo do you want to give the final LGTM?", "I think it would be wise to add a guard flag so that if this causes problems it can be disabled?  (Unless that's already there and I'm missing it.)", "If I'm reading the code correctly, this only helps when allow-growth is on, is that right?  Because we can only free units malloc'ed by individual cudaMalloc calls (these are called \"regions\" in the code?).  But when allow-growth is off, we malloc one big region, so the only case when we're able to free it is when it's empty, but then there's no need to free it.", "> If I'm reading the code correctly, this only helps when allow-growth is on, is that right? Because we can only free units malloc'ed by individual cudaMalloc calls (these are called \"regions\" in the code?). But when allow-growth is off, we malloc one big region, so the only case when we're able to free it is when it's empty, but then there's no need to free it.\r\n\r\nThat is a correct read. This commit only helps with the `allow_growth=true` mode, as in the `allow_growth=false` mode the entire memory is just one region (yes, this is a malloc'ed allocation) in the current implementation.\r\n\r\nSome data points: I hit this memory fragmentation issue with a resent50 model from _Joy of Cooking_ and it has `allow_growh=true` by default in its implementation. Without the PR, we can only bring up the fp32 model up to batch_size=96 w/ XLA, while vanilla TF can run with batch_size=128. With this PR, XLA can run up to batch_size=160. Somehow surprisingly, even if I set `allow_growth=false`, XLA cannot bring up the model with batch_size=128.\r\n\r\nOne more thing I'd like to point out for discussions is that it is possible for this PR to help with the `allow_growth=false` case (in the future), as long as we pre-allocate the entire memory with a set of regions with sizes, e.g., 100MB+200MB+400MB+...+4GB+8GB (instead of one giant region). I did not make the corresponding change because it is not (yet) clear to me if it will hurt some cases.", "> I think it would be wise to add a guard flag so that if this causes problems it can be disabled? (Unless that's already there and I'm missing it.)\r\n\r\nI don't mind and can help to add a guard flag (by introducing an env variable to turn it off?). However, logically, the new feature is only triggered when OOM happens in the original implementation. So, turning off the feature can only hit an OOM when there is an issue executing the new reallocation feature.\r\n\r\nThat's been said, it may still be possible that having a guard flag can help with debugging? Let me know what you think.\r\n", "> I hit this memory fragmentation issue with a resent50 model from Joy of Cooking and it has allow_growh=true by default in its implementation.\r\n\r\nPerhaps this explains some or all of the difference between what you were seeing (lots of OOMs) and what I was seeing (few OOMs) when we last talked about this in our meeting.  allow_growth=true is not the default setting in TensorFlow overall.\r\n\r\n> However, logically, the new feature is only triggered when OOM happens in the original implementation. So, turning off the feature can only hit an OOM when there is an issue executing the new reallocation feature.\r\n\r\nI think some users may prefer to know that they're OOMing instead of hitting potentially pathological slowdowns in their code.  A guard flag would also aid in debugging if we suspect this change could be causing an unexpected problem.  In general guard flags are cheap and can have large benefits.", ">> ... Somehow surprisingly, even if I set allow_growth=false, XLA cannot bring up the model with batch_size=128.\r\n\r\n> Perhaps this explains some or all of the difference between what you were seeing (lots of OOMs) and what I was seeing (few OOMs) when we last talked about this in our meeting. allow_growth=true is not the default setting in TensorFlow overall.\r\n\r\nNote that I meant (as quoted above) that in my observed case, setting `allow_growth=false` does not help. Only `allow_growth=true` with this PR brings up the ResNet50 with batch_size not smaller than vanilla TF can do.\r\n\r\n> I think some users may prefer to know that they're OOMing instead of hitting potentially pathological slowdowns in their code. A guard flag would also aid in debugging if we suspect this change could be causing an unexpected problem. In general guard flags are cheap and can have large benefits.\r\n\r\nAgreed. Will add a guard flag. (Hard to say what users want.)\r\n", "> Note that I meant (as quoted above) that in my observed case, setting allow_growth=false does not help.\r\n\r\nMaybe I misunderstand, but I thought you wrote above that with allow_growth=False XLA gets batch 128.  With allow_growth=True and without this PR, XLA gets batch 96.\r\n\r\nI don't mean to parse words, but that would suggest to me that allow_growth=False *does* help, just not as much as you might want?\r\n\r\nI agree it is odd that you are able to match TF's batch 160 with allow_growth=True + this PR but not with allow_growth=False.  I don't have an explanation for that, but I think it might be worth trying to understand.", "> @tayo do you want to give the final LGTM?\r\n\r\nWill do after guard flag commit, requested by jlebar", "When allow_growth=false, the allocator's constructor begins by claiming the entirety of memory.  When allow_growth=true, the allocator starts by claiming 1MB.  \r\n\r\nPerhaps starting with one large chunk that is split as needed will more quickly lead to the large-block external fragmentation issue that Trent has observed.  Almost like initializing the state of free memory with a different 'seed'.", "\r\nJust pushed a new commit adding the guard flag. Please help to take a look. @tayo \r\n\r\nI double checked and here are some notes and clarifications:\r\n1. I was not precise. **Both** `allow_growh=false` _and_ `allow_growh=true` with this PR can do batch_size=160 for my Joy-of-Cooking Resnet50.\r\n\r\n2. So, @jlebar you are right that this explains _partial_ difference between our observations about OOM.\r\n\r\n3. We do have another XLA OOM bug (Joy-of-Cooking GNMT) with `allow_growth=false` due to _internal_ memory fragmentation.\r\n", "> 3\\. We do have another XLA OOM bug (Joy-of-Cooking GNMT) with `allow_growth=false` due to _internal_ memory fragmentation.\r\n\r\nFYI, there is a max internal fragmentation parameter you could play with, in case you were not aware.\r\nhttps://github.com/tensorflow/tensorflow/blob/83f4a0c638988a040824081d0224964e1684214a/tensorflow/core/common_runtime/bfc_allocator.cc#L445", "> I was not precise. Both allow_growh=false and allow_growh=true with this\nPR can do batch_size=160 for my Joy-of-Cooking Resnet50.\n\nThat is surprising, since we said that this change should have no effect\nwith allow_growth=false, right?  Do we understand this?\n\nOn Fri, Jul 19, 2019, 12:46 PM Tayo Oguntebi <notifications@github.com>\nwrote:\n\n> 3. We do have another XLA OOM bug (Joy-of-Cooking GNMT) with\n> allow_growth=false due to *internal* memory fragmentation.\n>\n> FYI, there is a max internal fragmentation parameter you could play with,\n> in case you were not aware.\n>\n> https://github.com/tensorflow/tensorflow/blob/83f4a0c638988a040824081d0224964e1684214a/tensorflow/core/common_runtime/bfc_allocator.cc#L445\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/30827?email_source=notifications&email_token=AABEZB62CJAEHVEDWMHIXPDQAIKZTA5CNFSM4IEVUDSKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2MSKAI#issuecomment-513352961>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABEZB5YNFRXH22KNWMXS2DQAIKZTANCNFSM4IEVUDSA>\n> .\n>\n", "> we said that this change should have no effect with allow_growth=false\r\n\r\nI did not agree with this.  This change will have an effect with allow_growth=false.  The value of allow_growth would simply determine the starting state of the free chunk list.  This change takes effect when the OOM is about to occur, by doing the collection pass.", "Tayo, Trent agreed with it earlier:\nhttps://github.com/tensorflow/tensorflow/pull/30827#issuecomment-513100384\nIt's surprising to me that he's now saying that this does have an effect\nwith allow_growth=false, because I don't see how that can matter.  There is\nonly one allocation to play with (?), so you can't free and coalesce allocs\nlike this PR tries to.\n\n\nOn Fri, Jul 19, 2019, 1:11 PM Tayo Oguntebi <notifications@github.com>\nwrote:\n\n> we said that this change should have no effect with allow_growth=false\n>\n> I did not agree with this. This change will have an effect with\n> allow_growth=false. The value of allow_growth would simply determine the\n> starting state of the free chunk list. This change takes effect when the\n> OOM is about to occur, by doing the collection pass.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/30827?email_source=notifications&email_token=AABEZBYV44WMA3P2W7FABODQAINVNA5CNFSM4IEVUDSKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2MUCXA#issuecomment-513360220>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABEZB34PB2KJ6KX7B36STTQAINVNANCNFSM4IEVUDSA>\n> .\n>\n", "@jlebar Some natural language ambiguity. Please read the following rephrased sentence again.\r\n\r\nBoth `allow_growh=false without the PR` and `allow_growh=true with this PR` can do batch_size=160 for my Joy-of-Cooking Resnet50.\r\n", "> > 3. We do have another XLA OOM bug (Joy-of-Cooking GNMT) with `allow_growth=false` due to _internal_ memory fragmentation.\r\n> \r\n> FYI, there is a max internal fragmentation parameter you could play with, in case you were not aware.\r\n> \r\n> https://github.com/tensorflow/tensorflow/blob/83f4a0c638988a040824081d0224964e1684214a/tensorflow/core/common_runtime/bfc_allocator.cc#L445\r\n\r\nWill play with the parameter later. Thanks for the info.\r\n", "@jlebar -- Good point\r\n\r\n@trentlo -- Can you confirm that with this PR, your runs converge / work as expected?", "> @trentlo -- Can you confirm that with this PR, your runs converge / work as expected?\r\n\r\nYes, they work as expected. It is some natural language ambiguity as I replied [here](https://github.com/tensorflow/tensorflow/pull/30827#issuecomment-513371892). This PR does not help with the `allow_growh=false` mode.\r\n\r\nBTW, I just pushed a commit fixing a compilation error observed in the (previous) CI runs. Some compilers do not allow passing const_iterator to std::vector::erase(). It will be good if you can take a look.\r\n ", "Sorry, I am still having difficulty assimilating everything that was said here into a consistent picture of the world.\r\n\r\n> Note that I meant (as quoted above) that in my observed case, setting allow_growth=false does not help. Only allow_growth=true with this PR brings up the ResNet50 with batch_size not smaller than vanilla TF can do.\r\n\r\nThis seems unambiguous to me.  But now I'm hearing something which seems to contradict this:\r\n\r\n> Both allow_growh=false without the PR and allow_growh=true with this PR can do batch_size=160 for my Joy-of-Cooking Resnet50.\r\n\r\nI would assume that the first was simply an error, but I am hearing that this is all due to natural language ambiguity, so I am not sure, maybe I'm misunderstanding something here?\r\n\r\nPerhaps in the name of clarity we could make the table specifying the max batch size for all combinations of the following booleans?\r\n\r\n * TF classic vs XLA\r\n * allow_growth = true vs false\r\n * without this PR vs with this PR", "\r\n> Sorry, I am still having difficulty assimilating everything that was said here into a consistent picture of the world.\r\n\r\nNo problem. Let's see if we can make things clearer.\r\n\r\n\r\n> \r\n> > Note that I meant (as quoted above) that in my observed case, setting allow_growth=false does not help. Only allow_growth=true with this PR brings up the ResNet50 with batch_size not smaller than vanilla TF can do.\r\n\r\nI realized this above statement was wrong after I double checked the experiments. Setting `allow_growth=false` XLA can do batch_size=160 (PR is irrelevant in this case). Sorry for the confusion.\r\n\r\n\r\n> \r\n> > Both allow_growh=false without the PR and allow_growh=true with this PR can do batch_size=160 for my Joy-of-Cooking Resnet50.\r\n> \r\n> Perhaps in the name of clarity we could make the table specifying the max batch size for all combinations of the following booleans?\r\n> \r\n>     * TF classic vs XLA\r\n> \r\n>     * allow_growth = true vs false\r\n> \r\n>     * without this PR vs with this PR\r\n\r\nIn the Joy-of-Cooking Resnet50 case,\r\nTF classic: batch_size=160 (PR irrelevant in this case; allow_growth irrelevant too.)\r\nXLA `allow_growth=false`: batch_size=160 (PR irrelevant in this case)\r\nXLA `allow_growth=true` _without_ this PR: batch_size=96\r\nXLA `allow_growth=true` _with_ this PR: batch_size=160\r\n\r\nLet me know if this clarifies the discussions.\r\n", "> Let me know if this clarifies the discussions\r\n\r\nYes, thanks a lot!", "Thanks for the reviews everyone, I think you got this under control :) Removing myself as a reviewer."]}, {"number": 30826, "title": "Corrected a typo in CategorcialCrossEntropy", "body": "Here is a [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/13a4de468dbb3853369b8c68caf521d1/pr_categorcialcrossentropy.ipynb) that show the corrected output after correcting typo. Thanks!", "comments": ["Changes have been merged internally , waiting for auto merge to happen."]}, {"number": 30825, "title": "Clean up the lock&tmp files for CacheDatasetOp when needed", "body": "This PR fixes #28798 and also enhances the tests for the `CacheDatasetOp` kernel.\r\n\r\ncc: @jsimsa ", "comments": ["@aaudiber Thanks for your review! The warning log is added here (https://github.com/tensorflow/tensorflow/pull/30825/commits/a5d8c796b60a57d907494db8295b4102d68b4941). Could you please take a look when you get a chance? ", "@aaudiber Thanks for your great suggestion! I have changed the code (skip the test in graph mode) as you suggested and also add the log info for deleting files in the test class. Please take another look (https://github.com/tensorflow/tensorflow/pull/30825/commits/0d4a50fb9a63d059ade8d3edac0a382eac7d6a33)!", "@aaudiber The internal checks failed. As I could not access the logs, could you help check the failure and paste the log details here?", "@feihugis The failing test is `tensorflow/python/data/experimental/kernel_tests/serialization:cache_dataset_serialization_test`\r\n\r\n```\r\nin testCheckpointBeforeOneEpochThenRunFewSteps\r\n    verify_exhausted=False)\r\n  File \"<embedded stdlib>/unittest/case.py\", line 116, in __exit__\r\n    \"{0} not raised\".format(exc_name))\r\nAssertionError: AlreadyExistsError not raised\r\n```", "Thanks, @aaudiber! As the lock file is deleted when deconstructing the iterator, `AlreadyExistsError` will not be raised. I fixed the test here (https://github.com/tensorflow/tensorflow/pull/30825/commits/2c7437a5be1c7a28c45a7691eebef3423425a85f).    "]}, {"number": 30824, "title": "Remove dead link.", "body": "Fixes: https://github.com/tensorflow/tensorflow/issues/30566", "comments": ["Changes have been merged internally , waiting for auto-merge to happen."]}, {"number": 30823, "title": "[ROCm] Fix for the broken `--config=rocm` build", "body": "The following PR/commit breaks the `--config=rocm` build\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/29224\r\n\r\nIt introduces a couple of GPU kernels which have CUDA specific data-structures + syntax, which leads to a compile failure on the ROCm platform. This PR fixes the ROCm build by converting the CUDA specific code to its equivalent GPU generic code.\r\n\r\n----------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg ", "comments": []}, {"number": 30822, "title": "tf.keras: Model with multiple outputs cause error", "body": "Hi\r\n\r\nI'm training an auto-encoder, and this is the model summary.\r\n\r\n```\r\nModel: \"model\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\nENCODER_INPUT (InputLayer)      [(None, 15)]         0                                            \r\n__________________________________________________________________________________________________\r\nembedding (Embedding)           (None, 15, 100)      400000      ENCODER_INPUT[0][0]              \r\n__________________________________________________________________________________________________\r\nencoder (Encoder)               (None, 50)           189746      embedding[0][0]                  \r\n__________________________________________________________________________________________________\r\ndecoder (Decoder)               (None, 15, 4000)     673696      encoder[0][0]                    \r\n__________________________________________________________________________________________________\r\nsentiment (Sentiment)           (None, 1)            2601        encoder[0][0]                    \r\n==================================================================================================\r\nTotal params: 1,266,043\r\nTrainable params: 1,266,043\r\nNon-trainable params: 0\r\n```\r\n\r\n\r\nwhen I call\r\n` autoencoder.fit(x=x, y={'decoded_mean': x_one_hot, 'pred': y}, epochs=1) `\r\n\r\nit will return error:\r\n```\r\n~/anaconda3/envs/tf2_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    449     except KeyError as e:\r\n    450       raise ValueError('No data provided for \"' + e.args[0] + '\". Need data '\r\n--> 451                        'for each key in: ' + str(names))\r\n    452   elif isinstance(data, (list, tuple)):\r\n    453     if isinstance(data[0], (list, tuple)):\r\n\r\nValueError: No data provided for \"decoder\". Need data for each key in: ['decoder', 'sentiment']\r\n```\r\n\r\nHowever, this code works, but I really want to modify the name of the losses:\r\n`autoencoder.fit(x=x, y=[x_one_hot, y], epochs=1)`\r\n\r\n\r\n\r\nIn addition, If I use run following code, It will directly kill everything without showing any errors.\r\n```\r\ndb = tf.data.Dataset.from_tensor_slices((x, {'decoded_mean': x_one_hot, 'pred': y}))\r\ndb = db.shuffle(1000).batch(batch_size)\r\nauotencoder.fit(db, epochs=1)\r\n```\r\n\r\n", "comments": ["@thomasyue ,\r\nIn order to expedite the trouble-shooting process, please provide complete code snippet to reproduce the issue reported here also provide TF version being used .Thanks!", "@anush-o \r\nThanks for the reply. I'm using tf 2: tensorflow-gpu==beta1\r\n\r\n```\r\nbatch_size = 64\r\ntotal_words = 10000\r\nmax_length = 150\r\nembedding_dim = 100\r\n\r\n(x, y), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=total_words)\r\n\r\nx = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=max_length)\r\nx_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_length)\r\nprint(x.shape, y.shape, x_test.shape, y_test.shape)\r\n\r\ntemp = np.zeros((x.shape[0], max_length, total_words))\r\ntemp[np.expand_dims(np.arange(x.shape[0]), axis=0).reshape(x.shape[0], 1), np.repeat(\r\n    np.array([np.arange(max_length)]), x.shape[0], axis=0), x] = 1\r\nx_one_hot = temp\r\n\r\n# create dataset\r\ndb = tf.data.Dataset.from_tensor_slices((x, {'decoded_mean': x_one_hot, 'pred': y}))\r\ndb = db.shuffle(1000).batch(batch_size)\r\n\r\nclass Encoder(tf.keras.layers.Layer):\r\n\r\n    def __init__(self, lstm_units, hidden_dim):\r\n        super(Encoder, self).__init__()\r\n\r\n        self.lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units,\r\n                                                                        return_sequences=True,\r\n                                                                        name='ENCODE_BiLSTM_1'))\r\n        self.lstm2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units,\r\n                                                                        return_sequences=False,\r\n                                                                        name='ENCODE_BiLSTM_2'))\r\n        self.hidden = tf.keras.layers.Dense(hidden_dim, activation=tf.nn.relu)\r\n\r\n    def call(self, inputs, training=None):\r\n        h = self.lstm1(inputs)\r\n        h = self.lstm2(h)\r\n        encoded = self.hidden(h)\r\n\r\n        return encoded\r\n\r\n\r\nclass Decoder(tf.keras.layers.Layer):\r\n\r\n    def __init__(self, max_len, lstm_units, vocab_size):\r\n        super(Decoder, self).__init__()\r\n\r\n        # [None, hidden_dim] -> [None, total_words, hidden_dim]\r\n        self.repeat = tf.keras.layers.RepeatVector(max_len)\r\n\r\n        self.lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units,\r\n                                                                        return_sequences=True,\r\n                                                                        name='DECODE_BiLSTM_1'))\r\n        self.lstm2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units,\r\n                                                                        return_sequences=True,\r\n                                                                        name='DECODE_BiLSTM_2'))\r\n        self.out = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size,\r\n                                                                         activation=tf.nn.softmax),\r\n                                                   name='OUTPUT')\r\n\r\n    def call(self, inputs, training=None):\r\n        h = self.repeat(inputs)\r\n        h = self.lstm1(h)\r\n        h = self.lstm2(h)\r\n        output = self.out(h)\r\n\r\n        return output\r\n\r\n\r\nclass Sentiment(tf.keras.layers.Layer):\r\n\r\n    def __init__(self, hidden_dim, num_classes):\r\n        super(Sentiment, self).__init__()\r\n\r\n        self.dense1 = tf.keras.layers.Dense(hidden_dim, activation=tf.nn.relu, name='SENTIMENT_FF_1')\r\n        self.senti_pred = tf.keras.layers.Dense(num_classes, activation='sigmoid', name='SENTIMENT_OUT')\r\n\r\n    def call(self, inputs, training=False):\r\n        x = self.dense1(inputs)\r\n        out = self.senti_pred(x)\r\n\r\n        return out\r\n\r\n\r\ndef AE(lstm_units, hidden_dim, num_classes, vocab_size, max_len):\r\n    input1 = tf.keras.layers.Input(shape=(max_len,), name='ENCODER_INPUT')\r\n\r\n    embed_layer = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n    encoder_layer = Encoder(lstm_units, hidden_dim)\r\n    sentiment_layer = Sentiment(hidden_dim, num_classes)\r\n    decoder_layer = Decoder(max_len, lstm_units, vocab_size)\r\n\r\n    embedded = embed_layer(input1)\r\n    encoded = encoder_layer(embedded)\r\n\r\n    sentiment_pred = sentiment_layer(encoded)\r\n\r\n    decoded = decoder_layer(encoded)\r\n\r\n    autoencoder = tf.keras.Model(inputs=input1, outputs=[decoded, sentiment_pred])\r\n\r\n    return autoencoder\r\n\r\nlstm_units = 64\r\nnum_classes = 2\r\nhidden_dim = 50\r\n\r\nautoencoder = AE(lstm_units, hidden_dim, num_classes, total_words, max_length)\r\n\r\nautoencoder.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\r\n                    loss=[tf.losses.SparseCategoricalCrossentropy(), tf.losses.BinaryCrossentropy()],\r\n                    metrics=['accuracy'])\r\nautoencoder.summary()\r\n\r\nautoencoder.fit(db, epochs=1) # this quit without showing any error\r\nautoencoder.fit(x=x, y={'decoded_mean': x_one_hot, 'pred': y}, epoch=1) # this returns value error\r\nautoencoder.fit(x=x, y=[x_one_hot, y], epoch=1) # this works\r\n```", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 30821, "title": "Update version numbers for TensorFlow 1.14.1", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 1 -> 1\nMinor: 14 -> 14\nPatch: 0 -> 1\n\nWARNING: Below are potentially instances of lingering old version string \n\"1.14.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/lite/experimental/objc/tests/TFLInterpreterTests.m:22:1.14.0\ntensorflow/lite/experimental/objc/tests/TFLInterpreterTests.m:23:1.14.0\ntensorflow/tools/pip_package/setup.py:64:1.14.0\ntensorflow/tools/pip_package/setup.py:65:1.14.0\ntensorflow/tools/pip_package/setup.py:95:1.14.0\n\nWARNING: Below are potentially instances of lingering old version string \n\"1.14.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/lite/experimental/objc/tests/TFLInterpreterTests.m:22:1.14.0\ntensorflow/lite/experimental/objc/tests/TFLInterpreterTests.m:23:1.14.0\ntensorflow/tools/pip_package/setup.py:64:1.14.0\ntensorflow/tools/pip_package/setup.py:65:1.14.0\ntensorflow/tools/pip_package/setup.py:95:1.14.0\n```", "comments": ["The other files strings are either comments or TF dependencies from the ecosystem"]}, {"number": 30820, "title": "Can xla compile tf.estimator.DNNLinearCombinedEstimator?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source 1.13\r\n- TensorFlow version: 1.13\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: \r\n- Bazel version (if compiling from source): 0.19\r\n- GCC/Compiler version (if compiling from source):4.8\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory:n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\ntrying to AOT compile a model trained using XLA \r\nerror :  {{node dnn/input_from_feature_columns/input_layer/xyz/axyz_embedding_weights/SparseReshape}}\r\n\t.  Registered:  <no registered kernels>\r\n){{node dnn/input_from_feature_columns/input_layer/ad__ad_id_embedding/ad__ad_id_embedding_weights/SparseReshape}}\r\n\r\nIs there any ETA on this being supported ? \r\n\r\nHow can AOT xla compile : tf.estimator.DNNLinearCombinedEstimator , is this even possible with current support ?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel-bin/tensorflow/compiler/aot/tfcompile --graph=mygrapht.pb --config=graphv.config.pbtxt --cpp_class=\"mynamespace::MyComputation\"\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@patelprateek Could you provide more details about the issue.Thanks!", "@gadagashwini : can you please elaborate what details you need ?\r\n\r\nI took the DNNLinearCombinedEstimator code , trained a model and then tried xla AOT compilation.\r\nCan't get that to compile because of the following error : \r\nerror : {{node dnn/input_from_feature_columns/input_layer/xyz/axyz_embedding_weights/SparseReshape}}\r\n. Registered: \r\n){{node dnn/input_from_feature_columns/input_layer/ad__ad_id_embedding/ad__ad_id_embedding_weights/SparseReshape}}\r\n\r\nseem slike SparseReshape is not supported yet.\r\n\r\nPlease let me know what details are you looking for , because i belive the above information is enough to reproduce the problem as well ?\r\ntf 1.12 bazel 0.19 gcc 4.8 python 2.7 ubuntu 16.04", "@patelprateek Please provide the reproducible code to expedite the trouble-shooting process. Thanks!\r\n", "@gadagashwini : Please read my previous update , you can take DNNLinearCombinedEstimator provided by estimators api and try compiling with xla.\r\nThere is no need for me to share any code here (plus that is all internal code and would be hard to share , i already gave you enough information), i am talking about the pre built estimators\r\nAlso the error clearly shows what kind of feature is problematic.. i.e embedding \r\nI think this is sufficient to reproduce ", "> Is there any ETA on this being supported ?\r\n\r\nNo, we're not investigating adding any sparse operations to XLA at this time.\r\n\r\nI don't know enough about the TF ops to state whether they're even a good fit for XLA, but if they are a good fit for XLA I'd be fine reviewing a PR adding XLA support for these ops.", "@sanjoy : can you please provide me some pointers or documentation regarding \"what is a good fit for xla\". I am happy to contribute and add PRs but would need some guidance , can you point me to some example PRs that adds support for few ops , that would be very helpful for me to understand the different pieces that needs to go in for supporting a new op .", "Probably the easiest way to get started is to look at some example TF->XLA lowerings and try to find one that is close to `SparseReshape`.  All the TF->XLA lowerings are in tensorflow/compiler/tf2xla/kernels/.\r\n\r\nFor instance, this file contains the dense reshape operation: tensorflow/compiler/tf2xla/kernels/reshape_op.cc, although I suspect the implementation of `SparseReshape` is probably going to be very different from `Reshape`.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30820\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30820\">No</a>\n"]}]