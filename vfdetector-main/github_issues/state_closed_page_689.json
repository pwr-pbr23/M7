[{"number": 32921, "title": "Unable to input categorical columns in my preprocessing layer for keras", "body": "Hi All,\r\n\r\nI am trying to use python to run the [example](https://www.tensorflow.org/tutorials/load_data/csv) which is given on the tensorflow website on working with .CSV data. This example is meant to use some features to predict if a passenger is labeled dead or alive on the titanic. Everything goes well until the point where I attempt to run a fit on the training data data. The error below is generated:\r\n\r\nFailedPreconditionError: Table already initialized.\r\n\t [[{{node sequential_9/dense_features_17/embark_town_indicator/embark_town_lookup/hash_table/table_init/LookupTableImportV2}}]] [Op:__inference_keras_scratch_graph_11639]\r\n\r\nIf I attempt to use the numeric features alone the code runs to completion. I have output the layers from a batch (small size batch of 3 - 5) and it makes sense to the data which is input.   Has anyone had similar experience or would anyone kindly help with this? Thank you. I have added the link to the website so that it can be accessed by anyone checking but if you need the ipython file, I can provide that too. Thanks in advance.", "comments": ["I tried runningthe same example on google colab and its working finr foe me without any errors. Please take a look at my github gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/236357c898cebaa78bfd470f953baf56/titanic.ipynb).", "I looked through the example on google colab and and it works fine as you said, however mine still doesn't work. I have pretty much everything exact same besides the way I import the data. I have downloaded the training and testing (eval) data unto my google drive. The reason I have it this way is that I want to familiarize myself with working with data on drive. So that in future when I have personal data I am working with it will be easy for me to work straight from drive. Would you mind looking at my .ipynb file to see if the error I am making stands out to you? I have attached a  [link](https://drive.google.com/file/d/13m1MuxJhcTc4xokiaR-NF3DP0ToCSdA8/view?usp=sharing) to my version of the example on colab.", "Hi all,\r\n\r\nSo my version of the example now runs to completion. Excluding the code below seemed to cause the issue I was having. But I have an observation which I will like to clarify. The example only runs to completion if the below code statement is included:\r\n\r\n```\r\ntry:\r\n  # %tensorflow_version only exists in Colab.\r\n  %tensorflow_version 2.x\r\nexcept Exception:\r\n  pass\r\n\r\n```\r\n\r\nThe comment written on it states it only exist on google colab. If its not included the Titanic code fails at any point where a tensor is is being converted to numpy. If all I have said so far hold true, how do we implement something similar on Jupyter notebook?  I have read that eager execution can achieve this but I don't know how to implement correctly and how it may differ between Jupyter and google collab. Thanks in advance.", "@Odera-Dim You can find my github_gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/a91990922687e78065a089425eb25b5b/untitled157.ipynb). This command `%tensorflow_version 2.x` is installing the latest version of tensorflow 2.x and the example only works in Tensorflow 2.0. \r\n\r\n> how do we implement something similar on Jupyter notebook?\r\n\r\nInstall tensorflow 2.0.0.rc2 using pip\r\n`pip install tensorflow==2.0.0.rc2`\r\n\r\nand the rest you can follow the same steps as given in colab", "Thanks a lot,  that went well and the example now works on Jupyter too. Below is a screenshot showing that TF is now updated to version 2.0. Thanks again for spending your time to walk me through this. Cheers.\r\n\r\n![TF_Update](https://user-images.githubusercontent.com/43386043/65965260-51962880-e42c-11e9-91d1-9b0c4d734d44.png)\r\n\r\n\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32921\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32921\">No</a>\n"]}, {"number": 32920, "title": "How to explitly save the values of every buffer in a tflite model?", "body": "When using interpreter.get_tensor() to get the values in a tensor after calling interpreter.invoke(), some values seem to be overwritten. If I understand correctly, to explicitly prevent those values from being overwritten, we have to append the names of the tensors we care about in the \"output_arrays\" argument when calling tf.lite.TFLiteConverter.from_saved_model(). However, some tensors in a tflite model are called \"xx_int8\" and they don't exist in the original saved model. In this case, how do we include them in \"output_arrays\"?", "comments": ["@bwang-delft ,\r\nIs this still an issue?\r\nCould you please update TensorFlow to the latest stable version v.2.6 and let us know if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32920\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32920\">No</a>\n"]}, {"number": 32919, "title": "Multiple sessions with per_process_gpu_memory_fraction", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): 1.14.0\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: 10.0 / 7.4.2.24-1\r\n- GPU model and memory: GTX 1070ti, 8119Mb\r\n\r\n**Describe the current behavior**\r\nStart multiple sessions with gpu_options and different per_process_gpu_memory_fraction, but tensorflow outputs same amount of memory for both sessions:\r\n```\r\n...\r\ntensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a67330 executing computations on platform CUDA. Devices:\r\ntensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1070 Ti, Compute Capability 6.1\r\ntensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz\r\ntensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a645c0 executing computations on platform Host. Devices:\r\ntensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:01:00.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n\r\n... init second ...\r\n\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\ntensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n```\r\n\r\n**Describe the expected behavior**\r\nI expect each session to allocate amount of memory specified in config.gpu_options\r\n\r\n```\r\n...\r\nCreated TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory)\r\n...\r\nCreated TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 300 MB memory)\r\n```\r\n\r\n**Code to reproduce the issue**\r\n    \r\n    def init_first(self):\r\n        graph_def = tf.compat.v1.GraphDef()\r\n        with tf.io.gfile.GFile(self.MODEL_PATH[0], 'rb') as f:\r\n            graph_def.ParseFromString(f.read())\r\n\r\n        graph = tf.Graph()\r\n        with graph.as_default():\r\n            tf.import_graph_def(graph_def, name='import')\r\n\r\n        input = graph.get_tensor_by_name('import/image_tensor:0')\r\n        output = [\r\n            graph.get_tensor_by_name('import/boxes:0'),\r\n            graph.get_tensor_by_name('import/scores:0'),\r\n        ]\r\n\r\n        config = tf.compat.v1.ConfigProto()\r\n        config.gpu_options.allow_growth = True\r\n        config.gpu_options.per_process_gpu_memory_fraction = 0.061\r\n        sess = tf.compat.v1.Session(graph=graph, config=config)\r\n        return sess, input, output\r\n\r\n    def init_second(self):\r\n        graph_def = tf.compat.v1.GraphDef()\r\n        with tf.io.gfile.GFile(self.MODEL_PATH[1], 'rb') as f:\r\n            graph_def.ParseFromString(f.read())\r\n\r\n        graph = tf.Graph()\r\n        with graph.as_default():\r\n            tf.import_graph_def(graph_def)\r\n\r\n        config = tf.compat.v1.ConfigProto()\r\n        config.gpu_options.allow_growth = True\r\n        config.gpu_options.per_process_gpu_memory_fraction = 0.37\r\n        sess = tf.compat.v1.Session(graph=graph, config=config)\r\n\r\n        output = ('import/softmax_2/softmax:0',\r\n                  'import/conv6-2/conv6-2:0',\r\n                  'import/conv6-3/conv6-3:0')\r\n        input = 'import/Placeholder_2:0'\r\n\r\n        return sess, input, output\r\n\r\n    firsrt = init_first()\r\n    second = init_second()\r\n\r\n\r\n", "comments": ["@sealedtx, Please try with latest Tf 1.15.0.rc1 version. And also provide the complete code to reproduce the issue . Looks like MODEL_PATH is not given. Thanks!", "@gadagashwini I have tested latest Tf 1.15.0.rc1 version and it has same behavior. MODEL_PATH is just path to my custom networks files .pb. Thank you, for response", "This is an ancient bug #8136 which is unlikely to be fixed. Once the GPU devices are created, its configuration cannot be changed any more.", "@ppwwyyxx So it is not possible to manage gpu_memory_fraction for multiple sessions in a single process?", "I think that's true.", "Sad to hear this :( \r\nReally need this feature. Should I close the issue or leave as \"want enchantment\"?", "I'm closing this, please see #8136 for more info."]}, {"number": 32917, "title": "Added invocation and memory allocation checks", "body": "Added checks for the Invoke and AllocateTensors. \r\nAlso, consider using macros and more descriptive error logs. As in the TfLite C++ example for Desktop.", "comments": ["> Prefer using TF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, interpreter.Invoke()) for test methods. That way the test will fail quickly exactly where the issue is instead of just logging it.\r\n> \r\n> Good catch and thanks for the PR improving our error checking.\r\n\r\nDone\r\nThanks for the notes\r\nhttps://github.com/tensorflow/tensorflow/pull/32917/files", "Still yet to be merged, is there anyway I could help out resolving the build errors? ", "@lamarrr let me try to pull this again, thanks for your patience.", "> @lamarrr let me try to pull this again, thanks for your patience.\r\n\r\nMy pleasure actually. "]}, {"number": 32916, "title": "local variable 'nccl_lib_path' referenced before assignment", "body": "When I compile the tensorflow-1.12.0 version , I process command :\r\n./configure\r\n\r\nand then I got this error:\r\n  File \"./configure.py\", line 1693, in <module>\r\n    main()\r\n  File \"./configure.py\", line 1612, in main\r\n    set_tf_nccl_install_path(environ_cp)\r\n  File \"./configure.py\", line 1208, in set_tf_nccl_install_path\r\n    nccl_lib_path = os.path.join(nccl_install_path, nccl_lib_path)\r\nUnboundLocalError: local variable 'nccl_lib_path' referenced before assignment\r\n\r\n\r\nmy bazel version is 0.15.0,  gcc is 5.4.0", "comments": ["Please take a look at the similar issue [here](https://github.com/FloopCZ/tensorflow_cc/issues/147) and let me know if it helps. Thanks!", "@Julius-ZCJ Did you solve the issue or are you still facing the same issue?", "Yes, I solved this problem, but have some other issues raise. I'm now fight against that.", "Closing this issue as it has been resolved. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32916\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32916\">No</a>\n"]}, {"number": 32915, "title": "Wrong links in API document and search results", "body": "Items in TensorFlow Core r1.14 is linked to r2.0.\r\nIn search results, all informations are correct except the link.\r\nAll links point to RC version, not r1.14.\r\n\r\nI checked tf.nn.dynamic_rnn and tf.nn.fused_batch_norm.\r\ndynamic_rnn is linked to [https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) now.\r\nBut [https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/nn/dynamic_rnn](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/nn/dynamic_rnn) is right.", "comments": ["@canasta Thanks for reporting this issue. Can you explain the issue with little more details. I checked the links you provided and both points to same page. Are you seeing different page? Please let us know. Thanks!\r\n\r\n", "When I write this issue, the link(first result in [https://www.tensorflow.org/s/results?q=dynamic_rnn](this) page) moves me to [https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) and it shows 404 ERROR.\r\nAnd I tried again with another module which exist in r2.0 and r1.14 both, than search result moves me to r2.0 page, not 404 and r1.14 page.\r\n\r\nBut it seems fixed now, so I'll close this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32915\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32915\">No</a>\n", "@canasta Actually team is working hard on updating the docs. Updating many docs from 1.x to 2.x is a huge task. Still there are some links are not working in TF website but are updated in master branch. So, in the near future TF website will be updated completely.\r\n\r\nPlease let us know If you see any link that is not working as intended. Thanks!"]}, {"number": 32914, "title": "set tflite interpreter gpu delegate on android\uff0cit's output is different without gpu delegate", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):android\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: MI PAD 4 PLUS\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):1.14\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nset tflite interpreter gpu delegate on android\uff0cit's output is different without gpu delegate, and it seems that whatever data i fed, the model output is the same, is it something wrong with my code \uff1fand i have checked my code, it's output is correct without set the gpu delegate.\r\n\r\n**Describe the expected behavior**\r\nuse gpu to accelerate inference\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nhere is the code i set the tflite interpreter options:\r\n\r\n```\r\ntfliteModel = loadModelFile(activity);\r\n    switch (device) {\r\n        case NNAPI:\r\n            tfliteOptions.setUseNNAPI(true);\r\n            break;\r\n        case GPU:\r\n            gpuDelegate = new GpuDelegate();\r\n            tfliteOptions.addDelegate(gpuDelegate);\r\n            break;\r\n        case CPU:\r\n            break;\r\n    }\r\n    tfliteOptions.setNumThreads(numThreads);\r\n    tflite = new Interpreter(tfliteModel, tfliteOptions);\r\n```\r\nand here is the code i used to inference(where the input is a four dim array, and output is a two dim array, corresponding to the model input and output dimentions):\r\n`tflite.run(audioData, output);`\r\n**Other info / logs**\r\n14:11:28.433 30654-30654/? I/tflite: Created TensorFlow Lite delegate for GPU.\r\n2019-09-30 14:11:28.435 30654-30654/? I/tflite: Initialized TensorFlow Lite runtime.\r\n2019-09-30 14:11:28.464 30654-30654/? I/Adreno: QUALCOMM build                   : dcd4b96, I568c71768a\r\n    Build Date                       : 04/30/18\r\n    OpenGL ES Shader Compiler Version: EV031.22.00.01_06\r\n    Local Branch                     : \r\n    Remote Branch                    : quic/gfx-adreno.lnx.1.0.r33-rel\r\n    Remote Branch                    : NONE\r\n    Reconstruct Branch               : NOTHING\r\n2019-09-30 14:11:28.467 30654-30654/? I/Adreno: PFP: 0x005ff087, ME: 0x005ff063\r\n2019-09-30 14:11:28.471 30654-30654/? I/zygote64: android::hardware::configstore::V1_0::ISurfaceFlingerConfigs::hasWideColorDisplay retrieved: 0\r\n2019-09-30 14:11:28.472 30654-30654/? E/libEGL: call to OpenGL ES API with no current context (logged once per thread)\r\n2019-09-30 14:11:28.659 3275-3275/? D/EventBus: [3275, u0] send(AppTransitionFinishedEvent)\r\n2019-09-30 14:11:28.659 3275-3275/? D/EventBus: [3275, u0]  -> ForcedResizableInfoActivityController [0xe31f776, P1] onBusEvent(AppTransitionFinishedEvent)\r\n2019-09-30 14:11:28.659 3275-3275/? D/EventBus: [3275, u0] onBusEvent(AppTransitionFinishedEvent) duration: 17 microseconds, avg: 159\r\n2019-09-30 14:11:28.659 3275-3275/? D/EventBus: [3275, u0] send(AppTransitionFinishedEvent)\r\n2019-09-30 14:11:28.659 3275-3275/? D/EventBus: [3275, u0]  -> ForcedResizableInfoActivityController [0xe31f776, P1] onBusEvent(AppTransitionFinishedEvent)\r\n2019-09-30 14:11:28.659 3275-3275/? D/EventBus: [3275, u0] onBusEvent(AppTransitionFinishedEvent) duration: 6 microseconds, avg: 159\r\n2019-09-30 14:11:29.152 30654-30674/? D/OpenGLRenderer: HWUI GL Pipeline\r\n2019-09-30 14:11:29.161 30654-30654/? I/Toast: Show toast from OpPackageName:com.example.dm.testing, PackageName:com.example.dm.testing\r\n2019-09-30 14:11:29.201 30654-30674/? I/OpenGLRenderer: Initialized EGL, version 1.4\r\n2019-09-30 14:11:29.201 30654-30674/? D/OpenGLRenderer: Swap behavior 2\r\n2019-09-30 14:11:29.321 2629-2679/? I/ActivityManager: Displayed com.example.dm.testing/.MainActivity: +1s153ms\r\n2019-09-30 14:11:29.322 4049-4487/? D/PowerKeeper.Event: notifyActivityLaunchTime: com.example.dm.testing/.MainActivity totalTime: 1153\r\n2019-09-30 14:11:29.322 598-598/? W//system/bin/hwservicemanager: getTransport: Cannot find entry vendor.qti.hardware.iop@1.0::IIop/default in either framework or device manifest.\r\n2019-09-30 14:11:29.322 2629-2679/? E/ANDR-PERF-JNI: Iop tryGetService failed\r\n2019-09-30 14:11:29.360 2629-16635/? D/ActivityTrigger: ActivityTrigger activityStopTrigger \r\n2019-09-30 14:11:29.363 6198-6198/? D/Launcher.AdPendantUtils: updateAdvertisementPendantVisibility, mIsAdPendantEnable=false, mIsPullActionEnable=false, mIsEditDisabled=true, mCurrentScreenId=2, mDefaultScreenId=2, mIsLauncherVisible=false, mIsMinusOneScreenShow=false\r\n2019-09-30 14:11:29.452 3880-8501/? D/com.xiaomi.common.Network: Http POST Response Code: 200\r\n2019-09-30 14:11:31.156 768-815/? E/ANDR-PERF-OPTSHANDLER: perf_lock_rel: updated /sys/class/mmc_host/mmc0/clk_scaling/enable with 1\r\n     return value 2\r\n", "comments": ["i notice a error when lauching the app:  E/libEGL: call to OpenGL ES API with no current context (logged once per thread), is it related to it?", "@ArtemisZGL I don't think that error message is related.  I think it's a bug on one of the shaders.\r\n\r\nCan you share your network, or if it's confidential, can you do a binary search on your network to find out which op with which options (input/output dimensions, strides, dilations, weights, bias, etc.) is bad?", "@ArtemisZGL \r\nCan you please update as per above comment.", "@ArtemisZGL \r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32914\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32914\">No</a>\n"]}, {"number": 32913, "title": "Attention :module 'tensorflow.python.keras.api._v2.keras.layers' has no attribute 'Attention'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Win10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):2.0.0a0\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\nmodel = keras.Sequential()\r\nmodel.add(tf.keras.layers.Embedding(max_words, embed_size))\r\nmodel.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)))\r\nmodel.add(tf.keras.layers.Attention())\r\n**Describe the current behavior**\r\nAttributeError: module 'tensorflow.python.keras.api._v2.keras.layers' has no attribute 'Attention'\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@ares5221 Could you try with 2.0.0rc1 or 2.0.0rc2 instead of 2.0.0a0? There tf.keras.layers.Attention does exist.", "2.0.0a0 is extremely old, please switch to 2.0.0rc2", "@ares5221 Please find the github gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/62089d4044afed594e0c08e5ad6b4c8e/untitled152.ipynb). Attention layer does exist in tensorflow 2.0.0-rc2. ", "@ares5221 As mentioned by others, attention layer exists in recent versions of tensorflow (`TF2.0.0` and others). Please check for the details and code examples of attention layer [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention).\r\n\r\nI am closing this issue as this was resolved. Please feel free to open the issue if the issue persists in `TF2.0`. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32913\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32913\">No</a>\n", "> @ares5221 Could you try with 2.0.0rc1 or 2.0.0rc2 instead of 2.0.0a0? There tf.keras.layers.Attention does exist.\r\n\r\ni try in win10\uff0c2.0.0rc2 it works, and ubuntu18.04 only support 2.0.0b1,and it works too\r\nthanks very much ", "2.0.0 should be supported by every OS. Please make sure you have the latest `pip` though.", "> 2.0.0 should be supported by every OS. Please make sure you have the latest `pip` though.\r\n\r\nyes\uff0cthks"]}, {"number": 32912, "title": "model.fit with tf.data.Dataset.from_generator can't infer shape", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs 10.13.6\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-beta1-5101-gc75bb66a99 2.0.0-rc0\r\n- Python version: 3.6.4 \r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\n`model.fit` when given a `tf.data` dataset (that uses a `from_generator`) throws `ValueError: as_list() is not defined on an unknown TensorShape.` \r\n\r\nsee https://gist.github.com/matpalm/779c2c67d5ec195845ae2ab01570d883 for full traceback\r\n\r\n**Describe the expected behavior**\r\n\r\nmodel.fit should be able to infer the shape of the input.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\ninp = Input(shape=(3,))\r\noutput = Dense(1, activation='sigmoid')(inp)\r\nmodel = Model(inp, output)\r\nmodel.compile(optimizer=Adam(1e-2), loss='binary_crossentropy')\r\n\r\ndef simple_generator():\r\n    while True:\r\n        yield [0.5, 0.2, -0.3], 0.0\r\n        yield [-0.5, 0.3, -0.1], 1.0\r\n        \r\ndataset = tf.data.Dataset.from_generator(simple_generator,\r\n                                         output_types=(tf.float32,\r\n                                                       tf.float32))\r\ndataset = dataset.batch(4).prefetch(1)\r\n\r\nmodel.fit(dataset)\r\n```\r\n\r\nthrows `ValueError: as_list() is not defined on an unknown TensorShape.`\r\n\r\nnote: the following works...\r\n\r\n```\r\nfor X, y in dataset:\r\n  model.fit(X, y)\r\n  break\r\n```\r\n\r\n**Other info / logs**\r\n\r\nsee https://gist.github.com/matpalm/779c2c67d5ec195845ae2ab01570d883 for full traceback", "comments": ["Was able to reproduce this issue. Please find the github gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/ca54b9920fba141a43b2ecfa87af9232/untitled154.ipynb).", "I see the same behaviour with dataset created from tf.data.Dataset.list_files and then mapped into X,Y tensors dataset\r\n", "I also see the same behavior, downgrading to `2.0b1` makes the problem go away. Seems like a problem with the `2.0.0` stable release?", "I just tested with the docker images (py3-gpu), and the bug started occurring between 2.0.0b1 and 2.0.0rc0. ", "Ran into the same issue when trying to use model.fit() with a tf.data.dataset initialized from a generator using 2.0.0 stable. \r\n\r\nFor now as a workaround model.fit_generator() seems to work on the same dataset object.", "I have a similar issue pulling multidimensional arrays from TFRecords datapipeline after parsing/serializing. As others have tested change occurs between 2.0.0b1 and 2.0.0rc0.", "Having the same issue, using model.fit_generator() also seems to be a valid workaround.  In tf.keras the line between model.fit and model.fit_generator seems quite blurred, particularly when working with tf.data.Dataset inputs.  Which one are we actually meant to be using?", "> Having the same issue, using model.fit_generator() also seems to be a valid workaround. In tf.keras the line between model.fit and model.fit_generator seems quite blurred, particularly when working with tf.data.Dataset inputs. Which one are we actually meant to be using?\r\n\r\nReplying to myself, seemingly .fit since .fit_generator doesn't even support distributed training via a tf.distribute strategy.", "I have the same problem and I confirm `fit_generator` solves the problem while `fit` fails with \r\n```python\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-1-80f4363a81b7> in <module>\r\n     42 \r\n     43 print(model.summary())\r\n---> 44 model.fit(dataset, epochs=EPOCHS, verbose=2)\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    501       # This is the first call of __call__, so we have to initialize.\r\n    502       initializer_map = object_identity.ObjectIdentityDictionary()\r\n--> 503       self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n    504     finally:\r\n    505       # At this point we know that the initialization is complete (or less\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    406     self._concrete_stateful_fn = (\r\n    407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 408             *args, **kwds))\r\n    409 \r\n    410     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   1846     if self.input_signature:\r\n   1847       args, kwargs = None, None\r\n-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   1849     return graph_function\r\n   1850 \r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2148         graph_function = self._function_cache.primary.get(cache_key, None)\r\n   2149         if graph_function is None:\r\n-> 2150           graph_function = self._create_graph_function(args, kwargs)\r\n   2151           self._function_cache.primary[cache_key] = graph_function\r\n   2152         return graph_function, args, kwargs\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2039             arg_names=arg_names,\r\n   2040             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2041             capture_by_value=self._capture_by_value),\r\n   2042         self._function_attributes,\r\n   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    913                                           converted_func)\r\n    914 \r\n--> 915       func_outputs = python_func(*func_args, **func_kwargs)\r\n    916 \r\n    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    357         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    359     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    360 \r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in distributed_function(input_iterator)\r\n     64     \"\"\"A single step of the distributed execution across replicas.\"\"\"\r\n     65     x, y, sample_weights = _prepare_feed_values(\r\n---> 66         model, input_iterator, mode)\r\n     67     # Call `Model.{train,test,predict}_on_batch` on every replica passing\r\n     68     # PerReplicas as arguments.  On every replica inside this call, each\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in _prepare_feed_values(model, inputs, mode)\r\n    110     for inputs will always be wrapped in lists.\r\n    111   \"\"\"\r\n--> 112   inputs, targets, sample_weights = _get_input_from_iterator(inputs)\r\n    113 \r\n    114   # When the inputs are dict, then we want to flatten it in the same order as\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in _get_input_from_iterator(iterator)\r\n    147   # Validate that all the elements in x and y are of the same type and shape.\r\n    148   dist_utils.validate_distributed_dataset_inputs(\r\n--> 149       distribution_strategy_context.get_strategy(), x, y, sample_weights)\r\n    150   return x, y, sample_weights\r\n    151 \r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py in validate_distributed_dataset_inputs(distribution_strategy, x, y, sample_weights)\r\n    309 \r\n    310   if y is not None:\r\n--> 311     y_values_list = validate_per_replica_inputs(distribution_strategy, y)\r\n    312   else:\r\n    313     y_values_list = None\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py in validate_per_replica_inputs(distribution_strategy, x)\r\n    354     if not context.executing_eagerly():\r\n    355       # Validate that the shape and dtype of all the elements in x are the same.\r\n--> 356       validate_all_tensor_shapes(x, x_values)\r\n    357     validate_all_tensor_types(x, x_values)\r\n    358 \r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py in validate_all_tensor_shapes(x, x_values)\r\n    371 def validate_all_tensor_shapes(x, x_values):\r\n    372   # Validate that the shape of all the elements in x have the same shape\r\n--> 373   x_shape = x_values[0].shape.as_list()\r\n    374   for i in range(1, len(x_values)):\r\n    375     if x_shape != x_values[i].shape.as_list():\r\n\r\n~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py in as_list(self)\r\n   1169     \"\"\"\r\n   1170     if self._dims is None:\r\n-> 1171       raise ValueError(\"as_list() is not defined on an unknown TensorShape.\")\r\n   1172     return [dim.value for dim in self._dims]\r\n   1173 \r\n\r\nValueError: as_list() is not defined on an unknown TensorShape.\r\n```\r\n\r\nBelow my full code that reproduces the problem:  \r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport random\r\nimport tensorflow as tf\r\nimport time as tm\r\n\r\nINPUT_SHAPE=[7, 9]\r\nNUM_POINTS=2000\r\nBATCH_SIZE=32\r\nBUFFER_SIZE=32\r\nEPOCHS=2\r\n\r\ndef gen():\r\n    for i in range(1000):\r\n        x = np.random.rand(INPUT_SHAPE[0],INPUT_SHAPE[1])\r\n        y = np.random.randint(1, 3, size=1)\r\n        yield x,y\r\n    \r\ndataset = tf.data.Dataset.from_generator(gen, \r\n                                         (tf.float32, tf.int16),\r\n                                         output_shapes=(tf.TensorShape(INPUT_SHAPE), tf.TensorShape(None))\r\n                                        ).batch(BATCH_SIZE)\r\n\r\ndef create_model(input_shape):\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Dense(100, activation=\"tanh\", input_shape=input_shape),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(3, activation=\"softmax\")\r\n    ])\r\n    return model\r\n\r\nmodel = create_model(input_shape=INPUT_SHAPE)\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, clipvalue=1.0),\r\n    loss= tf.keras.losses.CategoricalCrossentropy(),\r\n    )\r\n\r\niterator = dataset.make_one_shot_iterator()\r\nx,y = iterator.get_next()\r\nprint(\"X.shape\", x.shape, y.shape)\r\nprint(\"Predicted\", model.predict(x).shape)\r\n\r\nprint(model.summary())\r\nmodel.fit_generator(dataset, epochs=EPOCHS, verbose=2)\r\nmodel.fit(dataset, epochs=EPOCHS, verbose=2)\r\n```", "I can confirm that `fit_generator` works around the issue, but I experienced it **wihout** making the dataset `from_generator`. I was actually working with with a `tf.data.TFRecordDataset`, but the following code reproduces the issue `fom_tensor_slices`:\r\n\r\n```python\r\nimport tensorflow as tf               # 2.0.0\r\nimport tensorflow_datasets as tfds    # 1.3.0\r\n\r\n# Dummy data.\r\ntext = [\r\n  \"the quick\",\r\n  \"brown fox\",\r\n  \"jups over\",\r\n  \"the lazy\",\r\n  \"dog.\"\r\n]\r\ntarget = [\r\n  \"class_1,class_2\",\r\n  \"class_1\",\r\n  \"class_2\",\r\n  \"class_1\",\r\n  \"class_1,class_2\"\r\n]\r\n\r\nbatch_size = 2\r\n\r\n# Make dataset.\r\ndataset = tf.data.Dataset.from_tensor_slices((text, target))\r\n\r\n# Text (features) encoder.\r\ncorpus_generator = (t[0].numpy() for t in dataset) \r\nencoder = tfds.features.text.SubwordTextEncoder.build_from_corpus(\r\n  corpus_generator, \r\n  target_vocab_size=500\r\n)\r\n\r\n# Targets lookup.\r\ntargets = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(\r\n  keys=[\"class_1\", \"class_2\"], \r\n  values=[1,2], \r\n  value_dtype=tf.int64), default_value=-1\r\n)\r\n\r\nvocab_size = encoder.vocab_size\r\nn_targets = targets.size().numpy()\r\nprint(f\"vocab_size: {vocab_size}\\tn_targets: {n_targets}\")\r\n\r\n# Map fn.\r\nencode = lambda x: [encoder.encode(x.numpy())]\r\ntf_encode = lambda x: tf.reduce_sum(\r\n  tf.one_hot(\r\n    tf.py_function(encode, [x], tf.int64), \r\n    depth=vocab_size, \r\n    axis=None, \r\n    dtype=tf.int64), \r\n  axis=0, \r\n  keepdims=False\r\n)\r\n\r\nlookup_targets = lambda x: tf.reduce_sum(\r\n  tf.one_hot(\r\n    targets.lookup(tf.strings.split(x, sep=\",\")),\r\n    depth=n_targets,\r\n    axis=None,\r\n    dtype=tf.float32), \r\n  axis=0, \r\n  keepdims=False\r\n)\r\n\r\nparse_fn = lambda x, y: (tf_encode(x), lookup_targets(y))\r\ndataset = dataset.map(parse_fn)\r\ndataset = dataset.batch(batch_size)\r\n\r\nfor batch_x, batch_y in dataset:\r\n  print(\"*** BATCH ***\")\r\n  for i, (x, y) in enumerate(zip(batch_x, batch_y)):\r\n    print(f\"> EXAMPLE {i + 1}\")\r\n    print(f\"text   : {x.numpy()} => shape: {x.shape}\")\r\n    print(f\"target : {y.numpy()} => shape:{y.shape}\")\r\n    print()\r\n  print()\r\n\r\ninputs = tf.keras.layers.Input(shape=(vocab_size,))\r\noutputs = tf.keras.layers.Dense(units=n_targets)(inputs)  # no activation!\r\n\r\nmodel = tf.keras.Model(\r\n  inputs=[inputs], \r\n  outputs=[outputs], \r\n)\r\n\r\nprint(f\"Sample prediction: {model.predict(dataset.take(1))}\\n\")\r\n\r\nloss = tf.keras.losses.BinaryCrossentropy()\r\noptimizer = tf.keras.optimizers.Adam()\r\n\r\nmodel.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\r\n\r\nhistory = model.fit(\r\n  dataset,\r\n  epochs=5,\r\n)\r\n```", "Adding the following after batching allowed me to work around this issue:\r\n```python\r\ndef _fixup_shape(images, labels, weights):\r\n    images.set_shape([None, None, None, 3])\r\n    labels.set_shape([None, 19]) # I have 19 classes\r\n    weights.set_shape([None])\r\n    return images, labels, weights\r\ndataset = dataset.map(_fixup_shape)\r\n```", "> Adding the following after batching allowed me to work around this issue:\r\n> \r\n> ```python\r\n> def _fixup_shape(images, labels, weights):\r\n>     images.set_shape([None, None, None, 3])\r\n>     labels.set_shape([None, 19]) # I have 19 classes\r\n>     weights.set_shape([None])\r\n>     return images, labels, weights\r\n> dataset = dataset.map(_fixup_shape)\r\n> ```\r\n\r\nThis works for me too.", "Also seeing this issue. For me it's happening with a FixedSizeRecordDataset with an explicit reshape at the end:\r\n\r\n```\r\nds = tf.data.FixedLengthRecordDataset(\r\n        path,\r\n        record_bytes=28 * 28, # rows * cols\r\n        header_bytes=4 + 4 + 4 + 4, # magic number + record count + rows + cols\r\n        compression_type=\"GZIP\"\r\n    )\r\n\r\nds = ds.map(lambda x: tf.io.decode_raw(x, tf.uint8))\r\nds = ds.map(lambda x: tf.reshape(x, (28, 28)))\r\nds = ds.map(lambda x: tf.ensure_shape(x, (28, 28)))\r\n```\r\n\r\n.fit_generator() works.", "same problem,mark", "Running into the same issue. `fit_generator` is not an option for us due to need for DistributionStrategy.", "Managed to fix this like this: https://gist.github.com/vicpara/5c23c78d0f3105af53798272e628d2ad .\r\nMy guess is that this is a problem related to deserialized tensors.", "In my case problem was in using many 'accuracy' metric which requires IteratorGetNext shape which I didn't have.\r\n\r\n> ```python\r\n> def _fixup_shape(images, labels, weights):\r\n>     images.set_shape([None, None, None, 3])\r\n>     labels.set_shape([None, 19]) # I have 19 classes\r\n>     weights.set_shape([None])\r\n>     return images, labels, weights\r\n> dataset = dataset.map(_fixup_shape)\r\n> ```\r\n\r\n@jpambrun's solution worked for me! \r\n\r\nNOTE: it doesn't matter whether you first do batch or map. But you'll need two map functions! The first is used for getting data, the other one setting the shape. Doing everything in one function fails, I don't know why exactly, even if you convert data to Tensor and set_shape before returning it. So I have the following order\r\n```dataset.batch.map(get_data).map(fix_shape).prefetch``` \r\nand everything goes smoothly. ", "Any update on this?\r\nI am having this problem after setting some `output_signature` params to None since the last batch is smaller than the previous ones (for example, training with 14 000 elements with a batch size of 32 gives a last batch of 16 elements only).\r\n```python\r\nDataset.from_generator(\r\n    gen,\r\n    output_signature=(\r\n        tf.TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32),\r\n        tf.TensorSpec(shape=None, dtype=tf.float32)\r\n    )\r\n)\r\n```\r\nWhat has been done so far?", "@BlueskyFR, shouldn't you set the output params to (None, 1)? The None shape is used for batch_size, right?", "@BlueskyFR for small last batch size i always give up trying to get shapes right and just use `drop_remainder=True`\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch", "Thanks @chrismaliszewski and @matpalm for your answers!\r\nYeah I could have used `drop_remainder=True` but I was trying to learn the right way to keep all the values no matter what :)\r\n\r\nHowever, I managed to find the solution to my problem, for those interested: a comma was missing :)\r\n```diff\r\nDataset.from_generator(\r\n    gen,\r\n    output_signature=(\r\n        tf.TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32),\r\n-       tf.TensorSpec(shape=None, dtype=tf.float32)\r\n+       tf.TensorSpec(shape=(None,), dtype=tf.float32)\r\n    )\r\n)\r\n```\r\n\r\nWhen using a batch size which is not a multiple of the total training elements count (so when `train_ds_element_count % batch_size != 0`), the `batch_size` in the `tf.TensorSpec(...)` must be set to None to be considered as dynamic.\r\nAlso, my error was to specify the output shape as `None` or `(None)` instead of `(None,)` which is considered as a **tuple** when the comma is added.\r\n\r\nHope it helps!", "> Adding the following after batching allowed me to work around this issue:\r\n> \r\n> ```python\r\n> def _fixup_shape(images, labels, weights):\r\n>     images.set_shape([None, None, None, 3])\r\n>     labels.set_shape([None, 19]) # I have 19 classes\r\n>     weights.set_shape([None])\r\n>     return images, labels, weights\r\n> dataset = dataset.map(_fixup_shape)\r\n> ```\r\n\r\nThank you so much jpambrun!! This worked well for me.\r\n", "Hi. I cannot manage to get the same tf version (2.0.0-rc0) on conda, but I tried the closest one I can find, which is version 2.0.0. I guess one workaround for this problem might be\r\n\r\n- not only should we specify `output_types`\r\n- **but also `output_shapes`**\r\n\r\nThe following snippets ran fine on an IPython session on my machine (Python3.6.13):\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\ninp = Input(shape=(3,))\r\noutput = Dense(1, activation='sigmoid')(inp)\r\nmodel = Model(inp, output)\r\nmodel.compile(optimizer=Adam(1e-2),\r\n              loss='binary_crossentropy',\r\n)\r\n\r\ndef simple_generator():\r\n    while True:\r\n        yield [0.5, 0.2, -0.3], 0.0\r\n        yield [-0.5, 0.3, -0.1], 1.0\r\n\r\ndataset = tf.data.Dataset.from_generator(\r\n    simple_generator,\r\n    output_types=(tf.float32, tf.float32),\r\n    output_shapes=((3,), (),)\r\n)\r\n\r\ndataset = dataset.batch(4).prefetch(1)\r\n\r\nmodel.fit(dataset)\r\n```\r\nWith output as follows:\r\n```\r\n   1591/Unknown - 6s 4ms/step - loss: 0.1298\r\n```\r\n\r\n**Rmk**. Although this works, as of April 22, 2021, `help(tf.data.Dataset.from_generator)` explains that it favors `output_signature` over `(output_types, output_shapes)`.", "@matpalm Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "happy to close, thought i actually had over a year ago sorry! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32912\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32912\">No</a>\n", "@sushreebarsa \r\n\r\nThis is still an issue if you are creating a dataset from filenames - e.g. from_generator creating the dataset from filenames, then using map and tf.io.decode_image to create the actual files", "> ```\r\n>    1591/Unknown - 6s 4ms/step - loss: 0.1298\r\n> ```\r\n\r\nI am creating a dataset from filenames and also see this \"/Unknown\" text when calling `model.fit`. Does anyone know why this happens?\r\n\r\nEDIT: Ah it only happens for the first epoch - I think because I have quite a large dataset that it had to first determine how many mini-batches there are in my dataset. The rest of the model.fit() output looks as normal.", "@cyberface it wouldn't be the dataset size, it's just that a generator doesn't have a length. i.e. you would have seen this with a tiny dataset. if you are just dealing with a fixed set of filenames you could just use `from_tensor_slices`", "@matpalm ah ok thank you for the clarification, very helpful!", "Thanks @jpambrun  - \r\n\r\n```\r\ndef _fixup_shape(images, labels, weights):\r\n    images.set_shape([128, 128, 1])\r\n    labels.set_shape([]) # I have 19 classes\r\n    return images, labels, weights\r\n\r\ndataset = dataset.map(_fixup_shape)\r\n\r\n```\r\nWorked for me.\r\n\r\nThough it would be interesting to figure out the cause of this issue - i.e., is it a bug in TF 2.0, or is it an expected behavior?", "This is expected behavior.\r\n\r\nNormally TensorFlow can handle shapes with unknown dimensions. It really can't handle shapes with an unknown **number of dimensions**. \r\n\r\n`from_generator` has the option of setting the shapes in the arguments.  \r\n\r\nEven if you don't fully know the shape, just setting the rank will often fix this. Fpr example, if you know the output is 3d but you don't know the sizes, set: `tf.data.Dataset.from_generator(..., output_shapes=[None, None, None])`."]}, {"number": 32911, "title": "tf.losses.mean_squared_error returns a list in tensorflow '2.0.0-rc1'", "body": "Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n```uname -mrs\r\nLinux 3.10.0-514.el7.x86_64 x86_64\r\n```\r\nTensorFlow installed from (source or binary): binary (pip)\r\nTensorFlow version (use command below): 'v2.0.0-rc0-101-gd2d2566'\r\nPython version: 3.6.6 :: Anaconda, Inc.\r\nBazel version (if compiling from source): N/A\r\nGCC/Compiler version (if compiling from source): N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\n\r\n\r\n\r\nI just updated my TensorFlow to version:\r\n```\r\ntf.__version__\r\n'2.0.0-rc1'\r\n```\r\nusing pip install.  I am using python version:\r\n\r\n```\r\npython -V\r\nPython 3.6.6 :: Anaconda, Inc.\r\n```\r\n\r\nthe bug is that `tf.losses.mean_squared_error`  returns a list rather than a scaler. A simple code to replicate this:\r\n\r\n```\r\nnp.random.seed(seed=10)\r\na, b = np.random.rand(5,1), np.random.rand(5,1)\r\ntf.losses.mean_squared_error(a,b).numpy()\r\n```\r\n\r\nreturns:\r\n\r\n`array([0.29868848, 0.03143916, 0.01609916, 0.33604403, 0.16823713])`\r\n\r\n\r\nyou can find a way around it by using \r\n\r\n`tf.losses.MeanSquaredError()(a,b).numpy()`\r\n\r\nwhich returns:\r\n`0.17010`", "comments": ["Yes the behavior of the same function in [1.15](https://colab.sandbox.google.com/gist/gowthamkpr/d9126a9645e900c67e48c05d4f620590/1-15-mse-loss.ipynb) and [2.0.o.rc2](https://colab.sandbox.google.com/gist/gowthamkpr/72b45ba833cb7f2fac87e7e276deee0a/2-0-mse-loss.ipynb) is not the same. ", "@alibeyram The mean_squared_error function returns one value per example, `MeanSquaredError` class which is the 2.0 way of specifying metrics uses mean_squared_error internally and computes the the weighted mean of the list of the values across all samples.", "@pavithrasv So I think we should not call it `mean_squared_error` since it does not do any averaging and it's just `(y_true - y_pred)**2`", "It computes the mean across all dimensions other than the batch dimension. If you provide 3D input the output will be 1D.", "@pavithrasv Thank you for clearing it up. The only suggestion I have is that if that's a change form  version 1 to version 2, it is useful to mention it in https://www.tensorflow.org/guide/migrate", "@pavithrasv Also it does not return a 1D when you provide 3D.\r\n\r\n```\r\nnp.random.seed(seed=10)\r\na, b = np.random.rand(2,2,1), np.random.rand(2,2,1)\r\ntf.losses.mean_squared_error(a,b).numpy()\r\n```\r\n\r\nreturns:\r\n\r\n```\r\narray([[7.44272772e-02, 4.16342380e-02],\r\n       [1.89734615e-01, 1.37518534e-04]]) \r\n```\r\n\r\nwhich is a 2D array. \r\n\r\nThe code only takes mean over the very last dimension.\r\ntake a look at the [code](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/losses.py#L762-L771) \r\n\r\n`K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)`\r\n\r\nMoreover, as @gowthamkpr mentioned while the code is the same for version [1.15](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/python/keras/losses.py#L757-L766) and [2.0.0-rc2](https://github.com/tensorflow/tensorflow/blob/v2.0.0-rc2/tensorflow/python/keras/losses.py#L762) the behavior is different \r\n\r\n\r\n", "Oh sorry, i was wrong, it computes mean along the last dimension. How is the behavior different between 1.15 and 2.0 ? Are you referring to the standalone behavior or behavior in a Keras model fit?", "@pavelbulanov Look at @gowthamkpr comment above. There are two code collab attached that shows one returns list and the other one return a scaler ", "@pavithrasv Also for me it does not make sense to compute mean along the last dimension. ", "So As you said I think this is the intended behavior which is different between versions [1.14](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/losses.py#L100) and [2.0](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/losses.py#L100)", "@alibeyram I am closing this issue as it is intended behavior. If your use case require additional features, then please raise new issue as a `feature request. Thanks", "In TF 1.x we had different loss functions in `tf.losses` and `tf.keras.losses`, we unified them in TF 2.0. We went the `tf.keras.losses` way for the functions where the inputs are expected to be at least 2D and we mean across the last dimension. "]}, {"number": 32910, "title": "No `libtensorflow_framework.so`", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.6 LTS (GNU/Linux 4.15.0-55-generic x86_64)\r\n- TensorFlow installed from (source or binary): `pip install tensorflow-gpu==2.0.0rc2`\r\n- TensorFlow version (use command below): v2.0.0-rc1-51-g2646d23 2.0.0-rc2\r\n- Python version: 3.5.2\r\n- CUDA/cuDNN version: 10.0/7.6.4.38\r\n- GPU model and memory: GTX 1080 Ti 11GB\r\n\r\n**Describe the current behavior**\r\nNo `libtensorflow_framework.so` inside `/home/username/.env/python3/lib/python3.5/site-packages/tensorflow_core`. Only `libtensorflow_framework.so.2` is present.\r\n\r\n**Describe the expected behavior**\r\nBoth `libtensorflow_framework.so.2` and `libtensorflow_framework.so` should be present in `/home/username/.env/python3/lib/python3.5/site-packages/tensorflow_core`.\r\n", "comments": ["Hi @netw0rkf10w , But why must libtensorflow_framework.so exsit?", "Hi @Leslie-Fang. Good question!\r\nI am not sure if `libtensorflow_framework.so` must exist, but there are 2 reasons why I thought it should exist:\r\n\r\n- It was existing before in previous versions. When compiling a custom TF operator in 2.0.0rc2, I obtained `ltensorflow_framework` linking error (it was working in TF 1.14). I had to create a symbolic link `libtensorflow_framework.so` pointing to `libtensorflow_framework.so.2` for it to work.\r\n\r\n- When I checked on my Mac (TF 2.0.0rc2), in `/Users/username/.env/python3/lib/python3.7/site-packages/tensorflow_core` there are 3 files:\r\n`libtensorflow_framework.2.0.0.dylib`, `libtensorflow_framework.2.dylib`, `libtensorflow_framework.dylib`. While I'm not sure why all these 3 files should exist, I believe they do for a good reason, which might be the same reason why `libtensorflow_framework.so` should exist on a Linux machine.\r\n\r\nJust my thoughts though...", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "I have updated the CMakeLists of my project by making use of `tf.sysconfig.get_link_flags(), tf.sysconfig.get_compile_flags()` and it works.\r\n\r\nThe conclusion is that it is not necessary to have `libtensorflow_framework.so`. Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32910\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32910\">No</a>\n", "Yes, it is recommended to use `tf.sysconfig.get_*_flags()` instead of manually specifying the filepaths.", "@mihaimaruseac Thanks. Building was successful, but then I obtained an `undefined symbol: _ZTIN10tensorflow8OpKernelE` error :( I'm posing a question to StackOverflow... ", "@mihaimaruseac Could you kindly help: https://stackoverflow.com/questions/58174643/issues-when-compiling-tensorflow-custom-operator-tf-2-0-0? Thank you so much!", "Why not use the bazel build? Makefile build is not supported and most likely you're missing a dependency.", "@mihaimaruseac Sorry I wanted to reply yesterday but the page was not reachable (probably because of the release). What do you mean by THE bazel build? I'm not building TensorFlow from source, I'm just building a custom operator."]}, {"number": 32909, "title": "No libtensorflow_framework.so", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.6 LTS (GNU/Linux 4.15.0-55-generic x86_64)\r\n- TensorFlow installed from (source or binary): `pip install tensorflow-gpu==2.0.0rc2`\r\n- TensorFlow version (use command below): v2.0.0-rc1-51-g2646d23 2.0.0-rc2\r\n- Python version: 3.5.2\r\n- CUDA/cuDNN version: 10.0/7.6.4.38\r\n- GPU model and memory: GTX 1080 Ti 11GB\r\n\r\n**Describe the current behavior**\r\nNo `libtensorflow_framework.so` inside `/home/username/.env/python3/lib/python3.5/site-packages/tensorflow_core`. Only `libtensorflow_framework.so.2` is present.\r\n\r\n**Describe the expected behavior**\r\nBoth `libtensorflow_framework.so.2` and `libtensorflow_framework.so` should be present in `/home/username/.env/python3/lib/python3.5/site-packages/tensorflow_core`.\r\n", "comments": []}, {"number": 32908, "title": "a bizarre mistake-----InvalidArgumentError: slice index -1 of dimension 0 out of bounds.\uff08\uff09", "body": "My computer is installed with win10, tf-nightly-2.0-preview==2.0.0dev20190926\uff0cpython3.7&python3.6.8\r\n\r\nTensorflow standard template: https://tensorflow.google.cn/tutorials/load_data/images#setup\r\n\r\nWhen I run the tensorflow standard template, I get an error in\r\n\r\n    for image, label in labeled_ds.take(1):\r\n        print(\"Image shape: \", image.numpy().shape)\r\n        print(\"Label: \", label.numpy())\r\n\r\n the error message :\r\nInvalidArgumentError: slice index -1 of dimension 0 out of bounds.\r\n[[{{node strided_slice}}]]\r\nEncountered when executing an operation using EagerExecutor. \r\nThis error cancels all future operations and poisons their output tensors.\r\n\r\n\r\nHowever, in google colab I installed tf-nightly-2.0-preview==2.0.0dev20190926, python==3.6,\r\nRunning the code but it runs fine without errors\r\n\r\nIf I want to run this standard template code on my computer, how should I modify it?", "comments": ["It seems the only difference between google colab system and yours is the Python version?", "> \u770b\u6765Google colab\u7cfb\u7edf\u4e0e\u60a8\u7684\u7cfb\u7edf\u4e4b\u95f4\u552f\u4e00\u7684\u533a\u522b\u662fPython\u7248\u672c\uff1f\r\n\r\nI used the same python3.6.8 as colab and got the same error.", "I tried executing the standard template code in colab and on my computer successfully.Thanks!", "But I can't successfully execute the code.\r\nhere is my pip list\r\n\r\nWill there be any errors in my pip list?\r\nPackage                            Version\r\n---------------------------------- -------------------\r\nabsl-py                            0.8.0\r\nalabaster                          0.7.12\r\nanaconda-client                    1.7.2\r\nanaconda-navigator                 1.9.7\r\nanaconda-project                   0.8.3\r\nasn1crypto                         0.24.0\r\nastor                              0.8.0\r\nastroid                            2.2.5\r\nastropy                            3.2.1\r\natomicwrites                       1.3.0\r\nattrs                              19.1.0\r\nBabel                              2.7.0\r\nbackcall                           0.1.0\r\nbackports.os                       0.1.1\r\nbackports.shutil-get-terminal-size 1.0.0\r\nbeautifulsoup4                     4.8.0\r\nbitarray                           1.0.1\r\nbkcharts                           0.2\r\nbleach                             3.1.0\r\nbokeh                              1.3.4\r\nboto                               2.49.0\r\nBottleneck                         1.2.1\r\ncertifi                            2019.9.11\r\ncffi                               1.12.3\r\nchardet                            3.0.4\r\nClick                              7.0\r\ncloudpickle                        1.2.2\r\nclyent                             1.2.2\r\ncolorama                           0.4.1\r\ncomtypes                           1.1.7\r\nconda-package-handling             1.6.0\r\nconda-verify                       3.1.1\r\ncontextlib2                        0.6.0\r\ncryptography                       2.7\r\ncycler                             0.10.0\r\nCython                             0.29.13\r\ncytoolz                            0.10.0\r\ndask                               2.4.0\r\ndecorator                          4.4.0\r\ndefusedxml                         0.6.0\r\ndistributed                        2.4.0\r\ndocutils                           0.15.2\r\nentrypoints                        0.3\r\net-xmlfile                         1.0.1\r\nfastcache                          1.1.0\r\nfilelock                           3.0.12\r\nFlask                              1.1.1\r\nfsspec                             0.5.1\r\nfuture                             0.17.1\r\ngast                               0.2.2\r\ngevent                             1.4.0\r\nglob2                              0.7\r\ngoogle-pasta                       0.1.7\r\ngreenlet                           0.4.15\r\ngrpcio                             1.24.0\r\nh5py                               2.9.0\r\nHeapDict                           1.0.1\r\nhtml5lib                           1.0.1\r\nidna                               2.8\r\nimageio                            2.5.0\r\nimagesize                          1.1.0\r\nimportlib-metadata                 0.23\r\nipykernel                          5.1.2\r\nipython                            7.8.0\r\nipython-genutils                   0.2.0\r\nipywidgets                         7.5.1\r\nisort                              4.3.21\r\nitsdangerous                       1.1.0\r\njdcal                              1.4.1\r\njedi                               0.15.1\r\nJinja2                             2.10.1\r\njoblib                             0.13.2\r\njson5                              0.8.5\r\njsonschema                         3.0.2\r\njupyter                            1.0.0\r\njupyter-client                     5.3.3\r\njupyter-console                    6.0.0\r\njupyter-core                       4.5.0\r\njupyterlab                         1.1.4\r\njupyterlab-server                  1.0.6\r\nKeras-Applications                 1.0.8\r\nKeras-Preprocessing                1.1.0\r\nkeyring                            18.0.0\r\nkiwisolver                         1.1.0\r\nlazy-object-proxy                  1.4.2\r\nlibarchive-c                       2.8\r\nllvmlite                           0.28.0\r\nlocket                             0.2.0\r\nlxml                               4.4.1\r\nMarkdown                           3.1.1\r\nMarkupSafe                         1.1.1\r\nmatplotlib                         3.1.1\r\nmccabe                             0.6.1\r\nmenuinst                           1.4.16\r\nmistune                            0.8.4\r\nmkl-fft                            1.0.14\r\nmkl-random                         1.1.0\r\nmkl-service                        2.3.0\r\nmock                               3.0.5\r\nmore-itertools                     7.2.0\r\nmpmath                             1.1.0\r\nmsgpack                            0.6.1\r\nmultipledispatch                   0.6.0\r\nnavigator-updater                  0.2.1\r\nnbconvert                          5.6.0\r\nnbformat                           4.4.0\r\nnetworkx                           2.3\r\nnltk                               3.4.5\r\nnose                               1.3.7\r\nnotebook                           6.0.1\r\nnumba                              0.43.1\r\nnumexpr                            2.7.0\r\nnumpy                              1.16.5\r\nnumpydoc                           0.9.1\r\nolefile                            0.46\r\nopenpyxl                           2.6.3\r\nopt-einsum                         3.0.1\r\npackaging                          19.2\r\npandas                             0.25.1\r\npandocfilters                      1.4.2\r\nparso                              0.5.1\r\npartd                              1.0.0\r\npath.py                            12.0.1\r\npathlib2                           2.3.4\r\npatsy                              0.5.1\r\npep8                               1.7.1\r\npickleshare                        0.7.5\r\nPillow                             6.1.0\r\npip                                19.2.3\r\npkginfo                            1.5.0.1\r\npluggy                             0.13.0\r\nply                                3.11\r\nprometheus-client                  0.7.1\r\nprompt-toolkit                     2.0.9\r\nprotobuf                           3.9.2\r\npsutil                             5.6.3\r\npy                                 1.8.0\r\npycodestyle                        2.5.0\r\npycosat                            0.6.3\r\npycparser                          2.19\r\npycrypto                           2.6.1\r\npycurl                             7.43.0.3\r\npyflakes                           2.1.1\r\nPygments                           2.4.2\r\npylint                             2.3.1\r\npyodbc                             4.0.27\r\npyOpenSSL                          19.0.0\r\npyparsing                          2.4.2\r\npyreadline                         2.1\r\npyrsistent                         0.15.4\r\nPySocks                            1.7.1\r\npytest                             5.1.2\r\npytest-arraydiff                   0.3\r\npytest-astropy                     0.5.0\r\npytest-doctestplus                 0.4.0\r\npytest-openfiles                   0.4.0\r\npytest-remotedata                  0.3.2\r\npython-dateutil                    2.8.0\r\npytz                               2019.2\r\nPyWavelets                         1.0.3\r\npywin32                            223\r\npywinpty                           0.5.5\r\nPyYAML                             5.1.2\r\npyzmq                              18.1.0\r\nQtAwesome                          0.6.0\r\nqtconsole                          4.5.5\r\nQtPy                               1.9.0\r\nrequests                           2.22.0\r\nrope                               0.14.0\r\nruamel-yaml                        0.15.46\r\nscikit-image                       0.15.0\r\nscikit-learn                       0.21.3\r\nscipy                              1.3.1\r\nseaborn                            0.9.0\r\nSend2Trash                         1.5.0\r\nsetuptools                         41.2.0\r\nsimplegeneric                      0.8.1\r\nsingledispatch                     3.4.0.3\r\nsix                                1.12.0\r\nsnowballstemmer                    1.9.1\r\nsortedcollections                  1.1.2\r\nsortedcontainers                   2.1.0\r\nsoupsieve                          1.9.3\r\nSphinx                             2.2.0\r\nsphinxcontrib-applehelp            1.0.1\r\nsphinxcontrib-devhelp              1.0.1\r\nsphinxcontrib-htmlhelp             1.0.2\r\nsphinxcontrib-jsmath               1.0.1\r\nsphinxcontrib-qthelp               1.0.2\r\nsphinxcontrib-serializinghtml      1.1.3\r\nsphinxcontrib-websupport           1.1.2\r\nspyder                             3.3.6\r\nspyder-kernels                     0.5.2\r\nSQLAlchemy                         1.3.8\r\nstatsmodels                        0.10.1\r\nstyle                              1.1.0\r\nsympy                              1.4\r\ntables                             3.5.2\r\ntb-nightly                         2.1.0a20190927\r\ntblib                              1.4.0\r\ntensorflow-estimator-2.0-preview   2.0.0\r\ntermcolor                          1.1.0\r\nterminado                          0.8.2\r\ntestpath                           0.4.2\r\ntf-estimator-nightly               2.0.0.dev2019092611\r\ntf-nightly-2.0-preview             2.0.0.dev20190926\r\ntoolz                              0.10.0\r\ntornado                            6.0.3\r\ntqdm                               4.36.1\r\ntraitlets                          4.3.2\r\nunicodecsv                         0.14.1\r\nupdate                             0.0.1\r\nurllib3                            1.24.2\r\nwcwidth                            0.1.7\r\nwebencodings                       0.5.1\r\nWerkzeug                           0.16.0\r\nwheel                              0.33.6\r\nwidgetsnbextension                 3.5.1\r\nwin-inet-pton                      1.1.0\r\nwin-unicode-console                0.5\r\nwincertstore                       0.2\r\nwrapt                              1.11.2\r\nxlrd                               1.2.0\r\nXlsxWriter                         1.2.1\r\nxlwings                            0.15.10\r\nxlwt                               1.3.0\r\nzict                               1.0.0\r\nzipp                               0.6.0", "> I tried executing the standard template code in colab and on my computer successfully.Thanks!\r\n\r\nThen this is my detailed error message.\r\n\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py in execution_mode(mode)\r\n   1733     ctx.executor = executor_new\r\n-> 1734     yield\r\n   1735   finally:\r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in _next_internal(self)\r\n    650             output_types=self._flat_output_types,\r\n--> 651             output_shapes=self._flat_output_shapes)\r\n    652 \r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)\r\n   2360     except _core._NotOkStatusException as e:\r\n-> 2361       _ops.raise_from_not_ok_status(e, name)\r\n   2362   # Add nodes to the TensorFlow graph.\r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in raise_from_not_ok_status(e, name)\r\n   6612   # pylint: disable=protected-access\r\n-> 6613   six.raise_from(core._status_to_exception(e.code, message), None)\r\n   6614   # pylint: enable=protected-access\r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: slice index -1 of dimension 0 out of bounds.\r\n\t [[{{node strided_slice}}]]\r\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors. [Op:IteratorGetNextSync]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-23-f421ee3a3c47> in <module>\r\n----> 1 for image, label in labeled_ds.take(1):\r\n      2   print(\"Image shape: \", image.numpy().shape)\r\n      3   print(\"Label: \", label.numpy())\r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in __next__(self)\r\n    620 \r\n    621   def __next__(self):  # For Python 3 compatibility\r\n--> 622     return self.next()\r\n    623 \r\n    624   def _next_internal(self):\r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in next(self)\r\n    664     \"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\r\n    665     try:\r\n--> 666       return self._next_internal()\r\n    667     except errors.OutOfRangeError:\r\n    668       raise StopIteration\r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py in _next_internal(self)\r\n    655         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access\r\n    656       except AttributeError:\r\n--> 657         return structure.from_compatible_tensor_list(self._element_spec, ret)\r\n    658 \r\n    659   @property\r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n    128                 value = type()\r\n    129             try:\r\n--> 130                 self.gen.throw(type, value, traceback)\r\n    131             except StopIteration as exc:\r\n    132                 # Suppress StopIteration *unless* it's the same exception that\r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py in execution_mode(mode)\r\n   1735   finally:\r\n   1736     ctx.executor = executor_old\r\n-> 1737     executor_new.wait()\r\n   1738 \r\n   1739 \r\n\r\nF:\\path\\python\\anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\eager\\executor.py in wait(self)\r\n     65   def wait(self):\r\n     66     \"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\r\n---> 67     pywrap_tensorflow.TFE_ExecutorWaitForAllPendingNodes(self._handle)\r\n     68 \r\n     69   def clear_error(self):\r\n\r\nInvalidArgumentError: slice index -1 of dimension 0 out of bounds.\r\n\t [[{{node strided_slice}}]]\r\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.\r\n", "> \u6211\u5c1d\u8bd5\u5728colab\u548c\u6211\u7684\u8ba1\u7b97\u673a\u4e0a\u6210\u529f\u6267\u884c\u6807\u51c6\u6a21\u677f\u4ee3\u7801\u3002\u8c22\u8c22\uff01\r\n\r\nRunning this code with python 3.6.8 also gets the same error", "I tried to reproduce the error reported however I was unsuccessful. In the due process I compared the pip versions from your session and my colab runtime sessions.\r\nI see that colab is using ```pathlib==1.0.1``` whereas you are on ```pathlib2``` module.\r\nI have also upgraded Pillow to  match your version (6.1.0) \r\nHere's a [gist](https://colab.sandbox.google.com/gist/ymodak/4dfbf118f49f7ad101ad25cf80d39b60/images.ipynb#scrollTo=mgeiPZkM8_4g) of my colab attempt using which I was able to execute the script successfully.\r\n", "> I tried to reproduce the error reported however I was unsuccessful. In the due process I compared the pip versions from your session and my colab runtime sessions.\r\n> I see that colab is using `pathlib==1.0.1` whereas you are on `pathlib2` module.\r\n> I have also upgraded Pillow to match your version (6.1.0)\r\n> Here's a [gist](https://colab.sandbox.google.com/gist/ymodak/4dfbf118f49f7ad101ad25cf80d39b60/images.ipynb#scrollTo=mgeiPZkM8_4g) of my colab attempt using which I was able to execute the script successfully.\r\n\r\nI am sorry, your code failed to run on my computer.And got the same error message.\r\nColab uses the linux version of python and successfully runs this code.\r\nAnd I am using the win10 version of python, running this code and getting the same error.", "Please switch to 2.0.0 final release as there were bug fixes between the rc and the final release.", "> Please switch to 2.0.0 final release as there were bug fixes between the rc and the final release.\r\n\r\nI am running this demo code.\r\nhttps://tensorflow.google.cn/tutorials/load_data/images\r\nIt still returns the same error message.\r\n\r\nInvalidArgumentError: {{function_node __inference_Dataset_map_process_path_117}} slice index -1 of dimension 0 out of bounds.\r\n\t [[{{node strided_slice}}]] [Op:IteratorGetNextSync]\r\n", "I am having the same problem running the tutorial on Win10, Python 3.6.5, tensorflow==2.0.0, tensorflow-estimator==2.0.1, tensorflow-gpu==2.0.0, tensorboard==2.0.0.\r\nI don't have pathlib installed.", "@ouy160 @arielkempf Will try to reproduce the issue in windows and will get back to you", "I was facing the same issue and after pulling my hairs out I FOUND THE ANSWER.\r\nThe tf tutorials sometimes use some code that only works with Unix-like paths (using /)\r\n\r\nA quick windows fix, replace in the tuturial code\r\n`parts = tf.strings.split(file_path, '/')\r\n`\r\nwith\r\n`parts = tf.strings.split(file_path, '\\\\')\r\n`\r\nAnd it works.\r\n\r\nAnd the below fix should work **on both** unix and windows:\r\n`import os`\r\n`...`\r\n`parts = tf.strings.split(file_path, os.path.sep)`\r\n\r\n\r\n\r\nThe original slice index error message was coming afterwards from the`parts[-2]` that fails because of the split results that was only of dim 0 (no / separator was found).\r\n\r\nI recommend tf to fix the tutorial so they work on both unix and windows, perhaps the way I suggested.\r\n", "I have submitted a pull request to fix the tutorial.\r\nIn the meantime you can go ahead by applying the above change in your local code.\r\nPlease note this is not a bug of the tensorflow library, but an issue with the tutorial itself.", "> I have submitted a pull request to fix the tutorial.\r\n> In the meantime you can go ahead by applying the above change in your local code.\r\n> Please note this is not a bug of the tensorflow library, but an issue with the tutorial itself.\r\n\r\nwow,thank you so much. O(\u2229_\u2229)O", "For the record, I tried both of these in Win 10, and only the windows specific solution worked. \r\nSo, this worked: \r\nA quick windows fix, replace in the tutorial code\r\n`parts = tf.strings.split(file_path, '/')`\r\nwith\r\n\r\n` parts = tf.strings.split(file_path, '\\\\')`\r\n\r\n\r\n\r\nBUT this did not...\r\nAnd the below fix should work on both unix and windows:\r\nimport os\r\n...\r\n`parts = tf.strings.split(file_path, os.path.sep)`", "@marireeves\r\nThis is quite strange, I suspect an error on your local code.\r\nTry this dummy python code: it should really work on windows!\r\n(I also have windows 10)\r\n```\r\n\r\nimport os\r\nimport tensorflow as tf\r\n\r\nprint('Is it Backslash?', '\\\\' == os.path.sep)  # should be True on Windows\r\na_windows_path = r'C:\\some\\dummmy\\path\\parent_folder\\file.txt'\r\nparts = tf.strings.split(a_windows_path , os.path.sep)\r\nprint(parts)\r\nprint(parts[-1]) # the file\r\nprint(parts[-2]) # the parent folder\r\n```\r\nAnd that should print on Windows as\r\n\r\n> Is it Backslash? True\r\n> tf.Tensor([b'C:' b'some' b'dummmy' b'path' b'parent_folder' b'file.txt'], shape=(6,), dtype=string)\r\n> tf.Tensor(b'file.txt', shape=(), dtype=string)\r\n> tf.Tensor(b'parent_folder', shape=(), dtype=string)\r\n", "You're right, the dummy code runs with the following output. I'll take another look at that tutorial code:\r\n\r\nIs it Backslash? True\r\ntf.Tensor([b'C:' b'some' b'dummmy' b'path' b'parent_folder' b'file.txt'], shape=(6,), dtype=string)\r\ntf.Tensor(b'file.txt', shape=(), dtype=string)\r\ntf.Tensor(b'parent_folder', shape=(), dtype=string)", "It works both ways if you don't leave out the import os statement... thanks!\r\n", "@ouy160: With the fixed tutorial is there any further action needed for this issue or should we close it?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32908\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32908\">No</a>\n"]}, {"number": 32907, "title": "tensorflow c sdk crash when called by a java program", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Red Hat 4.8.5-4**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **tensorflow-gpu-linux-x86_64-1.13.1**\r\n- Python version: **No**\r\n- CUDA/cuDNN version: **cuda 10.0**\r\n- GPU model and memory:  **NVIDIA Tesla v100 GPU 16GB**\r\n- JAVA version: \r\n`openjdk version \"1.8.0_65\"\r\nOpenJDK Runtime Environment (build 1.8.0_65-b17)\r\nOpenJDK 64-Bit Server VM (build 25.65-b01, mixed mode)`\r\n\r\n**Describe the current behavior**\r\n\r\nI write a dynamic library with the tensorflow c sdk which can be called normally by a c++ program but when I wrap it as a jni and call it from a java program, it will crash:\r\n\r\n`A fatal error has been detected by the Java Runtime Environment:\r\nSIGSEGV (0xb) at pc=0x00007fab17a903dd, pid=26065, tid=140380063385344\r\nJRE version: OpenJDK Runtime Environment (8.0_65-b17) (build 1.8.0_65-b17)\r\nJava VM: OpenJDK 64-Bit Server VM (25.65-b01 mixed mode linux-amd64 compressed oops)\r\nProblematic frame:\r\nC  [libtensorflow.so+0x9b03dd]  tensorflow::TF_TensorToTensor(TF_Tensor const*, tensorflow::Tensor*)+0x1d\r\n`\r\nWhat's the reason for that? Thanks.\r\n\r\n**Code to reproduce the issue**\r\n\r\nA sample class like [here](https://gist.github.com/knsong/4f39a467cb43d55e6176ffefed27863c), which was instantiated globally.  When called by the java program, the code will crash at this [line](https://gist.github.com/knsong/4f39a467cb43d55e6176ffefed27863c#file-sample-code-L142)\r\n", "comments": []}, {"number": 32906, "title": "An error occur in \"cwise_op_gpu\" and faile to complete when building the tf2.0_rc2", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10 1903\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0-rc2\r\n- Python version: Python 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): ms vs2017 15.9.16\r\n- CUDA/cuDNN version: cuda10.1 cudnn7.5\r\n- GPU model and memory: one rtx2080ti with 11GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nwhen I run \"bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\"\r\nI got an error and failed to build\r\n\r\n\r\n```\r\nERROR: C:/users/bill_/desktop/tensorflow-2.0.0-rc2/tensorflow/core/kernels/BUILD:3717:1: C++ compilation of rule '//tensorflow/core/kernels:cwise_op_gpu' failed (Exit 1): python.exe failed: error executing command\r\n  cd C:/users/bill_/_bazel_bill_/7zm7bpa5/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Anaconda3/envs/tf-2.0/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Anaconda3/envs/tf-2.0/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=C:\\Users\\bill_\\AppData\\Local\\Temp\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=7.0,8.0\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\bill_\\AppData\\Local\\Temp\r\n  C:/Anaconda3/envs/tf-2.0/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX -DGOOGLE_CUDA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -x cuda -DGOOGLE_CUDA=1 -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/_objs/cwise_op_gpu/cwise_op_gpu_xlogy.cu.o /c tensorflow/core/kernels/cwise_op_gpu_xlogy.cu.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nnvcc fatal   : Unsupported gpu architecture 'compute_80'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 481.922s, Critical Path: 146.36s\r\nINFO: 4933 processes: 4933 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI have build the tensorflow2.0 with https://tensorflow.google.cn/install/source_windows\r\n\r\nI run \"python ./configure.py\" with \r\n\r\n```\r\n(tf-2.0) C:\\Users\\bill_\\Desktop\\tensorflow-2.0.0-rc2>python .\\configure.py\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.26.1 installed.\r\nPlease specify the location of python. [Default is C:\\Anaconda3\\envs\\tf-2.0\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Anaconda3\\envs\\tf-2.0\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Anaconda3\\envs\\tf-2.0\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.1 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\r\nFound cuDNN 7 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 7.0,7.5\r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=noignite       # Disable Apache Ignite support.\r\n        --config=nokafka        # Disable Apache Kafka support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I found the way to handle this problem, after changing `Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 7.0,8,0` to `7.0,7.5` the error gone.\r\n\r\nhowever, another error occurred\r\n\r\n```ERROR: C:/users/bill_/desktop/tensorflow-2.0.0-rc2/tensorflow/core/grappler/optimizers/data/BUILD:712:1: C++ compilation of rule '//tensorflow/core/grappler/optimizers/data:rebatch' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/bill_/_bazel_bill_/7zm7bpa5/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Anaconda3/envs/tf-2.0/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Anaconda3/envs/tf-2.0/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=C:\\Users\\bill_\\AppData\\Local\\Temp\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=7.0,7.5\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\bill_\\AppData\\Local\\Temp\r\n  C:/Anaconda3/envs/tf-2.0/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX /Fobazel-out/x64_windows-opt/bin/tensorflow/core/grappler/optimizers/data/_objs/rebatch/rebatch.o /c tensorflow/core/grappler/optimizers/data/rebatch.cc\r\nExecution platform: @bazel_tools//platforms:host_platform`\r\n\r\nand\r\n\r\n`tensorflow/core/grappler/optimizers/data/rebatch.cc(66): fatal error C1001: \u7f16\u8bd1\u5668\u4e2d\u53d1\u751f\u5185\u90e8\u9519\u8bef\u3002\r\n(\u7f16\u8bd1\u5668\u6587\u4ef6\u201cmsc1.cpp\u201d\uff0c\u7b2c 1468 \u884c)\r\n \u8981\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u8bf7\u5c1d\u8bd5\u7b80\u5316\u6216\u66f4\u6539\u4e0a\u9762\u6240\u5217\u4f4d\u7f6e\u9644\u8fd1\u7684\u7a0b\u5e8f\u3002\r\n\u8bf7\u9009\u62e9 Visual C++\r\n\u201c\u5e2e\u52a9\u201d\u83dc\u5355\u4e0a\u7684\u201c\u6280\u672f\u652f\u6301\u201d\u547d\u4ee4\uff0c\u6216\u6253\u5f00\u6280\u672f\u652f\u6301\u5e2e\u52a9\u6587\u4ef6\u6765\u83b7\u5f97\u8be6\u7ec6\u4fe1\u606f\u3002\r\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\amd64\\cl.exe \u4e2d\u6709\u5185\u90e8\u7f16\u8bd1\u5668\u9519\u8bef\u3002\u7cfb\u7edf\u5c06\u4f1a\u63d0\u793a\u4f60\u7a0d\u540e\u5411 Microsoft \u53d1\u9001\u9519\u8bef\u62a5\u544a\u3002\r\n\u201cC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\amd64\\cl.exe\u201d\u4e2d\u7684\u5185\u90e8\u7f16\u8bd1\u5668\u9519\u8bef\r\n  \u8bf7\u9009\u62e9 Visual C++\r\n\u201c\u5e2e\u52a9\u201d\u83dc\u5355\u4e0a\u7684\u201c\u6280\u672f\u652f\u6301\u201d\u547d\u4ee4\uff0c\u6216\u6253\u5f00\u6280\u672f\u652f\u6301\u5e2e\u52a9\u6587\u4ef6\u6765\u83b7\u5f97\u8be6\u7ec6\u4fe1\u606f\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1136.963s, Critical Path: 419.18s\r\nINFO: 3774 processes: 3774 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "Thanks for your report and the `./configure` log. Can you attach a complete log of replicating this at `master`, please?", "> Thanks for your report and the `./configure` log. Can you attach a complete log of replicating this at `master`, please?\r\n\r\nI solved this problem according to https://github.com/tensorflow/tensorflow/issues/31520#issuecomment-524584978\r\n\r\nThe problem still exists in TF 2.0 release, and I don't know why the solution worked.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32906\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32906\">No</a>\n"]}, {"number": 32905, "title": " \"tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)\" is not compatible with \"tf.keras.LearningRateScheduler\" and \"tf.keras.ReduceLROnPlateau\"", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**Ubuntu 18.04**\r\n- TensorFlow version (you are using): 1.14.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\nAfter calling \"opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)\", the returned opt lost its attribute \"lr\".\r\n", "comments": ["I believe it\u2019s fixed in latest master. Could you try with the latest nightly packages again?", "@joe1chief,\r\nCan you try the @byronyi's suggestion and let us if that resolves your issue. Thanks!", "@joe1chief, Did you try with the latest TF nightly build version. Thanks", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 32904, "title": "  Inference time by quantized model is longer than that by non-quantized model in Tensorflow", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 1806\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  ARMv8 AARCH64\r\n- TensorFlow installed from (source or binary):  source\r\n- TensorFlow version (use command below):  1.12.3\r\n- Python version:  2.7.15\r\n- Bazel version (if compiling from source):  0.15.0-dist   \r\n- GCC/Compiler version (if compiling from source):  7.3\r\n- CUDA/cuDNN version:  NA\r\n- GPU model and memory: NA\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI want to measure Tensorflow inference time with different models on my 4-core ARMv8 CPU.\r\nI downloaded quantized and float point models from https://www.tensorflow.org/lite/guide/hosted_models. Then run benchmark_model to measure inference time. \r\nPlease see attached picture for my benchmarking result.\r\nFrom the result, you can see the inference time of the quantized models is always a little bit longer than the float point model. \r\nI also did the same benchmark with TFLite, the inference time of the quantized models is much lower as I expect.\r\n\r\n**Describe the expected behavior**\r\n I think the inference time of quantized models should be much lower than that of float point models.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThe \r\n![tensorflow](https://user-images.githubusercontent.com/44886342/65829997-fc4c0100-e2dd-11e9-8bd5-c8a3d2b69e82.jpg)\r\ncommands as below:\r\nFor quantized models:\r\n    echo \"inception_v4\"\r\n    bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=model/classfication_int8/inception_v4/inception_v4.pb  --input_layer=input --input_layer_type=float --input_layer_shape=1,299,299,3 --output_layer=InceptionV4/Logits/Predictions  --show_run_order=false --num_threads=1 --show_flops\r\n\r\n    echo \"mobilenet_v1_1.0_224\"\r\n    bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=model/classfication_int8/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224.pb --show_flops --input_layer=input --input_layer_type=float --input_layer_shape=1,224,224,3 --output_layer=MobilenetV1/Predictions/Reshape_1  --show_run_order=false --num_threads=1\r\n\r\n    echo \"mobilenet_v2_1.0_224\"\r\n    bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=model/classfication_int8/mobilenet_v2_1.0_224/mobilenet_v2_1.0_224.pb  --output_layer=output  --show_run_order=false --num_threads=1 --show_flops\r\n\r\nFor float point models:\r\n    echo \"inception_v4\"\r\n    bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=model/classfication-fp32/inception_v4/inception_v4.pb --show_flops --input_layer=input --input_layer_type=float --input_layer_shape=1,299,299,3 --output_layer=InceptionV4/Logits/Predictions  --show_run_order=false --num_threads=1\r\n\r\n    echo \"mobilenet_v1_1.0_224\"\r\n    bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=model/classfication-fp32/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224.pb --show_flops --input_layer=input --input_layer_type=float --input_layer_shape=1,224,224,3 --output_layer=MobilenetV1/Predictions/Reshape_1  --show_run_order=false --num_threads=1\r\n\r\n    echo \"mobilenet_v2_1.0_224\"\r\n    bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=model/classfication-fp32/mobilenet_v2_1.0_224/mobilenet_v2_1.0_224.pb --show_flops --input_layer=input --input_layer_type=float  --output_layer=MobilenetV2/Predictions/Reshape_1  --show_run_order=false --num_threads=1\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Hi,\r\n\r\nThis is because the included models are not fully quantized for TensorFlow, but instead Quantization-aware trained model. This means they are float, but have FakeQuantWithMinMaxVars operations emulating the effect of quantization during training. The intention of these models is to emulate the effects of quantization in TensorFlow graphs so that they can be easily converted to TensorFlow Lite models.\r\n\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32904\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32904\">No</a>\n"]}, {"number": 32903, "title": "Let us decide the index of the blank in tf.nn.ctc_greedy_decoder ", "body": "**System information**\r\n- TensorFlow version (you are using): 2.0.0rc1 \r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI am using ctc_greedy_decoder function to decode my output from logits. In the ctc_loss function, we have the opportunity to choose blank_index equals what, but in the ctc_greedy_decoder function, it seems equals (num_classes-1) by default. Thus I have to write a map function by myself or change my lookup table\r\n\r\n**Will this change the current api? How?**\r\n\r\nPlease add a parameter to this function in order to choose which index we use.", "comments": ["Hello! Is anyone working on this? If not could I have a try?", "Yes; please feel free.\n\nOn Fri, Apr 3, 2020 at 1:11 PM Panagiotis Varouktsis <\nnotifications@github.com> wrote:\n\n> Hello! Is anyone working on this? If not could I have a try?\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/32903#issuecomment-608636154>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AANWFGZDNTMIT4BS2NLDLE3RKY7HHANCNFSM4I3RR32A>\n> .\n>\n", "Thank you!", "Although I really want to do this, I don\u2019t know how to contribute it. I have gone to view the implementation of this function, but I can't find the gen_ctc_ops module. Maybe it implemented by c/c++ code, I am not clear how the python code calls the c/c++ code. There also have a function should add the parameter: tf.nn.ctc_beam_search_decoder.", "I believe it's in core/ops/ctc_ops.cc.\n\nOn Fri, Apr 3, 2020, 8:41 PM Yiming Huang <notifications@github.com> wrote:\n\n> Although I really want to do this, I don\u2019t know how to contribute it. I\n> have gone to view the implementation of this function, but I can't find the\n> gen_ctc_ops module.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/32903#issuecomment-608966737>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AANWFG6TGNMHOFABFJTCSJLRK2T77ANCNFSM4I3RR32A>\n> .\n>\n", "@FLming ,\r\nRelated PR was merged.Can you please let us confirm if the issue has resolved with the merged PR.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "OK, I will check it in this week.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "LGFM. Thanks."]}, {"number": 32902, "title": "bug when supplying metadata files for embeddings in tensorboard callback", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):MacOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):2.0.0-dev20190927\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\ngetting the error:\r\n`ValueError: Unrecognized `Embedding` layer names passed to `keras.callbacks.TensorBoard` `embeddings_metadata` argument: dict_keys(['char_embeddings'])`\r\nwhen passing embeddings_metadata to tensorflow.keras.callback.TesnorBoard\r\n**Describe the expected behavior**\r\nuse the metadata in tensorboard\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nin https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/callbacks.py#L1547\r\n\r\n```\r\n            if layer.name in embedding.metadata_path:\r\n              embedding.metadata_path = self.embeddings_metadata.pop(layer.name)\r\n\r\n```\r\nshould be:\r\n```\r\n            if layer.name in self.embeddings_metadata:\r\n              embedding.metadata_path = self.embeddings_metadata.pop(layer.name)\r\n\r\n```\r\n", "comments": ["@ophiry,\r\nDo you have sample code to reproduce the issue. Thanks!", "@gadagashwini \r\ncode to reproduce:\r\n```\r\nimport tensorflow\r\nimport numpy\r\nembedding_layer = tensorflow.keras.layers.Embedding(input_dim=1, output_dim=1, name='e')\r\nmodel = tensorflow.keras.models.Sequential([embedding_layer])\r\nmodel.compile(loss='mse')\r\nmodel.fit(numpy.zeros((10, 1)), numpy.zeros((10, 1)), steps_per_epoch=1, callbacks=[\r\n    tensorflow.keras.callbacks.TensorBoard(embeddings_freq=1, embeddings_metadata={'e': '/tmp/x'})\r\n])\r\n\r\n```\r\n\r\noutput is: \r\n\r\n> ValueError: Unrecognized `Embedding` layer names passed to `keras.callbacks.TensorBoard` `embeddings_metadata` argument: dict_keys(['e'])\r\n", "@ophiry, Thanks. I could reproduce the issue with Tf 2.0 latest preview version on colab. Please take a look at [gist here](https://colab.sandbox.google.com/gist/gadagashwini/231b054a770f2af69ca8ca782f3c49e3/untitled170.ipynb). Thanks!", "@ophiry,\r\nAs per the explanation provided in [this link](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard), the value of the Dictionary of the parameter, `embeddings_metadata` should be a File, not a Folder. Can you please modify it accordingly.\r\n\r\nPlease refer [this link](https://www.tensorflow.org/tensorboard/r1/summaries#metadata_optional) for more information on the MetaData Files. Thanks!", "It is a file - but from inspecting the code it's clear the value isn't used.\r\n\r\nnote that changing the code as I described in the original message fixes the issue\r\n", "+1", "> It is a file - but from inspecting the code it's clear the value isn't used.\r\n> \r\n> note that changing the code as I described in the original message fixes the issue\r\n\r\nCould you tell me the metadata format? \r\n```\r\nwith open('./logs/text_classify/word.tsv','w') as f:\r\n    f.write('{}\\t{}\\n'.format('id','words'))\r\n    for k, v in word_index.items():\r\n        f.write('{}\\t{}\\n'.format(v,k))\r\n```\r\n```\r\ncallback = [\r\n            tf.keras.callbacks.TensorBoard(log_dir='./logs/text_classify',histogram_freq=5000,\r\n            write_graph=True, write_images=False,\r\n            embeddings_freq=1,\r\n            update_freq='epoch',\r\n            embeddings_metadata ={layer_embed.name:'./logs/text_classify/word.tsv'} )\r\n```\r\nI wrote the code above, but I found it doesn't works, it still shows the id of word rather than the word itself.\r\n", "@ophiry I think the issue is resolved and closing this as of now. Please feel free to reopen the issue if you still have a concern.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32902\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32902\">No</a>\n"]}, {"number": 32901, "title": "whether cuda toolkit 10.1 version supports tensorflow 1.14Version?", "body": "trying to install tensorflow 2.0 in windows 10. Already installed CUDA toolkit 10.1 and cudNN", "comments": ["Yes and no. There are no public precompiled tf binaries for CUDA 10.1 but you can compile it yourself.\r\n\r\nYou're better off installing `cuda_10.0.130_411.31_win10` and `cudnn-10.0-windows10-x64-v7.6.4.38`.\r\n\r\ncudNN installation is just about extracting it to `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0`.\r\n\r\nYou can still have the latest NVIDIA drivers, so there is no need to go through all the trouble and timesink of compiling Tensorflow 2.0 by yourself in Windows. If you want to spend time with this, https://github.com/tensorflow/tensorflow/issues/28086 might be a good start.\r\n\r\nIf you still want to build with CUDA 10.1 then doing it in Linux is much easier than with Windows.", "@WrathofBhuvan11,\r\nPlease take a look at [software requirements](https://www.tensorflow.org/install/gpu#software_requirements) for Tensorflow. Thanks!", "@WrathofBhuvan11, Were you able to resolve this issue. Thanks!", "currently i have installed cudatoolkit 10.1 and cudnn recent one but having\npath error... i have added these to environmental variables... yet while\nimporting tf i'm getting\n\nOn Mon, Oct 7, 2019 at 4:52 PM gadagashwini <notifications@github.com>\nwrote:\n\n> @WrathofBhuvan11 <https://github.com/WrathofBhuvan11>, Were you able to\n> resolve this issue. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/32901?email_source=notifications&email_token=AIUNWZLPGDXXPI6YQJTJHHTQNMLXXA5CNFSM4I3RA5IKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEAP5SQQ#issuecomment-538958146>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIUNWZJNLPNPMRN2U72QRK3QNMLXXANCNFSM4I3RA5IA>\n> .\n>\n", "@WrathofBhuvan11 If you want to use cuda 10.1 then you must compile the whole tensorflow by yourself on Windows.\r\n\r\nUnless you have a very specific reason to use cuda 10.1, I'd strongly recommended to use cuda 10.0, which works great with the tensorflow binary package. Please note that GPU drivers themselves can be still the latest.\r\n\r\nLatest compatible versions as of last week are `cuda_10.0.130_411.31_win10` and `cudnn-10.0-windows10-x64-v7.6.4.38`.", "\u0634\u0643\u0631\u0627 \u0648\u0644\u0627\u0643\u0646\u064a \u0627\u0633\u062a\u062e\u062f\u0645\u00a0\u062c\u0648\u0627\u0644 \u0647\u0648\u0627\u0648\u064a q20\u0627\u0631\u062c\u0648 \u0627\u0644\u0631\u062f \u0648\u0627\u0644\u0627\u0626\u064a\u0641\u0627\u062f\u0647\u0647\u0644 \u062a\u0642\u0635\u062f \u0644\u0644\u0645\u062d\u0641\u0638\u0647 \u0627\u0645 \u0644\u062a\u0633\u0631\u064a\u0639 \u0627\u0644\u062a\u0639\u062f\u064a\u0646 \u0648\u0645\u0627\u0647\u064a \u0627\u0641\u0638\u0644 \u0628\u0631\u0627\u0645\u062c \u0647\u0648\u0627\u0648\u064a \u0644\u062a\u0633\u0631\u064a\u0639 \u0627\u0644\u062a\u0639\u062f\u064a\u0646 \u0648\u0627\u0628\u0642\u0627 \u0627\u0644\u062c\u0648\u0627\u0644 \u0628\u062d\u0627\u0644\u0647 \u0645\u0633\u062a\u0645\u0631\u0647 \u0644\u062a\u0639\u062f\u064a\u0646\u0645\u064f\u0631\u0633\u0644 \u0645\u0646 \ud83d\udcf1 android is Huawei \u0627\u0644\u062e\u0627\u0635 \u0628\u064a-------- \u0627\u0644\u0631\u0633\u0627\u0644\u0629 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 --------\u0627\u0644\u0645\u0648\u0636\u0648\u0639: Re: [tensorflow/tensorflow] whether cuda toolkit 10.1 version supports tensorflow 1.14Version? (#32901)\u0645\u0646: Ahti Kitsik \u0625\u0644\u0649: tensorflow/tensorflow \u0646\u0633\u062e\u0629 \u0625\u0644\u0649: salman222-1 ,Manual @WrathofBhuvan11 If you want to use cuda 10.1 then you must compile the whole tensorflow by yourself on Windows.\r\nUnless you have a very specific reason to use cuda 10.1, I'd strongly recommended to use cuda 10.0, which works great with the tensorflow binary package. Please note that GPU drivers themselves can be still the latest.\r\nLatest compatible versions as of last week are cuda_10.0.130_411.31_win10 and cudnn-10.0-windows10-x64-v7.6.4.38.\r\n\r\n\u2014You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or mute the thread.", "@WrathofBhuvan11,\r\nDid you try the suggestion of @ahtik's. Thanks!", "@WrathofBhuvan11, Were you able to resolve this issue. Thanks", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32901\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32901\">No</a>\n", "same issue, I can't use the GPU when I used the follow command:\r\n\r\n```shell\r\nfrom tensorflow.python.client import device_lib\r\nprint(device_lib.list_local_devices())\r\n```\r\n\r\nmy environment:\r\n```shell\r\n#cuda version\r\nCuda compilation tools, release 10.1, V10.1.243\r\n\r\n#tensorflow version\r\ntensorflow (1.14.0)\r\ntensorflow-gpu (1.14.0)\r\n\r\n#OS version\r\nCentOS Linux release 7.6.1810 (Core)\r\n\r\n#kernel version\r\n3.10.0-957.el7.x86_64\r\n\r\n```\r\n\r\n", "@Donald-Su ,\r\nPlease post a new issue and provide all the information asked by the template. We ask this because it's more efficient to have one thread dedicated to one issue. Thanks!"]}, {"number": 32900, "title": "cannot run the model from Saver", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04\r\n- TensorFlow version:Tensorflow nightly\r\n- Python version:3.6\r\n- Installed using virtualenv? pip? conda?:pip\r\n- CUDA/cuDNN version:7/10\r\n\r\n**Describe the problem**\r\nI use tf.train.Saver() to save the model, but when I train to restore it, I find the output didn't change even though the inputs are different. Here is my code to save the model:\r\n\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport gzip\r\nimport os\r\nimport sys\r\nimport time\r\nimport joblib\r\nimport math\r\nimport numpy\r\nfrom six.moves import urllib\r\nfrom six.moves import xrange  \r\nfrom PIL import Image\r\nfrom sklearn.metrics import confusion_matrix as sk_confusion_matrix\r\nfrom sklearn.metrics import classification_report\r\nimport tensorflow as tf\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\r\nFLAGS = None\r\nIMAGE_HEIGHT = 128\r\nIMAGE_WEITH = 128\r\nNUM_CHANNELS = 1\r\nNUM_LABELS = 4\r\nSEED = 66478  # Set to None for random seed.\r\nBATCH_SIZE = 32\r\nEVAL_BATCH_SIZE = 32\r\nEVAL_FREQUENCY = 10  # Number of steps between evaluations.\r\n\r\ndef data_type():\r\n  \"\"\"Return the type of the activations, weights, and placeholder variables.\"\"\"\r\n  if FLAGS.use_fp16:\r\n    return tf.float16\r\n  else:\r\n    return tf.float32\r\n\r\n\r\ndef fake_data(num_images):\r\n  \"\"\"Generate a fake dataset that matches the dimensions of MNIST.\"\"\"\r\n  data = numpy.ndarray(\r\n      shape=(num_images, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS),\r\n      dtype=numpy.float32)\r\n  labels = numpy.zeros(shape=(num_images,), dtype=numpy.int64)\r\n  for image in xrange(num_images):\r\n    label = image % 2\r\n    data[image, :, :, 0] = label - 0.5\r\n    labels[image] = label\r\n  return data, labels\r\n\r\n\r\ndef error_rate(predictions, labels):\r\n  Confusion_matrix=sk_confusion_matrix(numpy.argmax(predictions, 1).tolist(), labels.tolist())\r\n  print('Confusion_matrix:')\r\n  print(Confusion_matrix)  \r\n\r\n  Se1 = Confusion_matrix[1,1]+Confusion_matrix[2,2]+Confusion_matrix[3,3]\r\n  Se2 = Confusion_matrix[1,1]+Confusion_matrix[1,0]+Confusion_matrix[1,2]+Confusion_matrix[1,3]+Confusion_matrix[2,2]+Confusion_matrix[2,0]+Confusion_matrix[2,1]+Confusion_matrix[2,3]+Confusion_matrix[3,3]+Confusion_matrix[3,0]+Confusion_matrix[3,1]+Confusion_matrix[3,2]\r\n  Se = Se1/Se2\r\n  Sp = Confusion_matrix[0,0]/(Confusion_matrix[0,0]+Confusion_matrix[0,1]+Confusion_matrix[0,2]+Confusion_matrix[0,3]) \r\n  Acc = (Se+Sp)*100/2\r\n\r\n  target_names = ['class 0', 'class 1', 'class 2', 'class 3']\r\n\r\n  print()\r\n  accuracy = 100.0-(100.0 *numpy.sum(numpy.argmax(predictions, 1) == labels)/predictions.shape[0])\r\n  \r\n  \"\"\"Return the error rate based on dense predictions and sparse labels.\"\"\"\r\n  return 100.0 - (\r\n      100.0 *\r\n      numpy.sum(numpy.argmax(predictions, 1) == labels) /\r\n      predictions.shape[0]), Acc\r\n\r\ndef GroupNorm(x, G, eps=1e-05):\r\n    # x: input features with shape [N,H,W,C]\r\n    # gamma, beta: scale and offset, with shape [1,C,1,1]\r\n    # G: number of groups for GN\r\n  N, H, W, C = x.shape\r\n # N = BATCH_SIZE\r\n  gamma = tf.ones([1, 1, 1, C])\r\n  beta = tf.zeros([1, 1, 1, C])\r\n#  x = tf.reshape(x, [-1, G, H, W, C // G])\r\n\r\n  mean = tf.reduce_max(x, axis=[1,2,3], keep_dims=True)\r\n\r\n  var = tf.subtract(x,mean)\r\n  var = var*var\r\n  var = tf.reduce_max(x, axis=[1,2,3], keep_dims=True)\r\n \r\n  x1 = tf.subtract(x,mean) / tf.sqrt(var + eps)\r\n#  x2 = tf.reshape(x1, [-1, H, W, C])\r\n  return x1 * gamma + beta\r\n\r\nclass ResBlock(object):\r\n\r\n  def __init__(self, stride_num=1, downsample=False):\r\n    self.conv1_weights = tf.Variable(\r\n      tf.truncated_normal([1, 1, 64, 64],  # 1x1 filter, depth 64.\r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))  \r\n\r\n    self.conv2_weights = tf.Variable(\r\n      tf.truncated_normal([3, 3, 64, 64],  # 3x3 filter, depth 64.\r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))\r\n    self.conv3_weights = tf.Variable(\r\n      tf.truncated_normal([3, 3, 64, 64],  # 3x3 filter, depth 64.\r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))  \r\n    self.stride_num = stride_num\r\n    self.downsample = downsample\r\n\r\n  def forward(self, data):\r\n    with tf.name_scope('ResNet'):\r\n    # shortcut = x\r\n      shortcut = data\r\n      # out = self.relu(self.norm1(x))\r\n#      axis = list(range(len(data.get_shape()) - 1))\r\n      with tf.name_scope('BN1'):\r\n        out = GroupNorm(x=data, G=32)\r\n        #mean, variance = tf.nn.moments(data, axis)\r\n        #out = tf.nn.batch_normalization(data, mean, variance, 0, 1, 0.001)\r\n      with tf.name_scope('relu1'):\r\n        out = tf.nn.relu(out)\r\n      #  if self.downsample is not None:\r\n        #   shortcut = self.downsample(out)\r\n      with tf.name_scope('downsample'):\r\n        if self.downsample is True:\r\n          shortcut = tf.nn.conv2d(out,\r\n                                  self.conv1_weights,\r\n                                  strides=[1, self.stride_num, self.stride_num, 1],\r\n                                  padding='SAME')\r\n        #  out = self.conv1(out)\r\n      with tf.name_scope('conv1'):\r\n        out = tf.nn.conv2d(out,\r\n                          self.conv2_weights,\r\n                          strides=[1, self.stride_num, self.stride_num, 1],\r\n                          padding='SAME')\r\n      #  out = self.droupout(out)\r\n      #  out = self.norm2(out)\r\n      with tf.name_scope('BN2'):\r\n        out = GroupNorm(x=out, G=32)\r\n\r\n      #  out = self.relu(out) \r\n      with tf.name_scope('relu2'):\r\n        out = tf.nn.relu(out)   \r\n      #  out = self.conv2(out)\r\n      with tf.name_scope('conv2'):\r\n        out = tf.nn.conv2d(out,\r\n                          self.conv3_weights,\r\n                          strides=[1, 1, 1, 1],\r\n                          padding='SAME')\r\n    return shortcut+out\r\n\r\nclass BRN(object):\r\n\r\n  def __init__(self):\r\n    self.ResNet_0_0 = ResBlock(2, True)\r\n    self.ResNet_0_1 = ResBlock(2, True)\r\n    self.ResNet_1_0 = ResBlock(2, True)\r\n    self.ResNet_1_1 = ResBlock(2, True)\r\n    self.ResNet_0 = ResBlock(1, False)\r\n    self.ResNet_1 = ResBlock(1, False)\r\n    self.ResNet_2 = ResBlock(1, False)\r\n    self.ResNet_3 = ResBlock(1, False)\r\n    self.ResNet_4 = ResBlock(1, False)\r\n    self.ResNet_5 = ResBlock(1, False)\r\n    self.ResNet_6 = ResBlock(1, False)\r\n    self.ResNet_7 = ResBlock(1, False)\r\n    self.ResNet_8 = ResBlock(1, False)\r\n    self.ResNet_9 = ResBlock(1, False)\r\n    self.ResNet_10 = ResBlock(1, False)\r\n    self.ResNet_11 = ResBlock(1, False)\r\n    self.ResNet_12 = ResBlock(1, False)\r\n    self.ResNet_13 = ResBlock(1, False)\r\n    self.ResNet_14 = ResBlock(1, False)\r\n    self.ResNet_15 = ResBlock(1, False)\r\n    self.ResNet_16 = ResBlock(1, False)\r\n    self.ResNet_17 = ResBlock(1, False)\r\n    self.ResNet_18 = ResBlock(1, False)\r\n    self.ResNet_19 = ResBlock(1, False)\r\n    self.ResNet_20 = ResBlock(1, False)\r\n    self.ResNet_21 = ResBlock(1, False)\r\n    self.conv1_weights = tf.Variable(\r\n      tf.truncated_normal([3, 3, NUM_CHANNELS, 64],  \r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))  \r\n    self.conv2_weights = tf.Variable(\r\n      tf.truncated_normal([3, 3, NUM_CHANNELS, 64],  \r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))  \r\n    self.fc_weights = tf.Variable(tf.truncated_normal([64, NUM_LABELS],\r\n                                                stddev=0.1,\r\n                                                seed=SEED,\r\n                                                dtype=data_type()))\r\n\r\n    self.fc_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS], dtype=data_type()))\r\n\r\n  def forward(self, stft, mfcc):\r\n\r\n    with tf.name_scope('BRNcon1'):\r\n      out_s = tf.nn.conv2d(stft,\r\n                        self.conv1_weights,\r\n                        strides= [1, 1, 1, 1],\r\n                        padding='VALID')\r\n    with tf.name_scope('resnetblocks_1'):\r\n      out_s = self.ResNet_0_0.forward(out_s)\r\n    with tf.name_scope('resnetblocks_2'):\r\n      out_s = self.ResNet_0_1.forward(out_s)\r\n    with tf.name_scope('resnetblocks_3'):\r\n      out_s = self.ResNet_0.forward(out_s)\r\n    with tf.name_scope('resnetblocks_4'):\r\n      out_s = self.ResNet_2.forward(out_s)\r\n    with tf.name_scope('resnetblocks_5'):\r\n      out_s = self.ResNet_4.forward(out_s)\r\n    with tf.name_scope('resnetblocks_6'):\r\n      out_s = self.ResNet_6.forward(out_s)\r\n    with tf.name_scope('resnetblocks_7'):\r\n      out_s = self.ResNet_8.forward(out_s)\r\n    with tf.name_scope('resnetblocks_8'):\r\n      out_s = self.ResNet_10.forward(out_s)\r\n    with tf.name_scope('resnetblocks_9'):\r\n      out_s = self.ResNet_12.forward(out_s)\r\n    with tf.name_scope('resnetblocks_10'):\r\n      out_s = self.ResNet_14.forward(out_s)\r\n    with tf.name_scope('resnetblocks_11'):\r\n      out_s = self.ResNet_16.forward(out_s)\r\n    with tf.name_scope('resnetblocks_12'):\r\n      out_s = self.ResNet_18.forward(out_s)\r\n    with tf.name_scope('resnetblocks_13'):\r\n      out_s = self.ResNet_20.forward(out_s)\r\n    with tf.name_scope('brns_bn1'):\r\n      out_s = GroupNorm(x=out_s, G=32)\r\n\r\n    with tf.name_scope('brn_relu_1'):\r\n      out_s = tf.nn.relu(out_s)\r\n    with tf.name_scope('brn_pool1'):\r\n      out_s = tf.nn.avg_pool(out_s,\r\n                            ksize=[1,out_s.shape[2],out_s.shape[2],1],\r\n                            strides=[1, 1, 1, 1],\r\n                            padding='VALID')\r\n\r\n    with tf.name_scope('BRNcon2'):\r\n      out_m = tf.nn.conv2d(mfcc,\r\n                        self.conv2_weights,\r\n                        strides= [1, 1, 1, 1],\r\n                        padding='VALID')\r\n    with tf.name_scope('resnetblockm_1'):\r\n      out_m = self.ResNet_1_0.forward(out_m)\r\n    with tf.name_scope('resnetblockm_2'):\r\n      out_m = self.ResNet_1_1.forward(out_m)\r\n    with tf.name_scope('resnetblockm_3'):\r\n      out_m = self.ResNet_1.forward(out_m)\r\n    with tf.name_scope('resnetblockm_4'):\r\n      out_m = self.ResNet_3.forward(out_m)  \r\n    with tf.name_scope('resnetblockm_5'):\r\n      out_m = self.ResNet_5.forward(out_m)\r\n    with tf.name_scope('resnetblockm_6'):\r\n      out_m = self.ResNet_7.forward(out_m)\r\n    with tf.name_scope('resnetblockm_7'):\r\n      out_m = self.ResNet_9.forward(out_m)\r\n    with tf.name_scope('resnetblockm_8'):\r\n      out_m = self.ResNet_11.forward(out_m)\r\n    with tf.name_scope('resnetblockm_9'):\r\n      out_m = self.ResNet_13.forward(out_m)\r\n    with tf.name_scope('resnetblockm_10'):\r\n      out_m = self.ResNet_15.forward(out_m)\r\n    with tf.name_scope('resnetblockm_11'):\r\n      out_m = self.ResNet_17.forward(out_m)\r\n    with tf.name_scope('resnetblockm_12'):\r\n      out_m = self.ResNet_19.forward(out_m)\r\n    with tf.name_scope('resnetblockm_13'):\r\n      out_m = self.ResNet_21.forward(out_m)\r\n    with tf.name_scope('brnm_bn1'):\r\n      out_m = GroupNorm(x=out_m, G=32)\r\n\r\n    with tf.name_scope('brn_relu_2'):\r\n      out_m = tf.nn.relu(out_m)\r\n    with tf.name_scope('brn_pool2'):\r\n      out_m = tf.nn.avg_pool(out_m,\r\n                            ksize=[1,out_m.shape[2],out_m.shape[2],1],\r\n                            strides=[1, 1, 1, 1],\r\n                            padding='VALID')\r\n    with tf.name_scope('maumul'):\r\n    \r\n      out = tf.multiply(out_s,out_m)\r\n    with tf.name_scope('fc'):\r\n\r\n      out_shape = out.get_shape().as_list()\r\n      reshape = tf.reshape(\r\n          out,\r\n          [-1, out_shape[1] * out_shape[2] * out_shape[3]])    \r\n      out = tf.add(tf.matmul(reshape, self.fc_weights), self.fc_biases, name=\"logits_\")\r\n\r\n    return out\r\n\r\ndef main(_):\r\n\r\n  def loss_function(weight, logits, labels):\r\n    labels = tf.one_hot(labels,4)\r\n    labels = tf.cast(labels, tf.float32)\r\n    first = tf.reduce_sum(tf.multiply(-labels, logits),1)\r\n    second_0 = tf.add(tf.exp(logits[:,0]),tf.exp(logits[:,1]))\r\n    second_1 = tf.add(tf.exp(logits[:,2]),tf.exp(logits[:,3]))\r\n    log = tf.log(tf.add(second_1,second_0))\r\n    weight = tf.transpose(tf.reduce_sum(tf.multiply(labels, weight),1))\r\n    output = tf.multiply(weight,tf.add(first,log))\r\n\r\n    return output\r\n\r\n  def normalize(stft):\r\n    stft_1 = numpy.empty([stft.shape[0],128,128])\r\n    stft_2 = numpy.empty([stft_1.shape[0],stft_1.shape[1],stft_1.shape[2],1])\r\n    for i in range(stft_1.shape[0]):\r\n      image = Image.fromarray(stft[i,:,:])\r\n      image = image.resize([128,128])\r\n      stft_1[i,:,:] = numpy.array(image)\r\n\r\n      min = numpy.min(stft_1[i,:,:])\r\n      max = numpy.max(stft_1[i,:,:])\r\n      stft_1[i,:,:] = (stft_1[i,:,:]-min)/(max-min)\r\n      stft_2[i,:,:,:] = stft_1[i,:,:].reshape((stft_1.shape[1],stft_1.shape[2],1))\r\n    return stft_2  \r\n\r\n  if FLAGS.self_test:\r\n    \r\n    train_data, train_labels = fake_data(256)\r\n    validation_data, validation_labels = fake_data(EVAL_BATCH_SIZE)\r\n    test_data, test_labels = fake_data(EVAL_BATCH_SIZE)\r\n    num_epochs = 1\r\n  else:\r\n    # Get the data.\r\n    \r\n    stft_training, mfcc_training, labels_training = joblib.load(open(FLAGS.input, mode='rb'))\r\n    stft_test, mfcc_test, labels_test = joblib.load(open(FLAGS.test, mode='rb'))\r\n\r\n    stft_test = numpy.array(stft_test)\r\n    mfcc_test = numpy.array(mfcc_test)\r\n    labels_test = numpy.array(labels_test)\r\n    stft_test = normalize(stft_test)\r\n    mfcc_test = normalize(mfcc_test)\r\n\r\n    stft_training = numpy.array(stft_training)\r\n    mfcc_training = numpy.array(mfcc_training)\r\n    labels_training = numpy.array(labels_training)\r\n    stft_training = normalize(stft_training)\r\n    mfcc_training = normalize(mfcc_training)\r\n\r\n    stft_shape = stft_training.shape\r\n    stft_shape = (None, stft_shape[1], stft_shape[2], 1)\r\n\r\n    mfcc_shape = mfcc_training.shape\r\n    mfcc_shape = (None, mfcc_shape[1], mfcc_shape[2], 1)\r\n\r\n    labels_shape = labels_training.shape\r\n    labels_shape = (None)\r\n\r\n    stft_placeholder = tf.placeholder(stft_training.dtype, stft_shape)\r\n    labels_placeholder = tf.placeholder(labels_training.dtype, labels_shape)\r\n    mfcc_placeholder = tf.placeholder(mfcc_training.dtype, mfcc_shape)\r\n    \r\n    dataset_training = tf.data.Dataset.from_tensor_slices((stft_placeholder, mfcc_placeholder, labels_placeholder))\r\n    dataset_training  = dataset_training.apply(\r\n        tf.data.experimental.shuffle_and_repeat(len(stft_training), None))  \r\n    dataset_training  = dataset_training.batch(BATCH_SIZE)\r\n    dataset_training  = dataset_training.prefetch(1)\r\n    iterator_training = dataset_training.make_initializable_iterator()\r\n    next_element_training = iterator_training.get_next()\r\n    num_epochs = FLAGS.epochs\r\n\r\n  train_size = labels_training.shape[0]\r\n\r\n\r\n  stft_holder = tf.placeholder(\r\n        name=\"stft_holder\",\r\n        dtype=data_type(),\r\n        shape=(None, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS))\r\n  mfcc_holder = tf.placeholder(\r\n        name=\"mfcc_holder\",\r\n        dtype=data_type(),\r\n        shape=(None, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS))\r\n  labels = tf.placeholder(tf.int64, shape=(None,))\r\n\r\n  with tf.name_scope('test_input'):\r\n    stft_t = tf.placeholder(\r\n        data_type(),\r\n        shape=(None, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS))\r\n    mfcc_t = tf.placeholder(\r\n        data_type(),\r\n        shape=(None, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS))\r\n\r\n  model = BRN()\r\n  \r\n  logits = model.forward(stft_holder, mfcc_holder)\r\n  out1 = tf.identity(logits,name=\"out1\")\r\n\r\n  try:\r\n    scalar_summary = tf.scalar_summary\r\n    SummaryWrite = tf.train.SummaryWrite\r\n    merge_summary = tf.merge_summary\r\n  except:\r\n    scalar_summary = tf.summary.scalar\r\n    SummaryWrite = tf.summary.FileWriter\r\n    merge_summary = tf.summary.merge\r\n  with tf.name_scope('loss'):\r\n    weights = [1.0, 1.7, 4.1, 5.7]\r\n    mid = loss_function(weights, logits=logits, labels=labels)\r\n#    mid = tf.nn.sparse_softmax_cross_entropy_with_logits(\r\n#       labels=labels, logits=logits)\r\n\r\n    loss = tf.reduce_sum(mid)\r\n    \r\n    loss_summary = scalar_summary('loss', loss)\r\n\r\n    \r\n    # L2 regularization for the fully connected parameters.\r\n    regularizers = (tf.nn.l2_loss(model.conv1_weights) + tf.nn.l2_loss(model.conv2_weights) +\r\n                    tf.nn.l2_loss(model.fc_weights) + tf.nn.l2_loss(model.fc_biases))\r\n    # Add the regularization term to the loss.\r\n    loss += 0.02 * regularizers\r\n\r\n    batch = tf.Variable(0, dtype=data_type())\r\n  # Use simple momentum for the optimization.\r\n  with tf.name_scope('train'):\r\n\r\n    optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\r\n\r\n  # Predictions for the current training minibatch.\r\n  train_prediction = tf.nn.softmax(logits)\r\n  eval_prediction = tf.nn.softmax(model.forward(stft_t, mfcc_t))\r\n\r\n  # Create a local session to run the training.\r\n  start_time = time.time()\r\n\r\n  def eval_in_batches(stft_data, mfcc_data, sess, type):\r\n    \"\"\"Get all predictions for a dataset by running it in small batches.\"\"\"\r\n    size = stft_data.shape[0]\r\n    if size < EVAL_BATCH_SIZE:\r\n      raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\r\n    predictions = numpy.ndarray(shape=(size, NUM_LABELS), dtype=numpy.float32)\r\n    for begin in xrange(0, size, EVAL_BATCH_SIZE):\r\n      end = begin + EVAL_BATCH_SIZE\r\n      if end <= size:\r\n        if type == 'train':\r\n          predictions[begin:end, :] = sess.run(\r\n              train_prediction,\r\n              feed_dict={stft_holder: stft_data[begin:end, ...], mfcc_holder: mfcc_data[begin:end, ...]})\r\n        else: \r\n          predictions[begin:end, :] = sess.run(\r\n              eval_prediction,\r\n              feed_dict={stft_t: stft_data[begin:end, ...], mfcc_t: mfcc_data[begin:end, ...]})\r\n      else:\r\n        if type == 'train':\r\n          batch_predictions = sess.run(\r\n              train_prediction,\r\n              feed_dict={stft_holder: stft_data[-EVAL_BATCH_SIZE:, ...], mfcc_holder: mfcc_data[-EVAL_BATCH_SIZE:, ...]})\r\n        else:\r\n           batch_predictions = sess.run(\r\n              eval_prediction,\r\n              feed_dict={stft_t: stft_data[-EVAL_BATCH_SIZE:, ...], mfcc_t: mfcc_data[-EVAL_BATCH_SIZE:, ...]})\r\n        predictions[begin:, :] = batch_predictions[begin - size:, :]\r\n    return predictions\r\n\r\n  saver = tf.train.Saver()\r\n  config = tf.ConfigProto()\r\n  config.gpu_options.allow_growth = True  \r\n\r\n  with tf.Session(config=config) as sess:\r\n    # Run all the initializers to prepare the trainable parameters.\r\n    tf.global_variables_initializer().run()\r\n\r\n    merged = tf.summary.merge_all()\r\n    writer = SummaryWrite(FLAGS.logs + 'train', sess.graph)\r\n    print('Initialized!')\r\n    sess.run(iterator_training.initializer, feed_dict={stft_placeholder:stft_training,\r\n                      mfcc_placeholder:mfcc_training,\r\n                      labels_placeholder:labels_training})\r\n\r\n    # Loop through training steps.\r\n    for step in xrange(int(num_epochs * train_size) // BATCH_SIZE):\r\n\r\n      batch_stft, batch_mfcc, batch_labels = sess.run(next_element_training)\r\n  \r\n      feed_dict = {stft_holder: batch_stft,\r\n                   mfcc_holder: batch_mfcc,\r\n                   labels: batch_labels}\r\n      # Run the optimizer to update weights.\r\n\r\n      sess.run(optimizer, feed_dict=feed_dict)\r\n      # print some extra information once reach the evaluation frequency\r\n      if step % EVAL_FREQUENCY == 0:\r\n        # fetch some extra nodes' data\r\n        summary, l = sess.run([merged, loss],\r\n                                      feed_dict=feed_dict)\r\n        writer.add_summary(summary, step)\r\n        elapsed_time = time.time() - start_time\r\n        start_time = time.time()\r\n        rate, acc = error_rate(eval_in_batches(stft_training, mfcc_training, sess, 'train'), labels_training)\r\n        acc_summary = scalar_summary('accuracy', acc)\r\n        print('Step %d (epoch %.2f), Minibatch loss: %.3f, Minibatch error: %.1f%%, Accuracy:%.4f' %\r\n              (step, float(step) * BATCH_SIZE / train_size,\r\n              l,rate, acc))\r\n\r\n        \r\n    # Finally print the result!\r\n        sys.stdout.flush()\r\n        test_error, test_acc = error_rate(eval_in_batches(stft_test, mfcc_test, sess, 'test'), labels_test)\r\n        print('Testset error: %.1f%%, Accuracy:%.4f' % (test_error, test_acc))\r\n\r\n    \r\n    saver.save(sess, './local_ckpt3')        \r\n    writer.close()\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n#  dev = '/gpu:0'\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '--use_fp16',\r\n      default=False,\r\n      help='Use half floats instead of full floats if True.',\r\n      action='store_true')\r\n  parser.add_argument(\r\n      '--self_test',\r\n      default=False,\r\n      action='store_true',\r\n      help='True if running a self test.')\r\n  parser.add_argument(\r\n      '--input',\r\n      default='wavelet_stft.p')\r\n  parser.add_argument(\r\n      '--test',\r\n      default='wavelet_stft_test.p')  \r\n  parser.add_argument(\r\n      '--epochs',\r\n      type=float,\r\n      default=0.2)  \r\n  parser.add_argument(\r\n      '--logs',\r\n      default='')  \r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  tf.enable_resource_variables()\r\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n\r\n```\r\n\r\nand the code for restore model:\r\n```\r\ndef main(_):\r\n\r\n  config = tf.ConfigProto()\r\n  config.gpu_options.allow_growth = True  \r\n  with tf.Session(config=config) as sess:\r\n    # Run all the initializers to prepare the trainable parameters.\r\n    tf.global_variables_initializer().run()\r\n    saver = tf.train.import_meta_graph('./local_ckpt3.meta', clear_devices=True)\r\n    saver.restore(sess, './local_ckpt3')\r\n    graph = tf.get_default_graph()\r\n    w1 = graph.get_tensor_by_name(\"stft_holder:0\")\r\n    w2 = graph.get_tensor_by_name(\"mfcc_holder:0\")\r\n    input_shape = (2,128,128,1)\r\n    input_data = numpy.array(numpy.random.random_sample(input_shape), dtype=numpy.float32)\r\n    input_data2 = numpy.array(numpy.random.random_sample(input_shape), dtype=numpy.float32)\r\n    # Loop through training steps.\r\n  \r\n    feed_dict = {w1: input_data,\r\n                w2: input_data2}\r\n      # Run the optimizer to update weights.\r\n    op_to_restore = graph.get_tensor_by_name(\"out1:0\")\r\n    result = sess.run(op_to_restore, feed_dict=feed_dict)\r\n    print(result)\r\n```\r\nI can't find the reason of this question, then I check the ckpt file, and I find it seems that the model get the output though return the tensor stored in the ckpt file instead of running again in second code. I cannot figure out how to correct it ,thanks for your help anyway\r\n\r\n\r\n", "comments": ["@mmmmayi \r\n\r\nI tried to reproduce the issue and i am getting the below error.`FileNotFoundError: [Errno 2] No such file or directory: 'wavelet_stft.p'`.\r\nAlso, request you to provide a simple standalone code (the current code is too long and requires lot of efforts to resolve). If you provide simple standalone code, then it is easy for localizing the issue faster. Thanks !", "> @mmmmayi\r\n> \r\n> I tried to reproduce the issue and i am getting the below error.`FileNotFoundError: [Errno 2] No such file or directory: 'wavelet_stft.p'`.\r\n> Also, request you to provide a simple standalone code (the current code is too long and requires lot of efforts to resolve). If you provide simple standalone code, then it is easy for localizing the issue faster. Thanks !\r\n\r\nHere are the wavelet_stft.p and wavelet_stft_test.p: https://drive.google.com/open?id=1DfV7WPJymj66jJ13ds6javg3GSLPhwyr\r\n\r\nAlso, I am soooo sorry that I'm afraid I can't provide a more simple one because I don't know which is the key code that leads to this problem, if I delete some codes of them, maybe it won't reproduce the problem. But I try to build the simpler model here:\r\n\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport gzip\r\nimport os\r\nimport sys\r\nimport time\r\nimport joblib\r\nimport math\r\nimport numpy\r\nfrom six.moves import urllib\r\nfrom six.moves import xrange  \r\nfrom PIL import Image\r\nfrom sklearn.metrics import confusion_matrix as sk_confusion_matrix\r\nfrom sklearn.metrics import classification_report\r\nimport tensorflow as tf\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\r\nFLAGS = None\r\nIMAGE_HEIGHT = 128\r\nIMAGE_WEITH = 128\r\nNUM_CHANNELS = 1\r\nNUM_LABELS = 4\r\nSEED = 66478  # Set to None for random seed.\r\nBATCH_SIZE = 32\r\nEVAL_BATCH_SIZE = 32\r\nEVAL_FREQUENCY = 10  # Number of steps between evaluations.\r\n\r\ndef data_type():\r\n  \"\"\"Return the type of the activations, weights, and placeholder variables.\"\"\"\r\n  if FLAGS.use_fp16:\r\n    return tf.float16\r\n  else:\r\n    return tf.float32\r\n\r\n\r\ndef fake_data(num_images):\r\n  \"\"\"Generate a fake dataset that matches the dimensions of MNIST.\"\"\"\r\n  data = numpy.ndarray(\r\n      shape=(num_images, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS),\r\n      dtype=numpy.float32)\r\n  labels = numpy.zeros(shape=(num_images,), dtype=numpy.int64)\r\n  for image in xrange(num_images):\r\n    label = image % 2\r\n    data[image, :, :, 0] = label - 0.5\r\n    labels[image] = label\r\n  return data, labels\r\n\r\n\r\ndef error_rate(predictions, labels):\r\n  Confusion_matrix=sk_confusion_matrix(numpy.argmax(predictions, 1).tolist(), labels.tolist())\r\n  print('Confusion_matrix:')\r\n  print(Confusion_matrix)  \r\n\r\n  Se1 = Confusion_matrix[1,1]+Confusion_matrix[2,2]+Confusion_matrix[3,3]\r\n  Se2 = Confusion_matrix[1,1]+Confusion_matrix[1,0]+Confusion_matrix[1,2]+Confusion_matrix[1,3]+Confusion_matrix[2,2]+Confusion_matrix[2,0]+Confusion_matrix[2,1]+Confusion_matrix[2,3]+Confusion_matrix[3,3]+Confusion_matrix[3,0]+Confusion_matrix[3,1]+Confusion_matrix[3,2]\r\n  Se = Se1/Se2\r\n  Sp = Confusion_matrix[0,0]/(Confusion_matrix[0,0]+Confusion_matrix[0,1]+Confusion_matrix[0,2]+Confusion_matrix[0,3]) \r\n  Acc = (Se+Sp)*100/2\r\n\r\n  target_names = ['class 0', 'class 1', 'class 2', 'class 3']\r\n\r\n  print()\r\n  accuracy = 100.0-(100.0 *numpy.sum(numpy.argmax(predictions, 1) == labels)/predictions.shape[0])\r\n  \r\n  \"\"\"Return the error rate based on dense predictions and sparse labels.\"\"\"\r\n  return 100.0 - (\r\n      100.0 *\r\n      numpy.sum(numpy.argmax(predictions, 1) == labels) /\r\n      predictions.shape[0]), Acc\r\n\r\ndef GroupNorm(x, G, eps=1e-05):\r\n    # x: input features with shape [N,H,W,C]\r\n    # gamma, beta: scale and offset, with shape [1,C,1,1]\r\n    # G: number of groups for GN\r\n  N, H, W, C = x.shape\r\n # N = BATCH_SIZE\r\n  gamma = tf.ones([1, 1, 1, C])\r\n  beta = tf.zeros([1, 1, 1, C])\r\n#  x = tf.reshape(x, [-1, G, H, W, C // G])\r\n\r\n  mean = tf.reduce_max(x, axis=[1,2,3], keep_dims=True)\r\n\r\n  var = tf.subtract(x,mean)\r\n  var = var*var\r\n  var = tf.reduce_max(x, axis=[1,2,3], keep_dims=True)\r\n \r\n  x1 = tf.subtract(x,mean) / tf.sqrt(var + eps)\r\n#  x2 = tf.reshape(x1, [-1, H, W, C])\r\n  return x1 * gamma + beta\r\n\r\nclass ResBlock(object):\r\n\r\n  def __init__(self, stride_num=1, downsample=False):\r\n    self.conv1_weights = tf.Variable(\r\n      tf.truncated_normal([1, 1, 64, 64],  # 1x1 filter, depth 64.\r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))  \r\n\r\n    self.conv2_weights = tf.Variable(\r\n      tf.truncated_normal([3, 3, 64, 64],  # 3x3 filter, depth 64.\r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))\r\n    self.conv3_weights = tf.Variable(\r\n      tf.truncated_normal([3, 3, 64, 64],  # 3x3 filter, depth 64.\r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))  \r\n    self.stride_num = stride_num\r\n    self.downsample = downsample\r\n\r\n  def forward(self, data):\r\n    with tf.name_scope('ResNet'):\r\n    # shortcut = x\r\n      shortcut = data\r\n      # out = self.relu(self.norm1(x))\r\n#      axis = list(range(len(data.get_shape()) - 1))\r\n      with tf.name_scope('BN1'):\r\n        out = GroupNorm(x=data, G=32)\r\n        #mean, variance = tf.nn.moments(data, axis)\r\n        #out = tf.nn.batch_normalization(data, mean, variance, 0, 1, 0.001)\r\n      with tf.name_scope('relu1'):\r\n        out = tf.nn.relu(out)\r\n      #  if self.downsample is not None:\r\n        #   shortcut = self.downsample(out)\r\n      with tf.name_scope('downsample'):\r\n        if self.downsample is True:\r\n          shortcut = tf.nn.conv2d(out,\r\n                                  self.conv1_weights,\r\n                                  strides=[1, self.stride_num, self.stride_num, 1],\r\n                                  padding='SAME')\r\n        #  out = self.conv1(out)\r\n      with tf.name_scope('conv1'):\r\n        out = tf.nn.conv2d(out,\r\n                          self.conv2_weights,\r\n                          strides=[1, self.stride_num, self.stride_num, 1],\r\n                          padding='SAME')\r\n      #  out = self.droupout(out)\r\n      #  out = self.norm2(out)\r\n      with tf.name_scope('BN2'):\r\n        out = GroupNorm(x=out, G=32)\r\n\r\n      #  out = self.relu(out) \r\n      with tf.name_scope('relu2'):\r\n        out = tf.nn.relu(out)   \r\n      #  out = self.conv2(out)\r\n      with tf.name_scope('conv2'):\r\n        out = tf.nn.conv2d(out,\r\n                          self.conv3_weights,\r\n                          strides=[1, 1, 1, 1],\r\n                          padding='SAME')\r\n    return shortcut+out\r\n\r\nclass BRN(object):\r\n\r\n  def __init__(self):\r\n    self.ResNet_0_0 = ResBlock(2, True)\r\n    self.ResNet_0_1 = ResBlock(2, True)\r\n    self.ResNet_1_0 = ResBlock(2, True)\r\n    self.ResNet_1_1 = ResBlock(2, True)\r\n    self.ResNet_0 = ResBlock(1, False)\r\n    self.ResNet_1 = ResBlock(1, False)\r\n \r\n    self.conv1_weights = tf.Variable(\r\n      tf.truncated_normal([3, 3, NUM_CHANNELS, 64],  \r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))  \r\n    self.conv2_weights = tf.Variable(\r\n      tf.truncated_normal([3, 3, NUM_CHANNELS, 64],  \r\n                          stddev=0.1,\r\n                          seed=SEED, dtype=data_type()))  \r\n    self.fc_weights = tf.Variable(tf.truncated_normal([64, NUM_LABELS],\r\n                                                stddev=0.1,\r\n                                                seed=SEED,\r\n                                                dtype=data_type()))\r\n\r\n    self.fc_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS], dtype=data_type()))\r\n\r\n  def forward(self, stft, mfcc):\r\n\r\n    with tf.name_scope('BRNcon1'):\r\n      out_s = tf.nn.conv2d(stft,\r\n                        self.conv1_weights,\r\n                        strides= [1, 1, 1, 1],\r\n                        padding='VALID')\r\n    with tf.name_scope('resnetblocks_1'):\r\n      out_s = self.ResNet_0_0.forward(out_s)\r\n    with tf.name_scope('resnetblocks_2'):\r\n      out_s = self.ResNet_0_1.forward(out_s)\r\n    with tf.name_scope('resnetblocks_3'):\r\n      out_s = self.ResNet_0.forward(out_s)\r\n    \r\n    with tf.name_scope('brns_bn1'):\r\n      out_s = GroupNorm(x=out_s, G=32)\r\n\r\n    with tf.name_scope('brn_relu_1'):\r\n      out_s = tf.nn.relu(out_s)\r\n    with tf.name_scope('brn_pool1'):\r\n      out_s = tf.nn.avg_pool(out_s,\r\n                            ksize=[1,out_s.shape[2],out_s.shape[2],1],\r\n                            strides=[1, 1, 1, 1],\r\n                            padding='VALID')\r\n\r\n    with tf.name_scope('BRNcon2'):\r\n      out_m = tf.nn.conv2d(mfcc,\r\n                        self.conv2_weights,\r\n                        strides= [1, 1, 1, 1],\r\n                        padding='VALID')\r\n    with tf.name_scope('resnetblockm_1'):\r\n      out_m = self.ResNet_1_0.forward(out_m)\r\n    with tf.name_scope('resnetblockm_2'):\r\n      out_m = self.ResNet_1_1.forward(out_m)\r\n    with tf.name_scope('resnetblockm_3'):\r\n      out_m = self.ResNet_1.forward(out_m)\r\n\r\n    with tf.name_scope('brnm_bn1'):\r\n      out_m = GroupNorm(x=out_m, G=32)\r\n\r\n    with tf.name_scope('brn_relu_2'):\r\n      out_m = tf.nn.relu(out_m)\r\n    with tf.name_scope('brn_pool2'):\r\n      out_m = tf.nn.avg_pool(out_m,\r\n                            ksize=[1,out_m.shape[2],out_m.shape[2],1],\r\n                            strides=[1, 1, 1, 1],\r\n                            padding='VALID')\r\n    with tf.name_scope('maumul'):\r\n    \r\n      out = tf.multiply(out_s,out_m)\r\n    with tf.name_scope('fc'):\r\n\r\n      out_shape = out.get_shape().as_list()\r\n      reshape = tf.reshape(\r\n          out,\r\n          [-1, out_shape[1] * out_shape[2] * out_shape[3]])    \r\n      out = tf.add(tf.matmul(reshape, self.fc_weights), self.fc_biases, name=\"logits_\")\r\n\r\n    return out\r\n\r\ndef main(_):\r\n\r\n  def loss_function(weight, logits, labels):\r\n    labels = tf.one_hot(labels,4)\r\n    labels = tf.cast(labels, tf.float32)\r\n    first = tf.reduce_sum(tf.multiply(-labels, logits),1)\r\n    second_0 = tf.add(tf.exp(logits[:,0]),tf.exp(logits[:,1]))\r\n    second_1 = tf.add(tf.exp(logits[:,2]),tf.exp(logits[:,3]))\r\n    log = tf.log(tf.add(second_1,second_0))\r\n    weight = tf.transpose(tf.reduce_sum(tf.multiply(labels, weight),1))\r\n    output = tf.multiply(weight,tf.add(first,log))\r\n\r\n    return output\r\n\r\n  def normalize(stft):\r\n    stft_1 = numpy.empty([stft.shape[0],128,128])\r\n    stft_2 = numpy.empty([stft_1.shape[0],stft_1.shape[1],stft_1.shape[2],1])\r\n    for i in range(stft_1.shape[0]):\r\n      image = Image.fromarray(stft[i,:,:])\r\n      image = image.resize([128,128])\r\n      stft_1[i,:,:] = numpy.array(image)\r\n\r\n      min = numpy.min(stft_1[i,:,:])\r\n      max = numpy.max(stft_1[i,:,:])\r\n      stft_1[i,:,:] = (stft_1[i,:,:]-min)/(max-min)\r\n      stft_2[i,:,:,:] = stft_1[i,:,:].reshape((stft_1.shape[1],stft_1.shape[2],1))\r\n    return stft_2  \r\n\r\n  if FLAGS.self_test:\r\n    \r\n    train_data, train_labels = fake_data(256)\r\n    validation_data, validation_labels = fake_data(EVAL_BATCH_SIZE)\r\n    test_data, test_labels = fake_data(EVAL_BATCH_SIZE)\r\n    num_epochs = 1\r\n  else:\r\n    # Get the data.\r\n    \r\n    stft_training, mfcc_training, labels_training = joblib.load(open(FLAGS.input, mode='rb'))\r\n    stft_test, mfcc_test, labels_test = joblib.load(open(FLAGS.test, mode='rb'))\r\n\r\n    stft_test = numpy.array(stft_test)\r\n    mfcc_test = numpy.array(mfcc_test)\r\n    labels_test = numpy.array(labels_test)\r\n    stft_test = normalize(stft_test)\r\n    mfcc_test = normalize(mfcc_test)\r\n\r\n    stft_training = numpy.array(stft_training)\r\n    mfcc_training = numpy.array(mfcc_training)\r\n    labels_training = numpy.array(labels_training)\r\n    stft_training = normalize(stft_training)\r\n    mfcc_training = normalize(mfcc_training)\r\n\r\n    stft_shape = stft_training.shape\r\n    stft_shape = (None, stft_shape[1], stft_shape[2], 1)\r\n\r\n    mfcc_shape = mfcc_training.shape\r\n    mfcc_shape = (None, mfcc_shape[1], mfcc_shape[2], 1)\r\n\r\n    labels_shape = labels_training.shape\r\n    labels_shape = (None)\r\n\r\n    stft_placeholder = tf.placeholder(stft_training.dtype, stft_shape)\r\n    labels_placeholder = tf.placeholder(labels_training.dtype, labels_shape)\r\n    mfcc_placeholder = tf.placeholder(mfcc_training.dtype, mfcc_shape)\r\n    \r\n    dataset_training = tf.data.Dataset.from_tensor_slices((stft_placeholder, mfcc_placeholder, labels_placeholder))\r\n    dataset_training  = dataset_training.apply(\r\n        tf.data.experimental.shuffle_and_repeat(len(stft_training), None))  \r\n    dataset_training  = dataset_training.batch(BATCH_SIZE)\r\n    dataset_training  = dataset_training.prefetch(1)\r\n    iterator_training = dataset_training.make_initializable_iterator()\r\n    next_element_training = iterator_training.get_next()\r\n    num_epochs = FLAGS.epochs\r\n\r\n  train_size = labels_training.shape[0]\r\n\r\n\r\n  stft_holder = tf.placeholder(\r\n        name=\"stft_holder\",\r\n        dtype=data_type(),\r\n        shape=(None, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS))\r\n  mfcc_holder = tf.placeholder(\r\n        name=\"mfcc_holder\",\r\n        dtype=data_type(),\r\n        shape=(None, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS))\r\n  labels = tf.placeholder(tf.int64, shape=(None,))\r\n\r\n  with tf.name_scope('test_input'):\r\n    stft_t = tf.placeholder(\r\n        data_type(),\r\n        shape=(None, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS))\r\n    mfcc_t = tf.placeholder(\r\n        data_type(),\r\n        shape=(None, IMAGE_HEIGHT, IMAGE_WEITH, NUM_CHANNELS))\r\n\r\n  model = BRN()\r\n  \r\n  logits = model.forward(stft_holder, mfcc_holder)\r\n  out1 = tf.identity(logits,name=\"out1\")\r\n\r\n  try:\r\n    scalar_summary = tf.scalar_summary\r\n    SummaryWrite = tf.train.SummaryWrite\r\n    merge_summary = tf.merge_summary\r\n  except:\r\n    scalar_summary = tf.summary.scalar\r\n    SummaryWrite = tf.summary.FileWriter\r\n    merge_summary = tf.summary.merge\r\n  with tf.name_scope('loss'):\r\n    weights = [1.0, 1.7, 4.1, 5.7]\r\n    mid = loss_function(weights, logits=logits, labels=labels)\r\n#    mid = tf.nn.sparse_softmax_cross_entropy_with_logits(\r\n#       labels=labels, logits=logits)\r\n\r\n    loss = tf.reduce_sum(mid)\r\n    \r\n    loss_summary = scalar_summary('loss', loss)\r\n\r\n    \r\n    # L2 regularization for the fully connected parameters.\r\n    regularizers = (tf.nn.l2_loss(model.conv1_weights) + tf.nn.l2_loss(model.conv2_weights) +\r\n                    tf.nn.l2_loss(model.fc_weights) + tf.nn.l2_loss(model.fc_biases))\r\n    # Add the regularization term to the loss.\r\n    loss += 0.02 * regularizers\r\n\r\n    batch = tf.Variable(0, dtype=data_type())\r\n  # Use simple momentum for the optimization.\r\n  with tf.name_scope('train'):\r\n\r\n    optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\r\n\r\n  # Predictions for the current training minibatch.\r\n  train_prediction = tf.nn.softmax(logits)\r\n  eval_prediction = tf.nn.softmax(model.forward(stft_t, mfcc_t))\r\n\r\n  # Create a local session to run the training.\r\n  start_time = time.time()\r\n\r\n  def eval_in_batches(stft_data, mfcc_data, sess, type):\r\n    \"\"\"Get all predictions for a dataset by running it in small batches.\"\"\"\r\n    size = stft_data.shape[0]\r\n    if size < EVAL_BATCH_SIZE:\r\n      raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\r\n    predictions = numpy.ndarray(shape=(size, NUM_LABELS), dtype=numpy.float32)\r\n    for begin in xrange(0, size, EVAL_BATCH_SIZE):\r\n      end = begin + EVAL_BATCH_SIZE\r\n      if end <= size:\r\n        if type == 'train':\r\n          predictions[begin:end, :] = sess.run(\r\n              train_prediction,\r\n              feed_dict={stft_holder: stft_data[begin:end, ...], mfcc_holder: mfcc_data[begin:end, ...]})\r\n        else: \r\n          predictions[begin:end, :] = sess.run(\r\n              eval_prediction,\r\n              feed_dict={stft_t: stft_data[begin:end, ...], mfcc_t: mfcc_data[begin:end, ...]})\r\n      else:\r\n        if type == 'train':\r\n          batch_predictions = sess.run(\r\n              train_prediction,\r\n              feed_dict={stft_holder: stft_data[-EVAL_BATCH_SIZE:, ...], mfcc_holder: mfcc_data[-EVAL_BATCH_SIZE:, ...]})\r\n        else:\r\n           batch_predictions = sess.run(\r\n              eval_prediction,\r\n              feed_dict={stft_t: stft_data[-EVAL_BATCH_SIZE:, ...], mfcc_t: mfcc_data[-EVAL_BATCH_SIZE:, ...]})\r\n        predictions[begin:, :] = batch_predictions[begin - size:, :]\r\n    return predictions\r\n\r\n  saver = tf.train.Saver()\r\n  config = tf.ConfigProto()\r\n  config.gpu_options.allow_growth = True  \r\n\r\n  with tf.Session(config=config) as sess:\r\n    # Run all the initializers to prepare the trainable parameters.\r\n    tf.global_variables_initializer().run()\r\n\r\n    merged = tf.summary.merge_all()\r\n    writer = SummaryWrite(FLAGS.logs + 'train', sess.graph)\r\n    print('Initialized!')\r\n    sess.run(iterator_training.initializer, feed_dict={stft_placeholder:stft_training,\r\n                      mfcc_placeholder:mfcc_training,\r\n                      labels_placeholder:labels_training})\r\n\r\n    # Loop through training steps.\r\n    for step in xrange(int(num_epochs * train_size) // BATCH_SIZE):\r\n\r\n      batch_stft, batch_mfcc, batch_labels = sess.run(next_element_training)\r\n  \r\n      feed_dict = {stft_holder: batch_stft,\r\n                   mfcc_holder: batch_mfcc,\r\n                   labels: batch_labels}\r\n      # Run the optimizer to update weights.\r\n\r\n      sess.run(optimizer, feed_dict=feed_dict)\r\n      # print some extra information once reach the evaluation frequency\r\n      if step % EVAL_FREQUENCY == 0:\r\n        # fetch some extra nodes' data\r\n        summary, l = sess.run([merged, loss],\r\n                                      feed_dict=feed_dict)\r\n        writer.add_summary(summary, step)\r\n        elapsed_time = time.time() - start_time\r\n        start_time = time.time()\r\n        rate, acc = error_rate(eval_in_batches(stft_training, mfcc_training, sess, 'train'), labels_training)\r\n        acc_summary = scalar_summary('accuracy', acc)\r\n        print('Step %d (epoch %.2f), Minibatch loss: %.3f, Minibatch error: %.1f%%, Accuracy:%.4f' %\r\n              (step, float(step) * BATCH_SIZE / train_size,\r\n              l,rate, acc))\r\n\r\n        \r\n    # Finally print the result!\r\n        sys.stdout.flush()\r\n        test_error, test_acc = error_rate(eval_in_batches(stft_test, mfcc_test, sess, 'test'), labels_test)\r\n        print('Testset error: %.1f%%, Accuracy:%.4f' % (test_error, test_acc))\r\n\r\n    saver.save(sess, './local_ckpt3')        \r\n    writer.close()\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n#  dev = '/gpu:0'\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '--use_fp16',\r\n      default=False,\r\n      help='Use half floats instead of full floats if True.',\r\n      action='store_true')\r\n  parser.add_argument(\r\n      '--self_test',\r\n      default=False,\r\n      action='store_true',\r\n      help='True if running a self test.')\r\n  parser.add_argument(\r\n      '--input',\r\n      default='wavelet_stft.p')\r\n  parser.add_argument(\r\n      '--test',\r\n      default='wavelet_stft_test.p')  \r\n  parser.add_argument(\r\n      '--epochs',\r\n      type=float,\r\n      default=0.2)  \r\n  parser.add_argument(\r\n      '--logs',\r\n      default='')  \r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  tf.enable_resource_variables()\r\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n```", "@mmmmayi \r\nI tried executing your code in colab using TF version 1.15.0-rc1 . Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/df598e9d0a2defda70efd3c2e20f0d51/untitled242.ipynb#scrollTo=uHZ6RXaJkNnC). Is this the expected behavior?. Thanks!\r\n", "@mmmmayi \r\n\r\nPlease, let us know if the issue still persists. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 32899, "title": "Model training does not improve accuracy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.0.0-rc2\r\n- Python version: 3.7.3\r\n- CUDA/cuDNN version: release 10.0, V10.0.130\r\n- GPU model and memory: nVidia GTX 1080 Ti\r\n\r\n**Describe the current behavior**\r\nWhen attempting to train a sequential model on the MNIST dataset, the model remains at 11% accuracy.  This is only resolved when the inputs are scaled by 255.\r\n\r\n**Describe the expected behavior**\r\nThe model should improve in accuracy.\r\n\r\n**Code to reproduce the issue**\r\nhttps://github.com/PacktPublishing/What-s-New-in-TensorFlow-2.0/blob/master/Chapter02/end_to_end_sequential.py\r\n\r\n**Other info / logs**\r\nPlease reference the issue at https://github.com/PacktPublishing/What-s-New-in-TensorFlow-2.0/issues/1 for more information.  This behavior was not observed in 2.0.0-beta0\r\n", "comments": ["I have tried on colab with TF version 2.0 beta 1, 2.0.0-rc2 and was able to reproduce the issue. Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/2d329adc843eeca37e3c219e74515b9b/untitled233.ipynb) Thanks!", "The same Model / with inputs in range [0,255] on Pytorch gives the similar accuracy of around 11%. So I don't suppose its a tf issue.\r\nAlso, 2.0.0rc output is consistent with tf 1.14.0.\r\n\r\nAnyway, using Adam optimizer or SGD with momentum boosts up the accuracy on both tf and PyTorch.\r\n", "@ChosunOne I agree with @sghoshjr. If you change the learning rate from default `0.01` to `0.0005` gives you ~60% training accuracy. So you need to change\r\n\r\n```\r\nmodel.compile(loss=keras.losses.categorical_crossentropy,\r\n              optimizer=keras.optimizers.SGD(learning_rate=0.0005),\r\n              metrics=['accuracy'])\r\n```\r\n\r\nIn general, it is always suggested to normalize the inputs data so that you have faster convergence. Even without normalizing input data, you can still get better performance by tuning some hyper parameters. Please check very similar code on TF [website](https://colab.sandbox.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/r2/tutorials/quickstart/beginner.ipynb). If you want better performance, then change learning rate, optimization, normalize data etc.\r\n\r\nI am closing the issue as it is resolved. But, please let me know if I'm mistaken.Thanks!\r\n\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32899\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32899\">No</a>\n"]}, {"number": 32898, "title": "tf.lite not support Merge, RandomUniform, Switch", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 1.14.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n2019-09-29 11:27:27.677102: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4963 operators, 8473 arrays (0 quantized)\r\n2019-09-29 11:27:28.107098: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 4959 operators, 8467 arrays (0 quantized)\r\n2019-09-29 11:27:28.858936: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 4959 operators, 8467 arrays (0 quantized)\r\n2019-09-29 11:27:29.762413: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 4823 operators, 8044 arrays (0 quantized)\r\n2019-09-29 11:27:30.695850: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 4823 operators, 8044 arrays (0 quantized)\r\n2019-09-29 11:27:31.376652: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 4823 operators, 8044 arrays (0 quantized)\r\n2019-09-29 11:27:31.590536: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 19328 bytes, theoretical optimal value: 2048 bytes.\r\n2019-09-29 11:27:31.918181: E tensorflow/lite/toco/toco_tooling.cc:456] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, FLOOR, FULLY_CONNECTED, GATHER, GREATER_EQUAL, LOGISTIC, MUL, PACK, REDUCE_PROD, RESHAPE, SELECT, SHAPE, SLICE, STRIDED_SLICE, SUM, TILE, UNIQUE, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: Merge, RandomUniform, Switch.\r\nTraceback (most recent call last):\r\n  File \"/home/user/.local/bin/toco_from_protos\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33, in execute\r\n    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, FLOOR, FULLY_CONNECTED, GATHER, GREATER_EQUAL, LOGISTIC, MUL, PACK, REDUCE_PROD, RESHAPE, SELECT, SHAPE, SLICE, STRIDED_SLICE, SUM, TILE, UNIQUE, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: Merge, RandomUniform, Switch.\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```python\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\r\n    model_path, input_arrays=input_arrays, output_arrays=output_arrays)\r\nconverter.post_training_quantize=True\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_quantized_model = converter.convert()\r\nopen(\"quantized_model.tflite\", \"wb\").write(tflite_quantized_model)\r\n```\r\n", "comments": ["Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32898\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32898\">No</a>\n"]}, {"number": 32897, "title": "TF2: tfp.distributions.Normal in tf.keras.Model issue", "body": "I just found that if I returned a distribution in `call` not a tensor and called `self(tf.keras.Input())` in `__init__`, it would throw an exception `'Normal' object has no attribute 'shape'`\r\n```python\r\nclass MyModel(tf.keras.Model):\r\n    def __init__(self):\r\n        super(MyModel, self).__init__()\r\n\r\n        self.l = tf.keras.layers.Dense(2)\r\n        self(tf.keras.Input(shape=(3,)))\r\n\r\n    def call(self, inputs):\r\n        x = self.l(inputs)\r\n\r\n        policy = tfp.distributions.Normal(loc=x, scale=x)\r\n        return policy\r\n\r\n\r\nmodel = MyModel()\r\n```", "comments": ["Tried given code forTF-1.15rc1 and 2.0rc2 i was able to replicate the error. Kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/ccc142acb65fd5d7f519c2deea5b7893/32897.ipynb) of colab.Thanks!", "@BlueFisher This is more related to `tfb` repository. Can you open the issue [here](https://github.com/tensorflow/probability/issues) and then close this issue. Thanks!", "> @BlueFisher This is more related to `tfb` repository. Can you open the issue [here](https://github.com/tensorflow/probability/issues) and then close this issue. Thanks!\r\n\r\nThanks for reminding", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32897\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32897\">No</a>\n"]}, {"number": 32896, "title": "How to get cublas handle to run cublas function?", "body": "I write a custom op using cublas function `cublasCgetrfBatched` and `cublasCgetriBatched`, the functions use cublas handle as a input param, however the `cublasCreate(&handle);` cost nearly 100ms. \r\nI think the TF has already integrate CUBLAS module, `cublasCreate(&handle)` muse have been invoked in the init process, then how to get the handle? An example may be the best!", "comments": ["This question is more specific to GPU accelerated library than TF.\r\nPerhaps you may find this [page useful](https://developer.nvidia.com/cublas) .\r\nAlso see [cublas examples](https://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf).\r\nThanks!", "@ymodak Thanks! But my question is how the get the cublas handle from TF, I know the the usage of `cublas` and have run the custom op using cublas already, but the `handle` need be created with `cublasCreate(&handle)`, if run the op multi-times, then the handle is created multi-times, that's unreasonable. However I can't save the handle in an op and reuse it, as it is a global variable.\r\nIt seems that TF using steam_executor to wrap gpu device, maybe cublas handle has already created in the TF init process, and may get it from some TF C++ API.", "As of today cublas handle is for Tensorflow internal use only. It's not exposed to the public C++ API. See `tensorflow/stream_executor/cuda/cuda_blas.h` that no getters are there for getting the handle `blas_`.\r\n\r\nI don't know much about TF custom ops, but I'd expect somewhere in the executor to have a place for users to keep a handle there.", "@timshen91 Very useful info! Is there any sample code that use stream executor to do BLAS ops with cuBLAS. If I modify the src code to export a getter of `blas_` and use it in some custom op, will it affect releasing resource?", "@7oud For your own debugging and understanding, it's probably fine to add a getter for blas_.\r\n\r\nFor a real solution, I suggest you to:\r\n* Find a way to transport arbitrary data from your application to the execution of your custom op\r\n* Create your permanent BLAS handle before executing the graph, and expose it to the custom op executor\r\n* In the custom op executor, use the permanent BLAS handle you created.\r\n\r\nUnfortunately I don't know TF enough to tell you where those places are in code.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32896\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32896\">No</a>\n"]}, {"number": 32895, "title": "Decorated the call methods of tf.keras.Model subclass with @tf.function or not , result is very different", "body": "System information\r\n\r\nOS Platform and Distribution\r\nMac os (10.14.6)\r\nTensorFlow installed from (source or binary):\r\nbinary\r\nTensorFlow version (use command below):\r\n2.0.0rc1\r\nPython version:\r\nPython 3.6.4\r\nI implement a  model with tensorflow keras just copy [official tutorials](https://www.tensorflow.org/tutorials/quickstart/advanced). The code is shown below\r\n\r\n```\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\r\nfrom tensorflow.keras import Model\r\nimport tensorflow as tf\r\nimport time\r\nmnist = tf.keras.datasets.mnist\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train, x_test\r\ny_train, y_test = y_train , y_test\r\nx_train = x_train[..., tf.newaxis].astype(np.float64)\r\nx_test = x_test[..., tf.newaxis].astype(np.float64)\r\ntrain_ds = tf.data.Dataset.from_tensor_slices(\r\n(x_train, y_train)).shuffle(1000).batch(256)\r\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(256)\r\n\r\nclass MyModel(Model):\r\n    def __init__(self, *args, **kwargs):\r\n        super(MyModel, self).__init__(args, kwargs)\r\n        self.conv1 = Conv2D(32, 3, activation='relu')\r\n        self.flatten = Flatten()\r\n        self.d1 = Dense(128, activation='relu')\r\n        self.d2 = Dense(10, activation='softmax')\r\n        \r\n    def call(self, x):\r\n        x = self.conv1(x)\r\n        x = self.flatten(x)\r\n        x = self.d1(x)\r\n        return self.d2(x)\r\nmodel = MyModel()\r\nmodel.build((512, 28, 28, 1))\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\r\noptimizer = tf.keras.optimizers.Adam()\r\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\r\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\r\n\r\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\r\ntest_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\r\n@tf.function\r\ndef train_step(images, labels):\r\n    with tf.GradientTape() as tape:\r\n        predictions = model(images)\r\n        loss = loss_object(labels, predictions)\r\n    gradients = tape.gradient(loss, model.trainable_variables)\r\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\n    train_loss(loss)\r\n    train_accuracy(labels, predictions)\r\n@tf.function\r\ndef test_step(images, labels):\r\n    predictions = model(images)\r\n    t_loss = loss_object(labels, predictions)\r\n\r\n    test_loss(t_loss)\r\n    test_accuracy(labels, predictions)\r\n\r\nEPOCHS = 100\r\n\r\nfor epoch in range(EPOCHS):\r\n    start = time.time()\r\n    for images, labels in train_ds:\r\n        train_step(tf.cast(images, tf.float32), labels)\r\n\r\n    model.reset_metrics()\r\n    for test_images, test_labels in test_ds:\r\n        test_step(tf.cast(test_images, tf.float32), test_labels)\r\n    end = time.time()\r\n    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}, cost:{}'\r\n    print(\r\n        template.format(epoch + 1, train_loss.result(),\r\n                        train_accuracy.result() * 100, test_loss.result(),\r\n                        test_accuracy.result() * 100, end -start))\r\n```\r\nThe result show below\r\n```\r\nEpoch 1, Loss: 3.311713457107544, Accuracy: 89.99500274658203, Test Loss: 0.22570940852165222, Test Accuracy: 95.55000305175781, cost:14.249950170516968\r\nEpoch 2, Loss: 1.7273597717285156, Accuracy: 93.3933334350586, Test Loss: 0.18705108761787415, Test Accuracy: 96.28499603271484, cost:13.976628065109253\r\nEpoch 3, Loss: 1.1731806993484497, Accuracy: 95.00333404541016, Test Loss: 0.1706559658050537, Test Accuracy: 96.61333465576172, cost:14.125600099563599\r\nEpoch 4, Loss: 0.8890712261199951, Accuracy: 95.9800033569336, Test Loss: 0.1615695059299469, Test Accuracy: 96.78250122070312, cost:14.998674154281616\r\nEpoch 5, Loss: 0.7157263159751892, Accuracy: 96.64299774169922, Test Loss: 0.15943895280361176, Test Accuracy: 96.91000366210938, cost:14.496413230895996\r\nEpoch 6, Loss: 0.5996174216270447, Accuracy: 97.10027313232422, Test Loss: 0.15636563301086426, Test Accuracy: 97.01667022705078, cost:12.977428197860718\r\nEpoch 7, Loss: 0.5162842273712158, Accuracy: 97.44285583496094, Test Loss: 0.15558230876922607, Test Accuracy: 97.07571411132812, cost:13.014786005020142\r\nEpoch 8, Loss: 0.4553721249103546, Accuracy: 97.66041564941406, Test Loss: 0.1616506278514862, Test Accuracy: 97.0574951171875, cost:14.170269966125488\r\nEpoch 9, Loss: 0.4086601734161377, Accuracy: 97.81925964355469, Test Loss: 0.16302895545959473, Test Accuracy: 97.0955581665039, cost:13.114216804504395\r\nEpoch 10, Loss: 0.3699580430984497, Accuracy: 97.98149871826172, Test Loss: 0.16444820165634155, Test Accuracy: 97.10900115966797, cost:12.783933162689209\r\nEpoch 11, Loss: 0.3377893567085266, Accuracy: 98.12287902832031, Test Loss: 0.1649542897939682, Test Accuracy: 97.1427230834961, cost:12.907387256622314\r\nEpoch 12, Loss: 0.31051450967788696, Accuracy: 98.2509765625, Test Loss: 0.16677971184253693, Test Accuracy: 97.17666625976562, cost:12.56903600692749\r\nEpoch 13, Loss: 0.28760311007499695, Accuracy: 98.35563659667969, Test Loss: 0.168002188205719, Test Accuracy: 97.21846008300781, cost:13.040626049041748\r\nEpoch 14, Loss: 0.26825159788131714, Accuracy: 98.44261932373047, Test Loss: 0.17205245792865753, Test Accuracy: 97.22142791748047, cost:13.130248785018921\r\nEpoch 15, Loss: 0.2515304386615753, Accuracy: 98.51310729980469, Test Loss: 0.17627017199993134, Test Accuracy: 97.23332977294922, cost:12.66043996810913\r\nEpoch 16, Loss: 0.2367033064365387, Accuracy: 98.58124542236328, Test Loss: 0.17778924107551575, Test Accuracy: 97.26062774658203, cost:12.836369037628174\r\nEpoch 17, Loss: 0.2236185222864151, Accuracy: 98.6434326171875, Test Loss: 0.17880629003047943, Test Accuracy: 97.2752914428711, cost:12.845327854156494\r\nEpoch 18, Loss: 0.21163013577461243, Accuracy: 98.706298828125, Test Loss: 0.18086740374565125, Test Accuracy: 97.29389190673828, cost:13.29944920539856\r\nEpoch 19, Loss: 0.20079432427883148, Accuracy: 98.76526641845703, Test Loss: 0.18283464014530182, Test Accuracy: 97.31105041503906, cost:12.92448115348816\r\nEpoch 20, Loss: 0.19131030142307281, Accuracy: 98.81291198730469, Test Loss: 0.18425647914409637, Test Accuracy: 97.32350158691406, cost:12.959301948547363\r\n.....\r\n```\r\n\r\nBut I find can  Decorated the call methods with call method from [this](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/function#used_in_the_tutorials).\r\n\r\nso I add annotation @tf.function to call method with above code(The rest of the code remains unchanged), just like this\r\n```\r\n   @tf.function\r\n    def call(self, x):\r\n        x = self.conv1(x)\r\n        x = self.flatten(x)\r\n        x = self.d1(x)\r\n        return self.d2(x)\r\n```\r\nThe result show below\r\n```\r\nEpoch 1, Loss: 11.509495735168457, Accuracy: 28.50666618347168, Test Loss: 11.525819778442383, Test Accuracy: 28.400001525878906, cost:14.542086839675903\r\nEpoch 2, Loss: 11.499279022216797, Accuracy: 28.60249900817871, Test Loss: 11.579718589782715, Test Accuracy: 28.064998626708984, cost:13.102718114852905\r\nEpoch 3, Loss: 11.471456527709961, Accuracy: 28.78444480895996, Test Loss: 11.532645225524902, Test Accuracy: 28.369998931884766, cost:13.346691846847534\r\nEpoch 4, Loss: 11.456918716430664, Accuracy: 28.886667251586914, Test Loss: 11.518753051757812, Test Accuracy: 28.497499465942383, cost:13.706462860107422\r\nEpoch 5, Loss: 11.445549011230469, Accuracy: 28.961334228515625, Test Loss: 11.492920875549316, Test Accuracy: 28.6560001373291, cost:13.56296968460083\r\nEpoch 6, Loss: 11.424226760864258, Accuracy: 29.0897216796875, Test Loss: 11.270418167114258, Test Accuracy: 30.030000686645508, cost:13.60814118385315\r\nEpoch 7, Loss: 11.216507911682129, Accuracy: 30.37714385986328, Test Loss: 11.099614143371582, Test Accuracy: 31.09000015258789, cost:13.579961061477661\r\nEpoch 8, Loss: 11.050827980041504, Accuracy: 31.407499313354492, Test Loss: 10.950920104980469, Test Accuracy: 32.01874923706055, cost:13.574744701385498\r\nEpoch 9, Loss: 10.918838500976562, Accuracy: 32.227962493896484, Test Loss: 10.83558464050293, Test Accuracy: 32.7400016784668, cost:12.771528959274292\r\nEpoch 10, Loss: 10.808745384216309, Accuracy: 32.91266632080078, Test Loss: 10.74200439453125, Test Accuracy: 33.32600021362305, cost:12.579218864440918\r\nEpoch 11, Loss: 10.719698905944824, Accuracy: 33.46500015258789, Test Loss: 10.672236442565918, Test Accuracy: 33.759090423583984, cost:12.781628131866455\r\nEpoch 12, Loss: 10.644211769104004, Accuracy: 33.93402862548828, Test Loss: 10.609025955200195, Test Accuracy: 34.154998779296875, cost:13.060226202011108\r\nEpoch 13, Loss: 10.57997989654541, Accuracy: 34.33307647705078, Test Loss: 10.551304817199707, Test Accuracy: 34.51692199707031, cost:13.11635136604309\r\nEpoch 14, Loss: 10.525317192077637, Accuracy: 34.671546936035156, Test Loss: 10.500534057617188, Test Accuracy: 34.834999084472656, cost:13.43892216682434\r\nEpoch 15, Loss: 10.476855278015137, Accuracy: 34.972442626953125, Test Loss: 10.458395957946777, Test Accuracy: 35.099334716796875, cost:13.528913021087646\r\nEpoch 16, Loss: 10.435961723327637, Accuracy: 35.22645950317383, Test Loss: 10.421695709228516, Test Accuracy: 35.329376220703125, cost:13.542529821395874\r\nEpoch 17, Loss: 10.397627830505371, Accuracy: 35.46509552001953, Test Loss: 10.387943267822266, Test Accuracy: 35.541175842285156, cost:12.953328132629395\r\nEpoch 18, Loss: 10.317543983459473, Accuracy: 35.95990753173828, Test Loss: 10.273320198059082, Test Accuracy: 36.2488899230957, cost:13.799224138259888\r\nEpoch 19, Loss: 10.211501121520996, Accuracy: 36.61640167236328, Test Loss: 10.166360855102539, Test Accuracy: 36.910526275634766, cost:13.552597045898438\r\nEpoch 20, Loss: 10.113394737243652, Accuracy: 37.22416687011719, Test Loss: 10.071305274963379, Test Accuracy: 37.49850082397461, cost:12.61729907989502\r\n......\r\n``` \r\nWhen you compare these two results, The first code is obviously better than the second. **I've done many experiments, and the results are the same**. The first get better acc and loss just after one epoch, but the second will iterated many time from a not so good result and finally can get a better result.\r\n\r\nso my question are :\r\n(1) What causes these two different results\uff1f because I have added @tf.function annotation to the method train_step, so whether I add  @tf.function annotation to call method or not , the result should the same.\r\n(2) tensorflow keras will run with graph model automatic\uff0cwhy add  @tf.function annotation to the call method in [this api doc](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/function#used_in_the_tutorials)", "comments": ["@payne4handsome ,\r\nWhen tried executing the code in TF-rc2 i got the output as present in the [gist](https://colab.sandbox.google.com/gist/oanush/d76aa20e3777359100449f80dc6d15ee/32895.ipynb) of colab, kindly take a look at that same.Thanks!", "@oanush You didn't understand me and executed the wrong code.  Below code should replace call function that in class MyModel. \r\n```\r\n@tf.function\r\n    def call(self, x):\r\n        x = self.conv1(x)\r\n        x = self.flatten(x)\r\n        x = self.d1(x)\r\n        return self.d2(x)\r\n```\r\nI mean you should execute code with two cases. one is not decorated call function with @tf.function, another is decorated call function with @tf.function.\r\n\r\n**first case**\r\n```\r\nclass MyModel(Model):\r\n    def __init__(self, *args, **kwargs):\r\n        super(MyModel, self).__init__(args, kwargs)\r\n        self.conv1 = Conv2D(32, 3, activation='relu')\r\n        self.flatten = Flatten()\r\n        self.d1 = Dense(128, activation='relu')\r\n        self.d2 = Dense(10, activation='softmax')\r\n    \r\n    def call(self, x):\r\n        x = self.conv1(x)\r\n        x = self.flatten(x)\r\n        x = self.d1(x)\r\n        return self.d2(x)\r\n```\r\n\r\n**second case**\r\n```\r\nclass MyModel(Model):\r\n    def __init__(self, *args, **kwargs):\r\n        super(MyModel, self).__init__(args, kwargs)\r\n        self.conv1 = Conv2D(32, 3, activation='relu')\r\n        self.flatten = Flatten()\r\n        self.d1 = Dense(128, activation='relu')\r\n        self.d2 = Dense(10, activation='softmax')\r\n\r\n    @tf.function\r\n    def call(self, x):\r\n        x = self.conv1(x)\r\n        x = self.flatten(x)\r\n        x = self.d1(x)\r\n        return self.d2(x)\r\n```", "Please find the [gist](https://colab.sandbox.google.com/gist/oanush/e1ad3080cdd020c076f3bca11fae5b0f/32895.ipynb) of the colab replicating the issue for TF-2.0rc2.Thanks!", "> Please find the [gist](https://colab.sandbox.google.com/gist/oanush/e1ad3080cdd020c076f3bca11fae5b0f/32895.ipynb) of the colab replicating the issue for TF-2.0rc2.Thanks!\r\n\r\nThis isn't correct. I am facing the same issue. Decorating call method with @tf.function doesn't helps and rather hurts the performance. \r\n\r\nP.S. I was able to solve this by normalizing the data and few other changes. Please follow this link to check my solution https://colab.research.google.com/gist/sourcecode369/daaef199cbf90a0f7491df31c01b364a/tensorflow-2-0-training-with-tf-function.ipynb\r\n\r\nThank you.", "@payne4handsome \r\nplease let us know if the issue still persist in nightly", "@payne4handsome\r\nplease update as per above comment", "@Saduf2019 \r\nYes, the issue still persist in nightly.\r\nPlease follow this link to replicate this issue.\r\nhttps://colab.research.google.com/drive/19hYQVHxVK310e9KT4Wz1-PathzwkY9xC", "@payne4handsome\r\ni have run the gist shared by you on nightly and there are no errors, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/23705cc14b2ab78014af887d9d3ac1e0/32895.ipynb)", "@Saduf2019 \r\nPlease compare the results that have great differences.  First result  accuracy is 97.86444091796875 after 15 epochs. Second result  accuracy is 47.27222442626953 after 15 epochs", "@payne4handsome In a subclassed model, decorating call method with a tf.function is fine if you are using model.fit method. I tried a subclass model with mnist data as you had used, but used model.fit and decorated call method with tf.function and didn't notice any drop in performance. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/2aafc0386bd723d8b3f3e417198d9211/mnist_subclassed.ipynb). \r\n\r\nHowever, decorating small code snippets using tf.function will lead to lot of performance overhead and is not recommended. If you are training using custom training loops, we recommend decorating the training step function with tf.function. When I tried your code with tf.function decorated call method, I noticed drop in performance. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/09d0fb4f1692b997b95281bd3df6064a/untitled92.ipynb).\r\n\r\nCan you please try model.fit method with subclass model or remove tf.function decoration on call method. Thanks!\r\n\r\n\r\n", "@jvishnuvardhan  I know exactly how to solve this problem. I mean this is a bug.", "I tried it locally and I can also observe a difference in accuracy. I wonder where it comes from.\r\n\r\nRegarding the performance of tf.function: Are you talking about additional compile time in the beginning or about training performance? If training performance suffers that would be good to know... Even in tf-addons there are some functions that are decorated with tf.function (see also the discussion in https://github.com/tensorflow/addons/pull/28 ).", "@mdanatg Can you please take a look at this issue? Any insights on the root-cause of the issue. Thanks!", "@omalleyt12 and I spoke and we believe the difference is owed to the final Softmax layer.\r\n\r\nIn general, softmax with cross-entropy loss is prone to numerical instabilities, and the usual practice is to omit the softmax activation and use `tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)`. Normally, Keras will replace that automatically for you, but when you wrap the code with `tf.function`, it can't do it, so instead you need to do it explicitly in the code.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32895\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32895\">No</a>\n", "With the modifications suggested by @mdanatg results are much better and are similar to the other approach (without @tf.function). I am getting accuracy around 97% in 15 epochs. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/d801056670534d90b75a899c56ec11f2/untitled92.ipynb). \r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", ">Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/d801056670534d90b75a899c56ec11f2/untitled92.ipynb).\r\n\r\n@payne4handsome,\r\nCould you please check @jvishnuvardhan's comment above and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32895\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32895\">No</a>\n"]}, {"number": 32894, "title": "convolution2d_transpose() got an unexpected keyword argument 'kernel_constraint'", "body": "when i use tensorflow.contrib.layers.convolution2d_transpose()\r\nusing tensorflow1.13-gpu, ubuntu\r\ni got this error:\r\nconvolution2d_transpose() got an unexpected keyword argument 'kernel_constraint'\r\n\r\nbut i check the document, there exits 'kernel_constraint' parameter in tensorflow.contrib.layers.convolution2d_transpose\r\nhow to fix it???\r\n", "comments": ["the document get 404....\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/layers/conv2d_transpose", "If you are looking for `1.13` docs, then here is the [link](https://www.tensorflow.org/versions/r1.13/api_docs/python/tf).\r\n\r\nHowever, I do recommend you to upgrade to newer version of [Tensorflow](https://www.tensorflow.org/install). I believe that `tf.contrib` is removed in Tensorflow 2.0 so you should take that in consideration (find alternative).\r\n\r\nIn TF2, there is [`conv2d_transpose`](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose).", "@J-zin As suggested by @ichisadashioko Can you try `TF1.15.0rc1` or `TF2.0.0rc2` and let us know how it progresses. Please also share platform details and also provide a simple standalone code to reproduce the issue. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "btgtr"]}, {"number": 32893, "title": "Fix for 32890", "body": "Usage fix for https://github.com/tensorflow/tensorflow/issues/32890", "comments": ["@ichisadashioko The change is as per the TF2.0 moments API at - https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/moments \r\n![image](https://user-images.githubusercontent.com/1215029/65828451-ab75e180-e2b8-11e9-9d48-02f8b5b16517.png)\r\n", "Do you know that there is [`r2.0`](https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/python/ops/nn_impl.py#L1180) branch.\r\n\r\nAt the time of writing, [`r2.0`](https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow) was 451 commits ahead, 6650 commits behind `master`.", "Do we need to look at below instead for v2 ? https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/python/ops/nn_impl.py#L1245", "There is a set of errors in the CI like \"found a whitelisted error:\r\n  tensorflow/python/kernel_tests/constant_op_eager_test.py:250: [E0303(invalid-length-returned), ConstantTest.testInvalidLength.BadList.__len__] __len__ does not return non-negative integer\".   These appear unrelated to the doc change. Do I need to retrigger any of these to get a pass ?", "Whitelisted errors are ignored.\r\n\r\nHowever, you do have other errors:\r\n\r\n```\r\nFAIL: Found 1 non-whitelisted pylint errors:\r\ntensorflow/python/ops/nn_impl.py:1409: [C0301(line-too-long), ] Line too long (103/80)\r\n```\r\n\r\n"]}, {"number": 32892, "title": "Broken Link for API Development Recommendations", "body": "[This page](https://www.tensorflow.org/community/contribute/docs) links to https://www.tensorflow.org/customize, which doesn't exist.\r\n\r\n(\"We encourage the community to develop and maintain support for other languages with the approach recommended by the TensorFlow maintainers.\")\r\n", "comments": ["I believe that https://www.tensorflow.org/customize is no longer existed in https://www.tensorflow.org/community/contribute/docs.\r\n\r\nI wrote the snippet below to check in Developer console and nothing has been printed out. Maybe the problem has been fixed?\r\n\r\n```javascript\r\nvar anchors = document.getElementsByTagName('a')\r\nfor (let i = 0; i < anchors.length; i++) {\r\n  let href_attr = anchors[i].getAttribute('href')\r\n  if (href_attr) {\r\n    let s = href_attr.search('customize')\r\n    if (s >= 0) {\r\n      console.log(`href_attr: ${href_attr}`)\r\n      console.log(anchors[i])\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n![https://imgur.com/a/qdWWoWA](https://i.imgur.com/mGQEiyc.png)\r\n", "@kfrncs,\r\nIn [this link](https://www.tensorflow.org/community/contribute/docs), https://www.tensorflow.org/customize is not available. Could you please provide the exact position of the broken link. Thanks!", "It looks as though it's already fixed. I can't find the part I was referring to, so I guess whatever restructuring is done now.", "@kfrncs, Glad it fixed.\r\nClosing this issue. Please feel free to reopen if the issue still persists. Thanks!"]}, {"number": 32891, "title": "ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so: cannot open shared object file: No such file or directory", "body": "This error is obtained while importing tensorflow in a program.\r\n\r\n- OS Platform and Distribution : Linux raspberry 4.9.0-11-686 #1 SMP Debian 4.9.189-3+deb9u1 (2019-09-20) i686 GNU/Linux\r\n- TensorFlow installed from (source or binary): using pip3 python package\r\n- Python version: 3.5.3\r\n- TensorFlow version = 0.11.0\r\n\r\n\"import tensorflow as tf\"\r\nThe above command is throwing ImportError as follows:\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py\", line 23, in <module>\r\n    from tensorflow.python import *\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\n  File \"/usr/lib/python3.5/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so: cannot open shared object file: No such file or directory\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@Srikanth-Kb, Was the solution provided worked for you.  Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32891\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32891\">No</a>\n"]}]