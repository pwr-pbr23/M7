[{"number": 36344, "title": "Allow tf.estimator.Estimators to use CuDNN layers", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nN/A\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nN/A\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nsource\r\n- TensorFlow version (use command below):\r\n2.0+\r\n- Python version:\r\n3.7\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\n\r\ntf.estimator.Estimators cannot use CuDNN layers\r\n\r\n**Describe the expected behavior**\r\n\r\ntf.estimator.Estimators implement CuDNN optimized layers\r\n\r\n**Code to reproduce the issue**\r\nN/A\r\n\r\n**Other info / logs**\r\n\r\nCustom `tf.estimator.Estimators`, those that implement a user defined `model_fn`, will not allow for the utilization of CuDNN layers -- like the layers found in `tf.keras.layers.LSTM`\r\n\r\nThe TensorFlow 2.0 documents state, [\"Calling methods of Estimator will work while eager execution is enabled. However, the model_fn and input_fn is not executed eagerly, Estimator will switch to graph mode before calling all user-provided functions (incl. hooks), so their code has to be compatible with graph mode execution. Note that input_fn code using tf.data generally works in both graph and eager modes.\"](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#eager_compatibility)\r\n\r\nThereby, if a user tries to use CuDNN optimized layers, `ops.executing_eagerly_outside_functions()` will never trigger while the layer is being initialized. \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/cf7fcf164c9846502b21cebb7d3d5ccf6cb626e8/tensorflow/python/keras/layers/recurrent_v2.py#L366\r\n\r\nIt would be great to use CuDNN layers with custom estimators, or even with the prebuilt `tf.estimator.RNNEstimator` class. \r\n\r\nAs a temporary workaround, I force the ```self.could_use_cudnn``` to True after initialization and proceed to build the estimator with CuDNN layers. (Ensuring that all other parameters are rationalized) However, I get the below warning:\r\n\r\n> [1,0]<stderr>:2020-01-30 17:39:33.939905: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_6654_7125' and '__inference___backward_cudnn_lstm_with_fallback_6109_6289_specialized_for_training_gradients_lstm_StatefulPartitionedCall_grad_StatefulPartitionedCall_at_tf_graph' both implement 'lstm_b42b1bb1-dad6-4430-b5f1-d964cdf2b5a3' but their signatures do not match.\r\n\r\nAside from the warning report, this works as expected. \r\n", "comments": ["@nmatare \r\n\r\nCan you please provide simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "@nmatare \r\n\r\nAny update on this issue please. Thanks!", "Apologies on the delay. Please see the below failing assert statement:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ndef model_fn(features, labels, mode):\r\n        # https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\r\n\t# \"The requirements to use the cuDNN implementation are:\r\n\t# activation == tanh\r\n\t# recurrent_activation == sigmoid\r\n\t# recurrent_dropout == 0\r\n\t# unroll is False\r\n\t# use_bias is True\r\n\t# Inputs are not masked or strictly right padded.\"\r\n\tlstm_layer = tf.keras.layers.LSTM(\r\n\t\tunits=64,\r\n\t\tactivation='tanh',\r\n\t\trecurrent_activation='sigmoid',\r\n\t\trecurrent_dropout=0,\r\n\t\tunroll=False,\r\n\t\tuse_bias=True,\r\n\t)\r\n\r\n\tassert lstm_layer.could_use_cudnn is True, 'This should pass'\r\n\r\n\tlogits = tf.keras.layers.Dense(units=1, activation=None)(lstm_layer)\r\n\r\n\thead = tf.estimator.MultiClassHead()\r\n\r\n\toptimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.001)\r\n\r\n\tloss = tf.compat.v1.losses.sparse_softmax_cross_entropy(\r\n\t\tlabels=labels,\r\n\t\tlogits=logits,\r\n\t\treduction=tf.compat.v1.losses.Reduction.NONE,\r\n\t)\r\n\r\n\tstep = tf.compat.v1.train.get_or_create_global_step()\r\n\r\n\treturn head.create_estimator_spec(\r\n\t\ttrain_op_fn=lambda: optimizer.minimize(loss, step),\r\n\t\tfeatures=features,\r\n\t\tlabels=labels,\r\n\t\tmode=mode,\r\n\t\tlogits=logits,\r\n\t)\r\n\r\n# Please see comments from above on line 366 for tensorflow/tensorflow/python/keras/layers/recurrent_v2.py\r\nassert tf.executing_eagerly() is True\r\n\r\ndef train_input_fn():\r\n\tfeatures = tf.constant([[1, 3], [2, 1], [3, 3]])\r\n\tlabels = tf.constant(['A', 'B', 'A'])\r\n\treturn tf.data.Dataset.from_tensor_slices((features, labels)) \r\n\r\nclassifier = tf.estimator.Estimator(model_fn=model_fn)\r\nclassifier.train(input_fn=lambda: train_input_fn(), steps=500)\r\n```\r\n", "@nmatare \r\n\r\nI tried in colab with TF 2.0 and i am seeing `AssertionError: This should pass` and I tried in colab with TF 2.2.0-dev20200211 and i am seeing \r\n`AttributeError: 'LSTM' object has no attribute 'could_use_cudnn`'PLease, find the gist [here](https://colab.research.google.com/gist/ravikyram/f455ca020a66d9d36d2bc60fe4fdb0b6/untitled638.ipynb).Is this the expected behavior. Thanks!", "It appears the attribute  `could_use_cudnn` was changed to `_could_use_gpu_kernel ` for TF 2.2.0. When running the notebook with TF 2.2.0-dev20200211,\r\nplease change `assert lstm_layer.could_use_cudnn is True`, to `assert lstm_layer._could_use_gpu_kernel is True`, the underlying logic appears to have remained the same.", "Estimators do not distribute to GPUs natively, and we do not offer support for Estimators on GPU at this time. If you would like to use Keras Layers with GPU, we would encourage you to use Keras models with Distribution Strategies for GPUs: https://www.tensorflow.org/guide/distributed_training\r\n\r\nIt is possible that workarounds exist here, but because we do not explicitly support this use-case, Stack Overflow may be a better place to seek help on this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36344\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36344\">No</a>\n"]}, {"number": 36343, "title": "bazel test command broken because of Missing ROCM input files.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 tensorflow/tensorflow:devel-py3 container\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: commit ID 720b16121ea60d914f2d3df47e580e7e1e5542ae or latest master\r\n- Python version: Python 3.6.9\r\n- Installed using virtualenv? pip? conda?: Not installsed\r\n- Bazel version (if compiling from source): 1.2.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem** \r\nUnable to complete bazel test command because of missing rocm input files. \r\n\r\n```\r\n[eigen.log.zip](https://github.com/tensorflow/tensorflow/files/4135491/eigen.log.zip)\r\n\r\nERROR: missing input file '@local_config_rocm//rocm:rocm/include/hipcub/hipcub_version.hpp'\r\nERROR: missing input file '@local_config_rocm//rocm:rocm/include/rocprim/rocprim_version.hpp'\r\nERROR: /root/.cache/bazel/_bazel_root/104a68818e52204e40c368960e574528/external/local_config_rocm/rocm/BUILD:119:1: @local_config_rocm//rocm:rocprim: missing input file '@local_config_rocm//rocm:rocm/include/hipcub/hipcub_version.hpp'\r\nERROR: /root/.cache/bazel/_bazel_root/104a68818e52204e40c368960e574528/external/local_config_rocm/rocm/BUILD:119:1: @local_config_rocm//rocm:rocprim: missing input file '@local_config_rocm//rocm:rocm/include/rocprim/rocprim_version.hpp'\r\nERROR: /host/tensorflow/tensorflow/python/kernel_tests/BUILD:1222:1: Creating runfiles tree bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/summary_v1_ops_test.runfiles failed: build-runfiles failed: error executing command \r\n  (cd /root/.cache/bazel/_bazel_root/104a68818e52204e40c368960e574528/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PYTHON_BIN_PATH=/usr/local/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python3.6/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n    TF_ENABLE_XLA=1 \\\r\n  /root/.cache/bazel/_bazel_root/install/84defa6eb1e9416bf92d6f89ab2d4f31/build-runfiles bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/summary_v1_ops_test.runfiles_manifest bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/summary_v1_ops_test.runfiles): Process terminated by signal 15: Process terminated by signal 15\r\nERROR: /root/.cache/bazel/_bazel_root/104a68818e52204e40c368960e574528/external/local_config_rocm/rocm/BUILD:119:1 2 input file(s) do not exist```\r\n\r\nThese files do not exist in the bazel cache.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```$ docker pull tensorflow/tensorflow:devel-py3\r\n$ git clone https://github.com/tensorflow/tensorflow\r\n$ docker run -ti --rm -v $(pwd):/host tensorflow/tensorflow:devel-py3\r\n# cd /host/tensorflow\r\n# yes \"\" | python configure.py\r\n# bazel --nosystem_rc --nohome_rc test --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-march=haswell --copt=-mtune=broadwell --copt=-O3 --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector --config=v2 --test_timeout 300,450,1200,3600 --test_env=KMP_BLOCKTIME=0 -s --cache_test_results=no --test_size_filters=small,medium,large,enormous -c opt -- //tensorflow/... -//tensorflow/compiler/... -//tensorflow/lite/... -//tensorflow/stream_executor/cuda/... -//tensorflow/python/autograph/pyct/... -//tensorflow/core/kernels:eigen_mkldnn_contraction_kernel_test```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nlog file attached\r\n", "comments": ["@angerson This problem started occurring sometime after the last commit on Jan 26: f88440725cdf3808a20238864cfe75a5cd9f2f22 because I'm able to run the bazel test command above just fine against that commit. Is there something wrong with the bazel test command?", "I can't figure out why this command is trying to build rocm components...", "@angerson This is the culprit: b105944eb6c563849a085a1765d6700ee2c0f35c in the tensorflow/core/kernels/BUILD file. The test command succeeds on the commit before this: 0a3c2988804a71371f51e182bd70b81a0d88be6d.\r\n", "I can confirm this. I get this issue with with the latest tensorflow-rocm-upstream, into which tensorflow was last merged on Friday. After checking out the earlier commit @claynerobison pointed at, I do no longer see this error. I am not sure if this is the correct issue tracker, though. Pinging @whchung and @sunway513 for awareness.", "This appears to be fixed by the commit 930c651.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36343\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36343\">No</a>\n"]}, {"number": 36342, "title": "[ROCm][XLA] Fixing binary_ops_test", "body": "This CL disabled bfloat16 GEMM to fix the `binary_ops_test`", "comments": []}, {"number": 36341, "title": "[ROCm] Adding no_rocm tag to tests that started failing after the 200129 weekly sync", "body": "/cc @whchung @chsigg ", "comments": ["@deven-amd Can you please resolve conflicts? Thanks!", "@gbaned , I have rebased the PR to resolve the merge conflict. ", "@gbaned, gentle ping", "gentle ping", "gentle ping"]}, {"number": 36340, "title": "100-line Tensorflow code and Keras equivalent do not produce the same result, Tensorflow result does not converge, why?", "body": "I am doing experiments with a basic GAN, the code of which is provided for both TF (I use version 1.15.2, using TF 2.x-style API) and Keras (2.2.5), below.\r\nThe GAN learns to generate 2D points fitting a 2D curve, f(x) = x^2. Every point is considered as a 2D vector 'individual', (x,y).\r\n\r\nThe following 2 python programs compile and run out-of-the-box, and are meant to produce exactly the same result. However, the TF version **does not converge properly at all**.\r\n\r\nI tried everything I could to understand what's going wrong, to no avail. Obviously, there is something that I miss.\r\n\r\nThe TF version is largely inspired from the official GAN tutorial located here: https://www.tensorflow.org/tutorials/generative/dcgan\r\n\r\nI also provide the code in 2 pastebin links (for your convenience):\r\n\r\nKeras version: https://pastebin.com/N26e3hWh\r\nTensorflow version: https://pastebin.com/9ebmSyJB\r\n\r\nKeras version:\r\n\r\n```\r\nimport numpy as np\r\nfrom numpy import hstack\r\nfrom numpy import zeros\r\nfrom numpy import ones\r\nfrom numpy.random import rand\r\nfrom numpy.random import randn\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense\r\nimport keras.backend as K\r\nfrom matplotlib import pyplot\r\n\r\nclass GanPointGraph_Keras(object):\r\n    \r\n    def __init__(self):\r\n        self.latent_dim = 5\r\n        self.discriminator = self.define_discriminator()\r\n        self.generator = self.define_generator(self.latent_dim)\r\n        self.gan_model = self.define_gan(self.generator, self.discriminator)\r\n\r\n    def define_discriminator(self, n_inputs=2):\r\n        model = Sequential()\r\n        model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\r\n        model.add(Dense(1, activation='sigmoid'))\r\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n        print(K.eval(model.optimizer.lr))\r\n        return model\r\n    \r\n    def define_generator(self, latent_dim, n_outputs=2):\r\n        model = Sequential()\r\n        model.add(Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))\r\n        model.add(Dense(n_outputs, activation='linear'))\r\n        return model\r\n    \r\n    def define_gan(self, generator, discriminator):\r\n        discriminator.trainable = False\r\n        model = Sequential()\r\n        model.add(generator)\r\n        model.add(discriminator)\r\n        model.compile(loss='binary_crossentropy', optimizer='adam')\r\n        return model\r\n    \r\n    def generate_latent_points(self, n):\r\n        x_input = randn(self.latent_dim * n)\r\n        x_input = x_input.reshape(n, self.latent_dim)\r\n        return x_input\r\n    \r\n    def generate_fake_samples(self, n):\r\n        x_input = self.generate_latent_points(n)\r\n        X = self.generator.predict(x_input)\r\n        return X\r\n\r\n    def generate_real_samples(self, n):\r\n        X1 = rand(n) - 0.5\r\n        X2 = X1 * X1\r\n        X1 = X1.reshape(n, 1)\r\n        X2 = X2.reshape(n, 1)\r\n        X = hstack((X1, X2))    \r\n        return X\r\n    \r\n    def train(self):\r\n        n_batch = 128\r\n        half_batch = int(n_batch / 2)\r\n        x_real = self.generate_real_samples(half_batch)\r\n        y_real = ones((half_batch, 1))\r\n        x_fake = self.generate_fake_samples(half_batch)\r\n        y_fake = zeros((half_batch, 1))\r\n        self.discriminator.train_on_batch(x_real, y_real)\r\n        self.discriminator.train_on_batch(x_fake, y_fake)\r\n        x_gan = self.generate_latent_points(n_batch)\r\n        y_gan = ones((n_batch, 1))\r\n        self.gan_model.train_on_batch(x_gan, y_gan)\r\n\r\nif __name__ == \"__main__\":\r\n    g = GanPointGraph_Keras();\r\n\r\n    for epoch in range(10000):\r\n        print('Epoch', epoch)\r\n        g.train()\r\n        if epoch % 1000 == 0:\r\n            g_objects = g.generate_fake_samples(100)\r\n            r_objects = g.generate_real_samples(100)\r\n \r\n            pyplot.clf()\r\n            pyplot.title('Keras iteration ' + str(epoch))\r\n            pyplot.scatter([i[0] for i in r_objects], [i[1] for i in r_objects], c='black')\r\n            pyplot.scatter([i[0] for i in g_objects], [i[1] for i in g_objects], c='red')\r\n            pyplot.show()\r\n```\r\n\r\nTensorflow version:\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.enable_eager_execution() # if using TF 1.15.x\r\nfrom tensorflow.keras import layers\r\n\r\nimport numpy as np\r\nfrom numpy.random import rand\r\nfrom numpy import hstack\r\n\r\nfrom matplotlib import pyplot\r\n\r\nclass GanPointGraph(object):\r\n\r\n    def __init__(self):\r\n        self.latent_dim = 5\r\n        self.generator = self.make_generator()\r\n        self.discriminator = self.make_discriminator()\r\n        \r\n        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)        \r\n        self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n        self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n        \r\n    def make_generator(self):\r\n        model = tf.keras.Sequential()\r\n        model.add(layers.Dense(15, activation='relu', input_dim=self.latent_dim))\r\n        model.add(layers.Dense(2))\r\n        return model\r\n      \r\n    def make_discriminator(self):\r\n        model = tf.keras.Sequential()\r\n        model.add(layers.Dense(25, activation='relu', input_dim=2))\r\n        model.add(layers.Dense(1, activation='sigmoid')) # (-infinity, infinity) -> (0, 1)\r\n        return model\r\n    \r\n    def generator_loss(self, fake_output):\r\n        #return self.cross_entropy(tf.ones_like(fake_output), fake_output)\r\n        return tf.reduce_mean(tf.math.log(1-fake_output))\r\n\r\n    def discriminator_loss(self, real_output, fake_output):\r\n        #real_loss = self.cross_entropy(tf.ones_like(real_output), real_output)\r\n        #fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)\r\n        #total_loss = real_loss + fake_loss\r\n        #return total_loss\r\n        loss_real = tf.reduce_mean(-tf.math.log(real_output))\r\n        loss_fake = tf.reduce_mean(-tf.math.log(1-fake_output))\r\n        D_loss = loss_real + loss_fake\r\n        return D_loss\r\n\r\n    def generate_real_samples(self, n):\r\n        X1 = rand(n) - 0.5\r\n        X2 = X1 * X1\r\n        X1 = X1.reshape(n, 1)\r\n        X2 = X2.reshape(n, 1)\r\n        x_train = hstack((X1, X2))\r\n        return x_train\r\n    \r\n    def generate_fake_samples(self, n):\r\n        z_sample = np.random.normal(0, 1.0, size=[n, self.latent_dim]).astype(np.float32)\r\n        return self.generator(z_sample, training=False).numpy()\r\n    \r\n    def train(self):\r\n        images = self.generate_real_samples(128);\r\n        noise = tf.random.normal([images.shape[0], self.latent_dim])\r\n        \r\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n            generated_images = self.generator(noise, training=True)\r\n            \r\n            real_output = self.discriminator(images, training=True)\r\n            fake_output = self.discriminator(generated_images, training=True)\r\n            \r\n            gen_loss = self.generator_loss(fake_output)\r\n            disc_loss = self.discriminator_loss(real_output, fake_output)\r\n        \r\n        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\r\n        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\r\n        \r\n        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\r\n        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\r\n    \r\nif __name__ == \"__main__\":\r\n    g = GanPointGraph();\r\n    \r\n    for epoch in range(10000):\r\n        print('Epoch', epoch)\r\n        g.train()\r\n        if epoch % 1000 == 0:\r\n            g_objects = g.generate_fake_samples(100)\r\n            r_objects = g.generate_real_samples(100)\r\n \r\n            pyplot.clf()\r\n            pyplot.title('Tensorflow iteration ' + str(epoch))\r\n            pyplot.scatter([i[0] for i in r_objects], [i[1] for i in r_objects], c='black')\r\n            pyplot.scatter([i[0] for i in g_objects], [i[1] for i in g_objects], c='red')\r\n            pyplot.show()\r\n```\r\n\r\nIf you run the above programs, you will see that the **Keras version converges quite reliably**. The GAN learns to fit the example points quite nicely. Generate points slowly project onto the curve, and come close to it after about 4000 epochs.\r\n\r\nThe TF version just \"dances around\" the solution, producing quite bad results, even after a high number of epochs. It never really converges. The movement it does is quite funny, navigating on the left, then on the right, and on the left again, and so on. Sometimes, it seems that it starts to fit the curve, but it quickly goes away unfortunately.\r\n\r\nWhat am I doing wrong in Tensorflow? Obviously, there is something that I am missing.\r\n\r\nPlease note:\r\n\r\n- the layers for both versions are the same (initalizers may both be set to 'he_uniform', this does not change the outcome of the test)\r\n- the learning rate is the same (0.001 for both Keras and Tensorflow Adam optimizers)\r\n- I tried with TF 1.15.0 and 1.15.2 runtimes, same result.\r\n- all samples I have tried on my computer seem to work fine.\r\n\r\nI am using Windows x64 and Python 3.6.8 (just the regular Python distribution, not Anaconda).\r\n\r\nHelp would be immensely appreciated as I would like to migrate from Keras to Tensorflow.\r\n\r\nMany thanks in advance.\r\n", "comments": ["I have tried on colab with TF version 1.15  and was able to reproduce the issue.Please, find the gist for [Keras](https://colab.research.google.com/gist/ravikyram/529137515280fa62e9c448c1b08af051/untitled611.ipynb) and [Tensorflow keras](https://colab.research.google.com/gist/ravikyram/253009155c80160420e3b804ee3c5162/untitled612.ipynb). Thanks!", "I believe I made some important progress.\r\n\r\nIf I change the Adam optimizer settings to **learning_rate=0.0005 and beta_1=0.5**, convergence is  good.\r\n(These settings are used for instance in this page: https://towardsdatascience.com/dcgans-generating-dog-images-with-tensorflow-and-keras-fb51a1071432)\r\n\r\nWhen using the default Adam parameters (learning_rate=0.001, beta_1=0.9), convergence is almost never achieved.\r\nI am a bit puzzled here, as with Keras or **Tensorflow 1.x, convergence is (in most cases) achieved with the same default parameters (learning rate=0.001, beta_1=0.9)**.\r\n\r\nHas the Adam optimizer implementation changed between TF 1.x and 2.x? (on a side note, are there any known implementation differences between Keras and TF2.x-Keras?)\r\n", "Hi @fcunilim :\r\nThanks for reporting this. The original Keras Adam is not correct, i.e., the step changes non-deterministically, and it was fixed. The tf.keras Adam has been the correct version. It seems that in this particular case the correct version behaves worse given the learning rate, which is not surprising for GAN models. Sorry for the confusion though!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36340\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36340\">No</a>\n", "Thank you!\n\nLe mer. 4 mars 2020 \u00e0 11:05, tanzhenyu <notifications@github.com> a \u00e9crit :\n\n> Hi @fcunilim <https://github.com/fcunilim> :\n> Thanks for reporting this. The original Keras Adam is not correct, i.e.,\n> the step changes non-deterministically, and it was fixed. The tf.keras Adam\n> has been the correct version. It seems that in this particular case the\n> correct version behaves worse given the learning rate, which is not\n> surprising for GAN models. Sorry for the confusion though!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/36340?email_source=notifications&email_token=AONNO3W37XB4ZTWHRFXTG3LRFYRWDA5CNFSM4KNZB6I2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOENXEYLA#issuecomment-594431020>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AONNO3RLMRUELXMMTTZAZY3RFYRWDANCNFSM4KNZB6IQ>\n> .\n>\n"]}, {"number": 36339, "title": "Unable to convert DeeplabV3 - \"xception_65\" frozen graph to TFLite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (or github SHA if from source): 1.13\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n```\r\n#!/bin/bash\r\n\r\nset -e\r\nset -x\r\n\r\npython3 models/research/deeplab/export_model.py \\\r\n  --logtostderr \\\r\n  --checkpoint_path=\"train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/ckpt/model.ckpt-3000\" \\\r\n  --export_path=\"train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb\" \\\r\n  --model_variant=\"xception_65\" \\\r\n  --num_classes=2 \\\r\n  --atrous_rates=6 \\\r\n  --atrous_rates=12 \\\r\n  --atrous_rates=18 \\\r\n  --output_stride=4 \\\r\n  --decoder_output_stride=4 \\\r\n  --train_crop_size=312 \\\r\n  --train_crop_size=312 \\\r\n  --train_batch_size=1 \\\r\n  --fine_tune_batch_norm=False \\\r\n  --initialize_last_layer=False \\\r\n  --last_layers_contain_logits_only=False \\\r\n  --quantize_delay_step=0 \\\r\n  --dataset=\"trunks_seg\"                                              \r\n\r\ntflite_convert \\\r\n  --graph_def_file=\"train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb\" \\\r\n  --output_file=\"train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.tflite\" \\\r\n  --input_format=TENSORFLOW_GRAPHDEF  \\\r\n  --output_format=TFLITE \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --mean_values=128 \\\r\n  --std_dev_values=128 \\\r\n  --input_arrays=ImageTensor \\\r\n  --output_arrays=SemanticPredictions \\\r\n  --input_shapes=1,312,312,3 \\\r\n  --allow_custom_ops\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n+ python3 models/research/deeplab/export_model.py --logtostderr --checkpoint_path=train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/ckpt/model.ck\r\npt-3000 --export_path=train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb --model_variant=xception_65 --num_classes=2 --a\r\ntrous_rates=6 --atrous_rates=12 --atrous_rates=18 --output_stride=4 --decoder_output_stride=4 --train_crop_size=312 --train_crop_size=312 --train_batch_size=1 -\r\n-fine_tune_batch_norm=False --initialize_last_layer=False --last_layers_contain_logits_only=False --quantize_delay_step=0 --dataset=trunks_seg\r\nINFO:tensorflow:Prepare to export model to: train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb\r\nINFO:tensorflow:Exported model performs single-scale inference.\r\nWARNING:tensorflow:From /home/andre-criis/Source/coral-deeplearning-ros/detect/models/research/deeplab/core/feature_extractor.py:160: to_float (from tensorflow.\r\npython.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nWARNING:tensorflow:From /home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.p\r\nython.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From /home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.pyt\r\nhon.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nINFO:tensorflow:Restoring parameters from train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/ckpt/model.ckpt-3000\r\nWARNING:tensorflow:From /home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:232: convert_variables_to_constants (from t\r\nensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.compat.v1.graph_util.convert_variables_to_constants\r\nWARNING:tensorflow:From /home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorf\r\nlow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.compat.v1.graph_util.extract_sub_graph\r\nINFO:tensorflow:Froze 732 variables.\r\nINFO:tensorflow:Converted 732 variables to const ops.\r\n+ tflite_convert --graph_def_file=train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb --output_file=train/train_res/deepl\r\nav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --inference_type=QUANTIZED_U\r\nINT8 --mean_values=128 --std_dev_values=128 --input_arrays=ImageTensor --output_arrays=SemanticPredictions --input_shapes=1,312,312,3 --allow_custom_ops\r\nTraceback (most recent call last):\r\n  File \"/home/andre-criis/.local/bin/tflite_convert\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py\", line 442, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py\", line 438, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py\", line 191, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 455, in convert\r\n    **converter_kwargs)\r\n  File \"/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 442, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 205, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2020-01-30 15:30:08.786078: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1898 operators, 3080 arrays (0 quantized)\r\n2020-01-30 15:30:08.866046: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1888 operators, 3061 arrays (0 quantized)\r\n2020-01-30 15:30:08.974668: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1888 operators, 3061 arrays (0 quantized)\r\n2020-01-30 15:30:09.328460: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:625] Check failed: input_shape.dims().size() == op->size.size() (4 vs. 3)\r\nAborted (core dumped)\r\n```\r\n\r\n**Link to the saved GraphDef**\r\n\r\n```\r\nhttps://drive.google.com/file/d/1Cvb2LDUHlsSYKds0gev2wDWLdSVJZavi/view?usp=sharing\r\n```\r\n\r\nThanks in advance.", "comments": ["You may refer #23747"]}, {"number": 36338, "title": "not supported in the pynq board from xilinx", "body": "![image](https://user-images.githubusercontent.com/48592314/73463266-f9a00c00-43a2-11ea-80cf-628d6dbe1a69.png)\r\n", "comments": ["@vishwas1234567, Follow the steps mentioned [here](https://www.tensorflow.org/lite/guide/python).`\r\n pip3 install https://dl.google.com/coral/python/tflite_runtime-2.1.0-cp35-cp35m-linux_aarch64.whl`.\r\nThanks!", "@vishwas1234567, Is this still an issue", "@vishwas1234567, Closing since it is resolved. Please feel free to open if still issue persists. Thanks"]}, {"number": 36337, "title": "SSD300 on TF 2.0 is unable to train with batch size 32 on GPU with 8GB memory when it should be able to?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N.A.\r\n- TensorFlow installed from (source or binary): docker pull tensorflow/tensorflow:2.1.0-gpu-py3\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): N.A.\r\n- GCC/Compiler version (if compiling from source): N.A.\r\n- CUDA/cuDNN version: 10.1/7.6\r\n- GPU model and memory: GTX 1070 Ti, 8GB\r\n\r\n**Describe the current behavior**\r\nIt runs out of memory when the code is run.\r\n\r\n**Describe the expected behavior**\r\nThis (https://github.com/lufficc/SSD) is an alternative code which is written in PyTorch and it is able to run on my 8GB GPU, consuming only 6.8GB with batch size 32. I have ported the code to TF 2.0 and have provided a minimal runnable code below. The code consumes much more memory than 6.8 GB and causes out of memory error. Since TF does not provide any good way to profile GPU memory usage, I am unable to pinpoint the problem. However, I do not see any part of the code that should cause the code to consume much more memory than the PyTorch's version. Is it an inherent TF problem/bug or is there a way to make it consume less memory?\r\n\r\n**Code to reproduce the issue**\r\n```\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Layer, Conv2D, BatchNormalization, ReLU, MaxPool2D, ZeroPadding2D\r\nfrom tensorflow.keras import Model, Sequential\r\n\r\n\r\nfeature_extractor_config = {\r\n    '300': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M',\r\n            512, 512, 512],\r\n    '512': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M',\r\n            512, 512, 512],\r\n}\r\n\r\nfeature_pyramid_config = {\r\n    '300': [256, 'S', 512, 128, 'S', 256, 128, 256, 128, 256],\r\n    '512': [256, 'S', 512, 128, 'S', 256, 128, 'S', 256, 128, 'S', 256],\r\n}\r\n\r\nhead_config = {\r\n    '300': [4,6,6,6,4,4]\r\n}\r\n\r\n\r\ndef create_feature_extractor(cfg, batch_norm=False):\r\n    layers = []\r\n    in_channels = 3\r\n    for v in cfg:\r\n        if v == 'M':\r\n            layers += [MaxPool2D(pool_size=2, strides=2)]\r\n        elif v == 'C':\r\n            layers += [ZeroPadding2D(padding=((0,1), (0,1))), MaxPool2D(pool_size=2, strides=2)]\r\n        else:\r\n            pad = ZeroPadding2D(1)\r\n            conv2d = Conv2D(v, kernel_size=3)\r\n            if batch_norm:\r\n                layers += [pad, conv2d, BatchNormalization(v), ReLU()]\r\n            else:\r\n                layers += [pad, conv2d, ReLU()]\r\n            in_channels = v\r\n    pad5 = ZeroPadding2D(padding=1)\r\n    pool5 = MaxPool2D(pool_size=3, strides=1)\r\n    pad6 = ZeroPadding2D(padding=6)\r\n    conv6 = Conv2D(1024, kernel_size=3, dilation_rate=6)\r\n    conv7 = Conv2D(1024, kernel_size=1)\r\n    layers += [pad5, pool5, pad6, conv6,\r\n               ReLU(), conv7, ReLU()]\r\n    return layers\r\n\r\ndef create_feature_pyramid(cfg, size=300):\r\n    layers = []\r\n    # in_channels = i\r\n    flag = False\r\n    for k, v in enumerate(cfg):\r\n        if k==0 or in_channels != 'S':\r\n            if v == 'S':\r\n                layers += [ZeroPadding2D(padding=1), Conv2D(cfg[k + 1], kernel_size=(1, 3)[flag], strides=2)]\r\n            else:\r\n                layers += [Conv2D(v, kernel_size=(1, 3)[flag])]\r\n            flag = not flag\r\n        in_channels = v\r\n    if size == 512:\r\n        layers.append(Conv2D(128, kernel_size=1, strides=1))\r\n        layers.append(ZeroPadding2D(padding=1))\r\n        layers.append(Conv2D(256, kernel_size=4, strides=1))\r\n    return layers\r\n\r\ndef create_head(cfg, num_classes):\r\n    reg_layers  = []\r\n    cls_layers = []\r\n    for num_bboxes in cfg:\r\n        cls_layers.append(Sequential([ZeroPadding2D(padding=1), Conv2D(num_bboxes * num_classes, kernel_size=3)]))\r\n        reg_layers.append(Sequential([ZeroPadding2D(padding=1), Conv2D(num_bboxes * 4, kernel_size=3)]))\r\n    head = {'reg': reg_layers, 'cls': cls_layers}\r\n\r\n    return head\r\n\r\nclass L2Norm(Layer):\r\n    def __init__(self, in_channels, scale):\r\n        super(L2Norm, self).__init__()\r\n        self.in_channels = in_channels\r\n        self.gamma = scale or None\r\n        self.eps = 1e-10\r\n        self.w = self.add_weight(\r\n            name='w',\r\n            shape=(self.in_channels,),\r\n            initializer=tf.constant_initializer(20),\r\n            trainable=True,\r\n            dtype=self.dtype\r\n        )\r\n\r\n    def call(self, x):\r\n        norm = tf.sqrt(tf.reduce_sum(tf.pow(x, 2), axis=3, keepdims=True)) + self.eps\r\n        x = tf.truediv(x, norm)\r\n        out = self.w * x\r\n\r\n        return out\r\n\r\nclass VGG(Model):\r\n    def __init__(self):\r\n        super(VGG, self).__init__()\r\n        self.feature_extractor = create_feature_extractor(feature_extractor_config['300'])\r\n        self.l2_norm = L2Norm(512, scale=20)\r\n        self.feature_pyramid = create_feature_pyramid(feature_pyramid_config['300'], size=300)\r\n        self.num_classes = 21\r\n\r\n        self.head = create_head(head_config['300'], self.num_classes)\r\n\r\n\r\n    def call(self, x):\r\n        n, h, w, c = x.shape\r\n        features = []\r\n        for i in range(34):\r\n            x = self.feature_extractor[i](x)\r\n        s = self.l2_norm(x)\r\n\r\n        features.append(s)\r\n\r\n        for i in range(34, len(self.feature_extractor)):\r\n            x = self.feature_extractor[i](x)\r\n        features.append(x)\r\n\r\n        for k, v in enumerate(self.feature_pyramid):\r\n            x = tf.nn.relu(v(x))\r\n            if k in [2,5,7,9]:\r\n                features.append(x)\r\n\r\n        regressions = []\r\n        classifications = []\r\n\r\n        for k, v in enumerate(features):\r\n            regressions.append(tf.reshape(self.head['reg'][k](v), [32, -1, 4]))\r\n            classifications.append(tf.reshape(self.head['cls'][k](v), [32, -1, self.num_classes]))\r\n\r\n        regressions = tf.concat(regressions, axis=1)\r\n        classifications = tf.concat(classifications, axis=1)\r\n\r\n        return [regressions, classifications]\r\nmodel = VGG()\r\n\r\noptimizer = tf.keras.optimizers.Adam()\r\n\r\n\r\nsmooth_l1_loss = tf.keras.losses.Huber(\r\n    delta=1.0, reduction=tf.keras.losses.Reduction.NONE\r\n)\r\n\r\nce_loss = tf.keras.losses.CategoricalCrossentropy(\r\n    from_logits=True, label_smoothing=0, reduction=tf.keras.losses.Reduction.NONE\r\n)\r\n\r\n@tf.function\r\ndef train_step(input_imgs, target_bboxes, target_labels):\r\n    outputs = model(input_imgs)\r\n\r\n    regressions = outputs[0]\r\n    classifications = outputs[1]\r\n\r\n    pos_mask = target_labels > 0\r\n    neg_mask = target_labels == 0\r\n    num_pos = tf.reduce_sum(tf.cast(pos_mask, tf.float32))\r\n\r\n    predicted_bboxes = regressions[pos_mask]\r\n    target_bboxes = target_bboxes[pos_mask]\r\n\r\n    bbox_loss = tf.reduce_sum(smooth_l1_loss(target_bboxes, predicted_bboxes))\r\n\r\n    cls_loss = ce_loss(tf.one_hot(tf.cast(target_labels, tf.int32), classifications.shape[2]), classifications)\r\n\r\n    pos_cls_loss = cls_loss[pos_mask]\r\n    neg_cls_loss = cls_loss[neg_mask]\r\n    neg_cls_loss = tf.sort(neg_cls_loss, direction=\"DESCENDING\")\r\n    neg_cls_loss = neg_cls_loss[: 3 * tf.cast(num_pos, tf.int32)]\r\n\r\n    cls_loss = tf.reduce_sum(\r\n        tf.reduce_sum(pos_cls_loss) + tf.reduce_sum(neg_cls_loss)\r\n    )\r\n    loss = bbox_loss + cls_loss\r\n    loss = loss / num_pos\r\n\r\n    gradients = tf.gradients(loss, model.trainable_variables)\r\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\nwhile True:\r\n    imgs = tf.random.uniform((32, 300, 300, 3), minval=0, maxval=255)\r\n    img_bboxes = tf.random.uniform((32, 8732, 4), minval=0, maxval=1)\r\n    img_labels = tf.random.uniform((32, 8732), minval=0, maxval=21, dtype=tf.int32)\r\n    train_step(imgs, img_bboxes, img_labels)\r\n\r\n```\r\n\r\n\r\n\r\n**Other info / logs**\r\n\r\n```\r\n2020-01-30 14:48:46.435271: I tensorflow/core/common_runtime/bfc_allocator.cc:962] Sum Total of in-use chunks: 6.86GiB\r\n2020-01-30 14:48:46.435308: I tensorflow/core/common_runtime/bfc_allocator.cc:964] total_region_allocated_bytes_: 7510566400 memory_limit_: 7510566502 available bytes: 102 curr_region_allocation_bytes_: 15021133312\r\n2020-01-30 14:48:46.435336: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Stats:\r\nLimit:                  7510566502\r\nInUse:                  7367076608\r\nMaxInUse:               7509992704\r\nNumAllocs:                    2794\r\nMaxAllocSize:           3335127040\r\n\r\n2020-01-30 14:48:46.435424: W tensorflow/core/common_runtime/bfc_allocator.cc:429] ****************************************************************************************************\r\n2020-01-30 14:48:46.435484: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at slice_op.cc:154 : Resource exhausted: OOM when allocating tensor with shape[32,512,38,38] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n2020-01-30 14:48:46.435548: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Resource exhausted: OOM when allocating tensor with shape[32,512,38,38] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node gradients/vgg/sequential/zero_padding2d_18/Pad_grad/Slice_1}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\nTraceback (most recent call last):\r\n  File \"mve.py\", line 327, in <module>\r\n    train_step(imgs, img_bboxes, img_labels)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 599, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 2363, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 545, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[32,512,38,38] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node gradients/vgg/sequential/zero_padding2d_18/Pad_grad/Slice_1 (defined at mve.py:304) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n [Op:__inference_train_step_5034]\r\n\r\nFunction call stack:\r\ntrain_step\r\n\r\n```\r\n\r\n", "comments": ["@ymodak @gadagashwini I realized that manually padding with ZeroPadding2D layer makes the model consumes more memory than when using the implicit `padding` in `Conv2D` or `MaxPool2D`, i.e. Conv2D(..., padding='same'). This should be a bug! There is no reason why manually padding should consume more memory.\r\n\r\nManually padding is required in many situations because TF does not support symmetric padding, the one used by PyTorch and Caffe.", "If you can visualize the performance by using TensorBoard's Profile Plugin and share results that will be great.\r\nSee[ Profiling Tool.](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras) \r\nThanks!", "It has been 33 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36337\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36337\">No</a>\n"]}, {"number": 36336, "title": "Problem with build_rpi_lib.sh", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\nPRETTY_NAME=\"Raspbian GNU/Linux 9 (stretch)\"\r\nNAME=\"Raspbian GNU/Linux\"\r\nVERSION_ID=\"9\"\r\nVERSION=\"9 (stretch)\"\r\nVERSION_CODENAME=stretch\r\nID=raspbian\r\nID_LIKE=debian\r\nHOME_URL=\"http://www.raspbian.org/\"\r\nSUPPORT_URL=\"http://www.raspbian.org/RaspbianForums\"\r\nBUG_REPORT_URL=\"http://www.raspbian.org/RaspbianBugs\"\r\n\r\nDevice - Raspberry Pi 3B\r\n- TensorFlow clonned from git hub:\r\n- GCC/Compiler version (if compiling from source): 6.3.0 20170519\r\n\r\n**Describe the problem**\r\n\r\nI am following the example to build the raspberry pi version of the Tensorflow Lite C++ library and the build script fails and the pi locks up and requires a hard reset.  There are numerous warnings displayed when the build script runs.  The last warning shown is: .tensorflow/lite/kernels/cpu_backend_gemm_customer_gemv.h:500:13 warning: attributes at the beginning of statement are ignored [-Wattribute] [[clang::fallthrough]];\r\n\r\nAny help appreciated\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@apostrophesoftware \r\nCan you please go through the [link](https://www.tensorflow.org/lite/guide/build_rpi) and see if it helps you. Thanks!", "Hello @ravikyram the link you specified is to the same page that I was using so this will not help\r\nThanks", "\"build script fails and the pi locks up and requires a hard reset\" doesn't look like S/W issue. Considering that compiling takes more power, I'm wondering if you're using official power supply which gives at least 2.5A current.\r\nI had a similar experience with 1.0A power supply.", "Sorry I disagree, there are numerous warnings displayed.  Meaning there are clearly things the compiler does not like!\r\n\r\nI am also using an official raspberry pi power supply and have never seen a problem like this before", "Compiler warning doesn't make system look up. Compiler just generates object files by reading source files with CPU computation. So there is nothing harm to system.\r\n\r\nFortunately, I could reproduce this problem. It works well with RPI4 but RPI3 has the problem.\r\nThe reason is RPI3 only has 1GB memory while RPI4 has 4GB memory.\r\nSo the system frozen happens by out of system memory.\r\n\r\nThere are several solutions you can choose.\r\n1. Just build it on your workstation and copy binary.\r\nYou don't need to use RPI device to build TFLite. You can cross build RPI binary on your powerful workstation.\r\n2. Configure Swap on your RPI device.\r\nThe virtual memory can workaround your issue but it'll super slow due to [thrashing](https://en.wikipedia.org/wiki/Thrashing_(computer_science)).\r\n3. Build with single job\r\nThe script tensorflow/lite/tools/make/build_rpi_lib.sh has the following line.\r\n`\r\nmake -j 4 TARGET=rpi -C \"${TENSORFLOW_DIR}\" -f tensorflow/lite/tools/make/Makefile\r\n`\r\nUsing \"-j 4\" consumes 4 times more memory and it's not efficient when you don't have enough memory. You should remove the option.\r\n`\r\nmake TARGET=rpi -C \"${TENSORFLOW_DIR}\" -f tensorflow/lite/tools/make/Makefile\r\n`\r\n                                                                                \r\n\r\n\r\n", "I'd better update the script. Let me handle it."]}, {"number": 36335, "title": "[MLIR][XLA] Remove redundant LHLO CopyOp", "body": "The redundant LHLO CopyOp that copies an allocated buffer to a block argument is removed. The uses of the allocated buffer are replaced with the block argument. The associated Alloc and Dealloc are removed.", "comments": ["@dfki-ehna can you please include test cases around the new changes ?", "@pifon2a can you please merge this change internally.", "We have addressed all the comments in the new [PR](https://github.com/tensorflow/tensorflow/pull/37022).", "(GitHub does not let me answer inline apparently)\r\n\r\n> Although this code could exist from a theoretical point of view as an input program, the current implementation of the HLO-to-LHLO-Legalization pass ensures that there will always be a dealloc.\r\n\r\nI think this hits a principle of development for MLIR passes: the only invariant you can assume on your input is that the verifier is passing. It isn't allowed to crash on random vali input, we should be able to fuzz your pass safely (you can gracefully signal a pass failure and return though)\r\n"]}, {"number": 36334, "title": "Fix grammar", "body": "Fix grammar for the comments of `experimental_relax_shapes`", "comments": ["We will not be encouraging one liner grammatical changes as this is expensive process, please try to include more changes if possible., thank you\r\nCC @mihaimaruseac @chanshah", "Can you please try to fix multiple issues in the file? To justify spending hours of CI.", "@Rholais Any update on this PR, please. Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 36333, "title": "Fixed inconsistencies between int and int32_t type uses", "body": "Inconsistencies threw errors when building TFlite micro for STM32 project.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36333) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!\r\n", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36333) for more info**.\n\n<!-- ok -->"]}, {"number": 36332, "title": "Fit method printout is broken in version 2.1 ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MACOS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.4\r\n\r\n** Info **\r\nThe out-prints of in the fit method in version 2.0:\r\n<img width=\"1440\" alt=\"Screen Shot 2020-01-30 at 11 08 16\" src=\"https://user-images.githubusercontent.com/38648402/73436454-36441700-4353-11ea-86e1-7ff0023ae0b1.png\">\r\n\r\nThe out-prints of in the fit method in version 2.1:\r\n<img width=\"1440\" alt=\"Screen Shot 2020-01-30 at 11 11 07\" src=\"https://user-images.githubusercontent.com/38648402/73436538-5d024d80-4353-11ea-8fcb-d40560a2f79d.png\">\r\n\r\nWatch the output of the first epoch (the line, not the values), it prints Epcoh1/3 at the end of the line.\r\n\r\n\r\n", "comments": ["@OmerLiberman \r\n\r\nCan you please provide the simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "@OmerLiberman \r\n\r\nAny update on this issue please. Thanks!", "The output is:\r\n\r\n```\r\n13m 43s | 220 | Epoch 1/3\r\n-- | -- | --\r\n13m 43s | 221 | 2020-02-13 08:01:22.217883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n13m 43s | 222 | 2020-02-13 08:01:22.788927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n15m 55s | 223 | 1/82 [..............................] - ETA: 13:15 - loss: 4.1689 - accuracy: 0.4919\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 2/82 [..............................] - ETA: 9:49 - loss: 9.9026 - accuracy: 0.4879 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3/82 [>.............................] - ETA: 7:48 - loss: 8.2984 - accuracy: 0.4960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 4/82 [>.............................] - ETA: 6:46 - loss: 6.5161 - accuracy: 0.5544\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 5/82 [>.............................] - ETA: 5:59 - loss: 5.7836 - accuracy: 0.5597\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 6/82 [=>............................] - ETA: 5:16 - loss: 5.0436 - accuracy: 0.5847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 7/82 [=>............................] - ETA: 4:33 - loss: 4.3812 - accuracy: 0.6244\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 8/82 [=>............................] - ETA: 4:10 - loss: 3.9348 - accuracy: 0.6462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 9/82 [==>...........................] - ETA: 3:51 - loss: 3.6170 - accuracy: 0.6541\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10/82 [==>...........................] - ETA: 3:36 - loss: 3.3158 - accuracy: 0.6702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11/82 [===>..........................] - ETA: 3:23 - loss: 3.0370 - accuracy: 0.6906\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12/82 [===>..........................] - ETA: 3:13 - loss: 2.8060 - accuracy: 0.7077\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13/82 [===>..........................] - ETA: 3:03 - loss: 2.6200 - accuracy: 0.7205\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14/82 [====>.........................] - ETA: 2:55 - loss: 2.4594 - accuracy: 0.7327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15/82 [====>.........................] - ETA: 2:48 - loss: 2.3163 - accuracy: 0.7430\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16/82 [====>.........................] - ETA: 2:41 - loss: 2.1798 - accuracy: 0.7558\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17/82 [=====>........................] - ETA: 2:35 - loss: 2.0598 - accuracy: 0.7673\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18/82 [=====>........................] - ETA: 2:30 - loss: 1.9513 - accuracy: 0.7780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19/82 [=====>........................] - ETA: 2:25 - loss: 1.8566 - accuracy: 0.7867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/82 [======>.......................] - ETA: 2:20 - loss: 1.7731 - accuracy: 0.7944\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21/82 [======>.......................] - ETA: 2:16 - loss: 1.6957 - accuracy: 0.8015\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22/82 [=======>......................] - ETA: 2:11 - loss: 1.6245 - accuracy: 0.8090\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23/82 [=======>......................] - ETA: 2:07 - loss: 1.5569 - accuracy: 0.8161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24/82 [=======>......................] - ETA: 2:04 - loss: 1.4935 - accuracy: 0.8233\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25/82 [========>.....................] - ETA: 2:00 - loss: 1.4365 - accuracy: 0.8298\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26/82 [========>.....................] - ETA: 1:57 - loss: 1.3848 - accuracy: 0.8353\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27/82 [========>.....................] - ETA: 1:53 - loss: 1.3362 - accuracy: 0.8407\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28/82 [=========>....................] - ETA: 1:50 - loss: 1.2914 - accuracy: 0.8453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29/82 [=========>....................] - ETA: 1:47 - loss: 1.2492 - accuracy: 0.8497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30/82 [=========>....................] - ETA: 1:44 - loss: 1.2095 - accuracy: 0.8540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31/82 [==========>...................] - ETA: 1:41 - loss: 1.1723 - accuracy: 0.8582\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32/82 [==========>...................] - ETA: 1:39 - loss: 1.1365 - accuracy: 0.8624\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33/82 [===========>..................] - ETA: 1:36 - loss: 1.1026 - accuracy: 0.8664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34/82 [===========>..................] - ETA: 1:33 - loss: 1.0706 - accuracy: 0.8703\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35/82 [===========>..................] - ETA: 1:31 - loss: 1.0406 - accuracy: 0.8737\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36/82 [============>.................] - ETA: 1:28 - loss: 1.0124 - accuracy: 0.8770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37/82 [============>.................] - ETA: 1:26 - loss: 0.9857 - accuracy: 0.8800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38/82 [============>.................] - ETA: 1:24 - loss: 0.9603 - accuracy: 0.8829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39/82 [=============>................] - ETA: 1:21 - loss: 0.9367 - accuracy: 0.8854\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40/82 [=============>................] - ETA: 1:19 - loss: 0.9137 - accuracy: 0.8882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41/82 [==============>...............] - ETA: 1:17 - loss: 0.8918 - accuracy: 0.8907\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42/82 [==============>...............] - ETA: 1:14 - loss: 0.8708 - accuracy: 0.8933\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43/82 [==============>...............] - ETA: 1:12 - loss: 0.8510 - accuracy: 0.8956\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44/82 [===============>..............] - ETA: 1:10 - loss: 0.8318 - accuracy: 0.8980\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45/82 [===============>..............] - ETA: 1:08 - loss: 0.8134 - accuracy: 0.9002\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46/82 [===============>..............] - ETA: 1:06 - loss: 0.7960 - accuracy: 0.9023\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47/82 [================>.............] - ETA: 1:04 - loss: 0.7793 - accuracy: 0.9043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48/82 [================>.............] - ETA: 1:02 - loss: 0.7634 - accuracy: 0.9061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49/82 [================>.............] - ETA: 1:00 - loss: 0.7479 - accuracy: 0.9080\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50/82 [=================>............] - ETA: 58s - loss: 0.7331 - accuracy: 0.9098 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51/82 [=================>............] - ETA: 56s - loss: 0.7188 - accuracy: 0.9116\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52/82 [==================>...........] - ETA: 54s - loss: 0.7051 - accuracy: 0.9132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53/82 [==================>...........] - ETA: 52s - loss: 0.6919 - accuracy: 0.9149\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54/82 [==================>...........] - ETA: 50s - loss: 0.6792 - accuracy: 0.9164\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55/82 [===================>..........] - ETA: 48s - loss: 0.6669 - accuracy: 0.9180\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56/82 [===================>..........] - ETA: 46s - loss: 0.6550 - accuracy: 0.9194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57/82 [===================>..........] - ETA: 44s - loss: 0.6436 - accuracy: 0.9208\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58/82 [====================>.........] - ETA: 42s - loss: 0.6326 - accuracy: 0.9222\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59/82 [====================>.........] - ETA: 40s - loss: 0.6219 - accuracy: 0.9235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60/82 [====================>.........] - ETA: 38s - loss: 0.6116 - accuracy: 0.9248\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61/82 [=====================>........] - ETA: 37s - loss: 0.6016 - accuracy: 0.9260\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62/82 [=====================>........] - ETA: 35s - loss: 0.5919 - accuracy: 0.9272\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63/82 [======================>.......] - ETA: 33s - loss: 0.5825 - accuracy: 0.9284\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64/82 [======================>.......] - ETA: 31s - loss: 0.5735 - accuracy: 0.9295\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65/82 [======================>.......] - ETA: 29s - loss: 0.5647 - accuracy: 0.9306\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66/82 [=======================>......] - ETA: 27s - loss: 0.5561 - accuracy: 0.9316\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67/82 [=======================>......] - ETA: 26s - loss: 0.5478 - accuracy: 0.9327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68/82 [=======================>......] - ETA: 24s - loss: 0.5398 - accuracy: 0.9336\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69/82 [========================>.....] - ETA: 22s - loss: 0.5320 - accuracy: 0.9346\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70/82 [========================>.....] - ETA: 20s - loss: 0.5245 - accuracy: 0.9355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71/82 [========================>.....] - ETA: 19s - loss: 0.5171 - accuracy: 0.9364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72/82 [=========================>....] - ETA: 17s - loss: 0.5099 - accuracy: 0.9373\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73/82 [=========================>....] - ETA: 15s - loss: 0.5030 - accuracy: 0.9382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74/82 [==========================>...] - ETA: 13s - loss: 0.4962 - accuracy: 0.9390\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75/82 [==========================>...] - ETA: 12s - loss: 0.4896 - accuracy: 0.9398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76/82 [==========================>...] - ETA: 10s - loss: 0.4831 - accuracy: 0.9406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77/82 [===========================>..] - ETA: 8s - loss: 0.4769 - accuracy: 0.9414 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78/82 [===========================>..] - ETA: 6s - loss: 0.4708 - accuracy: 0.9422\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79/82 [===========================>..] - ETA: 5s - loss: 0.4648 - accuracy: 0.9429\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80/82 [============================>.] - ETA: 3s - loss: 0.4591 - accuracy: 0.9436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81/82 [============================>.] - ETA: 1s - loss: 0.4534 - accuracy: 0.9443Epoch 1/3\r\n16m 5s | 224 | 1/82 [..............................] - ETA: 2:30 - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 2/82 [..............................] - ETA: 1:19 - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3/82 [>.............................] - ETA: 1:02 - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 4/82 [>.............................] - ETA: 54s - loss: 0.1519 - accuracy: 0.9516 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 5/82 [>.............................] - ETA: 48s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 6/82 [=>............................] - ETA: 45s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 7/82 [=>............................] - ETA: 42s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 8/82 [=>............................] - ETA: 40s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 9/82 [==>...........................] - ETA: 38s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10/82 [==>...........................] - ETA: 37s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11/82 [===>..........................] - ETA: 36s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12/82 [===>..........................] - ETA: 34s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13/82 [===>..........................] - ETA: 33s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14/82 [====>.........................] - ETA: 33s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15/82 [====>.........................] - ETA: 32s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16/82 [====>.........................] - ETA: 31s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17/82 [=====>........................] - ETA: 30s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18/82 [=====>........................] - ETA: 29s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19/82 [=====>........................] - ETA: 29s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/82 [======>.......................] - ETA: 28s - loss: 0.1519 - accuracy: 0.9516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82/82 [==============================] - 148s 2s/step - loss: 0.4479 - accuracy: 0.9450 - val_loss: 0.1519 - val_accuracy: 0.9516\r\n16m 5s | 225 | Epoch 2/3\r\n\r\n```\r\n\r\nWatch the \"Epoch ..\" printed out.", "**The code I use:**\r\n\r\n**for creating the image generator**\r\n`\r\ndef __load_train_and_val_generators(data, image_size, val_size, image_color, batch_size, class_mode, classes):\r\n\tdata_gen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=val_size)\r\n\ttrain_gen = data_gen.flow_from_directory(\r\n\t\tdata,\r\n\t\tcolor_mode=image_color,\r\n\t\ttarget_size=image_size,\r\n\t\tbatch_size=batch_size,\r\n\t\tclass_mode=class_mode,\r\n\t\tsubset='training',\r\n\t\tclasses=classes,\r\n\t\tshuffle=True)\r\n\tval_gen = data_gen.flow_from_directory(\r\n\t\tdata,\r\n\t\tcolor_mode=image_color,\r\n\t\ttarget_size=image_size,\r\n\t\tbatch_size=batch_size,\r\n\t\tclass_mode=class_mode,\r\n\t\tsubset='validation',\r\n\t\tclasses=classes,\r\n\t\tshuffle=True)\r\n\treturn train_gen, val_gen\r\n`\r\n\r\n**for running the training:**\r\n\r\n`\r\n\tdef __train(self):\r\n\t\ttrain_generator, val_generator = load_generator(self.__arguments.data, self.__shape,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.__arguments.test_size, self.__arguments.image_color,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.__arguments.batch_size)\r\n\t\tsteps_per_epoch_training = train_generator.n // self.__arguments.epochs\r\n\t\tsteps_per_epoch_validation = val_generator.n // self.__arguments.epochs\r\n\r\n\t\tstart_time = time.time()\r\n\t\tprint(\"---start training---\")\r\n\t\tself.__model.fit(train_generator,\r\n\t\t\t\t\t\tepochs=self.__arguments.epochs,\r\n\t\t\t\t\t\tworkers=TensorflowTrainer.WORKERS,\r\n\t\t\t\t\t\tverbose=TensorflowTrainer.VERBOSE,\r\n\t\t\t\t\t\tsteps_per_epoch=steps_per_epoch_training,\r\n\t\t\t\t\t\tvalidation_data=val_generator,\r\n\t\t\t\t\t\tvalidation_steps=steps_per_epoch_validation)\r\n\t\tprint(\"---End training---\")\r\n\t\ttraining_time = time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time))\r\n\t\tself.__metrics['training_time'] = training_time\r\n`\r\n\r\n**Tensorflow version in use : 2.1.0**", "@ravikyram \r\nsorry for the delay, \r\nfinals at school.\r\n", "@OmerLiberman \r\n\r\nWill it be possible to share colab link or simple standalone code with  proper indentation to reproduce the issue in our environment. It helps in localizing the issue faster. Thanks!", "@ravikyram  \r\ntake this code : https://github.com/OmerLiberman/tf_2.0.1\r\n\r\nrun the file '''resnet50.py''' with '''--data=PATH\" \r\nwhere PATH is a path to a local directory with with images splitted to single class in each sub-directory.", "I am trying to debug it. \r\nIt is in the method: \r\n```\r\ndef model_iteration(...):\r\n```\r\n\r\nwhich is in :\r\n```\r\ntensorflow_core/python/keras/engine/training_generator.py", "check the methods:\r\n\r\n```\r\ndef on_epoch_end(...)\r\n```\r\n\r\nin ```tensorflow.python.keras.callbacks.py```", "check:\r\n\r\nIn:  ```tensorflow_core/python/keras/engine/training_generator.py```\r\nrow num 293: ```batch_logs = cbks.make_logs(model, batch_logs, batch_outs, mode)```\r\n\r\nIt happens in the last epoch", "Have you fixed the bug?", "@ravikyram \r\n![a](https://user-images.githubusercontent.com/38648402/75961905-8589e400-5ecb-11ea-9a4c-a6f2981b6357.png)\r\n", "problem was found: \r\n<img width=\"1440\" alt=\"Screen Shot 2020-03-05 at 11 44 35\" src=\"https://user-images.githubusercontent.com/38648402/75968871-c2a7a380-5ed6-11ea-824e-1071aae460b6.png\">\r\n\r\nit enters this line at the end of the epoch ", "Can you please reproduce it and share it on [colab] as I am not able to find your gist @OmerLiberman. Thanks!", "@OmerLiberman please use ` ``` `, not  just one backtick around the code blocks (and definitely not images)", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@OmerLiberman \r\n\r\nAny update on this issue please. Thanks!", "Tried to reproduce this issue using tensorflow 2.2.0rc2 but I am not running into any issues as mentioned above. Please find the github [gist](https://colab.sandbox.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/overview.ipynb#scrollTo=I7BcMHkB0E2U). Thanks!", "Closing this issue as it has been inactive for more than 3 weeks. Please add additional comments for us to open this issue again. Thanks!"]}, {"number": 36331, "title": "Got Warning : Disabling AVX support in Mac OSX Catalina", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOSX 10.15.3 (Catalina)\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 2.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 1.2.1\r\n- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.17) \r\n\r\n**Describe the problem**\r\n\r\nHi, I got so many warning when building TensorFlow in Macosx Catalina with AVX2 Enabled, I got warning like this : \r\n\r\n> 1 warning generated.\r\nINFO: From Compiling tensorflow/core/grappler/utils/functions.cc [for host]:\r\nIn file included from tensorflow/core/grappler/utils/functions.cc:15:\r\nIn file included from ./tensorflow/core/grappler/utils/functions.h:26:\r\nIn file included from ./tensorflow/core/framework/function.h:28:\r\nIn file included from ./tensorflow/core/framework/attr_value_util.h:23:\r\nIn file included from ./tensorflow/core/framework/partial_tensor_shape.h:20:\r\nIn file included from ./tensorflow/core/framework/tensor_shape.h:21:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14:\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:22:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/ConfigureVectorization.h:300:10: warning: \"Disabling AVX support: clang compiler shipped with XCode 11.[012] generates broken assembly with -macosx-version-min=10.15 and AVX enabled. \" [-W#warnings]\r\n        #warning \"Disabling AVX support: clang compiler shipped with XCode 11.[012] generates broken assembly with -macosx-version-min=10.15 and AVX enabled. \"\r\n         ^\r\n1 warning generated.\r\n\r\nDoes anyone know what is the root cause of this problem? thank you\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n- bazel build --config=opt --config=mkl --copt=-mavx2 //tensorflow/tools/lib_package:libtensorflow\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I am facing the same warning. Any news? \r\n\r\n**System information**\r\nXCode: Xcode 11.2.1\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOSX 10.15.3 (Catalina)\r\nTensorFlow installed from (source or binary): Source\r\nTensorFlow version: 2.0\r\nPython version: Python 3.7.3\r\nInstalled using virtualenv? pip? conda?: yes virtualenv\r\nBazel version (if compiling from source): bazel 2.0.0\r\nGCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.12)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n- ./configure -> Only with python3 path to virtualenv\r\n- bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n**Edit:**\r\nJust saw this post: https://www.logcg.com/en/archives/3283.html, claiming that it does not effect the result. Can sbdy verify that? ", "> Just saw this post: https://www.logcg.com/en/archives/3283.html, claiming that it does not effect the result. Can sbdy verify that?\r\n\r\nThe link you posted reported the same warning as well. Compiling with AVX was skipped, but it does not hurt to compile with non-vector ISA.", "The warning messages come form the Eigen library.\r\nThe warning message shows that AVX instructions of the Eigen library are disabled.\r\n\r\nThere are no plans to fix the Eigen library.because the Eigen library can work well in OSX 10.14.\r\nIt is a bug of clang in OSX 10.15 instead of the Eigen library.\r\n\r\n[Disable AVX on broken xcode versions. See PR 748](https://gitlab.stce.rwth-aachen.de/stce/eigen-ad/commit/71aa53dd6dfdc497324d9e87f59c4ba820191856)\r\n[PR 748: BUG: Xcode 11.0 with default -macosx-version-min=10.15 seg faults](http://manao.inria.fr/eigen_tmp/pullrequests/748/)\r\n\r\nThe best practice for AVX enabled in OSX could be as the following.\r\n1. staying in OSX 10.14.\r\n2. adding  '-mmacosx-version-min=10.14' to '--config=opt', when running './configure' to setup the building environment.\r\n3. using 'bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package' to rebuild the source code of TensorFlow.\r\n\r\n```\r\n~/tensorflow/ $ ./configure\r\n.....\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: -mmacosx-version-min=10.14\r\n......\r\n~/tensorflow/ $ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n~/tensorflow/ $ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n~/tensorflow/ $ mv /tmp/tensorflow_pkg/tensorflow-2.1.0-cp37-cp37m-macosx_10_14_x86_64.whl /tmp/tensorflow_pkg/tensorflow-2.1.0-cp37-cp37m-macosx_10_14_x86_64.whl\r\n~/tensorflow/ $ pip install --force-reinstall /tmp/tensorflow_pkg/tensorflow-2.1.0-cp37-cp37m-macosx_10_14_x86_64.whl\r\n```", "@mesmerli \r\nI used your steps but still see binaru for 10-15 getting created.\r\n ```\r\nls -lrt /tmp/tensorflow_pkg/\r\ntotal 395264\r\n-rw-r--r--  1 xxx  wheel  196530925 May  4 09:25 tensorflow-2.2.0rc4-cp36-cp36m-macosx_10_15_x86_64.whl \r\n```\r\n\r\n```\r\ncat .tf_configure.bazelrc \r\nbuild --action_env PYTHON_BIN_PATH=\"/Users/vikumar/anaconda3/envs/tb2-2/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/Users/vikumar/anaconda3/envs/tb2-2/lib/python3.6/site-packages\"\r\nbuild --python_path=\"/Users/vikumar/anaconda3/envs/tb2-2/bin/python\"\r\nbuild --config=xla\r\nbuild:opt --copt=-g\r\nbuild:opt --copt=-mmacosx-version-min=10.14\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac,-oss_serial\r\ntest:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac\r\ntest:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac,-oss_serial,-v1only\r\ntest:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac,-v1only\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\r\n```\r\nCommand I used was - \r\n`bazel build --config=opt --copt=-g //tensorflow/tools/pip_package:build_pip_package`\r\nI have macOS 10.14(mojave) and building from rc2.2 branch. Xcode is 11.3.1 .  After spending 3-4 days of time, I am completely stuck here.\r\n\r\nportion of logs, when building wheel file, comes from xla_ops.so - \r\n`build/bdist.macosx-10.9-x86_64/wheel/tensorflow/python/profiler/internal/_pywrap_profiler.so\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/python/profiler/internal/_pywrap_traceme.so\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/lite/python/optimize/_tensorflow_lite_wrap_calibration_wrapper.so\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/compiler/tf2tensorrt/_wrap_py_utils.so\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/compiler/tf2xla/ops/_xla_ops.so[WARNING] This wheel needs a higher macOS version than is set in MACOSX_DEPLOYMENT_TARGET variable.  To silence this warning, set MACOSX_DEPLOYMENT_TARGET to at least 10_15 or recreate these files with lower MACOSX_DEPLOYMENT_TARGET:  \r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/libtensorflow_framework.2.2.0.dylib\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/libtensorflow_framework.2.dylib\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/libtensorflow_framework.dylib\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/python/_dtypes.so\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/python/_pywrap_bfloat16.so\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/python/_op_def_registry.so\r\nbuild/bdist.macosx-10.9-x86_64/wheel/tensorflow/python/_pywrap_tfe.so\r\n`\r\nSome more logs warning which might be relevant -\r\n```\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/ConfigureVectorization.h:300:10: warning: \"Disabling AVX support: clang compiler shipped with XCode 11.[012] generates broken assembly with -macosx-version-min=10.15 and AVX enabled. \" [-W#warnings]\r\n        #warning \"Disabling AVX support: clang compiler shipped with XCode 11.[012] generates broken assembly with -macosx-version-min=10.15 and AVX enabled. \"\r\n```\r\nCan there be inherently something hardcoded in one of the build files that is causing it to build for 10.15?", "@mania25,\r\n\r\nWe are checking to see if you still need help on this issue. Can you try building latest stable version i.e `TF 2.6.0` from source using this [guide](https://www.tensorflow.org/install/source) for MacOS, and let us know if the issue still persists in newer versions.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36331\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36331\">No</a>\n"]}, {"number": 36330, "title": "How to profile GPU memory usage in TF2.0?", "body": "How to profile GPU memory usage in TF2.0?\r\n\r\nSince TF hogs the entire GPU or requires user to pre-allocate a fixed amount GPU memory, I am not able to know what is the exact memory usage. This is a problem when I need to know which part of my code is using too much memory.", "comments": ["@yxchng,\r\nCould you please check [this](https://stackoverflow.com/questions/36123740/is-there-a-way-of-determining-how-much-gpu-memory-is-in-use-by-tensorflow) similar StackOverflow issue and let us know if it helps? \r\n\r\nYou can also take a look at TensorBoard Profiling tool from [here](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras). Thanks!", "@amahendrakar Solutions presented in link you linked here are all for TF 1.0. The functions used are not working in TF 2.0.", "You can use `Profiler` Option of Tensorboard. Please find this [Stack Overflow Answer](https://stackoverflow.com/a/56698035/11530462) for more info. If the issue still persists, please provide a code snippet to reproduce the issue reported here. Thanks!", "@yxchng,\r\nAny updates regarding this issue? Thanks!", "@yxchng  Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 36329, "title": "OpenBLASS for efficient Matrix multiplications?", "body": "**System information**\r\n- TensorFlow version (you are using): TFLite micro (on ESP32)\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behaviour/state.**\r\n\r\nThe major CPU intensive function here are Convolution functions! Which are nothing but Large Matrix multiplications.\r\nFor Face detection example on ESP32, I have seen that it is the major contributor at more than 50% of total CPU eaten by example.\r\n\r\n[OpenBLASS](https://github.com/xianyi/OpenBLAS) is open implementation of [BLASS](http://www.netlib.org/blas/) library which is optimised version of large Matrix multiplications which takes into account Cache availability of system etc.\r\n\r\nAre there any plans to use this in TensorFlow?\r\n\r\n\r\n**Will this change the current api? How?**\r\n\r\nNeed to explore this, but it should most likely not affect existing APIs but shall change the implementations of few functions.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAll the platforms for which OpenBLASS is optimized to including x86 platforms, ARM, MIPS etc.\r\n\r\n**Any Other info.**\r\n\r\nLinks:\r\nhttp://www.netlib.org/blas/\r\nhttps://github.com/xianyi/OpenBLAS\r\n", "comments": ["Hi Vikram,\r\n\r\nAdding optimization path to TFLM is more than welcomed! I'm not familiar with OpenBLASS myself, a few questions:\r\n\r\n- Does it requires dynamic memory allocation?\r\n- What's the size for  statically linked library?\r\n- What are the hardware supported by OpenBLASS? I guess ESP32?\r\n\r\nThanks,", "Doesnt tensorflow already uses BLAS for dot products?\r\nWhat algorithm is used in tensorflow for convolutions? Im2Col? Winograd?", "@vikramdattu,\r\nSorry for the delayed response. Currently, most of the operations are handled by [cuDNN, cuBLAS, cuFFT, etc..](https://github.com/tensorflow/tensorflow/search?l=Markdown&q=cublas). Can you please let us know how **`OpenBLASS`** is efficient over them? Thanks!", "I think it's okay to close the issue.\nCode already is using some neat tricks, especially platform specific optimizations."]}, {"number": 36328, "title": "Error while saving transformer example to SavedModel ", "body": "**System information**\r\n- OS Platform and Distribution : Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: tf-nightly (2.2.0.dev20200123)\r\n- Python version: 3.7.4\r\n- Installed using virtualenv? pip? conda?: pip3\r\n- Bazel version (if compiling from source):  N/A\r\n- GCC/Compiler version (if compiling from source):  N/A\r\n- CUDA/cuDNN version:  N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\nHello, \r\n\r\nI am following transformer example:\r\nhttps://www.tensorflow.org/tutorials/text/transformer\r\n\r\n\r\nIt is working as expected and saving checkpoint as well, and I want to now save this to SavedModel.\r\n\r\nHere is my source code (attached as zip):\r\n[transformer.zip](https://github.com/tensorflow/tensorflow/files/4132379/transformer.zip)\r\n\r\nor same code in colab:\r\nhttps://colab.research.google.com/drive/1MMhRMICpzDwpP5OLNTWHfgXaZ20ckqfL\r\n\r\nCommand to run the code: \r\n```\r\npython3 transformer.py\r\n```\r\n\r\nBut I am getting this error: \r\n```Traceback (most recent call last):\r\n  File \"transformer.py\", line 860, in <module>\r\n    transformer.save(\"/tmp/savedmodel\", save_format=\"tf\")\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1029, in save\r\n    signatures, options)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 138, in save_model\r\n    signatures, options)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 925, in save\r\n    checkpoint_graph_view)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_serialization.py\", line 74, in find_function_to_export\r\n    functions = saveable_view.list_functions(saveable_view.root)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 142, in list_functions\r\n    self._serialization_cache)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2532, in _list_functions_for_serialization\r\n    .list_functions_for_serialization(serialization_cache))\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py\", line 91, in list_functions_for_serialization\r\n    fns = self.functions_to_serialize(serialization_cache)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 79, in functions_to_serialize\r\n    serialization_cache).functions_to_serialize)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 94, in _get_serialized_attributes\r\n    serialization_cache)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py\", line 47, in _get_serialized_attributes_internal\r\n    default_signature = save_impl.default_save_signature(self.obj)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py\", line 211, in default_save_signature\r\n    fn.get_concrete_function()\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 948, in get_concrete_function\r\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 854, in _get_concrete_function_garbage_collected\r\n    self._initialize(args, kwargs, add_initializers_to=initializers)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 500, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2440, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2771, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2661, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 439, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saving_utils.py\", line 150, in _wrapped_model\r\n    outputs_list = nest.flatten(model(inputs, training=False))\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 793, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 308, in wrapper\r\n    return func(*args, **kwargs)\r\nTypeError: call() missing 4 required positional arguments: 'tar', 'enc_padding_mask', 'look_ahead_mask', and 'dec_padding_mask'\r\n```\r\n", "comments": ["I have tried on colab with TF version 2.2.0-dev20200129 and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/f6d370dc3aafab9e134e8724f72e35f5/untitled605.ipynb#scrollTo=JJ4LZ2SRhk9e). Thanks!", "I changed my code a little to use  transformer.call()  directly (in training_step function):\r\n```\r\n  with tf.GradientTape() as tape:\r\n    predictions, _ = transformer.call(inp, tar_inp,\r\n                                 True,\r\n                                 enc_padding_mask,\r\n                                 combined_mask,\r\n                                 dec_padding_mask)\r\n    loss = loss_function(tar_real, predictions)\r\n```\r\n\r\nand I'm now getting a different error: \r\n```\r\n---------------------------------------------------------------------------------------------------------------------\r\nModel Summary\r\n\r\n---------------------------------------------------------------------------\r\n\r\nValueError                                Traceback (most recent call last)\r\n\r\n<ipython-input-2-d2fd7d3ad3dd> in <module>()\r\n    794 \r\n    795 print(\"Model Summary\")\r\n--> 796 transformer.summary()\r\n    797 \r\n    798 #translate(\"este \u00e9 um problema que temos que resolver.\")\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py in summary(self, line_length, positions, print_fn)\r\n   1325     \"\"\"\r\n   1326     if not self.built:\r\n-> 1327       raise ValueError('This model has not yet been built. '\r\n   1328                        'Build the model first by calling `build()` or calling '\r\n   1329                        '`fit()` with some data, or specify '\r\n\r\nValueError: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.\r\n```\r\n\r\nI'm not sure if it's a correct usage that directly using obj.call() method here, rather than using object name only. I wonder what's the difference between them.  \r\nAlso, why it says \"model has not yet built\" after training is done? \r\n", "For saving tensorflow checkpoints you may use `tf.keras.Model.save_weights` method instead.\r\n```python\r\ntransformer.save_weights(checkpoint_path)\r\n```\r\nSee https://www.tensorflow.org/guide/checkpoint#saving_from_tfkeras_training_apis", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36328\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36328\">No</a>\n", "HI! I am still struggling with the same problem, any recommendations? Tried to reload at the test time using checkpoints alone but looks like the purpose of tf.train.Checkpoint is only for training. and not for inferencing.\r\n\r\nLooking for a solution for the above problem", "The tutorial has moved to here: https://www.tensorflow.org/text/tutorials/transformer\r\n\r\nI believe keras Models assume the user passes one \"nest\" (see tf.nest) of inputs as the first argument.\r\n\r\nThe solution here will either be:\r\n\r\n1 - Use tf.Module instead\r\n2 - rearrange the `__call__` arguments from: \r\n\r\n```\r\n  def __call__(self, inp, tar, training, enc_padding_mask,\r\n           look_ahead_mask, dec_padding_mask):\r\n      ...\r\n```\r\n\r\nto:\r\n\r\n```\r\n  def __call__(self, inputs, training):\r\n      inp, tar, enc_padding_mask, look_ahead_mask, dec_padding_mask = inputs\r\n```", "That commit 9b85e7e fixes it. \r\n\r\nIt was just a matter of packing the tensor-inputs into a list for the `model.call`.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36328\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36328\">No</a>\n"]}, {"number": 36326, "title": "[INTEL MKL] DNNL1.x integration for tf_conv_ops.h and transpose.cc", "body": "DNNL1.x integration for tf_conv_ops.h and transpose.cc", "comments": ["@penpornk Gentle reminder for review.", "@penpornk done the changes.", "@penpornk Done."]}, {"number": 36325, "title": "[core] scatter_op: Remove duplicate check for IsScalar()", "body": "Remove duplicate check.", "comments": []}, {"number": 36324, "title": "[compiler] Simplify the expression for check batch size modified", "body": "Logical expression reduction.\r\n\r\n(!batch_size_is_defined ||  (batch_size_is_defined && size[0] != input_dims[0]));\r\nis logically equivalent to => \r\n(!batch_size_is_defined || size[0] != input_dims[0]);\r\n\r\nlike !A || (A && B) <=> !A || B\r\n\r\nSame for the other change.", "comments": ["Would you please provide a description on the PR, such as what problem it is trying to fix? The only difference this change would make is when input_dims[0] <= 0, IIUC.", "@bixia1 , thanks for the review. Sorry about that. Updated.", "@bixia1 Thank you. Done."]}, {"number": 36323, "title": "This part of code on `self.save_weights_only` is not necessary", "body": "In [tensorflow/tensorflow/python/keras/callbacks.py ](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/callbacks.py#L813-L1166), this part of code on `self.save_weights_only` is not necessary:\r\n```\r\n    # Use name matching rather than `isinstance` to avoid circular dependencies.\r\n    if (not self.save_weights_only and\r\n        not model._is_graph_network and  # pylint: disable=protected-access\r\n        model.__class__.__name__ != 'Sequential'):\r\n      self.save_weights_only = True\r\n```\r\nBecause when the argument `save_weights_only` is `True`, no matter what the model._is_graph_network is and no matter what model.__class__.__name__ is 'Sequential' or not,  `self.save_weights_only` will always be `True`.\r\n\r\nI am not sure if I am right. So, if you disagree with me, please explain it detaily. \r\n", "comments": ["@Ordgod,\r\nCode says even though `save_weights_only = False`, but if `model._is_graph_network = False` and if it `not a Sequential Model`, then **only Weights will be Saved**.\r\n\r\nIf I understand the Code and your explanation correctly, Code demonstrates the Case of  `save_weights_only = False` and your explanation is about `save_weights_only = True`. \r\n\r\nPlease correct me if I am wrong. Thanks!", "@Ordgod,\r\nCan you please respond to the above comment. Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 36322, "title": "[tf_micro] Allow toolchain for generated projects to be set in makefile", "body": "* toolchain_prefix and toolchain_root are now filled in the makefile template when supplied\r\n* adding a library compile option to the makefile template", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36322) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36322) for more info**.\n\n<!-- ok -->", "I'm working on being able to generate projects that compile after being generated. This allows us to set the compiler paths from the makefile.inc of the targets, so that when they are generated the makefile includes the correct compiler.\r\n\r\n\r\n\r\n", "@petewarden commit updated."]}, {"number": 36321, "title": "The shape of Tensors is UNKNOWN after batching in graph mode. ", "body": "\r\n**System information**\r\n- Have I written custom code: YES\r\n- OS Platform and Distribution: Google Colab\r\n- TensorFlow installed from: Preinstalled in Colab\r\n- TensorFlow version: v2.1.0-0-ge5bf8de410 2.1.0\r\n- Python version: sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\r\n\r\n**Describe the current behavior**\r\n\r\nThe shape of tensors is unknown when batching dataset in the graph mode. In the eager mode, the shape is know.\r\n\r\nSee the colab: https://colab.research.google.com/drive/1jfRaXtJXCgTSav3hvvE1RqUZ4FRyZ8fb\r\n\r\n**Describe the expected behavior**\r\n\r\nShape should be known in both eager and graph mode.\r\n\r\n**Code to reproduce the issue**\r\n\r\nhttps://colab.research.google.com/drive/1jfRaXtJXCgTSav3hvvE1RqUZ4FRyZ8fb", "comments": ["This is a not a bug.\r\nIn the graph mode, you have to use tf.shape(tensor) to return a shape tensor which won't be known until it really runs.", "I include additional details to show the full extend of the problem. Tensorflow layers cannot operate on Tensors with unknown shapes. For example, if I call the LSTM layer on the top of the Tensor with an unknown shape I get the error below. I have extended the Colab to include this error. The example is shown in the Colab cell named _Problems in application of Tensors with unknow shape._\r\n\r\n    <ipython-input-32-bd24e1627452>:12 iterate  *\r\n        for inputs in ds:\r\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py:662 scan_body\r\n        body(iterate)\r\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/layers/recurrent.py:644 __call__\r\n        return super(RNN, self).__call__(inputs, **kwargs)\r\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py:737 __call__\r\n        self.name)\r\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/input_spec.py:165 assert_input_compatibility\r\n        layer_name + ' is incompatible with the layer: '\r\n\r\n    ValueError: Input 0 of layer lstm_27 is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.", "@konopik You need to provide `output_shapes` parameter when you use `from_generator`.  TensorFlow has no idea what the shapes will be unless output_shapes is specified as the generator is never iterated over. Check [`from_generator`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator) documentation.\r\n\r\nI changed one line in your code from \r\n\r\n`ds = tf.data.Dataset.from_generator(ds_gen, output_types=tf.float3`2)\r\n\r\nto \r\n\r\n`ds = tf.data.Dataset.from_generator(ds_gen, output_types=tf.float32,output_shapes=(2,5))`\r\n\r\nThen everything worked as expected. [Here is the gist](https://colab.research.google.com/gist/jvishnuvardhan/adf0d7c32c1823a1d4d5655813b3c0bf/dataset-batching.ipynb) for your reference. \r\n\r\nI am closing this issue as it was resolved. Feel free to reopen if the issue persists again. Thanks for the nice colab example.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36321\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36321\">No</a>\n"]}, {"number": 36320, "title": " How to replace a layer of a compiled Keras' model ", "body": "I'm in tensorflow 1.14\r\nHow can I replace a layer in a Keras model? My new layer has a different output size so set_weights doesn't work.", "comments": ["@JoaoLages  Please provide details about what platform you are using (operating system, architecture) Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command[code] if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "I'm running it on Ubuntu 18.04.1 LTS. Just regularly intalled with `pip  install tensorflow==1.14`\r\n\r\nWhat I am doing now is:\r\n```\r\naux_model.load_weights(pretrained_weights_path)\r\n\r\nassert len(aux_model.get_weights()) == len(model.get_weights()), \\\r\n            \"unexpected different number of layers between new model and pretrained model\"\r\n\r\nnew_weights = [\r\n            x if x.shape == y.shape else y  # change every weight besides the output layer, which has a different shape\r\n            for x, y in zip(aux_model.get_weights(), model.get_weights())\r\n        ]\r\nmodel.set_weights(new_weights)\r\n```\r\n\r\nAnd that's all because there is 1 layer that has a different shape, so I can't just call `load_weights`...", "@JoaoLages code provided is not sufficient to replicate the issue faced by you, please provide complete code so we could help you.", "```from keras.models import Sequential\r\nfrom keras.layers import Dense, Activation\r\n\r\nmodel = Sequential([\r\n    Dense(32, input_shape=(784,)),\r\n    Activation('relu'),\r\n    Dense(10),\r\n    Activation('softmax'),\r\n])\r\nmodel.save_weights('weights.hdf5')\r\nnew_model = Sequential([\r\n    Dense(32, input_shape=(784,)),\r\n    Activation('relu'),\r\n    Dense(5),\r\n    Activation('softmax'),\r\n])\r\nnew_model.load_weights('weights.hdf5')\r\n```\r\n\r\nThis yields an error: `ValueError: Dimension 1 in both shapes must be equal, but are 5 and 10. Shapes are [32,5] and [32,10]. for 'Assign_2' (op: 'Assign') with input shapes: [32,5], [32,10].`\r\n\r\nIt could easily just load the weights that had the same shape. **I know** that an alternative would be to name all the layers the same, besides the last one. But it isnt in my case", "I think this [issue](https://stackoverflow.com/questions/43714713/modify-keras-model-after-training) would be very helpful in your case.\r\n\r\nYou can first add a layer and save the weights of all the layers using the code below\r\n`temp_weights = [layer.get_weights() for layer in model.layers]` and then load the individual layer weights into your model and train it again.\r\n", "@gowthamkpr exactly. but that's the problem. I need to load the weights one by one and match them. very unpractical when I could just load the weights and disregard the ones that dont match in length (same as we disregard with different names)", "@JoaoLages I think for your use-case, the only way to achieve what you want is by \r\n\r\n`new_model.load_weights('weights.hdf5', skip_mismatch=True, by_name=True)`\r\n\r\nPlease take a look at the gist [here](https://colab.research.google.com/gist/jvishnuvardhan/8361406a71273b4c703d16b727180f55/untitled.ipynb). Good thing with this approach is it is clearly warns the user which layers have mismatch as shown below.\r\n\r\n> WARNING:tensorflow:Skipping loading of weights for layer Dense2 due to mismatch in shape ((32, 5) vs (32, 10)).\r\n> WARNING:tensorflow:Skipping loading of weights for layer Dense2 due to mismatch in shape ((5,) vs (10,)).\r\n\r\n\r\nPlease note that if we load weights even when there is a mismatch, it could adversely affect other TF users. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this as this issue was resolved with the above comment. Please feel free to reopen if I am mistaken. Thanks!"]}, {"number": 36319, "title": "How do I create multiple custom AUC metrics, one for each of the outputs, in TensorFlow?", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: macOS Catalina (Version: 10.15.2 (19C57))\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.1\r\n- Python version: 3.7.5\r\n- GPU model and memory: Intel Iris Pro 1536 MB\r\n\r\n**Describe the current behavior**\r\n\r\nI get several errors, which are all described in [this Stack Overflow question](https://stackoverflow.com/q/59958089/3924118). In particular, I get the following error.\r\n\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (strided_slice_1:0) = ] [0.590847135 0.745689 0.524460673...] [y (Cast_1/x:0) = ] [0]\r\n\t [[{{node metrics/custom_auc_2/StatefulPartitionedCall/assert_greater_equal/Assert/AssertGuard/else/_79/Assert}}]] [Op:__inference_keras_scratch_graph_1129]\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nNo error.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\ndef get_model(num_inputs, num_outputs):\r\n    from keras.layers import Dense, Input\r\n    from keras.models import Model\r\n\r\n    inputs = Input((num_inputs,))\r\n    outputs = Dense(num_outputs)(inputs)\r\n    return Model(inputs, outputs)\r\n\r\n\r\ndef get_custom_auc(output):\r\n    import tensorflow as tf\r\n\r\n    # I may also want to use other metrics other than AUC (e.g. BinaryAccuracy).\r\n    auc = tf.metrics.AUC()\r\n\r\n    @tf.function\r\n    def custom_auc(y_true, y_pred):\r\n        y_true = y_true[:, output]\r\n        y_pred = y_pred[:, output]\r\n        auc.update_state(y_true, y_pred)\r\n        return auc.result()\r\n\r\n    custom_auc.__name__ = \"custom_auc_\" + str(output)\r\n    return custom_auc\r\n\r\n\r\ndef train():\r\n    import numpy as np\r\n\r\n    num_inputs = 5\r\n   \r\n    # I want to implement an AUC metric for each of these outputs SEPARATELY.\r\n    num_outputs = 3 \r\n\r\n    num_examples = 10\r\n\r\n    model = get_model(num_inputs, num_outputs)\r\n\r\n    # Create a separate AUC metric for each of the outputs.\r\n    metrics = [get_custom_auc(m) for m in range(num_outputs)]\r\n\r\n    # I want to visualize the metrics for each of the outputs (separately) during training.\r\n    model.compile(loss='mse', metrics=metrics, optimizer='adam')\r\n\r\n    print(model.metrics)\r\n\r\n    # Error occurs when calling fit.\r\n    model.fit(np.random.rand(num_examples, num_inputs), np.zeros((num_examples, num_outputs)))\r\n\r\n\r\nif __name__ == '__main__':\r\n    train()\r\n```\r\n\r\n**Other info / logs**\r\n\r\nIn [this Stack Overflow question](https://stackoverflow.com/q/59958089/3924118), I am describing my problem and my attempts to solve it. Please, have a look at it. I've tried other solutions, including implementing a custom class for this metric, but I am getting other errors (as described in the question). Ultimately, I just want to solve my problem, while keeping the use of `compile` and `fit` to train the model (as I dislike custom training loops and I want to keep it as simple as possible).\r\n", "comments": ["I was able to reproduce the issue on colab with Tf2.1.\r\nPlease find the gist [here](https://colab.research.google.com/gist/gadagashwini/368cc6e810c6332f328a44b33c28b688/untitled368.ipynb). Thanks!", "This issue persists on tf 2.6, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/84ada542be689c9fa15f2bf75d86355b/untitled604.ipynb). Thanks!", "@nbro Looks like the above model in your code has single output.  If you want to define separate metric and loss for each output, then you can follow [this guide](https://www.tensorflow.org/guide/keras/functional#models_with_multiple_inputs_and_outputs). \r\n\r\nMay be [this](https://github.com/tensorflow/tensorflow/issues/48038#issuecomment-820647223) or [this](https://github.com/tensorflow/tensorflow/issues/34199#issuecomment-592691772) might help. Please let us know how it progresses. Thanks!\r\n\r\n![my_first_model_with_shape_info (1)](https://user-images.githubusercontent.com/46058173/118873165-452f3f80-b89e-11eb-9105-765d2f897ed6.png)\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36319\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36319\">No</a>\n", "> @nbro Looks like the above model in your code has single output. If you want to define separate metric and loss for each output, then you can follow [this guide](https://www.tensorflow.org/guide/keras/functional#models_with_multiple_inputs_and_outputs).\r\n> \r\n> May be [this](https://github.com/tensorflow/tensorflow/issues/48038#issuecomment-820647223) or [this](https://github.com/tensorflow/tensorflow/issues/34199#issuecomment-592691772) might help. Please let us know how it progresses. Thanks!\r\n> \r\n> ![my_first_model_with_shape_info (1)](https://user-images.githubusercontent.com/46058173/118873165-452f3f80-b89e-11eb-9105-765d2f897ed6.png)\r\n\r\nIn the guide , how to set metrics for each output ```priority``` and ```department``` ?"]}, {"number": 36318, "title": "installation of CUDA documentation", "body": "Hi, \r\n\r\nTwo important lines are missing from the suggested CUDA >=10 installation scripts: \r\n\r\n```\r\nsudo add-apt-repository ppa:graphics-drivers/ppa\r\nsudo add-apt-repository \"deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/ /\"\r\n```\r\n", "comments": ["@Jordy-VL \r\n\r\nPlease, follow the below steps to install CUDA 10. Thanks!\r\n\r\nwget https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64\r\n\r\nsudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64\r\nsudo apt-key add /var/cuda-repo-<version>/7fa2af80.pub\r\nsudo apt-get update\r\nsudo apt-get install cuda", "@Jordy-VL , Please take a look at [this documentation](https://github.com/ashutosh1919/FaceGenerationStyleGAN/blob/master/CUDA_INSTALLATION_INSTRUCTIONS.md). Hope it helps.", "@Jordy-VL \r\n\r\nAny update on this issue please. Thanks!", "Hi, \r\nI was succesful in installing CUDA. I was more referring to the buggy installation instructions on https://www.tensorflow.org/install/gpu#install_cuda_with_apt. \r\nThese should be updated to account for adding the apt source explicitly, otherwise the package will not be updated when running \"apt-get update\"."]}, {"number": 36317, "title": "[XLA] Change the default SM in XLA.", "body": "It is better to use the most recent SM then an old one. The SM have always been backward compatible.", "comments": ["LGTM. :-)"]}, {"number": 36316, "title": "Pad keras.backend.ctc_decode output to consistent shape", "body": "Closes https://github.com/tensorflow/tensorflow/issues/35799\r\n\r\nThis PR does the following:\r\n\r\n- Fixes the `keras.backend.ctc_decode` function by having it return dense shapes defined by the input shape (with -1 used as the padding value, as documented) rather than by the length of decoded sequences in a given batch\r\n- Edits the associated unit test to expect padded outputs, and\r\n- Updates the function docstring to specify the shape for returned sequences.", "comments": ["Looks like I made a formatting mistake. I just fixed it. Sorry about that."]}, {"number": 36315, "title": "added 3 macro multilabel metrics", "body": "I added three MulitLabel specific metrics based off of issues:\r\n\r\n- https://github.com/tensorflow/tensorflow/issues/28074\r\n- https://github.com/tensorflow/tensorflow/issues/33636\r\n\r\nFollowing the code (see my comment on [28074](https://github.com/tensorflow/tensorflow/issues/28074#issuecomment-545376593)) reveals that there is already an argument `multi_label` but\r\n\r\n1. as addressed in both referenced issues above, depending on the users loss function the existing metrics may not be usable, and\r\n2. the choice not to expose `multi_label` may have been deliberate (I have found no documentation regarding this). Introducing it may have cascading effects (e.g. perhaps it is not fully implemented). \r\n\r\n", "comments": ["For new metrics we recommend that you add them to the TensorFlow addons repository first. Based on usage/demand we can later move them to the core repo.", "Closing based on @pavithrasv comments, thank you", "@pavithrasv fair enough, but then update https://www.tensorflow.org/community/contribute/code#contribution_workflow accordingly"]}, {"number": 36314, "title": "Empty step_stats from context.export_run_metadata() in TF 2.1", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n\r\nAs sessions are no more available in TF 2 API we are using `context.enable_run_metadata()` and `context.export_run_metadata()` to accure `run_metadata.step_stats` which then we feed to `timeline.Timeliner` to export tracing information about session execution and visualise it usgin chrome://tracing. This approch worked well with TF 2.0 but once we updated to 2.1 `run_metadata.step_stats` appears to be empty.\r\n\r\nHere is code which acquires and prints step stats:\r\nTF 2.0: https://colab.research.google.com/drive/1Jsk7Dn_gTd3xCTTxgQPx3bJvza4oRu1t\r\nTF 2.1: https://colab.research.google.com/drive/1JQ7rqyH5VOAmpHbjMuLGYLwU9dJ7xwk2\r\n\r\nI know that according to docs we should use `summary.trace_on` or `profiler_client .start_tracing` to acquire tracing information, however, there is seems an issue with GPU tracing https://github.com/tensorflow/tensorflow/issues/34844", "comments": ["Was able to reproduce the issue with [TF 2.0](https://colab.sandbox.google.com/gist/amahendrakar/3dab2da9961c6834738404f87f7f4deb/36314_2-0.ipynb), [TF 2.1](https://colab.sandbox.google.com/gist/amahendrakar/b8b246d084c420e8ef224879dc45182d/36314_2-1.ipynb) and [TF nightly](https://colab.sandbox.google.com/gist/amahendrakar/0461a8d5f0df8ee909c2fa395df9f546/36314_nightly.ipynb). Please find the attached Gists. Thanks!", "probably a duplicate of 34844\r\ncan you make sure that running \"!ldconfig -p | grep cupti\" in your colab?", "Here is the output of `!ldconfig -p | grep cupti`\r\n```\r\nlibcupti.so.10.1 (libc6,x86-64) => /usr/local/cuda-10.1/extras/CUPTI/lib64/libcupti.so.10.1\r\nlibcupti.so (libc6,x86-64) => /usr/local/cuda-10.1/extras/CUPTI/lib64/libcupti.so\r\n```\r\nSo seems 34844 has been already fixed in colab\r\nBut no step stats\r\nAnyway after using fix from 34844 we are able to get GPU profile using tensorboard, so this issue is not so critical anymore at least for us (yet traces converted from step_stats are more informative then those in tensorboard)", "unfortunately, profiler team don't support step_stats anymore in favor of new \"tf 2.0 profiler\".\r\n", "We have just released a new profiler in TF 2.2 rc0.\r\nhttps://tensorflow.org/guide/profiler\r\nOne of the profiler output is trace.json.gz, that can be directly upload to chrome://tracing to visualize. \r\n\r\nPlease try if the new profiler fixes your issue. \r\nIf it doesn't, we will follow up with you.\r\n\r\nthanks", "@dtim1985  it seems the issue is resolved  with the update.Please feel free to reopen the issue if you still have a concern. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36314\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36314\">No</a>\n"]}]