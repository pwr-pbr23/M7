[{"number": 22366, "title": "Example problem in tf.reduce_sum function documentation", "body": "I'm not sure about registering an issue for an documentation error here, I found that the name of argument \"keep_dims\" on example of tf.reduce_sum is wrong.\r\n\r\nref: https://www.tensorflow.org/versions/r1.11/api_docs/python/tf/reduce_sum\r\n\r\nx = tf.constant([[1, 1, 1], [1, 1, 1]])\r\ntf.reduce_sum(x)  # 6\r\ntf.reduce_sum(x, 0)  # [2, 2, 2]\r\ntf.reduce_sum(x, 1)  # [3, 3]\r\ntf.reduce_sum(x, 1, **keepdims**=True)  # [[3], [3]]\r\ntf.reduce_sum(x, [0, 1])  # 6\r\n\r\n==>\r\n\r\nx = tf.constant([[1, 1, 1], [1, 1, 1]])\r\ntf.reduce_sum(x)  # 6\r\ntf.reduce_sum(x, 0)  # [2, 2, 2]\r\ntf.reduce_sum(x, 1)  # [3, 3]\r\ntf.reduce_sum(x, 1, **keep_dims**=True)  # [[3], [3]]\r\ntf.reduce_sum(x, [0, 1])  # 6\r\n\r\n", "comments": ["@dyanos Thank you for your post. The arg: keep_dims in tf.reduce_sum() is deprecated and will be removed from future versions of TensorFlow. Please use arg: **keepdims** instead. "]}, {"number": 22365, "title": "Inconsistency in shape of cell state in ConvLSTM cell rectified", "body": "Fixes issue #21400 : next_state in LSTMStateTuple of ConvLSTM cell should have shape (state_size, output_size) but found (state_size,state_size)", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "This is my first contribution. So I am curious to know how much time would it take to run the above checks.", "The lint is failing for this PR. Please fix the code accordingly. \r\n\r\nFAIL: Found 1 non-whitelited pylint errors:\r\ntensorflow/contrib/rnn/python/ops/rnn_cell.py:2102: [C0301(line-too-long), ] Line too long (82/80)\r\n\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 22364, "title": "Estimator with MirroredStrategy on multiple GPUs seems to start with non-initialized weights on one of the GPUs", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: slightly modified example code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: n/a\r\n- **TensorFlow installed from (source or binary)**: binary (pip)\r\n- **TensorFlow version (use command below)**: ('v1.10.1-0-g4dcfddc5d1', '1.10.1')\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: 9.0/7.1.4\r\n- **GPU model and memory**: GeForce GTX 1080\r\n- **Exact command to reproduce**:\r\n\r\nSlightly modified version of https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute#example-with-estimator-api to add some print nodes.\r\n\r\n```\r\n\r\n    import tensorflow as tf\r\n    \r\n    def build_model_fn_optimizer():\r\n\r\n        def model_fn(features, labels, mode):\r\n            features = tf.Print(features, [features], message=\"features = \")\r\n            layer = tf.layers.Dense(1, use_bias=True)\r\n            logits = layer(features)\r\n            logits = tf.Print(logits, [logits], message=\"logits = \")\r\n\r\n            if mode == tf.estimator.ModeKeys.PREDICT:\r\n                predictions = {\"logits\": logits}\r\n                return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n            loss = tf.losses.mean_squared_error(\r\n                labels=labels, predictions=tf.reshape(logits, []))\r\n\r\n            if mode == tf.estimator.ModeKeys.EVAL:\r\n                return tf.estimator.EstimatorSpec(mode, loss=loss)\r\n\r\n            if mode == tf.estimator.ModeKeys.TRAIN:\r\n                train_op = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\r\n                return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\n        return model_fn\r\n    \r\n    def main(_):\r\n        #distribution = tf.contrib.distribute.OneDeviceStrategy(\"/device:GPU:0\")\r\n        distribution = tf.contrib.distribute.MirroredStrategy(\r\n            [\"/device:GPU:0\", \"/device:GPU:1\"]\r\n        )\r\n        config = tf.estimator.RunConfig(train_distribute=distribution)\r\n    \r\n        def input_fn():\r\n            features = tf.data.Dataset.from_tensors([[1.]]).repeat(10)\r\n            labels = tf.data.Dataset.from_tensors(1.).repeat(10)\r\n            return tf.data.Dataset.zip((features, labels))\r\n    \r\n        estimator = tf.estimator.Estimator(\r\n            model_fn=build_model_fn_optimizer(), config=config)\r\n        estimator.train(input_fn=input_fn, steps=10)\r\n    \r\n        eval_result = estimator.evaluate(input_fn=input_fn, steps=10)\r\n        print(\"Eval result: {}\".format(eval_result))\r\n    \r\n        def predict_input_fn():\r\n            predict_features = tf.data.Dataset.from_tensors([[1.]]).repeat(10)\r\n            return predict_features\r\n    \r\n        predictions = estimator.predict(input_fn=predict_input_fn)\r\n        predictions = list(predictions)\r\n        print(\"Prediction results: {}\".format(predictions))\r\n    \r\n    \r\n    if __name__ == \"__main__\":\r\n        tf.app.run()\r\n\r\n```\r\n\r\nThe output I get is the following:\r\n\r\n    WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpygBKCI\r\n    INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3bd6649b90>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpygBKCI', '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f3bd6649b10>, '_save_summary_steps': 100}\r\n    2018-09-18 23:44:42.051140: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n    2018-09-18 23:44:42.244608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties:\r\n    name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\n    pciBusID: 0000:08:00.0\r\n    totalMemory: 10.92GiB freeMemory: 9.93GiB\r\n    2018-09-18 23:44:42.392404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n    2018-09-18 23:44:42.394060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 1 with properties:\r\n    name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\n    pciBusID: 0000:42:00.0\r\n    totalMemory: 10.92GiB freeMemory: 10.76GiB\r\n    2018-09-18 23:44:42.398325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\r\n    2018-09-18 23:44:42.808254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-09-18 23:44:42.808317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1\r\n    2018-09-18 23:44:42.808325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y\r\n    2018-09-18 23:44:42.808331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N\r\n    2018-09-18 23:44:42.808726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:0 with 9603 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\r\n    2018-09-18 23:44:42.887416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\r\n    INFO:tensorflow:Configured nccl all-reduce.\r\n    2018-09-18 23:44:42.999232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\r\n    2018-09-18 23:44:42.999351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-09-18 23:44:42.999364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1\r\n    2018-09-18 23:44:42.999371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y\r\n    2018-09-18 23:44:42.999379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N\r\n    2018-09-18 23:44:42.999591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9603 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\r\n    2018-09-18 23:44:42.999726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Calling model_fn.\r\n    INFO:tensorflow:Calling model_fn.\r\n    INFO:tensorflow:batch_all_reduce invoked for batches size = 2 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Create CheckpointSaverHook.\r\n    INFO:tensorflow:Graph was finalized.\r\n    2018-09-18 23:44:43.215770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\r\n    2018-09-18 23:44:43.215877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-09-18 23:44:43.215889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1\r\n    2018-09-18 23:44:43.215897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y\r\n    2018-09-18 23:44:43.215904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N\r\n    2018-09-18 23:44:43.216104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9603 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\r\n    2018-09-18 23:44:43.216251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Running local_init_op.\r\n    INFO:tensorflow:Done running local_init_op.\r\n    INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpygBKCI/model.ckpt.\r\n    features = [[1]]\r\n    logits = [[0]]\r\n    features = [[1]]\r\n    logits = [[-0.225562453]]\r\n    INFO:tensorflow:loss = 1.2510016, step = 0\r\n    features = [[1]]\r\n    logits = [[0]]\r\n    features = [[1]]\r\n    logits = [[0.6646626]]\r\n    features = [[1]]\r\n    features = [[1]]\r\n    logits = [[-5.94375372]]\r\n    logits = [[1.19879758]]\r\n    features = [[1]]\r\n    logits = [[-23.9573383]]\r\n    features = [[1]]\r\n    logits = [[3.89678]]\r\n    features = [[1]]\r\n    features = [[1]]\r\n    logits = [[-82.8739166]]\r\n    logits = [[12.7210035]]\r\n    INFO:tensorflow:Saving checkpoints for 5 into /tmp/tmpygBKCI/model.ckpt.\r\n    INFO:tensorflow:Loss for final step: 3586.108.\r\n    INFO:tensorflow:Calling model_fn.\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Starting evaluation at 2018-09-18-23:44:45\r\n    INFO:tensorflow:Graph was finalized.\r\n    2018-09-18 23:44:45.322872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\r\n    2018-09-18 23:44:45.322972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-09-18 23:44:45.322984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1\r\n    2018-09-18 23:44:45.322992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y\r\n    2018-09-18 23:44:45.323000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N\r\n    2018-09-18 23:44:45.323190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9603 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\r\n    2018-09-18 23:44:45.323319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Restoring parameters from /tmp/tmpygBKCI/model.ckpt-5\r\n    INFO:tensorflow:Running local_init_op.\r\n    INFO:tensorflow:Done running local_init_op.\r\n\r\nNotice that the logits comes out printed as zero the first and third time, which suggests the weights for at least one of the GPU towers is all zeroes at the start (or both are all zeros initially but the prints are showing up interwoven between the two towers).\r\n\r\nIf I run the code with just a single GPU using OneDeviceStrategy, this does not happen (first logit value printed out is non-zero due to random initial weights).\r\n\r\nThis affects training for more complicated scenarios since it could lead to incorrect loss computation.\r\n\r\nStill happens if I upgrade to TensorFlow 1.11.0-rc1 ('v1.11.0-rc1-0-ge4c4b20805').\r\n\r\nI posted on [StackOverflow](https://stackoverflow.com/questions/52396116/tensorflow-estimator-with-mirroredstrategy-on-multiple-gpus-seems-to-start-with) but also decided to open this issue since it seems somewhat similar to the variable initialization issue reported in #19069 which is supposedly fixed. If this is more appropriate on StackOverflow, I can wait for responses there. Thanks!\r\n", "comments": ["Priya, not sure who's best for MirroredStrategy. ", "Actually, I tried on 2 other machines (with multiple v100 GPUs and multiple p100 GPUs) and the issue doesn't reproduce there. So this could be something specific to my hardware or software setup for the particular machine above.", "Thanks for the update @kahkeng. Is this something we should investigate further ? ", "I think we can close this out, will re-open if this is still an issue, thanks!"]}, {"number": 22363, "title": "Fix Embedding layer to check invalid inputs", "body": "Bug: If users set ```input_length``` for ```Embedding``` layer incorrectly, it should throw exception(existing not). Otherwise, the downstream layers compute shape incorrect and throw confused exception.\r\nI have fixed this at https://github.com/keras-team/keras/pull/11091, but it's different from ```tf.keras```. ```keras-team/keras``` makes this check in ```compute_output_shape``` which was executed always. But ```tf.keras``` only calls ```compute_output_shape``` in deferred mode, so we need to move this check to other place. Actually it makes more sense to move it to ```_assert_input_compatibility``` which is used to check the inputs legal, and would be run in all mode.\r\n", "comments": ["@fchollet I have updated the PR according your review. Thanks.", "Just resolved the merge conflicts.", "Ping @fchollet for review.", "Nagging Reviewer @fchollet: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 59 days with no activity and the `awaiting review` label has been applied."]}, {"number": 22362, "title": "Impossible to initialize Variable, restored from a model, in Java API?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nN/A\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary via pom.xml:\r\n```\r\n<dependency>\r\n     <groupId>org.tensorflow</groupId>\r\n     <artifactId>libtensorflow</artifactId>\r\n     <version>1.10.0</version>\r\n </dependency>\r\n <dependency>\r\n     <groupId>org.tensorflow</groupId>\r\n     <artifactId>libtensorflow_jni_gpu</artifactId>\r\n     <version>1.10.0</version>\r\n </dependency>\r\n```\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.10.0\r\n- **Python version**:\r\nUsing Java\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\n9.0/7.0.5\r\n- **GPU model and memory**:\r\nGeForce GTX 750 Ti\r\n- **Exact command to reproduce**:\r\nN/A\r\n\r\n### Describe the problem\r\n\r\nTrying to run inference in Java from a restored model, getting:\r\n\r\n```java.lang.IllegalStateException: Attempting to use uninitialized value```\r\n\r\nSame thing works in Python.\r\n\r\nThe  model is not trivial - 2 stages with intermediate data stored in that uninitialized variable in GPU.\r\n\r\nTo workaround would like to initialize it. Looked through Operation and OperationBuilder classes - nothing.\r\n\r\nAble to get the variable using:\r\n```\r\nOperation ooyoo = bundle.graph().operation(\"rv_stage1_out\");\r\nSystem.out.println(ooyoo.toString());\r\nSystem.out.println(ooyoo.type());\r\n```\r\ngetting:\r\n```\r\n<VariableV2 'rv_stage1_out'>\r\nVariableV2\r\n```\r\n\r\nHow to assign?\r\n\r\n### Source code / logs\r\n[Code](https://git.elphel.com/Elphel/imagej-elphel/blob/gpu/src/main/java/TensorflowExamplePlugin.java)\r\n\r\nMore information as well as code and logs are posted on [Stackoverflow](https://stackoverflow.com/questions/52394799/tensorflow-1-10-0-java-api-java-lang-illegalstateexception-attempting-to-use-u).\r\n", "comments": ["Alright, I think I have found the solution. \r\nThat variable belonged to LOCAL_VARIABLES - adding to GLOBAL collection (in Python) and storing then restoring seems to have fixed the error. Meaning, in Java there might be only some kind of equivalent of a global initializer if applicable. Need to double test.", "I didn't get a chance to dig into the code linked to (there is a lot of it), but yeah, I'd also guess that there is some additional operation you're running to initialize variables in the Python side that isn't being run on the Java side.\r\n\r\nIf it is the local variables initializer, one option would be to provide `tf.local_variables_initializer()` as [the `main_op` or `legacy_init_op` to `SavedModelBuilder.add_meta_graph()`](https://www.tensorflow.org/api_docs/python/tf/saved_model/builder/SavedModelBuilder#add_meta_graph), so that the variables are initialized just when you load the program.\r\n\r\nIf you could provide a more compact reproduction, I'm happy to take a look. If not, I'll try to dig into the Python and Java code provided when I get a chance. Or if things have worked out, let me know and I'll close the issue (and feel free to add details here). Thanks. ", "Yes, that extra operation is:\r\n`sess.run(tf.local_variables_initializer())`\r\n\r\nJust tested - your suggestion works - Java will read the saved-in-python-model w/o errors:\r\n```python\r\nbuilder = tf.saved_model.builder.SavedModelBuilder('somedir')\r\nbuilder.add_meta_graph_and_variables(sess,[tf.saved_model.tag_constants.SERVING],main_op=tf.local_variables_initializer())\r\n# builder.add_meta_graph_and_variables(sess,[tf.saved_model.tag_constants.SERVING])\r\n# builder.save(True)\r\nbuilder.save(False) # True = *.pbtxt, False = *.pb\r\n```\r\nlog output:\r\n```\r\n2018-09-20 13:48:40.812262: I tensorflow/cc/saved_model/loader.cc:90] Running MainOp on SavedModel bundle.\r\n```\r\nThanks.\r\n"]}, {"number": 22361, "title": "Conv1d ops don't get quantized", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 2.7.10\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See below.\r\n\r\n### Describe the problem\r\n\r\nCurrently `tf.contrib.quantize.create_eval_graph` and `tf.contrib.quantize.create_training_graph` will create a quantized version of the graph if the graph contains 2d convolutions.  The pattern matching that these functions use breaks in the case of 1d convolutions, however.  This is because 1d convolutions are transformed to 2d convolutions under the hood with an `ExpandDims` Op, and this Op breaks the expected pattern of Ops used by `_FindLayersToQuantize`.\r\n\r\nIt would be great if the pattern in `_FindLayersToQuantize` could be changed from\r\n\r\n```\r\nweight|folded_weight --> conv|fc --> [batch_to_space_nd] --> ...\r\n```\r\n\r\nto\r\n\r\n```\r\nweight|folded_weight --> [expand_dims] --> conv|fc --> [batch_to_space_nd] --> ...\r\n```\r\n\r\nThis should allow conv1d ops to quantize exactly like conv2d ops.\r\n\r\n### Source code / logs\r\n\r\n```\r\n# Create and quantize a graph with 2d convolution.\r\nX = tf.placeholder(tf.float32, [None, 28, 28, 1])\r\nconv = tf.layers.conv2d(X, 64, 3, padding='same', activation=tf.nn.relu)\r\ntf.contrib.quantize.create_eval_graph()\r\nlen([n.name for n in tf.get_default_graph().as_graph_def().node if 'quant' in n.name]) > 0\r\n```\r\n\r\nThis should be `True`.\r\n\r\n```\r\n# Create and quantize a graph with 1d convolution.\r\nX = tf.placeholder(tf.float32, [None, 28, 1])\r\nconv = tf.layers.conv1d(X, 64, 3, padding='same', activation=tf.nn.relu)\r\ntf.contrib.quantize.create_eval_graph()\r\nlen([n.name for n in tf.get_default_graph().as_graph_def().node if 'quant' in n.name]) > 0\r\n```\r\n\r\nThis should be `False`.", "comments": ["@joe-antognini good point. Just ran the above code snippets and both returned True. For image quantization conv2d is typically used, e.g. in your example. conv1d essentially does the same thing here, unless you want to do text quantization which would require different methodology.", "Interesting, what version of Tensorflow did you run those snippets on?  I tried again and I still get `True` from the first snippet and `False` from the second.  The reason I'm interested in quantizing 1d convolution is for audio applications.", "1.10.0", "@wt-huang, just as a sanity check, did you reset the graph between running the two snippets?", "@joe-antognini I didn't reset the graph between two snippets.", "Ah, that would explain it then.  Sorry, I should have included that explicitly:\r\n\r\n```\r\n# Create and quantize a graph with 2d convolution.\r\nX = tf.placeholder(tf.float32, [None, 28, 28, 1])\r\nconv = tf.layers.conv2d(X, 64, 3, padding='same', activation=tf.nn.relu)\r\ntf.contrib.quantize.create_eval_graph()\r\nquantized = len([n.name for n in tf.get_default_graph().as_graph_def().node if 'quant' in n.name]) > 0\r\nprint('Quantization succeeded:', quantized)\r\n\r\ntf.reset_default_graph()\r\n\r\n# Create and quantize a graph with 1d convolution.\r\nX = tf.placeholder(tf.float32, [None, 28, 1])\r\nconv = tf.layers.conv1d(X, 64, 3, padding='same', activation=tf.nn.relu)\r\ntf.contrib.quantize.create_eval_graph()\r\nquantized = len([n.name for n in tf.get_default_graph().as_graph_def().node if 'quant' in n.name]) > 0\r\nprint('Quantization succeeded:', quantized)\r\n```", "@joe-antognini Thanks for the clarification. In your case, expand_dims may not be the best solution as it only changes the shape by adding 1 to dimensions. You can use `tf.Variable` and `tf.reshape` to convert 1D filter to 2D then use `tf.layers.conv2d` for quantization when working with actual graph.", "Nagging Assignee @wt-huang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Will close this issue soon, chime in if this problem persists."]}, {"number": 22360, "title": "Op type not registered 'TRTEngineOp' in binary running with C API", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: r1.11\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: 5.4\r\n- **CUDA/cuDNN version**: 9/7.1\r\n- **GPU model and memory**: 1080ti/11gb\r\n- **Exact command to reproduce**: \r\n1. Clone tensorflow repo, checkout r1.11 branch\r\n2. Build from source as directed from documentation by disabling everything except cuda, tensorrt(4.0.1.6)\r\n3. Create a tensorrt .pb file using following:\r\n```\r\n    trt_graph = trt.create_inference_graph(\r\n    input_graph_def=tf.get_default_graph().as_graph_def(),\r\n    outputs=output_node,\r\n    max_batch_size=1,\r\n    max_workspace_size_bytes=1 << 25,\r\n    precision_mode=\"FP32\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\r\n    minimum_segment_size=2  # minimum number of nodes in an engine\r\n    )\r\n    f = open(\"trt.pb\", 'w')\r\n    f.write(trt_graph.SerializeToString())\r\n    f.close()\r\n\r\n```\r\n4. Use Tensorflow C API to run infernce on the protobuf file\r\n\r\nFull Error:\r\n2018-09-18 14:21:41.085891: E tensorflow/core/framework/op_kernel.cc:1197] OpKernel ('op: \"TRTEngineOp\" device_type: \"GPU\"') for unknown op: TRTEngineOp\r\ncheck_status: Caused by: Add graph to TF session: Not found: Op type not registered 'TRTEngineOp' in binary running on dhingratul-Workstation. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n\r\n\r\nRelated issue: #22005 , except I am using the latest version of tensorflow and tensorRT. I have also tried the workarounds mentioned [here](https://stackoverflow.com/questions/50125889/c-tensorflow-api-with-tensorrt), but don't work.\r\n \r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I was able to make the TF_LoadLibrary workaround work with r1.11", "I faced the same problem and solved it with  adding  \"import tensorflow.contrib.tensorrt \" in the code", "@cheneyoung HI, did you use the C API for tensorflow with the tensorrt optimized protobuf? Did you see a speedup there?"]}, {"number": 22357, "title": "Make NVIDIA library versions to TF Version matrix more visible.", "body": "This request was a product of the TensorFlow Fall Symposium. Consider talking to the documentation team as well as maybe linking it to the top or near the top of all the release documents.  ", "comments": ["This is a shared task/issue.", "@lamberta to discuss where \"minimum requirements\" would fit best.", "Now that the GPU info is on one page: https://www.tensorflow.org/install/gpu\r\nI'd like to keep this in one place so that it's easy to update and stays in sync. There are currently sections for *hardware requirements* and *software requirements*, can we add a table there?\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/install/gpu.md", "I like the idea. ", "Related: b/117278293", "Seem good to me, you could put it on the linux page but you could argue the link to the install page is also fine.  I am closing.  Feel free to reopen. \r\nhttps://www.tensorflow.org/install/source#linux\r\n\r\n"]}, {"number": 22356, "title": "Document DistributionStrategies including how it can be extended.", "body": "This request was a product of the TensorFlow Fall Symposium.  It might be nice to start with a simple block diagram and then go deeper with the objective to show companies, individual, and academics how they can extend DistributionStrategies at various points.\r\n\r\nPicking a random person from the tf-dist-strat team to start.", "comments": ["This looks interesting. Looking forward to a SIG in distributed training.", "Stale"]}, {"number": 22355, "title": "Bazel build fails for r1.11", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.4\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.11\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: 0.15.2-homebrew\\\r\n- **CUDA/cuDNN version**:  I use CPU-only tensorflow version\r\n- **GPU model and memory**: Intel Iris Graphics 6100 / 1536 MB\r\n- **Exact command to reproduce**: bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nHello everyone!\r\nI've updated tensorflow today, run ```./configure``` command succesfully, but then ```bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package``` command and it failed with error\r\n```\r\nERROR: /private/var/tmp/_bazel_kate/8be913d8cdea6dd8174f0dac0a48c277/external/double_conversion/BUILD.bazel:12:1: undeclared inclusion(s) in rule '@double_conversion//:double-conversion':\r\nthis rule is missing dependency declarations for the following files included by 'external/double_conversion/double-conversion/fast-dtoa.cc':\r\n  '/Library/Developer/CommandLineTools/usr/lib/clang/10.0.0/include/stdint.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 3.297s, Critical Path: 1.92s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```\r\nThis text was rendered after this command with ```--verbose_failures```  option", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nMobile device", "**Mobile device** N/A\r\nAlso can't get, why error is pointing at the clang files, because I set \"use clang: no\" while configuring.\r\nI have updated python dependencies that were mentioned in installation guide. I have installed other versions of tensorflow successfully before. Now I've tried also to build it for 1.9 version, but I had another error:\r\n```\r\nERROR: /Users/kate/tensorflow/tensorflow/core/BUILD:309:1: undeclared inclusion(s) in rule '//tensorflow/core:platform_base':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/platform/posix/env_time.cc':\r\n  '/Library/Developer/CommandLineTools/usr/lib/clang/10.0.0/include/stdint.h'\r\n  '/Library/Developer/CommandLineTools/usr/lib/clang/10.0.0/include/stddef.h'\r\n  '/Library/Developer/CommandLineTools/usr/lib/clang/10.0.0/include/__stddef_max_align_t.h'\r\n  '/Library/Developer/CommandLineTools/usr/lib/clang/10.0.0/include/stdarg.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 17.712s, Critical Path: 2.16s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```\r\npointing some clang files as well", "@kate-kate it looks like you are using XCode 10 beta. Have you tried using OSX-10.13.5?", "@wt-huang actually I'm not using XCode (it is not installed on my OS at all), that is why I configured tensorflow not to use clang. But anyway I have Xcode Command Line Tools installed and recently updated and here is the info about them \r\n```\r\nMacBook-Pro-Ekaterina:~ kate$ gcc --version\r\nConfigured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\r\nApple LLVM version 10.0.0 (clang-1000.10.44.2)\r\nTarget: x86_64-apple-darwin17.7.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n```\r\nAlso sorry for misinformation, my OS version is 10.13.6 now", "@kate-kate XCode is the conglomerate that contains XCode command line tool and SDK.\r\n\r\nI just installed and compiled TensorFlow using the following command without error:\r\n```\r\nbazel test -c opt -- //tensorflow/... -//tensorflow/compiler/... -//tensorflow/contrib/lite/...\r\n\r\nbazel: 0.17.1\r\nTensorFlow: 1.10.0\r\nOSX: 10.13.5\r\n```\r\nOne thing you would need to check though, make sure this folder is not empty: `/private/var/tmp/_bazel_kate/8be913d8cdea6dd8174f0dac0a48c277/external/double_conversion`. You may need to download the zip file from `https://github.com/google/double-conversion/archive` and manually move it there.", "@wt-huang I have following files in my ```/private/var/tmp/_bazel_kate/8be913d8cdea6dd8174f0dac0a48c277/external/double_conversion``` directory:\r\n```\r\nMacBook-Pro-Ekaterina:~ kate$ ls /private/var/tmp/_bazel_kate/8be913d8cdea6dd8174f0dac0a48c277/external/double_conversion\r\n3992066a95b823efc8ccc1baf82a1cfc73f6e9b8.zip\tMakefile\r\nAUTHORS\t\t\t\t\t\tREADME.md\r\nBUILD\t\t\t\t\t\tSConstruct\r\nBUILD.bazel\t\t\t\t\tWORKSPACE\r\nCMakeLists.txt\t\t\t\t\tcmake\r\nCOPYING\t\t\t\t\t\tdouble-conversion\r\nChangelog\t\t\t\t\tmsvc\r\nLICENSE\t\t\t\t\t\ttest\r\n```", "Finally solved by total reinstall of bazel. Thank you for help"]}, {"number": 22354, "title": "ig -v", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 22353, "title": "[Feature Request] Making gradient boosted trees available outside tf.Estimator", "body": "**Feature Request**\r\n\r\nIs there any ongoing discussion on making gradient boosted trees available outside of `tf.estimators` ?\r\n\r\nDoing this will allow a wider range of experimentation than what is possible with `tf.estimators`.\r\n", "comments": ["@nataliaponomareva not sure whether you have plans to expose the underlying ops?", "boosted_trees_ops_op_lib has public visibility, so you can potentially use the ops as you wish in your graph. \r\nWhat's ur use case? what kind of experiments you can't do with an estimator? ", "@nataliaponomareva  I specifically would like to jointly train a CNN/LSTM based pipeline with gradient boosted trees.  I could not find a concrete example of how to do this with an estimator.  That is the source of this feature request. If however it is possible to do it via tf.estimator, an example would be much welcome.", "You would have to write your own estimator (eg. model fn where you will call the ops from lstm and gbdts). An example of something like this is https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/boosted_trees/estimator_batch/dnn_tree_combined_estimator.py - you can get an idea on how to do it out of it (eg using hooks etc)"]}, {"number": 22352, "title": "[INTEL MKL] Adding #error when compiling for MKL ML only.", "body": "Converting warning to error as the MKL ML only feature is no longer being supported. ", "comments": ["pinging @tatianashp for review. Thanks."]}, {"number": 22351, "title": "Fix the name of MKL dockerfile in update_version.py.", "body": "", "comments": ["@yifeif Copybara says \r\n`import/copybara \u2014 Import didn't affect any internal file`\r\nI think it should?\r\nany idea what is going on?", "Nagging Assignee @yifeif: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 22350, "title": "Support gradient_multipliers as tensor for optimize_loss", "body": "This fix tries to address the issue raised in #22295 where gradient_multipliers for tf.contrib.layers.optimize_loss() does not support tensor as input. This fix update the optimize_loss to allow gradient_multipliers passed as dict of tensors.\r\n\r\nThis fix fixes #22295.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Lint is failing for this PR. Please fix it accordingly.\r\n\r\nFAIL: Found 2 non-whitelited pylint errors:\r\ntensorflow/contrib/layers/python/layers/optimizers.py:24: [W0611(unused-import), ] Unused constant_op imported from tensorflow.python.framework\r\ntensorflow/contrib/layers/python/layers/optimizers.py:25: [W0611(unused-import), ] Unused dtypes imported from tensorflow.python.framework", "Thanks @qlzh727. The PR has been updated with all tests passed now. Please take a look and let me know if there are any other issues."]}, {"number": 22349, "title": "Error in tf.contrib.distributions.fill_triangular_inverse", "body": "### System information\r\n** TF Env Info: **\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/2393567/tf_env.txt)\r\n\r\n** TF Version: **\r\n```\r\n$ python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n/home/mab/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype\r\nfrom `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nv1.10.1-0-g4dcfddc5d1 1.10.1\r\n```\r\n\r\n### Describe the problem\r\nThe function ```fill_triangular_inverse``` actually uses the upper triangular portion of the matrices when constructing the transformation.  This can be seen with the above code where a vector is converted to a lower triangular matrix with ```fill_triangular``` and then back to a vector with ```fill_triangular_inverse```.  This works fine and reproduces the original vector unless there are non-zero entries added to the upper triangular portion of the intervening matrix.\r\n\r\nThe fix for this should be relatively easy and include a call to ```tf.matrix_band_part``` at the beginning of ```fill_triangular_inverse```.\r\n\r\n### Source code / logs\r\nSource to reproduce the issue:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.distributions as tfdist\r\n\r\nd = 5\r\npar_d = d*(d+1)//2\r\nvec = tf.constant(np.random.randn(1,par_d))\r\nM_orig = tfdist.fill_triangular(vec)\r\nM = M_orig + tf.constant(np.triu(np.random.randn(d,d),1).reshape([1,d,d]))\r\nvec2 = tfdist.fill_triangular_inverse(M)\r\nvec3 = tfdist.fill_triangular_inverse(M_orig)\r\n\r\nwith tf.Session() as sess:\r\n    [vec_val,vec2_val,vec3_val] = sess.run([vec,vec2,vec3])\r\n\r\n    print(\"d = {}, w/upper error = {}, w/o upper error = {}\".format(d,np.linalg.norm(vec_val-vec2_val),np.linalg.norm(vec_val-vec3_val)))\r\n```\r\n\r\nOutput on local installation:\r\n```\r\nd = 5, w/upper error = 2.6202726540863606, w/o upper error = 0.0\r\n```", "comments": ["@mbrubake if you would like to contribute PR are always welcome!", "@jvdillon fyi", "Hi Marcus. Thanks for your feedback.\r\n\r\nThis is actually by design; TFP tries to incur as little overhead as possible by assuming the input is \"correct.\" That said, fill_triangular_inverse is idiomatically inconsistent with distributions in that it doesnt have a validate_args. If it did, then validate_args=True should produce an error in the case you describe.\r\n\r\nGiven this this I see two fixes we should make:\r\n1) update the documentation to warn users that we expect the triu to be zeroed.\r\n2) add validate_args logic which verifies this requirement.\r\n\r\nMarcus, would you be interested in making this change? You could use validate_args from MVNTril as a template.", "Nagging Assignee @wt-huang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Will close this issue soon, @mbrubake feel free to submit PR per recommendations from @jvdillon."]}, {"number": 22348, "title": "Try to install TF from source got error", "body": "The environment is Ubuntu 18, nvidia driver 396(K80), cuda 9.2, cudnn 7.2.1, nccl 2.2, TF 1.10, python 3.6, bazel 0.17.1, gcc 7.3.0\r\n \r\nthe ./configure is ok, but command below got error\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nERROR: /home/eliyart/tensorflow/tensorflow/python/BUILD:1598:1: Linking of rule '//tensorflow/python:gen_linalg_ops_py_wrappers_cc' failed (Exit 1)\r\n/usr/bin/x86_64-linux-gnu-ld: warning: libcublas.so.9.2, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/x86_64-linux-gnu-ld: warning: libcudnn.so.7, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/x86_64-linux-gnu-ld: warning: libcufft.so.9.2, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/x86_64-linux-gnu-ld: warning: libcurand.so.9.2, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlanMany@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIzamax_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreate@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreatePoolingDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDzasum_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandDestroyGenerator@libcurand.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateConvolutionDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBiasActivationForward@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIsamax_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyConvolutionDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZherk_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsymm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamax_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyFilterDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan3d@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetStream_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGemmEx@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyrk_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIsamin_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCscal_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecD2Z@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotg_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelForward@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyrk_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateRNNDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyRNNDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardData@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetWorkArea@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateFilterDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher2k_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyr2k_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelBackward@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan2d@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2k_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStpsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrmm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyLRNDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroy@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDznrm2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemmBatched@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdscal_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDdot_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDropoutGetStatesSize@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardWorkspaceSize@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetActivationDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetPoolingNdDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNWorkspaceSize@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStpmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardAlgorithm@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetConvolutionGroupCount@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardBias@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan1d@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsymm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmBatched@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDasum_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScopy_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotmg_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensorNdDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCaxpy_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnAddTensor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyActivationDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotg_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgerc_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhemv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyrk_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetConvolutionNdDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotmg_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemmBatched@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingBackward@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardData@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetFilterNdDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCrotg_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecR2C@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSdot_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZrotg_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsscal_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetProperty@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterWorkspaceSize@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDscal_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDger_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrsm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNTrainingReserveSize@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetStream@libcurand.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrot_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSaxpy_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateUniformDouble@libcurand.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetPseudoRandomGeneratorSeed@libcurand.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateUniform@libcurand.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetLRNDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardTraining@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDnrm2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrsm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyTensorDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyDropoutDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsymv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateTensorDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgeru_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrot_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetStream@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamin_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamin_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsymv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCherk_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardInference@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCdotu_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateDropoutDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreatePersistentRNNPlan@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsyr2k_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgerc_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZscal_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormal@libcurand.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftDestroy@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhemm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftCreate@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetMathMode@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyPersistentRNNPlan@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyPoolingDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtbsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateActivationDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSger_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGemmBatchedEx@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSasum_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsymm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDcopy_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlanMany@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspr_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDswap_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardInference@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormalDouble@libcurand.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCreate_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIzamin_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan1d@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetStream@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2Z@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithm@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionNdDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnActivationForward@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerMatrixParams@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetRNNDescriptor_v6@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataWorkspaceSize@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetGeneratorOffset@libcurand.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationBackward@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStbsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetPointerMode_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetDropoutDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgeru_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCswap_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspr2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCdotc_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDestroy_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetAutoAllocation@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2k_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCcopy_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionForward@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardFilter@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterAlgorithm@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZswap_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerBiasParams@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetFilterNdDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetRNNMatrixMathType@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSscal_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsyrk_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNParamsSize@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScnrm2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsymm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamax_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionNdForwardOutputDim@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan3d@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSnrm2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScasum_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetPersistentRNNPlan@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher2k_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmEx@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensor4dDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSswap_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardWeights@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtbsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotc_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStbmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdrot_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecC2R@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardTraining@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemm_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnTransformTensor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecC2C@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsrot_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotu_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsv_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetConvolutionMathType@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingForward@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDaxpy_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan2d@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2D@libcufft.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `curandCreateGenerator@libcurand.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZaxpy_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateLRNDescriptor@libcudnn.so.7'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGetMathMode@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZcopy_v2@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemmBatched@libcublas.so.9.2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ulinalg_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGetPointerMode_v2@libcublas.so.9.2'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 3430.624s, Critical Path: 213.00s\r\nINFO: 2894 processes: 2894 local.\r\nFAILED: Build did NOT complete successfully", "comments": ["@lightning20 Hi, have you tried following the instructions [here](https://www.tensorflow.org/install/install_sources). \r\nPlease go through [this](https://gist.github.com/Brainiarc7/6d6c3f23ea057775b72c52817759b25c), which has clear steps to build tensorflow from source.", "Thanks, after re-use the following commands, then built and installed successfully.\r\n1)export PATH=/usr/local/cuda-9.2/bin${PATH:+:${PATH}}\r\n2)export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64\\\r\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\nActually, them has been used before. But after restart, seems lost again. Is there a way to fix them in the system, thanks.", "Ideally it should retain the installation after the restart. You may try it again and feel free to reopen if you face the same issue.", "Every time restart ubuntu and type nvcc will not recognize, need type this 2 lines below then nvcc can work. Any suggestion, really appreciate.\r\n1)export PATH=/usr/local/cuda-9.2/bin${PATH:+:${PATH}}\r\n2)export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64\r\n${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}", "This is actually working as intended:\r\nhttps://www.tensorflow.org/install/gpu#linux_setup\r\n\r\nexport command does not update your LD_LIBRARY_PATH permanently. It only updates it for a session.\r\nIt is easy to find ways to permanently update your LD_LIBRARY_PATH.\r\n\r\nHere is one of the first results that come up in google when I search for \"cuda LD_LIBRARY_PATH\"\r\nhttps://devtalk.nvidia.com/default/topic/995815/path-amp-ld_library_path/"]}, {"number": 22347, "title": "Bug in tf.import_graph_def for Graph Editor", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: see example below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: Titan X\r\n- **Exact command to reproduce**: see example below\r\n\r\n### Describe the problem\r\nI'm trying to export and then later import a subset of my graph after using the graph editor for network pruning (such that I get only the pruned network left at the end). I've written two toy examples to illustrate the problem as simply as possible: example 1 (below) works, I can define two subgraphs that share only their input, grab the graphdef for one, clear the graph and restore only the subgraph I want; example 2 (below) tries to do the same thing but uses the graph editor to replace the weights (as in the pruning case) and grab the new subgraph.\r\n\r\n### Source code / logs\r\n**Example 1:**\r\n```\r\nimport tensorflow as tf\r\n\r\nx = tf.placeholder(tf.float32, [], 'x')\r\nw = tf.Variable([3.], dtype=tf.float32, name='w')\r\ny = tf.multiply(x, w, name='y')\r\n\r\nw_1 = tf.Variable([1.], dtype=tf.float32, name='w_1')\r\ny_1 = tf.multiply(x, w_1, name='y_1')\r\n\r\nsubgraph = tf.graph_util.extract_sub_graph(tf.get_default_graph().as_graph_def(), [y_1.op.name])\r\nprint(type(subgraph))\r\ntf.reset_default_graph()\r\n_ = tf.import_graph_def(subgraph)\r\n\r\nprint(tf.contrib.graph_editor.get_tensors(tf.get_default_graph()))\r\n```\r\nthis prints, as expected:\r\n> <class 'tensorflow.core.framework.graph_pb2.GraphDef'>\r\n> [<tf.Tensor 'import/w_1:0' shape=(1,) dtype=float32_ref>, <tf.Tensor 'import/w_1/read:0' shape=(1,) dtype=float32>, <tf.Tensor 'import/x_1:0' shape=() dtype=float32>, <tf.Tensor 'import/y_1:0' shape=(1,) dtype=float32>]\r\n\r\n**Example 2:**\r\n```\r\nimport tensorflow as tf\r\n\r\nx = tf.placeholder(tf.float32, [], 'x')\r\nw = tf.Variable([3.], dtype=tf.float32, name='w')\r\ny = tf.multiply(x, w, 'y')\r\n\r\nw_1 = tf.Variable([2.], dtype=tf.float32, name='w_1')\r\ny_1 = tf.contrib.graph_editor.graph_replace(y, {w.op.outputs[0]: w_1.op.outputs[0]})\r\n\r\nsubgraph = tf.graph_util.extract_sub_graph(tf.get_default_graph().as_graph_def(), [y_1.op.name])\r\nprint(type(subgraph))\r\ntf.reset_default_graph()\r\n_ = tf.import_graph_def(subgraph)\r\n\r\nprint(tf.contrib.graph_editor.get_tensors(tf.get_default_graph()))\r\n```\r\nEdit: fixed typo in example 2, error is now:\r\n\r\n> ValueError: Node 'w/read_1' expects to be colocated with unknown node 'w'\r\n\r\nThe notable difference in the subgraph graphdefs is the line `s: \"loc:@w\"` under node `w/read_1`, which indicates the root cause is likely in the graph editor (considering that's the only difference between the two examples). Tagging @purpledog for input on the graph editor setting the attribute of that node.", "comments": ["Thanks for reporting this bug. As you identified, the most likely cause is that the graph_editor does not copy the attribute of the graph correctly.\r\nThis package is maintained by the open-source community and contribution are welcome. I am happy to review commits.", "Fixed typo in the original post. The bug is only in the graph editor, not tf.import_graph_def, and is indeed in how it copies the operations, carrying over collocation attributes of the node_def. I'm working on a fix now.", "Pull request submitted. The issue was the deepcopy of the node_def. I added a line that checks for the colocation attribute and clears it whenever it is present.", "Closing this for now. Feel free to reopen.", "I updated from 1.8 to 1.10 and found there's more bugs in the graph editor. In fact, the graph editor's graph_replace function doesn't work at all now (nevermind trying to re-use the graph_def later, it now fails right away):\r\n> ValueError: cannot add an op with id 7443 as it already exists in the graph\r\n\r\nI think this should be re-opened.", "It seems that a new operation is automatically added to the graph now when it's created, so the line `info.graph_._add_op(op_)` in copy_op_handler is redundant and causing the above error."]}, {"number": 22346, "title": " NotFoundError (see above for traceback): Key Variable not found in checkpoint     \t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], ", "body": "When I restore a saved model using:\r\n\r\n    checkpoint = tf.train.get_checkpoint_state(config.pre_model_dir)\r\n    if checkpoint and checkpoint.model_checkpoint_path:\r\n     saver.restore(session, checkpoint.model_checkpoint_path)\r\n, I am getting this error: \r\n\r\n\r\n    INFO:tensorflow:Restoring parameters from ./saved_model/10_zones/10/network--1685000\r\n    ---------------------------------------------------------------------------\r\n    NotFoundError                             Traceback (most recent call last)\r\n    /usr/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n       1321     try:\r\n    -> 1322       return fn(*args)\r\n       1323     except errors.OpError as e:\r\n    \r\n    /usr/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n       1306       return self._call_tf_sessionrun(\r\n    -> 1307           options, feed_dict, fetch_list, target_list, run_metadata)\r\n       1308 \r\n    \r\n    /usr/lib/python3.6/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n       1408           self._session, options, feed_dict, fetch_list, target_list,\r\n    -> 1409           run_metadata)\r\n       1410     else:\r\n    \r\n    NotFoundError: Key Variable not found in checkpoint\r\n    \t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n    \t [[Node: save/RestoreV2/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_18_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    NotFoundError                             Traceback (most recent call last)\r\n    <ipython-input-97-0cbd09927b40> in <module>()\r\n         42 checkpoint = tf.train.get_checkpoint_state(config.pre_model_dir)\r\n         43 if checkpoint and checkpoint.model_checkpoint_path:\r\n    ---> 44     saver.restore(session, checkpoint.model_checkpoint_path)\r\n         45     print(\"loaded the model\")\r\n         46 else:\r\n    \r\n    /usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)\r\n       1800     else:\r\n       1801       sess.run(self.saver_def.restore_op_name,\r\n    -> 1802                {self.saver_def.filename_tensor_name: save_path})\r\n       1803 \r\n       1804   @staticmethod\r\n    \r\n    /usr/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n        898     try:\r\n        899       result = self._run(None, fetches, feed_dict, options_ptr,\r\n    --> 900                          run_metadata_ptr)\r\n        901       if run_metadata:\r\n        902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n    \r\n    /usr/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n       1133     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n       1134       results = self._do_run(handle, final_targets, final_fetches,\r\n    -> 1135                              feed_dict_tensor, options, run_metadata)\r\n       1136     else:\r\n       1137       results = []\r\n    \r\n    /usr/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n       1314     if handle is None:\r\n       1315       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n    -> 1316                            run_metadata)\r\n       1317     else:\r\n       1318       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n    \r\n    /usr/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n       1333         except KeyError:\r\n       1334           pass\r\n    -> 1335       raise type(e)(node_def, op, message)\r\n       1336 \r\n       1337   def _extend_graph(self):\r\n    \r\n    NotFoundError: Key Variable not found in checkpoint\r\n    \t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n    \t [[Node: save/RestoreV2/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_18_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n    \r\n    Caused by op 'save/RestoreV2', defined at:\r\n      File \"/usr/lib64/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n        \"__main__\", mod_spec)\r\n      File \"/usr/lib64/python3.6/runpy.py\", line 85, in _run_code\r\n        exec(code, run_globals)\r\n      File \"/usr/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n        app.launch_new_instance()\r\n      File \"/usr/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n        app.start()\r\n      File \"/usr/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\r\n        self.io_loop.start()\r\n      File \"/usr/lib64/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\r\n        self.asyncio_loop.run_forever()\r\n      File \"/usr/lib64/python3.6/asyncio/base_events.py\", line 422, in run_forever\r\n        self._run_once()\r\n      File \"/usr/lib64/python3.6/asyncio/base_events.py\", line 1432, in _run_once\r\n        handle._run()\r\n      File \"/usr/lib64/python3.6/asyncio/events.py\", line 145, in _run\r\n        self._callback(*self._args)\r\n      File \"/usr/lib64/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\r\n        handler_func(fileobj, events)\r\n      File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\r\n        return fn(*args, **kwargs)\r\n      File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\r\n        self._handle_recv()\r\n      File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\r\n        self._run_callback(callback, msg)\r\n      File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\r\n        callback(*args, **kwargs)\r\n      File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\r\n        return fn(*args, **kwargs)\r\n      File \"/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\r\n        return self.dispatch_shell(stream, msg)\r\n      File \"/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\r\n        handler(stream, idents, msg)\r\n      File \"/usr/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\r\n        user_expressions, allow_stdin)\r\n      File \"/usr/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\r\n        res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n      File \"/usr/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\r\n        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n      File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\r\n        raw_cell, store_history, silent, shell_futures)\r\n      File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\r\n        interactivity=interactivity, compiler=compiler, result=result)\r\n      File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\r\n        if self.run_code(code, result):\r\n      File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\r\n        exec(code_obj, self.user_global_ns, self.user_ns)\r\n      File \"<ipython-input-97-0cbd09927b40>\", line 26, in <module>\r\n        saver = tf.train.Saver()\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\r\n        self.build()\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1347, in build\r\n        self._build(self._filename, build_save=True, build_restore=True)\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1384, in _build\r\n        build_save=build_save, build_restore=build_restore)\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 835, in _build_internal\r\n        restore_sequentially, reshape)\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 472, in _AddRestoreOps\r\n        restore_sequentially)\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 886, in bulk_restore\r\n        return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\r\n        shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n        op_def=op_def)\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\r\n        op_def=op_def)\r\n      File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\r\n        self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n    \r\n    NotFoundError (see above for traceback): Key Variable not found in checkpoint\r\n    \t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n    \t [[Node: save/RestoreV2/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_18_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\n\r\nI searched about this error, and there was a tf bug which requires to call the model using a full relative path, and I followed that path and tried values: `'./saved_model/10_zones/10'` and `os.path.abspath(config.pre_model_dir+'./../saved_model/10_zones/10')`\r\nfor `config.pre_model_dir`. Both resulted in a same error. \r\n\r\nI also checked the name of the saved variables using \r\nfrom tensorflow.contrib.framework.python.framework import checkpoint_utils\r\n\r\n    var_list = checkpoint_utils.list_variables(config.pre_model_dir)\r\n    for v in var_list:\r\n        print(v)\r\nwhich is:\r\n\r\n    ('actor/main_net/layer1/biases/Variable', [90])\r\n    ('actor/main_net/layer1/biases/Variable/Adam', [90])\r\n    ('actor/main_net/layer1/biases/Variable/Adam_1', [90])\r\n    ('actor/main_net/layer1/weights/Variable', [30, 90])\r\n    ('actor/main_net/layer1/weights/Variable/Adam', [30, 90])\r\n    ('actor/main_net/layer1/weights/Variable/Adam_1', [30, 90])\r\n    ('actor/main_net/layer2/biases/Variable', [60])\r\n    ('actor/main_net/layer2/biases/Variable/Adam', [60])\r\n    ('actor/main_net/layer2/biases/Variable/Adam_1', [60])\r\n    ('actor/main_net/layer2/weights/Variable', [90, 60])\r\n    ('actor/main_net/layer2/weights/Variable/Adam', [90, 60])\r\n    ('actor/main_net/layer2/weights/Variable/Adam_1', [90, 60])\r\n    ('actor/main_net/layer3/biases/Variable', [30])\r\n    ('actor/main_net/layer3/biases/Variable/Adam', [30])\r\n    ('actor/main_net/layer3/biases/Variable/Adam_1', [30])\r\n    ('actor/main_net/layer3/weights/Variable', [60, 30])\r\n    ('actor/main_net/layer3/weights/Variable/Adam', [60, 30])\r\n    ('actor/main_net/layer3/weights/Variable/Adam_1', [60, 30])\r\n    ('actor/main_net/layer4/biases/Variable', [10])\r\n    ('actor/main_net/layer4/biases/Variable/Adam', [10])\r\n    ('actor/main_net/layer4/biases/Variable/Adam_1', [10])\r\n    ('actor/main_net/layer4/weights/Variable', [30, 10])\r\n    ('actor/main_net/layer4/weights/Variable/Adam', [30, 10])\r\n    ('actor/main_net/layer4/weights/Variable/Adam_1', [30, 10])\r\n    ('actor/target_net/layer1/biases/Variable', [90])\r\n    ('actor/target_net/layer1/weights/Variable', [30, 90])\r\n    ('actor/target_net/layer2/biases/Variable', [60])\r\n    ('actor/target_net/layer2/weights/Variable', [90, 60])\r\n    ('actor/target_net/layer3/biases/Variable', [30])\r\n    ('actor/target_net/layer3/weights/Variable', [60, 30])\r\n    ('actor/target_net/layer4/biases/Variable', [10])\r\n    ('actor/target_net/layer4/weights/Variable', [30, 10])\r\n    ('beta1_power', [])\r\n    ('beta1_power_1', [])\r\n    ('beta2_power', [])\r\n    ('beta2_power_1', [])\r\n    ('critic/main_net/l1/biases', [90])\r\n    ('critic/main_net/l1/biases/Adam', [90])\r\n    ('critic/main_net/l1/biases/Adam_1', [90])\r\n    ('critic/main_net/l1/weights', [40, 90])\r\n    ('critic/main_net/l1/weights/Adam', [40, 90])\r\n    ('critic/main_net/l1/weights/Adam_1', [40, 90])\r\n    ('critic/main_net/l2/biases', [60])\r\n    ('critic/main_net/l2/biases/Adam', [60])\r\n    ('critic/main_net/l2/biases/Adam_1', [60])\r\n    ('critic/main_net/l2/weights', [90, 60])\r\n    ('critic/main_net/l2/weights/Adam', [90, 60])\r\n    ('critic/main_net/l2/weights/Adam_1', [90, 60])\r\n    ('critic/main_net/l3/biases', [30])\r\n    ('critic/main_net/l3/biases/Adam', [30])\r\n    ('critic/main_net/l3/biases/Adam_1', [30])\r\n    ('critic/main_net/l3/weights', [60, 30])\r\n    ('critic/main_net/l3/weights/Adam', [60, 30])\r\n    ('critic/main_net/l3/weights/Adam_1', [60, 30])\r\n    ('critic/main_net/l4/bias', [1])\r\n    ('critic/main_net/l4/bias/Adam', [1])\r\n    ('critic/main_net/l4/bias/Adam_1', [1])\r\n    ('critic/main_net/l4/kernel', [30, 1])\r\n    ('critic/main_net/l4/kernel/Adam', [30, 1])\r\n    ('critic/main_net/l4/kernel/Adam_1', [30, 1])\r\n    ('critic/target_net/l1/biases', [90])\r\n    ('critic/target_net/l1/weights', [40, 90])\r\n    ('critic/target_net/l2/biases', [60])\r\n    ('critic/target_net/l2/weights', [90, 60])\r\n    ('critic/target_net/l3/biases', [30])\r\n    ('critic/target_net/l3/weights', [60, 30])\r\n    ('critic/target_net/l4/bias', [1])\r\n    ('critic/target_net/l4/kernel', [30, 1])\r\n\r\nwith what `tf.global_variables()` in my current model results in, and they are both similar:\r\n\r\n    <tf.Variable 'actor/main_net/layer1/weights/Variable:0' shape=(30, 90) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer1/biases/Variable:0' shape=(90,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer2/weights/Variable:0' shape=(90, 60) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer2/biases/Variable:0' shape=(60,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer3/weights/Variable:0' shape=(60, 30) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer3/biases/Variable:0' shape=(30,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer4/weights/Variable:0' shape=(30, 10) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer4/biases/Variable:0' shape=(10,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/target_net/layer1/weights/Variable:0' shape=(30, 90) dtype=float32_ref>,\r\n     <tf.Variable 'actor/target_net/layer1/biases/Variable:0' shape=(90,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/target_net/layer2/weights/Variable:0' shape=(90, 60) dtype=float32_ref>,\r\n     <tf.Variable 'actor/target_net/layer2/biases/Variable:0' shape=(60,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/target_net/layer3/weights/Variable:0' shape=(60, 30) dtype=float32_ref>,\r\n     <tf.Variable 'actor/target_net/layer3/biases/Variable:0' shape=(30,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/target_net/layer4/weights/Variable:0' shape=(30, 10) dtype=float32_ref>,\r\n     <tf.Variable 'actor/target_net/layer4/biases/Variable:0' shape=(10,) dtype=float32_ref>,\r\n     <tf.Variable 'Variable:0' shape=() dtype=int32_ref>,\r\n     <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\r\n     <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer1/weights/Variable/Adam:0' shape=(30, 90) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer1/weights/Variable/Adam_1:0' shape=(30, 90) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer1/biases/Variable/Adam:0' shape=(90,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer1/biases/Variable/Adam_1:0' shape=(90,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer2/weights/Variable/Adam:0' shape=(90, 60) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer2/weights/Variable/Adam_1:0' shape=(90, 60) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer2/biases/Variable/Adam:0' shape=(60,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer2/biases/Variable/Adam_1:0' shape=(60,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer3/weights/Variable/Adam:0' shape=(60, 30) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer3/weights/Variable/Adam_1:0' shape=(60, 30) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer3/biases/Variable/Adam:0' shape=(30,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer3/biases/Variable/Adam_1:0' shape=(30,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer4/weights/Variable/Adam:0' shape=(30, 10) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer4/weights/Variable/Adam_1:0' shape=(30, 10) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer4/biases/Variable/Adam:0' shape=(10,) dtype=float32_ref>,\r\n     <tf.Variable 'actor/main_net/layer4/biases/Variable/Adam_1:0' shape=(10,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l1/weights:0' shape=(40, 90) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l1/biases:0' shape=(90,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l2/weights:0' shape=(90, 60) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l2/biases:0' shape=(60,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l3/weights:0' shape=(60, 30) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l3/biases:0' shape=(30,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l4/kernel:0' shape=(30, 1) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l4/bias:0' shape=(1,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/target_net/l1/weights:0' shape=(40, 90) dtype=float32_ref>,\r\n     <tf.Variable 'critic/target_net/l1/biases:0' shape=(90,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/target_net/l2/weights:0' shape=(90, 60) dtype=float32_ref>,\r\n     <tf.Variable 'critic/target_net/l2/biases:0' shape=(60,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/target_net/l3/weights:0' shape=(60, 30) dtype=float32_ref>,\r\n     <tf.Variable 'critic/target_net/l3/biases:0' shape=(30,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/target_net/l4/kernel:0' shape=(30, 1) dtype=float32_ref>,\r\n     <tf.Variable 'critic/target_net/l4/bias:0' shape=(1,) dtype=float32_ref>,\r\n     <tf.Variable 'beta1_power_1:0' shape=() dtype=float32_ref>,\r\n     <tf.Variable 'beta2_power_1:0' shape=() dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l1/weights/Adam:0' shape=(40, 90) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l1/weights/Adam_1:0' shape=(40, 90) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l1/biases/Adam:0' shape=(90,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l1/biases/Adam_1:0' shape=(90,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l2/weights/Adam:0' shape=(90, 60) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l2/weights/Adam_1:0' shape=(90, 60) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l2/biases/Adam:0' shape=(60,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l2/biases/Adam_1:0' shape=(60,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l3/weights/Adam:0' shape=(60, 30) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l3/weights/Adam_1:0' shape=(60, 30) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l3/biases/Adam:0' shape=(30,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l3/biases/Adam_1:0' shape=(30,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l4/kernel/Adam:0' shape=(30, 1) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l4/kernel/Adam_1:0' shape=(30, 1) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l4/bias/Adam:0' shape=(1,) dtype=float32_ref>,\r\n     <tf.Variable 'critic/main_net/l4/bias/Adam_1:0' shape=(1,) dtype=float32_ref>\r\n\r\n\r\nThe only difference in these two lists, is ` <tf.Variable 'Variable:0' shape=() dtype=int32_ref>`, which I do not know what is this for and how it is generated. But, I do not think if it is the problem, since any of my models that can be restored also has it. \r\n\r\nI appreciate any help and comment to resolve this error. \r\n  \r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes. \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: P100, 24 GB\r\n- **Exact command to reproduce**: \r\n", "comments": ["@oroojlooy Hi, please check [here ](https://stackoverflow.com/questions/42697800/tensorflow-error-restore-checkpoint-file)and let me know if it helps. You may post your observations here.", "Thanks for the quick reply. \r\nWhat I understood is that `variables_to_restore` is used when `tf.train.ExponentialMovingAverage` exists in the model. Am I right? If so, I think I cannot use it, since I do not have `tf.train.ExponentialMovingAverage` in my model. \r\n", "@allenlavoie Any inputs here ?", "I'd pass a `var_list` to `tf.train.Saver`'s constructor excluding the new variable. If you don't know where it's from you can just filter the global variables collection. It does say \"Key Variable not found in checkpoint\", so it's definitely that one that's causing this exception.", "@allenlavoie Thanks for the suggestion. It worked now. I'll dig the code to find out where the new variable comes from. ", "And where it came from? I am having the same error with save/RestoreV2", "having the same error", "I met the same problem, and i have solved it now. I think it is caused by the implicit use of default graph. So, to solve it, just change the line of \"tf.get_default_graph()\" to \"tf.Graph()\" . What to say, it really works for me. It may help to solve yours."]}, {"number": 22345, "title": "bazel build Error: use of undeclared identifier 'strtold'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NA\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04 LTS\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: clang version 6.0.0-1ubuntu2 (tags/RELEASE_600/final), gcc 7.3\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: 2 Tesla K80 with 12 GB Memory\r\n- **Exact command to reproduce**: bazel build --cxxopt='-std=c++11'  -c opt //tensorflow/contrib/android:libtensorflow_inference.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a --verbose_failures --copt=-Wno-c++11-narrowing\r\n\r\n### Description of the problem / feature request:\r\n\r\n> I am trying to build tensorflow for android deployment. But the build process is failing with error message\r\n```\r\nexternal/llvm/include/llvm/ADT/StringExtras.h:220:35: error: use of undeclared identifier 'strtold'\r\n  return detail::to_float(T, Num, strtold);\r\n```\r\n### Operating system?\r\n\r\n> Distributor ID: Ubuntu\r\nDescription:    Ubuntu 18.04 LTS\r\nRelease:        18.04\r\nCodename:       bionic\r\n\r\n\r\n### output of `bazel info release\r\n\r\n> WARNING: detected http_proxy set in env, setting no_proxy for localhost.\r\n> Starting local Bazel server and connecting to it...\r\n> release 0.16.1- (@non-git)\r\n\r\n> I downloaded bazel-0.16.1-dist.zip and followed the instructions given in https://docs.bazel.build/versions/master/install-compile-source.html\r\n\r\nI could just find the solutions for 'use of undeclared identifier' in c or cpp perspective but nothing particularly wrt to bazel. I am not able to understand why only 'strtold' is causing the error when there are 'strtof' and 'strtod' in the same scope which are not declared in the file StringExtras.h\r\n\r\n### Error Log\r\n```\r\n\r\n\r\nERROR: /home/gtornd/.cache/bazel/_bazel_gtornd/fff5ece2010c235c3b6f64ee1f972ad4/external/llvm/BUILD.bazel:1175:1: C++ compilation of rule '@llvm//:debug_info_code_view' failed (Exit 1): clang failed: error executing command\r\n  (cd /home/gtornd/.cache/bazel/_bazel_gtornd/fff5ece2010c235c3b6f64ee1f972ad4/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=debian \\\r\n    ANDROID_NDK_API_LEVEL=15 \\\r\n    ANDROID_NDK_HOME=/usr/lib/android-sdk/android-ndk-r15c \\\r\n    ANDROID_SDK_API_LEVEL=23 \\\r\n    ANDROID_SDK_HOME=/usr/lib/android-sdk \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu \\\r\n    HOST_CXX_COMPILER=/usr/bin/g++ \\\r\n    HOST_C_COMPILER=/usr/bin/gcc \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64:/usr/local/cuda/extras/CUPTI/lib64 \\\r\n    PATH=/usr/local/cuda-9.0/bin:/data/java/jdk1.8.0_161/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF_CUDA_CLANG=1 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=3.7,3.7 \\\r\n    TF_CUDA_VERSION=9.0 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_DOWNLOAD_CLANG=1 \\\r\n    TF_NCCL_VERSION=1 \\\r\n    TF_NEED_COMPUTECPP=0 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=1 \\\r\n    TRISYCL_INCLUDE_DIR=/usr/local/triSYCL/include \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang '-D__ANDROID_API__=14' -isystemexternal/androidndk/ndk/sysroot/usr/include/arm-linux-androideabi -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64 -fpic -ffunction-sections -funwind-tables -fstack-protector-strong -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -no-canonical-prefixes -fno-integrated-as -target armv7-none-linux-androideabi '-march=armv7-a' '-mfloat-abi=softfp' '-mfpu=vfpv3-d16' -mthumb -Os -g -DNDEBUG -MD -MF bazel-out/armeabi-v7a-opt/bin/external/llvm/_objs/debug_info_code_view/CodeViewRecordIO.d '-frandom-seed=bazel-out/armeabi-v7a-opt/bin/external/llvm/_objs/debug_info_code_view/CodeViewRecordIO.o' -DLLVM_ENABLE_STATS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D_DEBUG -DLLVM_BUILD_GLOBAL_ISEL -iquote external/llvm -iquote bazel-out/armeabi-v7a-opt/genfiles/external/llvm -iquote bazel-out/armeabi-v7a-opt/bin/external/llvm -iquote external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/genfiles/external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/bin/external/bazel_tools -iquote external/zlib_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/zlib_archive -iquote bazel-out/armeabi-v7a-opt/bin/external/zlib_archive -isystem external/llvm/include -isystem bazel-out/armeabi-v7a-opt/genfiles/external/llvm/include -isystem bazel-out/armeabi-v7a-opt/bin/external/llvm/include -isystem external/zlib_archive -isystem bazel-out/armeabi-v7a-opt/genfiles/external/zlib_archive -isystem bazel-out/armeabi-v7a-opt/bin/external/zlib_archive -Wno-c++11-narrowing '-std=c++11' '--sysroot=external/androidndk/ndk/platforms/android-14/arch-arm' -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward -isystemexternal/androidndk/ndk/sysroot/usr/include -c external/llvm/lib/DebugInfo/CodeView/CodeViewRecordIO.cpp -o bazel-out/armeabi-v7a-opt/bin/external/llvm/_objs/debug_info_code_view/CodeViewRecordIO.o)\r\nIn file included from external/llvm/lib/DebugInfo/CodeView/CodeViewRecordIO.cpp:10:\r\nIn file included from external/llvm/include/llvm/DebugInfo/CodeView/CodeViewRecordIO.h:18:\r\nIn file included from external/llvm/include/llvm/DebugInfo/CodeView/CodeViewError.h:13:\r\nIn file included from external/llvm/include/llvm/Support/Error.h:19:\r\nexternal/llvm/include/llvm/ADT/StringExtras.h:220:35: error: use of undeclared identifier 'strtold'\r\n  return detail::to_float(T, Num, strtold);\r\n                                  ^\r\n1 error generated.\r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\nINFO: Elapsed time: 2.545s, Critical Path: 1.89s\r\nINFO: 10 processes: 10 local.\r\nFAILED: Build did NOT complete successfully\r\ngtornd@ubuntu:/data/Maitreya/tensorflow$\r\n\r\n\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nMobile device", "@aselle @jdduke \r\nIs it possible this is a side effect of enabling XLA by default?", "any update? I have the same problem.\r\n@gunan ", "@gunan @aselle @jdduke .\r\nany update ?\r\nthanks!", "@maitreya2954  have you solve this issue?", "I haven't been able to repro this so far. Are you able to compile successfully *without* enabling CUDA when you run `tensorflow/configure`?", "`ERROR: /home/xx/.cache/bazel/_bazel_xx/701469a9a53002d9d7bcd7284d7ad10b/external/llvm/BUILD.bazel:1599:1: C++ compilation of rule '@llvm//:object' failed (Exit 1)\r\nIn file included from external/llvm/lib/Object/SymbolicFile.cpp:14:\r\nIn file included from external/llvm/include/llvm/Object/SymbolicFile.h:20:\r\nIn file included from external/llvm/include/llvm/Object/Binary.h:18:\r\nIn file included from external/llvm/include/llvm/Object/Error.h:18:\r\nIn file included from external/llvm/include/llvm/Support/Error.h:20:\r\nexternal/llvm/include/llvm/ADT/StringExtras.h:221:35: error: use of undeclared identifier 'strtold'\r\n  return detail::to_float(T, Num, strtold);\r\n                                  ^\r\n1 error generated.\r\n`\r\nit still had this issue.", "Can you run configure again and *only* enable Android support (that is, disable XLA/Cuda/etc...)?", "yes,I do as you say.\r\nexecute 'bazel build  --cxxopt=-std=c++11 -c opt //tensorflow/examples/android:tensorflow_demo'\r\nit report errors.\r\n`/home/xx/.cache/bazel/_bazel_xx/701469a9a53002d9d7bcd7284d7ad10b/external/llvm/BUILD.bazel:836:1: C++ compilation of rule '@llvm//:arm_asm_printer' failed (Exit 1)\r\nIn file included from external/llvm/lib/Target/ARM/InstPrinter/ARMInstPrinter.cpp:18:\r\nIn file included from external/llvm/include/llvm/MC/MCAsmInfo.h:21:\r\nIn file included from external/llvm/include/llvm/MC/MCDwarf.h:24:\r\nIn file included from external/llvm/include/llvm/Support/Error.h:20:\r\nexternal/llvm/include/llvm/ADT/StringExtras.h:221:35: error: use of undeclared identifier 'strtold'\r\n  return detail::to_float(T, Num, strtold);\r\n                                  ^\r\n1 error generated.`", "Something seems broken with your build configuration, it shouldn't be pulling in the external/llvm build when you're building for Android. Can you try this command?\r\n\r\n```bazel build --cxxopt='-std=c++11' -c opt --config=android_arm //tensorflow/contrib/android:libtensorflow_inference.so ```", "`/home/xx/.cache/bazel/_bazel_xx/701469a9a53002d9d7bcd7284d7ad10b/external/llvm/BUILD.bazel:1204:1: C++ compilation of rule '@llvm//:debug_info_msf' failed (Exit 1)\r\nIn file included from external/llvm/lib/DebugInfo/MSF/MSFCommon.cpp:10:\r\nIn file included from external/llvm/include/llvm/DebugInfo/MSF/MSFCommon.h:16:\r\nIn file included from external/llvm/include/llvm/Support/Error.h:20:\r\nexternal/llvm/include/llvm/ADT/StringExtras.h:221:35: error: use of undeclared identifier 'strtold'\r\n  return detail::to_float(T, Num, strtold);\r\n                                  ^\r\n1 error generated.\r\n`\r\nalso have  this issue", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "> It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?\r\n\r\nIt is.I have encountered the same issue too", "Please either disable xla or use a newer android ndk/sdk. Report back with whether that works @mstc-xqp and @maitreya2954", "@aselle\r\nDisabling XLA worked for me. \r\nThanks", "It seems that we need to make sure following to build android .so without error:\r\n\r\n1. ANDROID_NDK_API_LEVEL=21 see #20192\r\n2. disable xla and cuda options."]}, {"number": 22344, "title": "tensorflow.contrib.mpi import fails and cannot run with mpi even though tensorflow is compiled with mpi", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes, I follow [this](https://github.com/tensorflow/tensorflow/issues/17758) to add \"#define TENSORFLOW_USE_MPI\" to each *.cc files and *.h files in mpi_collectives folder.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.5 LTS\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4.2\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**:cuda8.0 cudnn6\r\n- **GPU model and memory**:Tesla K80 11439MB\r\n- **Exact command to reproduce**: import tensorflow.contrib.mpi as mpi\r\n\r\n### Describe the problem\r\nI have built a docker image with openpai and tensorflow according to the [official tutorial](https://www.tensorflow.org/install/install_sources) and [this document](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/mpi). During the docker building process, nothing wrong. But, I cannot use mpi in the built docker. When I import mpi, it throws **ImportError: No module named mpi**. And when I run a tensorflow job `python code/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --local_parameter_device=cpu --batch_size=32 --model=resnet20 --variable_update=parameter_server --data_dir=$PAI_DATA_DIR --data_name=cifar10 --train_dir=$PAI_OUTPUT_DIR --ps_hosts=$PAI_TASK_ROLE_ps_server_HOST_LIST --worker_hosts=$PAI_TASK_ROLE_worker_HOST_LIST --job_name=ps --task_index=$PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX --server_protocol=grpc+mpi `, it throw error too. See [this issue](https://github.com/Microsoft/pai/issues/1336) in openpai to find the detail.\r\n\r\n### Source code / logs\r\nHere is the [base docker file](https://github.com/Microsoft/pai/blob/master/examples/Dockerfiles/cuda8.0-cudnn6/Dockerfile.build.base)\r\nHere is the [mpi docker file](https://github.com/Microsoft/pai/blob/master/examples/Dockerfiles/cuda8.0-cudnn6/Dockerfile.build.mpi)\r\nAnd here is my [tensorflow docker file](https://github.com/Microsoft/pai/blob/77715f758dcdb9fb6c68b3f931703d4cd20db822/examples/mpi/Dockerfile.example.tensorflow-mpi)\r\n", "comments": ["As this is under contrib, we have no official support for it.\r\n@jhseu @martinwicke who is the best person to talk to about MPI support?", "AFAIK, there is no Python package in contrib.mpi. You should at least take a look on its [README](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/mpi).", "Ping @jbedorf ", "There are two MPI based additions in TensorFlow, the one you are trying to use here (`grpc+mpi`) does not have a Python interface. Hence you will see the import error.  Also you should launch your program via `mpirun` otherwise the MPI environment will not be setup and the processes won't be able to communicate.\r\nThe other addition, `mpi_collectives`,  does have a Python interface, but it requires a different way of setting up your network. \r\n\r\nLooking at your original error that you linked on the `pai` repository it seems you have a problem with your OpenMPI installation inside docker. I would first try to create a simple `hello world` MPI program and see if that works correctly inside the docker container. Right now you might be missing some of the support libraries inside your container.\r\n\r\n", "Thank you! What's the `hello world` MPI test program? I can test the [mpi docker image](https://github.com/Microsoft/pai/blob/master/examples/Dockerfiles/cuda8.0-cudnn6/Dockerfile.build.mpi) too.", "I mean something like this example, that will verify that you have the right libraries installed and enabled in your Docker images. \r\nhttp://mpitutorial.com/tutorials/mpi-hello-world/\r\n", "Thank you for the example. I will test my docker image according to it after Chinese National Day. ", "@tatianashp @jhseu to check if they can redirect to mpi support maintainers.", "+@azaks2 on distributed execution", "Closing due to inactivity."]}, {"number": 22343, "title": "How to penalize the loss of one class more than the other in tensorflow for a multi class problem?", "body": "Let's say my model has two classes Class 1 and Class 2. Both Class 1 and Class 2 has a equal amount of training and testing data. But I want to penalize the loss of the Class 1 more than Class 2, so that one class has a fewer number of False Positives than the other (I want the model to perform better for one class than the other). ", "comments": ["This question is better asked on [StackOverflow ](https://stackoverflow.com/questions/tagged/tensorflow)since it is not a bug or feature request. There is also a larger community that reads questions there."]}, {"number": 22342, "title": "tensorflow import error(tf.estimator package not installed)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Centos 7\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:1.10.0\r\n- **Python version**:anaconda python 3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**: import tensorflow\r\n\r\nI have installed anaconda 3 on Centos 7 and instlall tensorflow with pip.\r\nJust import tensorflow and the error says \"tf.estimator package not installed.\" I am not able to import tensorflow.estimator().\r\nI have figured out one way to avoid this is to import msgpack or distributed before import tensorflow and it works just fine. But I am still looking for the right fix.\r\n", "comments": ["I have tried uninstall and install tensorflow & tensorflow-hub. But it doesn't work.", "#21478 ", "I was experiencing this error as well. It was preventing me from using some of the contrib rnn packages. I was also getting \r\n\r\n> cannot import name hashtable\r\n\r\nwhich led me to this [SO post](https://stackoverflow.com/questions/14422976/importing-pandas-shows-importerror-cannot-import-name-hashtable).\r\n\r\nApparently there is some dependency on pandas that was out-of-date for me. I fixed it accordingly and now these warning are gone\r\n\r\n`pip3 install --upgrade pandas`", "@07freedom Can you please try to check if any of the dependencies are out-of-date and try upgrading those.", "@harshini-gadige @bjvanov thanks for the quick reply. I have already fixed the problem by upgrade pandas. I have to install Tensorflow offline from scratch so I am so glad to find the exact needed dependency.\r\nThe pandas comes with my Anaconda3-5.2.0-Linux-x86_64 is 0.23.0\r\nAfter upgrade pandas with pip to 0.23.4 and it works for me.", "pip install pandas and **reconfigure** tensorflow, fixed the my problem.", "I have run some tests and found that the version of pandas and pytz matters, when:\r\npandas 0.23.4--pytz 2018.5 or\r\npandas 0.23.0--pytz 2018.4\r\nthen tensorflow runs perfectly", "I have the same problem as well. I have tried (as suggested in this and other posts):\r\n- downgrading pytz from 2018.7 to 2018.5 (with pandas already being version 0.23.4)\r\n- downgrading pytz to 2018.4 and pandas to 0.23.0\r\n- importing pandas before importing tensorflow\r\n- uninstalling pandas : this got rid of the error message but surely pandas is needed to run tensorflow? (I am very new to this)\r\n\r\nPlease advise", "Requirement already up-to-date: pandas in c:\\users\\anaconda3\\lib\\site-packages (0.23.4)\r\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in c:\\users\\anaconda3\\lib\\site-packages (from pandas) (2.7.5)\r\nRequirement already satisfied, skipping upgrade: pytz>=2011k in c:\\users\\anaconda3\\lib\\site-packages (from pandas) (2018.7)\r\nRequirement already satisfied, skipping upgrade: numpy>=1.9.0 in c:\\users\\anaconda3\\lib\\site-packages (from pandas) (1.15.4)\r\nRequirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\r\n\r\nI am also getting same error. \r\ntf.estimator package not installed.\r\n\r\nPlease help out\r\n", "Faced the same problem with Anaconda5.3, python3.6, and tensorflow 1.12.0: \r\n\r\n- pip install -U pandas (0.23.4 installed)\r\n- pip install -U matplotlib (3.0.2 installed)\r\n\r\nWorked for me", "updating to tensorflow 1.12.0 worked for me in the end", "Updating pandas alone did not help. Updating matplotlib fixed the issue for me.", "Thanks all. I resolved it", "Updating matplotlib helped. Thanks.", "> Faced the same problem with Anaconda5.3, python3.6, and tensorflow 1.12.0:\r\n> \r\n> * pip install -U pandas (0.23.4 installed)\r\n> * pip install -U matplotlib (3.0.2 installed)\r\n> \r\n> Worked for me\r\n\r\nit also works with conda:\r\n`conda upgrade matplotlib`", "For me this had nothing to do with pandas or matplotlib. The issue was that I had installed a newer version of TF then downgraded. Uninstalling `tensorflow-estimator` and `tensorflow-gpu`, then reinstalling `tensorflow-gpu` fixed it.", "faced the same problem, and \r\ntensorflow==1.13.1, \r\npandas==0.23.0, \r\nmatplotlib==1.5.1 \r\nworked for me : )", "downgrading tensorflow-estimator works for me."]}, {"number": 22341, "title": "Feature Request: Add quadratic weighted kappa", "body": "### System information\r\n- **Have I written custom code**: No\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **Mobile device if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: GTX 1070 8G\r\n- **Exact command to reproduce**: N/A\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nQuadratic weighted kappa (qwk) is a frequently used evaluation criteria, and is used in many competitions, such as the Kaggle Diabetic Retinopathy Detection, Prudential Life Insurance Assessment, and Crowdflower Search Results Relevance, etc. \r\n\r\nIt would be very helpful for those who actively take part in those competitions if a quadratic_weighted_kappa function can be added into tf.contrib.metrics.\r\n\r\nAlso, we already have cohen's kappa (tf.contrib.metrics.cohen_kappa) and confusion matrix (tf.contrib.metrics.confusion_matrix -> tf.confusion_matrix) . Adding qwk is consistent with the existing codes. \r\n\r\nAgain, please add quadratic weighted kappa into tensorflow.\r\n\r\n\r\n", "comments": ["@fclof  This will be an interesting feature addition to tf.contrib.metrics. Workaround will be to refer [quadratic_weighted_kappa](https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/quadratic_weighted_kappa.py)\r\nFeel free to contribute PR for this feature, we will be glad to review it.", "Any changes with this feature?"]}, {"number": 22340, "title": "Update CONTRIBUTING.md to reflect PR merge process", "body": "", "comments": ["Thanks @gunan!", "Nagging Assignee @yifeif: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@yifeif @Androbin just checking that this is ready to go?", "Thanks @drpngx. It should be ready now."]}, {"number": 22339, "title": "pip official package compiled differently with docker package?", "body": "I found in docker container, tensorflow is installed from `http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.7.0-cp27-none-linux_x86_64.whl`\r\nnot official pip source `https://pypi.org/project/tensorflow/`. \r\n\r\nAnd i am working on filesystem plugin, a .so file, which works fine with official tensorflow pip package, but with tensorflow from `http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.7.0-cp27-none-linux_x86_64.whl`, i got error `_ZN10tensorflow10FileSystem10FilesExistERKSt6vectorISsSaISsEEPS1_INS_6StatusESaIS6_EE`.\r\n\r\nSeems tensorflow from official source compiled differently with `http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.0.0-cp27-none-linux_x86_64.whl` ?\r\n\r\nWhy and how to solve this? How can i  compile a filesystem plugin compatible to `http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.0.0-cp27-none-linux_x86_64.whl`?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@u2takey could you check your TensorFlow version? Should be something like: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.10.1-cp27-none-linux_x86_64.whl", "@wt-huang  hi\uff0cthis issue seems not quite related with specific version. I reproduced this issue with version 1.6-1.8, to be more clear: my custom filesystem plugin works fine with tensorflow from `pip install tensorflow==1.6.0`  `pip install tensorflow==1.7.0` `pip install tensorflow==1.8.0`, but get error `_ZN10tensorflow10FileSystem10FilesExistERKSt6vectorISsSaISsEEPS1_INS_6StatusESaIS6_EE ` with `pip install http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.6.0-cp27-none-linux_x86_64.whl` `pip install http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.7.0-cp27-none-linux_x86_64.whl` `pip install http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.8.0-cp27-none-linux_x86_64.whl`\r\n\r\nand my bazel version for compiling filesystem plugin is\r\n```\r\nBuild label: 0.13.1\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed May 23 11:17:23 2018 (1527074243)\r\nBuild timestamp: 1527074243\r\nBuild timestamp as int: 1527074243\r\n```\r\nbazel command:\r\n\r\n```\r\nbazel build -c opt --copt=\"-fPIC\" --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/core/platform/cxs:cxs_file_system.so\r\n```", "@u2takey I installed above TensorFlow versions without encountering any error. Make sure you use the latest bazel version. Please fill out the template, in particular the exact command to reproduce.", "To check how to use those dockerfiles, please see the readme in that folder:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/README.md\r\n\r\nThe link you are seeing there should not exist. its version string is `0.0.0`\r\n\r\nThose dockerfiles **cannot** be used without the `parameterized_docker_build.sh` script.\r\nFor the newer and more flexible dockerfiles, please see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles", "@gunan @wt-huang why not take a minute to read through my issue before you give answer in a hurry? My issue is not a install issue! My issue is caused by : package from different source compiled differently. And of course, no one will really install 0.0.0!", "When I read your issue, I see that you link to this package:\r\n`http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.0.0-cp27-none-linux_x86_64.whl`\r\nThis is an invalid path, that just stays as a placeholder. (looks like part of your report was modified 14 minutes ago)\r\n\r\nWhen we are building dockerfiles using parameterized_docker_build.sh, this placeholder is replaced with the exact same binaries we release through pypi, only copied to GCS. There is no difference in the packages we use in dockerfiles, or releases.\r\n", "@gunan sorry for confusion, i haven's expressed my question clearly. \r\nGCS package is same as pypi, but seems different from package in docker image?\r\nI checked docker hub image history `tensorflow/tensorflow:1.7.0` with docker history\r\n```\r\n/bin/sh -c pip --no-cache-dir install /tensorflow-1.7.0-cp27-cp27mu-manylinux1_x86_64.whl\r\n``` \r\nseems tensorflow is install from local wal, and tensorflow size is `16533200` and symbol i want to find missing\r\n\r\n```\r\n-rwxr-xr-x  1 root staff 16533200 Mar 29 17:04 libtensorflow_framework.so*\r\n\r\nnm libtensorflow_framework.so|grep _ZN10tensorflow10FileSystem10FilesExistERKSt6vectorISsSaISsEEPS1_INS_6StatusESaIS6_EE\r\n```\r\nBut if i uninstall tensorflow an reinstall in again\r\n```\r\npip uninstall -y tensorflow\r\npip install tensorflow==1.7.0\r\n```\r\n\r\ni get different tensorflow library with size `16337456`, and symbol i want to find  appears\r\n````\r\n16337456 Sep 20 02:45 libtensorflow_framework.so*\r\n\r\n nm libtensorflow_framework.so|grep _ZN10tensorflow10FileSystem10FilesExistERKSt6vectorISsSaISsEEPS1_INS_6StatusESaIS6_EE\r\n0000000000553240 T _ZN10tensorflow10FileSystem10FilesExistERKSt6vectorISsSaISsEEPS1_INS_6StatusESaIS6_EE\r\n```\r\n", "@av8ramit \r\nI thought we simply did `pip install tensorflow` in docker images.\r\nDo you know if there are any differences in the pip packages docker uses, and we upload to pypi?", "I cannot find the issue now, but another used had brought this up. We were creating the docker images for a few versions (until 1.7 I believe) with a pip whl file that was created separately. We cannot download from pypi because the docker images are built prior to releasing on pypi. The adjustment we made to satisfy this user was that we installed the exact same whl file instead that we upload to pypi.\r\n\r\nTLDR: There used to be differences, now they are not.", "thanks @av8ramit, seems my filesystem plugin works fine since image 1.8, so i will give up filesystem plugin support before 1.7. Closed.", "Happy to help! Sorry for the inconvenience @u2takey !"]}, {"number": 22338, "title": "using bazel to build tensorflow.dll", "body": "i try using bazel to build on windows, but tips:\r\n\r\n**Have I written custom code** No\r\n**OS Platform and Distribution** WIN7 Visual Studio 2015\r\n**TensorFlow installed from** source master\r\n**Bazel version** 0.17.1\r\n**CUDA/cuDNN version** CUDA9.0 / CUDNN 7.2.1\r\n**GPU model and memory** 1080Ti / 11G\r\n**Mobile device** N/A\r\n**Exact command to reproduce**\r\n1. python ./configure.py\r\n```\r\nWARNING: An illegal reflective access operation has occurred\r\nWARNING: Illegal reflective access by com.google.protobuf.UnsafeUtil (file:/C:/U\r\nsers/tao/_bazel_tao/install/360a69cc0fef41d83a4dd948c0474ca5/_embedded_binaries/\r\nA-server.jar) to field java.lang.String.value\r\nWARNING: Please consider reporting this to the maintainers of com.google.protobu\r\nf.UnsafeUtil\r\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflect\r\nive access operations\r\nWARNING: All illegal access operations will be denied in a future release\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Ba\r\nzel server using the command \"bazel shutdown\".\r\nYou have bazel 0.17.1 installed.\r\nPlease specify the location of python. [Default is C:\\Users\\tao\\AppData\\Local\\Pr\r\nograms\\Python\\Python35\\python.exe]:\r\n\r\nFound possible Python library paths:\r\n  C:\\Users\\tao\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Users\\tao\\A\r\nppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with nGraph support? [y/N]:\r\nNo nGraph support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to\r\nCUDA 9.0]:\r\n\r\nPlease specify the location where CUDA 9.0 toolkit is installed. Refer to README\r\n.md for more details. [Default is C:/Program Files/NVIDIA GPU Computing Toolkit/\r\nCUDA/v9.0]:\r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuD\r\nNN 7.0]:\r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.\r\nmd for more details. [Default is C:/Program Files/NVIDIA GPU Computing Toolkit/C\r\nUDA/v9.0]:\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to b\r\nuild with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.\r\ncom/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your\r\n build time and binary size. [Default is: 3.5,7.0]:\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"-\r\n-config=opt\" is specified [Default is /arch:AVX]:\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduc\r\ne the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n```\r\n\r\n\r\n2.bazel build --config=opt --config=cuda //tensorflow:libtensorflow.so\r\n```\r\nbazel build --config=opt --config=cuda //tensorflow:libtensorflow.so will be generated tensorflow.so and tensorflow.lib ?\r\n```\r\nThen rename the libtensorflow.so to tensorflow.dll, it can be work? @meteorcloudy", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nTensorFlow version", "> Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\r\n> TensorFlow version\r\n\r\n**TensorFlow version**   master   maybe r1.10", "Yes, it should work.", "You might find this script useful:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/windows/libtensorflow_cpu.sh", "> You might find this script useful:\r\n> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/windows/libtensorflow_cpu.sh\r\n\r\nHow should I choose to compile the debug version or the realse version?", "Debug: pass `-c debug` or `-c fastbuild`\r\nRelease: pass `-c opt`", "i try using `bazel build --config=fastbuild --config=cuda //tensorflow:libtensorflow.so` or `bazel build --config=debug --config=cuda //tensorflow:libtensorflow.so` but it's have some mistake, tips:\r\n```\r\nERROR: Config value fastbuild is not defined in any .rc file   \r\nor \r\nERROR: Config value debug is not defined in any .rc file\r\n```", "Sorry, I meant you need to pass `-c debug` or `-c fastbuild`, it's different from `--config`", "> fastbuild\r\n\r\nThank you  very much", "> Sorry, I meant you need to pass `-c debug` or `-c fastbuild`, it's different from `--config`\r\n realse version can sucess build, but debug version tops:\r\n```\r\n\u8133\u5784\u812a\u8292: \u63b3\u7709\u6f5e\u5362\u8126\u811b\u5f55\u9541:      C:\\Program Files (x86)\\Microsoft Visual Studio\r\n14.0\\VC\\INCLUDE\\thread\r\n\u8133\u5784\u812a\u8292: \u63b3\u7709\u6f5e\u5362\u8126\u811b\u5f55\u9541:       C:\\Program Files (x86)\\Microsoft Visual Studio\r\n 14.0\\VC\\INCLUDE\\memory\r\n\u8133\u5784\u812a\u8292: \u63b3\u7709\u6f5e\u5362\u8126\u811b\u5f55\u9541:    C:\\users\\tao\\_bazel_tao\\ic7qrvhc\\execroot\\org_ten\r\nsorflow\\tensorflow/core/platform/thread_annotations.h\r\n\u8133\u5784\u812a\u8292: \u63b3\u7709\u6f5e\u5362\u8126\u811b\u5f55\u9541:     C:\\users\\tao\\_bazel_tao\\ic7qrvhc\\execroot\\org_te\r\nnsorflow\\tensorflow/core/platform/default/thread_annotations.h\r\nc:\\users\\tao\\_bazel_tao\\ic7qrvhc\\execroot\\org_tensorflow\\tensorflow\\core\\lib\\io\\\r\npath.cc(290) : error C4716: \u9686\u63b3tensorflow::io::GetTempFilename\u9686\u5364: \u5364\u8134\u8128\u6bdb\u8def\r\n\u788c\u7984\u8134\u812a\u7984\u8d42\u679a\u8130\u788c\r\nTarget //tensorflow:libtensorflow.so failed to build\r\nINFO: Elapsed time: 439.737s, Critical Path: 427.30s\r\nINFO: 806 processes: 806 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n```", "I have very similar issue:\r\n\r\n**Have I written custom code** No\r\n**OS Platform and Distribution** WIN10 Visual Studio 2015\r\n**TensorFlow installed from** stable release v1.10.1\r\n**Bazel version** 0.17.2\r\n**CUDA/cuDNN version** CUDA8.0 / CUDNN 7.0\r\n**GPU model and memory** 1050Ti / 8G\r\n**Mobile device**  N/A\r\n**Exact command to reproduce**\r\n bazel build -c opt //tensorflow/tools/lib_package:libtensorflow\r\nran after python ./configure.py\r\n\r\nI have tried the script located in \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/windows/libtensorflow_gpu.sh --- the GPU version. Ended again after a long build with similiar error. Whole bunch of Eigen and protobuf errors.", "@taotaolin Looks like this function `tensorflow::io::GetTempFilename` failed, can you show me what's the value of your `TEMP`, `TMP` environment variable?", "@Croolman Can you provide the exact error message? \r\nDoes https://github.com/tensorflow/tensorflow/issues/19198 seem to be related?", "@meteorcloudy The issue you re reffering to might be related.  The error message is way too long and it is hard to find the exact position where it started.\r\n\r\nWay above, it starts with some INFO, but this should not be a problem\r\n\r\n`bazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist`\r\n\r\nThe final error message:\r\n\r\n```\r\n1 error detected in the compilation of \"[...]/AppData/Local/Temp/nvcc_inter_files_tmp_dir/gather_functor_gpu.cu.cpp1.ii.\r\nTarget //tensorflow/tools/lib_package:libtensorflow failed to build\r\n```\r\n\r\nAnd before that a reoccuring pattern that looks like this - the no return at the nonvoid func:\r\n\r\n```\r\n[...]\\eviletzq\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\src/SpecialFunctions/SpecialFunctionsImpl.h(651): warning: missing return statement at end of non-void function \"Eigen::internal::igammac_cf_impl<Scalar, mode>::run [with Scalar=float, mode=Eigen::internal::DERIVATIVE]\"\r\n          detected during:\r\n            instantiation of \"Scalar Eigen::internal::igammac_cf_impl<Scalar, mode>::run(Scalar, Scalar) [with Scalar=float, mode=Eigen::internal::DERIVATIVE]\"\r\n(855): here\r\n            instantiation of \"Scalar Eigen::internal::igamma_generic_impl<Scalar, mode>::run(Scalar, Scalar) [with Scalar=float, mode=Eigen::internal::DERIVATIVE]\"\r\n(2102): here\r\n```\r\n\r\n\r\n", "@Croolman The error you showed here are warnings. You can redirect the output to a file and search for `error:`", "@meteorcloudy  Allrighty, this should be it\r\n\r\n```\r\nERROR: [...]/tensorflow/tensorflow/core/kernels/BUILD:4245:1: C++ compilation of rule '//tensorflow/core/kernels:scatter_nd_op_gpu' failed (Exit 2): msvc_wrapper_for_nvcc.bat failed: error executing command \r\n  cd [...]/eviletzq/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Program Files/Anaconda3/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Program Files/Anaconda3/lib/site-packages\r\n    SET TEMP=[...]\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_VERSION=8.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TMP=[...]\\AppData\\Local\\Temp\r\n```\r\nThe second one:\r\n`  external/protobuf_archive/src\\google/protobuf/arena.h(338): error: static assertion failed with \"CreateArray requires a trivially destructible type\"`\r\n\r\nThis first one seems like an incompatible configuration settings. The only extra thing I have set is the compute capability - 6.1. I have tried building it with default - 3.5 and 7.0 which yields `nvcc fatal   : Unsupported gpu architecture 'compute_70' ` That might be because of CUDA v8.0. Then I tried it with 5.0 and ended up with the same error as the first one again.\r\n", "@Croolman  Can you try to build with CUDA v9.0? That is a known working version.", "> @taotaolin Looks like this function `tensorflow::io::GetTempFilename` failed, can you show me what's the value of your `TEMP`, `TMP` environment variable?\r\n\r\nWhat is TMP environment variable?My Realse version has been compiled successfully, and the Debug version has gone wrong. I think there should be no problem with environment variables.", "@meteorcloudy I cant really use cuda v9 in my enviroment, so I cannot try to build with v9", "@meteorcloudy \r\nI tried to use the realse version of the dll file but an error message:\r\n```\r\n\u9519\u8bef\tLNK2019\t\u65e0\u6cd5\u89e3\u6790\u7684\u5916\u90e8\u7b26\u53f7 \"char const * __cdecl tensorflow::core::GetVarint32PtrFallback(char const *,char const *,unsigned int *)\" (?GetVarint32PtrFallback@core@tensorflow@@YAPEBDPEBD0PEAI@Z)\uff0c\u8be5\u7b26\u53f7\u5728\u51fd\u6570 \"char const * __cdecl tensorflow::core::GetVarint32Ptr(char const *,char const *,unsigned int *)\" (?GetVarint32Ptr@core@tensorflow@@YAPEBDPEBD0PEAI@Z) \u4e2d\u88ab\u5f15\u7528\tConsoleApplication1\tC:\\Users\\tao\\Desktop\\tensorflow-test\\ConsoleApplication1\\ConsoleApplication1\\ConsoleApplication1.obj\t1\t\r\n\r\n```", "I guess you need to add the import library to the link command.\r\nFind this file `tensorflow\\bazel-bin\\tensorflow\\libtensorflow.so.if.lib`", "> I guess you need to add the import library to the link command.\r\n> Find this file `tensorflow\\bazel-bin\\tensorflow\\libtensorflow.so.if.lib`\r\n\r\ni don't have `tensorflow\\bazel-bin\\tensorflow\\libtensorflow.so.if.lib` file", "> I guess you need to add the import library to the link command.\r\n> Find this file `tensorflow\\bazel-bin\\tensorflow\\libtensorflow.so.if.lib`\r\n\r\nonly `liblibtensorflow.so`  `liblibtensorflow.so.ifso` `libtensorflow.so` `libtensorflow.so-2.params` and `libtensorflow.so.runfiles_manifest`", "Oh, you must be using an old version of Bazel?  `liblibtensorflow.so.ifso` is the import library you want.", "> Oh, you must be using an old version of Bazel? `liblibtensorflow.so.ifso` is the import library you want.\r\n\r\nDo I need to use the old version of bazel and compile the tensorflow or  rename the liblibtensorflow.so.ifso to libtensorflow.so.if.lib and use Visual Studio 2015 to import it?", "> Oh, you must be using an old version of Bazel? `liblibtensorflow.so.ifso` is the import library you want.\r\n\r\nI tried to rename the `liblibtensorflow.so.ifso` to ` libtensorflow.so.if.lib` and import it in Visual Studio, but this error still occurred.", "@taotaolin Sorry, I'm not sure what the problem is exactly. But seems people are having lot of troubles to use TensorFlow's C++ library. I'll look into this the next few days, hopefully I can find a good solution for you.", "> @taotaolin Sorry, I'm not sure what the problem is exactly. But seems people are having lot of troubles to use TensorFlow's C++ library. I'll look into this a next few days, hopefully I can find a good solution for you.\r\n\r\nthanks", "I also get an error LNK2019 when connecting the library to the project.\r\n```c++\r\n#pragma comment(lib, \"tensorflow/libtensorflow_cc.so.if.lib\")\r\n```\r\n```\r\nError\tLNK2019\r\nunresolved external symbol \"char const * __cdecl tensorflow::core::GetVarint32PtrFallback(char const *,char const *,unsigned int *)\" (?GetVarint32PtrFallback@core@tensorflow@@YAPEBDPEBD0PEAI@Z) referenced in function \"char const * __cdecl tensorflow::core::GetVarint32Ptr(char const *,char const *,unsigned int *)\" (?GetVarint32Ptr@core@tensorflow@@YAPEBDPEBD0PEAI@Z)\tConsoleApplication1.obj\t1\t\r\n```\r\n.tf_configure.bazelrc: \r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"D:/ProgramFiles/Anaconda3/envs/pycharm/python.exe\"\r\nbuild --action_env PYTHON_LIB_PATH=\"D:/ProgramFiles/Anaconda3/envs/pycharm/lib/site-packages\"\r\nbuild --python_path=\"D:/ProgramFiles/Anaconda3/envs/pycharm/python.exe\"\r\nbuild:gcp --define with_gcp_support=true\r\nbuild:hdfs --define with_hdfs_support=true\r\nbuild:aws --define with_aws_support=true\r\nbuild:kafka --define with_kafka_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild:gdr --define with_gdr_support=true\r\nbuild:verbs --define with_verbs_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"0\"\r\nbuild --action_env TF_DOWNLOAD_CLANG=\"0\"\r\nbuild --define grpc_no_ares=true\r\nbuild:opt --copt=/arch:AVX\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --strip=always\r\nbuild --config monolithic\r\nbuild --copt=-w --host_copt=-w\r\nbuild --verbose_failures\r\n# build --config windows_msvc\r\n```\r\n```sh\r\nbazel --output_base=./ build :libtensorflow_cc.so\r\n```", "I meet the same problem. @taotaolin @meteorcloudy @Roffild \r\nI use the `tensorflow\\bazel-bin\\tensorflow\\libtensorflow.so.if.lib` in VS 2015. And there are errors.\r\n` error LNK2001: \u65e0\u6cd5\u89e3\u6790\u7684\u5916\u90e8\u7b26\u53f7 \"private: void __cdecl tensorflow::Tensor::CopyFromInternal(class tensorflow::Tensor const &,class tensorflow::TensorShape const &)\" (?CopyFromInternal@Tensor@tensorflow@@AEAAXAEBV12@AEBVTensorShape@2@@Z)`\r\nDoes anyone know how to use the libtensorflow_cc.so??", "@yicn Can you provide your source code or a minimal repo of this error?", "@meteorcloudy  Of course. This is the test code.\r\n```\r\n#define _SCL_SECURE_NO_WARNINGS\r\n#define NOMINMAX\r\n#define COMPILER_MSVC\r\n\r\n#include \"tensorflow/cc/client/client_session.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n\r\nint main() {\r\n\tusing namespace tensorflow;\r\n\tusing namespace tensorflow::ops;\r\n\tScope root = Scope::NewRootScope();\r\n\tauto A = Const(root, { { 3.f, 2.f },{ -1.f, 0.f } });\r\n\tauto b = Const(root, { { 3.f, 5.f } });\r\n\tauto v = MatMul(root.WithOpName(\"v\"), A, b, MatMul::TransposeB(true));\r\n\tstd::vector<Tensor> outputs;\r\n\tClientSession session(root);\r\n\tTF_CHECK_OK(session.Run({ v }, &outputs));\r\n\tstd::cout << outputs[0].matrix<float>();\r\n\tgetchar();\r\n\treturn 0;\r\n}\r\n```\r\nI also compile the code with the tensorflow r1.4 's dll and lib which is built using cmake, and it works well.  ", "@meteorcloudy So I have tried to build it with CUDA 9.0 and I got similar error\r\n```\r\nERROR: E:/tsf1.10/tensorflow/tensorflow/core/kernels/BUILD:775:1: C++ compilation of rule '//tensorflow/core/kernels:pad_op_gpu' failed (Exit 1): msvc_wrapper_for_nvcc.bat failed: error executing command \r\n  cd [...]/62ehlahw/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=E:/Programs/Nvidia\r\n    SET CUDNN_INSTALL_PATH=E:/Programs/Nvidia\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17134.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17134.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Programs/Anaconda/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Programs/Anaconda/lib/site-packages\r\n    SET TEMP=C:\\Users\\[...]\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_VERSION=9.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TMP=C:\\Users\\[...]\\AppData\\Local\\Temp \r\n```", "> I meet the same problem. @taotaolin @meteorcloudy @Roffild\r\n> I use the `tensorflow\\bazel-bin\\tensorflow\\libtensorflow.so.if.lib` in VS 2015. And there are errors.\r\n> `error LNK2001: \u65e0\u6cd5\u89e3\u6790\u7684\u5916\u90e8\u7b26\u53f7 \"private: void __cdecl tensorflow::Tensor::CopyFromInternal(class tensorflow::Tensor const &,class tensorflow::TensorShape const &)\" (?CopyFromInternal@Tensor@tensorflow@@AEAAXAEBV12@AEBVTensorShape@2@@Z)`\r\n> Does anyone know how to use the libtensorflow_cc.so??\r\n\r\n\u6211\u4e5f\u7f16\u8bd1\u597d\u4e86.so\u4e86\uff0c\u8fd9\u4e2a\u4e0d\u96be\uff0c\u4f46\u662f\u597d\u4e86\u4e4b\u540e\u4e0d\u77e5\u9053\u600e\u4e48\u7528\uff0c\u8fd9\u4e2a\u56f0\u96be\uff01", "> @meteorcloudy Of course. This is the test code.\r\n> \r\n> ```\r\n> #define _SCL_SECURE_NO_WARNINGS\r\n> #define NOMINMAX\r\n> #define COMPILER_MSVC\r\n> \r\n> #include \"tensorflow/cc/client/client_session.h\"\r\n> #include \"tensorflow/cc/ops/standard_ops.h\"\r\n> #include \"tensorflow/core/framework/tensor.h\"\r\n> \r\n> int main() {\r\n> \tusing namespace tensorflow;\r\n> \tusing namespace tensorflow::ops;\r\n> \tScope root = Scope::NewRootScope();\r\n> \tauto A = Const(root, { { 3.f, 2.f },{ -1.f, 0.f } });\r\n> \tauto b = Const(root, { { 3.f, 5.f } });\r\n> \tauto v = MatMul(root.WithOpName(\"v\"), A, b, MatMul::TransposeB(true));\r\n> \tstd::vector<Tensor> outputs;\r\n> \tClientSession session(root);\r\n> \tTF_CHECK_OK(session.Run({ v }, &outputs));\r\n> \tstd::cout << outputs[0].matrix<float>();\r\n> \tgetchar();\r\n> \treturn 0;\r\n> }\r\n> ```\r\n> I also compile the code with the tensorflow r1.4 's dll and lib which is built using cmake, and it works well.\r\n\r\n\u6211\u4eec\u4e00\u6837\uff0c\u62111.8\u7248\u672cCMAKE\u7f16\u8bd1\u7684\u7528\u8d77\u6765\u4e5f\u6ca1lnk error", "I believe only API defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h are available. \r\n@EdwardVincentMa @Croolman Can you explain to me how did you build the library with CMake and how were you using it?", "@meteorcloudy I did not use CMake, I ve used bazel as I have stated in https://github.com/tensorflow/tensorflow/issues/22338#issuecomment-424212735", "> I believe only API defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h are available.\r\n> @EdwardVincentMa @Croolman Can you explain to me how did you build the library with CMake and how were you using it?\r\n\r\nI can use the 1.6 version of tensorflow to successfully compile with cmake and use the C++ API, but the bazel compiled dll files can only be used at  Functions defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h", "> > I believe only API defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h are available.\r\n> > @EdwardVincentMa @Croolman Can you explain to me how did you build the library with CMake and how were you using it?\r\n> \r\n> I can use the 1.6 version of tensorflow to successfully compile with cmake and use the C++ API, but the bazel compiled dll files can only be used at Functions defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h\r\n\r\nTF 1.9+ has LKN error when using.", "> > I believe only API defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h are available.\r\n> > @EdwardVincentMa @Croolman Can you explain to me how did you build the library with CMake and how were you using it?\r\n> \r\n> I can use the 1.6 version of tensorflow to successfully compile with cmake and use the C++ API, but the bazel compiled dll files can only be used at Functions defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h\r\n\r\n\u5144\u5f1f\u4f60qq\u591a\u5c11", "\r\n\r\n\r\n> > > I believe only API defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h are available.\r\n> > > @EdwardVincentMa @Croolman Can you explain to me how did you build the library with CMake and how were you using it?\r\n> > \r\n> > \r\n> > I can use the 1.6 version of tensorflow to successfully compile with cmake and use the C++ API, but the bazel compiled dll files can only be used at Functions defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h\r\n> \r\n> \u5144\u5f1f\u4f60qq\u591a\u5c11\r\n\r\n`NzUyNzM5MDg2` base64\u89e3\u4e00\u4e0b", "\u8bf7\u95ee\u6700\u540e\u600e\u4e48\u89e3\u51b3\u7684\uff1f@taotaolin", "> \u8bf7\u95ee\u6700\u540e\u600e\u4e48\u89e3\u51b3\u7684\uff1f@taotaolin\r\n\r\n\u8fd9\u4e2a\u6700\u65b0\u7248\u6ca1\u6709\u89e3\u51b3\u3002\u3002\u88c5\u65e7\u7248\u672c\u7684tensorflow\u7528cmake\u7f16\u8bd1\u5c31\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898", "Has anybody solved this problem? I am able to build the release build, but as soon as I switch to dbg (debug), it shows a `'tensorflow::io::GetTempFilename': must return a value` error.", "I've worked on it for several days...\r\n\r\n1. I must denote that if you want a C++ API library, you should build with `//tensorflow:libtensorflow_cc.so` instead of `//tensorflow:libtensorflow.so`.\r\n1. Then you should encounter a problem like #23542 and somebody provide a way to solve it in [this comment](https://github.com/tensorflow/tensorflow/issues/22047#issuecomment-421452033). But I have no idea whether it is good or not.\r\n\r\nI have asked a [question](https://stackoverflow.com/questions/53809398/how-to-program-with-c-api-library-on-windows-using-bazel) on stackoverflow, and I hope people with similar problems can work together to solve it.", "See my [post](https://github.com/tensorflow/tensorflow/issues/22047#issuecomment-447992343). Let me know if it doesnt work.\r\n\r\n", "Some people in this thread still don't understand what OP said.\r\nMost instructions in Tensorflow sites are saying about how to build \"so\" file, which is used for Linux or Unix system.\r\nThe question of OP is how to build \"lib\" or \"dll\" file by using Bazel for Windows system.\r\n\r\nThis might be helpful:\r\n- https://github.com/tensorflow/tensorflow/issues/22047#issuecomment-421452033\r\n- https://github.com/tensorflow/tensorflow/issues/22047#issuecomment-447992343", "Well, the topic description states that it is about building the library on windows. \r\nBazel builds an so file, which is actually a dll. It also creates a lib file against which you can link with CMake. See my previous comment which links to the build scripts for windows (10).", "See my [comment](https://github.com/tensorflow/tensorflow/issues/7258#issuecomment-450802749) which provides a way to build on Windows.", "@guikarist Nice to see the acknowledgements. \r\nNice cleanup of the script and parsing of the parameters by the way.", "@guikarist @Steroes Thank you for the script, it makes the environment preparation much easier. However, it does not address the original issue: if I try to compile the debug version (with `-c dbg` parameter), I get a `error C4716: 'tensorflow::io::GetTempFilename': must return a value` error - this happens regardless whether I use the script or not.", "@matthewbundala I have built without this flag but succeeded to use VS debug tools or build debug Tensorflow program.", "@Steroes @guikarist Thank you for the script and i will try to compile the latest version again.", "@taotaolin This script cannot work on the latest Tensorflow. To be exact, it can only work on Tensorflow 1.11.0 at least now.", "@taotaolin \r\n\r\n> I tried to use the realse version of the dll file but an error message:\r\n> \r\n> ```\r\n> \u9519\u8bef\tLNK2019\t\u65e0\u6cd5\u89e3\u6790\u7684\u5916\u90e8\u7b26\u53f7 \"char const * __cdecl tensorflow::core::GetVarint32PtrFallback(char const *,char const *,unsigned int *)\" (?GetVarint32PtrFallback@core@tensorflow@@YAPEBDPEBD0PEAI@Z)\uff0c\u8be5\u7b26\u53f7\u5728\u51fd\u6570 \"char const * __cdecl tensorflow::core::GetVarint32Ptr(char const *,char const *,unsigned int *)\" (?GetVarint32Ptr@core@tensorflow@@YAPEBDPEBD0PEAI@Z) \u4e2d\u88ab\u5f15\u7528\tConsoleApplication1\tC:\\Users\\tao\\Desktop\\tensorflow-test\\ConsoleApplication1\\ConsoleApplication1\\ConsoleApplication1.obj\t1\t\r\n> ```\r\n\r\nHave you resolved this problem? Which seems that it cannot be solved by [my solution](https://github.com/guikarist/tensorflow-windows-build-script#prerequisites) according to [this issue](https://github.com/guikarist/tensorflow-windows-build-script/issues/3).", "> This script cannot work on the latest Tensorflow. To be exact, it can only work on Tensorflow 1.11.0 at least now.\r\n\r\n@taotaolin Now [the script](https://github.com/guikarist/tensorflow-windows-build-script) has supported Tensorflow 1.12.0!", "```error C4716: must return a value error```\r\nhttps://github.com/tensorflow/tensorflow/blob/3751264e3a1a91159c68603476461dfe164e92ce/tensorflow/core/lib/io/path.cc#L255\r\nhttps://github.com/tensorflow/tensorflow/blob/3751264e3a1a91159c68603476461dfe164e92ce/tensorflow/core/framework/device_base.cc#L28\r\nhttps://github.com/tensorflow/tensorflow/blob/3751264e3a1a91159c68603476461dfe164e92ce/tensorflow/core/framework/device_base.cc#L32", "@Roffild Did you use the script from [here](https://github.com/guikarist/tensorflow-windows-build-script)?\r\nI think you build in debug, is that correct. Debug is still not working properly.", "@taotaolin hi. my question is how do we use tensorflow.dll? where can we find the functions inside?  Or can you share some example?", "> @taotaolin\u55e8\u3002\u6211\u7684\u95ee\u9898\u662f\u6211\u4eec\u5982\u4f55\u4f7f\u7528tensorflow.dll\uff1f\u6211\u4eec\u5728\u54ea\u91cc\u53ef\u4ee5\u627e\u5230\u91cc\u9762\u7684\u529f\u80fd\uff1f\u6216\u8005\u4f60\u80fd\u5206\u4eab\u4e00\u4e9b\u4f8b\u5b50\u5417\uff1f\r\n\r\nI have an example of MNIST recognition, which I can show you tomorrow.", "> @taotaolin hi. my question is how do we use tensorflow.dll? where can we find the functions inside? Or can you share some example?\r\n\r\nPlease tell me your contact information", "> @taotaolin [wangxuesong29@gmail.com](mailto:wangxuesong29@gmail.com)\r\n> \r\n> Thanks.\r\n\r\nIt's too big. I put the code on github. The data set is MNIST.\r\n\r\n[MNIST_tensorflow_C](https://github.com/taotaolin/MNIST_tensorflow_C)", "> > This script cannot work on the latest Tensorflow. To be exact, it can only work on Tensorflow 1.11.0 at least now.\r\n> \r\n> @taotaolin Now [the script](https://github.com/guikarist/tensorflow-windows-build-script) has supported Tensorflow 1.12.0!\r\n\r\nERROR LNK2019 .  Have you resolved this problem? I don't seem to have solved this problem in the latest edition\r\n", "@Roffild You may replace the fatal message with this code, and it will work:\r\n\r\n#if defined(PLATFORM_WINDOWS)\r\n  for (const char* dir : std::vector<const char*>(\r\n           {getenv(\"TEST_TMPDIR\"), getenv(\"TMPDIR\"), getenv(\"TMP\"), getenv(\"TEMP\"), \"/tmp\"})) {\r\n    if (!dir || !dir[0]) {\r\n      continue;\r\n    }\r\n    struct stat statbuf;\r\n    if (!stat(dir, &statbuf) && S_ISDIR(statbuf.st_mode)) {\r\n      string tmp_filepath;\r\n      tmp_filepath = io::JoinPath(\r\n          dir,\r\n          strings::StrCat(\"tmp_file_tensorflow_\", UniqueId(), \"_XXXXXX\", extension));\r\n\t  //TODO Switch to secured method _mktemp_s\r\n\t  //int sizeInChars = strnlen(names[i], 9) + 1; \r\n\t  //int err = _mktemp_s( names[i], sizeInChars );\r\n      char* fd = _mktemp(&tmp_filepath[0]);\r\n      if (fd == nullptr) {\r\n        LOG(FATAL) << \"Failed to create temp file.\";\r\n      } else {\r\n        return tmp_filepath;\r\n      }\r\n    }\r\n  }\r\n  LOG(FATAL) << \"No temp directory found.\";  ", "You may add `--copt=/w34716` to the bazel build command line, e.g.\r\n`bazel build --copt=/w34716 --experimental_shortened_obj_file_path //moco:moco`\r\nThis makes the MSVC compiler happy.\r\nInspired by: https://stackoverflow.com/a/11386226/12338026\r\n\r\n> `error C4716: must return a value error`\r\n> https://github.com/tensorflow/tensorflow/blob/3751264e3a1a91159c68603476461dfe164e92ce/tensorflow/core/lib/io/path.cc#L255\r\n> \r\n> \r\n> https://github.com/tensorflow/tensorflow/blob/3751264e3a1a91159c68603476461dfe164e92ce/tensorflow/core/framework/device_base.cc#L28\r\n> \r\n> \r\n> https://github.com/tensorflow/tensorflow/blob/3751264e3a1a91159c68603476461dfe164e92ce/tensorflow/core/framework/device_base.cc#L32\r\n\r\n", "@taotaolin We are checking to see if you still need help on this issue. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. check comment: https://github.com/tensorflow/tensorflow/issues/22338#issuecomment-590247503 Thanks!'", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22338\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22338\">No</a>\n"]}, {"number": 22337, "title": "Support scoped_allocator_ops for renamed device.", "body": "This fixes #22274.\r\n\r\nSigned-off-by: Bairen Yi <byi@connect.ust.hk>", "comments": ["Thanks for the contribution @byronyi!", "@dubey Could you cherry-pick that to r1.11 as it\u2019s a bug fix?\r\n\r\nThanks!", "@byronyi I think we've missed the cherrypick deadline.  Also, the release policy is to not cherrypick bugfixes to contrib features, in this case distribution strategies, so it is unlikely this will be included in 1.11.\r\n\r\nPaging @gunan to confirm.", "Yes, no more cherrypicks into 1.11.\r\nHowever, we will cut 1.12 next week, so this will be in the next release."]}, {"number": 22336, "title": "ssd_mobilenet_v1_quantized_300x300_coco14_sync's mAP=0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform Ubuntu 16.04\r\n- **TensorFlow installed from source: models's commit = 55d55abc71483723743c0273b9c1fd8e0c7d8391 and tensorflow's commit = 6c3e1f4bc803f2dc8a804f4f15ada0eda6c90a18\r\n- **TensorFlow version **:1.9.0\r\n- **Python version**:Python 3.5.2 (default, Nov 23 2017, 16:37:01)\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: Cuda compilation tools, release 9.0, V9.0.176;cuDNN7.0\r\n- **GPU model and memory**: GeForce GTX 1070 Ti  * 4\r\n- **Exact command to reproduce**:\r\npython object_detection/model_main.py --pipeline_config_path=./object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config  --model_dir=/checkpoint/ssd_mobilenet_v1_quantized_300x300_coco14_sync --checkpoint_dir=/ssd/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18 --run_once=True\r\n\r\n### Describe the problem\r\n0.\r\ntrain\t\t118287\r\nwget -c http://images.cocodataset.org/zips/train2017.zip \r\nwget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip\r\neval\t\t5000\r\nwget -c http://images.cocodataset.org/zips/val2017.zip \r\nwget -c http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\r\n1\r\nDownload checkpoint in http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz\r\n2\r\nAmend file's path in models/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config\r\n3.\r\nfrom models/research,\r\npython object_detection/model_main.py --pipeline_config_path=./object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config  --model_dir=/checkpoint/ssd_mobilenet_v1_quantized_300x300_coco14_sync --checkpoint_dir=/ssd/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18 --run_once=True\r\n\r\n### Source code / logs\r\n1\r\n[ssd_mobilenet_v1_quantized_300x300_coco14_sync.zip](https://github.com/tensorflow/tensorflow/files/2391202/ssd_mobilenet_v1_quantized_300x300_coco14_sync.zip)\r\n2\r\n[ssd_mobilenet_v1_quantized_300x300_coco14_sync_log.txt](https://github.com/tensorflow/tensorflow/files/2391211/ssd_mobilenet_v1_quantized_300x300_coco14_sync_log.txt)\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nOS Platform and Distribution\nMobile device", "@cococyx Hi, Could you please explain the issue in brief ? Also appreciate if you provide a code snippet to reproduce the issue.", "OS Platform and Distribution :Ubuntu 16.04 , not Mobile device", "And ssd_mobilenet_v1_quantized_300x300_coco14_sync.config is attached ssd_mobilenet_v1_quantized_300x300_coco14_sync.zip\r\n\r\ndiff --git a/models/research/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config b/models/research/object_detection/samples/configs/ssd_mobilenet_v1_qua                                                  ntized_300x300_coco14_sync.config\r\nindex a79d772..ed054ab 100644\r\n--- a/models/research/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config\r\n+++ b/models/research/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config\r\n@@ -139,7 +139,8 @@ model {\r\n }\r\n\r\n train_config: {\r\n-  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED/model.ckpt\"\r\n+  #fine_tune_checkpoint: \"/data/checkpoint/ssd/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18/model.ckpt\"\r\n+  fine_tune_checkpoint: \"/data/checkpoint/ssd/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt\"\r\n   batch_size: 128\r\n   sync_replicas: true\r\n   startup_delay_steps: 0\r\n@@ -172,29 +173,29 @@ train_config: {\r\n }\r\n train_input_reader: {\r\n   tf_record_input_reader {\r\n-    input_path: \"PATH_TO_BE_CONFIGURED/mscoco_train.record-00000-of-00100\"\r\n+    input_path: \"/data/dataset/coco/output_train/coco_train.record-?????-of-00100\"\r\n   }\r\n-  label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\r\n+  label_map_path: \"/home/DLA_TF19_Train/models/research/object_detection/data/mscoco_label_map.pbtxt\"\r\n }\r\n\r\n eval_config: {\r\n   metrics_set: \"coco_detection_metrics\"\r\n   use_moving_averages: false\r\n-  num_examples: 8000\r\n+  num_examples: 5000\r\n }\r\n\r\n eval_input_reader: {\r\n   tf_record_input_reader {\r\n-    input_path: \"PATH_TO_BE_CONFIGURED/mscoco_val.record-00000-of-00010\"\r\n+    input_path: \"/data/dataset/coco/output_val/coco_val.record-?????-of-00010\"\r\n   }\r\n-  label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\r\n+  label_map_path: \"/home/DLA_TF19_Train/models/research/object_detection/data/mscoco_label_map.pbtxt\"\r\n   shuffle: false\r\n   num_readers: 1\r\n }\r\n\r\n graph_rewriter {\r\n   quantization {\r\n-    delay: 48000\r\n+    delay: 4800\r\n     activation_bits: 8\r\n     weight_bits: 8\r\n   }\r\n", "This is easy to reproduce by\r\n\r\npython object_detection/model_main.py --pipeline_config_path=./object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config --model_dir=/checkpoint/ssd_mobilenet_v1_quantized_300x300_coco14_sync --checkpoint_dir=/ssd/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18 --run_once=True\r\n \r\nfrom models/research", "hi bro @cococyx , do you solve the problem. i got a similar problem. the all of AP/AR are almost 0 when I train ssd using .config: ssd_mobilenet_v2_quantized_300x300_coco_2018_09_14.config and its corresponding pre-trained checkpoint.\r\ncould someone help or give some hint? thank you ", "This bug is a couple of years old and the assignee is no longer working in this area, so closing this since we're unlikely to get to it. Please reopen if you are still hitting this problem."]}, {"number": 22335, "title": "Add linear_operator_addition to tensorflow/python/.  A subsequent CL", "body": "will remove this from contrib.\r\nlinear_operator_addition is hidden from the public API.\r\n\r\nPiperOrigin-RevId: 212655087", "comments": ["Assign to angersson since this PR is for release branch.", "This is an addition.\r\nOnly critical bugfixes are accepted as cherrypicks into the release."]}]