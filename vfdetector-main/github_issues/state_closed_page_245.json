[{"number": 47154, "title": "[TFL] Optimize add/sub", "body": "- Assign to `Eigen::Map` will cause forced evaluation. Chain `cwiseMin` and `cwiseMax` to avoid read/write memory twice. One can verify with\r\n\r\n```cpp\r\n#include <Eigen/Core>\r\n#include <algorithm>\r\n\r\nvoid foo(int* a, int mn, int mx, int n) {\r\n  Eigen::Map<Eigen::Matrix<int, Eigen::Dynamic, 1>> vector_map(a, n, 1);\r\n  vector_map = vector_map.cwiseMin(mx);\r\n  vector_map = vector_map.cwiseMax(mn);\r\n}\r\n\r\nvoid bar(int* a, int mn, int mx, int n) {\r\n  Eigen::Map<Eigen::Matrix<int, Eigen::Dynamic, 1>> vector_map(a, n, 1);\r\n  vector_map = vector_map.cwiseMin(mx).cwiseMax(mn);\r\n}\r\n\r\nvoid zoo(int* a, int mn, int mx, int n) {\r\n  for (int i = 0; i < n; ++i) {\r\n    a[i] = std::min(std::max(a[i], mn), mx);\r\n  }\r\n}\r\n```\r\n\r\n- Optimize non broadcast sub with Eigen\r\n   - `SetActivationMinMax` is the same with `GetActivationParams` in `tensorflow/lite/kernels/internal/types.h`\r\n   - I cannot see any usage of  `SubNonBroadcast` across TensorFlow. It's just an alias of `SubWithActivation`, which is the real function being dispatched.\r\n   - Eigen's vectorization for neon looks pretty good. Do we need to write intrinsics like some of optimized kernels in tflite?\r\n\r\nOn pixel 3a, benchmark with single op\r\n\r\n-----\r\n\r\nSub two (224 * 224 * 32) float32 \r\n\r\nBefore \r\n```\r\nTimings (microseconds): count=191 first=2281 curr=2278 min=2250 max=3229 avg=2445.86 std=251\r\n```\r\nAfter\r\n```\r\nTimings (microseconds): count=208 first=1769 curr=1757 min=1715 max=3050 avg=2083.2 std=397\r\n```\r\n\r\n-----\r\n\r\n\r\nAdd two (224 * 224 * 32) int32 (I modify int32 kernel only)\r\n\r\nBefore\r\n```\r\nTimings (microseconds): count=133 first=4698 curr=4344 min=4201 max=6049 avg=4628.22 std=429\r\n```\r\nCommit 6fc655b\r\n```\r\nTimings (microseconds): count=158 first=3307 curr=3015 min=2917 max=4429 avg=3335.49 std=419\r\n```\r\nCommit 86c1a09 -  fuse add and clip\r\n```\r\nTimings (microseconds): count=221 first=1985 curr=1706 min=1596 max=3085 avg=1901.17 std=404\r\n```", "comments": ["Could you provide some numbers regarding performance improvements on common android devices? https://www.tensorflow.org/lite/performance/measurement#android_performance_benchmarks", "Hi @abattery, here is the benchmark on my pixel 3a with a simple single op model. Run with `adb shell taskset f0 --graph=model.tflite --num_threads=1 --enable_op_profiling=true --num_runs=100`\r\n\r\n-----\r\n\r\nSub two (224 * 224 * 32) float32 \r\n\r\nBefore \r\n```\r\nTimings (microseconds): count=191 first=2281 curr=2278 min=2250 max=3229 avg=2445.86 std=251\r\n```\r\nAfter\r\n```\r\nTimings (microseconds): count=208 first=1769 curr=1757 min=1715 max=3050 avg=2083.2 std=397\r\n```\r\n\r\n-----\r\n\r\nAdd two (224 * 224 * 32) int32 (I modify int32 kernel only)\r\n\r\nBefore\r\n```\r\nTimings (microseconds): count=133 first=4698 curr=4344 min=4201 max=6049 avg=4628.22 std=429\r\n```\r\nCommit 6fc655b\r\n```\r\nTimings (microseconds): count=158 first=3307 curr=3015 min=2917 max=4429 avg=3335.49 std=419\r\n```\r\nLatest commit 86c1a09 -  fuse add and clip\r\n```\r\nTimings (microseconds): count=221 first=1985 curr=1706 min=1596 max=3085 avg=1901.17 std=404\r\n```", "Thanks, the numbers look great. Could you update the PR's description with those numbers for the commit's history?"]}, {"number": 47153, "title": "Add reminder on MacOS Catalina", "body": "ARM mbed MacOS installer (mbed-cli-v0.0.10.dmg from https://github.com/ARMmbed/mbed-cli-osx-installer/releases/tag/v0.0.10) creates error during installation.\r\n\r\nIt is caused by MacOS Catalina moving path of terminal app from _/Applications/Utilities/Terminal.app_ to _/System/Applications/Utilities/Terminal.app_. ) ARM mbed installer scripts still use _/Applications/Utilities/Terminal.app_.\r\n\r\nSo add a reminder, and a [link](https://github.com/ARMmbed/mbed-cli/issues/930#issuecomment-660550734) to a solution from ARM mbed github.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47153) for more info**.\n\n<!-- need_sender_cla -->", "@marconi1964  Can you please sign CLA. Thanks!\r\n", " @googlebot I signed it!\n\n    On Monday, February 15, 2021, 04:14:43 PM GMT+8, google-cla[bot] <notifications@github.com> wrote:  \n \n \n\n\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n \ud83d\udcdd Please visit https://cla.developers.google.com/ to sign.\n\nOnce you've signed (or fixed any issues), please reply here with @googlebot I signed it! and we'll verify it.\n\nWhat to do if you already signed the CLA\n\nIndividual signers\n   \n   - It's possible we don't have your GitHub username or you're using a different email address on your commit. Check your existing CLA data and verify that your email is set on your git commits.\n\nCorporate signers\n   \n   - Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to go/cla#troubleshoot (Public version).\n   - The email used to register you as an authorized contributor must be the email used for the Git commit. Check your existing CLA data and verify that your email is set on your git commits.\n   - The email used to register you as an authorized contributor must also be attached to your GitHub account.\n\n \u2139\ufe0f Googlers: Go here for more info.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or unsubscribe.\n  "]}, {"number": 47152, "title": "Update README.md", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47152) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47152) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47152) for more info**.\n\n<!-- need_sender_cla -->", "@Pulkit0076  Can you please sign CLA. Thanks!", "> @Pulkit0076 Can you please sign CLA. Thanks!\r\n\r\n@gbaned already done :)\r\n![image](https://user-images.githubusercontent.com/71369943/107935446-69ca0180-6fa7-11eb-92ff-67c1bde6abdc.png)\r\n", "Why did you delete the file?\r\n", "> Why did you delete the file?\r\nActually it was having some errors, so I updated and deleted the file that was having a error", "There cannot be an error from a README file.", "> There cannot be an error from a README file.\r\n\r\nI meant to say in first file , I made a mistake so I updated it and deleted the error commit ( file )", "Your first commit is spam."]}, {"number": 47151, "title": "ERROR: Could not find a version that satisfies the requirement tensorflow ERROR: No matching distribution found for tensorflow", "body": "I'm trying to install the TensorFlow lib for 3 days now & tried everything, I'm using win10 64 bit and python 3.9.1 64 bit with up to date pip\r\n\r\n", "comments": ["![image](https://user-images.githubusercontent.com/79036528/107900745-9d2a7300-6f4a-11eb-9316-cade5c093845.png)\r\n\r\nand that what happened!!!\r\nCan you please help!", "@EmadElDinH TensorFlow has not supported Python3.9 yet.  See https://github.com/tensorflow/tensorflow/issues/44485. As a workaround, can you try to install Python3.8 or lower version?", "actually this is what I'm doing right now ....\r\nI'll check it & come back to you!\r\nthanks!", "@EmadElDinH,\r\nTensorFlow v2.4 is compatible with Python 3.6 - 3.8. For more information, please take a look at the [tested build configurations](https://www.tensorflow.org/install/source_windows#cpu).\r\n\r\n\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\n-- | -- | -- | -- | -- | --\r\ntensorflow_gpu-2.4.0 | 3.6-3.8 | MSVC 2019 | Bazel 3.1.0 | 8.0 | 11.0\r\ntensorflow_gpu-2.3.0 | 3.5-3.8 | MSVC 2019 | Bazel 3.1.0 | 7.6 | 10.1\r\ntensorflow_gpu-2.2.0 | 3.5-3.8 | MSVC 2019 | Bazel 2.0.0 | 7.6 | 10.1\r\n\r\n\r\nAs mentioned by @WindQAQ, support for Python 3.9 is already being tracked in issue [#44485](https://github.com/tensorflow/tensorflow/issues/44485). \r\n\r\nThanks!", "Same issue on python 3.8\r\n```\r\nster \u219135 \ue0b0 pip install tensorflow                             \ue0b2 1 \u21b5 \ue0b2 3430 \ue0b2 14:09:46\r\nERROR: Could not find a version that satisfies the requirement tensorflow\r\nERROR: No matching distribution found for tensorflow\r\n```\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@evalsocket Please post output of `python --version`, `python -m pip --version` and `python -m pip install -vvv tensorflow`", "Closing as stale. Please reopen if you'd like to work on this further.\n", "These steps gave me a solution to the error.\r\n\r\n# In[3]: pip install --user virtualenv\r\n\r\n\r\n# In[3]: pip install wheel\r\n\r\n\r\n# In[1]: pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\r\n\r\n\r\n# In[ ]: pip install tf-nightly", "This:\r\n pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl gave me the response as well\r\n", "These are not TF errors. You pip install is old and needs to be updated. Please file a bug on Pip repo if that is not the case as most likely the issue comes from there"]}, {"number": 47150, "title": "I tried filling in all of your \"form\" & you closed off the issue so, were going to do this EVERY DAY until you act like grown ups", "body": "Backend terminated or disconnected.Fatal Python error: Illegal instruction\r\n\r\nCurrent thread 0x00007f0f5412a740 (most recent call first):\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 1101 in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 556 in module_from_spec\r\n  File \"<frozen importlib._bootstrap>\", line 657 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"/home/ian/.local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64 in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 783 in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 671 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1042 in _handle_fromlist\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"/home/ian/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py\", line 39 in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 783 in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 671 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 961 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"/home/ian/.local/lib/python3.8/site-packages/tensorflow/__init__.py\", line 41 in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 783 in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 671 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"<pyshell>\", line 1 in <module>\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1272 in _execute_prepared_user_code\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1200 in wrapper\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1213 in wrapper\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1259 in execute_source\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 814 in _execute_source\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 444 in _cmd_execute_source\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 204 in handle_command\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 146 in mainloop\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend_launcher.py\", line 87 in <module> Use 'Stop/Restart' to restart.\r\n\r\n", "comments": ["@IanSMoyes,\r\nIn order to expedite the trouble-shooting process, could you please provide the following details\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nand the exact sequence of commands / steps that you executed before running into the error. \r\n\r\nThanks!", "Please don't spam. Please follow the rules listed in [the code of conduct](https://github.com/tensorflow/tensorflow/blob/master/CODE_OF_CONDUCT.md)"]}, {"number": 47149, "title": "ValueError: Cannot add function '__inference_Dataset_map_<lambda>_12' because a different function with the same name already exists.", "body": "Hi\r\n I am using ubuntu 16.04 , and tensorflow-gpu==1.14.0, I obtained this error \r\n\" ValueError: Cannot add function '__inference_Dataset_map_<lambda>_12' because a different function with the same name already exists.\"\r\n\r\nPlease let me know if you have idea how I can resolve it? thank you in advance.\r\n\r\n", "comments": ["@dardaa \r\nThere is no support for tf 1.x, please upgrade to tf 2.x and let us know if you face nay issues.", "@Saduf2019 \r\nthank you for your reply. the code is written with tf 1.x  so when i upgraded tensorflow, I obtained a lot of error, anyway i tried to correct some bugs but I did not able to resolve the following error \"\"\"\"\"\"\"  TypeError: Dimension value must be integer or None or have an __index__ method, got value 'tf.float32' with type '<class 'tensorflow.python.framework.dtypes.DType'>'\"\"\"\"\"\"\"\r\nI will attach the script python, please let me know if you know how i can resolve it.\r\n\r\n\r\n[predict.txt](https://github.com/tensorflow/tensorflow/files/5981401/predict.txt)\r\n", "@dardaa \r\nI ran the code shared but face a different error, please find the [gist](https://colab.research.google.com/gist/Saduf2019/e983882514862d98280d15a585e9016c/untitled538.ipynb) here and share all dependencies such that we can replicate the issue faced.", "@Saduf2019 \r\nI appreciate your time\r\nso I need to share all the files and the weights, the datasets.. anyway I will attach a screenshot for the output maybe you can understand well the reason of the bug.\r\n![Screenshot from 2021-02-15 23-48-32](https://user-images.githubusercontent.com/23746643/107999824-b7b32980-6fe8-11eb-8541-c3c537f4e479.png)\r\n\r\nfor the this \"\"\"\"\"     iterator = tf.data.Iterator.from_structure(tf.data.get_output_types(valDataset), tf.data.get_output_types(valDataset))\r\n\"\"\"\" \r\nit was \"\"\"\"\"\"\"\"\"\"\"\"\"\"\" iterator = tf.data.Iterator.from_structure(valDataset.output_types, valDataset.output_shapes)\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\r\nbut when i updated the tensorflow from 1.x to 2.x i did some modification.\r\ni am for your reply.\r\n\r\n", "@dardaa Can you please simple standalone code (with any public data) to reproduce the issue? The code code is too long and not complete. We recommend this kind of support related questions in Stackoverflow where there is a large community to support issues. GitHub is mainly for bugs and performance related issues. Thanks!", "hi \r\ni resolved the  previous error but i meet another error .\r\neven i tried on colab server and i obtain the same issue: \r\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\r\n\r\n\r\n\t [[{{node EagerPyFunc}}]]\r\n\t [[IteratorGetNext]]\r\n ", "the lines of codes caused the error are:\r\n  # read image and label\r\n    image = self.read_image(image_path.decode(\"utf-8\"))\r\n    label = self.read_image(label_path.decode(\"utf-8\"))", "I am closing this issue as this is more of a support type issue without a simple standalone code. Thanks!\r\n \r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47149\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47149\">No</a>\n"]}, {"number": 47148, "title": "[MLIR] Add conversion of `tf.leakyRelu` and `tf.leakyReluGrad` from t\u2026", "body": "\u2026f to mhlo.\r\n\r\nThis commits implements conversion of tf.leakyRelu and tf.leakyReluGrad\r\noperations from tf to mhlo. The changes have been made as a part of\r\nxla-legalize-tf pass.\r\n\r\nSigned-off-by: Prashant Kumar <prashantk@polymagelabs.com>", "comments": []}, {"number": 47147, "title": "GPU not detected / tf.test.is_built_with_cuda returns False", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: N/A\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: N/A\r\n-   **TensorFlow installed from (source or binary)**: conda\r\n-   **TensorFlow version (use command below)**: 2.3.0\r\n-   **Python version**: 3.8.5 [Anaconda 2020.11]\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**: 10.1 / 7.6.4 [graphics driver 461.40]\r\n-   **GPU model and memory**: GeForce RTX 3080 / 10GB [EVGA Black]\r\n-   **Exact command to reproduce**: import tensorflow as tf, tf.test.is_built_with_cuda()\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\n-Installed MSVS 2019 Community Edition\r\n-Installed Cuda Toolkit 10.1 [in preparation for TensorFlow 2.3.0 from conda]. NOTE: Did custom installation, not installing the graphics or physics drivers as I already have the most up to date drivers.\r\n-Installed / copied drivers across from cuDNN 7.6.4\r\n-Installed Anaconda 2020.11\r\n-Created environment and installed TensorFlow-GPU [conda create -n tf-gpu tensorflow-gpu]\r\n-Activated tf-gpu environment [conda activate tf-gpu]\r\n-started python [python]\r\n-imported tensorflow [import tensorflow as tf]\r\n-checked installation [tf.test.is_built_with_cuda()]\r\nreturns False\r\n-checked for GPU [tf.config.list_physical_devices('GPU')\r\nreturns []\r\n\r\nI'm not sure what I'm missing or doing wrong during the installation. I don't have the CPU only tensorflow installed. Is it because I am not installing the graphics drivers with CUDA Toolkit? Any help is much appreciated.\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["As an update I ran the deviceQuery program and CUDA seems to be able to see by GPU; but tensorflow doesn't?\r\n\r\n\r\nC:\\Users\\XXXX>cd C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\extras\\demo_suite\r\n\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\extras\\demo_suite>deviceQuery.exe\r\ndeviceQuery.exe Starting...\r\n\r\n CUDA Device Query (Runtime API) version (CUDART static linking)\r\n\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: \"GeForce RTX 3080\"\r\n  CUDA Driver Version / Runtime Version          11.2 / 10.1\r\n  CUDA Capability Major/Minor version number:    8.6\r\n  Total amount of global memory:                 10240 MBytes (10737418240 bytes)\r\nMapSMtoCores for SM 8.6 is undefined.  Default to use 64 Cores/SM\r\nMapSMtoCores for SM 8.6 is undefined.  Default to use 64 Cores/SM\r\n  (68) Multiprocessors, ( 64) CUDA Cores/MP:     4352 CUDA Cores\r\n  GPU Max Clock rate:                            1710 MHz (1.71 GHz)\r\n  Memory Clock rate:                             9501 Mhz\r\n  Memory Bus Width:                              320-bit\r\n  L2 Cache Size:                                 5242880 bytes\r\n  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\r\n  Total amount of constant memory:               zu bytes\r\n  Total amount of shared memory per block:       zu bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  1536\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\r\n  Maximum memory pitch:                          zu bytes\r\n  Texture alignment:                             zu bytes\r\n  Concurrent copy and kernel execution:          Yes with 5 copy engine(s)\r\n  Run time limit on kernels:                     Yes\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  CUDA Device Driver Mode (TCC or WDDM):         WDDM (Windows Display Driver Model)\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Device supports Compute Preemption:            Yes\r\n  Supports Cooperative Kernel Launch:            Yes\r\n  Supports MultiDevice Co-op Kernel Launch:      No\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\n\r\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.2, CUDA Runtime Version = 10.1, NumDevs = 1, Device0 = GeForce RTX 3080\r\nResult = PASS", "@deepLearner84,\r\nPlease try installing **TensorFlow v2.4** with **CUDA 11.0** and **cuDNN 8** as mentioned in the [tested build configurations](https://www.tensorflow.org/install/source_windows#gpu) and check if you are facing the same issue. \r\n\r\n\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\n-- | -- | -- | -- | -- | --\r\ntensorflow_gpu-2.4.0 | 3.6-3.8 | MSVC 2019 | Bazel 3.1.0 | 8.0 | 11.0\r\ntensorflow_gpu-2.3.0 | 3.5-3.8 | MSVC 2019 | Bazel 3.1.0 | 7.6 | 10.1\r\ntensorflow_gpu-2.2.0 | 3.5-3.8 | MSVC 2019 | Bazel 2.0.0 | 7.6 | 10.1\r\n\r\nThanks!", "@amahendrakar Thank you for your quick response, this has resolved the issue. What had I done wrong? My understanding was that cuDNN 7.6 / CUDA 10.1 was the tested build configuration for tensorflow 2.3.0? Cheers", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47147\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47147\">No</a>\n"]}, {"number": 47146, "title": "Python import failure", "body": "**System information**\r\n- OS Platform and Distribution (Linux Ubuntu 20 latest update):\r\n- Mobile device ()Starlabs Star Lite laptop with 8Gb of RAM 113Gb of SSD space:\r\n- TensorFlow installed from (pip install tensorflow==2.4.1):\r\n- TensorFlow version: see above\r\n- Python version: Python 3.8.5 (/usr/bin/python3)\r\n- Installed using virtualenv? pip? conda?: See above\r\n- Bazel version (if compiling from source): NA NA\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: Dunno\r\n- GPU model and memory: (description: VGA compatible controller\r\n       product: UHD Graphics 605\r\n       vendor: Intel Corporation\r\n       physical id: 2\r\n       bus info: pci@0000:00:02.0\r\n       version: 03\r\n       width: 64 bits\r\n       clock: 33MHz\r\n       capabilities: pciexpress msi pm vga_controller bus_master cap_list rom\r\n       configuration: driver=i915 latency=0\r\n       resources: irq:132 memory:a0000000-a0ffffff memory:90000000-9fffffff ioport:f000(size=64) memory:c0000-dffff)\r\n\r\n\r\n\r\n**Describe the problem**\r\nwhen I import tensorflow into the Thonny shell I get:\r\n\r\nBackend terminated or disconnected.Fatal Python error: Illegal instruction\r\n\r\nCurrent thread 0x00007f30949d8740 (most recent call first):\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 1101 in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 556 in module_from_spec\r\n  File \"<frozen importlib._bootstrap>\", line 657 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"/home/ian/.local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64 in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 783 in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 671 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1042 in _handle_fromlist\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"/home/ian/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py\", line 39 in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 783 in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 671 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 961 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"/home/ian/.local/lib/python3.8/site-packages/tensorflow/__init__.py\", line 41 in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 783 in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 671 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"<pyshell>\", line 1 in <module>\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1272 in _execute_prepared_user_code\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1200 in wrapper\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1213 in wrapper\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1259 in execute_source\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 814 in _execute_source\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 444 in _cmd_execute_source\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 204 in handle_command\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 146 in mainloop\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend_launcher.py\", line 87 in <module> Use 'Stop/Restart' to restart.Backend terminated or disconnected.Fatal Python error: Illegal instruction\r\n\r\nCurrent thread 0x00007f30949d8740 (most recent call first):\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 1101 in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 556 in module_from_spec\r\n  File \"<frozen importlib._bootstrap>\", line 657 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"/home/ian/.local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64 in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 783 in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 671 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1042 in _handle_fromlist\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"/home/ian/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py\", line 39 in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 783 in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 671 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 961 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"/home/ian/.local/lib/python3.8/site-packages/tensorflow/__init__.py\", line 41 in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 219 in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap_external>\", line 783 in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 671 in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 975 in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 991 in _find_and_load\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 285 in _custom_import\r\n  File \"<pyshell>\", line 1 in <module>\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1272 in _execute_prepared_user_code\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1200 in wrapper\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1213 in wrapper\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 1259 in execute_source\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 814 in _execute_source\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 444 in _cmd_execute_source\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 204 in handle_command\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend.py\", line 146 in mainloop\r\n  File \"/usr/lib/python3/dist-packages/thonny/backend_launcher.py\", line 87 in <module> Use 'Stop/Restart' to restart.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npip install tensorflow==2.4.1 # into the terminal\r\n# followed by\r\n\r\nimport tensorflow # into Thonny's shell\r\n\r\n# the error appears in the shell\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nNA\r\n", "comments": ["@IanSMoyes,\r\nCould you please share the make and model of the CPU on your machine and output of the `cat /proc/cpuinfo` command with us.\r\n\r\nStarting with v1.6, TensorFlow binaries use AVX instructions which may not run on older CPUs. For more information, please take a look at the [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements) for installing TensorFlow. Also check similar issues [#33038](https://github.com/tensorflow/tensorflow/issues/33038#issuecomment-538470776), [#29788](https://github.com/tensorflow/tensorflow/issues/29788#issuecomment-505571104) for reference.\r\n\r\nThanks!", "Hello,\nI'm VERY grateful for your response this time. Thank you.\n\nHere is the output from cat /proc/cpuinfo which I included with my original\nquestion, the one that was ignored and closed.\n\nprocessor : 0\nvendor_id : GenuineIntel\ncpu family : 6\nmodel : 122\nmodel name : Intel(R) Pentium(R) Silver N5000 CPU @ 1.10GHz\nstepping : 1\nmicrocode : 0x32\ncpu MHz : 1266.027\ncache size : 4096 KB\nphysical id : 0\nsiblings : 4\ncore id : 0\ncpu cores : 4\napicid : 0\ninitial apicid : 0\nfpu : yes\nfpu_exception : yes\ncpuid level : 24\nwp : yes\nflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat\npse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb\nrdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology\nnonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor\nds_cpl vmx est tm2 ssse3 sdbg cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe\npopcnt tsc_deadline_timer aes xsave rdrand lahf_lm 3dnowprefetch\ncpuid_fault cat_l2 pti cdp_l2 ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow\nvnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust smep erms mpx rdt_a\nrdseed smap clflushopt intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves\ndtherm ida arat pln pts umip rdpid md_clear arch_capabilities\nvmx flags : vnmi preemption_timer posted_intr invvpid ept_x_only ept_ad\nept_1gb flexpriority apicv tsc_offset vtpr mtf vapic ept vpid\nunrestricted_guest vapic_reg vid ple shadow_vmcs ept_mode_based_exec\ntsc_scaling\nbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass\nbogomips : 2188.80\nclflush size : 64\ncache_alignment : 64\naddress sizes : 39 bits physical, 48 bits virtual\npower management:\n\nprocessor : 1\nvendor_id : GenuineIntel\ncpu family : 6\nmodel : 122\nmodel name : Intel(R) Pentium(R) Silver N5000 CPU @ 1.10GHz\nstepping : 1\nmicrocode : 0x32\ncpu MHz : 1321.060\ncache size : 4096 KB\nphysical id : 0\nsiblings : 4\ncore id : 1\ncpu cores : 4\napicid : 2\ninitial apicid : 2\nfpu : yes\nfpu_exception : yes\ncpuid level : 24\nwp : yes\nflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat\npse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb\nrdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology\nnonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor\nds_cpl vmx est tm2 ssse3 sdbg cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe\npopcnt tsc_deadline_timer aes xsave rdrand lahf_lm 3dnowprefetch\ncpuid_fault cat_l2 pti cdp_l2 ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow\nvnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust smep erms mpx rdt_a\nrdseed smap clflushopt intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves\ndtherm ida arat pln pts umip rdpid md_clear arch_capabilities\nvmx flags : vnmi preemption_timer posted_intr invvpid ept_x_only ept_ad\nept_1gb flexpriority apicv tsc_offset vtpr mtf vapic ept vpid\nunrestricted_guest vapic_reg vid ple shadow_vmcs ept_mode_based_exec\ntsc_scaling\nbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass\nbogomips : 2188.80\nclflush size : 64\ncache_alignment : 64\naddress sizes : 39 bits physical, 48 bits virtual\npower management:\n\nprocessor : 2\nvendor_id : GenuineIntel\ncpu family : 6\nmodel : 122\nmodel name : Intel(R) Pentium(R) Silver N5000 CPU @ 1.10GHz\nstepping : 1\nmicrocode : 0x32\ncpu MHz : 1222.266\ncache size : 4096 KB\nphysical id : 0\nsiblings : 4\ncore id : 2\ncpu cores : 4\napicid : 4\ninitial apicid : 4\nfpu : yes\nfpu_exception : yes\ncpuid level : 24\nwp : yes\nflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat\npse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb\nrdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology\nnonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor\nds_cpl vmx est tm2 ssse3 sdbg cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe\npopcnt tsc_deadline_timer aes xsave rdrand lahf_lm 3dnowprefetch\ncpuid_fault cat_l2 pti cdp_l2 ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow\nvnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust smep erms mpx rdt_a\nrdseed smap clflushopt intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves\ndtherm ida arat pln pts umip rdpid md_clear arch_capabilities\nvmx flags : vnmi preemption_timer posted_intr invvpid ept_x_only ept_ad\nept_1gb flexpriority apicv tsc_offset vtpr mtf vapic ept vpid\nunrestricted_guest vapic_reg vid ple shadow_vmcs ept_mode_based_exec\ntsc_scaling\nbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass\nbogomips : 2188.80\nclflush size : 64\ncache_alignment : 64\naddress sizes : 39 bits physical, 48 bits virtual\npower management:\n\nprocessor : 3\nvendor_id : GenuineIntel\ncpu family : 6\nmodel : 122\nmodel name : Intel(R) Pentium(R) Silver N5000 CPU @ 1.10GHz\nstepping : 1\nmicrocode : 0x32\ncpu MHz : 1070.831\ncache size : 4096 KB\nphysical id : 0\nsiblings : 4\ncore id : 3\ncpu cores : 4\napicid : 6\ninitial apicid : 6\nfpu : yes\nfpu_exception : yes\ncpuid level : 24\nwp : yes\nflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat\npse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb\nrdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology\nnonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor\nds_cpl vmx est tm2 ssse3 sdbg cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe\npopcnt tsc_deadline_timer aes xsave rdrand lahf_lm 3dnowprefetch\ncpuid_fault cat_l2 pti cdp_l2 ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow\nvnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust smep erms mpx rdt_a\nrdseed smap clflushopt intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves\ndtherm ida arat pln pts umip rdpid md_clear arch_capabilities\nvmx flags : vnmi preemption_timer posted_intr invvpid ept_x_only ept_ad\nept_1gb flexpriority apicv tsc_offset vtpr mtf vapic ept vpid\nunrestricted_guest vapic_reg vid ple shadow_vmcs ept_mode_based_exec\ntsc_scaling\nbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass\nbogomips : 2188.80\nclflush size : 64\ncache_alignment : 64\naddress sizes : 39 bits physical, 48 bits virtual\npower management:\n\nOn Mon, 15 Feb 2021 at 06:25, Abhilash Mahendrakar <notifications@github.com>\nwrote:\n\n> @IanSMoyes <https://github.com/IanSMoyes>,\n> Could you please share the make and model of the CPU on your machine and\n> output of the cat /proc/cpuinfo command with us.\n>\n> Starting with v1.6, TensorFlow binaries use AVX instructions which may not\n> run on older CPUs. For more information, please take a look at the hardware\n> requirements\n> <https://www.tensorflow.org/install/pip#hardware-requirements> for\n> installing TensorFlow. Also check similar issues #33038\n> <https://github.com/tensorflow/tensorflow/issues/33038#issuecomment-538470776>,\n> #29788\n> <https://github.com/tensorflow/tensorflow/issues/29788#issuecomment-505571104>\n> for reference.\n>\n> Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/47146#issuecomment-778978937>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AO64SOPNGBP5YGKCSDCHQCDS7C44RANCNFSM4XTMR6ZA>\n> .\n>\n", "Your CPU does not support AVX. You have to compile from source or use a newer machine / a VM in the cloud.", "Thank you for that helpful information. Can you please post a link to what I have to download and how to install it?", "@IanSMoyes,\r\nPlease follow [this guide](https://www.tensorflow.org/install/source) to build TensorFlow from source on Linux machines.\r\n\r\nMake sure you have all the required dependencies installed as mentioned in the [tested build configurations](https://www.tensorflow.org/install/source#linux). Thanks!", "Closing as duplicate of  #33038, #29788 and several others", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47146\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47146\">No</a>\n"]}, {"number": 47145, "title": "tensorflow", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Issue template not filled, no subject. Closing.", "I'm so very glad that you've solved your problem de jour. I, on the other hand, don't have a solution to my problem. Google, the wealthiest company on the planet EVER, can't offer some resource to solving problems with their software."]}, {"number": 47144, "title": "Hi I am trying to compile on windows and get errors", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): trying to install from source\r\n- TensorFlow version:2.2\r\n- Python version:3.9\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):3.73\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:11.2/8.1.0.77\r\n- GPU model and memory:RTX 2080/ 15.9GB\r\n\r\n\r\n\r\n\r\n**Describe the problem** I followed everything explained in this tutorial https://towardsdatascience.com/how-to-compile-tensorflow-2-3-with-cuda-11-1-8cbecffcb8d3\r\nuntil the command :\r\nbazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\nwhere I got :\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/418c218efa950245ba075b9bb3a53505b807c5df.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (419 packages loaded, 27891 targets configured).\r\nINFO: Found 1 target...\r\nERROR: C:/users/korin/tensorflow/tensorflow/core/profiler/internal/gpu/BUILD:108:16: undeclared inclusion(s) in rule '//tensorflow/core/profiler/internal/gpu:cupti_wrapper':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/profiler/internal/gpu/cupti_wrapper.cc':\r\n  'tensorflow/stream_executor/cuda/cuda_activation.h'\r\n  'tensorflow/stream_executor/gpu/gpu_activation.h'\r\ncl : Command line warning D9035 : option 'experimental:preprocessor' has been deprecated and will be removed in a future release\r\ncl : Command line warning D9036 : use 'Zc:preprocessor' instead of 'experimental:preprocessor'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1356.616s, Critical Path: 249.97s\r\nINFO: 7667 processes: 3916 internal, 3751 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["python 3.8", "@divastar,\r\nEvery TensorFlow release is compatible with a certain CUDA/cuDNN version. For more information, please take a look at the [tested build configurations](https://www.tensorflow.org/install/source_windows#gpu). \r\n\r\nCould you please run the `bazel clean --expunge` command and then try building the latest version of **TensorFlow v2.4** with **CUDA 11.0** and **cuDNN 8** and check if you are facing the same issue.\r\n\r\n Also, follow the [official guide](https://www.tensorflow.org/install/source_windows) while building TensorFlow from source. Thanks!", "I am working on it. Thank you", "Hi .\r\nSo I uinstalled cuda 11.0 cudnn 8.0.1.13\r\nmade a new environment with conda python 3.6\r\nbazel 3.7\r\nwhen I configure I get :\r\n\r\n(newtensor) C:\\Users\\korin\\tensorflow>python ./configure.py\r\nYou have bazel 3.7.2 installed.\r\nPlease specify the location of python. [Default is C:\\Users\\korin\\anaconda3\\envs\\newtensor\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Users\\korin\\anaconda3\\envs\\newtensor\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Users\\korin\\anaconda3\\envs\\newtensor\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nCould not find any cuda.h matching version '' in any subdirectory:\r\n        ''\r\n        'include'\r\n        'include/cuda'\r\n        'include/*-linux-gnu'\r\n        'extras/CUPTI/include'\r\n        'include/cuda/CUPTI'\r\n        'local/cuda/extras/CUPTI/include'\r\nof:\r\n\r\nAsking for detailed CUDA configuration...\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 11\r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 8\r\n\r\n\r\nPlease specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\\extras\\CUPTI\\include\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"third_party\\gpus\\find_cuda_config.py\", line 653, in <module>\r\n    main()\r\n  File \"third_party\\gpus\\find_cuda_config.py\", line 645, in main\r\n    for key, value in sorted(find_cuda_config().items()):\r\n  File \"third_party\\gpus\\find_cuda_config.py\", line 583, in find_cuda_config\r\n    result.update(_find_cuda_config(cuda_paths, cuda_version))\r\n  File \"third_party\\gpus\\find_cuda_config.py\", line 257, in _find_cuda_config\r\n    get_header_version)\r\n  File \"third_party\\gpus\\find_cuda_config.py\", line 244, in _find_header\r\n    required_version, get_version)\r\n  File \"third_party\\gpus\\find_cuda_config.py\", line 233, in _find_versioned_file\r\n    actual_version = get_version(file)\r\n  File \"third_party\\gpus\\find_cuda_config.py\", line 250, in get_header_version\r\n    version = int(_get_header_version(path, \"CUDA_VERSION\"))\r\nValueError: invalid literal for int() with base 10: ''\r\nAsking for detailed CUDA configuration...\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 11\r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 8\r\n\r\nafter I copied cuda.h from C:\\Users\\korin\\tensorflow\\tensorflow\\core\\platform to \r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\\extras\\CUPTI\\include\r\nand specified this folder for cuda during confi - same errors \r\nthen i tried to edit cuda_configure.bzl with:\r\n       ),\r\n        \"cupti\": _check_cuda_lib_params(\r\n            \"cupti\",\r\n            cpu_value,\r\n            cuda_config.config[\"cupti_library_dir\"],\r\n            #cuda_config.cuda_version,\r\n\t\t\t\"11\",\r\n            static = False,\r\n        ),\r\n        \"cusparse\": _check_cuda_lib_params(\r\n            \"cusparse\",\r\n\r\nstil same errors during config\r\n\r\nThank you..", "of course I did bazel clean --expunge before and downloaded latest tensorflow as you suggested ..", "@divastar,\r\nCould you please confirm if you've added the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environmental variable as mentioned in [this guide](https://www.tensorflow.org/install/gpu#windows_setup). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47144\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47144\">No</a>\n"]}, {"number": 47143, "title": "EdgeTPU compilation fails for multi-head networks", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution  Linux Ubuntu 20.04:\r\n- TensorFlow installation pip installation 2.3.1:\r\n\r\n### 2. Code\r\n\r\nModel Architecture:\r\n```\r\nTARGET_SIZE = 224\r\ninputs = tf.keras.layers.Input(shape=(TARGET_SIZE, TARGET_SIZE, 3))\r\nbase_model = tf.keras.applications.MobileNetV2(input_shape=(TARGET_SIZE, TARGET_SIZE, 3), alpha=1.0, include_top=False, weights='imagenet', input_tensor=inputs)\r\nbase_out = base_model.output\r\nbase_out = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu')(base_out)\r\nbase_out = tf.keras.layers.Dropout(0.2)(base_out)\r\nbase_out = tf.keras.layers.GlobalAveragePooling2D()(base_out)\r\n#base_out = tf.keras.layers.Flatten()(base_out)\r\n\r\n# construct a fully-connected layer header to output the predicted\r\n# bounding box coordinates\r\nbboxHead = tf.keras.layers.Dense(256, activation=\"relu\")(base_out)\r\nbboxHead = tf.keras.layers.Dense(128, activation=\"relu\")(bboxHead)\r\nbboxHead = tf.keras.layers.Dense(64, activation=\"relu\")(bboxHead)\r\nbboxHead = tf.keras.layers.Dense(32, activation=\"relu\")(bboxHead)\r\nbboxHead = tf.keras.layers.Dense(4, activation=\"sigmoid\", name=\"bounding_box\")(bboxHead)\r\n\r\n# construct a second fully-connected layer head, this one to predict\r\n# the class label\r\nsoftmaxHead = tf.keras.layers.Dense(256, activation=\"relu\")(base_out)\r\nsoftmaxHead = tf.keras.layers.Dense(128, activation=\"relu\")(softmaxHead)\r\nsoftmaxHead = tf.keras.layers.Dense(64, activation=\"relu\")(softmaxHead)\r\nsoftmaxHead = tf.keras.layers.Dense(8, activation=\"relu\")(softmaxHead)\r\nsoftmaxHead = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"class_label\")(softmaxHead)\r\n\r\n# put together our model which accept an input image and then output\r\n# bounding box coordinates and a class label\r\nmodel = tf.keras.models.Model(inputs=base_model.input, outputs=(bboxHead, softmaxHead))\r\n```\r\n\r\nVisualisation of the architecture : [model_plot](https://user-images.githubusercontent.com/17791005/107879987-5dc53d80-6edc-11eb-98b9-46ec369b8c89.png)\r\n\r\nTFLite Conversion:\r\n```\r\ndef convert_tflite(pl_model):\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(pl_model)\r\n    # Set quantize to true\r\n    converter.post_training_quantize = True\r\n    converter.representative_dataset = tf.lite.RepresentativeDataset(representative_dataset_gen)\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # For EdgeTPU, no float ops allowed\r\n    converter.inference_input_type = tf.uint8\r\n    converter.inference_output_type = tf.uint8\r\n\r\n    tflite_model = converter.convert()\r\n    open(\"pl_od_model_edgetpu.tflite\", \"wb\").write(tflite_model)\r\n\r\ndef representative_dataset_gen():\r\n    data_dir = os.path.join(os.path.join(ma_uav_dir, 'Vision/Detector/CNN_Classifier'), 'Data/test')\r\n    pl_dir = os.path.join(data_dir, 'PayLoad')\r\n    pl_imgs = [cv2.imread(os.path.join(pl_dir, image)) for image in os.listdir(pl_dir) if '.png' in image]\r\n    not_pl_dir = os.path.join(data_dir, 'Not_PayLoad')\r\n    not_pl_imgs = [cv2.imread(os.path.join(not_pl_dir, image)) for image in os.listdir(not_pl_dir) if '.png' in image]\r\n    all_imgs = pl_imgs + not_pl_imgs\r\n    random.shuffle(all_imgs)\r\n\r\n    for i in range(len(all_imgs) - 1):\r\n        img = all_imgs[i]\r\n        image = resize_img(img_org=img).astype(np.float32)\r\n        image = tf.expand_dims(image, 0)\r\n        yield [image]\r\n\r\ndef resize_img(img_org):\r\n    return cv2.resize(img_org, (TARGET_SIZE, TARGET_SIZE)) * (1. / 255)\r\n```\r\nResulting in following Netron output: [image](https://user-images.githubusercontent.com/17791005/107880057-bac0f380-6edc-11eb-9bf9-7cfb7fff8f55.png)\r\n\r\n### 3. Failure after conversion\r\nThe TFLite conversion is successful but the compilation to Coral EdgeTPU fails. Following command `edgetpu_compiler pl_od_model_edgetpu.tflite ` results in the error below:\r\n\r\nEdgeTPU Compiler Output:\r\n```\r\nEdge TPU Compiler version 15.0.340273435\r\nERROR: :309 scale_diff / output_scale <= 0.02 was not true.\r\nERROR: Node number 79 (FULLY_CONNECTED) failed to prepare.\r\n\r\nERROR: :309 scale_diff / output_scale <= 0.02 was not true.\r\nERROR: Node number 79 (FULLY_CONNECTED) failed to prepare.\r\n\r\nCompilation failed: Internal error\r\n\r\nInternal compiler error. Aborting!\r\n```\r\n\r\nI suppose the issue is related to https://github.com/tensorflow/tensorflow/issues/41069. As I am also dealing with a model with two outputs. If the model has a single output, the compilation is successful. Could you clarify the `ERROR :309`? Is the coral able to handle a known issue regarding multi-head network quantisation? Is the coral able to handle multi-head networks?\r\n\r\nI have to clarify that I trained the network for only 1 epoch and just wanted to use this \"dummy network\" to test if it is compatible with the Coral. \r\n\r\nThanks! \r\n", "comments": ["FYI @jingpu ", "@niciBume,\r\nOn running the code, I am facing an error stating `NameError: name 'ma_uav_dir' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/7b8f8e39966cc150708d0907d88b1ab2/47143.ipynb).\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "@amahendrakar \r\nThanks for the response! Not sure why, but when trying to recreate with dummy data [here](https://colab.research.google.com/gist/niciBume/5e1f8a6243525513e726bab6173cff58/47143.ipynb) it works! But on my machine it's still failing. I'll try to dig deeper into this, give me a few days and I'll try to come up with an explanation.\r\nThanks!", "> ERROR: :309 scale_diff / output_scale <= 0.02 was not true.\r\n> ERROR: Node number 79 (FULLY_CONNECTED) failed to prepare.\r\n\r\nThe error in the initial post seems to come from \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/kernel_util.cc#L310\r\n\r\nwhich indicates an quantization issue during TFLite conversion", "I used dummy images i.e `np.ones(img_shape)` to try to reproduce the error.\r\nI think the reason is because the `represantative_dataset()` originally used `resize(cv2.imread(os.path.join(pl_dir, image))) `whereas the network has been trained with` img_to_array(load_img(os.path.join(pl_dir, img_p) `which is why the scaling error could occur.\r\n\r\n- `img_to_array(load_img(os.path.join(pl_dir, img_p)` returns an image matrix between 0 and 255\r\n- `resize(cv2.imread(os.path.join(pl_dir, image)))` returns image matrix between 0 and 1", "@niciBume,\r\nThank you for the update. Is this still an issue?", "@amahendrakar sorry forgot to close the issue. It's working consistently now! Thanks a lot!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47143\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47143\">No</a>\n"]}, {"number": 47142, "title": "Installing tensorflow 2 on raspberry pi 3 model B", "body": "- Raspbian GNU/Linux 10 (buster)\r\n- firstly trying to install via pip then second attempt trying to install from source\r\n- TensorFlow version: 2.3.0\r\n- Python version: 3.7.3\r\n- gcc version 8.3.0 (Raspbian 8.3.0-6+rpi1) \r\n\r\nHello, I've been trying to get tensorflow (specifically Keras) to work on a raspberry pi 3 model B, using a Raspbian GNU/Linux 10 (buster), default python version is 3.7.3 and pip version is updated to 21.0.1.\r\nthe official tensorflow site says that the installation via pip should be all the same when it comes to raspberry pi with the following details but for some reasons pip installs tensorflow 1.12.0 when I run the command line `pip3 install tensorflow`, I've also tried following a guide to install tensorflow 2.3.0 via a wheel but that failed too when pip failed to find a version of tesnorflow-estimator/tensorboard that satisfies the requirements.\r\nI would really appreciate any help.\r\n\r\nthe exact guide I am following is this guide: https://itnext.io/installing-tensorflow-2-3-0-for-raspberry-pi3-4-debian-buster-11447cb31fc4 and when I get to the last phase of actually installing tensorflow 2.3.0 I get the following error:\r\n\r\n` Could not find a version that satisfies the requirement tensorflow-estimator<2.4.0,>=2.3.0 (from tensorflow==2.3.0) (from versions: 1.10.0, 1.10.1, 1.10.2, 1.10.3, 1.10.4, 1.10.5, 1.10.6, 1.10.7, 1.10.8, 1.10.9, 1.10.10, 1.10.11, 1.10.12)\r\nNo matching distribution found for tensorflow-estimator<2.4.0,>=2.3.0 (from tensorflow==2.3.0)`\r\n\r\n\r\n\r\n\r\n", "comments": ["@COfek \r\nCould you please refer to [this link](https://www.tensorflow.org/install/pip#raspberry-pi) and let us know", "@Saduf2019 Hello and Thanks for responding, I've had a readthrough of that guide and I've done everything except creating a venv because I want everything to be on the root.\r\n", "@COfek,\r\n\r\nCan you take a look at this [guide](https://www.bitsy.ai/3-ways-to-install-tensorflow-on-raspberry-pi/) & the [blog](https://nitin9809.medium.com/getting-started-with-raspberry-pi-installation-guide-for-tensorflow-2-3-1-and-opencv-4-5-1-3a5bd0b6de2d) and let us know if it helps in setting up TF on your raspberry pi. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47142\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47142\">No</a>\n"]}, {"number": 47141, "title": "Tensorflow C API Prebuilt Library for Ubuntu 20", "body": "Hi,\r\n\r\nCurrently, published Tensorflow C API Ubuntu libraries are  built for Ubuntu 16. Is there any plan to built it for Ubuntu 20? \r\n\r\nWhen I try to link it against my Ubuntu 20 projects, I got linker errors such as:\r\n\r\n```\r\n.dynsym local symbol at index 857\r\n...\r\n/usr/bin/ld: Model.cpp:(.text+0x101): undefined reference to `TF_NewGraph'\r\n/usr/bin/ld: Model.cpp:(.text+0x10a): undefined reference to `TF_NewSessionOptions'\r\n/usr/bin/ld: Model.cpp:(.text+0x128): undefined reference to `TF_SetConfig'\r\n/usr/bin/ld: Model.cpp:(.text+0x160): undefined reference to `TF_LoadSessionFromSavedModel'\r\n```\r\n\r\nThanks.", "comments": ["@fatihkiralioglu \r\nWe see that the issue template has not been filled, we ask for the template as it helps us analyse the issue [ ex: tf version]\r\nCan you please refer to these resolved issues and let us know if it helps: [link](https://github.com/tensorflow/tensorflow/issues/23649), [link1](https://github.com/tensorflow/tensorflow/issues/8033), #41506, #21301.", "@Saduf2019 Hi,\r\n\r\nThe version is 2.4.0. I have downloaded prebuilt library from : https://www.tensorflow.org/install/lang_c\r\n\r\nhttps://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-2.4.0.tar.gz\r\n\r\nThe issues you have shared do not resolve my issue. I can successully monitor .so objects with nm but cant link them against my Ubuntu 20 project\r\n\r\n", "@Saduf2019 There is a similar issue: \r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/41382\r\n", "Thanks @Saduf2019, issue is resolved, I just fixed the linkage order in my make file. Best Regards", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47141\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47141\">No</a>\n"]}, {"number": 47140, "title": "pip install error could not find a version that satisfies the requirement tensorflow", "body": "I'm using python 3.9.1 64-bit, win10 and I try to install TesorFlow using either pip, pip3 or pip3.9, but I always receive the error:\r\n\r\nERROR: Could not find a version that satisfies the requirement tesorflow\r\nERROR: No matching distribution found for tesorflow\r\n\r\n![image](https://user-images.githubusercontent.com/79036528/107870484-5896cd00-6ea1-11eb-8267-aee1f3e27e88.png)\r\n\r\ncan you please help!\r\n\r\n", "comments": ["You wrote tesorflow and not tensorflow.", "it's a typing mistake of course, it seems that chose the only one time in which i misspelled TensorFlow \r\nanyway here another trial that shows the error i'm trying to solve\r\n![image](https://user-images.githubusercontent.com/79036528/107894858-c7276980-6f39-11eb-966c-b81e2b30fcb8.png)\r\ncan you please help!\r\nN.B: I'm using win10 & python 3.9,1 64-bit", "@EmadElDinH,\r\nTensorFlow v2.2 is compatible with Python 3.5 - 3.8. For more information, please take a look at the [tested build configurations](https://www.tensorflow.org/install/source_windows#cpu).\r\n\r\n\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\n-- | -- | -- | -- | -- | --\r\ntensorflow_gpu-2.4.0 | 3.6-3.8 | MSVC 2019 | Bazel 3.1.0 | 8.0 | 11.0\r\ntensorflow_gpu-2.3.0 | 3.5-3.8 | MSVC 2019 | Bazel 3.1.0 | 7.6 | 10.1\r\ntensorflow_gpu-2.2.0 | 3.5-3.8 | MSVC 2019 | Bazel 2.0.0 | 7.6 | 10.1\r\n\r\nCould you please install Python 3.8 and let us know if you are facing the same issue.\r\n\r\nThanks!", "TensorFlow has no release for Python 3.9. Closing as duplicate of #44485 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47140\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47140\">No</a>\n", "I have uninstalled python 3.9 and then installed python 3.8, after that I could successfully install the TensorFlow module ,,,\r\nBUT now I'm encountering another issue; although I was able to install all the needed modules using the pip install command on my virtual environment, I always get an error in importing them through my program: e.g.: I could install the pandas_datareader module, but it returns the error \"**ModuleNotFoundError: No module named 'pandas_datareader**\" when I import it in my python program !!!\r\nI've been trying for the whole day, can you please help!\r\nthanks!", "@EmadElDinH,\r\nThis repository is only for tracking TensorFlow bugs and feature requests. \r\n\r\nFor help with the `pandas_datareader`module, please raise an issue in the [pydata/pandas-datareader](https://github.com/pydata/pandas-datareader/issues) repo.\r\n\r\nThanks!"]}, {"number": 47139, "title": "InaccessibleTensorError for tensor defined in same scope", "body": "Hello\r\nI am for some reason getting an error in Tensorflow 2.2 stating that I am not being able to access a tensor when created within the same scope, but using `tf.function`\r\n\r\n```python\r\nimport tensorflow as tf\r\ncosine_loss = tf.keras.losses.CosineSimilarity(axis=0,reduction=tf.keras.losses.Reduction.NONE)\r\n@tf.function\r\ndef func():\r\n    A = tf.convert_to_tensor([[1,1.,1],[1,3,1]])\r\n    B = tf.convert_to_tensor([[1,1.,1]])\r\n\r\n    S = []\r\n    for b in B:\r\n        S_n = []\r\n        for a in A:\r\n            S.append(-cosine_loss(a,b))\r\n        S.append(S_n)\r\n    \r\n    return S\r\nprint(func())\r\n```\r\n\r\n```\r\nInaccessibleTensorError: The tensor 'Tensor(\"while/while/Neg:0\", shape=(), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_while_body_55, id=140111838031568); accessed from: FuncGraph(name=func, id=140111839241488).\r\n```\r\n\r\nWhy is this not being able to access it?\r\nThank you", "comments": ["@nicolasshu \r\nThe code shared seems incomplete, I ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/44c2eed897f05554b7e516b7982fecdf/untitled530.ipynb)", "Sorry. That was my bad. I just updated it", "I am able to replicate the issue reported on tf 2.4 and nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/1ac6960e24bfd171dc59167629851572/untitled535.ipynb).", "@nicolasshu,\r\nDocumentation of [TF.Function](https://www.tensorflow.org/api_docs/python/tf/function#example_usage_2) states:\r\n\r\n> Key Point: Any Python side-effects (appending to a list, printing with print, etc) will only happen once, when func is traced. To have side-effects executed into your tf.function they need to be written as TF ops:\r\n\r\nInstead, use TensorFlow collections like tf.TensorArray:\r\n\r\n```python\r\n@tf.function\r\ndef f(x):\r\n  ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\r\n  for i in range(len(x)):\r\n    ta = ta.write(i, x[i] + 1)\r\n  return ta.stack()\r\nf(tf.constant([1, 2, 3]))\r\n```\r\nSo, replacing `Lists` and `List Operations` with `TensorArray` should resolve your issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47139\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47139\">No</a>\n"]}, {"number": 47138, "title": "How to use tensor on the tensorflow lite  like tensorflow tensor operation? For example, tensor ascend dimension ,reduction dimension and tensor  slice. Thanks.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["Please help me!Thanks!", "Hi, if it's a question, please use stackoverflow for faster answer. I not sure if I get it correctly, but if you want to try if how those ops work in TFLite model, you can make a TF model and convert it to TFLite model. dimensionality manipulation and slice ops can be supported partially with RESHAPE and STRIDED_SLICE ops in TFLite.", "\r\n> Hi, if it's a question, please use stackoverflow for faster answer. I not sure if I get it correctly, but if you want to try if how those ops work in TFLite model, you can make a TF model and convert it to TFLite model. dimensionality manipulation and slice ops can be supported partially with RESHAPE and STRIDED_SLICE ops in TFLite.\r\n\r\nHi, I integrated TFLite on android by using TFLite .a static lib.  TFLite support TfLiteTensor class, not support Tensor class, can't find RESHAPE and STRIDED_SLICE API in  TfLiteTensor. Thanks!", "Operations on the tensor is actually another op in the computation graph. That being said, the graph would be like\r\n\r\nTfLiteTensor -> RESHAPE op -> new TfLiteTensor with new shape.\r\n\r\nI still don't get what you're actually trying to achieve. What part of the graph you're trying to modify?", "@158703127 If you are looking for RESHAPE op, may be the example provided in [this issue](https://github.com/tensorflow/tensorflow/issues/45150) might help. \r\n\r\nPlease provide any standalone code to reproduce the issue. If you have a general question, please post them in Stackoverflow as GitHub is mainly for bugs and performance related issue. There is a large community on Stackoverflow that support general questions. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47137, "title": "com_github_apple_swift_swift_protobuf sha256 mismatch in tensorflow/workspace.bzl", "body": "\r\n**System information**\r\n\r\nIn reference to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/workspace.bzl on master, as-written.\r\n\r\n**Describe the current behavior**\r\n\r\nWhile digging in to an unrelated buildsystem problem, I noticed that\r\n```\r\n    # https://github.com/apple/swift-protobuf/releases\r\n    tf_http_archive(\r\n        name = \"com_github_apple_swift_swift_protobuf\",\r\n        strip_prefix = \"swift-protobuf-1.6.0/\",\r\n        sha256 = \"4ccf6e5ea558e8287bf6331f9f6e52b3c321fca5f1d181d03680f415c32a6bba\",\r\n        urls = [\r\n            \"https://storage.googleapis.com/mirror.tensorflow.org/github.com/apple/swift-protobuf/archive/1.6.0.zip\",\r\n            \"https://github.com/apple/swift-protobuf/archive/1.6.0.zip\",\r\n        ],\r\n    )\r\n```\r\n\r\nhas a `sha256` value that doesn't match what I get from either source.  Note that I'm looking at this from a \"prepare for offline builds\" perspective, I don't know if the normal build system will actually fetch this, or if \"everyone\" already has the matching version cached, or if something else is going on (like the `intel/mkl-dnn` archive-rename problem.)\r\n\r\n**Describe the expected behavior**\r\n\r\nThe particular values in `workspace.bzl` have been unchanged for a while.  I don't know if the upstream has changed or not, intentionally, but specific releases aren't supposed to; that's one reason for the hash checks...\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nworkbench$ wget https://storage.googleapis.com/mirror.tensorflow.org/github.com/apple/swift-protobuf/archive/1.6.0.zip\r\n2021-02-13 18:49:23 (9.31 MB/s) - \u20181.6.0.zip\u2019 saved [1918999/1918999]\r\nworkbench$ sha256sum 1.6.0.zip \r\n4d6d2543da84474fe50a543f70ba145d99c4d14a4aac10d7b3c7dc9f0f7ecec3  1.6.0.zip\r\nworkbench$ rm 1.6.0.zip \r\nworkbench$ wget https://github.com/apple/swift-protobuf/archive/1.6.0.zip\r\n2021-02-13 18:49:43 (8.42 MB/s) - \u20181.6.0.zip\u2019 saved [1918999/1918999]\r\nworkbench$ sha256sum 1.6.0.zip \r\n4d6d2543da84474fe50a543f70ba145d99c4d14a4aac10d7b3c7dc9f0f7ecec3  1.6.0.zip\r\n```\r\n(and note that 4d6.*ec3 does not match the 4cc.*bba in the `.bzl` file.)\r\n\r\n**Other info / logs**\r\n\r\nVaguely related: https://github.com/tensorflow/tensorflow/issues/12979 and https://github.com/libgit2/libgit2/issues/4343 that suggest that \"it is known\" that github archive hashes change when github itself updates; usually the `storage.googleapis.com/mirror.tensorflow.org` links are enough to cover for that but it looks like they match now.\r\n", "comments": ["I think this should be fixed now as we bumped this dep several times.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47137\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47137\">No</a>\n"]}, {"number": 47136, "title": "Incorrect console print output while printing tensor generated from tf.image.grayscale_to_rgb api in Tensorflow 1.2", "body": "I am trying to convert a grayscale png image into rgb. I am using Tensor version 1.2. When I print the output of the converted tensor on console, it shows me zero in all 3 channels. If I visualize the output on tensor board, it shows the image just fine. \r\n\r\nI tried doing the same in Tensor 2.4 and it works fine there. Is there a bug in printing on 1.2 version? \r\n\r\nimport tensorflow as tf\r\nimport os\r\nimport numpy as np\r\nfrom datetime import datetime\r\n\r\nlogdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\nimage_list = ['<full path of IR image.png>']\r\n            \r\nsess = tf.InteractiveSession()\r\nimageHandle = tf.read_file(image_list[0])\r\n\r\nimage_tensor = tf.image.decode_png(imageHandle, dtype=tf.uint8) \r\nimage_tensor = tf.reshape(image_tensor, [1, 512, 640, 1])\r\nimage_tensor = tf.Print(image_tensor, [image_tensor], \"*** read_images_from_decode_png\", summarize=900) # **This print is correct**\r\n\r\nimage_tensor1 = tf.image.grayscale_to_rgb(image_tensor)\r\nimage_tensor1 = tf.Print(image_tensor1, [image_tensor1], \"*** read_images_from_disk_grayscale2rgb\", summarize=900) # **This print is wrong**\r\n\r\nsummary_op3 = tf.summary.image('config/config', image_tensor1)\r\nsummary_writer = tf.summary.FileWriter(logdir, sess.graph)\r\ntext = sess.run(summary_op3)\r\nsummary_writer.flush()\r\nsummary_writer.close()", "comments": ["@ssnirgudkar \r\nI ran the code shared and face a [different error](https://colab.research.google.com/gist/Saduf2019/a283a1c09743316b1cb00511248c1150/untitled530.ipynb), please share all dependencies , if possible share a colab gist with the error reported.", "[\r\n![1603392383 356605_color](https://user-images.githubusercontent.com/37679575/107960318-797b2300-6f72-11eb-976a-17e23d85c25a.png)\r\n](url)\r\n\r\nimage_list = ['1603392383 356605_color.png']\r\n\r\nI have attached a png file (1603392383 356605_color.png). From my original script, please adjust the variable 'image_list' to point to the path of this image and you should be able to reproduce the problem.\r\n\r\nAlso I noticed that you are using TensorFlow 1.15, my environment is TensorFlow 1.2. It is important to keep the environment same to reproduce the issue.", "@ssnirgudkar\r\nThere is no support for 1.x, there is support only for 2.x only, in case it is working fine on 2.x please move this issue to closed status.", "Can you confirm if you can reproduce the issue which I am seeing (TF 1.2) at your end? I am not necessarily asking to fix the problem. The code which I am using is a legacy code and it will take some time/effort to port this code on TF 2.X.\r\nBut it is important for me to know that this issue exists (or not) so that I can focus on other parts of the system.", "@ssnirgudkar \r\nI ran the code with the image shared, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/d5380a6e71ab5999064c2a0ae1807f4e/untitled543.ipynb) and confirm if this is the error faced.", "Sorry, one typo in the script. Can you please change 'reshape' line to following ?\r\n\r\nimage_tensor = tf.reshape(image_tensor, [1, 512, 640, **3**])\r\n\r\nAlso, again to reiterate the TF version is **1.2** not 1.12.", "@ssnirgudkar \r\nWe will not be able to replicate this on tf 1.2, please upgrade to 2.x as informed earlier and move this issue to closed status if there is no error or create a new issue in case you face any errors.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47135, "title": "Fix for keras applications preprocess_input with data_format=\"channels_first\" symbolic tensors", "body": "Fixes #46539\r\n\r\nThe rescaling by `std` in keras.applications.imagenet_utils._preprocess_symbolic_input was not taking into account `data_format`, causing a shape mismatch error.\r\n\r\nThis was not caught by the unit tests as only the default `mode='caffe'` was tested, which does not use `std`. I changed the test to run for all modes.", "comments": []}, {"number": 47133, "title": "Data provided by a keras.utils.sequence DataGenerator has None dimensions when used to fit Model subclass", "body": "Code is written using Google Colab on Tensorflow Version 2.4.1\r\n\r\nA DataGenerator subclassing keras.utils.sequence is providing data of correct shape when used to fit a sequential model. However, when used to fit a custom model subclassing keras.Model the input dimensions become (None, None, None, None) in the call method during the first training epoch.\r\n\r\nWhen the custom model is fit using the DataGenerator the input dimensions to the call method should be (16, 256, 128, 3).\r\n\r\nA simplified recreation of the issue is provided on Google Colab in the following notebook:\r\n[Colab Notebook](https://colab.research.google.com/drive/1VqPc6Wn2tIND6myoZyFWXhGiMispiDxJ#scrollTo=KMRPZrfQE3KA)", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/3117d9916427e0ddd9e12beaa96f2329/47133.ipynb). Thanks!", "cc @amahendrakar @rmothukuru ", "Can you try switching your input pipeline to be `tf.data` based instead? That should make it generally more performant anyways.", "@05hazza06,\r\nCan you please respond to the above comment? Thanks! ", "The tf.data dataset implementation worked as expected. Thanks.\r\nStill unsure about why Keras sequence didn't work but the issue is sorted.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47133\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47133\">No</a>\n"]}, {"number": 47132, "title": "Tensorflow 2.4.1 AUC bug", "body": "Hi, I think there is a bug in tf 2.4.1. If I use tf 2.3.2 it works fine, if I clone the environment and update tf to 2.4.1 I get the following behaviour and auc and val_auc are always at 0.5 no matter how many epochs I run (with a simple dense model; also the loss seems to be erratic):\r\nEpoch 1/10\r\n585/585 [==============================] - 2s 3ms/step - loss: 0.6466 - auc: 0.5065 - val_loss: 0.5479 - val_auc: 0.5000\r\nEpoch 2/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.7262 - auc: 0.5000 - val_loss: 0.4576 - val_auc: 0.5000\r\nEpoch 3/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.4614 - auc: 0.5000 - val_loss: 0.4271 - val_auc: 0.5000\r\nEpoch 4/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.4601 - auc: 0.5000 - val_loss: 0.5069 - val_auc: 0.5000\r\nEpoch 5/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.4871 - auc: 0.5000 - val_loss: 0.4679 - val_auc: 0.5000\r\nEpoch 6/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.4748 - auc: 0.5000 - val_loss: 0.4341 - val_auc: 0.5000\r\nEpoch 7/10\r\n585/585 [==============================] - 1s 2ms/step - loss: 0.4763 - auc: 0.5000 - val_loss: 0.4290 - val_auc: 0.5000\r\nEpoch 8/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.4932 - auc: 0.5000 - val_loss: 0.4367 - val_auc: 0.5000\r\nEpoch 9/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.5291 - auc: 0.5000 - val_loss: 0.4290 - val_auc: 0.5000\r\n\r\n------------------------\r\n\r\nI'm on a Mac Os 10.14.6 and python 3.8.5. (everything else is the same; I cloned the env and copied the notebook)\r\nWith tf 2.3.2 auc and val_auc get updated correctly and loss is much better \r\nEpoch 1/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.4133 - auc: 0.6771 - val_loss: 0.3942 - val_auc: 0.7115\r\nEpoch 2/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.3959 - auc: 0.6943 - val_loss: 0.3858 - val_auc: 0.7069\r\nEpoch 3/10\r\n585/585 [==============================] - 1s 1ms/step - loss: 0.3889 - auc: 0.6992 - val_loss: 0.3811 - val_auc: 0.6996\r\n", "comments": ["@adalseno \r\nPlease share simple indented stand code for us to replicate the issue reported or a colab gist with the code and error to analyse.", "Here you are the code:\r\n```\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(128, activation='relu'))\r\nmodel.add(Dropout(0.1))\r\nmodel.add(Dense(2,activation='sigmoid'))\r\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['AUC'] )\r\n\r\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\r\n# Set early stopping\r\nes = EarlyStopping(monitor = 'val_auc', min_delta = 1e-4, patience = 30, mode = 'max', \r\n                        baseline = None, restore_best_weights = True, verbose = 1)\r\n\r\nrlr = ReduceLROnPlateau(monitor = 'val_auc', factor = 0.1, patience = 25, verbose = 1, \r\n                            min_delta = 1e-4, mode = 'max', min_lr = 0.00001)\r\n\r\n\r\n\r\nmodel.fit(x=X_train, \r\n          y=y_train.values, \r\n          epochs=200,\r\n          validation_data=(X_test, y_test.values), \r\n          verbose=1,\r\n          callbacks=[es,rlr]\r\n          )\r\n```\r\nPlease note that the \"bug\" is present even without callbacks (so they are not the problem)", "In case you'll need the full code, here you are the first part:\r\n```\r\nimport pandas as pd\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\n#import pandas_profiling as pf\r\n%matplotlib inline\r\n#Data from https://www.drivendata.org/competitions/66/flu-shot-learning/data/\r\n\r\ntrain = pd.read_csv('./training_set_features.csv', index_col='respondent_id')\r\ntest = pd.read_csv('./test_set_features.csv', index_col='respondent_id')\r\nlabels = pd.read_csv('./training_set_labels.csv', index_col='respondent_id')\r\n\r\nnum_cols = train.select_dtypes('number').columns\r\ncat_cols = ['race', 'sex', \r\n       'marital_status', 'rent_or_own',  \r\n       'census_msa',  'employment_occupation',\r\n           'age_group', 'education',  'income_poverty',\r\n        'employment_status']\r\n\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\r\nfrom sklearn.impute import SimpleImputer\r\nfrom sklearn.compose import ColumnTransformer\r\nfrom category_encoders import OrdinalEncoder as oe\r\n\r\nnum_pipe= Pipeline([\r\n    ('impute', SimpleImputer(strategy='constant', fill_value = -1  )),\r\n    ('scale', MinMaxScaler())\r\n])\r\n\r\ncat_pipe = Pipeline([\r\n        ('impute', SimpleImputer(strategy='constant', fill_value = 'missing'  )),\r\n        ('encode', OneHotEncoder(handle_unknown='ignore'))\r\n\r\n])\r\n\r\nct = ColumnTransformer(\r\n    [('numerical', num_pipe, num_cols), \r\n    ('onehot', cat_pipe, cat_cols)],\r\n    remainder='drop')\r\n\r\nsel_cols = train.columns\r\n\r\nfor col in num_cols:\r\n    train[col] = train[col].fillna(value=-1)\r\n\r\nfor col in (cat_cols):\r\n    train[col] = train[col].fillna(value='missing')\r\n\r\ntrain = pd.DataFrame(train, columns=sel_cols)\r\n\r\ntrain = ct.fit_transform(train)\r\n\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nX_train, X_test, y_train, y_test = train_test_split( train, labels, test_size=0.3, random_state=68)\r\n\r\n\r\n```", "@adalseno \r\nI ran the code shared and face a different issue, please find [gist here](https://colab.research.google.com/gist/Saduf2019/a2520a6f2a5591931ffff8112ad13713/untitled535.ipynb) and share all dependencies such that we can replicate the issue faced or if possible share a colab gist with the error.", "I apologize for the late reply. The issue was with a missing package. I solved adding:\r\n`!pip install category_encoders`\r\nIt works fine now and the issue is there:\r\n\r\nEpoch 1/200\r\n585/585 [==============================] - 2s 3ms/step - loss: 0.6616 - auc: 0.5036 - val_loss: 0.5443 - val_auc: 0.5000\r\nEpoch 2/200\r\n585/585 [==============================] - 1s 2ms/step - loss: 2.3236 - auc: 0.5000 - val_loss: 1.0065 - val_auc: 0.5000\r\nEpoch 3/200\r\n585/585 [==============================] - 1s 2ms/step - loss: 2.9277 - auc: 0.5000 - val_loss: 1.4446 - val_auc: 0.5000\r\nEpoch 4/200\r\n585/585 [==============================] - 1s 2ms/step - loss: 2.2756 - auc: 0.5000 - val_loss: 0.5043 - val_auc: 0.5000", "@adalseno \r\nThank you for your update, please move this issue to closed status as it is resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47132\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47132\">No</a>\n"]}, {"number": 47131, "title": "Can't set empty layer name", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):2.4\r\n- Python version:3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nGet variable name like 'dense/kernel:0'\r\n**Describe the expected behavior**\r\nGet variable name like 'kernel:0'\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```python\r\nimport tensorflow as tf\r\ndense = tf.keras.layers.Dense(16, name='')\r\ndense(tf.ones([16, 16]))\r\ndense.weights[0].name\r\n```\r\nhttps://colab.research.google.com/drive/1KBzEMwJtMsgSoIfUieLBV9_5iLKmik46?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["> **Describe the expected behavior**\r\n> Get variable name like 'dense/kernel:0'\r\n\r\n@fsx950223,\r\nOn running the given Colab notebook with TensorFlow v2.4.1, I got the 'expected behavior'. \r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/ff7e9c9c2ae7181edb87a28a1b177022/47131.ipynb#scrollTo=QoCm0cbfN50k). Thanks!", "Sorry, I swap the current behavior and the expected behavior by mistake.\r\nI have updated the comment.", "Hyy, I have descibed the issue.\r\nThe explaination is that tensorflow by default gives the info about the layer which is created by the user. If you want to give the custom name of the layer you should pass it to the **name**=\" some_name\" or if you want it to be empty it cant be possible but an alternate solution is by passing space in the **name**=\" \"\r\n\r\nHere is the link to your notebook:\r\n[https://colab.research.google.com/drive/1KBzEMwJtMsgSoIfUieLBV9_5iLKmik46?usp=sharing](url)", "> Hyy, I have descibed the issue.\r\n> The explaination is that tensorflow by default gives the info about the layer which is created by the user. If you want to give the custom name of the layer you should pass it to the **name**=\" some_name\" or if you want it to be empty it cant be possible but an alternate solution is by passing space in the **name**=\" \"\r\n> \r\n> Here is the link to your notebook:\r\n> [https://colab.research.google.com/drive/1KBzEMwJtMsgSoIfUieLBV9_5iLKmik46?usp=sharing](url)\r\n\r\nIt's impossible\r\n``` python\r\ninput = tf.keras.layers.Input((6 ,6))\r\noutput = tf.keras.layers.Dense(128, name=' ')(input)\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 952, in __call__\r\n    input_list)\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1091, in _functional_construction_call\r\n    inputs, input_masks, args, kwargs)\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 822, in _keras_tensor_symbolic_call\r\n    return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 856, in _infer_output_signature\r\n    with backend.name_scope(self._name_scope()):\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 6650, in __enter__\r\n    scope_name = scope.__enter__()\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4246, in name_scope\r\n    raise ValueError(\"'%s' is not a valid scope name\" % name)\r\nValueError: ' /' is not a valid scope name\r\n```", "BTW, I met this issue when I try to transfer JAX's weights to Tensorflow's weights. Since sometimes JAX weights don't have layer name, e.g: VIT.\r\nI wonder it's a bug or expected behavior.\r\nIf it's a bug I could fix it soon.", "Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/05756d04a1196ad097c9009027218c7b/47131.ipynb). Thanks!", "@fsx950223 I can reproduce this with recent TF2.6 and `tf-nightly`. May be this is a intended behavior. As the layer is of dense, default name includes `dense`.\r\n\r\nAs Keras moved to separate repo (i can't move the issue), can you please close here and open in keras repo https://github.com/keras-team/keras/issues\r\n\r\nKeras team is focussed on the new repo mentioned above.\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47131\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47131\">No</a>\n"]}, {"number": 47130, "title": "Different Tensorflow Performance between Linux and Windows10", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NO\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):tensorflow 2.3.0\r\n- Python version:3.7.0\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1 \r\n- GPU model and memory:Linux:11G 1080TI  Windows:6G 1060\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI use the same python environment and tensorflow version in my pc which used windows10 trained a model, and I use model.save_weights to save the model, when i back to Linux system use load_weights and the same model arch to resume but get different performance. \r\nAlso I tried use same code and same hyparameter to train model, they get different results.\r\nI am very confused.\r\n**Describe the expected behavior**\r\nI expected the same results.\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 47129, "title": "Does tf.keras.callbacks.Callback work with 3 Dimensions?", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Google Colab, OS unknown.\r\n- TensorFlow installed from (source or binary): ?\r\n- TensorFlow version: 2.0 (tf-gpu)\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): ?\r\n- GCC/Compiler version (if compiling from source): ?\r\n- CUDA/cuDNN version: CUDA 11.2\r\n- GPU model and memory: Tesla P100-PCIE w/ 16 GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI already documented everything here:  https://github.com/ayulockin/deepimageinpainting/issues/3\r\nMy last answer from 02/09/21 is my current state.\r\n\r\nMy plan was to inpaint on grayscale images by adapting their architecture: https://github.com/ayulockin/deepimageinpainting\r\n\r\n(!) The current problem is indeed the grayscale instead of the 16-bit scale which I thought earlier. (!)\r\n\r\nFirst I adapted their notebook \"Inpainting Partial Convolution\" with the training data from MNIST (60000,28,28)\r\nMNIST is 8-bit.\r\n\r\nThe results from the fit_generator() was an error:\r\n\r\n```python \r\n----> 7                      PredictionLogger()])\r\n[...]                            6 frames\r\n--> 565                            'with shape ' + str(data_shape))\r\nValueError: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (32, 28, 28) \r\n```\r\n\r\nI tried the same with my own training dataset called VT_1000 (1000, 256, 256).\r\nAlso grayscale, but 16-bit. \r\nAs I said before: This is not the problem due to normalization.\r\n\r\nThe result from fit_generator() was kind of the same:\r\n\r\n```python \r\n----> 7                      PredictionLogger()])\r\n[...]                            6 frames\r\n--> 565                            'with shape ' + str(data_shape))\r\nValueError: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (32, 256, 256)\r\n```\r\n\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n\r\n\r\nPredictionLogger is a class with tf inheritance so I assumed the problem to be here. \r\n\r\nKey lines:\r\n\r\n```python\r\n\r\n%%capture\r\n!pip install tensorflow-gpu==2.0\r\n\r\n!pip install wandb -q\r\n!pip install --upgrade wandb\r\n\r\nimport wandb\r\nfrom wandb.keras import WandbCallback\r\n\r\n!wandb login ab4d648da3c296fa678ab39761b8a37e28efec62\r\nwandb.init(entity='svsz', project=\"MNIST\")\r\n\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nimport cv2\r\nimport numpy as np\r\n\r\n\r\n\r\n\r\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n\r\nmaxElement_train, maxElement_test  = np.amax(x_train), np.amax(x_test)\r\nmaxElement = np.amax(np.array(maxElement_train, maxElement_test))\r\n\r\nformat = len(x_train[0][0])\r\nformatxy = len(x_train[0][0]), len(x_train[0][0])\r\nformatxyz = len(x_train[0][0]), len(x_train[0][0]), 1\r\n\r\n\r\n\r\n## Ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.\r\nclass createAugment(keras.utils.Sequence):\r\n  'Generates data for Keras'\r\n  def __init__(self, X, y, batch_size=32, dim=(formatxy), shuffle=True):\r\n      'Initialization'\r\n      self.batch_size = batch_size \r\n      self.X = X \r\n      self.y = y\r\n      self.dim = dim\r\n      self.shuffle = shuffle\r\n      \r\n      self.on_epoch_end()\r\n \r\n  def __len__(self):\r\n      'Denotes the number of batches per epoch'\r\n      return int(np.floor(len(self.X) / self.batch_size))\r\n\r\n  def __getitem__(self, index):\r\n      'Generate one batch of data'\r\n      # Generate indexes of the batch\r\n      indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\r\n\r\n      # Generate data\r\n      X_inputs, y_output = self.__data_generation(indexes)\r\n      return X_inputs, y_output\r\n\r\n  def on_epoch_end(self):\r\n      'Updates indexes after each epoch'\r\n      self.indexes = np.arange(len(self.X))\r\n      if self.shuffle:\r\n          np.random.shuffle(self.indexes)\r\n\r\n  def __data_generation(self, idxs):\r\n    # Masked_images is a matrix of masked images used as input\r\n    Masked_images = np.empty((self.batch_size, self.dim[0], self.dim[1])) # Masked image\r\n    # Mask_batch is a matrix of binary masks used as input\r\n    Mask_batch = np.empty((self.batch_size, self.dim[0], self.dim[1])) # Binary Masks\r\n    # y_batch is a matrix of original images used for computing error from reconstructed image\r\n    y_batch = np.empty((self.batch_size, self.dim[0], self.dim[1])) # Original image\r\n    \r\n\r\n    ## Iterate through random indexes\r\n    for i, idx in enumerate(idxs):\r\n      image_copy = self.X[idx].copy()\r\n  \r\n      ## Get mask associated to that image\r\n      masked_image, mask = self.__createMask(image_copy)\r\n      \r\n      Masked_images[i,] = masked_image/maxElement\r\n      Mask_batch[i,] = mask/maxElement\r\n      y_batch[i] = self.y[idx]/maxElement\r\n\r\n    ## Return mask as well because partial convolution require the same.\r\n    return [Masked_images, Mask_batch], y_batch\r\n\r\n  def __createMask(self, img):\r\n    ## Prepare masking matrix\r\n    mask = np.full((formatxy), maxElement, np.uint8) ## White background\r\n    for _ in range(np.random.randint(1, 5)):\r\n      # Get random x locations to start line\r\n      x1, x2 = np.random.randint(1, format), np.random.randint(1, format)\r\n      # Get random y locations to start line\r\n      y1, y2 = np.random.randint(1, format), np.random.randint(1, format)\r\n      # Get random thickness of the line drawn\r\n      thickness = np.random.randint((format/28), (format/14))\r\n      # Draw black line on the white mask\r\n      cv2.line(mask,(x1,y1),(x2,y2),(0,0,0),thickness)\r\n\r\n    ## Mask the image\r\n    masked_image = img.copy()\r\n    masked_image[mask==0] = maxElement\r\n\r\n    return masked_image, mask\r\n\r\n\r\n\r\n## Prepare training and testing mask-image pair generator\r\ntraingen = createAugment(x_train, x_train)\r\ntestgen = createAugment(x_test, x_test, shuffle=False)\r\n\r\n\r\n\r\n!git clone https://github.com/ayulockin/deepimageinpainting.git\r\n%cd deepimageinpainting/\r\n\r\n\r\n\r\n## utils is present in the cloned repo. Visit repo for the implementation of PConv2D.\r\nfrom utils.pconv_layer import PConv2D\r\n\r\n\r\n\r\n## For more information into formulation: https://www.youtube.com/watch?v=AZr64OxshLo\r\n## Metric\r\ndef dice_coef(y_true, y_pred):\r\n    y_true_f = keras.backend.flatten(y_true)\r\n    y_pred_f = keras.backend.flatten(y_pred)\r\n    intersection = keras.backend.sum(y_true_f * y_pred_f)\r\n    return (2. * intersection) / (keras.backend.sum(y_true_f + y_pred_f))\r\n\r\n\r\n\r\n\r\nclass InpaintingModel:\r\n  '''\r\n  Build UNET like model for image inpaining task.\r\n  '''\r\n  def prepare_model(self, input_size=(formatxyz)):\r\n    input_image = keras.layers.Input(input_size)\r\n    input_mask = keras.layers.Input(input_size, name='encoder_input')\r\n  \r\n    conv1, mask1, conv2, mask2 = self.__encoder_layer(32, input_image, input_mask, ['conv1', 'conv2'])\r\n    conv3, mask3, conv4, mask4 = self.__encoder_layer(64, conv2, mask2, ['conv3', 'conv4'])\r\n   # conv5, mask5, conv6, mask6 = self.__encoder_layer(128, conv4, mask4, ['conv5', 'conv6'])\r\n   # conv7, mask7, conv8, mask8 = self.__encoder_layer(256, conv6, mask6, ['conv7', 'encoder_output'])\r\n\r\n  #  conv9, mask9, conv10, mask10 = self.__decoder_layer(256, 128, conv8, mask8, conv7, mask7, ['conv9', 'conv10'])\r\n  #  conv11, mask11, conv12, mask12 = self.__decoder_layer(128, 64, conv10, mask10, conv5, mask5, ['conv11', 'conv12'])\r\n    conv13, mask13, conv14, mask14 = self.__decoder_layer(64, 32, conv4, mask4, conv3, mask3, ['conv13', 'conv14'])\r\n    conv15, mask15, conv16, mask16 = self.__decoder_layer(32, 3, conv14, mask14, conv1, mask1, ['conv15', 'decoder_output'])\r\n\r\n    outputs = keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(conv16)\r\n\r\n    return keras.models.Model(inputs=[input_image, input_mask], outputs=[outputs])\r\n    \r\n  def __encoder_layer(self, filters, in_layer, in_mask, names):\r\n    conv1, mask1 = PConv2D(32, (3,3), strides=1, padding='same', name=names[0])([in_layer, in_mask])\r\n    conv1 = keras.activations.relu(conv1)\r\n\r\n    conv2, mask2 = PConv2D(32, (3,3), strides=2, padding='same', name=names[1])([conv1, mask1])\r\n    # conv2 = keras.layers.BatchNormalization()(conv2, training=True)gis\r\n    conv2 = keras.activations.relu(conv2)\r\n\r\n    return conv1, mask1, conv2, mask2\r\n\r\n  def __decoder_layer(self, filter1, filter2, in_img, in_mask, share_img, share_mask, names):\r\n    up_img = keras.layers.UpSampling2D(size=(2,2))(in_img)\r\n    up_mask = keras.layers.UpSampling2D(size=(2,2))(in_mask)\r\n    concat_img = keras.layers.Concatenate(axis=3)([share_img, up_img])\r\n    concat_mask = keras.layers.Concatenate(axis=3)([share_mask, up_mask])\r\n\r\n    conv1, mask1 = PConv2D(filter1, (3,3), padding='same', name=names[0])([concat_img, concat_mask])\r\n    conv1 = keras.activations.relu(conv1)\r\n\r\n    conv2, mask2 = PConv2D(filter2, (3,3), padding='same', name=names[1])([conv1, mask1])\r\n    # conv2 = keras.layers.BatchNormalization()(conv2)\r\n    conv2 = keras.activations.relu(conv2)\r\n\r\n    return conv1, mask1, conv2, mask2\r\n\r\n\r\n\r\n\r\nkeras.backend.clear_session()\r\nmodel = InpaintingModel().prepare_model()\r\nmodel.summary()\r\nmodel.compile(optimizer='adam', loss='mean_absolute_error', metrics=[dice_coef])\r\n\r\n\r\n\r\nclass PredictionLogger(tf.keras.callbacks.Callback):\r\n    def __init__(self):\r\n        super(PredictionLogger, self).__init__()\r\n\r\n    def on_epoch_end(self, logs, epoch):\r\n        sample_idx = 54\r\n        [masked_images, masks], nomask = testgen[sample_idx]  \r\n        \r\n        m_images = []\r\n        binary_masks = []\r\n        predictions = []\r\n     #  labels = []\r\n        \r\n        for i in range(32):\r\n          inputs = [masked_images[i].reshape((1,)+masked_images[i].shape), masks[i].reshape((1,)+masks[i].shape)]\r\n          impainted_image = model.predict(inputs)\r\n\r\n          m_images.append(masked_images[i])\r\n          binary_masks.append(masks[i])\r\n          predictions.append(impainted_image.reshape(impainted_image.shape[1:]))\r\n          labels.append(momasks[i])\r\n\r\n        wandb.log({\"masked_images\": [wandb.Image(m_image)\r\n                              for m_image in m_images]})\r\n        wandb.log({\"masks\": [wandb.Image(mask)\r\n                              for mask in binary_masks]})\r\n        wandb.log({\"predictions\": [wandb.Image(inpainted_image)\r\n                              for inpainted_image in predictions]})\r\n      # wandb.log({\"labels\": [wandb.Image(label)\r\n                          #   for label in labels]})\r\n\r\n\r\n\r\n\r\n_ = model.fit_generator(traingen, validation_data=testgen, \r\n          epochs=20, \r\n          steps_per_epoch=len(traingen), \r\n          validation_steps=len(testgen),\r\n          use_multiprocessing=False,\r\n          callbacks=[WandbCallback(),\r\n                     PredictionLogger()])\r\n\r\n```\r\n\r\n_______________________________________________________________________________\r\n_______________________________________________________________________________\r\n\r\n\r\n### My main question is: Do I need to \"reshape\" my traingen and testgen inside of _class createAugment(keras.utils.Sequence)_ to include the single-color band into an extra list to create or emulate a \"4th color-dimension\" or... is there an easy or quick way to make Callback work with 3 dimensions?\r\n\r\n\r\n_______________________________________________________________________________\r\n_______________________________________________________________________________\r\n\r\n\r\n**Any other info / logs**\r\n\r\n\r\n\r\n\r\n\r\nExpanding the 6 frames from the Error Log:\r\n\r\n\r\n```python\r\nEpoch 1/20\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-69-7c83ff6d9254> in <module>()\r\n      5           use_multiprocessing=False,\r\n      6           callbacks=[WandbCallback(),\r\n----> 7                      PredictionLogger()])\r\n\r\n6 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1295         shuffle=shuffle,\r\n   1296         initial_epoch=initial_epoch,\r\n-> 1297         steps_name='steps_per_epoch')\r\n   1298 \r\n   1299   def evaluate_generator(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/wandb/integration/keras/keras.py in new_generator(*args, **kwargs)\r\n    109             for cbk in cbks:\r\n    110                 set_wandb_attrs(cbk, val_data)\r\n--> 111         return old_generator(*args, **kwargs)\r\n    112 \r\n    113     def new_v2(*args, **kwargs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\r\n    263 \r\n    264       is_deferred = not model._is_compiled\r\n--> 265       batch_outs = batch_function(*batch_data)\r\n    266       if not isinstance(batch_outs, list):\r\n    267         batch_outs = [batch_outs]\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)\r\n    971       outputs = training_v2_utils.train_on_batch(\r\n    972           self, x, y=y, sample_weight=sample_weight,\r\n--> 973           class_weight=class_weight, reset_metrics=reset_metrics)\r\n    974       outputs = (outputs['total_loss'] + outputs['output_losses'] +\r\n    975                  outputs['metrics'])\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)\r\n    251   x, y, sample_weights = model._standardize_user_data(\r\n    252       x, y, sample_weight=sample_weight, class_weight=class_weight,\r\n--> 253       extract_tensors_from_dataset=True)\r\n    254   batch_size = array_ops.shape(nest.flatten(x, expand_composites=True)[0])[0]\r\n    255   # If `model._distribution_strategy` is True, then we are in a replica context\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\r\n   2470           feed_input_shapes,\r\n   2471           check_batch_axis=False,  # Don't enforce the batch size.\r\n-> 2472           exception_prefix='input')\r\n   2473 \r\n   2474     # Get typespecs for the input data and sanitize it if necessary.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    563                            ': expected ' + names[i] + ' to have ' +\r\n    564                            str(len(shape)) + ' dimensions, but got array '\r\n--> 565                            'with shape ' + str(data_shape))\r\n    566         if not check_batch_axis:\r\n    567           data_shape = data_shape[1:]\r\n\r\nValueError: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (32, 256, 256)\r\n```\r\n\r\n\r\n\r\n", "comments": ["@SvSz \r\nI ran the above code on tf 2.0 as mentioned and do not face the error reported, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/24267ed7ab8683febf17cd47c2193b47/untitled537.ipynb).\r\nI ran the code on tf 2.4 and nightly as well, [gist for the same](https://colab.research.google.com/gist/Saduf2019/2608bf88118a328a5d7aab9c774b4ba9/untitled.ipynb).", "okay thank you. It does not work for me. I will simply work with my 4 dimensional data now. ", "@SvSz\r\nPlease update us if the issue exist with 4 dimensional data as well.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47129\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47129\">No</a>\n"]}, {"number": 47128, "title": "Fix `tf.keras.initializers.get`: convert provided type object to object", "body": "Closes #47054\r\n\r\nSummary: \r\n\r\nModels with layers instantiated with initializers provided as type objects couldn't be saved after training, despite models were initialized and trained fine ([colab](https://colab.research.google.com/drive/1ehWxx6PaDKP6nFMaI2Nf84O3-Xyv3-Sm?usp=sharing) with example).  This problem have been resolved the same way as in the `add_weight` method: now type objects are converting to objects in the function `initializers.get`. A unit test covering this case was implemented.\r\n\r\n\r\nPossible alternative fixes:\r\n* Remove support for type object initializers from `add_weight`. Drawback: would break backward compatibility\r\n* Make any initializer class (not just object) serializable. Could work, but hard to maintain and confusing.\r\n* Add instantiation of type objects of initializer type to the serialization function. Drawbacks: this function affects many other things and we should not overcomplicate it. Also it could lead to bugs in the parts of the code base non-related to initializets. ", "comments": ["CI failed due to my mistype, unfortunately. I am new to the Tensorflow CI, and still couldn't manage to run TF unit tests locally. So, I've fixed mistype which causes an error, but not sure if I should run tests locally before you start them in the Google CI. ", "@mishc9 can you please check sanity build failures ?", "@rthadur I've checked the failures and fixed bad indentation in my PR. Thank you for pointing that. "]}, {"number": 47127, "title": "Fix `tf.keras.initializers.get`: return initializer object if type object initializer is provided", "body": "\r\n\r\nSummary: \r\n\r\nModels with layers instantiated with initializers provided as type objects couldn't be saved after training, despite models were initialized and trained fine ([colab](https://colab.research.google.com/drive/1ehWxx6PaDKP6nFMaI2Nf84O3-Xyv3-Sm?usp=sharing) with example).  This problem have been resolved the same way as in the `add_weight` method: now type objects are converting to objects in the function `initializers.get`. A unit test covering this case was implemented.\r\n\r\n\r\nPossible alternative fixes:\r\n* Remove support for type object initializers from `add_weight`. Drawback: would break backward compatibility\r\n* Make any initializer class (not just object) serializable. Could work, but hard to maintain and confusing.\r\n* Add instantiation of type objects of initializer type to the serialization function. Drawbacks: this function affects many other things and we should not overcomplicate it. Also it could lead to bugs in the parts of the code base non-related to initializets. ", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47127) for more info**.\n\n<!-- need_author_cla -->", "Closed due to CLA problem"]}, {"number": 47126, "title": "Tensorflow Custom Metric: SensitivityAtSpecificity failed during model fitting", "body": "**System information**\r\n- MacOS\r\n- TensorFlow installed from conda\r\n- TensorFlow version 2.0.0\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\n# Background\r\nThe metric for my machine learning task is `weight TPR = 0.4 * TPR1 + 0.3 * TPR2 + 0.3 * TPR3`. Generally, it asks for a model with higher recall rate while disturbing less negative samples. \r\n\r\nSome terminology:\r\n> - TPR\uff08True Positive Rate, Sensitivity) : TPR = TP /\uff08TP + FN\uff09\r\n> - FPR\uff08False Positive Rate, 1 - Specificity\uff09: FPR = FP /\uff08FP + TN\uff09\r\n> - TP\u3001FN\u3001FP\u3001TN stands for True Positive, False Negative, Fasle Positive and True Negative. \r\n> - TPR1\uff1aTPR at FPR = 0.001\r\n> - TPR2\uff1aTPR at FPR = 0.005\r\n> - TPR3\uff1aTPR at FPR = 0.01\r\n\r\n# My attempt\r\n\r\nSince keras does not have such metric, we need to write our own custome metric. Another word for mention, unlike in lightgbm and xgboost, custom metric in `keras` is not straight-foward because training process are on tensors instead of pandas/numpy arrays.\r\n\r\nIn lightgbm/Xgboost, I have this `wtpr` custom metric, and it works fine:\r\n```\r\ndef tpr_weight_funtion(y_true,y_predict):\r\n    d = pd.DataFrame()\r\n    d['prob'] = list(y_predict)\r\n    d['y'] = list(y_true)\r\n    d = d.sort_values(['prob'], ascending=[0])\r\n    y = d.y\r\n    PosAll = pd.Series(y).value_counts()[1]\r\n    NegAll = pd.Series(y).value_counts()[0]\r\n    pCumsum = d['y'].cumsum()\r\n    nCumsum = np.arange(len(y)) - pCumsum + 1\r\n    pCumsumPer = pCumsum / PosAll\r\n    nCumsumPer = nCumsum / NegAll\r\n    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\r\n    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\r\n    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\r\n    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3\r\n```\r\n\r\n\r\nIn keras, I write a custom metric below. It works with regular tensor input, but it failed during **model fitting with batch Gradient descent**:\r\n```\r\nimport keras.backend as K\r\ndef keras_wtpr_metric(y_true, y_predict):\r\n    n = y_predict.shape[0]\r\n    \r\n    a = tf.dtypes.cast(y_predict, tf.float32)\r\n    b = tf.dtypes.cast(y_true, tf.float32)\r\n    a = tf.reshape(a,shape = [-1])\r\n    b = tf.reshape(b,shape = [-1])\r\n    d = tf.stack([a,b], axis = 0)\r\n    d = tf.gather(d, tf.argsort(a,direction='DESCENDING'), axis = 1)\r\n    PosAll = tf.math.reduce_sum(b, axis = -1) # the number of positive samples\r\n    NegAll = tf.math.reduce_sum(1-b, axis = -1) # the number of negative samples\r\n    pCumsum = tf.math.cumsum(d[1]) # TP\r\n    pCumsum = tf.dtypes.cast(pCumsum,dtype = tf.float32)\r\n    nCumsum = tf.range(0,n,dtype = tf.float32) - pCumsum + 1 # FP\r\n    pCumsumPer = pCumsum / PosAll # tpr\r\n    nCumsumPer = nCumsum / NegAll # fpr\r\n    TR1 = pCumsumPer[tf.math.argmin(abs(nCumsumPer-0.001))]\r\n    TR2 = pCumsumPer[tf.math.argmin(abs(nCumsumPer-0.005))]\r\n    TR3 = pCumsumPer[tf.math.argmin(abs(nCumsumPer-0.01))]\r\n    return tf.reduce_sum(0.4*TR1+0.3*TR2+0.3*TR3)\r\n```\r\n\r\nMy model is :\r\n```\r\nfrom sklearn.datasets import load_breast_cancer\r\nfrom sklearn.model_selection import train_test_split\r\nx_train, x_test, y_train, y_test = train_test_split(load_breast_cancer().data, load_breast_cancer().target,test_size = 0.3)\r\n\r\nmodel = keras.models.Sequential([\r\n# I have a tabular data\r\n    keras.layers.Dense(256, activation='relu',input_shape = (x_train.shape[1],)), \r\n    keras.layers.Dense(64, activation = 'relu'),\r\n    keras.layers.Dense(1, activation = 'sigmoid')\r\n])\r\nmodel.compile(optimizer='adam',loss = 'binary_crossentropy', metrics = [keras_wtpr_metric])\r\n# it seems can not work under batch training, I don't know why\r\nmodel.fit(x=x_train, y= y_train, batch_size = 2048, epochs = 30,validation_data = [x_test,y_test]) \r\n```\r\nError message is \r\n``` Train on 398 samples, validate on 171 samples\r\nEpoch 1/30\r\n398/398 [==============================] - 1s 2ms/sample\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-639-da481d44d615> in <module>\r\n      5 ])\r\n      6 model.compile(optimizer='adam',loss = 'binary_crossentropy', metrics = [keras_wtpr_metric])\r\n----> 7 model.fit(x=x_train, y= y_train, batch_size = 2048, epochs = 30,validation_data = [x_test,y_test]) # it seems can not work under batch training, I don't know why\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    518         # Lifting succeeded, so variables are initialized and we can run the\r\n    519         # stateless function.\r\n--> 520         return self._stateless_fn(*args, **kwds)\r\n    521     else:\r\n    522       canon_args, canon_kwds = \\\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n   1825   @property\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\n~/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError:  Incompatible shapes: [0] vs. [398]\r\n\t [[node metrics/keras_wtpr_metric/sub_1 (defined at /Users/travis/opt/anaconda3/envs/envpython36/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_681042]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n```\r\n# My question \r\n\r\n1. How to write a weighted SensitivityAtSpecificity in keras?\r\n2. Why my `keras_wtpr_metric` failed?\r\n\r\n# Some Useful Sources:\r\n1. https://keras.io/api/metrics/#creating-custom-metrics\r\n2. https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SensitivityAtSpecificity\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\nMy custom metric should work fine.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\n# model\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom scipy import stats\r\nimport lightgbm as lgbm\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import auc, roc_auc_score\r\nimport tensorflow as tf\r\nimport tensorflow.keras as keras\r\nimport keras.backend as K\r\ndef keras_wtpr_metric(y_true, y_predict):\r\n    n = y_predict.shape[0]\r\n    \r\n    a = tf.dtypes.cast(y_predict, tf.float32)\r\n    b = tf.dtypes.cast(y_true, tf.float32)\r\n    a = tf.reshape(a,shape = [-1])\r\n    b = tf.reshape(b,shape = [-1])\r\n    d = tf.stack([a,b], axis = 0)\r\n    d = tf.gather(d, tf.argsort(a,direction='DESCENDING'), axis = 1)\r\n    PosAll = tf.math.reduce_sum(b, axis = -1) # the number of positive samples\r\n    NegAll = tf.math.reduce_sum(1-b, axis = -1) # the number of negative samples\r\n    pCumsum = tf.math.cumsum(d[1]) # TP\r\n    pCumsum = tf.dtypes.cast(pCumsum,dtype = tf.float32)\r\n    nCumsum = tf.range(0,n,dtype = tf.float32) - pCumsum + 1 # FP\r\n    pCumsumPer = pCumsum / PosAll # tpr\r\n    nCumsumPer = nCumsum / NegAll # fpr\r\n    TR1 = pCumsumPer[tf.math.argmin(abs(nCumsumPer-0.001))]\r\n    TR2 = pCumsumPer[tf.math.argmin(abs(nCumsumPer-0.005))]\r\n    TR3 = pCumsumPer[tf.math.argmin(abs(nCumsumPer-0.01))]\r\n    return tf.reduce_sum(0.4*TR1+0.3*TR2+0.3*TR3)\r\nfrom sklearn.datasets import load_breast_cancer\r\nfrom sklearn.model_selection import train_test_split\r\nx_train, x_test, y_train, y_test = train_test_split(load_breast_cancer().data, load_breast_cancer().target,test_size = 0.3)\r\n\r\nmodel = keras.models.Sequential([\r\n# I have a tabular data\r\n    keras.layers.Dense(256, activation='relu',input_shape = (x_train.shape[1],)), \r\n    keras.layers.Dense(64, activation = 'relu'),\r\n    keras.layers.Dense(1, activation = 'sigmoid')\r\n])\r\nmodel.compile(optimizer='adam',loss = 'binary_crossentropy', metrics = [keras_wtpr_metric])\r\n# it seems can not work under batch training, I don't know why\r\nmodel.fit(x=x_train, y= y_train, batch_size = 2048, epochs = 30,validation_data = [x_test,y_test]) \r\n```\r\n\r\n", "comments": ["@thisisreallife Try this.\r\n\r\nhttps://colab.research.google.com/drive/1ngxOYmtdFXkXoEXI19g9U1PqZ8VdOkh4?usp=sharing", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @thisisreallife Try this.\r\n> \r\n> https://colab.research.google.com/drive/1ngxOYmtdFXkXoEXI19g9U1PqZ8VdOkh4?usp=sharing\r\n\r\nThanks a lot, it works! [related stackoverflow link](https://stackoverflow.com/questions/66182518/tensorflow-custom-metric-sensitivityatspecificity)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47126\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47126\">No</a>\n"]}, {"number": 47125, "title": "Model still getting updated even set the trainable flag to be False ", "body": "I have a trained DNN `model`, and I hope to find the input `x` that maximize `model.predict(x)` through gradient descent. Here's what I did:\r\n\r\n```python\r\ndef minimize_output(model, input_dim):\r\n  N = input_dim\r\n  model.trainable = False\r\n  model.compile(optimizer='adam', loss='mean_squared_error')\r\n  \r\n  x = tf.Variable( np.random.uniform(-1, 1, (1, N, 1)) , name='subset', dtype=tf.float32)\r\n\r\n  x_sigmoid = tf.sigmoid(x)\r\n  x_target = -model(x_sigmoid)\r\n\r\n  optimizer = tf.train.AdamOptimizer()\r\n  train = optimizer.minimize(x_target, var_list=[subset])\r\n\r\n  init = tf.initialize_all_variables()\r\n\r\n  with tf.Session() as session:\r\n      session.run(init)\r\n      for step in range(2000):\r\n        session.run(train)\r\n        print(\"step\", step, \"target\", x_target.eval())\r\n      subset_pred = session.run(x_sigmoid)\r\n  return subset_pred.reshape(-1)\r\n\r\nmin_input = minimize_output(model, input_dim=N)\r\n```\r\n\r\nHowever, it seems that value of `model.predict(min_input)` is much smaller than `-x_target.eval()`, therefore I think model is still updating during the Session. I have no idea why that happen, I already set model to be `model.trainable = False` and `var_lst=[subset]` for the optimizer.\r\n\r\nAnyone have any idea how can I freeze the model during the training session? Thanks a lot!!!\r\n", "comments": ["Here's output of `min_input = minimize_output(model, input_dim=N)`:\r\n\r\nstep 1990 target [[-0.9065793]]\r\nstep 1991 target [[-0.90662825]]\r\nstep 1992 target [[-0.9066771]]\r\nstep 1993 target [[-0.90672606]]\r\nstep 1994 target [[-0.906775]]\r\nstep 1995 target [[-0.90682375]]\r\nstep 1996 target [[-0.9068723]]\r\nstep 1997 target [[-0.906921]]\r\nstep 1998 target [[-0.90696967]]\r\nstep 1999 target [[-0.9070183]]\r\n\r\nHowever, the output of `model.predict(min_input)` is `[[0.7591585]]`, which is supposed to be `[[-0.9070183]]`.", "@TIANHAO-WANG,\r\nOn running the given code snippet, I am facing an error stating `NameError: name 'model' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/582b6268fc47d068e86247cc4e4bfa08/47125.ipynb).\r\n\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47125\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47125\">No</a>\n"]}, {"number": 47124, "title": "Do not use TF mirror for the AMbiq SDK.", "body": "", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}]