[{"number": 3135, "title": "Raspberry Pi build error", "body": "I am trying to build tensorflow on a Raspberry Pi 3 (Raspbian OS, gcc 4.9.2, no USB stick for swap) according to the steps provided [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile).  When I execute the following make command,\n\nmake -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI \\\n OPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\"\n\nI am getting the error reproduced below.  Is this an eigen issue?  Any suggestions on how to overcome this error?\n\n---\n\nIn file included from /usr/include/c++/4.9/atomic:41:0,\n                 from /home/pi/Desktop/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-334b1d428283/unsupported/Eigen/CXX11/ThreadPool:40,\n                 from /home/pi/Desktop/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-334b1d428283/unsupported/Eigen/CXX11/Tensor:57,\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\n                 from tensorflow/core/lib/core/threadpool.cc:19:\n/usr/include/c++/4.9/bits/atomic_base.h: In member function \u2018void Eigen::EventCount::CancelWait(Eigen::EventCount::Waiter_)\u2019:\n/usr/include/c++/4.9/bits/atomic_base.h:538:70: error: failure memory model cannot be stronger than success memory model for \u2018__atomic_compare_exchange\u2019\n  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1, __m1, __m2);\n                                                                      ^\n/usr/include/c++/4.9/bits/atomic_base.h: In member function \u2018void Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter_)\u2019:\n/usr/include/c++/4.9/bits/atomic_base.h:538:70: error: failure memory model cannot be stronger than success memory model for \u2018__atomic_compare_exchange\u2019\n  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1, __m1, __m2);\n                                                                      ^\n/usr/include/c++/4.9/bits/atomic_base.h: In member function \u2018void Eigen::EventCount::Notify(bool)\u2019:\n/usr/include/c++/4.9/bits/atomic_base.h:538:70: error: failure memory model cannot be stronger than success memory model for \u2018__atomic_compare_exchange\u2019\n  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1, __m1, __m2);\n                                                                      ^\n/usr/include/c++/4.9/bits/atomic_base.h: In member function \u2018Work Eigen::RunQueue<Work, kSize>::PushBack(Work) [with Work = tensorflow::thread::EigenEnvironment::Task; unsigned int kSize = 1024u]\u2019:\n/usr/include/c++/4.9/bits/atomic_base.h:581:70: error: failure memory model cannot be stronger than success memory model for \u2018__atomic_compare_exchange\u2019\n  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);\n                                                                      ^\n/usr/include/c++/4.9/bits/atomic_base.h: In member function \u2018void Eigen::NonBlockingThreadPoolTempl<Environment>::Schedule(std::function<void()>) [with Environment = tensorflow::thread::EigenEnvironment]\u2019:\n/usr/include/c++/4.9/bits/atomic_base.h:581:70: error: failure memory model cannot be stronger than success memory model for \u2018__atomic_compare_exchange\u2019\n  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);\n                                                                      ^\n/usr/include/c++/4.9/bits/atomic_base.h: In member function \u2018Work Eigen::RunQueue<Work, kSize>::PopFront() [with Work = tensorflow::thread::EigenEnvironment::Task; unsigned int kSize = 1024u]\u2019:\n/usr/include/c++/4.9/bits/atomic_base.h:581:70: error: failure memory model cannot be stronger than success memory model for \u2018__atomic_compare_exchange\u2019\n  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);\n                                                                      ^\n/usr/include/c++/4.9/bits/atomic_base.h: In member function \u2018Work Eigen::RunQueue<Work, kSize>::PopBack() [with Work = tensorflow::thread::EigenEnvironment::Task; unsigned int kSize = 1024u]\u2019:\n/usr/include/c++/4.9/bits/atomic_base.h:581:70: error: failure memory model cannot be stronger than success memory model for \u2018__atomic_compare_exchange\u2019\n  return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0, __m1, __m2);\n                                                                      ^\ntensorflow/contrib/makefile/Makefile:404: recipe for target '/home/pi/Desktop/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/lib/core/threadpool.o' failed\nmake: **\\* [/home/pi/Desktop/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/lib/core/threadpool.o] Error 1\n", "comments": ["I've seen this bug on gcc 4.9 - can you try installing 4.8 manually, and then running it like this:\n\n``` bash\nmake -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI \\\nOPTFLAGS=\"-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize\" \\\nCXX=g++-4.8\n```\n", "Thanks, this worked for me and I am closing this issue.\n"]}, {"number": 3134, "title": "Fix arithmetic transform test", "body": "", "comments": []}, {"number": 3133, "title": "Update README.md", "body": "Fixed spelling mistake line 64\nFixed link to NDK line 107\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3132, "title": "Fixed early stopping example and copyright", "body": "- Used `DNNClassifier` for early stopping example\n- Updated copyright information\n", "comments": []}, {"number": 3131, "title": "string_input_producer misbehave when num_epochs is set", "body": "string_input_producer doesn't seem to enqueue string when the **num_epochs** is set.\n\nWith the following code, the program print [0], which is not right.\n\n``` python\nimport tensorflow as tf\nsess = tf.InteractiveSession()\nfilenames = [\"1\", \"2\", \"3\"]\nfilename_queue = tf.train.string_input_producer(filenames, num_epochs=10)\ntest_value = tf.convert_to_tensor(filename_queue.size())\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\nprint(sess.run([test_value]))\n```\n\nBut if I take out num_epochs,\n\n``` python\nimport tensorflow as tf\nsess = tf.InteractiveSession()\nfilenames = [\"1\", \"2\", \"3\"]\nfilename_queue = tf.train.string_input_producer(filenames)\ntest_value = tf.convert_to_tensor(filename_queue.size())\n\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\nprint(sess.run([test_value]))\n```\n\nIt prints [3] as expected.\n\nIs there anyone else encounter the same issue?\n", "comments": ["The solution is to add the line\n\n``` python\nsess.run(tf.initialize_all_variables())\n```\n\n...before starting the queue runners. The `tf.train.string_input_producer()` function creates a variable internally to track the current epoch index, and (at present) it needs to be initialized before use.\n", "I had to run \r\n\r\n` sess.run(tf.initialize_local_variables())`\r\n \r\nTo fix this when I had the same problem. Just adding this for reference for other folks."]}, {"number": 3130, "title": "Remove mentions of `with_dependencies` from API docs", "body": "We no longer (perhaps never did?) expose this function in our public API, so it shouldn't be mentioned in our public API docs.\n", "comments": ["@tensorflow-jenkins, test this please.\n"]}, {"number": 3129, "title": "Change FIXME to TODO", "body": "FIXME is on the list of banned words in the Google export script.\n", "comments": ["@tensorflow-jenkins test this please\n", "No need for testing this, i'll just merge\n", "Thanks.\n"]}, {"number": 3128, "title": "conv3d_transpose -- Error in 'python': free(): invalid pointer", "body": "I'm running into an issue with the recently added `conv3d_transpose` -- error statement in the title. The network builds, but upon first training session it outputs the above error, runs for a second, and then `Aborted (core dumped)`.  I have verified all dimensions and data. \n\nI wrote a simple convolutional-deconvolutional network to reproduce the bug. This small program actually outputs a different error than the network I am trying to build, but I believe it is pointing to the same issue.\n\nThe error it is outputting is: `Error in 'python': double free or corruption (out):`\n\nI have tried running the program on two different linux (Ubuntu 14) machines. I had to install Tensorflow from the nightly builds in order to include the `conv3d_transpose` source code. I want to try and run the program on my Mac, but there isn't a build out yet that includes the function.\n\n```\n#this is a small program to reproduce the bug\n    # Error in 'python': free(): invalid pointer:\n    # and\n    # Error in `python': double free or corruption (out):\n\n    #the network is designed for image segmentation\n        #input and outputs have the same dimensions\n\nimport tensorflow as tf\nimport numpy as np\nimport pdb\n\nlearning_rate = 0.001\n\nn_depth = 5\nn_input_x = 200\nn_input_y = 200\nn_classes = 2\nn_examples = 3\n\nx = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y])\ny = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y, n_classes], name=\"ground_truth\")\n\n#generate random data\ninput_data = np.random.rand(n_examples, n_depth, n_input_x, n_input_y)\nlabel_data = np.random.rand(n_examples * n_depth * n_input_x * n_input_y, n_classes)\n\nweights = {\n    'l1': tf.Variable(tf.random_normal([5, 5, 5, 1, 32])),\n    'l2': tf.Variable(tf.random_normal([3, 2, 2, 2, 32]))\n}\n\nbiases = {\n    'l1': tf.Variable(tf.random_normal([32])),\n    'l2': tf.Variable(tf.random_normal([2]))\n}\n\n#build network\ndef conv(x, w, b):\n    #one convolutional layer followed by one deconvolutional layer\n    x = tf.reshape(x, shape=[-1, n_depth, n_input_x, n_input_y, 1])\n\n    conv1 = tf.nn.conv3d(x, weights['l1'], strides=[1,1,1,1,1], padding=\"SAME\")\n    conv1 = tf.nn.bias_add(conv1, biases['l1'])\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool3d(conv1, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding=\"SAME\")\n\n    output_shape = [n_examples, n_depth, n_input_x, n_input_y, n_classes]\n    deconv1 = tf.nn.conv3d_transpose(conv1, weights['l2'], output_shape=output_shape, strides=[1,1,2,2,1], padding=\"VALID\")\n    deconv1 = tf.nn.bias_add(deconv1, biases['l2'])\n\n    return deconv1\n\npred = conv(x, weights, biases)\n\n#reshape for classification\ntemp_pred = tf.reshape(pred, [-1,n_classes])\ntemp_y = tf.reshape(y, [-1,n_classes])\n\n#define loss & optimizer\ncost = tf.nn.softmax_cross_entropy_with_logits(temp_pred, temp_y)\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\ninit = tf.initialize_all_variables()\n\n#train\nwith tf.Session() as sess:\n    sess.run(init)\n    sess.run(optimizer, feed_dict={x: input_data, temp_y: label_data})\n\n```\n", "comments": ["Looks like this came in from https://github.com/tensorflow/tensorflow/pull/3049\n\n@daeyun can you take a look?\n", "Any update on this @daeyun ?\n", "@KendallWeihe I'm unable to reproduce the error. Have you tried running a 2D version of this? Are you using GPU or CPU? I installed from sources with cuda 7.5, cuDNN 5.1.3, python 3.5 (anaconda), ubuntu 14.04.\n", "I'm currently trying to install python 3.5, but the nightly builds are 404 https://github.com/tensorflow/tensorflow/issues/3196#issuecomment-230926570\n", "I have installed tensorflow for python 3.4 and I'm still getting the same error `*** Error in`python3.4': free(): invalid pointer: 0x00007f98bf2eb0b0 ***` \n\nStill trying to install for python 3.5, but the nightly builds for 3.5 install for 3.4. \n", "Ok I have successfully installed Python 3.5, but the error still exists. `*** Error in 'python3.5': free(): invalid pointer: 0x00007f09bc3cde30 ***\nAborted (core dumped)`\n\nI'm installed with the latest nightly build [here](http://ci.tensorflow.org/view/Nightly/job/nightly-python35-linux-cpu/)  for CPU, python 3.5.2, and ubuntu 14.04. Can you test this setup?\n\nI have a 2D network fully functional, and can confirm that the issue is from `conv3d_transpose`\n", "Pinging @daeyun again on this. @andydavis1 can you try to recreate this issue? You just need to copy and paste the example code I have given. Are you training with a CPU or a GPU? I have narrowed down the problem to CPU vs GPU.\n", "@daeyun I tested on Mac OS, CPU, Python 3.5. It trains for one iteration and then seg faults. It is probably a similar problem as this issue -- memory running out because it isn't able to `free()`\n", "Why is this issue closed?\n\nThink this issue still persists?\n", "is there any solution for this issue ? \r\n", "I have not tested this in a while, but the last time I tested it, the bug was still present. I have since upgraded to training on a GPU and that fixed the issue. If someone can confirm that this is still a bug, then this issue needs to be reopened, or just open a new issue and reference this one.", "@KendallWeihe please open a new one referencing this one and CC me and @gunan on this.\r\n\r\nWe test a lot of our code with asan and msan, but if this fell through the cracks that's a really important issue for us.\r\n", "I found this issue happened in my docker container using tensorflow 1.0.0 `gcr.io/tensorflow/tensorflow:1.0.0-devel-py3`. Is this the source of the problem? Was 1.0.0 suppose to fix it? I'm unsure what to do to fix this.", "I am also having this problem using the bleeding-edge version of theano (as of july 6)"]}, {"number": 3127, "title": "installation problem (version `GLIBC_2.14' not found)", "body": "Hello,\nI tried to install tensorflow using pip.\nIt has been installed without any error.\nWhen I am trying to use it:\nimport tensorflow as tf\nit gives me the following error, but the requested library exists at the /lib64/.\nWhat should I do?!\nThanks\n\n> Traceback (most recent call last):\n>   File \"<string>\", line 1, in <module>\n>   File \"/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/**init**.py\", line 23, in <module>\n>     from tensorflow.python import *\n>   File \"/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/**init**.py\", line 48, in <module>\n>     from tensorflow.python import pywrap_tensorflow\n>   File \"/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n>     _pywrap_tensorflow = swig_import_helper()\n>   File \"/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n>     _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n> ImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)\n### Environment info\n\nOperating System:\nLinux mmmlog2 2.6.32-573.26.1.el6.x86_64 #1 SMP Tue Apr 12 01:47:01 EDT 2016 x86_64 x86_64 x86_64 GNU/Linux Red Hat\n\nInstalled version of CUDA and cuDNN: 7.5 & 5\n\n> -rw-rw-r-- 1 jbaker2 jbaker2 189170 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudadevrt.a\n> lrwxrwxrwx 1 jbaker2 jbaker2     16 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5\n> lrwxrwxrwx 1 jbaker2 jbaker2     19 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18\n> -rwxrwxr-x 1 jbaker2 jbaker2 311596 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudart.so.7.5.18\n> -rw-rw-r-- 1 jbaker2 jbaker2 558020 May 31 08:11 /apps/CUDA/cuda-7.5/lib/libcudart_static.a\n\nIf installed from binary pip package, provide:\n\nI am using conda, https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl\n\nThe output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`:\n\n> Traceback (most recent call last):\n>   File \"<string>\", line 1, in <module>\n>   File \"/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/**init**.py\", line 23, in <module>\n>     from tensorflow.python import *\n>   File \"/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/**init**.py\", line 48, in <module>\n>     from tensorflow.python import pywrap_tensorflow\n>   File \"/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n>     _pywrap_tensorflow = swig_import_helper()\n>   File \"/project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n>     _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n> ImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /project/EvolvingAI/mnorouzz/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)\n", "comments": ["This seems to be a CentOS 6 system. Its glibc is too old for the pre-built TensorFlow packages. You may be able to install from source.\n", "But installation from source needs Bazel\n\nBazel needs GLIBC_2.14\n\nWhat Should I do?\n\n@martinwicke \n", "That's why I wrote \"may be able to\" :(\n\nFor C++ only, you can build using the cmake or makefile in contrib. But that doesn't give you the python (as of now).\n\nDo you have the ability to install things (like a new glibc) on these machines?\n", "@zh19970205 Did you solve your problem? I have the same issue...\n", "@faruihuihui  I have not solve it yet :(, I just run tensorflow in another machine :|\n", "If anyone is still running into the same problem (like I did few days ago) - it turns out to be perfectly possible to build bazel-0.4.1 and then build tensorflow 0.12rc0 from source on CentOS6.5, with glibc-2.12. However, [some tricks](https://github.com/tensorflow/tensorflow/issues/110#issuecomment-265431453) are needed.", "I had the same problem while using the mini conda, I think it might be due to not updated version. I installed Anaconda to replace mini conda and it worked. So the best way is to update your IDE."]}, {"number": 3126, "title": "GPU not working on C++", "body": "I'm on working on load trained model in c++ like [this](http://stackoverflow.com/questions/34343259/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow/34343517#34343517).\nAfter many tries, I've manage to load trained model with its weights. But it looks like c++ version doesn't use GPU for inference. While running my code in c++, I check GPU usage using nvidia-smi and there is no change in GPU usage. After close looking at the example code in /tensorflow/cc/tutorials/example_trainer.cc and [this,](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/graph/default_device.h) I've tried assigning device to each node like below. But still, no GPU usage in nvidia-smi and actual running time is horribly slow. BTW, there is no problem using GPU if it is running on python.\n`  const std::string device = \"/gpu:0\";\n\n  std::vector<string> vNames;\n\n  int node_count = graph_def.node_size();\n  for (int i = 0; i < node_count; i++) {\n      auto n = graph_def.node(i);\n       if (n.name().find(\"nWeights\") != std::string::npos) {\n          vNames.push_back(n.name());\n          std::cout << n.name() << std::endl;\n      }\n      auto node = graph_def.mutable_node(i);\n      node->set_device(device);\n  }`\n\nMy Environment:\nOS: ubuntu 14.04\nGraphics: GeForce GTX 980 Ti\nCUDA Driver Version / Runtime Version          7.5 / 7.5\nCUDA Capability Major/Minor version number:    5.2\n", "comments": ["Did you print out the GraphDef and check that the \"/gpu:0\" device was set in each node? Can you include a link to your C++ code which has the issue?\n", "Here is the code. when printing out std::cout <<  node->device() << std::endl, /gpu:0 was printed out. But no GPU was running. \n\n#include <opencv2/core/core.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <iostream>\n\n#include \"tensorflow/core/public/session.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/graph/default_device.h\"\n#include \"tensorflow/core/graph/graph_def_builder.h\"\n\nusing namespace tensorflow;\n\nint main(int argc, char\\* argv[]) {\n\n  int width=100;\n  int height=100;\n  cv::Mat image = cv::imread(\"/home/myname/test1.jpg\");\n  image.convertTo(image, CV_32FC1);\n\n  // Initialize a tensorflow session\n  Session\\* session;\n  Status status = NewSession(SessionOptions(), &session);\n  if (!status.ok()) {\n    std::cout << status.ToString() << \"\\n\";\n    return 1;\n  }\n\n  // Read in the protobuf graph we exported\n  // (The path seems to be relative to the cwd. Keep this in mind\n  // when using `bazel run` since the cwd isn't where you call\n  // `bazel run` but from inside a temp folder.)'/home/daejin/test_model2', 'train.pb'\n  GraphDef graph_def;\n\n  status = ReadBinaryProto(Env::Default(), \"/home/daejin/test_model2/train.pb\", &graph_def);\n  if (!status.ok()) {\n    std::cout << status.ToString() << \"\\n\";\n    return 1;\n  }\n\n  // Add the graph to the session\n  status = session->Create(graph_def);\n  const std::string device = \"/gpu:0\";\n  std::vector<string> vNames;\n  int node_count = graph_def.node_size();\n  for (int i = 0; i < node_count; i++) {\n      auto n = graph_def.node(i);\n       if (n.name().find(\"nWeights\") != std::string::npos) {\n          vNames.push_back(n.name());\n      }\n      auto node = graph_def.mutable_node(i);\n      node->set_device(device);\n      std::cout <<  node->device() << std::endl;\n  }\n\n  std::vectortensorflow::Tensor out1;\n  session->Run({}, vNames, {}, &out1);\n  Tensor input(tensorflow::DT_FLOAT, {1, height, width,3});\n  Tensor learning_phase(tensorflow::DT_UINT8, TensorShape());\n  learning_phase.scalar<uchar>()()=0;\n  std::copy_n(image.begin<float>(), width*height,\n              input.flat<float>().data());\n\n  graph::SetDefaultDevice(\"/gpu:0\", &graph_def);\n\n  // The session will initialize the outputs\n  std::vectortensorflow::Tensor outputs;\n\n  const TensorShape expected_shape({1, height, width,1});\n  cv::Mat outMat = cv::Mat::zeros(height, width, CV_32FC1);\n\n  status = session->Run(\n        {{\"input1:0\", input}},\n        {\"output1:0\"}, {}, &outputs);\n  if (!status.ok()) {\n    std::cout << status.ToString() << \"\\n\";\n    return 1;\n  }\n}\n", "I've just found that when running a tensorflow python script using '$python ~.py', GPU was used. \nBut if the script is built with bazel and execute binary, GPU was not used.\nFYI, I've put my code on tensorflow/example/myproject directory in tensorflow source location. \n", "My bad. building with '-c opt --config=cuda' option solved problem.\n", "BTW, in the future you can use IsCudaEnabled from\ntensorflow/core/util/port.cc in your tests to catch building without GPU\noptions, AddDevices from tensorflow/core/common_runtime/device_factory.h to\ncatch cases when GPUs are missing for other reasons\n\nOn Fri, Jul 1, 2016 at 2:20 PM, dzhyeon notifications@github.com wrote:\n\n> Closed #3126 https://github.com/tensorflow/tensorflow/issues/3126.\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3126#event-710374895,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AABaHI2_sGMhZfc_VBbQE9PuJBPl-77Wks5qRPgHgaJpZM4JCYuH\n> .\n", "@dzhyeon building what ? you mean rebuilding tensorflow with cuda option? ", "@dzhyeon , I also come this problem now. I build the tensorflow using bazel build -c opt --config=cuda , but I still cannot slove this problem. Can you help me?\r\n\r\nI do like;\r\n1   ./configure.  I choose CUDA support, and cuda 9.1 and cudnn 7 is used.\r\n2   bazel .   bazel build -c opt --config=cuda //tensorlfow:libtensorflow_cc.so.\r\nAt last ,complete sucessfully.\r\n\r\nMy code like:\r\n\r\n#include <tensorflow/core/protobuf/meta_graph.pb.h>\r\n#include <tensorflow/core/public/session.h>\r\n#include <tensorflow/core/graph/default_device.h>\r\n#include <tensorflow/core/graph/graph_def_builder.h>\r\n\r\ntensorflow::GraphDef GraphDef;\r\ntensorflow::Session* Session = nullptr;\r\n\r\n1 void LoadGraph()\r\n2 {\r\n3       // Read in the protobuf graph we exported\r\n4        tensorflow::Status Status;\r\n5\r\n6         Status = tensorflow::ReadBinaryProto(tensorflow::Env::Default(), \"my_model.pb\", &GraphDef);\r\n7 if (!Status.ok())\r\n8 {\r\n9         printf(\"Error reading graph definition from %s: %s\\n\", \"my_model.pb\", Status.ToString().c_str());\r\n10        return false;\r\n11 }\r\n12\r\n13         Session = tensorflow::NewSession(tensorflow::SessionOptions());\r\n14 if (Session == nullptr)\r\n15 {\r\n16         printf(\"Could not create Tensorflow session.\\n\");\r\n17         return false;\r\n18 }\r\n19\r\n20 graph::SetDefaultDevice(\"/device:GPU:0\",&GraphDef); ///////// I add , for use GPU\r\n\r\n21 // Add the graph to the session\r\n22 Status = Session->Create(GraphDef);\r\n23 if (!Status.ok())\r\n24 {\r\n25        printf(\"Error creating graph: %s\\n\", Status.ToString().c_str());\r\n26        return false;\r\n27 }\r\n28 }\r\n\r\nBut the code will be get an error.  Segmentation fault(core dumped)..I do not know how to deal with it.\r\n\r\nwhen I do ldd libtensorflow_cc.so, the result like :\r\n![image](https://user-images.githubusercontent.com/28335784/39849233-d4ddbabc-543d-11e8-8793-78989d1e54ac.png)\r\n\r\n\r\n\r\n\r\n", "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): jetpack 4.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below):2.0.0\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source):0.26.1\r\n- GCC/Compiler version (if compiling from source):7.5\r\n- CUDA/cuDNN version:10.0/7.6.3\r\n- GPU model and memory: tegra tx2\r\n\r\n\r\n**Describe the current behavior**\r\nwhen I try running sample application it is crashing. With error logs as \"CUDA runtime implicit initialization on GPU:0 failed. Status: unknown error\"\r\n\r\n**Describe the expected behavior**\r\nit should start session\r\n\r\n**Standalone code to reproduce the issue**\r\nSample Code \r\n```\r\n#include <tensorflow/core/platform/env.h>\r\n#include <tensorflow/core/public/session.h>\r\n#include <iostream>\r\nusing namespace std;\r\nusing namespace tensorflow;\r\n\r\nint main()\r\n{\r\n    Session* session;\r\n    Status status = NewSession(SessionOptions(), &session);\r\n    if (!status.ok()) {\r\n        cout << status.ToString() << \"\\n\";\r\n    }\r\n    session->Close();\r\n    cout << \"Session successfully created.\\n\";\r\n}\r\n\r\n```\r\n\r\nCMakeLists.txt\r\n```\r\ncmake_minimum_required(VERSION 3.10)\r\n\r\nproject(test_hello)\r\n\r\nset(TENSORFLOW_LIBRARIES tensorflow_cc protobuf)\r\nadd_executable(example example.cpp)\r\nset(CUDA_NVCC_FLAGS\r\n        ${CUDA_NVCC_FLAGS};\r\n        -O3 -gencode arch=compute_30,code=sm_30;\r\n        --std=c++11\r\n        )\r\nset(CMAKE_CXX_STANDARD 11)\r\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\r\n\r\n# Link the Tensorflow library.\r\n# TensorFlow headers\r\ninclude_directories(\"/usr/local/include/\")\r\ninclude_directories(\"/usr/local/include/tensorflow/\")\r\ninclude_directories(\"/usr/local/include/third-party/\")\r\ntarget_link_libraries(example \"/usr/local/lib/libtensorflow_cc.so\")\r\n\r\n# You may also link cuda if it is available.\r\nfind_package(CUDA)\r\nif(CUDA_FOUND)\r\n  target_link_libraries(example ${CUDA_LIBRARIES})\r\nendif()\r\n\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```\r\n$ ./example \r\n2020-07-08 15:01:34.122381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-07-08 15:01:34.127413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-07-08 15:01:34.127566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3\r\npciBusID: 0000:00:00.0\r\n2020-07-08 15:01:34.127608: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-07-08 15:01:34.127693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-07-08 15:01:34.127815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-07-08 15:01:34.127879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\nInternal: CUDA runtime implicit initialization on GPU:0 failed. Status: unknown error\r\nSegmentation fault (core dumped)\r\n\r\n```", "is this issue resolved ?"]}, {"number": 3125, "title": "TypeError: load_dataset() got an unexpected keyword argument 'test_with_fake_data'", "body": "### Environment info\n\nOperating System: ubuntu 14.04 and Mac OSX\nPip install: 0.9.0\n\nIn 'tensorflow/tensorflow/examples/skflow/' folder, when run 'text_classification*.py',\nthe code\n'''\ndbpedia = learn.datasets.load_dataset(\n    'dbpedia', test_with_fake_data=FLAGS.test_with_fake_data)\n'''\ncause a bug\n'''\nTypeError: load_dataset() got an unexpected keyword argument 'test_with_fake_data'\n'''\n\nIt is because that if user install tensorflow by pip, the definition of 'load_dataset()' in 'tensorflow/tensorflow/contrib/learn/python/learn/datasets/**init**.py' is\n'def load_dataset(name):',\nbut in current git version, the definition of 'load_dataset()' is\n'def load_dataset(name, size='small', test_with_fake_data=False):'.\n", "comments": ["@ziaoang Yeah you are using the old version. Please install the latest version. \n", "@terrytangyuan Do you mean I should re-install tensorflow via source code instead of pip?\n", "I re-install tensorflow via source code, and the example runs normally. Thank you @terrytangyuan .\n"]}, {"number": 3124, "title": "Branch 126308395", "body": "Merging internal Google changes.\n", "comments": ["@vrv @martinwicke this seems good to go except for a known flaky test tensorflow/contrib/learn/python/learn/utils/export_test.py\n"]}, {"number": 3123, "title": "Documentation link broken ", "body": "### Environment info\n\nOperating System: osX\nBrowser: Firefox\nLooks like the below link in the documentation page is broken\n\nhttps://www.tensorflow.org/versions/r0.9/tutorials/linear/index.html\n", "comments": []}, {"number": 3122, "title": "Enable tf.erf() for SparseTensor", "body": "Enabled `tf.erf()` for `SparseTensor`. Added tests and verified locally. This partially addresses #1828.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "@vrv @martinwicke could you please merge this? It is only blocked by the failing tflearn/export test, which is known to be flaky.\n"]}, {"number": 3121, "title": "change boringssl resource from googlesource to github", "body": "Due to the network issue in China, the `https://boringssl.googlesource.com/boringssl` can not be downloaded while using Bazel. So I suggest to change it to a github mirror `https://github.com/google/boringssl.git`.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3120, "title": "R0.9 merge", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "This is pure cherry-picks, so CLA can be ignored.\n", "Jenkins, test this please.\n"]}, {"number": 3119, "title": "can not load custom op", "body": " I just do as the document'adding a new op', when i used the Op in Python, i got the error as below:\n I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nTraceback (most recent call last):\n  File \"test.py\", line 2, in <module>\n    zero_out_module = tf.load_op_library('zero_out.so')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py\", line 57, in load_op_library\n    raise RuntimeError(compat.as_text(py_tf.TF_Message(status)))\nRuntimeError: zero_out.so: undefined symbol: _ZN10tensorflow10DEVICE_CPUE\n\nwhere am i wrong?\n", "comments": ["How did you compile the shared library?\nDid you use `bazel` or a manual compilation command?\n\nIf you feel that a problem you're having might not be a bug, but just a problem with how you're using tensorflow, it's better to post it to the tensorflow Discuss group: https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss\n", "More information is required to understand the issue. Can you please provide the information requested in the \"NewIssue\" template:\n\nGitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from sources, provide the commit hash:\n\n### Steps to reproduce\n\n1.\n2.\n3.\n\n### What have you tried?\n\n1.\n\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 3118, "title": "Update the directory of cuDNN in doc of install cuda", "body": "The directory of cuDNN has been changed to `cuda`. It would be better to update the doc.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n\nOn Thu, Jun 30, 2016 at 12:05 PM, googlebot notifications@github.com\nwrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n> \n> \ud83d\udcdd _Please visit https://cla.developers.google.com/\n> https://cla.developers.google.com/ to sign._\n> \n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> \n> ## verify. Thanks.\n> - If you've already signed a CLA, it's possible we don't have your\n>   GitHub username or you're using a different email address. Check your\n>   existing CLA data https://cla.developers.google.com/clas and verify\n>   that your email is set on your git commits\n>   https://help.github.com/articles/setting-your-email-in-git/.\n> - If you signed the CLA as a corporation, please let us know the\n>   company's name.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3118#issuecomment-229554346,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AClteCvWyIz76lCQFx0ug3b_pzZBw3X2ks5qQ0CdgaJpZM4JByDM\n> .\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Thanks!\n", "Thanks for merging this @martinwicke \ud83d\ude03 \n"]}, {"number": 3117, "title": "Android Tensorflow Crashes w/ Custom Graph ", "body": "Solved: Followed steps at the bottom of [#1269](https://github.com/tensorflow/tensorflow/issues/1269)\n\nAnd the app works fine!\n### Environment info\n\nUbuntu 14.04\nAndroid LG G4\n\nInstalled version of CUDA and cuDNN: \nCuda 7.5\ncuDNN 5\n\n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Jun 29 09:46 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 root root       17 Jun 29 09:46 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.5\n-rwxrwxr-x 1 root root 59909104 Apr 22 17:15 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n-rw-rw-r-- 1 root root 58775484 Apr 22 17:15 /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from sources, provide the commit hash:\n\nInstalled from source June 29th, 2016\n### Steps to reproduce\n1. Followed Tensorflow for Poets tutorial (OK!) used --config=cuda and --use_gpu to speed up process\n2. Create new graph and labels and test to see if it can classify new image (OK!)\n3. Try to build tensorflow_demo.apk using new graph and labels with modifications to:\n\n[TensorflowImageListener.java](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorflowImageListener.java#L45)\n\n```\n  // These are the settings for the original v1 Inception model. If you want to\n  // use a model that's been produced from the TensorFlow for Poets codelab,\n  // you'll need to set IMAGE_SIZE = 299 **_# do they mean INPUT_SIZE?_**, IMAGE_MEAN = 128, IMAGE_STD = 128,\n  // INPUT_NAME = \"Mul:0\", and OUTPUT_NAME = \"final_result:0\".\n  // You'll also need to update the MODEL_FILE and LABEL_FILE paths to point to\n  // the ones you produced.\n  private static final int NUM_CLASSES = 5;\n  private static final int INPUT_SIZE = 299;\n  private static final int IMAGE_SIZE = 299; **_# i added this line in / confused about instructions_**\n  private static final int IMAGE_MEAN = 128;\n  private static final float IMAGE_STD = 128;\n  private static final String INPUT_NAME = \"Mul:0\";\n  private static final String OUTPUT_NAME = \"final_result:0\";\n\n  private static final String MODEL_FILE = \"file:///android_asset/retrained_graph.pb\";\n  private static final String LABEL_FILE =\n\"file:///android_asset/retrained_labels.txt\";\n\n// I moved files into /tensorflow/examples/android/assets\n```\n\n4) Do bazel build and adb devices install\n\n5) Launch app and it crashes everytime\n### What have you tried?\n1.  I restored TensorflowImageListener.java to it's original state and the app works fine.\n", "comments": ["Can you post the adb logcat output please?\n\nYou are probably get an unsupported op error for decodejpeg. If you are then you can use strip_unused.py to remove it from your model.\n", "re06-29 20:06:44.680 20471 20486 F native  : tensorflow_jni.cc:304 Error during inference: Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs\n06-29 20:06:44.680 20471 20486 F native  :   [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]\n06-29 20:06:44.680 20471 20486 F libc    : Fatal signal 6 (SIGABRT), code -6 in tid 20486 (InferenceThread)\n06-29 20:06:44.782   440   440 F DEBUG   : **\\* **\\* **\\* **\\* **\\* **\\* **\\* **\\* **\\* **\\* **\\* **\\* **\\* **\\* **\\* ***\n06-29 20:06:44.782   440   440 F DEBUG   : Build fingerprint: 'lge/p1_tls_ca/p1:6.0/MRA58K/1608715111a20:user/release-keys'\n06-29 20:06:44.782   440   440 F DEBUG   : Revision: '11'\n06-29 20:06:44.782   440   440 F DEBUG   : ABI: 'arm'\n06-29 20:06:44.783   440   440 F DEBUG   : pid: 20471, tid: 20486, name: InferenceThread  >>> org.tensorflow.demo <<<\n06-29 20:06:44.783   440   440 F DEBUG   : signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------\n06-29 20:06:44.806   440   440 F DEBUG   : Abort message: 'tensorflow_jni.cc:304 Error during inference: Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs\n06-29 20:06:44.806   440   440 F DEBUG   :   [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]'\n06-29 20:06:44.807   440   440 F DEBUG   :     r0 00000000  r1 00005006  r2 00000006  r3 f3e7a978\n06-29 20:06:44.807   440   440 F DEBUG   :     r4 f3e7a980  r5 f3e7a930  r6 00000000  r7 0000010c\n06-29 20:06:44.807   440   440 F DEBUG   :     r8 f3e7a298  r9 f3e7a008  sl 0000e1b1  fp 00000000\n06-29 20:06:44.807   440   440 F DEBUG   :     ip 00000006  sp f3e79fb0  lr f75420ed  pc f7543ee8  cpsr 400f0010\n06-29 20:06:44.811   440   440 F DEBUG   : \n06-29 20:06:44.811   440   440 F DEBUG   : backtrace:\n06-29 20:06:44.811   440   440 F DEBUG   :     #00 pc 00041ee8  /system/lib/libc.so (tgkill+12)\n06-29 20:06:44.812   440   440 F DEBUG   :     #01 pc 000400e9  /system/lib/libc.so (pthread_kill+32)\n06-29 20:06:44.812   440   440 F DEBUG   :     #02 pc 0001c88f  /system/lib/libc.so (raise+10)\n06-29 20:06:44.812   440   440 F DEBUG   :     #03 pc 00019a41  /system/lib/libc.so (__libc_android_abort+34)\n06-29 20:06:44.812   440   440 F DEBUG   :     #04 pc 000175fc  /system/lib/libc.so (abort+4)\n06-29 20:06:44.812   440   440 F DEBUG   :     #05 pc 0052c034  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so\n06-29 20:06:44.812   440   440 F DEBUG   :     #06 pc 0052c1b8  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so\n06-29 20:06:44.812   440   440 F DEBUG   :     #07 pc 0052c1d4  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so\n06-29 20:06:44.812   440   440 F DEBUG   :     #08 pc 000750f0  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so\n06-29 20:06:44.812   440   440 F DEBUG   :     #09 pc 0007530c  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so (Java_org_tensorflow_demo_TensorflowClassifier_classifyImageBmp+256)\n06-29 20:06:44.812   440   440 F DEBUG   :     #10 pc 000136bd  /data/app/org.tensorflow.demo-1/oat/arm/base.odex (offset 0xd000) (java.lang.String org.tensorflow.demo.TensorflowClassifier.classifyImageBmp(android.graphics.Bitmap)+96)\n06-29 20:06:44.812   440   440 F DEBUG   :     #11 pc 000139df  /data/app/org.tensorflow.demo-1/oat/arm/base.odex (offset 0xd000) (java.util.List org.tensorflow.demo.TensorflowClassifier.recognizeImage(android.graphics.Bitmap)+154)\n06-29 20:06:44.813   440   440 F DEBUG   :     #12 pc 00013fd3  /data/app/org.tensorflow.demo-1/oat/arm/base.odex (offset 0xd000) (void org.tensorflow.demo.TensorflowImageListener$1.run()+174)\n06-29 20:06:44.813   440   440 F DEBUG   :     #13 pc 035d79d7  /system/framework/arm/boot.oat (offset 0x2949000)\n06-29 20:06:45.133   440   440 F DEBUG   : \n06-29 20:06:45.133   440   440 F DEBUG   : Tombstone written to: /data/tombstones/tombstone_05\n\nFollowed steps at the bottom of [#1269 ](https://github.com/tensorflow/tensorflow/issues/1269)\n\nAnd the app works fine!  Solved!\n"]}, {"number": 3116, "title": "Getting an 0.8 .whl when installing from source from master branch", "body": "I'm getting an `0.8` `.whl` when installing from source right now (current master [6-27]; Ubuntu 15.1; Python3.5). Am trying it from scratch again.\n- Checked the repo: `README.md`: `# Release 0.9.0`\n- cudnn 7.5, is that correct?\n- bazel version: `0.2.3`\n\nOutput from `ls -l /usr/local/cuda/lib64/cudn*`:\n\n`\n Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\n16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\n19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n61453024 Jun 25 17:23 /usr/local/cuda/lib64/libcudnn.so\n61453024 Jun 25 17:23 /usr/local/cuda/lib64/libcudnn.so.4\n61453024 Jun 25 17:23 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n62025862 Jun 25 17:23 /usr/local/cuda/lib64/libcudnn_static.a\n`\n\n**And my primary question: what does the following mean:**\n\n`Cudnn libraries, use '6.5' for R2, '7.0' for R3, and '4.0.4' for R4-RC.`\n\nThat's about the only thing I can think of that could be causing me problems.\n", "comments": ["Need 0.9 for the `conv3d` support\n", "I believe it's named 0.8 but it should have conv3d.  We haven't merged the version number changes from r0.9 back into master.  @caisq @martinwicke \n", "Awesome, will check.  Would not have guessed that at all.\n", "Closing.  Hope this helps others.  That threw me for a loop.\n", "I think we should probably keep this open until we fix the issue\n", "I merged 0.9 into master earlier today.\n"]}, {"number": 3115, "title": "initializer option for all RNNCell's", "body": "RNN's are very sensitive to the initial weight settings, but only the LSTMCell allows the user to specify an initializer. Could we add similar initializer options for all cells?\n\nMore control would be particularly helpful for implementing ReLU RNN's (http://arxiv.org/abs/1504.00941), where the hidden-to-hidden weight matrix should be initialized to the identity matrix.\n", "comments": ["Most cells in core use a merged weight matrix for all gates for performance purposes, making gate specific initialization difficult.  If you have an approach that doesn't involve breaking up the weights into 4 smaller tensors, we should consider it for merging.\n", "I don't think the issue that @davek44 is raising is gate-specific initialization, but rather just initialization period. LSTMCell allows the user to pass an initializer (used for all gates), but the other types of cells do not (e.g. GRUs).\n", "Yes, initializers for all different types of cells (like LSTMCell already has) is an important first step.\n\n@ebrevdo, I see the challenge in trading off flexibility for complexity in initializing different matrices. Are you saying it's also a programming challenge? I imagined it was straightforward to initialize the matrices separately and combine them into the merged version.\n", "Performing a concat & then a split of the gradients will still slow down calculation, so I would not modify existing RNNCells with this behavior.  LSTMCell provides the ability to initialize the shared matrix, not individual gate weights.\n", "In addition, that initialization option is deprecated, since you can just use tf.variable_scope with a proper initializer (which is what LSTMCell does under the hood).  that parameter will probably go away soonish.\n", "@davek44 probably the easiest approach to initializing parts of the LSTM matrix differently is to separately construct the desired matrices, concatenate them, and then assign their value to the LSTM matrix using assign.\n", "Thanks for the suggestion @alquraishi! I'm most interested in Geoff Hinton's identity initialization of the hidden-hidden weight matrix of the BasicRNNCell. It sounds like the codebase doesn't want to move in the initialization direction that I imagined, so I'll explore ad hoc methods to get it done. Thanks for the feedback @ebrevdo \n", "@davek44 Did you get any further with your exploration? I am very much interested in the identity initialization for just the RNN hidden-hidden weights. \n", "I did not, but the new CuDNN RNN code appears to have a ReLU RNN that I've been meaning to try. Check it out here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cudnn_rnn\n", "Thanks for the info! I looked that up, but couldn't find gen_cudnn_rnn_ops.py meaning I can't tell how this is different than any RNNCell with activation = tf.nn.relu. Thoughts? \n", "The CuDNN RNN code is quite different from the previous Cell-centric framework. I haven't spent much time with it, but you have to pass in your own parameter tensor, which makes it easy to initialize with the identity.\n", "There are other changes happening to rnncells right now, adding initializer\narguments will have to wait a while anyway.  If someone is working on this\nplease sync with me first.\n\nOn Nov 16, 2016 2:45 PM, \"David Kelley\" notifications@github.com wrote:\n\n> The CuDNN RNN code is quite different from the previous Cell-centric\n> framework. I haven't spent much time with it, but you have to pass in your\n> own parameter tensor, which makes it easy to initialize with the identity.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3115#issuecomment-261097103,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtimy1ZiZk4KE4IJsjoWMn4RH-C75yMks5q-4d6gaJpZM4JBpll\n> .\n", "hello, what is the current status for Api 1.2? Can please provide anyone an example how to assign weights to RNN or LSTM cells? with tf.assign? how does that work?\r\n\r\nI think these are the current names for  tf.Variables in an basic_rnn_cell with tf.variable_scope('RNN'):\r\n\r\n```\r\ntf.Variable 'RNN/rnn/basic_rnn_cell/kernel:0'\r\ntf.Variable 'RNN/rnn/basic_rnn_cell/bias:0'\r\n```\r\n\r\nconcenated example is enough at first, but it will be also nice,  if tensorflow let us know in what way the 4 weights for inputs and 4 weights for the hiddenstates (input, ouput, forget, internal cell gate) are arranged? (Kind of tedious to figure it out all by myself by always programming in parallel a pure numpy example)", "Hello, I am also wondering if there are any updates for this? I am currently trying to deal with transfer learning for LSTMCell. I would like to initialize the weights of the LSTMCell with my pretrained model weights. However, I am not very sure how should I approached this problem.", "Write a new cell, modify call to _Linear() with your trained weights inside your new cell's cell() call..", "@davek44 I am trying to initialize the cell with a constant initializer but it is giving en error. The code which I'm using is -  \r\nf = [np.random.normal(size = [15, 40]), np.random.normal(size = [40,])]\r\ninit = tf.constant_initializer(f, verify_shape = True, dtype = tf.float32)\r\n\r\ncell = tf.contrib.rnn.LSTMCell(lstm_units, initializer = init)\r\ninitial_state = cell.zero_state(2, dtype = tf.float32)\r\nunused_encoder_outputs, encoder_state =tf.nn.dynamic_rnn(cell ,source_seq_embedded,sequence_length=source_seq_len,dtype = tf.float32, initial_state = initial_state)\r\n\r\nIt is giving error - \r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-2-445bac49bd02> in <module>()\r\n     29 initial_state = cell.zero_state(2, dtype = tf.float32)\r\n     30 unused_encoder_outputs, encoder_state =tf.nn.dynamic_rnn(cell ,source_seq_embedded,sequence_length=source_seq_len,\r\n---> 31                                                         dtype = tf.float32, initial_state = initial_state)\r\n     32 \r\n     33 sampling_prob = tf.Variable(0.0, dtype=tf.float32)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py in dynamic_rnn(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\r\n    625         swap_memory=swap_memory,\r\n    626         sequence_length=sequence_length,\r\n--> 627         dtype=dtype)\r\n    628 \r\n    629     # Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py in _dynamic_rnn_loop(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\r\n    822       parallel_iterations=parallel_iterations,\r\n    823       maximum_iterations=time_steps,\r\n--> 824       swap_memory=swap_memory)\r\n    825 \r\n    826   # Unpack final output if not using output tuples.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)\r\n   3222     if loop_context.outer_context is None:\r\n   3223       ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)\r\n-> 3224     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n   3225     if maximum_iterations is not None:\r\n   3226       return result[1]\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)\r\n   2954       with ops.get_default_graph()._lock:  # pylint: disable=protected-access\r\n   2955         original_body_result, exit_vars = self._BuildLoop(\r\n-> 2956             pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2957     finally:\r\n   2958       self.Exit()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2891         flat_sequence=vars_for_body_with_tensor_arrays)\r\n   2892     pre_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\r\n-> 2893     body_result = body(*packed_vars_for_body)\r\n   2894     post_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\r\n   2895     if not nest.is_sequence(body_result):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py in <lambda>(i, lv)\r\n   3192         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\r\n   3193             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\r\n-> 3194         body = lambda i, lv: (i + 1, orig_body(*lv))\r\n   3195 \r\n   3196     if context.executing_eagerly():\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py in _time_step(time, output_ta_t, state)\r\n    791           call_cell=call_cell,\r\n    792           state_size=state_size,\r\n--> 793           skip_conditionals=True)\r\n    794     else:\r\n    795       (output, new_state) = call_cell()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py in _rnn_step(time, sequence_length, min_sequence_length, max_sequence_length, zero_output, state, call_cell, state_size, skip_conditionals)\r\n    246     # steps.  This is faster when max_seq_len is equal to the number of unrolls\r\n    247     # (which is typical for dynamic_rnn).\r\n--> 248     new_output, new_state = call_cell()\r\n    249     nest.assert_same_structure(state, new_state)\r\n    250     new_state = nest.flatten(new_state)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py in <lambda>()\r\n    779 \r\n    780     input_t = nest.pack_sequence_as(structure=inputs, flat_sequence=input_t)\r\n--> 781     call_cell = lambda: cell(input_t, state)\r\n    782 \r\n    783     if sequence_length is not None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py in __call__(self, inputs, state, scope, *args, **kwargs)\r\n    337     # method.  See the class docstring for more details.\r\n    338     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\r\n--> 339                                      *args, **kwargs)\r\n    340 \r\n    341 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\r\n    697           if all(hasattr(x, 'get_shape') for x in input_list):\r\n    698             input_shapes = nest.map_structure(lambda x: x.get_shape(), inputs)\r\n--> 699           self.build(input_shapes)\r\n    700         try:\r\n    701           # Note: not all sub-classes of Layer call Layer.__init__ (especially\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py in build(self, inputs_shape)\r\n    765         shape=[input_depth + h_depth, 4 * self._num_units],\r\n    766         initializer=self._initializer,\r\n--> 767         partitioner=maybe_partitioner)\r\n    768     self._bias = self.add_variable(\r\n    769         _BIAS_VARIABLE_NAME,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in add_variable(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)\r\n    544             constraint=constraint,\r\n    545             trainable=trainable and self.trainable,\r\n--> 546             partitioner=partitioner)\r\n    547 \r\n    548         if init_graph is not None:  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\r\n    434     new_variable = getter(\r\n    435         name=name, shape=shape, dtype=dtype, initializer=initializer,\r\n--> 436         **kwargs_for_getter)\r\n    437 \r\n    438     # If we set an initializer and the variable processed it, tracking will not\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\r\n   1315       partitioner=partitioner, validate_shape=validate_shape,\r\n   1316       use_resource=use_resource, custom_getter=custom_getter,\r\n-> 1317       constraint=constraint)\r\n   1318 get_variable_or_local_docstring = (\r\n   1319     \"\"\"%s\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\r\n   1077           partitioner=partitioner, validate_shape=validate_shape,\r\n   1078           use_resource=use_resource, custom_getter=custom_getter,\r\n-> 1079           constraint=constraint)\r\n   1080 \r\n   1081   def _get_partitioned_variable(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\r\n    423           caching_device=caching_device, partitioner=partitioner,\r\n    424           validate_shape=validate_shape, use_resource=use_resource,\r\n--> 425           constraint=constraint)\r\n    426 \r\n    427   def _get_partitioned_variable(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\r\n    392           trainable=trainable, collections=collections,\r\n    393           caching_device=caching_device, validate_shape=validate_shape,\r\n--> 394           use_resource=use_resource, constraint=constraint)\r\n    395 \r\n    396     if custom_getter is not None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\r\n    784         validate_shape=validate_shape,\r\n    785         constraint=constraint,\r\n--> 786         use_resource=use_resource)\r\n    787     if not context.executing_eagerly() or self._store_eager_variables:\r\n    788       # In eager mode we do not want to keep default references to Variable\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in variable(initial_value, trainable, collections, validate_shape, caching_device, name, dtype, constraint, use_resource)\r\n   2218                          name=name, dtype=dtype,\r\n   2219                          constraint=constraint,\r\n-> 2220                          use_resource=use_resource)\r\n   2221 \r\n   2222 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in <lambda>(**kwargs)\r\n   2208              constraint=None,\r\n   2209              use_resource=None):\r\n-> 2210   previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n   2211   for getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n   2212     previous_getter = _make_getter(getter, previous_getter)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)\r\n   2191         collections=collections, validate_shape=validate_shape,\r\n   2192         caching_device=caching_device, name=name, dtype=dtype,\r\n-> 2193         constraint=constraint)\r\n   2194 \r\n   2195 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\r\n    233           dtype=dtype,\r\n    234           expected_shape=expected_shape,\r\n--> 235           constraint=constraint)\r\n    236 \r\n    237   def __repr__(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\r\n    341             with ops.name_scope(\"Initializer\"), ops.device(None):\r\n    342               self._initial_value = ops.convert_to_tensor(\r\n--> 343                   initial_value(), name=\"initial_value\", dtype=dtype)\r\n    344               shape = (self._initial_value.get_shape()\r\n    345                        if validate_shape else tensor_shape.unknown_shape())\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in <lambda>()\r\n    768           initializer = initializer(dtype=dtype)\r\n    769         init_val = lambda: initializer(  # pylint: disable=g-long-lambda\r\n--> 770             shape.as_list(), dtype=dtype, partition_info=partition_info)\r\n    771         variable_dtype = dtype.base_dtype\r\n    772 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py in __call__(self, shape, dtype, partition_info, verify_shape)\r\n    215       verify_shape = self._verify_shape\r\n    216     return constant_op.constant(\r\n--> 217         self.value, dtype=dtype, shape=shape, verify_shape=verify_shape)\r\n    218 \r\n    219   def get_config(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name, verify_shape)\r\n    212   tensor_value.tensor.CopyFrom(\r\n    213       tensor_util.make_tensor_proto(\r\n--> 214           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n    215   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)\r\n    216   const_tensor = g.create_op(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape)\r\n    430       nparray = np.empty(shape, dtype=np_dt)\r\n    431     else:\r\n--> 432       _AssertCompatible(values, dtype)\r\n    433       nparray = np.array(values, dtype=np_dt)\r\n    434       # check to them.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py in _AssertCompatible(values, dtype)\r\n    341     else:\r\n    342       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\r\n--> 343                       (dtype.name, repr(mismatch), type(mismatch).__name__))\r\n    344 \r\n    345 \r\n\r\nTypeError: Expected float32, got array([[ 1.04484751e+00,  4.59392878e-02,  8.02706034e-01,\r\n        -1.11174105e+00,  8.89477561e-01, -1.20486729e+00,\r\n         8.86266342e-01, -1.64510319e+00, -9.89266584e-01,\r\n         1.31369015e+00,  4.88107334e-01,  1.49676477e-01,\r\n        -6.81036506e-01, -9.64134982e-02, -1.39690939e+00,\r\n         7.25600555e-02, -9.32924292e-02, -7.95291205e-01,\r\n         2.18235671e-01,  1.01727717e+00,  9.90535181e-01,\r\n        -4.35980568e-01,  7.94711686e-01, -3.13013630e-02,\r\n        -7.20243003e-01, -1.37384000e+00, -9.62151398e-01,\r\n         1.07646743e+00,  4.69513293e-01, -4.47742163e-02,\r\n        -4.95195536e-01,  6.76953787e-01,  2.39035230e-01,\r\n        -1.11104812e-01,  2.05507744e+00,  9.33967217e-01,\r\n        -8.96051458e-01, -8.77908566e-02,  1.43848201e+00,\r\n        -1.04624360e+00],\r\n       [-3.41335190e-01,  1.40035909e+00, -1.60449447e-01,\r\n        -9.41774525e-01,  1.81853256e+00, -2.20882493e-01,\r\n         3.01935183e+00, -6.22724692e-01,  6.57625596e-01,\r\n         3.85760589e-01,  1.25143595e+00,  3.95787835e-01,\r\n        -1.15711379e-01,  1.04277452e+00,  1.18388115e-01,\r\n        -2.67029800e+00,  4.53791661e-01,  1.21855412e+00,\r\n         1.35663694e+00,  1.11392313e+00, -6.14336793e-01,\r\n         2.90739971e-01,  1.37860208e+00,  2.52123588e+00,\r\n        -8.47994930e-01, -1.57757604e-01, -3.22334965e-01,\r\n        -5.11127934e-01,  1.17326724e+00, -1.33463413e-01,\r\n         1.53402616e+00,  9.27541940e-01, -1.65259834e+00,\r\n         1.52193955e+00, -7.02834497e-01,  1.30055130e+00,\r\n        -1.27054858e+00,  1.93102289e+00,  4.90642813e-01,\r\n         1.05364636e+00],\r\n       [-2.82434425e-01,  4.84068350e-01, -1.54210849e+00,\r\n         2.17935455e+00, -1.33159023e+00,  9.24332614e-01,\r\n        -5.04315970e-01,  9.85161964e-01,  8.72890896e-01,\r\n         9.33685162e-01,  2.29173759e-01,  1.80474211e+00,\r\n         7.72485270e-01,  1.11224300e-01, -7.35284649e-01,\r\n         1.22797144e-01,  2.49131972e-02, -8.82123778e-01,\r\n         1.05901313e+00, -3.91695444e-01,  1.52364293e+00,\r\n        -2.02547241e+00, -1.11905764e+00, -1.39702563e-01,\r\n         6.00853245e-01,  1.06457879e+00,  7.23094038e-01,\r\n         2.30281455e-01,  2.85937688e-02,  1.88589155e-02,\r\n         6.45507430e-01, -5.51370987e-02, -1.68287628e+00,\r\n        -3.59386792e-01,  2.64980652e-01, -4.73594067e-01,\r\n        -1.16968518e+00,  6.28055865e-01,  2.84448999e+00,\r\n        -8.13157852e-01],\r\n       [-1.31717291e-01,  1.02786130e+00,  1.53418718e-01,\r\n        -1.97088279e-01,  1.25098576e+00, -3.64066728e-01,\r\n        -1.31257463e-01,  1.64076530e+00, -2.15908745e+00,\r\n        -6.22189979e-01, -2.53163951e-02,  1.44229587e+00,\r\n         1.42744437e+00,  1.17886987e+00, -1.37219218e+00,\r\n         1.95677402e+00,  1.25885663e-01, -1.74788095e-01,\r\n         1.49759607e+00,  1.69086673e+00,  1.70750645e+00,\r\n         8.23124033e-03, -6.57806464e-01, -6.86276358e-01,\r\n         2.76553853e-01, -5.89633972e-01,  4.83433320e-01,\r\n        -4.78963168e-01,  1.57649031e+00, -8.97853620e-01,\r\n         1.12044567e-01, -6.14123732e-01, -2.61661823e-01,\r\n         1.08654068e+00, -2.13519684e+00, -2.20165083e+00,\r\n        -1.79124609e+00,  1.66096352e+00,  1.01991370e+00,\r\n        -6.31529272e-01],\r\n       [-9.41644716e-01, -8.22052119e-02, -7.82717117e-01,\r\n         4.66941465e-01, -3.41506828e-01,  2.85859511e-01,\r\n        -5.39347861e-01,  4.83069925e-01, -1.96077011e+00,\r\n        -1.79893071e+00,  4.02349515e-01,  2.19665512e-01,\r\n         4.81469059e-01, -9.67396064e-01,  1.28371488e+00,\r\n         1.74737441e-01, -1.42200749e+00, -1.02551183e+00,\r\n         9.19474529e-01,  1.10227219e+00,  2.39780104e-01,\r\n         1.54564488e+00,  5.48480031e-01,  2.53774766e-01,\r\n        -1.05690541e+00,  2.04109323e+00, -8.91820616e-01,\r\n        -9.67841805e-01,  6.84840673e-02, -2.64095272e+00,\r\n        -9.63133723e-01,  1.27685637e+00,  6.88337275e-01,\r\n         2.05600684e+00, -1.62778234e+00, -3.23933044e-01,\r\n        -3.16615539e-01, -6.67369617e-01, -1.15297191e+00,\r\n        -5.91319319e-01],\r\n       [ 1.91052422e+00,  6.33272998e-01,  8.26497424e-01,\r\n         6.03023598e-01,  3.92400071e-01,  9.29020785e-01,\r\n        -6.88585491e-01,  9.77940308e-01, -1.26848693e+00,\r\n         9.94840201e-02,  7.52848243e-01, -3.04239973e-01,\r\n         3.67167359e-01,  5.69559156e-01, -6.36591114e-01,\r\n         1.11083130e+00, -8.39891783e-01,  4.10057372e-01,\r\n        -1.38307188e-01,  3.90518293e-01, -5.50275734e-01,\r\n        -8.79075363e-01, -1.66958109e-01,  6.56225679e-01,\r\n         1.95612624e+00, -4.45663548e-01, -1.09293024e-01,\r\n        -2.01618327e+00,  4.58819223e-01,  9.22194083e-01,\r\n         9.95847584e-01,  5.23072609e-02,  1.24794740e+00,\r\n        -4.53764894e-02,  2.95947625e-01, -7.41021448e-01,\r\n         2.50512089e+00,  9.61431201e-01,  1.69506349e+00,\r\n         6.95733555e-01],\r\n       [ 1.16595131e+00, -9.16556527e-01,  1.58695646e+00,\r\n         1.53449732e-01,  1.17051377e-01, -4.14580879e-01,\r\n        -5.97632083e-01, -9.09788623e-02,  2.06036713e-01,\r\n        -1.68144113e+00, -1.44447690e+00,  6.33471999e-01,\r\n         1.67047115e+00,  1.32731338e+00, -1.04672470e+00,\r\n         4.54657832e-01, -2.23668935e-01,  6.40420094e-01,\r\n        -2.76215451e-01,  1.29460409e+00, -1.38940318e-01,\r\n        -1.04813960e+00, -1.47631494e+00,  4.58803440e-01,\r\n         5.98103656e-01, -6.04906161e-01, -5.70246924e-02,\r\n         1.42080757e+00, -1.97360377e+00, -7.95265695e-01,\r\n         2.94820707e-01, -4.83390366e-01,  4.50911220e-01,\r\n         8.74186348e-01, -5.99966992e-01, -1.21949591e-01,\r\n        -2.52309447e-01,  1.53064407e+00,  3.72279673e-01,\r\n         1.07315179e+00],\r\n       [ 8.86889539e-01,  1.16549545e-01,  1.38816289e+00,\r\n         1.01371089e+00, -1.44051110e+00, -3.53644010e-01,\r\n        -3.65782677e-01,  6.13860886e-02, -3.14833634e-01,\r\n         2.59271600e+00,  8.16096390e-01,  1.50172499e-01,\r\n         5.30068573e-01, -7.30386914e-01, -2.03084764e-01,\r\n        -6.74878994e-01,  9.66930750e-02,  7.21899634e-01,\r\n        -1.99889298e-01,  1.64892187e-02, -1.19705017e+00,\r\n        -1.59441455e+00,  6.20422424e-01, -2.18686254e-01,\r\n         1.12343324e+00,  1.86378524e+00, -1.83527953e-01,\r\n        -1.00652180e+00, -1.65150954e-01,  4.72737655e-02,\r\n         4.04227537e-01,  7.75649967e-01, -1.67503021e+00,\r\n         1.58444824e+00, -5.54640787e-01, -9.06882661e-01,\r\n        -8.85061481e-01, -2.57646814e-01, -1.58392420e-01,\r\n        -8.72515024e-01],\r\n       [ 2.30347997e-01,  2.93106723e+00,  2.32079761e+00,\r\n         1.05747984e-02,  6.43344453e-01,  1.48450845e+00,\r\n        -1.32288375e+00, -3.35875203e-02, -1.53430836e-01,\r\n         1.13107152e+00,  2.71825618e-01, -1.70896982e+00,\r\n         6.73988768e-01, -1.52623124e+00,  8.51444615e-01,\r\n         9.58495328e-01,  1.13117333e+00,  1.57066734e-01,\r\n        -2.49850210e-01, -3.57635309e-01,  6.84622356e-01,\r\n         2.02666474e-01, -7.12002046e-01,  1.24946477e-02,\r\n         5.75374743e-01,  1.93356031e-01, -1.29900584e+00,\r\n         5.04674883e-02,  1.22158010e+00,  1.63139677e+00,\r\n        -2.49405615e-01,  1.82925921e+00,  3.54699037e-01,\r\n         9.97620566e-01,  9.85580452e-02,  1.11274364e-01,\r\n        -6.00244704e-01, -1.95023124e-01,  2.00273727e-01,\r\n         1.83794424e+00],\r\n       [ 7.09088942e-01, -1.04879043e+00, -5.74103670e-01,\r\n         7.43992315e-01,  1.52200161e+00, -2.03207326e+00,\r\n         2.11875292e-01,  1.04272441e+00, -1.26958291e+00,\r\n         2.70366571e-01, -2.19008125e-01,  1.40483006e+00,\r\n        -2.09482711e-01, -9.20875207e-01,  1.72865711e+00,\r\n        -2.64627344e-01,  3.47781018e-01,  4.81586537e-01,\r\n         1.07322305e+00, -8.17717513e-01,  1.28391605e+00,\r\n         1.97842517e-01,  1.72612806e+00,  2.13807753e-01,\r\n         1.03357557e+00,  5.84119555e-01, -8.61174988e-01,\r\n        -1.17678694e+00,  1.92928507e+00,  5.60831434e-01,\r\n         3.31615685e-01,  6.15759349e-02, -9.18765403e-02,\r\n        -1.25591199e+00, -1.69617993e+00, -1.04056449e-03,\r\n        -1.02922137e-01, -6.70639273e-01,  1.16609151e-01,\r\n         1.10320101e+00],\r\n       [ 3.14600442e-01, -4.65363105e-01,  1.67887551e+00,\r\n        -6.92450808e-01,  3.14357667e-01,  1.32540623e-01,\r\n         9.15669217e-01, -1.39204004e+00,  7.20252339e-01,\r\n         5.94095417e-01, -8.18707441e-02,  5.91751351e-01,\r\n        -6.68691321e-01,  4.96172554e-01,  5.29582332e-01,\r\n        -1.55275307e-01,  2.46515467e-02,  6.03194472e-01,\r\n         1.31759695e+00,  5.45525211e-01, -2.30398220e-02,\r\n         8.12616540e-01, -2.61076466e-01,  1.66934365e+00,\r\n        -8.31025772e-01, -2.00446090e-01,  2.91231454e-01,\r\n         7.98223470e-01, -9.60227710e-01,  1.90107485e+00,\r\n        -7.44250114e-01, -7.20353857e-01,  1.32092989e-01,\r\n         8.44143593e-01,  5.01753704e-01, -2.05186337e-02,\r\n         1.13485011e+00, -1.06831952e-01,  2.44283342e-01,\r\n        -2.09994058e+00],\r\n       [-6.29958586e-01,  5.63142982e-01, -3.90122789e-01,\r\n         1.63745415e+00,  6.94110430e-01,  8.22926404e-02,\r\n         1.95863036e-01, -1.38925172e-01,  2.25575648e-01,\r\n         8.12663637e-01,  2.17542039e-01, -4.50958688e-01,\r\n        -1.01270050e+00,  3.51468797e-01, -1.67982586e+00,\r\n         1.07461121e+00,  6.99860539e-01,  4.94039591e-01,\r\n        -5.90147661e-01, -1.83109452e+00,  1.03962324e+00,\r\n         1.15843905e+00, -3.49911595e-01,  7.62128043e-01,\r\n        -1.67721454e+00,  3.76573218e-01, -7.48380931e-01,\r\n        -1.00878241e+00,  1.25593116e+00,  1.18679312e+00,\r\n        -1.05711288e+00, -4.00083667e-01, -1.10232880e+00,\r\n         1.21308371e+00, -4.47723244e-01, -2.68600107e-01,\r\n         1.26868008e+00,  8.23863001e-01,  5.47930794e-01,\r\n         2.77146607e-01],\r\n       [ 8.58208487e-02,  1.56905645e+00,  1.82461216e+00,\r\n        -1.95056238e+00,  8.84093358e-01, -2.30546309e-01,\r\n         1.68715760e+00,  1.51402049e+00,  1.97083952e+00,\r\n         3.47050464e-01,  2.45418091e+00, -1.28676786e+00,\r\n        -3.13972072e-02, -9.15640304e-02, -6.08760602e-01,\r\n         6.27315932e-01,  2.99423764e-01,  1.47387084e+00,\r\n        -2.22367289e-01,  1.36963199e+00, -1.03270696e+00,\r\n         5.07323436e-01,  1.03998597e+00,  7.48829007e-01,\r\n         5.56559176e-01,  8.65196651e-01, -9.69346627e-01,\r\n        -3.61670544e-02,  9.58567659e-01, -3.05810054e-01,\r\n         1.57696086e+00,  6.16235833e-01, -1.05029472e+00,\r\n         4.44189207e-01, -2.39608656e+00,  5.52516728e-01,\r\n         1.41880306e+00,  8.11277537e-01,  4.57157626e-01,\r\n        -3.63861533e-01],\r\n       [-5.50649441e-01,  6.17569991e-01, -6.07970309e-01,\r\n         4.38174300e-01, -1.35517086e+00,  2.25004668e-02,\r\n        -3.37577140e-02,  1.06195204e-01,  1.28345880e+00,\r\n        -3.46079223e-01, -1.53264926e-01,  1.22802991e+00,\r\n         1.22813763e-01,  2.24233889e+00, -5.45865371e-01,\r\n        -6.42548620e-01, -5.81109641e-01, -9.70743156e-01,\r\n        -1.80179925e+00, -1.11872377e+00, -2.22970191e+00,\r\n         4.94857288e-01, -5.86297124e-01, -6.56848913e-01,\r\n        -1.17092937e-03, -7.39394009e-01,  1.19986436e+00,\r\n         3.96717450e-01, -1.24115664e-01,  1.00324288e+00,\r\n        -1.14458800e-01, -2.25008521e+00,  5.45973540e-01,\r\n         2.37025750e-01, -1.14356885e+00, -4.88471919e-01,\r\n        -1.13206828e+00, -1.62136190e+00,  1.23749918e-01,\r\n         3.08363831e-01],\r\n       [-2.36785516e+00,  1.93758109e-01,  9.52158319e-01,\r\n         1.74236299e-01, -1.37006190e+00, -3.20627648e-01,\r\n         2.16886312e+00, -8.07024449e-01, -9.12120118e-01,\r\n        -2.45296765e+00,  1.09160450e+00, -1.00823007e+00,\r\n        -1.08279055e-01, -3.37003362e-01,  8.89784314e-01,\r\n         4.28913333e-01, -1.31532876e+00,  1.99979263e-01,\r\n        -2.95699114e-01, -1.07325068e+00, -7.65415033e-01,\r\n        -7.57991272e-01,  1.58699077e+00, -6.27470343e-01,\r\n         4.39592393e-01,  1.19306894e+00, -1.41762289e+00,\r\n        -1.92094209e-01,  4.98275997e-01,  4.75333804e-01,\r\n         2.42416125e-01,  3.97092492e-02,  2.18313764e-01,\r\n         9.20630155e-01,  1.32786770e-01,  1.07811778e+00,\r\n        -1.56297503e-01,  1.84818124e-01,  6.83802272e-01,\r\n        -1.76218224e+00]]) of type 'ndarray' instead.\r\n\r\nCan anybody tell why this error is coming, the size of numpy arrays are correct."]}, {"number": 3114, "title": "Backpropagation through the while-loop doesn't work if external tensors are used inside", "body": "In the simple example below I copy `inputs` to `outputs` in a while loop. When I try to take gradient of the `outputs` w.r. to `inputs`, I get an error. It's worth noting that 1) the forward pass works 2) the gradient computation works if I made `inputs` a `TensorArray`, like it is done in the [scan implementation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/functional_ops.py#L289)\n\nThe code:\n\n``` python\nwith tf.Graph().as_default(), tf.Session() as sess:\n  num_steps = 9\n\n  inputs = tf.placeholder(dtype='float32', shape=(num_steps))\n  initial_outputs = tf.TensorArray(dtype=tf.float32, size=num_steps)\n  initial_i = tf.constant(0, dtype='int32')\n\n  def should_continue(i, *args):\n    return i < num_steps\n\n  def iteration(i, outputs_):\n    outputs_ = outputs_.write(i, tf.gather(inputs, i))\n    return i + 1, outputs_\n\n  i, outputs = tf.while_loop(\n    should_continue, iteration,\n    [initial_i, initial_outputs])\n\n  outputs = outputs.pack()\n  grad_wr_inputs = tf.convert_to_tensor(tf.gradients([tf.reduce_sum(outputs)], [inputs])[0])\n  print sess.run([outputs, grad_wr_inputs],\n                 feed_dict={inputs: [4, 6, 0, 7, 0, 0, 1, 2, 0]})\n```\n\nThe stack trace:\n\n```\n---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n<ipython-input-354-e1d117e742f9> in <module>()\n     20   grad_wr_inputs = tf.convert_to_tensor(tf.gradients([tf.reduce_sum(outputs)], [inputs])[0])\n     21   print sess.run([outputs, grad_wr_inputs],\n---> 22                  feed_dict={inputs: [4, 6, 0, 7, 0, 0, 1, 2, 0]})\n\n/google/data/ro/teams/colab/tensorflow/google3/third_party/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    366     try:\n    367       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 368                          run_metadata_ptr)\n    369       if run_metadata:\n    370         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/google/data/ro/teams/colab/tensorflow/google3/third_party/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    639     movers = self._update_with_movers(feed_dict_string, feed_map)\n    640     results = self._do_run(handle, target_list, unique_fetches,\n--> 641                            feed_dict_string, options, run_metadata)\n    642 \n    643     # User may have fetched the same tensor multiple times, but we\n\n/google/data/ro/teams/colab/tensorflow/google3/third_party/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n    707     if handle is None:\n    708       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n--> 709                            target_list, options, run_metadata)\n    710     else:\n    711       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/google/data/ro/teams/colab/tensorflow/google3/third_party/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n    727         except KeyError:\n    728           pass\n--> 729       raise type(e)(node_def, op, message)\n    730 \n    731   def _extend_graph(self):\n\nInvalidArgumentError: All inputs to node Slice must be from the same frame.\n```\n", "comments": ["This is a bug in the handling of IndexedSlices in while loop.  We seemed to handle the shape tensor incorrectly.  I need to talk to others about how the shape tensor should be updated within the loop. We should have a fix soon.\n", "Can you confirm this has been fixed at head?\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n", "I get the same error at head when using a dynamic rnn:\n\n`InvalidArgumentError: All inputs to node gradients/while_2/strided_slice_2_grad/StridedSliceGrad/StackPush must be from the same frame.`\n\nSo gradient computation does not work if you use slicing inside a while_loop?\n", "Are you using a nightly build? If not, try it\n", "Have you tried a nightly build?\n\nOn Sep 11, 2016 2:54 AM, \"3rd3\" notifications@github.com wrote:\n\n> I'm getting the same error upon what seems to be the Assignment operation\n> in the initial variable initialization of a variable inside a tf.scan. I'm\n> using the latest official build from the TensorFlow website. Any idea?\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3114#issuecomment-246171778,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim4Rn_-z6AXEXmaVqKUFuHsiqIjklks5qo8_NgaJpZM4JBoiG\n> .\n", "I have this error with scan too, on nightly build (version is 0.10.0)\nI.e.\n\n```\nInvalidArgumentError                      Traceback (most recent call last)\n<ipython-input-10-dc172f44e124> in <module>()\n      1 with tf.Session() as sess:\n----> 2     sess.run(init)\n      3 \n      4     # Training cycle\n      5     for epoch in range(training_epochs):\n\n/Users/link_er/miniconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    715     try:\n    716       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 717                          run_metadata_ptr)\n    718       if run_metadata:\n    719         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/Users/link_er/miniconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    913     if final_fetches or final_targets:\n    914       results = self._do_run(handle, final_targets, final_fetches,\n--> 915                              feed_dict_string, options, run_metadata)\n    916     else:\n    917       results = []\n\n/Users/link_er/miniconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n    963     if handle is None:\n    964       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n--> 965                            target_list, options, run_metadata)\n    966     else:\n    967       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/Users/link_er/miniconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\n    983         except KeyError:\n    984           pass\n--> 985       raise type(e)(node_def, op, message)\n    986 \n    987   def _extend_graph(self):\n\nInvalidArgumentError: All inputs to node scan_1/while/Variable_1/Assign must be from the same frame.\n```\n", "I am getting the exact same error for a similar model (also on v0.10.0, and now v0.11.0rc0). Given that some time has passed since the last post, I'd be curious whether any of you have found a solution or workaround to this issue and would be willing to share.\n", "@Fr-d-rik hi!\nThe way that I was able to found - remove Variable initialization from the scan step. I do not know is this a case for you, but I had something like\n\n```\nvar = tf.Variable(...)\n```\n\ninside the step. Once I removed it outside the step, by announcing earlier and just accessing inside, error disappeared.\nHope it can help you \n", "It's common to access an external variable inside a while_loop.  For\nexample, RNN code does this all the time via tf.get_variable().  How are\nyou creating a variable?  Directly with tf.Variable?\n\nOn Tue, Oct 4, 2016 at 5:11 AM, Linara Adilova notifications@github.com\nwrote:\n\n> @Fr-d-rik https://github.com/Fr-d-rik hi!\n> The way that I was able to found - remove Variable initialization from the\n> scan step. I do not know is this a case for you, but I had something like\n> \n> var = tf.Variable(...)\n> \n> inside the step. Once I removed it outside the step, by announcing earlier\n> and just accessing inside, error disappeared.\n> Hope it can help you\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3114#issuecomment-251370465,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim86IkqYVHUQqx95B1vY_N2VUkSftks5qwkKGgaJpZM4JBoiG\n> .\n", "Yes, I was doing it like this before and then I changed it to get_variable, that fixed the error\nBut still maybe the error message can be a little bit changed, because it is really hard to get what is causing it\n", "Can you create a new issue, appropriately named, with a small code snippet and the full error trace?   This bug is closed.\n", "@ebrevdo actually it is already there, https://github.com/tensorflow/tensorflow/issues/4478\n", "Sweet! Thanks a lot! I made the variables on the first iteration of the while loop and accessed them from then on. I guess moving that bit out of the loop should fix my problem then... - yup! That did it.\n", "@fchollet I also get the same error when using dynamic_rnn, have you ever solved this problem?\n\nHere's my snippet\n\n``` python\nimport numpy as np\nimport tensorflow as tf\nimport tflearn\n\ndef retrieve_sequence_length(data):\n    with tf.name_scope('sequence_length'):\n        used = tf.sign(tf.abs(data))\n        length = tf.cast(tf.reduce_sum(used, reduction_indices=[1, 2]), tf.int32)\n    return length \n\ndef loss(x, y, sequence_length):\n    with tf.name_scope('loss'):\n        n_states = x.get_shape()[-1].value\n        transition_params = tflearn.variable(name='transition_params', shape=[n_states, n_states], \n                                             initializer='xavier', dtype=tf.float32)\n        loss = tf.contrib.crf.crf_log_norm(x, sequence_length, transition_params)\n        # loss, _ = tf.contrib.crf.crf_log_likelihood(x, y, sequence_length, transition_params)\n    return tf.reduce_mean(loss)\n\n# Data settings.\nnum_examples = 10000\nnum_words = 20\nnum_features = 100\nnum_tags = 5\n\n# Random features.\nx = np.random.uniform(low=0.1, high=1.1, size=(num_examples, num_words, num_features)).astype(np.float32)\n\n# Random tag indices representing the gold sequence.\ny = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)\n\n# All sequences in this example have the same length, but they can be variable in a real model.\n# sequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)\n\n\ninput0 = tflearn.input_data(shape=[None, num_words, num_features], dtype=tf.float32)\nsequence_length = retrieve_sequence_length(input0)\nprint 'sequence_length: ', sequence_length\n\nunary_scores = tflearn.time_distributed(input0, tflearn.fully_connected, [num_tags, 'softmax'])\nprint 'unary_score: ', unary_scores\n\nnet = tflearn.regression(unary_scores,\n                         placeholder=tf.placeholder(shape=[None, num_words], dtype=tf.int32),\n                         learning_rate=0.001,\n                         optimizer='sgd',\n                         loss=lambda x, y: loss(x, y, sequence_length),\n                         metric=None,\n                         n_classes=num_tags,\n                         to_one_hot=False)\n\nmodel = tflearn.DNN(net)\n\nmodel.fit(x, y, batch_size=32)\n```\n\nthe stacktrace of the error:\n\n```\n--\nTraceback (most recent call last):\n  File \"c.py\", line 54, in <module>\n    model.fit(x, y, batch_size=32)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/models/dnn.py\", line 214, in fit\n    callbacks=callbacks)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 304, in fit\n    show_metric)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 762, in _train\n    feed_batch)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: All inputs to node SGD/gradients/loss/RNN/while/expand_dims_state_grad/Reshape/StackPush must be from the same frame.\n```\n"]}, {"number": 3113, "title": "Branch 126229168", "body": "", "comments": ["@vrv @martinwicke This push is ready to go.\n"]}, {"number": 3112, "title": "Branch 126222638", "body": "Push of internal Google changes.\n", "comments": ["@tensorflow-jenkins test this please\n", "It looks like Ben checked in a fix for the last remaining failure. I'll do another push to pick that up.\n"]}, {"number": 3111, "title": "word2vec_basic : Unique nodes clustering", "body": "Hi !\n\nI am getting the output of word2vec_basic.py in the following format\n\n```\nNearest to key1  : node1, node2, node3 ..\nNearest to key2 : node2, node4, node5 ..\n\n```\n\nThis implies that node2 is comparatively closer to key2 over key1 (Please correct me if I am wrong, as I am newbie here)\n\nIt would be great if I get the output in the following format\n\n```\nNearest to key1  : node1, node3 , node6..\nNearest to key2 : node2, node4, node5 ..\n\n```\n\nThat is, consider only the closest neighbor for clustering. Suggestions are welcome!\n\nAppreciate the hardwork behind tensorflow :+1:\n\nThanks! \n", "comments": ["This is a question better suited for StackOverflow. Please ask it there and tag it with the `tensorflow` tag\n", "Hi @andydavis1 , I have raised it on stackoverflow.\n\nFor future reference: please refer [issue#3111](http://stackoverflow.com/questions/38109476/dictionary-unique-relative-values-where-values-are-of-list-type) \n\nThanks!\n"]}, {"number": 3110, "title": "R0.9: Fixes URLs and headings", "body": "Points links to wide_and_deep.py to master, fixes a heading, and changes a versioned URL to a generic URL.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Trying to trigger a cla recheck.\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Jenkins, test this please!\n", "failure unrelated\n"]}, {"number": 3109, "title": "fixed ValueError in tensorflow/examples/skflow/mnist_weights.py", "body": "Solution to #3083. \n\nI replaced `mnist.train.images` with `mnist.train.images.astype(np.float32)` and `mnist.train.labels` with `mnist.train.labels.astype(np.int)`.\n", "comments": ["Can one of the admins verify this patch?\n", "I'm closing this PR, as we seem to agree that this is not the right fix.\n"]}, {"number": 3108, "title": "Fixes code URLs and a heading in docs", "body": "Points links to wide_n_deep.py to master, and adjusts the heading level of the top level heading in the tf.contrib.learn quickstart.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3107, "title": "[Docs Request] InceptionV3 Classify multiple images in same run.", "body": "Dearest github community,\n\nThank you for your wonderful contributions to Tensorflow! I greatly appreciate Tensorflow being open-source, for anyone to use :)\n\nI was browsing the docs. and was attempting to retrain the last layer of the inceptionV3 model on new categories.(From https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html)\n\nIt was successful, and i can predict a single image by running:\n\n```\n\nbazel build tensorflow/examples/label_image:label_image && \\\nbazel-bin/tensorflow/examples/label_image/label_image \\\n--graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt \\\n--output_layer=final_result \\\n--image=PATH_TO_IMG\n```\n\nHowever, after much searching, I still could not find a way to use this retrained model to classify multiple images. The link provided here: https://github.com/eldor4do/Tensorflow-Examples/blob/master/retraining-example.py also discusses using the model on a per-image basis.\n\nI've attempted to modify that file to accept multiple images, but I was unsuccessful. (Playing around with feed_dict threw errors.)\n\nIt would be really helpful if there was a documentation of some sort to provide guidelines / show how to accomplish this task :) \n\nTldr: requesting documentation to show how to classify multiple images using InceptionV3 (tensorflow) in python instead of one by one.\n\nThank you, and have a great day!\n", "comments": ["This is a question better suited for StackOverflow. Please ask it there and tag it with the `tensorflow` tag\n"]}, {"number": 3106, "title": "system memory leak", "body": "Running tutorial_example_trainer (similar leak for my own tensorflow scripts) results in ~70MB of memory being lost. `free` shows the memory is used, but `ps` shows that no process is using the memory. Nothing short of a reboot seems to free up the memory.\n\nReproduce with the following (After the ~10 minute run, you should be down ~7GB of memory)\n`for i in `seq 1 100`; do ./bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu; done`\n\nos: 14.04\ngpu: Titan X (361.28)\ncommit: 0927e5eaf3f5f031dbb1d3a13ac6529d8263ad9e (from yesterday)\ncuda: 7.5\ncudnn: 4.0.7\nThis leak is also present on an EC2 12.04 with an older version of tensorflow, cuda 7.0, cudnn 6.5.\n\nHere is the output from a fresh reboot:\n\n```\nwoodward@dev-box:~/install_files/tensorflow$ free -g\n             total       used       free     shared    buffers     cached\nMem:           125          0        125          0          0          0\n-/+ buffers/cache:          0        125\nSwap:          127          0        127\nwoodward@dev-box:~/install_files/tensorflow$ for i in `seq 1 100`; do ./bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu &>/dev/null; done\nwoodward@dev-box:~/install_files/tensorflow$ free -g\n             total       used       free     shared    buffers     cached\nMem:           125          7        118          0          0          0\n-/+ buffers/cache:          7        118\nSwap:          127          0        127\nwoodward@dev-box:~/install_files/tensorflow$ ps -Ao user,pid,%mem,vsz,rss,command --sort -rss | head -n 10\nUSER       PID %MEM    VSZ   RSS COMMAND\nroot      1263  0.0 105648  6532 sshd: woodward [priv]\nroot      1317  0.0 105648  6512 sshd: woodward [priv]\nwoodward  1387  0.0  22756  5560 /bin/bash\nwoodward  1388  0.0  22668  5504 /bin/bash\nwoodward  1390  0.0  22668  5488 /bin/bash\nwoodward  1389  0.0  22668  5464 /bin/bash\nroot      1097  0.0  61384  5376 /usr/sbin/sshd -D\nwoodward  1366  0.0  22552  5144 -bash\nwoodward  1365  0.0 106776  5000 sshd: woodward@pts/0\n```\n", "comments": ["Further observations:\n- The leak occurs with a simple script, but not when the gpu is disabled.\n\n```\nwoodward@dev-box:~$ cat leak.py\nimport tensorflow as tf\n\nhello = tf.constant('hello')\nwith tf.Session() as sess:\n  print sess.run(hello)\nwoodward@dev-box:~$ free -g\n             total       used       free     shared    buffers     cached\nMem:           125          0        125          0          0          0\n-/+ buffers/cache:          0        125\nSwap:          127          0        127\nwoodward@dev-box:~$ for i in `seq 1 100`; do python leak.py &> /dev/null; done\nwoodward@dev-box:~$ free -g\n             total       used       free     shared    buffers     cached\nMem:           125          7        118          0          0          0\n-/+ buffers/cache:          7        118\nSwap:          127          0        127\nwoodward@dev-box:~$ export CUDA_VISIBLE_DEVICES=-1\nwoodward@dev-box:~$ for i in `seq 1 100`; do python leak.py &> /dev/null; done\nwoodward@dev-box:~$ free -g\n             total       used       free     shared    buffers     cached\nMem:           125          7        118          0          0          0\n-/+ buffers/cache:          7        118\nSwap:          127          0        127\nwoodward@dev-box:~$ export CUDA_VISIBLE_DEVICES=0\nwoodward@dev-box:~$ for i in `seq 1 100`; do python leak.py &> /dev/null; done\nwoodward@dev-box:~$ free -g\n             total       used       free     shared    buffers     cached\nMem:           125         14        111          0          0          0\n-/+ buffers/cache:         14        111\nSwap:          127          0        127\nwoodward@dev-box:~$ ps -Ao user,pid,%mem,vsz,rss,command --sort -rss | head -n 5\nUSER       PID %MEM    VSZ   RSS COMMAND\nroot      1258  0.0 105648  6420 sshd: woodward [priv]\nroot     18088  0.0 104436  6120 sshd: root [priv]   \nwoodward  1331  0.0  22756  5684 /bin/bash\nwoodward  1329  0.0  22748  5608 /bin/bash\n```\n", "It's suspicious to me that used is the same for \"Mem\" and also for \"buffers/cache\". Isn't this just the OS hanging on to some chunks of RAM for buffer cache?\n", "The buffers and cached columns are 0GB because I had just rebooted (I also rebooted between posts, which is how I got down to 0GB used again). The \"used\" and \"free\" of the buffers/cache line are  - or + \"buffers+cached\", since \"buffers+cached\" is 0GB the two rows are equal. You are correct that a system running for a while will have very different rows, since buffers and cached will be large. \n\nThe field to focus on is row['buffers/cache'], column['free'], this field is the real free memory available to programs. When that field drops to zero, the system hangs (ignoring swap), which is what brought this to my attention on EC2 where the instance only had ~14GB of memory, and that field dropped to 0GB.\n\n`free` says that 7GB are being used, even after you account for buffers and cache, but `ps` says that no programs are using that memory. I believe this suggest a leak in kernel space, but I am not an expert in that. My second post gives a simple script to reproduce the problem. If you have 7GB of ram, then execute that script 100 times, as I do above, and the computer should lock up, or 400 times if you have 28GB, etc. \n\nIn my second post, I first run with GPU enabled and 7GB are leaked, I then run with GPU disabled and 0GB are leaked, I then run again with GPU enabled and another 7GB are leaked, leaving the system with 14GB used, but ps shows that no programs are using that memory. So it seems to be a problem with GPU calls.\n\nThank you for taking a look at this.\n", "From: https://github.com/tensorflow/tensorflow/issues/2728 can you try updating your driver from 361.28 to something very recent?  Even 361.42 caused problems for some people, and it was apparently solved by updating the driver.\n", "Oops, the original post of that issue made me think that it was about \"within\" process memory. As identified there, upgrading the nvidia driver (to 367.27) on my Titan X machine and on the EC2 instance fixed the problem. No more kernel space leak. Thank you!\n\nAnd thank you all for your hard work on TensorFlow! It is an excellent library.\n", "Awesome, glad the driver update fixed the problem!\n"]}]