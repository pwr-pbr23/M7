[{"number": 44304, "title": "optimize all_reduce_indexed_slices for better performance", "body": "the original dense all reduce is not efficient, update to a more efficient one.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44304) for more info**.\n\n<!-- need_author_cla -->"]}, {"number": 44303, "title": "fix tf.Saver save and restore bug under distributed setting(with ps, \u2026", "body": "\u2026master and worker)", "comments": []}, {"number": 44302, "title": "Unable to install CUDA on Ubuntu 18.04.5", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): pip3 \r\n- TensorFlow version: \r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: I am trying to install this.\r\n- GPU model and memory: GTX 960M\r\n\r\n**Describe the problem**\r\n\r\nI have spent the whole day trying to install CUDA into my newly installed Ubuntu.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI followed the instruction as outlined [here](https://www.tensorflow.org/install/gpu). Before doing that, I make sure that I delete all previously installed CUDA:\r\n```\r\n\r\nsudo apt-get purge nvidia\\*\r\nsudo apt remove nvidia-\\*\r\nsudo rm /etc/apt/sources.list.d/cuda*\r\nsudo apt-get autoremove && sudo apt-get autoclean\r\nsudo rm -rf /usr/local/cuda*\r\n\r\n```\r\nThe following commands are executed without problems:\r\n```\r\n# Add NVIDIA package repositories\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.1.243-1_amd64.deb\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo dpkg -i cuda-repo-ubuntu1804_10.1.243-1_amd64.deb\r\nsudo apt-get update\r\nwget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\r\nsudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\r\nsudo apt-get update\r\n\r\n# Install NVIDIA driver\r\nsudo apt-get install --no-install-recommends nvidia-driver-450\r\n```\r\nAfter that, I restart my machine. However, I failed to execute the following: \r\n```\r\n# Install development and runtime libraries (~4GB)\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.5.32-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.5.32-1+cuda10.1\r\n\r\n```\r\nThe error I got is \r\n`E: Unable to locate package cuda-10-1`\r\n\r\nI found there is at least one other having the same issue with me: https://github.com/tensorflow/tensorflow/issues/39506\r\n\r\nI follow the advice given in that issue and instead of executing the commands that gave me errors, I do the following (as instructed [here](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=deblocal)):\r\n\u00a0\r\n```\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\r\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\r\nwget https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda-repo-ubuntu1804-11-1-local_11.1.0-455.23.05-1_amd64.deb\r\nsudo dpkg -i\u00a0cuda-repo-ubuntu1804-11-1-local_11.1.0-455.23.05-1_amd64.deb\r\nsudo apt-key add /var/cuda-repo-ubuntu1804-11-1-local/7fa2af80.pub\r\nsudo apt-get update\r\nsudo apt-get -y install cuda-10-1\r\n```\r\n\r\nBut when executing  `sudo apt-get -y install cuda-10-1` I got the following errors:\r\n```\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nSome packages could not be installed. This may mean that you have\r\nrequested an impossible situation or if you are using the unstable\r\ndistribution that some required packages have not yet been created\r\nor been moved out of Incoming.\r\nThe following information may help to resolve the situation:\r\n\r\nThe following packages have unmet dependencies:\r\n cuda-10-1 : Depends: cuda-runtime-10-1 (>= 10.1.243) but it is not going to be installed\r\n             Depends: cuda-demo-suite-10-1 (>= 10.1.243) but it is not going to be installed\r\nE: Unable to correct problems, you have held broken packages.\r\n```\r\nI have tried other methods on stackoverflow but it seems like all paths lead to Rome, where I have some unmet dependencies.\r\n\r\n**Any other info / logs**\r\nWhen executing `sudo apt-get install --no-install-recommends nvidia-driver-450`, I got the following log:\r\n```\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nThe following additional packages will be installed:\r\n  dkms libnvidia-cfg1-450 libnvidia-common-450 libnvidia-decode-450\r\n  libnvidia-encode-450 libnvidia-extra-450 libnvidia-fbc1-450 libnvidia-gl-450\r\n  libnvidia-ifr1-450 nvidia-compute-utils-450 nvidia-dkms-450\r\n  nvidia-kernel-common-450 nvidia-kernel-source-450 nvidia-utils-450\r\n  xserver-xorg-video-nvidia-450\r\nSuggested packages:\r\n  menu\r\nRecommended packages:\r\n  nvidia-settings nvidia-prime libnvidia-compute-450:i386\r\n  libnvidia-decode-450:i386 libnvidia-encode-450:i386 libnvidia-ifr1-450:i386\r\n  libnvidia-fbc1-450:i386 libnvidia-gl-450:i386\r\nThe following NEW packages will be installed:\r\n  dkms libnvidia-cfg1-450 libnvidia-common-450 libnvidia-decode-450\r\n  libnvidia-encode-450 libnvidia-extra-450 libnvidia-fbc1-450 libnvidia-gl-450\r\n  libnvidia-ifr1-450 nvidia-compute-utils-450 nvidia-dkms-450\r\n  nvidia-driver-450 nvidia-kernel-common-450 nvidia-kernel-source-450\r\n  nvidia-utils-450 xserver-xorg-video-nvidia-450\r\n0 to upgrade, 16 to newly install, 0 to remove and 3 not to upgrade.\r\nNeed to get 0 B/76.3 MB of archives.\r\nAfter this operation, 267 MB of additional disk space will be used.\r\nDo you want to continue? [Y/n] y\r\nSelecting previously unselected package dkms.\r\n(Reading database ... 176145 files and directories currently installed.)\r\nPreparing to unpack .../00-dkms_2.3-3ubuntu9.7_all.deb ...\r\nUnpacking dkms (2.3-3ubuntu9.7) ...\r\nSelecting previously unselected package libnvidia-cfg1-450:amd64.\r\nPreparing to unpack .../01-libnvidia-cfg1-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking libnvidia-cfg1-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package libnvidia-common-450.\r\nPreparing to unpack .../02-libnvidia-common-450_450.80.02-0ubuntu0.18.04.2_all.deb ...\r\nUnpacking libnvidia-common-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package libnvidia-decode-450:amd64.\r\nPreparing to unpack .../03-libnvidia-decode-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking libnvidia-decode-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package libnvidia-encode-450:amd64.\r\nPreparing to unpack .../04-libnvidia-encode-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking libnvidia-encode-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package libnvidia-extra-450:amd64.\r\nPreparing to unpack .../05-libnvidia-extra-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking libnvidia-extra-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package libnvidia-fbc1-450:amd64.\r\nPreparing to unpack .../06-libnvidia-fbc1-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking libnvidia-fbc1-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package libnvidia-gl-450:amd64.\r\nPreparing to unpack .../07-libnvidia-gl-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking libnvidia-gl-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package libnvidia-ifr1-450:amd64.\r\nPreparing to unpack .../08-libnvidia-ifr1-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking libnvidia-ifr1-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package nvidia-compute-utils-450.\r\nPreparing to unpack .../09-nvidia-compute-utils-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking nvidia-compute-utils-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package nvidia-kernel-source-450.\r\nPreparing to unpack .../10-nvidia-kernel-source-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking nvidia-kernel-source-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package nvidia-kernel-common-450.\r\nPreparing to unpack .../11-nvidia-kernel-common-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking nvidia-kernel-common-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package nvidia-dkms-450.\r\nPreparing to unpack .../12-nvidia-dkms-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking nvidia-dkms-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package nvidia-utils-450.\r\nPreparing to unpack .../13-nvidia-utils-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking nvidia-utils-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package xserver-xorg-video-nvidia-450.\r\nPreparing to unpack .../14-xserver-xorg-video-nvidia-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking xserver-xorg-video-nvidia-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSelecting previously unselected package nvidia-driver-450.\r\nPreparing to unpack .../15-nvidia-driver-450_450.80.02-0ubuntu0.18.04.2_amd64.deb ...\r\nUnpacking nvidia-driver-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up libnvidia-decode-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up libnvidia-extra-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up libnvidia-encode-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up libnvidia-fbc1-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up nvidia-utils-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up nvidia-kernel-common-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nupdate-initramfs: deferring update (trigger activated)\r\nSetting up dkms (2.3-3ubuntu9.7) ...\r\nSetting up nvidia-kernel-source-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up libnvidia-cfg1-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up nvidia-dkms-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nupdate-initramfs: deferring update (trigger activated)\r\nINFO:Enable nvidia\r\nDEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/lenovo_thinkpad\r\nDEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/dell_latitude\r\nDEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/put_your_quirks_here\r\nLoading new nvidia-450.80.02 DKMS files...\r\nBuilding for 5.4.0-52-generic\r\nBuilding for architecture x86_64\r\nBuilding initial module for 5.4.0-52-generic\r\nSecure Boot not enabled on this system.\r\nDone.\r\n\r\nnvidia:\r\nRunning module version sanity check.\r\n - Original module\r\n   - No original module exists within this kernel\r\n - Installation\r\n   - Installing to /lib/modules/5.4.0-52-generic/updates/dkms/\r\n\r\nnvidia-modeset.ko:\r\nRunning module version sanity check.\r\n - Original module\r\n   - No original module exists within this kernel\r\n - Installation\r\n   - Installing to /lib/modules/5.4.0-52-generic/updates/dkms/\r\n\r\nnvidia-drm.ko:\r\nRunning module version sanity check.\r\n - Original module\r\n   - No original module exists within this kernel\r\n - Installation\r\n   - Installing to /lib/modules/5.4.0-52-generic/updates/dkms/\r\n\r\nnvidia-uvm.ko:\r\nRunning module version sanity check.\r\n - Original module\r\n   - No original module exists within this kernel\r\n - Installation\r\n   - Installing to /lib/modules/5.4.0-52-generic/updates/dkms/\r\n\r\ndepmod...\r\n\r\nDKMS: install completed.\r\nSetting up nvidia-compute-utils-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nWarning: The home dir /nonexistent you specified can't be accessed: No such file or directory\r\nAdding system user `nvidia-persistenced' (UID 122) ...\r\nAdding new group `nvidia-persistenced' (GID 127) ...\r\nAdding new user `nvidia-persistenced' (UID 122) with group `nvidia-persistenced' ...\r\nNot creating home directory `/nonexistent'.\r\nSetting up libnvidia-common-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up xserver-xorg-video-nvidia-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up libnvidia-gl-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up libnvidia-ifr1-450:amd64 (450.80.02-0ubuntu0.18.04.2) ...\r\nSetting up nvidia-driver-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nProcessing triggers for libc-bin (2.27-3ubuntu1.2) ...\r\nProcessing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\nProcessing triggers for initramfs-tools (0.130ubuntu3.11) ...\r\nupdate-initramfs: Generating /boot/initrd.img-5.4.0-52-generic\r\nW: Possible missing firmware /lib/firmware/rtl_nic/rtl8125a-3.fw for module r8169\r\nW: Possible missing firmware /lib/firmware/rtl_nic/rtl8168fp-3.fw for module r8169\r\nW: Possible missing firmware /lib/firmware/i915/tgl_dmc_ver2_04.bin for module i915\r\nW: Possible missing firmware /lib/firmware/i915/skl_guc_33.0.0.bin for module i915\r\nW: Possible missing firmware /lib/firmware/i915/bxt_guc_33.0.0.bin for module i915\r\nW: Possible missing firmware /lib/firmware/i915/kbl_guc_33.0.0.bin for module i915\r\nW: Possible missing firmware /lib/firmware/i915/glk_guc_33.0.0.bin for module i915\r\nW: Possible missing firmware /lib/firmware/i915/kbl_guc_33.0.0.bin for module i915\r\nW: Possible missing firmware /lib/firmware/i915/icl_guc_33.0.0.bin for module i915\r\nI: The initramfs will attempt to resume from /dev/dm-2\r\nI: (/dev/mapper/ubuntu--vg-swap_1)\r\nI: Set the RESUME variable to override this.\r\n```\r\nNo errors, but some warnings...", "comments": ["@vitsensei \r\nPlease refer to these resolved issues and let us know:\r\n[link](https://askubuntu.com/questions/1153604/problems-installing-cuda-10-0), [link1](https://stackoverflow.com/questions/58921156/unable-to-install-cuda-on-ubuntu-16-04) , #44291", "Hi @Saduf2019, thanks for the pointers. Here's my result so far:\r\n1. I follow one of the link and doing it step by step. I follow the instruction [here](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=deblocal), but still failed:\r\n```\r\n$ sudo apt-get -y install cuda\r\n\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nSome packages could not be installed. This may mean that you have\r\nrequested an impossible situation or if you are using the unstable\r\ndistribution that some required packages have not yet been created\r\nor been moved out of Incoming.\r\nThe following information may help to resolve the situation:\r\n\r\nThe following packages have unmet dependencies:\r\n cuda : Depends: cuda-11-1 (>= 11.1.0) but it is not going to be installed\r\nE: Unable to correct problems, you have held broken packages.\r\n```\r\nThe rest of the commands went ok.\r\n\r\nAll roads lead to Rome, it always says something about me held broken packages...", "@vitsensei \r\nCan you please refer to this issue with same error and let us know: #36121 #39116 ,also please update the tf version and system properties are missing from the issue template.", "Hi @Saduf2019,\r\nIt seems like people had similar problems as I am in the past. And the way to deal with it is generally to recursively install all the dependencies as suggested in the errors. However, as I were doing that, I came across another problem:\r\n\r\n```\r\nanh@anh-GL552VW:~$ sudo apt-get install cuda-drivers-455\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nThe following packages were automatically installed and are no longer required:\r\n  libnvidia-cfg1-450 libnvidia-common-450 libnvidia-extra-450\r\n  libnvidia-fbc1-450 libnvidia-gl-450 libnvidia-ifr1-450 libxatracker2 libxss1\r\n  libxvmc1 nvidia-dkms-450 nvidia-kernel-common-450 nvidia-kernel-source-450\r\n  x11-apps x11-session-utils xbitmaps xinit xinput\r\nUse 'sudo apt autoremove' to remove them.\r\nThe following additional packages will be installed:\r\n  lib32gcc1 libc6-i386 libxnvctrl0 nvidia-455 nvidia-455-dev nvidia-modprobe\r\n  nvidia-prime nvidia-settings pkg-config screen-resolution-extra\r\n  xserver-xorg-core\r\nSuggested packages:\r\n  xfonts-100dpi | xfonts-75dpi\r\nThe following packages will be REMOVED:\r\n  ubuntu-desktop xorg xserver-xorg-core-hwe-18.04 xserver-xorg-hwe-18.04\r\n  xserver-xorg-input-all-hwe-18.04 xserver-xorg-input-libinput-hwe-18.04\r\n  xserver-xorg-input-wacom-hwe-18.04 xserver-xorg-video-all-hwe-18.04\r\n  xserver-xorg-video-amdgpu-hwe-18.04 xserver-xorg-video-ati-hwe-18.04\r\n  xserver-xorg-video-fbdev-hwe-18.04 xserver-xorg-video-intel-hwe-18.04\r\n  xserver-xorg-video-nouveau-hwe-18.04 xserver-xorg-video-nvidia-450\r\n  xserver-xorg-video-qxl-hwe-18.04 xserver-xorg-video-radeon-hwe-18.04\r\n  xserver-xorg-video-vesa-hwe-18.04 xserver-xorg-video-vmware-hwe-18.04\r\nThe following NEW packages will be installed:\r\n  cuda-drivers-455 lib32gcc1 libc6-i386 libxnvctrl0 nvidia-455 nvidia-455-dev\r\n  nvidia-modprobe nvidia-prime nvidia-settings pkg-config\r\n  screen-resolution-extra xserver-xorg-core\r\n0 to upgrade, 12 to newly install, 18 to remove and 0 not to upgrade.\r\nNeed to get 160 MB/160 MB of archives.\r\nAfter this operation, 550 MB of additional disk space will be used.\r\nDo you want to continue? [Y/n] y\r\nGet:1 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  nvidia-455 455.32.00-0ubuntu1 [155 MB]\r\nGet:2 http://au.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libc6-i386 amd64 2.27-3ubuntu1.2 [2,650 kB]\r\nGet:3 http://au.archive.ubuntu.com/ubuntu bionic-updates/main amd64 lib32gcc1 amd64 1:8.4.0-1ubuntu1~18.04 [48.1 kB]\r\nGet:4 http://au.archive.ubuntu.com/ubuntu bionic-updates/main amd64 xserver-xorg-core amd64 2:1.19.6-1ubuntu4.7 [1,352 kB]\r\nGet:5 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  nvidia-455-dev 455.32.00-0ubuntu1 [24.5 kB]\r\nGet:6 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  nvidia-modprobe 455.32.00-0ubuntu1 [19.4 kB]\r\nGet:7 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  libxnvctrl0 455.32.00-0ubuntu1 [21.3 kB]\r\nGet:8 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  nvidia-settings 455.32.00-0ubuntu1 [886 kB]\r\nGet:9 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-drivers-455 455.32.00-1 [2,472 B]\r\nFetched 160 MB in 34s (4,762 kB/s)                                             \r\n(Reading database ... 176702 files and directories currently installed.)\r\nRemoving ubuntu-desktop (1.417.5) ...\r\nRemoving xorg (1:7.7+19ubuntu7.1) ...\r\nRemoving xserver-xorg-video-nvidia-450 (450.80.02-0ubuntu0.18.04.2) ...\r\nRemoving xserver-xorg-video-all-hwe-18.04 (1:7.7+19ubuntu8~18.04.3) ...\r\nRemoving xserver-xorg-video-amdgpu-hwe-18.04 (19.1.0-1~18.04.1) ...\r\nRemoving xserver-xorg-hwe-18.04 (1:7.7+19ubuntu8~18.04.3) ...\r\nRemoving xserver-xorg-input-wacom-hwe-18.04 (1:0.36.1-0ubuntu1~18.04.1) ...\r\nRemoving xserver-xorg-video-vmware-hwe-18.04 (1:13.3.0-2build1~18.04.1) ...\r\nRemoving xserver-xorg-video-vesa-hwe-18.04 (1:2.4.0-1~18.04.1) ...\r\nRemoving xserver-xorg-input-all-hwe-18.04 (1:7.7+19ubuntu8~18.04.3) ...\r\nRemoving xserver-xorg-input-libinput-hwe-18.04 (0.28.1-1~18.04.1) ...\r\nRemoving xserver-xorg-video-ati-hwe-18.04 (1:19.1.0-1~18.04.1) ...\r\nRemoving xserver-xorg-video-fbdev-hwe-18.04 (1:0.5.0-1ubuntu1~18.04.1) ...\r\nRemoving xserver-xorg-video-intel-hwe-18.04 (2:2.99.917+git20171229-1ubuntu1~18.04.1) ...\r\nRemoving xserver-xorg-video-nouveau-hwe-18.04 (1:1.0.16-1~18.04.1) ...\r\nRemoving xserver-xorg-video-qxl-hwe-18.04 (0.1.5-2build2~18.04.1) ...\r\nRemoving xserver-xorg-video-radeon-hwe-18.04 (1:19.1.0-1~18.04.1) ...\r\nRemoving xserver-xorg-core-hwe-18.04 (2:1.20.8-2ubuntu2.2~18.04.3) ...\r\nSelecting previously unselected package libc6-i386.\r\n(Reading database ... 176380 files and directories currently installed.)\r\nPreparing to unpack .../00-libc6-i386_2.27-3ubuntu1.2_amd64.deb ...\r\nUnpacking libc6-i386 (2.27-3ubuntu1.2) ...\r\nReplaced by files in installed package libc6:i386 (2.27-3ubuntu1.2) ...\r\nSelecting previously unselected package lib32gcc1.\r\nPreparing to unpack .../01-lib32gcc1_1%3a8.4.0-1ubuntu1~18.04_amd64.deb ...\r\nUnpacking lib32gcc1 (1:8.4.0-1ubuntu1~18.04) ...\r\nSelecting previously unselected package xserver-xorg-core.\r\nPreparing to unpack .../02-xserver-xorg-core_2%3a1.19.6-1ubuntu4.7_amd64.deb ...\r\nUnpacking xserver-xorg-core (2:1.19.6-1ubuntu4.7) ...\r\nSelecting previously unselected package nvidia-455.\r\nPreparing to unpack .../03-nvidia-455_455.32.00-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-455 (455.32.00-0ubuntu1) ...\r\ndpkg: error processing archive /tmp/apt-dpkg-install-OCf8f7/03-nvidia-455_455.32.00-0ubuntu1_amd64.deb (--unpack):\r\n trying to overwrite '/usr/share/glvnd/egl_vendor.d/10_nvidia.json', which is also in package libnvidia-gl-450:amd64 450.80.02-0ubuntu0.18.04.2\r\ndpkg-deb: error: paste subprocess was killed by signal (Broken pipe)\r\nSelecting previously unselected package nvidia-455-dev.\r\nPreparing to unpack .../04-nvidia-455-dev_455.32.00-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-455-dev (455.32.00-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-modprobe.\r\nPreparing to unpack .../05-nvidia-modprobe_455.32.00-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-modprobe (455.32.00-0ubuntu1) ...\r\nSelecting previously unselected package pkg-config.\r\nPreparing to unpack .../06-pkg-config_0.29.1-0ubuntu2_amd64.deb ...\r\nUnpacking pkg-config (0.29.1-0ubuntu2) ...\r\nSelecting previously unselected package screen-resolution-extra.\r\nPreparing to unpack .../07-screen-resolution-extra_0.17.3_all.deb ...\r\nUnpacking screen-resolution-extra (0.17.3) ...\r\nSelecting previously unselected package libxnvctrl0:amd64.\r\nPreparing to unpack .../08-libxnvctrl0_455.32.00-0ubuntu1_amd64.deb ...\r\nUnpacking libxnvctrl0:amd64 (455.32.00-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-settings.\r\nPreparing to unpack .../09-nvidia-settings_455.32.00-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-settings (455.32.00-0ubuntu1) ...\r\nSelecting previously unselected package cuda-drivers-455.\r\nPreparing to unpack .../10-cuda-drivers-455_455.32.00-1_amd64.deb ...\r\nUnpacking cuda-drivers-455 (455.32.00-1) ...\r\nSelecting previously unselected package nvidia-prime.\r\nPreparing to unpack .../11-nvidia-prime_0.8.8.2_all.deb ...\r\nUnpacking nvidia-prime (0.8.8.2) ...\r\nErrors were encountered while processing:\r\n /tmp/apt-dpkg-install-OCf8f7/03-nvidia-455_455.32.00-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n```\r\nDoes this give you any insight?", "@vitsensei \r\nThis issue is related to ubuntu or cuda, please create issue with them and move this to closed status as it is not tensorflow bug.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44302\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44302\">No</a>\n", "Same issue here, just several months later and a version upgrade or two\r\n\r\nsudo apt install cuda\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nSome packages could not be installed. This may mean that you have\r\nrequested an impossible situation or if you are using the unstable\r\ndistribution that some required packages have not yet been created\r\nor been moved out of Incoming.\r\nThe following information may help to resolve the situation:\r\n\r\nThe following packages have unmet dependencies:\r\n cuda : Depends: cuda-11-4 (>= 11.4.2) but it is not going to be installed\r\nE: Unable to correct problems, you have held broken packages.\r\n\r\nThis has been reported by many people, and no one has found a resolution for it. It is as if ubuntu 20.04 doesn't support cuda. Period."]}, {"number": 44301, "title": "docs: Failed to initialize NVML: Driver/library version mismatch", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/gpu#install_cuda_with_apt\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI'm following the Ubuntu 18.04 (CUDA 10.1) instructions. I installed the NVIDIA package repositories & NVIDIA driver 450 and rebooted, then ran nvidia-smi:\r\n```\r\n$ nvidia-smi\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   62C    P0    63W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nI then installed cuda-10-1, libcudnn7=7.6.5.32-1+cuda10.1, libcudnn7-dev=7.6.5.32-1+cuda10.1 as per the instructions. Now I get:\r\n\r\n```\r\n$ nvidia-smi\r\nFailed to initialize NVML: Driver/library version mismatch\r\n```\r\n\r\nI'm running Ubuntu 18.04.5 LTS (Bionic Beaver)", "comments": ["I've rebooted after installing cuda & libcudnn, and now it works:\r\n\r\n```\r\n$ nvidia-smi\r\n\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   24C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nIt looks like the nvidia driver version was upgraded to 455.\r\n\r\nWould it be worth updating the docs to move the reboot to the end of the instructions? ", "Because cuda-10-1 installs cuda-drivers-455, which installs nvidia-driver-455, perhaps a better solution is to remove this line from the instructions:\r\n```\r\nsudo apt-get install --no-install-recommends nvidia-driver-450\r\n```", "@tekumara \r\n\r\nPlease, see this [SO link](https://stackoverflow.com/questions/43022843/nvidia-nvml-driver-library-version-mismatch) and see if it helps you. Is this issue related to Tensorflow?\r\nThanks!", "It's working for me now but I believe the docs could be improved as mentioned above.", "@tekumara \r\n\r\nThe requested change has been implemented in this [PR#1749](https://github.com/tensorflow/docs/pull/1749).Please, verify once and close the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44300, "title": "docs: Unable to locate package libcudnn7", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/gpu#install_cuda_with_apt\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI'm following the Ubuntu 18.04 (CUDA 10.1) instructions. I've installed the NVIDIA package repositories & NVIDIA driver and rebooted. I now try to install cuda & libcudnn7:\r\n\r\n```\r\n$ sudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.5.32-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.5.32-1+cuda10.1\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nE: Unable to locate package libcudnn7\r\nE: Unable to locate package libcudnn7-dev\r\n```\r\n\r\nI'm running Ubuntu 18.04.5 LTS (Bionic Beaver)", "comments": ["It looks like I missed running the second `sudo apt-get update` in the instructions. I've run it again, and it works!"]}, {"number": 44299, "title": "Is is possible to use tf.keras.applications.VGG16/Resnet50 in under the scope of TPU?", "body": "I am currently trying to use  tf.keras.applications.VGG16/Resnet50 to do transfer learning with TPU. I run this on a Google Colab with tensorflow 2.3.0.  I briefly use the following code to build the model:\r\n\r\n```\r\nwith strategy.scope():\r\n  # loading VGG\r\n  vgg16_base = tf.keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=(224,224,3))\r\n  # freeze pretrained model\r\n  vgg16_base.trainable = False\r\n  vgg16 = tf.keras.models.Sequential(name='vgg16')\r\n  vgg16.add(vgg16_base)\r\n  vgg16.add(tf.keras.layers.Flatten())\r\n  vgg16.add(tf.keras.layers.Dense(4096, activation='relu'))\r\n  vgg16.add(tf.keras.layers.Dropout(0.5))\r\n  vgg16.add(tf.keras.layers.Dense(4096, activation='relu'))\r\n  vgg16.add(tf.keras.layers.Dropout(0.5))\r\n  vgg16.add(tf.keras.layers.Dense(2, activation=None))\r\n  vgg16.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n        optimizer=tf.keras.optimizers.SGD(lr=0.001,momentum=0.9),metrics=['accuracy'])\r\n  vgg16.summary()\r\n```  \r\nThe summary can be displayed normally and correctly, but when I use the fit method with the model, it gives out the following error:s for all the roots:\r\n```\r\nUnavailableError: 7 root error(s) found.\r\n  (0) Unavailable: {{function_node __inference_train_function_27953}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1603596583.299611768\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3948,\"referenced_errors\":[{\"created\":\"@1603596583.299610117\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":394,\"grpc_status\":14}]}\r\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n\t [[RemoteCall]]\r\n\t [[IteratorGetNextAsOptional]]\r\n\t [[Cast_1/_26]]\r\n```\r\nThe code is runnable when using GPU. I wonder it is supposed to be related to the image_generator or we can not use these pre-trained models in TPU currently?", "comments": ["@cytwill \r\nPlease share complete code such that we can replicate the issue faced or if possible share a colab gist with the error reported.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44299\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44299\">No</a>\n"]}, {"number": 44298, "title": "Fix _CumprodGrad for 0. inputs", "body": "Copyed from https://github.com/tensorflow/tensorflow/pull/32714", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44298) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 44297, "title": "Is padding also required in model.predict function?", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["The question does not mentions which padding are we talking about so I will answer wrt CNN . No padding is not required in model.predict function. Its only used in conv2D while making a CNN. You can find more about padding [here](https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t).", "> The question does not mentions which padding are we talking about so I will answer wrt CNN . No padding is not required in model.predict function. Its only used in conv2D while making a CNN. You can find more about padding [here](https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t).\r\n\r\nI am talking about LSTM\r\n", "I think this [link](https://github.com/keras-team/keras/issues/2375) is very helpful in answering your question .", "@Vignesh1-art \r\n\r\nPadding is not required in model.predict function. As suggested by @PrattJena you can go through the [link](https://github.com/keras-team/keras/issues/2375) which explains clearly about padding.\r\n\r\nThis question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44296, "title": "Strange error when I try to use tf.roll in a custom loss function", "body": "Hello, I would love if anyoen could point me  in a good direction to find why I am getting the following error when I try to use a custom loss function like:\r\n\r\ndef lfunction(y_true, y_pred):\r\n \r\n  mask = K.variable(np.array([1.0,0.0,0.0,0.0,0.0]))\r\n  squared = (y_true - y_pred)**2\r\n  \r\n  mass_mal_to_bk = tf.roll(y_pred,1,axis=1)*mask\r\n  \r\n  add_mass_mal_to_bk = y_true * mass_mal_to_bk\r\n \r\n  return squared + add_mass_mal_to_bk\r\n\r\nThe error I get is this:\"\r\n\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable _AnonymousVar84 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar84/class tensorflow::Var does not exist.\r\n         [[node loss/predictions_loss/batata/mul/ReadVariableOp (defined at C:\\Users\\tiago\\Anaconda3\\envs\\Aqula36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_10394]\r\n\r\nSorry to bother with that, but the message  gives me no clue on what is going on.", "comments": ["@TStein81,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using. Thanks!\r\n\r\nI am providing some resources here. check https://keras.io/api/losses/, https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss, and these articles [1](https://medium.com/swlh/custom-loss-and-custom-metrics-using-keras-sequential-model-api-d5bcd3a4ff28), [2](https://towardsdatascience.com/custom-loss-function-in-tensorflow-2-0-d8fa35405e4e), and [3](https://towardsdatascience.com/advanced-keras-constructing-complex-custom-losses-and-metrics-c07ca130a618). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44295, "title": "Add extra warning info for lr", "body": "Fix  https://github.com/tensorflow/tensorflow/issues/44293 https://github.com/tensorflow/tensorflow/issues/44172", "comments": ["We're adding an unconditional deprecation warning. Closing this PR since it is no longer applicable. Thanks!", "Yes 5 months passed."]}, {"number": 44294, "title": "Non-Gradient Descend Learning", "body": "\r\n**System information**\r\n- OS Platform and Distribution Windows 10\r\n- TensorFlow installed from binary\r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am currently developing a Radial Basis Function Network, where I use a layer calculating the radial basis functions, followed by a Dense layer.\r\nThe problem is, that the Dense-Layer should use a non-gradient-descent learning algorithm.\r\nIt should calculate the optimal weights by using the Moore-Penrose Pseudo-Inverse.\r\nHowever, it does not seem to be possible to update the layers weight within the train_step of the model.\r\nThe only option, I am aware of, is through optimizer.apply_gradients.\r\n\r\nIs is possible, to change the weights in another way than applying gradients?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n# in model:train_step\r\n\r\nself.interpolated_dense_weights = tf.tensordot(tf.linalg.pinv(input_after_rbf_layer), tf.transpose(y), axes=1)\r\nprint(self.dense_layer.get_weights()) <-- ERROR here. So \"layer.set_weights()\" does not work\r\n\r\n\r\n**Any other info / logs**\r\nError I received:\r\n\r\nRuntimeError: Cannot get value inside Tensorflow graph function.\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I am now using an Optimizer for a custom non-gradient learning algorithm.\r\nThis works by using the following code in a custom Optimizer:\r\n\r\n`\r\ndef _resource_apply_dense(self, update, value, apply_state):\r\n        updated_value = state_ops.assign(value, update)\r\n        return control_flow_ops.group(*[updated_value])\r\n`\r\n\r\nThis is not great style, and I have to mis-use the variable in _resource_apply_dense, but as far as I know, tensorflow does not support any better way to do this.\r\n\r\nIn my opinion, it is a bit strange, that because of the naming (\"Optimizer\"-class and \"gradients\"-variable in _resource_apply_dense), the library is restricting its features to gradient-descend learning-algorithms only.\r\nPlease correct my if I am wrong and there actually is a way to implement such a learning-algorithm in tensorflow.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44294\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44294\">No</a>\n"]}, {"number": 44293, "title": "tf.keras.experimental.CosineDecay error", "body": "- TensorFlow version: 2.3.0\r\n- Python version: 3.7.6\r\n\r\nAccording to https://www.tensorflow.org/api_docs/python/tf/keras/experimental/CosineDecay :\r\n> You can pass this schedule directly into a tf.keras.optimizers.Optimizer as the learning rate. \r\n\r\nHowever when I try to use the suggested code, I get the following error:\r\n\r\n`TypeError: '<' not supported between instances of 'CosineDecay' and 'int'`\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nHere is a sample code:\r\n\r\n```\r\nimport numpy as np\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport tensorflow as tf\r\n\r\n# Model / data parameters\r\nnum_classes = 10\r\ninput_shape = (28, 28, 1)\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n\r\n# Scale images to the [0, 1] range\r\nx_train = x_train.astype(\"float32\") / 255\r\nx_test = x_test.astype(\"float32\") / 255\r\n# Make sure images have shape (28, 28, 1)\r\nx_train = np.expand_dims(x_train, -1)\r\nx_test = np.expand_dims(x_test, -1)\r\nprint(\"x_train shape:\", x_train.shape)\r\nprint(x_train.shape[0], \"train samples\")\r\nprint(x_test.shape[0], \"test samples\")\r\n\r\n\r\n# convert class vectors to binary class matrices\r\ny_train = keras.utils.to_categorical(y_train, num_classes)\r\ny_test = keras.utils.to_categorical(y_test, num_classes)\r\n\r\nmodel = keras.Sequential(\r\n    [\r\n        keras.Input(shape=input_shape),\r\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\r\n        layers.MaxPooling2D(pool_size=(2, 2)),\r\n        layers.Flatten(),\r\n        layers.Dropout(0.5),\r\n        layers.Dense(num_classes, activation=\"softmax\"),\r\n    ]\r\n)\r\n\r\nmodel.summary()\r\n\r\ndecay_steps = 10\r\nlr_decayed_fn = tf.keras.experimental.CosineDecay(0.0001, decay_steps)\r\n\r\nmodel.compile(\r\n    loss='categorical_crossentropy',\r\n    optimizer=keras.optimizers.Adam(lr=lr_decayed_fn),\r\n    metrics=['categorical_accuracy'],\r\n)\r\n\r\nbatch_size = 128\r\nepochs = 5\r\n\r\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr=lr_decayed_fn), metrics=[\"categorical_accuracy\"])\r\n\r\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\r\n```", "comments": ["Please check https://github.com/tensorflow/tensorflow/issues/44172#issuecomment-712776248", "Thank you! It works if I use \"learning_rate\" instead of \"lr\". I wasn't aware of this change.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44293\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44293\">No</a>\n", " It doesn't work. Tf 2.2 python 3.6", "@tricoffee Please reopen this issue / file a new one with your code that is failing."]}, {"number": 44292, "title": "Building TF-2.2 OpenCL triSYCL-1.2 on macOS-10.15 with GCC-4.9 and Bazel-2.0.0 Failed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina (macOS-10.15)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r2.2\r\n- Python version: 3.6.1\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): GCC-4.9\r\n- CUDA/cuDNN version: None (OpenCL-1.2 with triSYCL-1.2)\r\n- GPU model and memory: Intel Iris Graphics 550 1536MB\r\n\r\n\r\n\r\n**Describe the problem**\r\nErrors occurred when I was trying to build TensorFlow-2.2 from source code. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\n(venv) localhost:src daqirui$ ./configure\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nYou have bazel 2.0.0 installed.\r\nPlease specify the location of python. [Default is /Users/daqirui/PycharmProjects/TF2-Mac/venv/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /Users/daqirui/PycharmProjects/TF2-Mac/venv/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/Users/daqirui/PycharmProjects/TF2-Mac/venv/lib/python3.6/site-packages]\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: y\r\nOpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nPlease specify which C++ compiler should be used as the host C++ compiler. [Default is /usr/bin/g++]: /usr/local/bin/c++-4.9\r\n\r\n\r\nPlease specify which C compiler should be used as the host C compiler. [Default is /usr/bin/gcc]: /usr/local/bin/gcc-4.9\r\n\r\n\r\nDo you wish to build TensorFlow with ComputeCPP support? [Y/n]: n\r\nNo ComputeCPP support will be enabled for TensorFlow.\r\n\r\nPlease specify the location of the triSYCL include directory. (Use --config=sycl_trisycl when building with Bazel) [Default is /usr/local/triSYCL/include]: \r\n\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: n\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: n\r\nClang will not be downloaded.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: -march=native -Wno-sign-compare -O0\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nDo you wish to build TensorFlow with iOS support? [y/N]: n\r\nNo iOS support will be enabled for TensorFlow.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n```\r\n```\r\n(venv) localhost:src daqirui$ /usr/local/bin/bazel build //tensorflow/tools/pip_package:build_pip_package --config=sycl_trisycl --config=opt --config=v2 --local_ram_resources=2048\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=133\r\nERROR: Config value sycl_trisycl is not defined in any .rc file\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nI tried to deleted `--config=sycl_trisycl` but it occurred another error `ERROR: Config value opt is not defined in any .rc file`. And I also found out that the configure file `.tf_configure.bazelrc` seemed not being detected by Bazel. So I renamed it into `.bazelrc` which I deleted the prefix. This time, Bazel detected it. But it did work either that `ERROR: Config value xla is not defined in any .rc file`. By the way, I need to clarify that the reason I used `/usr/local/bin/bazel` instead of `bazel` is that I've installed two versions of Bazel. One is 3.7.0, and one is 2.0.0 because TF-2.2 needs it. I don't know why Bazelisk cannot work properly since it can't download the right version automatically. And command `/usr/local/bin/bazel` refers to 2.0.0, which `bazel` refers to 3.7.0. But both of them can't work well (same error). I hope that someone could solve my issue. This is my `.tf_configure.bazelrc` file: \r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/Users/daqirui/PycharmProjects/TF2-Mac/venv/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/Users/daqirui/PycharmProjects/TF2-Mac/venv/lib/python3.6/site-packages\"\r\nbuild --python_path=\"/Users/daqirui/PycharmProjects/TF2-Mac/venv/bin/python\"\r\nbuild --config=xla\r\nbuild --config=sycl\r\nbuild --action_env HOST_CXX_COMPILER=\"/usr/local/bin/c++-4.9\"\r\nbuild --action_env HOST_C_COMPILER=\"/usr/local/bin/gcc-4.9\"\r\nbuild --action_env TF_NEED_COMPUTECPP=\"0\"\r\nbuild --action_env TRISYCL_INCLUDE_DIR=\"/usr/local/triSYCL/include\"\r\nbuild:opt --copt=-march=native\r\nbuild:opt --copt=-Wno-sign-compare\r\nbuild:opt --copt=-O0\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac,-oss_serial\r\ntest:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac\r\ntest:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac,-oss_serial,-v1only\r\ntest:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac,-v1only\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n```", "comments": ["I've made some progress. But it's still not working. \r\n```\r\n(venv) localhost:src daqirui$ bazel build //tensorflow/tools/pip_package:build_pip_package --config=sycl_trisycl --config=opt --config=v2 --config=noaws --config=nogcp --config=nohdfs --config=nonccl --local_ram_resources=2048\r\nExtracting Bazel installation...\r\nStarting local Bazel server and connecting to it...\r\nWARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=133\r\nINFO: Reading rc options for 'build' from /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\nINFO: Reading rc options for 'build' from /Users/daqirui/PycharmProjects/TF2-Mac/src/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/Users/daqirui/PycharmProjects/TF2-Mac/venv/bin/python --action_env PYTHON_LIB_PATH=/Users/daqirui/PycharmProjects/TF2-Mac/venv/lib/python3.6/site-packages --python_path=/Users/daqirui/PycharmProjects/TF2-Mac/venv/bin/python --config=xla --config=sycl --action_env HOST_CXX_COMPILER=/usr/local/bin/c++-4.9 --action_env HOST_C_COMPILER=/usr/local/bin/gcc-4.9 --action_env TF_NEED_COMPUTECPP=0 --action_env TRISYCL_INCLUDE_DIR=/usr/local/triSYCL/include --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:v2 in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true\r\nINFO: Found applicable config definition build:sycl in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --crosstool_top=@local_config_sycl//crosstool:toolchain --define=using_sycl=true --action_env TF_NEED_OPENCL_SYCL=1\r\nINFO: Found applicable config definition build:sycl_trisycl in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=using_trisycl=true\r\nINFO: Found applicable config definition build:opt in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --copt=-O0 --host_copt=-march=native --define with_default_optimizations=true\r\nINFO: Found applicable config definition build:v2 in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:noaws in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=no_aws_support=true\r\nINFO: Found applicable config definition build:nogcp in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=no_gcp_support=true\r\nINFO: Found applicable config definition build:nohdfs in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=no_hdfs_support=true\r\nINFO: Found applicable config definition build:nonccl in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=no_nccl_support=true\r\nINFO: Found applicable config definition build:macos in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):\r\n - /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/bazel_toolchains/repositories/repositories.bzl:37:9\r\n - /Users/daqirui/PycharmProjects/TF2-Mac/src/WORKSPACE:37:1\r\nERROR: /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/local_config_sycl/crosstool/BUILD:12:1: @local_config_sycl//crosstool:cc-compiler-local: missing value for mandatory attribute 'toolchain_config' in 'cc_toolchain' rule\r\nINFO: Call stack for the definition of repository 'com_google_absl' which is a tf_http_archive (rule definition at /Users/daqirui/PycharmProjects/TF2-Mac/src/third_party/repo.bzl:134:19):\r\n - /Users/daqirui/PycharmProjects/TF2-Mac/src/tensorflow/workspace.bzl:186:5\r\n - /Users/daqirui/PycharmProjects/TF2-Mac/src/WORKSPACE:19:1\r\nINFO: Call stack for the definition of repository 'sobol_data' which is a third_party_http_archive (rule definition at /Users/daqirui/PycharmProjects/TF2-Mac/src/third_party/repo.bzl:219:28):\r\n - /Users/daqirui/PycharmProjects/TF2-Mac/src/third_party/sobol_data/workspace.bzl:6:5\r\n - /Users/daqirui/PycharmProjects/TF2-Mac/src/tensorflow/workspace.bzl:66:5\r\n - /Users/daqirui/PycharmProjects/TF2-Mac/src/tensorflow/workspace.bzl:101:5\r\n - /Users/daqirui/PycharmProjects/TF2-Mac/src/WORKSPACE:19:1\r\nERROR: /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/local_config_sycl/crosstool/BUILD:12:1: Target '@local_config_sycl//crosstool:empty' contains an error and its package is in error and referenced by '@local_config_sycl//crosstool:cc-compiler-local'\r\nERROR: /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/local_config_sycl/crosstool/BUILD:5:1: Target '@local_config_sycl//crosstool:cc-compiler-local' contains an error and its package is in error and referenced by '@local_config_sycl//crosstool:toolchain'\r\nERROR: /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/bazel_tools/tools/cpp/BUILD:58:1: every rule of type cc_toolchain_alias implicitly depends upon the target '@local_config_sycl//crosstool:toolchain', but this target could not be found because of: Target '@local_config_sycl//crosstool:toolchain' contains an error and its package is in error\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 542.845s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (161 packages loaded, 3609 targets configured)\r\n    Fetching @local_config_python; fetching 6s\r\n```", "I've also tried to rerun `./configure`. But it didn't work either. ", "> I've made some progress. But it's still not working.\r\n> \r\n> ```\r\n> (venv) localhost:src daqirui$ bazel build //tensorflow/tools/pip_package:build_pip_package --config=sycl_trisycl --config=opt --config=v2 --config=noaws --config=nogcp --config=nohdfs --config=nonccl --local_ram_resources=2048\r\n> Extracting Bazel installation...\r\n> Starting local Bazel server and connecting to it...\r\n> WARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\n> INFO: Options provided by the client:\r\n>   Inherited 'common' options: --isatty=1 --terminal_columns=133\r\n> INFO: Reading rc options for 'build' from /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc:\r\n>   Inherited 'common' options: --experimental_repo_remote_exec\r\n> INFO: Reading rc options for 'build' from /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc:\r\n>   'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\n> INFO: Reading rc options for 'build' from /Users/daqirui/PycharmProjects/TF2-Mac/src/.tf_configure.bazelrc:\r\n>   'build' options: --action_env PYTHON_BIN_PATH=/Users/daqirui/PycharmProjects/TF2-Mac/venv/bin/python --action_env PYTHON_LIB_PATH=/Users/daqirui/PycharmProjects/TF2-Mac/venv/lib/python3.6/site-packages --python_path=/Users/daqirui/PycharmProjects/TF2-Mac/venv/bin/python --config=xla --config=sycl --action_env HOST_CXX_COMPILER=/usr/local/bin/c++-4.9 --action_env HOST_C_COMPILER=/usr/local/bin/gcc-4.9 --action_env TF_NEED_COMPUTECPP=0 --action_env TRISYCL_INCLUDE_DIR=/usr/local/triSYCL/include --action_env TF_CONFIGURE_IOS=0\r\n> INFO: Found applicable config definition build:v2 in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\n> INFO: Found applicable config definition build:xla in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true\r\n> INFO: Found applicable config definition build:sycl in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --crosstool_top=@local_config_sycl//crosstool:toolchain --define=using_sycl=true --action_env TF_NEED_OPENCL_SYCL=1\r\n> INFO: Found applicable config definition build:sycl_trisycl in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=using_trisycl=true\r\n> INFO: Found applicable config definition build:opt in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --copt=-O0 --host_copt=-march=native --define with_default_optimizations=true\r\n> INFO: Found applicable config definition build:v2 in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\n> INFO: Found applicable config definition build:noaws in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=no_aws_support=true\r\n> INFO: Found applicable config definition build:nogcp in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=no_gcp_support=true\r\n> INFO: Found applicable config definition build:nohdfs in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=no_hdfs_support=true\r\n> INFO: Found applicable config definition build:nonccl in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --define=no_nccl_support=true\r\n> INFO: Found applicable config definition build:macos in file /Users/daqirui/PycharmProjects/TF2-Mac/src/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\n> DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\n> DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):\r\n>  - /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/bazel_toolchains/repositories/repositories.bzl:37:9\r\n>  - /Users/daqirui/PycharmProjects/TF2-Mac/src/WORKSPACE:37:1\r\n> ERROR: /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/local_config_sycl/crosstool/BUILD:12:1: @local_config_sycl//crosstool:cc-compiler-local: missing value for mandatory attribute 'toolchain_config' in 'cc_toolchain' rule\r\n> INFO: Call stack for the definition of repository 'com_google_absl' which is a tf_http_archive (rule definition at /Users/daqirui/PycharmProjects/TF2-Mac/src/third_party/repo.bzl:134:19):\r\n>  - /Users/daqirui/PycharmProjects/TF2-Mac/src/tensorflow/workspace.bzl:186:5\r\n>  - /Users/daqirui/PycharmProjects/TF2-Mac/src/WORKSPACE:19:1\r\n> INFO: Call stack for the definition of repository 'sobol_data' which is a third_party_http_archive (rule definition at /Users/daqirui/PycharmProjects/TF2-Mac/src/third_party/repo.bzl:219:28):\r\n>  - /Users/daqirui/PycharmProjects/TF2-Mac/src/third_party/sobol_data/workspace.bzl:6:5\r\n>  - /Users/daqirui/PycharmProjects/TF2-Mac/src/tensorflow/workspace.bzl:66:5\r\n>  - /Users/daqirui/PycharmProjects/TF2-Mac/src/tensorflow/workspace.bzl:101:5\r\n>  - /Users/daqirui/PycharmProjects/TF2-Mac/src/WORKSPACE:19:1\r\n> ERROR: /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/local_config_sycl/crosstool/BUILD:12:1: Target '@local_config_sycl//crosstool:empty' contains an error and its package is in error and referenced by '@local_config_sycl//crosstool:cc-compiler-local'\r\n> ERROR: /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/local_config_sycl/crosstool/BUILD:5:1: Target '@local_config_sycl//crosstool:cc-compiler-local' contains an error and its package is in error and referenced by '@local_config_sycl//crosstool:toolchain'\r\n> ERROR: /private/var/tmp/_bazel_daqirui/c16b9230c8e6c6d13b7a65f321c3dea6/external/bazel_tools/tools/cpp/BUILD:58:1: every rule of type cc_toolchain_alias implicitly depends upon the target '@local_config_sycl//crosstool:toolchain', but this target could not be found because of: Target '@local_config_sycl//crosstool:toolchain' contains an error and its package is in error\r\n> ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\n> INFO: Elapsed time: 542.845s\r\n> INFO: 0 processes.\r\n> FAILED: Build did NOT complete successfully (161 packages loaded, 3609 targets configured)\r\n>     Fetching @local_config_python; fetching 6s\r\n> ```\r\n\r\nSorry, I forgot to mention that this progress was made by recloning TensorFlow-2.2. I think the previous one was missing some important files. ", "@XDflight,\r\n\r\nCan you try building the latest stable version of Tensorflow i.e `2.6.0` using this [guide](https://www.tensorflow.org/install/source) for MacOS and let us know if the issue still persists in the newer version? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44292\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44292\">No</a>\n"]}, {"number": 44291, "title": "tensorflow-nightly-gpu looking for cusolver64_10.dll on a cuDNN 11.1 installation", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: tf-nightly-gpu-2.4.0.dev20201023\r\n- Python version: 3.7.9\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.1\r\n- GPU model and memory: GeForceMX250\r\n\r\n\r\n\r\n**Describe the problem**\r\nAfter installing the new CUDA and cuDNN, I can now get the installation to go through. However, the first command tensorflow.test.is_gpu_available() fails because one dll is not found:\r\n\r\n2020-10-24 11:59:36.156976: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\r\n\r\nIn the \"NVIDIA GPU Computing Toolkit\"\\CUDA\\v11.1\\bin directory I see the following dll:\r\n\r\ncusolver64_11.dll\r\n\r\nHowever, tensorflow nightly seems to be looking for cusolver64_10.dll.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npython\r\nimport tensorflow\r\ntensorflow.test.is_gpu_available()\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Same story here, moved to tf-nightly to be able to use CUDA 11.1 & most libraries loading fine:\r\n\r\n[begin]\r\n2020-10-25 11:10:32.681242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-10-25 11:10:37.551178: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-10-25 11:10:37.555135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2020-10-25 11:10:38.066103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: Quadro M2000M computeCapability: 5.0\r\ncoreClock: 1.137GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-10-25 11:10:38.068610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-10-25 11:10:38.222716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-10-25 11:10:38.223383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-10-25 11:10:38.229546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-25 11:10:38.232914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2020-10-25 11:10:38.234937: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\r\n2020-10-25 11:10:38.306445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2020-10-25 11:10:38.319388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n[end]\r\n\r\n\r\n", "@apurvakalia \r\nThis error has been reported and resolved, please refer [to these](https://github.com/tensorflow/tensorflow/issues/44159#issuecomment-712543145) issues and let us know:\r\n\r\n#40804 #42354 #41909 [link](https://stackoverflow.com/questions/59823283/could-not-load-dynamic-library-cudart64-101-dll-on-tensorflow-cpu-only-install)\r\n", "Thanks for the pointers.\r\n\r\nI saw that there was a cusolver64_10.dll in my conda environment at .conda\\pkgs\\cudatoolkit-10.2.89-h74a9793_1. I copied that into \"NVIDIA GPU Computing Toolkit\"\\CUDA\\v11.1\\bin as a temporary fix. This got me past the first issue.\r\n\r\nNow I cannot seem to import keras properly:\r\n\r\n>>> from tensorflow import keras\r\n>>> from keras import regularizers\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'keras'\r\n>>> dir()\r\n['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'keras', 'tensorflow']\r\n\r\nAs you can see, keras is visible as a package after importing it, but does not seem to work properly.", "@apurvakalia \r\nPlease try [this comment](https://github.com/keras-team/keras/issues/4889#issuecomment-296452384), [for conda](https://stackoverflow.com/questions/45271344/importerror-no-module-named-keras).#41186 else\r\n\r\nPlease create a new issue for this as the issue reported is resolved, the new issue will be addressed and resolved. [kindly move this to closed status]", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44291\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44291\">No</a>\n", "Having the same problem on Windows 10 with tf_nightly-2.5.0.dev20201027, CUDA 11.1\r\n\r\nLooks like TF is looking for the previous version of `cusolver`, from CUDA 10.x, instead of the current one. ", "having the same issue on windows 10", "I'm having the same issue here... is the only solution to downgrade to Cuda 10.2 ? I have an RTX 3080, I don't think that's compatible with Cuda 10.2... ", "@Saduf2019 @apurvakalia can we reopen this ?\r\n\r\nThe resolution of copying over the `cusolver` from Cuda 10.x to a 11.x installation doesn't seem acceptable, and it looks like more people are running into this.", "If you are urgent, you can build tensorflow from source with Cuda 11.1 as a temporary expedient.\r\n\r\nI tried to build Tensorflow from source with Cuda 11.1 and 2.4.0-rc1 branch, it seemed to work.\r\n![image](https://user-images.githubusercontent.com/47196430/99183402-ca665a00-277e-11eb-80bb-efd6aab5a386.png)\r\n\r\nI am waiting for Tensorflow developers also.\r\n\r\n", "Same issue on windows 10.", "[CUDA 11.1  tf-nightly 2.5.0-dev20201111]\r\nsolved by renaming  cusolver64_11.dll  to cusolver64_10.dll", "@galaktyk Renaming takes the error away, but it pretty much breaks Tensorflow (as one would expect).. At least that's what happened for me, have you tried training a model after the name change ?", "Might be similar to #44697\r\n\r\n@sanjoy, @pkanwar23  can you take a look please?", "> If you are urgent, you can build tensorflow from source with Cuda 11.1 as a temporary expedient.\r\n> \r\n> I tried to build Tensorflow from source with Cuda 11.1 and 2.4.0-rc1 branch, it seemed to work.\r\n> ![image](https://user-images.githubusercontent.com/47196430/99183402-ca665a00-277e-11eb-80bb-efd6aab5a386.png)\r\n> \r\n> I am waiting for Tensorflow developers also.\r\n\r\nI build it with Cuda 11.1, cuDNN 8.0.5 and master branch. Now I've a new error trying to train a DenseNet201 model:\r\n```\r\n2020-11-17 19:56:26.891715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-17 19:56:28.234059: I tensorflow/stream_executor/cuda/cuda_dnn.cc:344] Loaded cuDNN version 8005\r\n2020-11-17 19:56:28.261778: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0\r\n2020-11-17 19:56:28.300510: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0\r\n2020-11-17 19:56:28.311968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-17 19:56:29.036126: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.074751: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.106229: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.118288: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.131608: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.173475: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.187861: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.202861: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.218411: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.240216: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.261836: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.272978: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.284639: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.296523: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.308768: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.320860: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.333894: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.346721: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.360002: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.373523: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.387512: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.401665: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.534656: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.546407: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.560431: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.572234: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.584615: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.597087: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.609493: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.622025: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.634791: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.648957: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.664141: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.679590: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.699014: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.723953: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.738516: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.753892: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.769328: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.784456: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.799754: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.815631: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.831503: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.847497: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.864215: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.881252: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.898373: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.916005: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.933782: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.951953: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.970192: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:29.989432: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.009755: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.029797: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.049250: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.070358: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.092788: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.112571: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.136109: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.156577: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.177445: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-11-17 19:56:30.180956: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.181111: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.181390: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.181623: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.181871: W tensorflow/core/kernels/gpu_utils.cc:69] Failed to check cudnn convolutions for out-of-bounds reads and writes with an error message: 'stream did not block host until done; was already in an error state'; skipping this check. This only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\r\n2020-11-17 19:56:30.182282: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.182429: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.182704: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.182917: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.183572: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.183771: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.183986: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.184241: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.184484: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.184678: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.184899: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.185144: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.185565: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.185769: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.186009: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.186178: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.186430: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.186681: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.187168: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.187364: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.187618: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.187753: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.187934: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.188099: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.188611: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.188737: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.188919: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.189079: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.189249: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.189367: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.189548: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.189709: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.190233: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.190355: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.190532: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.190690: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.190860: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.191024: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.191265: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.191443: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.195127: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.195276: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.195701: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.195935: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.196209: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.196366: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.196637: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.196873: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.200522: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.200687: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.200957: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.201213: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.201455: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.201641: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.201879: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.202078: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.203603: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.203760: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.203962: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.204125: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.204294: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.204410: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.204584: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.204753: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.206097: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.206238: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.206511: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.206783: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.206970: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-11-17 19:56:30.207093: E tensorflow/stream_executor/stream.cc:5011] Internal: Failed to enqueue async memset operation: CUDA_ERROR_INVALID_VALUE: invalid argument\r\n2020-11-17 19:56:30.207275: E tensorflow/stream_executor/cuda/cuda_driver.cc:1051] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE: invalid argument; host dst: 0xe10ae6c640; GPU src: (nil); size: 8=0x8\r\n2020-11-17 19:56:30.207485: I tensorflow/stream_executor/stream.cc:4977] [stream=000002458FD1B4C0,impl=000002458606B630] Internal: stream did not block host until done; was already in an error state\r\n2020-11-17 19:56:30.207769: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"E:\\PyCharm 2020.2.1\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_umd.py\", line 197, in runfile\r\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\r\n  File \"E:\\PyCharm 2020.2.1\\plugins\\python\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"mytest.py\", line 74, in <module>\r\n    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val),\r\n  File \"\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1103, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 784, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 844, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2971, in __call__\r\n    return graph_function._call_flat(\r\n  File \"\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1947, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 556, in call\r\n    outputs = execute.execute(\r\n  File \"\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InternalError:  MatrixTriangularSolveOp: failed to copy rhs from device\r\n\t [[node densenet201/conv4_block38_1_bn/FusedBatchNormV3 (defined at mytest.py:74) ]] [Op:__inference_train_function_38662]\r\nFunction call stack:\r\ntrain_function\r\n```\r\n", "@TheEnigmist My code worked well, i think that it is an other issue or some codes is not compatible.", "> @TheEnigmist My code worked well, i think that it is an other issue or some codes is not compatible.\r\n\r\nYes, I found that the problem was related to memory growth. Adding these lines solved my problems:\r\n```\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n```\r\n\r\nBut with a DenseNet201 it doens't work well:\r\n```2020-11-18 10:47:56.014915: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 4.00G (4294967296 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory```\r\n", "Anyone solved this issue? I am getting same error\r\nRTX 3080\r\nCuda 11.1\r\nwindows 10\r\n\r\nI have cusolver64_11.dll but tf searches for cusolver64_10.dll !!", "solved by copying cusolver64_10.dll from cuda 10.1 to the bin folder of cuda 11.\r\nfor me at least\r\n\r\nalso the cuda handle error solved by\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n\r\nalso i use cudnn 8\r\nand tf 2.5", "Same here !!!!\r\n", "Install 2.4.0rc3 version with pip. The release note says tensorflow was builded with cuda 11 and cudnn 8.0.2.\r\n\r\n```\r\npip install tensorflow-gpu==2.4.0rc3\r\n```", "Please use CUDA 11.0 when using TF 2.4 (and nightly). We've built and tested against CUDA 11.0, not 11.1.", "> Please use CUDA 11.0 when using TF 2.4 (and nightly). We've built and tested against CUDA 11.0, not 11.1.\r\n\r\nInstallation of CUDA 10.2 solved the problem.", "> [CUDA 11.1 tf-nightly 2.5.0-dev20201111]\r\n> solved by renaming cusolver64_11.dll to cusolver64_10.dll\r\n\r\nit's help to me! thank you ", "On Windows10 with tensorflow 2.4.0 and cudnn 11.2 renaming **cusolver64_11.dll** to **cusolver64_10.dll** solved the issue.\r\n\r\nBut in this way other cuDNN dependent libraries may not work.", "I encountered the same problem on Windows 10 with:\r\n- CUDA Toolkit 11.1.2\r\n- Tensorflow 2.4.0\r\n- cuDNN 8.0.5\r\n\r\nI could solve it by downloading CUDA Toolkit 10.0.2, opening the archive and copying the missing file (cusolver64_10.dll) to the installation folder of CUDA Toolkit 11.1.2.\r\nThis seems to solve the problem for me.", "I have it working with:\r\n- CUDA Toolkit 11.0 (May 2020) (I didn't try update 1 August 2020 version)\r\n- Tensorflow 2.4.0\r\n- cuDNN 8.0.5\r\n\r\nI've tried:\r\n- CUDA Toolkit 11.2.0\r\n- CUDA Toolkit 11.1.1\r\n- CUDA Toolkit 11.1.0\r\nAll of them doesn't install cusolver64_10.dll but installed cusolver64_11.dll.", "> [CUDA 11.1 tf-nightly 2.5.0-dev20201111]\r\n> solved by renaming cusolver64_11.dll to cusolver64_10.dll\r\n\r\nWow! What a king!\r\n04/01/2021\r\nWorkingg", "> On Windows10 with tensorflow 2.4.0 and cudnn 11.2 renaming **cusolver64_11.dll** to **cusolver64_10.dll** solved the issue.\r\n> \r\n> But in this way other cuDNN dependent libraries may not work.\r\n\r\nThis works with tensorflow '2.5.0-dev20210107', cuda 11.2 and cudnn 11.1 for me.", "I am running into the same error with TF v2.4.0rc3 (`cusolver64_10.dll not found`). Unfortunately, compiling TF from source doesn't seem to be working either for me. ", "Renaming      cusolver64_11.dll        to        cusolver64_10.dll         also solved the issue for me.", "> I encountered the same problem on Windows 10 with:\r\n> \r\n> * CUDA Toolkit 11.1.2\r\n> * Tensorflow 2.4.0\r\n> * cuDNN 8.0.5\r\n> \r\n> I could solve it by downloading CUDA Toolkit 10.0.2, opening the archive and copying the missing file (cusolver64_10.dll) to the installation folder of CUDA Toolkit 11.1.2.\r\n> This seems to solve the problem for me.\r\n\r\nplease help me to locate it from instalation file.", "> I have it working with:\r\n> \r\n> * CUDA Toolkit 11.0 (May 2020) (I didn't try update 1 August 2020 version)\r\n> * Tensorflow 2.4.0\r\n> * cuDNN 8.0.5\r\n> \r\n> I've tried:\r\n> \r\n> * CUDA Toolkit 11.2.0\r\n> * CUDA Toolkit 11.1.1\r\n> * CUDA Toolkit 11.1.0\r\n>   All of them doesn't install cusolver64_10.dll but installed cusolver64_11.dll.\r\n\r\nThank you for this. This combination does indeed work.\r\n\r\nIn case anyone else experiences this - I was unable to download the CUDA toolkit 11.0 May release from the archives at https://developer.nvidia.com/cuda-11.0-download-archive due to Google Chrome blocking the download. Microsoft Edge worked. ", "Based on the rename answer above, in my cuda/bin folder I just copied the dll from 11 to 10, ie copy cusolver64_11.dll cusolver64_10.dll. \r\n\r\nThe full python stack is now working for me ie pandas, pandas-datareader, numpy, scikit-learn, matplotlib, tensorflow, sklearn etc. Please find attached my pip freeze, and as I started with a conda env to get my python 8.5 - I also attached a conda list.\r\n\r\n[T2.4_CUDA11.1_CUDNN8_Win10_pipfreeze.txt](https://github.com/tensorflow/tensorflow/files/5823548/T2.4_CUDA11.1_CUDNN8_Win10_pipfreeze.txt)\r\n[T2.4_CUDA11.1_CUDNN8_Win10_condalist.txt](https://github.com/tensorflow/tensorflow/files/5823549/T2.4_CUDA11.1_CUDNN8_Win10_condalist.txt)\r\n\r\n", "> [CUDA 11.1 tf-nightly 2.5.0-dev20201111]\r\n> solved by renaming cusolver64_11.dll to cusolver64_10.dll\r\n\r\ni also do it", "Does renaming the file cause any other bug?", "> [CUDA 11.1 tf-nightly 2.5.0-dev20201111]\r\n> solved by renaming cusolver64_11.dll to cusolver64_10.dll\r\n\r\nyou are a lifesaver, thank you", "> Renaming cusolver64_11.dll to cusolver64_10.dll also solved the issue for me.\r\n\r\nThis worked for me as well! ", "> > I encountered the same problem on Windows 10 with:\r\n> > \r\n> > * CUDA Toolkit 11.1.2\r\n> > * Tensorflow 2.4.0\r\n> > * cuDNN 8.0.5\r\n> > \r\n> > I could solve it by downloading CUDA Toolkit 10.0.2, opening the archive and copying the missing file (cusolver64_10.dll) to the installation folder of CUDA Toolkit 11.1.2.\r\n> > This seems to solve the problem for me.\r\n> \r\n> please help me to locate it from instalation file.\r\n\r\nI think in C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin scroll down to find cusolver files ", "> \r\n> \r\n> Renaming cusolver64_11.dll to cusolver64_10.dll also solved the issue for me.\r\n\r\nThis worked for me as well, I've been running into this same issue. Found the solution here: https://stackoverflow.com/questions/65608713/tensorflow-gpu-could-not-load-dynamic-library-cusolver64-10-dll-dlerror-cuso\r\n\r\nFor those looking, and happen to be using windows, these files are found here if you installed in the default locations: `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin` as @Nkcells mentions above. \r\n", "I wish the doc emphasized to install Cuda **_11.0_**, not newer version 11.1 or 11.2. Hit this problem with 11.1\r\n", "I had the same issue with TF2.4.1, cuda 11 and cudnn 8 and **solved it by copying the file `cusolver64_10.dll` from cuda 10 bin folder into cuda 11 bin folder** (for me dst folder was `Miniforge3\\envs\\py37-tf241\\Library\\bin` because I installed cuda 11 with conda).", "This worked for me as well! cusolver64_11.dll to cusolver64_10.dll", "https://www.youtube.com/watch?v=-Q6SM_usn84\r\n\r\n\r\nFirst time installing this, I have tried everything but didnt' work out\r\n\r\nwatch this video (link at top) and follow everything from beginning to the end\r\n\r\nthen it is NOT gonna work out.  However, like people have said here multiple times\r\n\r\njust Renaming { cusolver64_11.dll to cusolver64_10.dll }  will solve the problem\r\n \r\nWhy am I recommending this video?  because other videos or instructions ask you to do unnecessary steps such as doing \r\n\r\nsomething to visual studio which you don't really have to.", "For me this is working now with tf 2.5.0.", "@apurvakalia,\r\n\r\nCan you try building the latest nightly version using this [guide](https://www.tensorflow.org/install/source_windows) for windows, and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44291\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44291\">No</a>\n"]}, {"number": 44290, "title": "missing folder absl? ", "body": "As I see, there's a folder called absl which doesn't exist. For instance, this include won't work: #include \"absl/strings/str_join.h\" and a lot of missing file for C++\r\n\r\n", "comments": ["@CppProgrammer23 \r\n\r\nCan you please fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Please, elaborate the issue. Please, let us know which link you are referring to. Thanks!", "in this link: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/bfc_allocator.cc\r\nthat file contains an #include\"absl/strings/string_view.h\" but there's no folder in the repos called absl or even the string_view.h file", "@CppProgrammer23 Could you please refer to [**`link1`**](https://github.com/tensorflow/tensorflow/issues/22240) , [**`link2`**](https://github.com/lysukhin/tensorflow-object-detection-cpp/issues/5) and [**`comment`**](https://github.com/tensorflow/tensorflow/issues/22007#issuecomment-424553600) and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44290\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44290\">No</a>\n"]}, {"number": 44289, "title": "Converted TFLite model accuracy drop", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source): 2.3\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\ndef rep_data_gen():\r\n    f = \"/home/pychen/Datasets/VOCdevkit/VOC0712_TRAIN/ImageSets/train.txt\"\r\n    f_name = np.loadtxt(f, dtype = np.str).reshape(-1)\r\n    # print('Here', type(f_name))\r\n    # print(f_name)\r\n    NORM_H = 300\r\n    NORM_W = 300\r\n    for i in range(22136):\r\n        image = next(iter(f_name))\r\n        image = tf.io.read_file(img_dir + image + '.jpg')\r\n        image = tf.io.decode_jpeg(image, channels=3)\r\n        image = tf.image.resize(image, [NORM_H, NORM_W])\r\n        image = tf.cast(image / 255., tf.float32)\r\n        image = tf.expand_dims(image, 0)\r\n        yield [image]\r\n\r\nfrozen_graph='./tflite_graph.pb'\r\ninput_arrays=[\"normalized_input_image_tensor\"]\r\noutput_arrays=['TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3']\r\ninput_shapes={\"normalized_input_image_tensor\":[1,300,300,3]}\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(frozen_graph,input_arrays,output_arrays,input_shapes=input_shapes)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n# converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n\r\n# Float 16\r\n# converter.target_spec.supported_types = [tf.float16]\r\n\r\n# Float 16 activations with int8 weights\r\n# converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]\r\n\r\nconverter.representative_dataset=rep_data_gen\r\nconverter.allow_custom_ops=True\r\n\r\ntflite_quant_model = converter.convert()\r\n\r\n# Save the model.\r\nwith open('ssd_mobilenet_v1_voc0712_int8.tflite', 'wb') as f:\r\n    f.write(tflite_quant_model)\r\n```\r\n\r\n\r\n\r\n\r\nI trained a Mobilenet_ssd and converted it to a int8 quantized TFLite model by post-training quantization.\r\nBut the accuracy of int8 quantized TFLite model drop about 30% mAP for the Pascal VOC dataset.\r\nIs there any method to fine-tune or retrain the TFLite model?\r\nI tried the quantization-aware training, but quantization-aware training add FakeQuantWithMinMaxVars node unsupported by Arm NN.\r\n\r\nAnd can I just quantize the weight to int8 and activation still remain FP32?\r\n\r\nIf I just use converter.optimizations = [tf.lite.Optimize.DEFAULT], the model will be converted to uint8 or int8?\r\n\r\nWhat is the exact function of the following two commands?\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n\r\n\r\n\r\n\r\n", "comments": ["@ivs-pychen,\r\nOn running the code, I am facing an error stating `OSError: File './tflite_graph.pb' does not exist.`. \r\n\r\nCould you please provide the complete code and all the supporting files necessary to reproduce the issue reported here. Thanks!", "The following zip file is the code used to convert the pb to the tflite. But the dataset is too large to upload. The dataset is pascal voc.\r\n\r\n\r\n[code_pb.zip](https://github.com/tensorflow/tensorflow/files/5446542/code_pb.zip)\r\n[tflite_model.zip](https://github.com/tensorflow/tensorflow/files/5446545/tflite_model.zip)\r\n\r\nThe main problem I encountered is the model accuracy drop significantly. So, I want to know whether I can fine-tune the tflite model. \r\nAnd can I just quantize the weight to int8 and activation still remain FP32?\r\n\r\n", "@ivs-pychen This is a stale issue. Is this still an issue for you?\r\n\r\nAs there were lot of improvements since the issue opened, can you please try latest versions and let us know whether this is still an issue for you? As the accuracy dropped with `int8` model, did you try `float` model? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44289\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44289\">No</a>\n"]}, {"number": 44288, "title": "I had tried this code in Xcode with objective c but I am getting the error \"Explicit specialization of undeclared template struct 'NumTraits'", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["I want to convert opencv mat object to tensors but I am getting below error : - \r\n \"Explicit specialization of undeclared template struct 'NumTraits'\r\n\r\nI am using this code in objective c", "@disha1112 \r\nPlease share simple stand alone code such that we can replicate the issue or if possible share a colab gist with the error reported.", "![Screen Shot 2020-10-28 at 11 48 30 AM](https://user-images.githubusercontent.com/73386434/97402174-18263a00-1918-11eb-9b9e-53b3f259778f.png)\r\n\r\n\r\n@Saduf2019 Above is the screenshot of the code. Let me know will it work ?", "@disha1112 \r\nPlease paste the code/error message (using makrdown formatting around it) instead of screenshotting. Screenshots are not searchable so they don't help in looking for the issue and also don't help other people having the same error from finding about the issue.", "Hello @Saduf2019 \r\nhere is the error which shown in ss\r\n\"Explicit specialization of undeclared template struct 'NumTraits'\"\r\n\"No template named 'GenericNumTraits'\"\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44287, "title": "Heteregnous inference", "body": "I'm wondering if there is a procedure for inference calculation within a heterogeneous environment. The goal is to run graf inference as multiple its subgraph on the various processing unit (CPU, GPU). basically to split the inference workload across multiple CPUs, GPUs ... Is there any example or guide on how to do it?", "comments": ["Check https://www.tensorflow.org/tutorials/distribute/save_and_load?hl=en#the_tfsaved_model_api\r\nAnd the glossary at https://www.tensorflow.org/api_docs/python/tf/distribute\r\n", "@peter197321 \r\n\r\nPlease, see the [link](https://www.tensorflow.org/tutorials/distribute/save_and_load)  and see if it helps you.\r\n\r\nThis question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44286, "title": "What is I and W in tensorflow logs?", "body": "Recently I installed tensorflow 2.x on my PC and while importing I find the following logs. What does `I` and `W` mean in these logs that appear after the timestamp.\r\n\r\nInitially, I felt `I` is used to give a human touch to the machine (`W` meaning `We`). But it does not appear so. It would be really helpful If you could clarify what it actually means. I found the similar notations used in ONNX also. I guess it is some well known shortforms. But I really could not find it on google.\r\n\r\nI had always used tensorflow on Google Colab and AWS Cloud but never faced this.\r\n\r\n\r\n```bash\r\n2020-10-24 15:29:53.303267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-24 15:29:53.303299: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-10-24 15:29:53.303324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-10-24 15:29:53.303346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-10-24 15:29:53.303370: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-10-24 15:29:53.303394: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-10-24 15:29:53.303509: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\r\n```", "comments": ["I stands for information type of log. It just informs you that something happened\r\nW stands for warning type of log. It warns you that something didn't go as planned(in your case it wasn't able to load an dynamic library). It is not critical, but it can lead to some unexpected results(in your case, since it didn't find cudnn lib, operations will be performed on CPU instead of GPU, so it will take longer.\r\n\r\nThere is also E log type which stands for error. Well, error is something critical and means that something is not going well at all", "@Moldoteck is correct. Thanks for the answer!"]}, {"number": 44285, "title": "training keras Sequential model with python generator raise error: AttributeError: 'tuple' object has no attribute 'rank'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.3\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cu101\r\n- GPU model and memory: Quadro M6000 24G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nWhen training a Sequential model by fit function with python generator as inputs, it raise AttributeError: 'tuple' object has no attribute 'rank'. The python generator yield a tuple (x, y), which follows the tf document of fit function.\r\n\r\n**Describe the expected behavior**\r\nI want to know how to make it.\r\n\r\n**Standalone code to reproduce the issue**\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ntrain_time = pd.read_csv(\"./train.csv\")\r\ntrain = pd.read_csv(\"./train_v1.csv\")\r\nx_train = train[[\"year\", 'month', 'day', 'hour', 'label']]\r\ny_train = train['label']\r\ntest = pd.read_csv(\"./test_v1.csv\")\r\n\r\n\r\ndef train_dataset(x):\r\n    for i in range(0, len(x)):\r\n        if i < 23:\r\n            feature = x[[\"year\", 'month', 'day', 'hour', 'label']][0:i + 1]\r\n        else:\r\n            feature = x[[\"year\", 'month', 'day', 'hour', 'label']][i - 23:i + 1]\r\n        feature = np.asarray(feature)\r\n        feature[i, -1] = 0\r\n        yield tf.expand_dims(feature, 0), x[\"label\"][i]\r\n\r\n\r\ndef test_dataset(x):\r\n    for i in range(0, len(x)):\r\n        if i < 24:\r\n            yield tf.expand_dims(x[[\"year\", 'month', 'day', 'hour', 'label']][0:i], 0), 0\r\n        else:\r\n            yield tf.expand_dims(x[[\"year\", 'month', 'day', 'hour', 'label']][1 - 24:i], 0), 0\r\n\r\n\r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.LSTM(200, input_shape=[None, 5]))\r\nmodel.add(keras.layers.Dropout(0.3))\r\nmodel.add(keras.layers.Dense(100))\r\nmodel.add(keras.layers.Dense(1))\r\n\r\ntrain_generator = train_dataset(train)\r\ntest_generator = test_dataset(test)\r\nmodel.compile(loss=keras.losses.mean_absolute_error, metrics=keras.metrics.mean_absolute_error)\r\n\r\nmodel.fit(x=train_generator, y=None, epochs=100)\r\n\r\npre = model.predict(test_generator)\r\n\r\n**Other info / logs** \r\nTraceback (most recent call last):\r\n  File \"D:/code/competetion/railway station/model.py\", line 43, in <module>\r\n    model.fit(x=train_generator, y=None, epochs=100)\r\n  File \"C:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"C:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1063, in fit\r\n    steps_per_execution=self._steps_per_execution)\r\n  File \"C:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 1117, in __init__\r\n    model=model)\r\n  File \"C:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 805, in __init__\r\n    output_shapes = nest.map_structure(_get_dynamic_shape, peek)\r\n  File \"C:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 635, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"C:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 635, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"C:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 801, in _get_dynamic_shape\r\n    if shape.rank is None:\r\nAttributeError: 'tuple' object has no attribute 'rank'\r\n", "comments": ["@over-shine \r\nThe code provided has indentation issues,please share indented code or is possible share a colab gist with the error reported.", "```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ntrain = pd.read_csv(\"./train_v1.csv\")\r\nx_train = train[[\"year\", 'month', 'day', 'hour', 'label']]\r\ny_train = train['label']\r\ntest = pd.read_csv(\"./test_v1.csv\")\r\n\r\ndef train_dataset(x):\r\n    for i in range(0, len(x)):\r\n        if i < 23:\r\n            feature = x[[\"year\", 'month', 'day', 'hour', 'label']][0:i + 1]\r\n        else:\r\n            feature = x[[\"year\", 'month', 'day', 'hour', 'label']][i - 23:i + 1]\r\n        feature = np.asarray(feature)\r\n        feature[i, -1] = 0\r\n        yield tf.expand_dims(feature, 0), x[\"label\"][i]\r\n\r\ndef test_dataset(x):\r\n    for i in range(0, len(x)):\r\n        if i < 23:\r\n            yield tf.expand_dims(x[[\"year\", 'month', 'day', 'hour', 'label']][0:i], 0), 0\r\n        else:\r\n            yield tf.expand_dims(x[[\"year\", 'month', 'day', 'hour', 'label']][1 - 24:i], 0), 0\r\n\r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.LSTM(200, input_shape=[None, 5]))\r\nmodel.add(keras.layers.Dropout(0.3))\r\nmodel.add(keras.layers.Dense(100))\r\nmodel.add(keras.layers.Dense(1))\r\n\r\ntrain_generator = train_dataset(train)\r\ntest_generator = test_dataset(test)\r\nmodel.compile(loss=keras.losses.mean_absolute_error, metrics=keras.metrics.mean_absolute_error)\r\n\r\nmodel.fit(train_generator, epochs=100)\r\n\r\npre = model.predict(test_generator)\r\n```", "@over-shine \r\nPlease share all dependencies to replicate the issue, i ran the code and  face \"FileNotFoundError: [Errno 2] No such file or directory: './train.csv'\" error", "This is a part of train_v1.csv\r\n```csv\r\n,year,month,day,hour,label\r\n0,2012,8,25,0,8\r\n1,2012,8,25,1,2\r\n2,2012,8,25,2,6\r\n3,2012,8,25,3,2\r\n4,2012,8,25,4,2\r\n5,2012,8,25,5,2\r\n6,2012,8,25,6,2\r\n7,2012,8,25,7,2\r\n8,2012,8,25,8,6\r\n9,2012,8,25,9,2\r\n10,2012,8,25,10,2\r\n11,2012,8,25,11,6\r\n12,2012,8,25,12,4\r\n13,2012,8,25,13,2\r\n14,2012,8,25,14,6\r\n15,2012,8,25,15,2\r\n16,2012,8,25,16,2\r\n17,2012,8,25,17,2\r\n18,2012,8,25,18,2\r\n19,2012,8,25,19,2\r\n20,2012,8,25,20,2\r\n21,2012,8,25,21,6\r\n22,2012,8,25,22,2\r\n23,2012,8,25,23,2\r\n24,2012,8,26,0,4\r\n```\r\n\r\nThis is  a part of test_v1.csv\r\n```csv\r\n,year,month,day,hour,label\r\n0,2014,6,25,0,0\r\n1,2014,6,25,1,0\r\n2,2014,6,25,2,0\r\n3,2014,6,25,3,0\r\n4,2014,6,25,4,0\r\n5,2014,6,25,5,0\r\n6,2014,6,25,6,0\r\n7,2014,6,25,7,0\r\n8,2014,6,25,8,0\r\n9,2014,6,25,9,0\r\n10,2014,6,25,10,0\r\n11,2014,6,25,11,0\r\n12,2014,6,26,12,0\r\n13,2014,6,26,13,0\r\n14,2014,6,26,14,0\r\n15,2014,6,26,15,0\r\n16,2014,6,26,16,0\r\n17,2014,6,26,17,0\r\n18,2014,6,26,18,0\r\n19,2014,6,26,19,0\r\n20,2014,6,26,20,0\r\n21,2014,6,26,21,0\r\n22,2014,6,26,22,0\r\n23,2014,6,26,23,0\r\n24,2014,6,27,12,0\r\n25,2014,6,27,13,0\r\n26,2014,6,27,14,0\r\n27,2014,6,27,15,0\r\n28,2014,6,27,16,0\r\n29,2014,6,27,17,0\r\n30,2014,6,27,18,0\r\n31,2014,6,27,19,0\r\n32,2014,6,27,20,0\r\n33,2014,6,27,21,0\r\n34,2014,6,27,22,0\r\n35,2014,6,27,23,0\r\n```", "@ymodak \r\nI m able to replicate the issue faced, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/2b25ebedc984251f6ac76021c122b59d/untitled458.ipynb)", "So, how to deal it?", "> So, how to deal it?\r\n\r\nHi, I got the same error. Did you fix it?", "In my case, the issue lay with passing Pandas dataframes. In this case, it might be `expand_dims` giving you trouble.\r\n\r\nSee this:\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/engine/data_adapter.py#L1011-L1019\r\n\r\nAt that point, it's going to try to convert things to tensors. But it only checks for ndarrays and sparse arrays.\r\n\r\nFor some reason I can't find `gen_array_ops` in the repo, so I can't confirm, but I don't think `tf.expand_dims` is meant to take anything but tensors, so it might be generating unexpected results when it receives a numpy array.\r\n\r\nYou might try using numpy to expand your dimensions instead of tensorflow, and yielding numpy arrays instead of tensors.\r\n\r\n", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210528, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/68ae40894a34760320c15a277723cc5f/44285.ipynb). Thanks!", "Could you please refer to the solutions provided in these [1](https://stackoverflow.com/questions/62744659/) & [2](https://github.com/tensorflow/agents/issues/363) links and let us know the outcome of it. Thanks!", "The solution may be https://github.com/tensorflow/tensorflow/issues/44285#issuecomment-742885714", "If the below solution worked, could you please close the issue, Thanks!\r\n> The solution may be [#44285 (comment)](https://github.com/tensorflow/tensorflow/issues/44285#issuecomment-742885714)\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44285\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44285\">No</a>\n"]}, {"number": 44284, "title": "ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.", "body": "I am using python 3.7.2 and I have installed the packages required for a code but I have encountered an error while trying to run the code \r\nThis is what I received\r\n\r\n`Traceback (most recent call last):\r\n  File \"C:\\Users\\Future\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 6, in <module>\r\n    import cvlib as cv\r\n  File \"C:\\Users\\Future\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\cvlib\\__init__.py\", line 8, in <module>\r\n    from .gender_detection import detect_gender\r\n  File \"C:\\Users\\Future\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\cvlib\\gender_detection.py\", line 3, in <module>\r\n    from tensorflow.keras.utils import get_file\r\n  File \"C:\\Users\\Future\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Future\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\Future\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"C:\\Users\\Future\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Future\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Future\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.`\r\n\r\nHow can this be solved?", "comments": ["@KingTamo \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\n\r\nPlease, check Your CPU/Python is on 32 bits?\r\n\r\nPlease, refer duplicate issue #43130\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44284\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44284\">No</a>\n"]}, {"number": 44283, "title": "failed dnn implementation", "body": "import tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\r\nfrom sklearn import preprocessing\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import accuracy_score\r\nfrom yahoo_fin import stock_info as si\r\nfrom collections import deque\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport time\r\nimport os\r\nimport random\r\n\r\nset seed, so we can get the same results after rerunning several times\r\nnp.random.seed(314)\r\ntf.random.set_seed(314)\r\nrandom.seed(314)\r\n\r\nHyper-parameters\r\nimport os\r\nimport time\r\nfrom tensorflow.keras.layers import LSTM\r\n\r\nWindow size or the sequence length\r\nN_STEPS = 70\r\n\r\nLookup step, 1 is the next day\r\nLOOKUP_STEP = 1\r\n\r\ntest ratio size, 0.2 is 20%\r\nTEST_SIZE = 0.2\r\n\r\nfeatures to use\r\nFEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\r\n\r\ndate now\r\ndate_now = time.strftime(\"%Y-%m-%d\")\r\n\r\nmodel parameters\r\nN_LAYERS = 3\r\n\r\nLSTM cell\r\nCELL = LSTM\r\n\r\n256 LSTM neurons\r\nUNITS = 256\r\n\r\n40% dropout\r\nDROPOUT = 0.4\r\n\r\nwhether to use bidirectional RNNs\r\nBIDIRECTIONAL = False\r\n\r\ntraining parameters\r\nmean absolute error loss\r\nLOSS = \"mae\"\r\nhuber loss\r\nLOSS = \"huber_loss\"\r\nOPTIMIZER = \"adam\"\r\nBATCH_SIZE = 64\r\nEPOCHS = 400\r\n\r\nTesla stock market\r\nticker = \"TSLA\"\r\nticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\r\n\r\nmodel name to save, making it as unique as possible based on parameters\r\nmodel_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.name}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\r\nif BIDIRECTIONAL:\r\nmodel_name += \"-b\"\r\n\r\ndef load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1,\r\ntest_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\r\n\"\"\"\r\nLoads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\r\nParams:\r\nticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\r\nn_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\r\nscale (bool): whether to scale prices from 0 to 1, default is True\r\nshuffle (bool): whether to shuffle the data, default is True\r\nlookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\r\ntest_size (float): ratio for test data, default is 0.2 (20% testing data)\r\nfeature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\r\n\"\"\"\r\n# see if ticker is already a loaded stock from yahoo finance\r\nif isinstance(ticker, str):\r\n# load it from yahoo_fin library\r\ndf = si.get_data(ticker)\r\nelif isinstance(ticker, pd.DataFrame):\r\n# already loaded, use it directly\r\ndf = ticker\r\nelse:\r\nraise TypeError(\"ticker can be either a str or a pd.DataFrame instances\")\r\n\r\n# this will contain all the elements we want to return from this function\r\nresult = {}\r\n# we will also return the original dataframe itself\r\nresult['df'] = df.copy()\r\n\r\n# make sure that the passed feature_columns exist in the dataframe\r\nfor col in feature_columns:\r\n    assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\r\n\r\nif scale:\r\n    column_scaler = {}\r\n    # scale the data (prices) from 0 to 1\r\n    for column in feature_columns:\r\n        scaler = preprocessing.MinMaxScaler()\r\n        df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\r\n        column_scaler[column] = scaler\r\n\r\n    # add the MinMaxScaler instances to the result returned\r\n    result[\"column_scaler\"] = column_scaler\r\n\r\n# add the target column (label) by shifting by `lookup_step`\r\ndf['future'] = df['adjclose'].shift(-lookup_step)\r\n\r\n# last `lookup_step` columns contains NaN in future column\r\n# get them before droping NaNs\r\nlast_sequence = np.array(df[feature_columns].tail(lookup_step))\r\n\r\n# drop NaNs\r\ndf.dropna(inplace=True)\r\n\r\nsequence_data = []\r\nsequences = deque(maxlen=n_steps)\r\n\r\nfor entry, target in zip(df[feature_columns].values, df['future'].values):\r\n    sequences.append(entry)\r\n    if len(sequences) == n_steps:\r\n        sequence_data.append([np.array(sequences), target])\r\n\r\n# get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\r\n# for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\r\n# this last_sequence will be used to predict future stock prices not available in the dataset\r\nlast_sequence = list(sequences) + list(last_sequence)\r\nlast_sequence = np.array(last_sequence)\r\n# add to result\r\nresult['last_sequence'] = last_sequence\r\n\r\n# construct the X's and y's\r\nX, y = [], []\r\nfor seq, target in sequence_data:\r\n    X.append(seq)\r\n    y.append(target)\r\n\r\n# convert to numpy arrays\r\nX = np.array(X)\r\ny = np.array(y)\r\n\r\n# reshape X to fit the neural network\r\nX = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\r\n\r\n# split the dataset\r\nresult[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \r\n                                                                            test_size=test_size, shuffle=shuffle)\r\n# return the result\r\nreturn result\r\ndef create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\r\nloss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\r\nmodel = Sequential()\r\nfor i in range(n_layers):\r\nif i == 0:\r\n# first layer\r\nif bidirectional:\r\nmodel.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\r\nelse:\r\nmodel.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\r\nelif i == n_layers - 1:\r\n# last layer\r\nif bidirectional:\r\nmodel.add(Bidirectional(cell(units, return_sequences=False)))\r\nelse:\r\nmodel.add(cell(units, return_sequences=False))\r\nelse:\r\n# hidden layers\r\nif bidirectional:\r\nmodel.add(Bidirectional(cell(units, return_sequences=True)))\r\nelse:\r\nmodel.add(cell(units, return_sequences=True))\r\n# add dropout after each layer\r\nmodel.add(Dropout(dropout))\r\nmodel.add(Dense(1, activation=\"linear\"))\r\nmodel.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\r\nreturn model\r\n\r\ncreate these folders if they does not exist\r\nif not os.path.isdir(\"results\"):\r\nos.mkdir(\"results\")\r\n\r\nif not os.path.isdir(\"logs\"):\r\nos.mkdir(\"logs\")\r\n\r\nif not os.path.isdir(\"data\"):\r\nos.mkdir(\"data\")\r\n\r\nload the data\r\ndata = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\r\n\r\nsave the dataframe\r\ndata[\"df\"].to_csv(ticker_data_filename)\r\n\r\nconstruct the model\r\nmodel = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\r\ndropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\r\n\r\nsome tensorflow callbacks\r\ncheckpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\r\ntensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\r\n\r\nhistory = model.fit(data[\"X_train\"], data[\"y_train\"],\r\nbatch_size=BATCH_SIZE,\r\nepochs=EPOCHS,\r\nvalidation_data=(data[\"X_test\"], data[\"y_test\"]),\r\ncallbacks=[checkpointer, tensorboard],\r\nverbose=1)\r\n\r\nmodel.save(os.path.join(\"results\", model_name) + \".h5\")\r\n\r\ndef plot_graph(model, data):\r\ny_test = data[\"y_test\"]\r\nX_test = data[\"X_test\"]\r\ny_pred = model.predict(X_test)\r\ny_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\r\ny_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\r\nplt.plot(y_test[-200:], c='b')\r\nplt.plot(y_pred[-200:], c='r')\r\nplt.xlabel(\"Days\")\r\nplt.ylabel(\"Price\")\r\nplt.legend([\"Actual Price\", \"Predicted Price\"])\r\nplt.show()\r\n\r\ndef get_accuracy(model, data):\r\ny_test = data[\"y_test\"]\r\nX_test = data[\"X_test\"]\r\ny_pred = model.predict(X_test)\r\ny_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\r\ny_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\r\ny_pred = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_pred[LOOKUP_STEP:]))\r\ny_test = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_test[LOOKUP_STEP:]))\r\nreturn accuracy_score(y_test, y_pred)\r\n\r\ndef predict(model, data):\r\n# retrieve the last sequence from data\r\nlast_sequence = data[\"last_sequence\"][-N_STEPS:]\r\n# retrieve the column scalers\r\ncolumn_scaler = data[\"column_scaler\"]\r\n# reshape the last sequence\r\nlast_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\r\n# expand dimension\r\nlast_sequence = np.expand_dims(last_sequence, axis=0)\r\n# get the prediction (scaled from 0 to 1)\r\nprediction = model.predict(last_sequence)\r\n# get the price (by inverting the scaling)\r\npredicted_price = column_scaler[\"adjclose\"].inverse_transform(prediction)[0][0]\r\nreturn predicted_price\r\n\r\nload the optimal model weights\r\nmodel_path = os.path.join(\"results\", model_name) + \".h5\"\r\nmodel.load_weights(model_path)\r\n\r\nload the data with shuffle = False\r\ndata = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\r\nfeature_columns=FEATURE_COLUMNS, shuffle=False)\r\n\r\nevaluate the model\r\nmse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\r\n\r\ncalculate the mean absolute error (inverse scaling)\r\nmean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\r\nprint(\"Mean Absolute Error:\", mean_absolute_error)\r\n\r\npredict the future price\r\nfuture_price = predict(model, data)\r\nprint(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\r\nprint(\"Accuracy Score:\", get_accuracy(model, data))\r\nplot_graph(model, data)\r\n\r\nTHIS IS THE ERROR\r\nTrain on 2023 samples, validate on 506 samples\r\nEpoch 1/400\r\n64/2023 [..............................] - ETA: 2:51WARNING:tensorflow:Can save best model only with val_loss available, skipping.\r\nUnknownError Traceback (most recent call last)\r\nin\r\n28 validation_data=(data[\"X_test\"], data[\"y_test\"]),\r\n29 callbacks=[checkpointer, tensorboard],\r\n---> 30 verbose=1)\r\n31\r\n32 model.save(os.path.join(\"results\", model_name) + \".h5\")\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n817 max_queue_size=max_queue_size,\r\n818 workers=workers,\r\n--> 819 use_multiprocessing=use_multiprocessing)\r\n820\r\n821 def evaluate(self,\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n340 mode=ModeKeys.TRAIN,\r\n341 training_context=training_context,\r\n--> 342 total_epochs=epochs)\r\n343 cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n344\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n126 step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n127 try:\r\n--> 128 batch_outs = execution_function(iterator)\r\n129 except (StopIteration, errors.OutOfRangeError):\r\n130 # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in execution_function(input_fn)\r\n96 # numpy translates Tensors to values in Eager mode.\r\n97 return nest.map_structure(_non_none_constant_value,\r\n---> 98 distributed_function(input_fn))\r\n99\r\n100 return execution_function\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in call(self, *args, **kwds)\r\n566 xla_context.Exit()\r\n567 else:\r\n--> 568 result = self._call(*args, **kwds)\r\n569\r\n570 if tracing_count == self._get_tracing_count():\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n630 # Lifting succeeded, so variables are initialized and we can run the\r\n631 # stateless function.\r\n--> 632 return self._stateless_fn(*args, **kwds)\r\n633 else:\r\n634 canon_args, canon_kwds = \\\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in call(self, *args, **kwargs)\r\n2361 with self._lock:\r\n2362 graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 2363 return graph_function._filtered_call(args, kwargs) # pylint: disable=protected-access\r\n2364\r\n2365 @Property\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _filtered_call(self, args, kwargs)\r\n1609 if isinstance(t, (ops.Tensor,\r\n1610 resource_variable_ops.BaseResourceVariable))),\r\n-> 1611 self.captured_inputs)\r\n1612\r\n1613 def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n1690 # No tape is watching; skip to running the function.\r\n1691 return self._build_call_outputs(self._inference_function.call(\r\n-> 1692 ctx, args, cancellation_manager=cancellation_manager))\r\n1693 forward_backward = self._select_forward_and_backward_functions(\r\n1694 args,\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in call(self, ctx, args, cancellation_manager)\r\n543 inputs=args,\r\n544 attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 545 ctx=ctx)\r\n546 else:\r\n547 outputs = execute.execute_with_cancellation(\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n65 else:\r\n66 message = e.message\r\n---> 67 six.raise_from(core._status_to_exception(e.code, message), None)\r\n68 except TypeError as e:\r\n69 keras_symbolic_tensors = [\r\n\r\n~\\anaconda3\\envs\\gputest\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nUnknownError: [Derived] Fail to find the dnn implementation.\r\n[[{{node CudnnRNN}}]]\r\n[[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_distributed_function_7959]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function -> distributed_function", "comments": ["@rohan1090,\r\nIn order to expedite the trouble-shooting process, please provide the following details\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nAlso, share the Python script or the notebook you are running with all the indentation and formatting preserved, so that we can reproduce the issue on our end. Thanks!\r\n\r\nI tried formatting your code but not successfull. can you please update the [gist](https://colab.research.google.com/gist/jvishnuvardhan/3a1ca01c1bf5d6f41137730d7c60f83f/untitled.ipynb) attached here. Thanks!\r\n\r\nPossible root-cause: As mentioned in the error trace, there is something wrong with the validation data. Can you please check validation data for any possible root-cause?\r\n\r\n> 64/2023 [..............................] - ETA: 2:51WARNING:tensorflow:Can save best model only with val_loss available, skipping.\r\n> UnknownError Traceback (most recent call last)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44281, "title": "Mirrored Strategy CUDA_ERROR_ILLEGAL_ADDRESS", "body": "**System information**\r\nHave I written custom code: NO\r\nOS: Windows 10\r\nTensorflow Version: v2.3.0-54-gfcc4b966f1 2.3.1\r\nPython Version: Python 3.8.6\r\nCUDA/cuDNN version: 10.1/cudnn-10.1-windows10-x64-v7.6.5.32\r\nGPU model and memory: 2x GeForce RTX 2080 Ti 11GB\r\n\r\n**Describe the current behavior**\r\nTensorflow fails with the folllowing error:\r\n\r\n```\r\nError polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n```\r\nOnly see this error when executing using MirroredStrategy. Single GPU works just fine.\r\n\r\n**Describe the expected behavior**\r\nTensorflow should execute my code without any errors.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.applications import Xception\r\nimport numpy as np\r\n\r\nnum_samples = 1000\r\nheight = 224\r\nwidth = 224\r\nnum_classes = 1000\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    parallel_model = Xception(weights=None,\r\n                     input_shape=(height, width, 3),\r\n                     classes=num_classes)\r\n    parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n\r\n# Generate dummy data.\r\nx = np.random.random((num_samples, height, width, 3))\r\ny = np.random.random((num_samples, num_classes))\r\n\r\nparallel_model.summary()\r\nparallel_model.fit(x, y, epochs=20, batch_size=16) #batch_sized changed to 16\r\n```\r\n\r\n**Other info / logs** \r\n```\r\n2020-10-23 23:35:09.514415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:03:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-10-23 23:35:09.514583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:\r\npciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-10-23 23:35:09.514832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-23 23:35:09.518478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-23 23:35:09.521479: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-23 23:35:09.522718: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-10-23 23:35:09.526250: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-10-23 23:35:09.528215: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-10-23 23:35:09.536133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-23 23:35:09.536323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1\r\n2020-10-23 23:35:09.536813: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-23 23:35:09.546403: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14c16f08870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-10-23 23:35:09.546511: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-10-23 23:35:09.749996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:03:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-10-23 23:35:09.750156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:\r\npciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-10-23 23:35:09.750429: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-23 23:35:09.750544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-23 23:35:09.750639: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-23 23:35:09.750729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-10-23 23:35:09.750818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-10-23 23:35:09.750874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-10-23 23:35:09.750958: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-23 23:35:09.751069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1\r\n2020-10-23 23:35:10.440797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-10-23 23:35:10.440935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1\r\n2020-10-23 23:35:10.441179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N\r\n2020-10-23 23:35:10.441273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N\r\n2020-10-23 23:35:10.441592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9418 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:03:00.0, compute capability: 7.5)\r\n2020-10-23 23:35:10.442616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9419 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)\r\n2020-10-23 23:35:10.446257: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14c88a25f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-10-23 23:35:10.446360: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-10-23 23:35:10.446450: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-10-23 23:35:11.113923: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-23 23:35:11.114521: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:220] Unexpected Event status: 1\r\n```", "comments": ["@adstep \r\nCan you please refer to [this comment](https://github.com/tensorflow/tensorflow/issues/40814#issuecomment-663838196) and let us know if it helps.\r\n\r\nSimilar issues for reference:\r\n#41891 [link](https://github.com/tensorflow/tensorflow/issues/6509), [link1](https://stackoverflow.com/questions/60771063/tensorflow-reported-cuda-error-illegal-address-bug-while-train-yolo), please check if you have any [batch size related issue](https://forums.developer.nvidia.com/t/intermittent-cuda-error-illegal-address-error-on-ubuntu-18-04-with-tensorflow-2-2-0/127744/3)", "@Saduf2019 thanks for the response!\r\n\r\nI've tried the method in the suggested comment. \r\n\r\n```\r\nos.environ['TF_CUDNN_DETERMINISTIC']='1'\r\n\r\nrandom.seed(42)\r\nnp.random.seed(42)\r\ntf.random.set_seed(42)\r\n```\r\n\r\nI still experience the same error\r\n\r\n```\r\n2020-10-27 10:29:37.095946: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n```\r\n\r\n@Saduf2019 do you have an example working script that I can run on a multi-gpu to verify it works?", "Hi @adstep, I was able to run this example on GCP with two GPUs. I did not encounter any errors. \r\nSince I am unable to reproduce, I'm wondering if maybe there's an issue with one of your GPUs. Can you first run a test to make sure each GPU is functioning by running training with a single GPU at a time? If you have more than one GPU in your system, the GPU with the lowest ID will be selected by default, so you'll need to specify which GPU you want utilized. You can do that with `tf.config.set_visible_devices` to specify which devices are visible to the runtime. This experiment is to confirm that both GPUs are (independently) working fine.\r\n\r\nThe second thing to check is to try \r\n`strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())`\r\nthis is to check whether NCCL is causing problems.\r\n\r\n", "Hey @nikitamaia, I tried both of your suggestions.\r\n\r\nI ran the following code limiting it to a single GPU, as suggested, and validated both cards are working properly individually. I saw both cards load increase and use the entirety of the available memory. Ran the entire workload without issue.\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.applications import Xception\r\nimport numpy as np\r\nimport os\r\nimport random\r\n\r\nos.environ['TF_CUDNN_DETERMINISTIC']='1'\r\n\r\nrandom.seed(42)\r\nnp.random.seed(42)\r\ntf.random.set_seed(42)\r\n\r\nnum_samples = 1000\r\nheight = 224\r\nwidth = 224\r\nnum_classes = 1000\r\n\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.set_visible_devices(physical_devices[0:], 'GPU')\r\n\r\nparallel_model = Xception(weights=None,\r\n                    input_shape=(height, width, 3),\r\n                    classes=num_classes)\r\nparallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n\r\n# Generate dummy data.\r\nx = np.random.random((num_samples, height, width, 3))\r\ny = np.random.random((num_samples, num_classes))\r\n\r\nparallel_model.summary()\r\n# This `fit` call will be distributed on 8 GPUs.\r\n# Since the batch size is 256, each GPU will process 32 samples.\r\nparallel_model.fit(x, y, epochs=20, batch_size=16) #batch_sized changed to 16\r\n```\r\n\r\nAdditonally, I ran the MirroredStrategy with ReductionToOneDevice, as suggested, and experienced the same issue ```CUDA_ERROR_ILLEGAL_ADDRESS```.", "@nikitamaia any more ideas for what I can try? Is there any additional information I can provide?", "When you did the single GPU training, were you still using `MirroredStrategy`? The strategy should work even with a single GPU, so it's worth running that experiment with a strategy.\r\n\r\nCan you also try running the original code but with the default distribution strategy? Basically you would replace `tf.distribute.MirroredStrategy()` with  `tf.distribute.get_strategy()`.\r\n\r\nIt might also be worth testing out a different model other than Xception.", "@nikitamaia \r\n\r\nOriginally I didn't test using ```MirroredStrategy```. I re-reran the test using ```MirroredStrategy``` but limiting the visible GPUs. I tried a test limiting each GPU individually. Both tests worked fine.\r\n\r\nI replaced ```tf.distribute.MirroredStrategy()``` with ```tf.distribute.get_strategy()``` and re-ran the test with no limitations on visible GPUs, and didn't see the error. However, it was only using 1 of the 2 GPUs so I don't think it's doing the right thing.\r\n\r\nI have ran this on private models other than Xception and continue to see the same error when using ```MirroredStrategy```.", "Hi @adstep, sorry for the delayed response here. I'm having a difficult time thinking of how to debug since I cannot reproduce this issue. For a baseline, have you tried running the [simple distributed mnist example from the docs?](https://www.tensorflow.org/tutorials/distribute/keras)", "Hello I tried running the mnist example. Hitting a different issue with it.\r\n\r\nCode:\r\n```\r\n# Import TensorFlow and TensorFlow Datasets\r\n\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\n\r\nimport os\r\n\r\ndatasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\r\n\r\nmnist_train, mnist_test = datasets['train'], datasets['test']\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\nnum_train_examples = info.splits['train'].num_examples\r\nnum_test_examples = info.splits['test'].num_examples\r\n\r\nBUFFER_SIZE = 10000\r\n\r\nBATCH_SIZE_PER_REPLICA = 64\r\nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n\r\ndef scale(image, label):\r\n  image = tf.cast(image, tf.float32)\r\n  image /= 255\r\n\r\n  return image, label\r\n\r\ntrain_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\r\neval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\r\n\r\nwith strategy.scope():\r\n  model = tf.keras.Sequential([\r\n      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\r\n      tf.keras.layers.MaxPooling2D(),\r\n      tf.keras.layers.Flatten(),\r\n      tf.keras.layers.Dense(64, activation='relu'),\r\n      tf.keras.layers.Dense(10)\r\n  ])\r\n\r\n  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n                optimizer=tf.keras.optimizers.Adam(),\r\n                metrics=['accuracy'])\r\n\r\n# Define the checkpoint directory to store the checkpoints\r\n\r\ncheckpoint_dir = './training_checkpoints'\r\n# Name of the checkpoint files\r\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\r\n\r\n# Function for decaying the learning rate.\r\n# You can define any decay function you need.\r\ndef decay(epoch):\r\n  if epoch < 3:\r\n    return 1e-3\r\n  elif epoch >= 3 and epoch < 7:\r\n    return 1e-4\r\n  else:\r\n    return 1e-5\r\n\r\n# Callback for printing the LR at the end of each epoch.\r\nclass PrintLR(tf.keras.callbacks.Callback):\r\n  def on_epoch_end(self, epoch, logs=None):\r\n    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\r\n                                                      model.optimizer.lr.numpy()))\r\n\r\ncallbacks = [\r\n    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\r\n    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\r\n                                       save_weights_only=True),\r\n    tf.keras.callbacks.LearningRateScheduler(decay),\r\n    PrintLR()\r\n]\r\n\r\nmodel.fit(train_dataset, epochs=12, callbacks=callbacks)\r\n```\r\n\r\nStdout:\r\n```\r\n2020-11-19 15:17:18.070203: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-11-19 15:17:21.499802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-11-19 15:17:21.557219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:03:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-11-19 15:17:21.574089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \r\npciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-11-19 15:17:21.590150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-11-19 15:17:21.602893: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-11-19 15:17:21.615903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-11-19 15:17:21.627121: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-11-19 15:17:21.654699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-11-19 15:17:21.669031: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-11-19 15:17:21.689263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-11-19 15:17:21.703846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1\r\n2020-11-19 15:17:21.717343: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-19 15:17:21.761689: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1935a3ab900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-11-19 15:17:21.773593: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-11-19 15:17:22.063036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:03:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-11-19 15:17:22.084841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \r\npciBusID: 0000:04:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-11-19 15:17:22.112355: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-11-19 15:17:22.125436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-11-19 15:17:22.139006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-11-19 15:17:22.152512: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-11-19 15:17:22.166484: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-11-19 15:17:22.180377: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-11-19 15:17:22.194679: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-11-19 15:17:22.208581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1\r\n2020-11-19 15:17:22.923990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-11-19 15:17:22.932969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 \r\n2020-11-19 15:17:22.942861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N \r\n2020-11-19 15:17:22.952796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N \r\n2020-11-19 15:17:22.958146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9418 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:03:00.0, compute capability: 7.5)\r\n2020-11-19 15:17:22.997793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9419 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)\r\n2020-11-19 15:17:23.020132: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1938f7312f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-11-19 15:17:23.033983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-11-19 15:17:23.050604: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-11-19 15:17:25.049350: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\r\n2020-11-19 15:17:25.054777: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 2 GPUs\r\n2020-11-19 15:17:25.061183: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cupti64_101.dll'; dlerror: cupti64_101.dll not found\r\n2020-11-19 15:17:25.090233: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cupti.dll'; dlerror: cupti.dll not found\r\n2020-11-19 15:17:25.120624: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\r\nEpoch 1/12\r\nWARNING:tensorflow:From C:\\Users\\adstep\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Iterator.get_next_as_optional()` instead.\r\nWARNING:tensorflow:From C:\\Users\\adstep\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Iterator.get_next_as_optional()` instead.\r\n```\r\n\r\nStderr:\r\n```\r\nNo OpKernel was registered to support Op 'NcclAllReduce' used by {{node NcclAllReduce}} with these attrs: [reduction=\"sum\", shared_name=\"c1\", T=DT_FLOAT, num_devices=2]\r\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[NcclAllReduce]] [Op:__inference_train_function_2229]\r\n  File \"C:\\dev\\github\\dist_mnist\\run.py\", line 74, in <module>\r\n    model.fit(train_dataset, epochs=12, callbacks=callbacks)\r\n```", "I switched to using ```strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())``` based on recommendation from [this post](https://github.com/tensorflow/tensorflow/issues/33656#issuecomment-692710505). The code completes successfully now.", "Okay seems like your GPUs are working okay (although for better performance in the longer term you might want to look into getting NCCL on your system). The only real difference here is that the MNIST example is smaller than the Xception example. So for the Xception example, have you tried to limit memory growth? https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth\r\n\r\nOne other thing to try is using tf.data instead of passing numpy arrays to `model.fit`", "Hey I went back to my original example and ran it again. Now, I get the same error about ```Nccl```. Using the cross_device_ops workaround from above I was able to get my original example working. I haven't updated CUDN/tf/python since we last spoke, but I have went through a couple of Windows Updates, which I suspect might have been the issue.\r\n\r\nI'm not familiar with NCCL. I'm on Windows. Looking around it seems like it's not available for Windows. Is this the case?", "NCCL is the default `cross_device_ops` when using `MirroredStrategy`, but if you don't have NCCL on your system then you can use `HierarchicalCopyAllReduce` or `ReductionToOneDevice`. I suspect `ReductionToOneDevice` will be the better option for you since `HierarchicalCopyAllReduce` is really best for a particular configuration of GPUs. But you can try out both.\r\n\r\nAs far as NCCL on Windows, I unfortunately am not familiar with that. You might want to check out the NCCL github repo to get more information on a Windows setup.\r\n\r\nClosing this issue now because there is no bug present, and a workaround was found.", "I have the same error and find no way to solve it but turn down the `batch_size`, the error disappears automatically"]}, {"number": 44280, "title": "tensorflow.js have tf.nn.ctc_greedy_decoder?", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["@TSYHUB \r\n\r\nThis issue is more suitable for TFjs repo. Please post it on TFjs repo from [here](https://github.com/tensorflow/tfjs/issues/new). Thanks!"]}, {"number": 44279, "title": "Protobuf Installation Issue (?)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Fedora 32\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):  Source\r\n- TensorFlow version:  Master\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?:  N/A\r\n- Bazel version (if compiling from source):3.7\r\n- GCC/Compiler version (if compiling from source):  10.2.1\r\n- CUDA/cuDNN version:8\r\n- GPU model and memory: Titan XP 12 GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nBuild fails with the following error:\r\nERROR: /home/melrobin/.cache/bazel/_bazel_melrobin/f2116cf848eff0a1d187a7773c1fea53/external/com_google_protobuf/BUILD:155:11: C++ compilation of rule '@com_google_protobuf//:protobuf' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/external/com_google_protobuf/_objs/protobuf/descriptor_database.d ... (remaining 48 argument(s) skipped)\r\nccache: error: invalid size: D\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build --config=cuda  //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@melrobin,\r\nCould you please provide all the commands that you executed before running into the problem and the complete error log.\r\n\r\nAlso, if you're building TensorFlow from the master branch make sure you have CUDA 11 and cuDNN 8 installed. Thanks!", "OK I have CUDA 11 and cuDNN 8 installed.  I am using Bazel 3.7.0.  He is the command:\r\nbazel build --verbose_failures --config=cuda --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nHere is the latest error:\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (414 packages loaded, 35398 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /home/melrobin/.cache/bazel/_bazel_melrobin/f2116cf848eff0a1d187a7773c1fea53/external/com_google_protobuf/BUILD:110:11: C++ compilation of rule '@com_google_protobuf//:protobuf_lite' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\n  (cd /home/melrobin/.cache/bazel/_bazel_melrobin/f2116cf848eff0a1d187a7773c1fea53/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/lib:/usr/local/atlas/lib:/usr/local/lib:/opt/intel/lib/intel64_lin:/usr/local/protobuf/lib \\\r\n    PATH=/usr/share/Modules/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/melrobin/.local/bin:/home/melrobin/bin:/usr/local/cuda/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/external/com_google_protobuf/_objs/protobuf_lite/generated_enum_util.d '-frandom-seed=bazel-out/host/bin/external/com_google_protobuf/_objs/protobuf_lite/generated_enum_util.o' -iquote external/com_google_protobuf -iquote bazel-out/host/bin/external/com_google_protobuf -isystem external/com_google_protobuf/src -isystem bazel-out/host/bin/external/com_google_protobuf/src -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIE -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 -w '-march=native' -g0 '-std=c++14' -DHAVE_PTHREAD -DHAVE_ZLIB -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -Wno-write-strings -c external/com_google_protobuf/src/google/protobuf/generated_enum_util.cc -o bazel-out/host/bin/external/com_google_protobuf/_objs/protobuf_lite/generated_enum_util.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nccache: error: invalid size: D\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 10.589s, Critical Path: 0.12s\r\nINFO: 20 processes: 20 internal.\r\nFAILED: Build did NOT complete successfully\r\n", "TF will build by not to include CUDA support  I can then use the bazel command for CUDA support and still have access to the GPU.", "./configure has been run in this environment prior to the `bazel` call, correct?", "Yes I ran configure.  Not choosing CUDA allows a build. Choosing CUDA\nfails.\n\nOn Mon, Nov 9, 2020 at 6:03 PM Austin Anderson <notifications@github.com>\nwrote:\n\n> ./configure has been run in this environment prior to the bazel call,\n> correct?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/44279#issuecomment-724358545>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ACQ6BLFGAEBHYINM7BM25WDSPB7MBANCNFSM4S5KFH5Q>\n> .\n>\n", "Changed the GCC_HOST_PREFIX from /usr/bin/ccache to /usr/bin/gcc and this has fixed the problem.  ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44279\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44279\">No</a>\n"]}, {"number": 44278, "title": "Unexpected `snapshot` behaviour with `flat_map` in tf-nightly", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): '2.4.0-dev20201023'\r\n- Python version: 3.7.7\r\n\r\n**Describe the current behavior**\r\nA dataset formed by `flat_map`ping multiple snapshotted datasets which have each been iterated over individually (thus producing files on disk) results in a dataset which seemingly does not use those files on disk. This is different to the behaviour of `cache` in tf-2.3 and tf-nightly and `snapshot` in tf-2.3\r\n\r\n**Describe the expected behavior**\r\n`snapshot` to work equivalently in 2.3 as tf-nightly, and similarly to `cache`.\r\n\r\n**Standalone code to reproduce the issue**\r\nColab [here](https://colab.research.google.com/drive/13mXDdNKNg04MEDvFTwmQq0tAw8L0MY02?usp=sharing).\r\n\r\n```python\r\nimport os\r\nfrom tempfile import TemporaryDirectory\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef as_numpy(ds: tf.data.Dataset):\r\n    return np.array([x.numpy() for x in ds])\r\n\r\n\r\ndef get_data(\r\n    num_repeats=2,\r\n    snap=False,\r\n    preprocess_early=False,\r\n    preprocess_late=False,\r\n    del_rng=False,\r\n):\r\n    \"\"\"\r\n    Get numpy results from a data pipeline.\r\n\r\n    The pipeline looks like:\r\n        1. range\r\n        2. add stateful random noise\r\n        3. create `num_repeats` `cache`d or `snapshot`ted versions\r\n        4. `flat_map` if num_repeats > 1\r\n\r\n    Args:\r\n        num_repeats: number of duplicates created in step 3 above.\r\n        snap: use `snapshot` (otherwise use `cache`)\r\n        preprocess_early: if True, we iterate over individually cached / snapshotted\r\n            datasets prior to flat-mapping.\r\n        preprocess_late: if True, we iterate over the `flat_map`ped dataset\r\n        del_rng: if True, we delete the rng responsible for generating random noise in\r\n            step 2. This will cause an error if this map function is called again,\r\n            rather than using cached / snapshotted files on disk.\r\n\r\n    Returns:\r\n        Two iterations of the repeated dataset.\r\n    \"\"\"\r\n    rng = tf.random.Generator.from_seed(0)\r\n    dataset = tf.data.Dataset.range(10).map(\r\n        lambda x: tf.cast(x, tf.float32) + rng.uniform(())\r\n    )\r\n    with TemporaryDirectory() as tmp_dir:\r\n        paths = [os.path.join(tmp_dir, f\"repeat-{i}\") for i in range(num_repeats)]\r\n        if snap:\r\n            datasets = [\r\n                dataset.apply(tf.data.experimental.snapshot(path)) for path in paths\r\n            ]\r\n        else:\r\n            datasets = [dataset.cache(path) for path in paths]\r\n        if preprocess_early:\r\n            # iterate over datasets individually to force saving to file\r\n            for ds in datasets:\r\n                as_numpy(ds)\r\n        if num_repeats == 1:\r\n            (dataset,) = datasets\r\n        else:\r\n            dataset = tf.data.Dataset.from_tensor_slices(datasets).flat_map(lambda x: x)\r\n        if preprocess_late:\r\n            # iterate over concatenated dataset to force saving to file\r\n            as_numpy(dataset)\r\n        if del_rng:\r\n            # this will cause an error is the original mapped dataset is called\r\n            del rng\r\n        return as_numpy(dataset), as_numpy(dataset)\r\n\r\n\r\nclass SnapshotTest(tf.test.TestCase):\r\n    def test_consistent(self):\r\n        base0, base1 = get_data()\r\n        np.testing.assert_equal(base0, base1)\r\n\r\n    def test_reproducible(self):\r\n        base0, _ = get_data()\r\n        s0, s1 = get_data()\r\n        np.testing.assert_equal(s0, s1)\r\n        np.testing.assert_equal(s0, base0)\r\n\r\n    def test_snapshot(self):\r\n        base0, _ = get_data()\r\n        s0, s1 = get_data(snap=True)\r\n        np.testing.assert_equal(s0, s1)\r\n        np.testing.assert_equal(s0, base0)\r\n\r\n    def test_preprocess_late(self):\r\n        base0, _ = get_data()\r\n        s0, s1 = get_data(snap=True, preprocess_late=True)\r\n        np.testing.assert_equal(s0, s1)\r\n        np.testing.assert_equal(s0, base0)\r\n\r\n    def test_preprocess_late_del_rng(self):\r\n        base0, _ = get_data()\r\n        s0, s1 = get_data(snap=True, preprocess_late=True, del_rng=True)\r\n        np.testing.assert_equal(s0, s1)\r\n        np.testing.assert_equal(s0, base0)\r\n\r\n    def test_preprocess_early(self):\r\n        base0, _ = get_data()\r\n        s0, s1 = get_data(snap=True, preprocess_early=True)\r\n        np.testing.assert_equal(s0, s1)\r\n        np.testing.assert_equal(s0, base0)\r\n\r\n    def test_preprocess_early_del_rng(self):\r\n        base0, _ = get_data()\r\n        s0, s1 = get_data(snap=True, preprocess_early=True, del_rng=True)\r\n        np.testing.assert_equal(s0, s1)\r\n        np.testing.assert_equal(s0, base0)\r\n\r\n    def test_preprocess_no_repeats(self):\r\n        # preprocess_early is equivalent to preprocess_late here\r\n        base0, _ = get_data(num_repeats=1)\r\n        s0, s1 = get_data(snap=True, preprocess_early=True, num_repeats=1)\r\n        np.testing.assert_equal(s0, s1)\r\n        np.testing.assert_equal(s0, base0)\r\n\r\n    def test_preprocess_del_rng_no_repeats(self):\r\n        # preprocess_early is equivalent to preprocess_late here\r\n        base0, _ = get_data(num_repeats=1)\r\n        s0, s1 = get_data(snap=True, preprocess_early=True, num_repeats=1, del_rng=True)\r\n        np.testing.assert_equal(s0, s1)\r\n        np.testing.assert_equal(s0, base0)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.test.main()\r\n```\r\n\r\n**Other info / logs**\r\nFailed test output:\r\n```txt\r\n======================================================================\r\nERROR: test_preprocess_early_del_rng (__main__.SnapshotTest)\r\nSnapshotTest.test_preprocess_early_del_rng\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 2113, in execution_mode\r\n    yield\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 733, in _next_internal\r\n    output_shapes=self._flat_output_shapes)\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2579, in iterator_get_next\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 6862, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.NotFoundError: Resource localhost/_AnonymousVar6/N10tensorflow3VarE does not exist.\r\n\t [[{{node stateful_uniform/StatefulUniform}}]] [Op:IteratorGetNext]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"foob.py\", line 107, in test_preprocess_early_del_rng\r\n    s0, s1 = get_data(snap=True, preprocess_early=True, del_rng=True)\r\n  File \"foob.py\", line 67, in get_data\r\n    return as_numpy(dataset), as_numpy(dataset)\r\n  File \"foob.py\", line 9, in as_numpy\r\n    return np.array([x.numpy() for x in ds])\r\n  File \"foob.py\", line 9, in <listcomp>\r\n    return np.array([x.numpy() for x in ds])\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 747, in __next__\r\n    return self._next_internal()\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 739, in _next_internal\r\n    return structure.from_compatible_tensor_list(self._element_spec, ret)\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 2116, in execution_mode\r\n    executor_new.wait()\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\", line 69, in wait\r\n    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Resource localhost/_AnonymousVar6/N10tensorflow3VarE does not exist.\r\n\t [[{{node stateful_uniform/StatefulUniform}}]]\r\n\r\n======================================================================\r\nFAIL: test_preprocess_early (__main__.SnapshotTest)\r\nSnapshotTest.test_preprocess_early\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"foob.py\", line 103, in test_preprocess_early\r\n    np.testing.assert_equal(s0, base0)\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/numpy/testing/_private/utils.py\", line 342, in assert_equal\r\n    return assert_array_equal(actual, desired, err_msg, verbose)\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/numpy/testing/_private/utils.py\", line 931, in assert_array_equal\r\n    verbose=verbose, header='Arrays are not equal')\r\n  File \"/home/jackd/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/numpy/testing/_private/utils.py\", line 840, in assert_array_compare\r\n    raise AssertionError(msg)\r\nAssertionError: \r\nArrays are not equal\r\n\r\nMismatched elements: 20 / 20 (100%)\r\nMax absolute difference: 0.90819454\r\nMax relative difference: 1.9366292\r\n x: array([0.91562 , 1.45509 , 2.253555, 3.829305, 4.681193, 5.65526 ,\r\n       6.401854, 7.514806, 8.184864, 9.174181, 0.130606, 1.063369,\r\n       2.513922, 3.190604, 4.433053, 5.044663, 6.653943, 7.007094,\r\n       8.878403, 9.046815], dtype=float32)\r\n y: array([0.311793, 1.18098 , 2.761353, 3.138052, 4.027518, 5.460741,\r\n       6.235661, 7.175892, 8.786037, 9.549028, 0.860469, 1.631952,\r\n       2.669349, 3.255722, 4.884421, 5.066545, 6.267429, 7.34992 ,\r\n       8.16538 , 9.955009], dtype=float32)\r\n\r\n----------------------------------------------------------------------\r\nRan 10 tests in 0.849s\r\n\r\nFAILED (failures=1, errors=1, skipped=1)\r\n```\r\n", "comments": ["@ymodak \r\nI am able to replicate the issue reported,please find the [gist here](https://colab.research.google.com/gist/Saduf2019/919b0216f01d1b8d41444ee0f24b47f3/untitled453.ipynb).", "Hi @jackd, thank you for the thorough testing and reproduction details! I dug into the issue and found a couple behaviors that combined to cause this issue:\r\n\r\n1. Datasets passed through `flat_map` functions are not optimized before iterating over them.\r\n2. [This commit](https://github.com/tensorflow/tensorflow/commit/2e0c0b153a11b98f3e4e3c13adc31958268246b3) changed SnapshotDataset so that when the dataset is optimized, the dataset hash changes. This happens because the compression type gets changed/resolved from AUTO to SNAPPY, and compression type is included in the snapshot hash.\r\n\r\nI'm preparing a fix that will address both issues by always computing snapshot hashes based on the structure of the dataset before optimization.\r\n\r\nTo work around the issue in the short term, you could change the way you implement `preprocess_early` to use flat_map, like so:\r\n\r\n```python\r\nif preprocess_early:\r\n    # iterate over datasets individually to force saving to file\r\n    for ds in datasets:\r\n        as_numpy(tf.data.Dataset.from_tensors(ds).flat_map(lambda x: x))\r\n```", "This should be fixed now, right?\r\n\r\nPlease reopen if that is not the case.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44278\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44278\">No</a>\n"]}, {"number": 44277, "title": "NFC - minor spelling tweaks of documents under compiler directory", "body": "This PR addresses minor spelling tweaks of md/td files under compiler directory", "comments": []}, {"number": 44276, "title": "NFC - minor spelling tweaks of documents under lite directory", "body": "This PR addresses minor spelling tweaks of md files under `lite` directory", "comments": []}, {"number": 44275, "title": "Reverting xcode to 10.3 and adding MACOSX_DEPLOYMENT_TARGET to just n\u2026", "body": "\u2026onpip\r\n\r\nPiperOrigin-RevId: 338745176\r\nChange-Id: Ib241fbf2c40d2e9bbea70421f8e851af6de33c05", "comments": []}, {"number": 44274, "title": "Tensorflow dataset is not faster with multiple cores", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- Linux Ubuntu 18.04):\r\n- TensorFlow installed from Colab / AWS Deep Learning AMI\r\n- TensorFlow version 2.3.0\r\n- Python version 3.6\r\n- Bazel version N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nI am using tensorflow dataset to read multiple datasets in parallel. I am trying to use dataset.interleave(map_function, ...) with multiple cores to speed up reads. All of the example code I have seen uses time.sleep() to \"emulate\" a real workload in the map_function. When doing this the dataset runs faster with multiple cores. However, when the map_function has a real computational load (and not just a sleep function) using multiple cores has no improvement. \r\n\r\n**Describe the expected behavior**\r\nI expect that when I use multiple cores I will get a performance improvement when using a real workload in the map_function.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport time\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom multiprocessing import cpu_count\r\n        \r\ndef real_work():\r\n    for i in range(1000000):\r\n        2+2\r\n    \r\ndef sleep_delay():\r\n    time.sleep(.03)\r\n\r\ndef run_test(num_cores, delay):\r\n    def test_gen(k):\r\n        for i in range(10):\r\n            delay()\r\n            yield 0\r\n\r\n    class TestDataset(tf.data.Dataset):\r\n\r\n        def __new__(cls,k):\r\n            return tf.data.Dataset.from_generator(\r\n                test_gen,\r\n                output_types=((tf.dtypes.float32)),\r\n                output_shapes=((None)),\r\n                args=(k,)\r\n            )\r\n\r\n    def get_test_dataset(num_cores):\r\n\r\n        dataset = tf.data.Dataset.from_tensor_slices([str(f) for f in range(30)])\r\n        dataset = dataset.interleave(lambda k: TestDataset(k),\r\n                                cycle_length=num_cores,\r\n                                num_parallel_calls=num_cores, #tf.data.experimental.AUTOTUNE,\r\n                                block_length=1,\r\n                                deterministic=False)\r\n        dataset = dataset.prefetch(100)\r\n        return dataset\r\n\r\n    it = get_test_dataset(num_cores).as_numpy_iterator()\r\n\r\n    for i in it:\r\n        continue\r\n\r\nn_cpus = cpu_count()\r\n\r\nprint('\\n 1 core, sleep delay')\r\n%time run_test(1,sleep_delay)\r\n\r\nprint(f'\\n {n_cpus} core, sleep delay')\r\n%time run_test(n_cpus,sleep_delay)\r\n\r\nprint('\\n 1 core, real_work')\r\n%time run_test(1,real_work)\r\n\r\nprint(f'\\n {n_cpus} core, real_work')\r\n%time run_test(n_cpus,real_work)\r\n```\r\n\r\n\r\n** OUTPUT **\r\n 1 core, sleep delay\r\nCPU times: user 259 ms, sys: 11 ms, total: 270 ms\r\nWall time: 6.55 s\r\n\r\n 4 core, sleep delay\r\nCPU times: user 276 ms, sys: 11.3 ms, total: 287 ms\r\nWall time: 1.94 s\r\n\r\n 1 core, real_work\r\nCPU times: user 7.55 s, sys: 4.67 ms, total: 7.55 s\r\nWall time: 7.42 s\r\n\r\n 4 core, real_work\r\nCPU times: user 7.87 s, sys: 1.8 ms, total: 7.87 s\r\nWall time: 7.61 s\r\n\r\nAs can be seen the sleep delay system works as intended but with a real workload multicore has no impact.\r\n\r\nhere is a colab link: \r\nhttps://colab.research.google.com/drive/1hqxHWK4cxD-ja8kV33LM56z6uxPthsjo?usp=sharing\r\n", "comments": ["I have tried in colab with TF version 2.3, nightly version (`2.5.0-dev20201026`)and was able to reproduce the issue.Please,find the gist [here](https://colab.research.google.com/gist/ravikyram/c84c40dd216db48b3c7bbdb02c902b90/untitled87.ipynb?authuser=1). Thanks!", "This is due to contention on the Python Global Interpreter Lock. `real_work` can't be run from multiple cores because it holds the lock. To avoid this, you can define your computation using TensorFlow ops. Then the computation will be executed in C++, where it can use multiple cores. [This colab](https://colab.research.google.com/drive/1cLk-G8P1dNOajKy0RKBHDVA50jf5qC8I) demonstrates some speedup from using multiple cores for a compute-intensive dataset.", "Thank you. This is helpful. Unfortunately the code that I am working with is not easily converted to tensorflow ops. What I would like is some sort of generator that works in parallel in python and takes advantage of multiple cores. Basically I want to be able to do something like:\r\n\r\npreds = []\r\nfor b in generator:\r\n    preds.append(model(b))\r\n\r\nwhere the generator uses multiprocessing in python the use all cores. Does something like this exists in the tensorflow library or is there no way to parallelize python functions for input?", "There isn't a way to use multiple processes to call a Python generator function faster. If performance is important, I suggest investing the effort into representing the preprocessing with TensorFlow ops, so that the preprocessing can be optimized and parallelized.", "Hi @seankerman ! Did you check with above [suggestion](https://github.com/tensorflow/tensorflow/issues/44274#issuecomment-719770863) yet?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}]