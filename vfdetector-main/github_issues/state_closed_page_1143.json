[{"number": 18923, "title": "Missing Numerous models in TF-Slim from Tensorflow/models", "body": "Hello dear friends,\r\n\r\nIf you have a look to: [tensorflow/tensorflow =>/tensorflow/contrib/slim/python/slim/nets](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim/python/slim/nets), you may notice that numerous models are missing:\r\n\r\n* cifarnet.py\r\n* cyclegan.py\r\n* dcgan.py\r\n* inception_resnet_v2.py\r\n* lenet.py\r\n* mobilenet_v1.py\r\n* pix2pix.py\r\n* nasnet/nasnet.py\r\n* nasnet/pnasnet.py\r\n* mobilenet/mobilenet.py  # Might be redundant with mobilenet_v1.py\r\n* mobilenet/mobilenet_v2.py\r\n\r\nAll of them are available here : [tensorflow/models =>/research/slim/nets](https://github.com/tensorflow/models/tree/master/research/slim/nets)\r\n\r\nWhy some of them are given with TF and not the others ?\r\n\r\nHave a nice day,\r\n\r\nJonathan", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "tensorflow/models is the right place for models. We are aiming not to include any in TF in the medium term."]}, {"number": 18922, "title": "Why the leaky_relu is better\uff1f", "body": "\r\ndef lrelu(x, leak=0.2, name=\"lrelu\"):\r\n     with tf.variable_scope(name):\r\n         f1 = 0.5 * (1 + leak)\r\n         f2 = 0.5 * (1 - leak)\r\n         return f1 * x + f2 * abs(x)\r\n\r\nI don't know why is better than tf.maximum(0.2*x,x)\r\nCould someone tell me why?\r\nI really want to know.", "comments": ["This is not the place for this question. Please close the issue and go to StackOverflow or StackExchange."]}, {"number": 18921, "title": "Resume checkpoint problem. Question in stackoverflow no answer", "body": "I want to restore model parameters in the checkpoint file.\r\nBut I found\r\n`NotFoundError (see above for traceback): Key wavenet/dilated_stack/layer10/gc_filter not found in checkpoint\r\n`\r\n\r\nI tried to read the model parameters, but found that I could not read it. The error was strange. I couldn't find the same error on google. I didn't seem to be able to do anything about it.\r\n\r\n```\r\nUnimplementedError Traceback (most recent call last)\r\n<ipython-input-21-bef7e856f26a> in <module>()\r\n\u00a0\u00a0\u00a0\u00a0\u00a010 for key in (var_to_shape_map):\r\n\u00a0\u00a0\u00a0\u00a0\u00a011 print(\"tensor_name: \", key)\r\n---> 12 print(reader.get_tensor(key))\r\n\r\n~/PSnet/env/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py in get_tensor(self, tensor_str)\r\n\u00a0\u00a0\u00a0\u00a0144 from tensorflow.python.util import compat\r\n\u00a0\u00a0\u00a0\u00a0145 return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\r\n--> 146 status)\r\n\u00a0\u00a0\u00a0\u00a0147\r\n\u00a0\u00a0\u00a0\u00a0148 CheckpointReader_swigregister = _pywrap_tensorflow.CheckpointReader_swigregister\r\n\r\n/usr/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)\r\n\u00a0\u00a0\u00a0\u00a0\u00a064 if type is None:\r\n\u00a0\u00a0\u00a0\u00a0\u00a065 try:\r\n---> 66 next(self.gen)\r\n\u00a0\u00a0\u00a0\u00a0\u00a067 except StopIteration:\r\n\u00a0\u00a0\u00a0\u00a0\u00a068 return\r\n\r\n~/PSnet/env/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\r\n\u00a0\u00a0\u00a0\u00a0464 None, None,\r\n\u00a0\u00a0\u00a0\u00a0465 compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 466 pywrap_tensorflow.TF_GetCode(status))\r\n\u00a0\u00a0\u00a0\u00a0467 finally:\r\n\u00a0\u00a0\u00a0\u00a0468 pywrap_tensorflow.TF_DeleteStatus(status)\r\n\r\nUnimplementedError: Unsupported tf type half\r\n```", "comments": ["I use \r\n- **OS Platform and Distribution (Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (binary)**:\r\n- **TensorFlow version (1.0.1)**:\r\n- **Python version**: 3.52\r\n- **CUDA/cuDNN version**: 8.0/5.0\r\n- **GPU model and memory**:GTX1070/8G\r\n\r\n", "Please keep in mind that the TensorFlow GitHub Issues page is for tracking bugs and feature requests. It is not a way to escalate a Stack Overflow support question that is not getting enough attention. Thanks!", "@reedwm \r\nI was thinking that this is not a bug\uff1f what I describe is not clear enough. How should this problem be described\r\n", "Can you clarify exactly what the issue is and how to reproduce it? What model are you trying to restore? How did you get the checkpoint? ", "\r\n> \r\n> \r\n> @reedwm\r\n> I was thinking that this is not a bug\uff1f what I describe is not clear enough. How should this problem be described\r\n\r\nHi, were you able to solve this issue?\r\nI have a similar problem to you.\r\nwhen i run \r\n`pywrap_tensorflow.get_tensor`\r\nmy code will exit on \r\n`def CheckpointReader_GetTensor(reader, name):`\r\n\r\n```\r\nC:\\public\\study\\anaconda\\python.exe \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2020.1.1\\plugins\\python-ce\\helpers\\pydev\\pydevd.py\" --multiproc --qt-support=auto --client 127.0.0.1 --port 14962 --file C:/public/study/workplace/github/bert4keras/examples/task_conditional_language_model.py\r\npydev debugger: process 12012 is connecting\r\n\r\nConnected to pydev debugger (build 201.7223.92)\r\n2020-05-14 20:22:41.263616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\nUsing TensorFlow backend.\r\n2020-05-14 20:31:06.067683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-05-14 20:31:06.096301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.815\r\npciBusID: 0000:01:00.0\r\n2020-05-14 20:31:06.096527: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-05-14 20:31:06.096909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-05-14 20:31:06.097213: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-05-14 20:31:06.099160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.815\r\npciBusID: 0000:01:00.0\r\n2020-05-14 20:31:06.099380: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-05-14 20:31:06.099778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-05-14 20:31:06.549633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-05-14 20:31:06.549771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2020-05-14 20:31:06.549820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2020-05-14 20:31:06.550325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6283 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n\r\nProcess finished with exit code -1073741819 (0xC0000005)\r\n```\r\nwin10 2070super tf 2.0  cuda 10.0 cudnn 7.4.2 vs2019 vs2015", "Opening a new Github issue or asking on StackOverflow would be best, especially considering the error is different. If you do so, please give a code sample to reproduce the issue."]}, {"number": 18920, "title": "Feature request: Gradient for number of loop iterations for automatic differentiation of physics simulations", "body": "## System information\r\n**Not relevant.**\r\n\r\nHave I written custom code **yes**\r\nOS Platform and Distribution **different linux systems**\r\nTensorFlow installed from **source and pip** (on different systems)\r\nTensorFlow version **different versions, all >= 1.5.0**\r\nBazel version **different versions on different systems**\r\nCUDA/cuDNN version **different versions, all >= 8**\r\nGPU model and memory **GTX 1080, GTX 1060, Tesla P40** (potentially many others on our cluster, but not tested yet)\r\nExact command to reproduce **run [bug_test.py](https://github.com/AlexHarn/tf-ice-model-optimization/blob/1a9f9e11d55277bd595266410bf10a54bbd8b5f0/bug_test.py)**\r\n\r\n## Describe the problem\r\n### Motivation\r\n(you might want to skip this)\r\nTensorflow is a powerful framework that can potentially be used for much more than static computations like those needed to train neural networks. We (a couple of physicists) are trying to use Tensorflow to get a gradient on some physical parameters to fit those parameters to measured data by propagating the gradient through the entire physics simulation to replicate the data. This is extremely relevant for a lot of people and the idea is not new.  Instead of performing extremely time consuming (in terms of computational and human work time) grid searches on high dimensional parameter spaces we would like to be able to directly perform gradient descent on such spaces in an automated fashion by using Tensorflows automatic differentiation. You can find our work in progress repository [here](https://github.com/AlexHarn/tf-ice-model-optimization).\r\n\r\n### The Problem\r\nLike explicitly stated [here](http://download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf) on page 15 \"This means that we assume that `pred` is not trainable\", the number of loop iterations is just a constant while backpropagating the gradient. This leads to some extremely unexpected behavior like described in this [issue](https://github.com/AlexHarn/tf-ice-model-optimization/issues/1) (at least unexpected for someone who is a Tensorflow newbie like I am). For our plans to work it is mandatory for the gradient to include information on how the number of loop iterations would have changed, if the trainable variables changed. \r\n\r\n### Example\r\n(You might want to skip this)\r\nIn our project we have a trainable variable, which describes the mean distance between scattering events of photons. Tensorflow is able to propagate the gradient through the simulation (while loop), but the gradient only \"thinks\" that the photons will reach further points when the scattering length is longer, but \"is not aware\" of the fact that there will be less iterations. \r\n\r\n### Request\r\nI do not know if this is even possible with how Tensorflow works, but we would love to see a way to make this work. Tensorflow would be a really great tool for us to use. So is this something you might work on in the future? \r\n\r\nAlso: does anyone maybe have any idea of how to solve or get around this right now with the current implementation? We have put quite some thought into this ourselves already, but until now we have not found a working solution.\r\n\r\n## Source code\r\nFor a work in progress example of how this would be useful you can take a look at the [master](https://github.com/AlexHarn/tf-ice-model-optimization) and [experimental](https://github.com/AlexHarn/tf-ice-model-optimization/tree/experimental) branches of our repo. \r\n\r\nFor a stripped down minimal one dimensional example of the simulation you can take a look at [minimal_1d.py](https://github.com/AlexHarn/tf-ice-model-optimization/blob/gradient-sign-bug/minimal_1d.py), this in its current state however actually converges. For some more information on the unexpected behavior take a look at my [issue](https://github.com/AlexHarn/tf-ice-model-optimization/issues/1) where I reference commits, which demonstrate what's happening.\r\n\r\nA minimal example, which does not include any physics and purely demonstrates the unexpected behavior is given [here](https://github.com/AlexHarn/tf-ice-model-optimization/blob/1a9f9e11d55277bd595266410bf10a54bbd8b5f0/bug_test.py).\r\n\r\nAll of the code includes detailed comments. \r\n\r\nIf you are interested in the background and general idea you can take a look at my [slides](https://drive.google.com/file/d/17WdIcpIzFDZmQvD-DCqonmDvz_S0-Arz/view?usp=sharing), even though I am not sure how much of a help those will be for someone from outside. Slides 5 to 8 might be helpful for everyone though. Especially slide 5 which shows how we fit the data using simulations. For the general concept testing right now the data is also given by the same simulation with \"true\" parameters.\r\n\r\nWe really hope to get some form of feedback here and I am sorry if this is a trivial or stupid request in the eyes of someone more experienced with Tensorflow.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I added system information, even though that should not be relevant.", "@alextp, do you think this might be possible with eager? That seems like the best option to me. That allows you to do control flow in python rather than TensorFlow and it does automatic differentiation with a gradient tape (log of operations run in imediate mode). @AlexHarn, does this make sense?", "I think what you want is very reasonable, but you need different math than plain gradients. Once you do move beyond gradients the many known approaches to this are well-supported by TensorFlow.\r\n\r\nThe problem lies in (hopefully) continuous functions which are not differentiable everywhere. Anytime you have control flow in a program you have a function which, though it might be continuous, is not guaranteed to have a derivative everywhere. For example, the function f(x) defined by f(x) = x^2 for x < 0, f(x) = x otherwise is continuous, but has no derivative at the change point (0). What it can have is a directional derivative or a subgradient, which is what TensorFlow computes.\r\n\r\nIf you think about it, by the definition of derivatives (epsilons and deltas, etc) if you make a small change to a number used in a predicate to decide the number of iterations in a loop the number of iterations will not change (for sufficiently small epsilon). There is only a set of measure zero of settings which will change the number of iterations.\r\n\r\nSo if you want to optimize something which involves the number of iterations you need some other method. A popular one is to define auxiliary losses in your training problem (for example, make the probability of stopping at this loop iteration a function of some parameters, and then add a term to your loss function which maximizes this probability; this will encourage the model to stop earlier). A generalization of this is to write a differentiable upper bound on your number of iterations which you can then optimize. Work like [adaptive computation time rnns](https://arxiv.org/abs/1603.08983) is based on this upper-bound approach.\r\n\r\nAnother way of dealing with this non-differentiability is to simply pretend things are differentiable and not use a bound. For example, [bengio](https://arxiv.org/abs/1308.3432) shows that in many cases you can approximate the \"gradient\" of a step function by pretending that the step function isn't there (the staight through estimator).\r\n\r\nFinally, approaches such as policy gradient and the REINFORCE algorithm (many sources on the internet; I like [Sergey Levine's slides](http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_4_policy_gradient.pdf)) are a general (and so slow) way of optimizing these functions;  you can use them to approximate gradients to change your number of loop iterations.\r\n\r\nAll of these approaches can be (and have been) implemented in TensorFlow, but none of them is just computing gradients. Because it requires some thought to decide what you should do we remain agnostic."]}, {"number": 18919, "title": "Tf lite: Array activation1, which is an input to the Div operator producing the output array dropout/div, is lacking min/max data", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS X High Sierra\r\n- **TensorFlow version (use command below)**: 1.8.0rc1\r\n- **Python version**: 3.5\r\n\r\nI'm trying to save a very simple NN model to tflite format, with weight quantization, following this documentation: https://www.tensorflow.org/performance/quantization.\r\n\r\nHowever, when converting with toco, I get this error:\r\n\r\nArray Relu, which is an input to the Div operator producing the output array dropout/div, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\\n\"\r\n\r\nThis is the graph:\r\n\r\n![image](https://user-images.githubusercontent.com/8360740/39358075-28e18702-4a15-11e8-82de-8f2d705b1f78.png)\r\n\r\nThe code to reproduce:\r\n\r\n```\r\n    inputs = tf.placeholder(tf.float32, shape=(1, train_X.shape[1]), name='inputs')\r\n    label = tf.placeholder(tf.float32, shape=(1, num_classes), name='labels')\r\n\r\n    # First layer\r\n    hid1_size = 128\r\n    w1 = tf.Variable(tf.random_normal([hid1_size, train_X.shape[1]], stddev=0.01), name='w1')\r\n    b1 = tf.Variable(tf.constant(0.1, shape=(hid1_size, 1)), name='b1')\r\n    y1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(inputs)), b1, name=\"layer1\"), \"activation1\"),\r\n                       keep_prob=0.5)\r\n\r\n    # Second layer\r\n    hid2_size = 256\r\n    w2 = tf.Variable(tf.random_normal([hid2_size, hid1_size], stddev=0.01), name='w2')\r\n    b2 = tf.Variable(tf.constant(0.1, shape=(hid2_size, 1)), name='b2')\r\n    y2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w2, y1), b2, name=\"layer2\"), name=\"activation2\"), keep_prob=0.5)\r\n\r\n    # Output layer\r\n    wo = tf.Variable(tf.random_normal([num_classes, hid2_size], stddev=0.01), name='wo')\r\n    bo = tf.Variable(tf.random_normal([num_classes, 1]), name='bo')\r\n    yo = tf.transpose(tf.add(tf.matmul(wo, y2), bo), name=\"logits\")\r\n\r\n    # Loss function and optimizer\r\n    lr = tf.placeholder(tf.float32, shape=(), name='learning_rate')\r\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=yo, labels=label), name=\"loss\")\r\n\r\n    # Call the training rewrite which rewrites the graph in-place with\r\n    # FakeQuantization nodes and folds batchnorm for training. It is\r\n    # often needed to fine tune a floating point model for quantization\r\n    # with this training tool. When training from scratch, quant_delay\r\n    # can be used to activate quantization after training to converge\r\n    # with the float graph, effectively fine-tuning the model.\r\n    #tf.contrib.quantize.create_training_graph(quant_delay=3)\r\n\r\n    optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\r\n\r\n    # Prediction\r\n    pred = tf.nn.softmax(yo, name=\"prediction\")\r\n    pred_label = tf.argmax(pred, 1)\r\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(label, 1))\r\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\r\n\r\n    # Create operation which will initialize all variables\r\n    init = tf.global_variables_initializer()\r\n\r\n    # Configure GPU not to use all memory\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n\r\n    # Start a new tensorflow session and initialize variables\r\n    sess = tf.InteractiveSession(config=config)\r\n\r\n    writer = tf.summary.FileWriter(\"tensorboard\", sess.graph)\r\n\r\n    sess.run(init)\r\n\r\n    # This is the main training loop: we train for 50 epochs with a learning rate of 0.05 and another\r\n    # 50 epochs with a smaller learning rate of 0.01\r\n    for learning_rate in [0.05, 0.01]:\r\n        for epoch in range(50):\r\n            avg_cost = 0.0\r\n\r\n            # For each epoch, we go through all the samples we have.\r\n            for i in range(train_X.shape[0]):\r\n                # Finally, this is where the magic happens: run our optimizer, feed the current example into X and the current target into Y\r\n                _, c = sess.run([optimizer, loss], feed_dict={lr: learning_rate,\r\n                                                              inputs: train_X[i, None],\r\n                                                              label: train_y[i, None]})\r\n                avg_cost += c\r\n            avg_cost /= train_X.shape[0]\r\n\r\n            # Print the cost in this epcho to the console.\r\n            if epoch % 10 == 0:\r\n                print(\"Epoch: {:3d}    Train Cost: {:.4f}\".format(epoch, avg_cost))\r\n\r\n    # Call the eval rewrite which rewrites the graph in-place with\r\n    # FakeQuantization nodes and fold batchnorm for eval.\r\n    #tf.contrib.quantize.create_eval_graph()\r\n\r\n    writer.close()\r\n\r\n    graph_path = os.path.join(\"models\", \"model.pbtxt\")\r\n    checkpoint_path = os.path.join(\"models\", \"model.ckpt\")\r\n\r\n    # Save the checkpoint and eval graph proto to disk for freezing and providing to TFLite.\r\n    with open(graph_path, 'w') as f:\r\n        f.write(str(sess.graph.as_graph_def()))\r\n\r\n    saver = tf.train.Saver()\r\n    saver.save(sess, checkpoint_path)\r\n\r\n    frozen_graphdef = tf.graph_util.convert_variables_to_constants(\r\n        sess, sess.graph_def, [\"prediction\"])\r\n    open(\"models/frozen_model.pb\", \"w\").write(str(frozen_graphdef))\r\n\r\n    tflite_model = tf.contrib.lite.toco_convert(\r\n        frozen_graphdef, [inputs], [pred], inference_type=tf.contrib.lite.QUANTIZED_UINT8,\r\n        quantized_input_stats=[(127.5, 127.5)])\r\n    open(\"models/converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nNot sure if this is the problem, but could it be that the quantization scripts (quantize.create_training_graph quantize.create_eval_graph) are not detecting the first layer, not fake quantizing it and for this reason I get an error at activation1 when converting?", "comments": ["It seems to me that you are trying to create an eval graph from your training graph. Since your graph contains a lot of things that are different between training and eval (i.e. batchnorm, dropout), you should create two separates graphs, either in two files or graph construction code that has a eval vs training parameter. One file creates the training graph and calls `tf.contrib.quantize.create_training_graph()` and the other creates the eval graph, restores the values from training, and calls `tf.contrib.quantize.create_eval_graph()`. ", "So if I understand correctly, the correct training code is until the `saver.save(sess, checkpoint_path)` line. Then, I create a new file to create the eval graph and load the trained parameters:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef build_eval_model(num_feat, num_classes):\r\n    inputs = tf.placeholder(tf.float32, shape=(1, num_feat), name='inputs')\r\n\r\n    # First layer\r\n    hid1_size = 128\r\n    w1 = tf.get_variable(\"w1\", [hid1_size, num_feat])\r\n    b1 = tf.get_variable(\"b1\", [hid1_size, 1])\r\n    y1 = tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(inputs)), b1, name=\"layer1\"), \"activation1\")\r\n\r\n    # Second layer\r\n    hid2_size = 256\r\n    w2 = tf.get_variable(\"w2\", [hid2_size, hid1_size])\r\n    b2 = tf.get_variable(\"b2\", [hid2_size, 1])\r\n    y2 = tf.nn.relu(tf.add(tf.matmul(w2, y1), b2, name=\"layer2\"), name=\"activation2\")\r\n\r\n    # Output layer\r\n    wo = tf.get_variable(\"wo\", [num_classes, hid2_size])\r\n    bo = tf.get_variable(\"bo\", [num_classes, 1])\r\n    yo = tf.transpose(tf.add(tf.matmul(wo, y2), bo), name=\"logits\")\r\n\r\n    pred = tf.nn.softmax(yo, name=\"prediction\")\r\n\r\n    saver = tf.train.Saver()\r\n\r\n    with tf.Session() as sess:\r\n        writer = tf.summary.FileWriter(\"tensorboard_eval\", sess.graph)\r\n\r\n        saver.restore(sess, \"models/model.ckpt\")\r\n\r\n        # Call the eval rewrite which rewrites the graph in-place with\r\n        # FakeQuantization nodes and fold batchnorm for eval.\r\n        tf.contrib.quantize.create_eval_graph()\r\n\r\n        writer.close()\r\n\r\n        frozen_graphdef = tf.graph_util.convert_variables_to_constants(\r\n            sess, sess.graph_def, [\"prediction\"])\r\n        tflite_model = tf.contrib.lite.toco_convert(\r\n            frozen_graphdef, [inputs], [pred], inference_type=tf.contrib.lite.QUANTIZED_UINT8,\r\n            quantized_input_stats=[(127.5, 127.5)])\r\n        open(\"models/converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nThis is the eval graph:\r\n\r\n![image](https://user-images.githubusercontent.com/8360740/39517277-ae569240-4dff-11e8-8278-f8a68a202e46.png)\r\n\r\nBut I still get the same error. Maybe it's because I'm not restoring the quantization nodes, so when I call toco it doesn't know the min/max information? How to load this information?\r\n\r\nI think that this procedure should be explained more thoroughly in the documentation (for example here https://www.tensorflow.org/performance/quantization). Or is it explained somewhere else?\r\n", "Note that the create_training_graph and create_eval_graph rewrite adds variables to the graph that store the quantization information needed by toco. So when you save a checkpoint from training, it will have these extra variables stored in it. Thus, when restoring that checkpoint into the eval graph, you need to restore *after* you call the rewrite.\r\n\r\nThink of the rewrite as part of graph construction in that you shouldn't run anything on the graph until the quantization rewrite has been called.\r\n\r\nIn particular, your code should be updated like this: \r\n\r\n\r\n        # Call the eval rewrite which rewrites the graph in-place with\r\n        # FakeQuantization nodes and fold batchnorm for eval.\r\n        tf.contrib.quantize.create_eval_graph()\r\n\r\n        saver.restore(sess, \"models/model.ckpt\")\r\n\r\nAlso check out this file for some instructions: \r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/quantize \r\n\r\nThat being said, the documents can likely be improved more and I will work to do that. Thanks for your feedback!", "Hi, tried your changes but I still got the same error. If I inspect the eval graph in tensorboard it's the same as my last reply, for some reason `tf.contrib.quantize.create_eval_graph()` is not rewriting the graph (or not adding the quantization nodes) so when I restore the checkpoint only the weights and biases are restored, not the min/max information or the weights_quant/act_quant nodes.", "Hi, thanks for trying. I ran your code and can reproduce what you are seeing exactly. I will take a look to see what the issue is soon. Thanks for the repro case!", "I have found the issue, the rewriter currently only recognizes one ordering of inputs to MatMul. I will work on a fix for that. But in the meantime you can change all of you Matmuls to `tf.matmul(y1, w2)` (having the weight as the second parameter to get thing working in the meantime. Thanks!", "Ok, so now the `tf.contrib.quantize.create_eval_graph()` is working:\r\n\r\n![image](https://user-images.githubusercontent.com/8360740/39800010-a5fb7766-5366-11e8-8378-42b87be5c99b.png)\r\n\r\nBut now I get an error when freezing the model (in the eval graph code, attached below, function `convert_variables_to_constants`):\r\n\r\n`tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value weights_quant_2/min\r\n\t [[Node: _retval_weights_quant_2/min_0_16 = _Retval[T=DT_FLOAT, index=16, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](weights_quant_2/min)]]`\r\n\r\nLooks like when I perform the restore from the checkpoint, the quantization nodes are not restored (but the weights and biases are correctly restored).\r\n\r\nHere's the new training code:\r\n\r\n```inputs = tf.placeholder(tf.float32, shape=(1, train_X.shape[1]), name='inputs')\r\nlabel = tf.placeholder(tf.float32, shape=(1, num_classes), name='labels')\r\n\r\n# First layer\r\nhid1_size = 1000\r\nw1 = tf.Variable(tf.random_normal([train_X.shape[1], hid1_size], stddev=0.01), name='w1')\r\nb1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\r\ny1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\"), keep_prob=0.5)\r\n\r\n# Second layer\r\nhid2_size = 1000\r\nw2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\r\nb2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\r\ny2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\"), keep_prob=0.5)\r\n\r\n# Output layer\r\nwo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\r\nbo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\r\nyo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\r\n\r\n# Loss function and optimizer\r\n# lr = tf.placeholder(tf.float32, shape=(), name='learning_rate')\r\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=yo, labels=label), name=\"loss\")\r\n\r\n# Call the training rewrite which rewrites the graph in-place with\r\n# FakeQuantization nodes and folds batchnorm for training. It is\r\n# often needed to fine tune a floating point model for quantization\r\n# with this training tool. When training from scratch, quant_delay\r\n# can be used to activate quantization after training to converge\r\n# with the float graph, effectively fine-tuning the model.\r\ntf.contrib.quantize.create_training_graph(quant_delay=50)\r\n\r\noptimizer = tf.train.AdamOptimizer().minimize(loss)\r\n\r\n# Prediction\r\npred = tf.nn.softmax(yo, name=\"prediction\")\r\npred_label = tf.argmax(pred, 1)\r\ncorrect_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(label, 1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\r\n\r\n# Create operation which will initialize all variables\r\ninit = tf.global_variables_initializer()\r\n\r\n# Start a new tensorflow session and initialize variables\r\nsess = tf.Session()\r\n\r\nwriter = tf.summary.FileWriter(\"tensorboard\", sess.graph)\r\n\r\nsess.run(init)\r\n\r\nsaver = tf.train.Saver()\r\n\r\n# This is the main training loop: we train for 50 epochs with a learning rate of 0.05 and another\r\n# 50 epochs with a smaller learning rate of 0.01\r\nfor epoch in range(10):\r\n    print(\"Epoch: {:3d}\".format(epoch))\r\n    avg_cost = 0.0\r\n\r\n    # For each epoch, we go through all the samples we have.\r\n    for i in tqdm.tqdm(range(train_X.shape[0])):\r\n        # Finally, this is where the magic happens: run our optimizer, feed the current example into X and the current target into Y\r\n        _, c = sess.run([optimizer, loss], feed_dict={inputs: train_X[i, None],\r\n                                                      label: train_y[i, None]})\r\n        avg_cost += c\r\n    avg_cost /= train_X.shape[0]\r\n\r\n    # Print the cost in this epcho to the console.\r\n    if epoch % 10 == 0:\r\n        print(\"Epoch: {:3d}    Train Cost: {:.4f}\".format(epoch, avg_cost))\r\n\r\ngraph_path = os.path.join(\"models\", \"model.pbtxt\")\r\ncheckpoint_path = os.path.join(\"models\", \"model.ckpt\")\r\n\r\n# Save the checkpoint and eval graph proto to disk for freezing and providing to TFLite.\r\nwith open(graph_path, 'w') as f:\r\n    f.write(str(sess.graph.as_graph_def()))\r\n\r\nsaver.save(sess, checkpoint_path)\r\n\r\nwriter.close()\r\n```\r\n\r\nAnd the eval graph code:\r\n\r\n```\r\ninputs = tf.placeholder(tf.float32, shape=(1, num_feat), name='inputs')\r\n\r\n# First layer\r\nhid1_size = 1000\r\nw1 = tf.Variable(tf.random_normal([num_feat, hid1_size], stddev=0.01), name='w1')\r\nb1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\r\ny1 = tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\")\r\n\r\n# Second layer\r\nhid2_size = 1000\r\nw2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\r\nb2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\r\ny2 = tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\")\r\n\r\n# Output layer\r\nwo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\r\nbo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\r\nyo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\r\n\r\npred = tf.nn.softmax(yo, name=\"prediction\")\r\n\r\nsaver = tf.train.Saver()\r\n\r\nwith tf.Session() as sess:\r\n    # Call the eval rewrite which rewrites the graph in-place with\r\n    # FakeQuantization nodes and fold batchnorm for eval.\r\n    tf.contrib.quantize.create_eval_graph()\r\n\r\n    writer = tf.summary.FileWriter(\"tensorboard_eval\", sess.graph)\r\n\r\n    saver.restore(sess, \"models/model.ckpt\")\r\n\r\n    writer.close()\r\n\r\n    frozen_graphdef = tf.graph_util.convert_variables_to_constants(\r\n        sess, sess.graph_def, [\"prediction\"])\r\n\r\n    tflite_model = tf.contrib.lite.toco_convert(\r\n        frozen_graphdef, [inputs], [pred], inference_type=tf.contrib.lite.FLOAT)\r\n\r\n    open(\"models/converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nDo I need to do something else when saving or restoring the graph parameters? \r\n", "Using your code I am able to successfully get a frozen graph. Here is the code I used (copy pasted from your snippets): \r\n\r\n```\r\ndef train_model(num_feat, num_classes):\r\n  g = tf.Graph()\r\n  with tf.Session(graph=g) as sess:\r\n    inputs = tf.placeholder(tf.float32, shape=(1, num_feat), name=\"inputs\")\r\n    label = tf.placeholder(tf.float32, shape=(1, num_classes), name='labels')\r\n\r\n    # First layer\r\n    hid1_size = 1000\r\n    w1 = tf.Variable(tf.random_normal([num_feat, hid1_size], stddev=0.01), name='w1')\r\n    b1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\r\n    y1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\"), keep_prob=0.5)\r\n\r\n    # Second layer\r\n    hid2_size = 1000\r\n    w2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\r\n    b2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\r\n    y2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\"), keep_prob=0.5)\r\n\r\n    # Output layer\r\n    wo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\r\n    bo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\r\n    yo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\r\n\r\n    # Loss function and optimizer\r\n    # lr = tf.placeholder(tf.float32, shape=(), name='learning_rate')\r\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=yo, labels=label), name=\"loss\")\r\n\r\n    # Call the training rewrite which rewrites the graph in-place with\r\n    # FakeQuantization nodes and folds batchnorm for training. It is\r\n    # often needed to fine tune a floating point model for quantization\r\n    # with this training tool. When training from scratch, quant_delay\r\n    # can be used to activate quantization after training to converge\r\n    # with the float graph, effectively fine-tuning the model.\r\n    tf.contrib.quantize.create_training_graph(quant_delay=50)\r\n\r\n    optimizer = tf.train.AdamOptimizer().minimize(loss)\r\n\r\n    sess = tf.Session()\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    saver = tf.train.Saver()\r\n    saver.save(sess, '/tmp/oink.ckpt')\r\n\r\n\r\ndef eval_model(num_feat, num_classes):\r\n  g = tf.Graph()\r\n  with tf.Session(graph=g) as sess:\r\n    inputs = tf.placeholder(tf.float32, shape=(1, num_feat), name='inputs')\r\n\r\n    # First layer\r\n    hid1_size = 1000\r\n    w1 = tf.Variable(tf.random_normal([num_feat, hid1_size], stddev=0.01), name='w1')\r\n    b1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\r\n    y1 = tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\")\r\n\r\n    # Second layer\r\n    hid2_size = 1000\r\n    w2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\r\n    b2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\r\n    y2 = tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\")\r\n\r\n    # Output layer\r\n    wo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\r\n    bo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\r\n    yo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\r\n\r\n    pred = tf.nn.softmax(yo, name=\"prediction\")\r\n\r\n    tf.contrib.quantize.create_eval_graph()\r\n\r\n    saver = tf.Saver()\r\n    saver.restore(sess, \"/tmp/oink.ckpt\")\r\n\r\n    frozen_graphdef = tf.graph_util.convert_variables_to_constants(\r\n          sess, sess.graph_def, [\"prediction\"])\r\n\r\n\r\ndef main(_):\r\n  train_model(3, 1000)\r\n  eval_model(3, 1000)\r\n```\r\n\r\nIn particular make sure you delete your old checkpoints from before you swapped the order of the params, the above code seems to work for me. Hope that works! (I have a fix in progress for the ordering issue.)", "I had a related follow up. I am following the pattern shown above. But when I restore a trained graph, and evaluate the 'preds', I seem to get substantially different (and worse) outputs than in my train graph. Is there some extra step I need to take to make the eval graph line up with the train graph for quantization? Or what is the best way to confirm that the eval graph quantization is working?", "Do you have a specific example of the mismatch? IIUC, there is an expected difference since you are using dropout during training but not eval. If you want to compare training and eval predictions, you should try with keep_prob=1 during training.\r\n\r\nOtherwise the graphs should matchup. If there are still differences between the graphs, i would recommend viewing them to see if there is anything unexpected or running corresponding intermediate nodes to try to identity where the difference appears.", "@suharshs \r\nYou said \u201cI have found the issue, the rewriter currently only recognizes one ordering of inputs to MatMul. \u201d Did it means that it couldn't recognize the conv2d if I use it in the training part ?", "@suharshs As you pointed out, a more comprehensive documentation could be of great help.\r\nEspecially, a full example showing:\r\n\r\n- training_graph quantization +  **exporting/displaying  weights/activations already quantized** \r\n- evaluation_graph quantization + **exporting/displaying weights/activations already quantized**\r\n\r\nwould be of great help, allowing us developers to access and debug the layers and check whether the quantization is being correctly performed.\r\n\r\nThanks", "@eejackliu The rewriter uses pattern matching to find layers. Prior to the fix, if `tf.matmul(w, y)` would be ignored but `tf.matmul(y, w)` would be matched. These should both be matched. This is fixed now.\r\n\r\n@fgr1986 Thanks. Yes, i will work to add better docs in the coming weeks. Thanks for the specific examples of what would be helpful!", "@suharshs Tahnk you very much, let me know if you need a hand with the documentation.\r\nIn the mean time, I tried myself the following example, but unfortunately couldn't show how the quantization is correctly working.\r\nPlease note that I use `experimental_create_training_graph` instead `create_training_graph` only to be able to determine the quantization bits more easily:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nD_SIZE = 2048\r\nBATCH_SIZE = 32\r\nEPOCHS = 1000\r\nW_B = 3\r\nA_B = 3\r\n\r\n\r\ndef train_quantization():\r\n\r\n    g_tr = tf.Graph()\r\n    with g_tr.as_default():\r\n\r\n        # prepare dataset\r\n        features_arr = tf.constant(2 * np.arange(D_SIZE), dtype=tf.float32)\r\n        labels_arr = tf.constant(np.arange(D_SIZE), dtype=tf.float32)\r\n        trn_data = tf.data.Dataset.zip(\r\n            (tf.data.Dataset.from_tensor_slices(features_arr),\r\n             tf.data.Dataset.from_tensor_slices(labels_arr))\r\n        )\r\n        trn_data = trn_data.shuffle(1000)\r\n        trn_data = trn_data.batch(BATCH_SIZE)\r\n        trn_data = trn_data.repeat(EPOCHS)\r\n        trn_data = trn_data.prefetch(1)\r\n\r\n        iterator = tf.data.Iterator.from_structure(trn_data.output_types,\r\n                                                   trn_data.output_shapes)\r\n        feat, labels = iterator.get_next()\r\n        data_init_op = iterator.make_initializer(trn_data)\r\n\r\n        # global step\r\n        global_step = tf.train.get_or_create_global_step()\r\n\r\n        # simple model dense, WITH ACTIVATION TO TEST QUANTIFICATION\r\n        flow = tf.identity(feat, name='input_tensor')\r\n        print(feat)\r\n        flow = tf.reshape(flow, (-1, BATCH_SIZE))\r\n        # require activation for quantization\r\n        flow = tf.layers.dense(flow, units=BATCH_SIZE,\r\n                               activation=tf.nn.relu, name='out')\r\n\r\n        # Build forward pass of model.\r\n        # Make the loss op\r\n        with tf.variable_scope('loss'):\r\n            tf.logging.debug('[loss] size of out: %s',\r\n                             flow.get_shape().as_list())\r\n            power = tf.pow(labels - flow, 2)\r\n            power = tf.reduce_sum(power, 1)\r\n            loss = tf.reduce_mean(power, name='m_loss')\r\n        tf.summary.scalar('loss', loss)\r\n\r\n        # Optimizer\r\n        opt_op = tf.train.AdamOptimizer(1e-4).minimize(loss, global_step)\r\n\r\n\r\n        # Call the training rewrite which rewrites the graph in-place with\r\n        # FakeQuantization nodes and folds batchnorm for training. It is\r\n        # often needed to fine tune a floating point model for quantization\r\n        # with this training tool. When training from scratch, quant_delay\r\n        # can be used to activate quantization after training to converge\r\n        # with the float graph, effectively fine-tuning the model.\r\n        tf.contrib.quantize.experimental_create_training_graph(weight_bits=W_B,\r\n                                                               activation_bits=A_B,\r\n                                                               quant_delay=int(EPOCHS / 2))\r\n\r\n        # Merge all the summaries\r\n        merged = tf.summary.merge_all()\r\n\r\n        with tf.Session(graph=g_tr) as sess:\r\n            # global variables Initializing\r\n            sess.run(tf.global_variables_initializer())\r\n            # local variables Initializing\r\n            sess.run(tf.local_variables_initializer())\r\n\r\n            train_writer = tf.summary.FileWriter('./tmp/train', sess.graph)\r\n\r\n            # re-initialize the iterator, but this time with training data\r\n            sess.run(data_init_op)\r\n\r\n            epoch_counter = 0\r\n            for i in range(int(D_SIZE/BATCH_SIZE) * EPOCHS):\r\n                _, nn_out, nn_loss, gs, summary = sess.run(\r\n                    [opt_op, flow, loss, global_step, merged])\r\n                # tensorboard and  statistics\r\n                train_writer.add_summary(summary, gs)\r\n                if i % BATCH_SIZE == 0:\r\n                    print(epoch_counter, ': loss ', nn_loss)\r\n                    epoch_counter += 1\r\n\r\n            saver = tf.train.Saver()\r\n            saver.save(sess, './tmp/oink.ckpt')\r\n\r\n        # debug\r\n        print('nn_out different values in BATCH_SIZE (32) elements:', len(np.unique(nn_out)))\r\n        print('nn_out [0:8]: ', nn_out[0:8])\r\n        print('nn_labels [0:8]: ', nn_labels[0:8])\r\n\r\n\r\n        print('[debug] exit training')\r\n\r\ndef inference_quantization():\r\n\r\n    #################################\r\n    # Reset default graph\r\n    tf.reset_default_graph()\r\n    #################################\r\n\r\n    g_inf = tf.Graph()\r\n    with g_inf.as_default():\r\n        # create inference graph\r\n        # prepare dataset\r\n        features_arr = tf.constant(2 * np.arange(D_SIZE), dtype=tf.float32)\r\n        labels_arr = tf.constant(np.arange(D_SIZE), dtype=tf.float32)\r\n        trn_data = tf.data.Dataset.zip(\r\n            (tf.data.Dataset.from_tensor_slices(features_arr),\r\n             tf.data.Dataset.from_tensor_slices(labels_arr))\r\n        )\r\n        trn_data = trn_data.shuffle(1000)\r\n        trn_data = trn_data.batch(BATCH_SIZE)\r\n        trn_data = trn_data.repeat(EPOCHS)\r\n        trn_data = trn_data.prefetch(1)\r\n\r\n        iterator = tf.data.Iterator.from_structure(trn_data.output_types,\r\n                                                   trn_data.output_shapes)\r\n        feat, labels = iterator.get_next()\r\n        data_init_op = iterator.make_initializer(trn_data)\r\n\r\n        # global step\r\n        global_step = tf.train.get_or_create_global_step()\r\n\r\n        # simple model dense, WITH ACTIVATION TO TEST QUANTIFICATION\r\n        flow = tf.identity(feat, name='input_tensor')\r\n        print(feat)\r\n        flow = tf.reshape(flow, (-1, BATCH_SIZE))\r\n        # require activation for quantization\r\n        flow = tf.layers.dense(flow, units=BATCH_SIZE,\r\n                               activation=tf.nn.relu, name='out')\r\n\r\n        # Build forward pass of model.\r\n        # Make the loss op\r\n        with tf.variable_scope('loss'):\r\n            tf.logging.debug('[loss] size of out: %s',\r\n                             flow.get_shape().as_list())\r\n            power = tf.pow(labels - flow, 2)\r\n            power = tf.reduce_sum(power, 1)\r\n            loss = tf.reduce_mean(power, name='m_loss')\r\n        tf.summary.scalar('loss', loss)\r\n\r\n        with tf.Session(graph=g_inf) as sess:\r\n            # Call the eval rewrite which rewrites the graph in-place with\r\n            # FakeQuantization nodes and fold batchnorm for eval.\r\n            tf.contrib.quantize.experimental_create_eval_graph(weight_bits=W_B,\r\n                                                               activation_bits=A_B)\r\n\r\n            saver = tf.train.Saver()\r\n            saver.restore(sess, \"./tmp/oink.ckpt\")\r\n            # frozen_graphdef = tf.graph_util.convert_variables_to_constants(\r\n            #       sess, sess.graph_def, [\"out\"])\r\n            print('[debug] restored')\r\n\r\n            # re-initialize the iterator, but this time with training data\r\n            sess.run(data_init_op)\r\n\r\n            nn_out, nn_labels, nn_loss = sess.run([flow, labels, loss])\r\n\r\n        # debug\r\n        print('loss: ', nn_loss)\r\n        print('nn_out different values in BATCH_SIZE (32) elements:', len(np.unique(nn_out)))\r\n        print('nn_out [0:8]: ', nn_out[0:8])\r\n        print('nn_labels [0:8]: ', nn_labels[0:8])\r\n\r\ndef test_quantization():\r\n\r\n    train_quantization()\r\n    inference_quantization()\r\n\r\ntest_quantization()\r\n\r\n\r\n```\r\n", "When I run toco_convert, I got this error. Please help me.\r\n-------------------------------------------------------------------------\r\nRuntimeError: TOCO failed see console for info.\r\nb'2018-06-11 15:17:15.015923: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 382 operators, 573 arrays (0 quantized)\\n2018-06-11 15:17:15.021257: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 382 operators, 573 arrays (0 quantized)\\n2018-06-11 15:17:15.042092: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 49 operators, 94 arrays (1 quantized)\\n2018-06-11 15:17:15.042787: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 48 operators, 92 arrays (1 quantized)\\n2018-06-11 15:17:15.043349: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 47 operators, 90 arrays (1 quantized)\\n2018-06-11 15:17:15.043875: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 47 operators, 90 arrays (1 quantized)\\n2018-06-11 15:17:15.043956: W tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:105] Tweaking the MinMax of array model_st/lmpnts_pri/final/BiasAdd, which is an input to {Concatenation operator with output model_st/lmpnts}, because we want all inputs and outputs of a Concatenation operator to have the same MinMax so that it can be implemented as a pure byte-copy, no arithmetic.\\n2018-06-11 15:17:15.043965: W tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:105] Tweaking the MinMax of array model_st/lmpnts_sec/final/BiasAdd, which is an input to {Concatenation operator with output model_st/lmpnts}, because we want all inputs and outputs of a Concatenation operator to have the same MinMax so that it can be implemented as a pure byte-copy, no arithmetic.\\n2018-06-11 15:17:15.044103: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 28 operators, 71 arrays (1 quantized)\\n2018-06-11 15:17:15.044314: **F tensorflow/contrib/lite/toco/tooling_util.cc:1445] Array model_st/add, which is an input to the Conv operator producing the output array model_st/conv_3/conv/add_fold, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\\n'**", "Nagging Assignee @suharshs: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @suharshs: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @suharshs: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@mynameischaos this seems like a separate issue. Please create a new issue for that with a repro details. \r\n\r\nThis issue seems resolved so I will close. Please reopen if i am wrong."]}, {"number": 18918, "title": "Unable to save a checkpoint", "body": "Hello\r\n\r\nI found a interesting project on github which recognize face in realtime:\r\nhttps://github.com/vudung45/FaceRec\r\n\r\nIn that project there are two part, the face detection and the face recognition. The two graph are stored in a global graph and I want to export that global graph.\r\n\r\nI add that code in mtcnn_detect.py:\r\n\r\n```\r\n        def __init__(self, face_rec_graph, model_path = \"models\", threshold = [0.6, 0.7, 0.7], factor = 0.709, scale_factor = 1):\r\n        '''\r\n        :param face_rec_sess: FaceRecSession\r\n        :param threshold: detection threshold\r\n        :param factor: default 0.709 image pyramid -- magic number\r\n        :param model_path:\r\n        '''\r\n        self.threshold = threshold\r\n        self.factor = factor\r\n        self.scale_factor = scale_factor;\r\n        with face_rec_graph.graph.as_default():\r\n            print(\"Loading MTCNN Face detection model\")\r\n            self.sess = tf.Session()\r\n            if not model_path:\r\n                model_path, _ = os.path.split(os.path.realpath(__file__))\r\n\r\n            with tf.variable_scope('pnet'):\r\n                data = tf.placeholder(tf.float32, (None, None, None, 3), 'input')\r\n                pnet = PNet({'data': data})\r\n                pnet.load(os.path.join(model_path, 'det1.npy'), self.sess)\r\n            with tf.variable_scope('rnet'):\r\n                data = tf.placeholder(tf.float32, (None, 24, 24, 3), 'input')\r\n                rnet = RNet({'data': data})\r\n                rnet.load(os.path.join(model_path, 'det2.npy'), self.sess)\r\n            with tf.variable_scope('onet'):\r\n                data = tf.placeholder(tf.float32, (None, 48, 48, 3), 'input')\r\n                onet = ONet({'data': data})\r\n                onet.load(os.path.join(model_path, 'det3.npy'), self.sess)\r\n\r\n            self.pnet = lambda img: self.sess.run(('pnet/conv4-2/BiasAdd:0', 'pnet/prob1:0'), feed_dict={'pnet/input:0': img})\r\n            self.rnet = lambda img: self.sess.run(('rnet/conv5-2/conv5-2:0', 'rnet/prob1:0'), feed_dict={'rnet/input:0': img})\r\n            self.onet = lambda img: self.sess.run(('onet/conv6-2/conv6-2:0', 'onet/conv6-3/conv6-3:0', 'onet/prob1:0'),\r\n                                            feed_dict={'onet/input:0': img})\r\n            print(\"MTCNN Model loaded\")\r\n\r\n\r\n            ###############what I added #################\r\n            writer = tf.summary.FileWriter(\"/tmp/model3/\", face_rec_graph.graph)\r\n            saver = tf.train.Saver() #saver load pretrain model\r\n            save_path = saver.save(self.sess, \"/tmp/model3/model.ckpt\")\r\n            print(\"Model saved in path: %s\" % save_path)\r\n```\r\n\r\n\r\n\r\nWhen I launch the program I get that error:\r\n\r\n   ```\r\n MTCNN Model loaded\r\n  \r\n\r\n\r\n    Traceback (most recent call last):\r\n          File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1323, in _do_call\r\n            return fn(*args)\r\n          File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1302, in _run_fn\r\n            status, run_metadata)\r\n          File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n            c_api.TF_GetCode(self.status.status))\r\n        tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value InceptionResnetV1/Block8/Branch_0/Conv2d_1x1/BatchNorm/beta\r\n        \t [[Node: save_1/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/SaveV2/tensor_names, save_1/SaveV2/shape_and_slices, InceptionResnetV1/Block8/Branch_0/Conv2d_1x1/BatchNorm/beta, InceptionResnetV1/Block8/Branch_0/Conv2d_1x1/BatchNorm/moving_mean, InceptionResnetV1/Block8/Branch_0/Conv2d_1x1/BatchNorm/moving_variance, InceptionResnetV1/Block8/Branch_0/Conv2d_1x1/weights, InceptionResnetV1/Block8/Branch_1/Conv2d_0a_1x1/BatchNorm/beta, InceptionResnetV1/Block8/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean, InceptionResnetV1/Block8/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_variance, InceptionResnetV1/Block8/Branch_1/Conv2d_0a_1x1/weights, InceptionResnetV1/Block8/Branch_1/Conv2d_0b_1x3/BatchNorm/beta, InceptionResnetV1/Block8/Branch_1/Conv2d_0b_1x3/BatchNorm/moving_mean, InceptionResnetV1/Block8/Branch_1/Conv2d_0b_1x3/BatchNorm/moving_variance,\r\n\r\n     \r\n    ....\r\n    \r\n    \r\n    Caused by op 'save_1/SaveV2', defined at:\r\n      File \"./main.py\", line 156, in <module>\r\n        face_detect = MTCNNDetect(FRGraph, scale_factor=2); #scale_factor, rescales image for faster detection\r\n      File \"/home/xavier/T\u00e9l\u00e9chargements/FaceRec-master/mtcnn_detect.py\", line 51, in __init__\r\n        saver = tf.train.Saver() #saver load pretrain model\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\r\n        self.build()\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1227, in build\r\n        self._build(self._filename, build_save=True, build_restore=True)\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1263, in _build\r\n        build_save=build_save, build_restore=build_restore)\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\r\n        save_tensor = self._AddSaveOps(filename_tensor, saveables)\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\r\n        save = self.save_op(filename_tensor, saveables)\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 239, in save_op\r\n        tensors)\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\r\n        shape_and_slices=shape_and_slices, tensors=tensors, name=name)\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n        op_def=op_def)\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n        op_def=op_def)\r\n      File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n        self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\n\r\n\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@xav12358 need to initialize variables first before you execute anything within the graph (including saving variables), by using `sess.run(tf.global_variables_intializer())` for example\r\n\r\nEDIT: Sorry, I was only looking at glance, you can check the numpy file first whether the array for the mentioned variable exists or not, but seems it is better to ask the owner itself which you have already done", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18917, "title": "tf.contrib.image.connected_components works incorrectly with 3D numpy arrays", "body": "### System information\r\nHave I written custom code: N/A\r\nOS Platform and Distribution: Linux Ubuntu 16.04\r\nBazel version: N/A\r\nTensorFlow installed from binary\r\nTensorFlow version: v1.7.0-3-g024aecf414 1.7.0\r\nPython version: 3.6\r\nCUDA/cuDNN version: CUDA 9.0 / cuDNN 7.1.1\r\nGPU model and memory: GeForce GTX 1060 6GB\r\n\r\n### Exact command to reproduce:\r\n`import numpy as np`\r\n`from tensorflow.contrib.image import connected_components`\r\n`a = np.zeros((2,3,4))`\r\n`a[0,0,0]=1`\r\n`a[0,0,1]=1`\r\n`a[1,0,1]=1`\r\n`print((tf.Session().run(connected_components(a))))`\r\n\r\n> [[[1 1 0 0]\r\n  [0 0 0 0]\r\n  [0 0 0 0]]\r\n [[0 2 0 0]\r\n  [0 0 0 0]\r\n  [0 0 0 0]]]\r\n\r\nIt gives two components instead of one. ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nBazel version\nCUDA/cuDNN version\nExact command to reproduce", "Updated, thanks.", "@dpaniukov, the documentation [here](https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/image/connected_components) indicates that `connected_components` operates on 1 or more 2D tensors (i.e., an `(H,W)` or `(N,H,W)` tensor) rather than a single `(H,W,D)` 3D tensor. As a result, regions in separate 2D images (i.e. differing values in the first dimension) are assigned different indices.", "@ntenenz Thanks for the clarification! I work with 3D images of brains and need this to work with a single 3D image. At some point of the analysis, I search for clusters of connected voxels (3D pixels). As of now, to accomplish the task I use:\r\n\r\n`from scipy.sparse.csgraph import connected_components`\r\n`from sklearn.neighbors import radius_neighbors_graph`\r\n\r\n`n_components, labels = connected_components(radius_neighbors_graph(my_voxels, radius=1, mode='connectivity', include_self=True).toarray())`\r\n\r\nHowever, it does not work on large images.\r\n\r\nWill it be possible to incorporate such or similar functionality in tensorflow? It will significantly help researchers like me and speed things up with a GPU. \r\n\r\nThanks for your consideration.", "Nagging Assignee @bignamehyp: It has been 107 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 18916, "title": "Does tensorflow have 2D short time Fourier transform? ", "body": "Tensorflow have tf.contrib.signal.stft which i think implements 1D stft. Can this be used fpr the 2D case?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: No\r\nOS Platform and Distribution: Ubuntu 16.04\r\nTensorFlow installed from:  NA\r\nTensorFlow version: 1.7\r\nBazel version: NA\r\nCUDA/cuDNN version: 9.0\r\nGPU model and memory: Nvidia Titan Xp 12 Gb\r\nExact command to reproduce: NA", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request (it could *become* a feature request, but this question will be much more useful on SO until it is answered). There is also a larger community that reads questions there.\r\n\r\nIf you discover that TF is lacking such a feature, please create another issue formatted as a feature request. Thanks!"]}, {"number": 18915, "title": "Tensorflow lite version 0.1.7 is too slow", "body": "\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: android\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: no\r\n- **Python version**: no\r\n- **Bazel version (if compiling from source)**: no\r\n- **GCC/Compiler version (if compiling from source)**: no\r\n- **CUDA/cuDNN version**: no\r\n- **GPU model and memory**: no\r\n- **Exact command to reproduce**: no\r\n\r\nI used the Tensor Flowlight library on my device. Until then, the operation speed was 300ms. However, it took more than a second after using the 0.1.7 version of the Tensor Flow Lite version released this week. If i use the current 0.0.0-nightly version, it takes 300ms again. The question is whether or not you have removed the option that the 0.1.7 version of the library uses neon.\r\n\r\nAsk https://bintray.com/google/tensorflow/tensorflow-lite to post your question here and upload it here. Even if it does not fit the form, please understand and ask for confirmation.\r\n\r\n", "comments": ["We are investigating. There were no changes to remove neon support. Do you have custom inference code or are you running benchmark_model?", "There was a bug in the schema where the default values of dilation width and height factors were set to 0 instead of 1. This incorrect value will cause the slow kernel to be selected for execution.\r\nThis got fixed with recent update to [schema](https://github.com/tensorflow/tensorflow/commit/e41e70ed9827b81a07c42f68def80f3f61b70375#diff-16ca4f2738c3598cf9b1d79b45eed593), that is the reason you saw the regression in 0.1.7 version."]}, {"number": 18914, "title": "Dose Titan Xp work in Windows10?", "body": "Hi i bought new GPU - Titan Xp for learning, so i set the system like below:\r\nCPU-AMD Ryzen 51600 Six-Core Processor\r\nGPU-Titan Xp\r\nTensorflow-1.5.0 GPU\r\nCUDA-9.0\r\ncuDNN-7.0\r\n\r\nBut i found that when the calculation begins, the data looks not stacked on GPU, so that it occurs error message.\r\n\r\ndoes Titan XP work in Windows 10 to use tensorflow gpu?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 18913, "title": "Accessing CuDNN autotuner in built-in Keras", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n```bash\r\n$ uname -mrs\r\nLinux 4.14.0-49.el7a.ppc64le ppc64le\r\n```\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.6.0\r\n- **Python version**: 2.7.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: CUDA 9.1, CuDNN 7.0.5\r\n- **GPU model and memory**: Tesla V100:\r\n```\r\n== nvidia-smi ===================================================\r\nThu Apr 26 18:35:34 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.19                 Driver Version: 396.19                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  Off  | 00000004:04:00.0 Off |                    0 |\r\n| N/A   29C    P0    52W / 300W |      0MiB / 15360MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n```\r\n- **Exact command to reproduce**: N/A\r\n\r\nWe would like to be able to have access to the CuDNN autotuner in `tf.keras` module to access optimal algorithms for a given hardware (or, perhaps passing a custom convolutional algorithm from config). In TensorFlow, I can specify to use the CuDNN autotuner by setting: \r\n```bash\r\nos.environ['TF_CUDNN_USE_AUTOTUNE'] = \"1\"\r\n```\r\n(currently enabled by default), which improves performance significantly on Volta GPUs and especially with FP16.\r\n\r\nHowever, I am unable to access this performance improvement when running pure `tf.keras`, where setting this environmental variable does not have any effect. \r\n\r\n### Source code / logs\r\n\r\nFollowing simple example could be used to reproduce the issue: https://gist.github.com/ASvyatkovskiy/8d1dd622e447d9d8de1ec4e238e0dbaa", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Check also https://github.com/keras-team/keras/issues/9825 /cc @fchollet", "[Off-topic] @fchollet I note that more and more issues are a little bit duplicated after keras gone in the tf namespace. I think it is quite natural that people are a little bit cofused on where to report issues. I think that TF is a special case backend that it is also a sort of frontend in tf.keras. Of course keras is the upstream but this frontend/backend/frontend loop confuse many users.\r\n\r\nEDIT:\r\nJust to mention another case https://github.com/tensorflow/tensorflow/issues/10215", "It has been 18 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 33 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "Please reopen."]}, {"number": 18912, "title": "Update build_pip_package.sh", "body": "", "comments": []}, {"number": 18911, "title": "Check failed: dtype() == expected_dtype (9 vs. 3)", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source (Today's version)\r\n- **TensorFlow version (use command below)**: v1.8.0-rc1-1107-g8a428cd 1.8.0-rc1\r\n- **Python version**: Python3\r\n- **Bazel version (if compiling from source)**: 0.12\r\n- **GCC/Compiler version (if compiling from source)**: 5.4\r\n- **CUDA/cuDNN version**: 9.1/7.1.3\r\n- **GPU model and memory**: Geforce gtx Titan X\r\n- **Exact command to reproduce**: \r\n\r\n```\r\n std::vector<tensorflow::Tensor> finalOutput;\r\n\r\n  std::string InputName  = \"inp\";\r\n  std::string OutputName = \"out\";\r\n  tensorflow::Status run_status =\r\n      session->Run({{InputName, input_tensor}}, {OutputName}, {}, &finalOutput);\r\n\r\n  for (int y = 0; y < height; y++)\r\n  {\r\n    for (int x = 0; x < width; x++)\r\n    {\r\n     std::cout << finalOutput[0].tensor<int, 4>()(0, y, x, 0); // Error: Check failed: dtype() == expected_dtype (9 vs. 3)\r\n    }\r\n  }\r\n```\r\n\r\n### Describe the problem\r\nI have trained network in python. I froze the model from python and writing inference model in c++. I am using above code to run the inference on frozen graph. It works as I got the tensor output but I am unable to read this tensor file by using above method.\r\n\r\n**Based on types.proto, I am comparing DT_INT64(frozen model) with DT_INT32(c++ inference model).**\r\n\r\n**Things I have tried:**\r\n1. Specify tf.int32 in argmax layer. (Last layer in frozen model) **-> It works** (But I don't want to modify the network architecture)\r\n2. Instead of  finalOutput[0].tensor<int, 4>, I have tried  finalOutput[0].tensor<long int, 4>,  finalOutput[0].tensor<int64_t, 4> but compilation issue as eigen might not be supporting this. (Just a guess)\r\n\r\n### Source code / logs\r\n\r\nError: Check failed: dtype() == expected_dtype (9 vs. 3)\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Change \"int64_t\" to \"__int64\""]}, {"number": 18910, "title": "Make TensorFlow Lite library for Android target", "body": "You can compile Tensorflow Lite library using Makefile.\r\nIt is possible to compile both static and shared library\r\nexcluding benchmark tools.\r\n\r\nFor more details, see android.md in tensorflow/contrib/lite/g3doc/\r\n\r\nSigned-off-by: MyungSung Kwak <yesmung@gmail.com>", "comments": ["@martinwicke, @petewarden \r\n\r\nHello, \r\n\r\nI want to contribute this request to master branch.\r\nIt is a bit different from the related my request #18631  \r\nPlease review & merge as process.\r\n\r\nThanks.", "@petewarden , @aselle \r\nHello, \r\nI have resolved the conflict with the current master branch.\r\nPlease let me know the progress of review.", "Is there any update?", "@yesmung does your PR work? I want to use this to build an android shared library.", "@pineking\r\nSorry for late response.\r\nSure, you can use this commit.\r\nWould you explain PR work? ", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@yesmung have you tried the latest Android target of TensorFlow Lite? This issue is already resolved at head. Thanks", "Closing, since this is already resolved."]}, {"number": 18909, "title": "Optimization pass and Memory allocator integration", "body": "This PR introduces TRTOptimizationPass to run TensorRT conversion automatically as an optimization pass at the time of running and also adds necessary components to integrate TensorRT memory allocation into TensorFlow memory systems.", "comments": ["Tagging @aaroey "]}, {"number": 18908, "title": "[tf.keras] tf.keras.utils.plot_model does not work with Sequential API", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 & OSX\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.0 & 1.8.0.rc1\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a \r\n- **Exact command to reproduce**: See code/logs.\r\n\r\n\r\n### Describe the problem\r\ntf.keras.utils.plot_model does not work with a model specified in the Sequential API.\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\n\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.layers.Dense(10, input_dim=50))\r\n\r\ntf.keras.utils.plot_model(model, \"sequential.png\")\r\n```\r\n\r\nError tensorflow 1.7.0:\r\n```\r\nTraceback (most recent call last):\r\n  File \"plot_tf.py\", line 6, in <module>\r\n    tf.keras.utils.plot_model(model, \"sequential.png\")\r\n  File \"/Users/removed/.local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/utils/vis_utils.py\", line 149, in plot_model\r\n    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)\r\n  File \"/Users/removed/.local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/utils/vis_utils.py\", line 123, in model_to_dot\r\n    if node_key in model._container_nodes:\r\nAttributeError: 'Model' object has no attribute '_container_nodes'\r\n```\r\n\r\nError tensorflow 1.8.0.rc1\r\n```\r\nTraceback (most recent call last):\r\n  File \"plot_tf.py\", line 6, in <module>\r\n    tf.keras.utils.plot_model(model, \"sequential.png\")\r\n  File \"/Users/removed/.local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/utils/vis_utils.py\", line 149, in plot_model\r\n    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)\r\n  File \"/Users/removed/.local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/utils/vis_utils.py\", line 80, in model_to_dot\r\n    model = model.model\r\nAttributeError: 'Sequential' object has no attribute 'model'\r\n```\r\n\r\n", "comments": ["Note in tensorflow 1.8.0.rc1 the functional API appears to be working:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ninputs = tf.keras.layers.Input(shape=(784,))\r\noutputs = tf.keras.layers.Dense(10)(inputs)\r\nmodel = tf.keras.models.Model(inputs=inputs, outputs=outputs)\r\n\r\ntf.keras.utils.plot_model(model, \"functional.png\")\r\n```\r\n\r\nin tensorflow 1.7.0 the functional API has the same error as the Sequential API.", "Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Fixed by #19508 "]}, {"number": 18907, "title": "Fix build error with MPI support", "body": "This fix tries to fix the issue raised in #18363 where the bazel build with MPI support fails as a header is missing in the include.\r\n\r\nThis fix fixes the issue. The fix is verified locally with MPI+CUDA on Ubuntu 16.04.\r\n\r\nThis fix fixes #18363.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["can tensorflow merge this change into master?\r\n", "@B3N50N The change is in the master now:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/mpi/mpi_utils.h", "I met the same error and fixed from the change https://github.com/tensorflow/tensorflow/commit/5cd6a8d1edff984de5b8e08a579d96235137c38b\r\n"]}, {"number": 18906, "title": "Planning Ticket  CUDA 9.2 + cuDNN 7.1", "body": "Updated 02-JUNE-2018\r\n\r\nI have done some testing with CUDA 9.2/cuDNN 7.1.4/NCCL 2.x with tf_cnn_benchmarks.\r\n\r\nBelow you will see that if you upgrade to cuDNN 7.1.4 and a newer device driver you get some pretty nice gains and no need to compile from source as well as using CUDA 9.0.  Compiling from source and using NCCL 2.x (Hierarchal Copy was almost the same) I was able to get 6,800+ 8xV100s ResNet50v1 FP16 with synthetic data and about 6,500+ real data sustained over a full run for under 5 hours.  \r\n\r\nI suspect many of you saw NVIDIA announce 1K and 1.3K for 1xV100 ResNet50.  That was with **unreleased** libraries and we are working to ensure we can hit those numbers when the libraries are available or with our own tricks.\r\n\r\nI apologize for any short hand I use below in describing the runs.  I am happy to answer questions or make clarifications.  This testing was slightly informal but recent full scale testing yielded similar results.  \r\n\r\n**CUDA 9.0**\r\n[Recommended driver] 6,197.70 CUDA 9.0 + 384.13 (v1.8.0-1386-g2dc7575) hierarchical copy\r\n6,620 CUDA 9.0 + 390.59 (v1.8.0-1386-g2dc7575) NCCL\r\n6,613.11 CUDA 9.0 + 396.26 (v1.8.0-2215-gf528eba) NCCL\r\n6,564.9 CUDA 9.0 + 396.26 (v1.8.0-2215-gf528eba) hierarchical copy\r\n6,541.25 CUDA 9.0 + 390.59 (1.9.0.dev20180523) hierarchical copy\r\n6,276.02 CUDA 9.0 + 384.13 (1.9.0.dev20180523) hierarchical copy\r\n6,197.70 CUDA 9.0 + 384.13 (v1.8.0-1386-g2dc7575) hierarchical copy\r\n\r\n**CUDA 9.1**\r\n[Recommended driver]  6,227.64 CUDA 9.1 + 390.59 (v1.8.0-2215-gf528eba) hierarchical copy\r\n6,210.28 CUDA 9.1 + 396.26 (v1.8.0-2215-gf528eba) hierarchical copy\r\n6,118.21 CUDA 9.1 + 396.26 (v1.8.0-2215-gf528eba) NCCL\r\n\r\n**CUDA 9.2**\r\n[Recommended driver]  6,696.39 CUDA 9.2 + 396.26 (v1.8.0-2215-gf528eba) NCCL\r\n6,606.57 CUDA 9.2 + 396.26 (v1.8.0-2215-gf528eba) hierarchical copy\r\n6,738.32 CUDA 9.2 + 396.26 (v1.8.0-2215-gf528eba) NCCL SGD\r\n\r\n**Full test runs with CUDA 9.2**\r\ntop_1 ranges between 75.7% and 76% and does not seem to be based on the hyper parameters.  I was focused on testing NCCL vs. hierarchical copy.  I have a minor concern about my validation command, but this is still good info.\r\nHierarchical copy:  6441.64  Accuracy @ 1 = 0.7584 Accuracy @ 5 = 0.9267 [49920 examples] \r\nNCCL (repacking:2):  6490.62  Accuracy @ 1 = 0.7572 Accuracy @ 5 = 0.9265 [49920 examples]\r\nNCCL (repacking:8):  6490.62  Accuracy @ 1 = 0.7582 Accuracy @ 5 = 0.9268 [49920 examples]\r\nMy first hierarchical copy run was 76% exactly. \r\n\r\n**Note:**  I would like to move to CUDA 9.2 as the default but the driver is not widely available for easy apt-get install.  I am working long-term to get the build team to support a secondary CUDA build.  I am also very open to feedback as I do not see any easy path forward to moving to newer CUDA versions faster.  You can always (usually) install a new cuDNN.  We are compiling with 7.0 but you see gains by installing 7.1.4 as you see above if you upgrade your driver.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Great! I was able to build TF with the configuration below but the biggest roadblock is to get a version of TensorRT that works with anything above 9.0 hopefully TensorRT 4.1 comes right in time for this r1.9\r\n\r\nOS Platform and Distribution: Lubuntu 17.04\r\nTensorFlow installed from Source\r\nTensorFlow version r1.8\r\nGCC version 7\r\nBazel version 0.12\r\nCUDA/cuDNN version 9.1/7.1\r\nNCCL 2.1.15\r\nTensorRT None\r\nGPU model and memory Dual GTX1080Ti + GTX980Ti\r\n", "When 1.9 release can be expected, at least approximately?", "1.9 had a code cut off of 31st May.  It normally takes 1-2 weeks to verify the RCs and let them \"bake\".  CUDA 9.2 will not be in 1.9 as the default due to CUDA 9.2 not being public yet and in my opinion the device driver is too new and still not available for Debian although you can get it for Ubuntu as \"beta\".  I am hopeful NVIDIA is making some changes that will reduce this pain.\r\n\r\n@SephirothFFKH   I am just getting more involved in including TensorRT.  I did the testing for the NVIDIA \"launch\" but that was very one off.  Thank you for the info on versions working with 9.2.  ", "@tfboyd Thanks for clarification! So 1.9 will be shipped with CUDA 9.0 or at least switch to 9.1 could be expected?", "CUDA 9.2 GA is just released and support official driver of course\r\nFYI", "I can't find cudnn for cuda 9.2 windows", "I am trying to build tensorflow with cuda 9.2. Although cudnn doesn't support cuda 9.2 officially. ", "@K3n4 \r\n@achalshah20 \r\n\r\ncudnn also just been released\r\n\r\ncudnn 7.1.4 for cuda 9.2", "@alanpurple Thanks!", "@alanpurple Thanks,\r\nIs it possible to build tf with this configuration ?", "@K3n4 \r\nI'll skip that one until 1.9rc\r\n\r\nas a developer it's not a good timing for trying those, since 1.8 has many compiling issue( intel MPI support for example)\r\n\r\nand 1.9 will come with prebuilt binary for cuda 9.2 and cudnn 7.1(so compiling will be promising), and mpi-support issue fixed\r\n\r\n1.9rc are planned to come within 2 weeks as far as I know\r\n\r\nso I recommend you also wait for 1.9rc", "You've missed CUDA 9.1 and now decide to simply skip it? People will never be able to switch from CUDA 8.0 if the support for CUDAs 9.x among ML algos is so randomly scattered among these 3 versions (and counting)... ", "Yes, Tensorflow 1.7 can be built against CUDA 9.1 and CuDNN 7.1.2 if you have 1-2 hours per each try and don't want automated builds (e.g. for Docker). [Here's how to do it](http://www.python36.com/install-tensorflow141-gpu/), dear Tensorflow team.", "But wait, there's more: TinyMind prepared a comprehensive set of [pre-compiled Tensorflow wheels](https://github.com/mind/wheels), including those for CUDA 9.1. Make sure to star their hard work.", "I was not able to install CUDA 9.1 on Ubuntu 16.04-64bit a week ago.\r\nI just managed to have CUDA 9.2 running on Ubuntu 16.04-64bit, and cuDNN 7.1.4 that is compatible with CUDA 9.2.\r\nHowever, Tensorflow GPU does not seem to work with CUDA 9.2. It keeps complaining \"ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\".\r\nAny ideas?", "@mirekphd  no i'm using 9.1 to build tf-gpu 1.8 and i'm using it\r\ni'm skipping 9.2 for 1.8, waiting 1.9rc", "@alanpurple, if you have a working wheel for TF 1.8 compiled under CUDA 9.1 and CuDNN 7.1.2, then consider contributing it to TinyMind, they seem to be missing 1.8", "@Harbing: \r\nI had a similar error message caused by Tensorflow expecting CUDA 9.0, when I tried to import it in a CUDA 9.1 NVIDIA-docker container. What solved the problem for me was the obvious thing: using a different build of TF, compatible with my CUDA 9.1 version. I used the [CUDA 9.1 Tensorflow 1.7 Python 3.6 wheel from TinyMind](https://github.com/mind/wheels/releases/tag/tf1.7-gpu-cuda91-nomkl). It loaded correctly and passed our usability test under CUDA Version 9.1.85 and cuDNN 7.1.2 (i.e. in the latest NVIDIA CUDA 9.1 container - [nvidia/cuda:9.1-cudnn7-devel](https://hub.docker.com/r/nvidia/cuda/)).\r\n\r\n\r\n\r\n", "@mirekphd, unfortunately there is no CUDA 9.2 build there.  To sum up, the problem is that Nvidia is pointing users to install CUDA 9.2, but the available builds are 9.0 compatible only.  It seems that the only solution is either downgrade to CUDA 9.0 (could use some help here, I couldn't find a simple way in Nvidia's site) or to compile Tensorflow from source. ", "@fredguth on Linux at least, I just need to unpack cuda under different folders. Right now, I have:\r\n\r\n /usr/local/cuda-8.0  /usr/local/cuda-9.0  /usr/local/cuda-9.1\r\n\r\nPlus /usr/local/cuda as a symlink to whichever one I want to be my default.", "It was just released a couple days ago.  There are a few problems:\r\n\r\n1) It shipped day one with a patch\r\n2) the device driver is very new  396.26 is needed. Ubuntu does not have it in their repo just yet and it will be a while before Debian has it even in experimental.  The DGX-1 also does not have a driver that supports it.  \r\n\r\nNot sure who will read this, but I am concluding that we should roll out TensorFlow with 9.1 as the default, which seems to be stable with ~4 patches you have to apply.  The downside is the NVIDIA download site for cuDNN does not list 9.1 but I think you can just use cuDNN based on 9.0 and that is just a typo.  \r\n\r\nVery much welcome feedback.  Keep in mind the target audience is a wide range of people and upgrading to a device driver released just a few days ago as a requirement to install TensorFlow is a little steep.  \r\n\r\nI would also like feedback on this idea:  I would like to have a second \"cutting edge\" build that is linux only to reduce the amount of resources needed to test and deploy.  Likely linux + python 2.x.  This will be really vital to many of you when we start playing with CUDA 10.  I am not aware of anything huge in CUDA 9.0 to 9.2 that is amazing but with data as proof I could be very wrong.  \r\n\r\nEdited:  Years to days.\r\n", "> upgrade to a device driver released just a few years ago\r\n\r\nI think you probably mean \"days\", not years, right? :-)\r\n\r\nAnother side of the story might be that people who right away upgrade to the newest TensorFlow version are cutting-edge anyway and also don't mind upgrading to the latest device driver.\r\nI do believe that there's a significant portion of people that like to live on the \"edge\" and have the latest stuff, particularly with respect to CUDA version.\r\nLike in the spirit of \"Live at head\" that Google is already promoting, at least with respect to C++ and Abseil.\r\n\r\n> have a second \"cutting edge\" build\r\n\r\nI do like the idea about that. Would be nice if there was a Windows build too though. Doesn't have to be for all Python versions etc., just the latest would be fine, to reduce the number of builds needed.\r\n\r\nBut why would you use python 2.x for that? There's not really much \"cutting edge\" about that. I don't think I even have python 2.x installed anymore.", "@tfboyd cudnn 7.1.4 for cuda 9.2 is link to *_92.dll and for 9.0 use *_90.dll. It is not typo, nvidia delete all cudnn 7.1.* for cuda 9.1 download link except cudnn 7.1.2 for Linux (Power8/Power9).\r\n\r\n@patrikhuber \r\nHere is tensorflow-gpu1.8.0 with cuda 9.2, cudnn 7.1.4 for windows.\r\nhttps://github.com/fo40225/tensorflow-windows-wheel/tree/master/1.8.0/py36/GPU/cuda92cudnn71sse2", "@fo40225 Thanks for this wheel, I am able to install it under Anaconda 3.6 Python on a dual-1080 Ti machine with the latest official CUDA 9.2 driver 397.93, and run Keras R.", "@fo40225 Thanks for your answer , it works for me.", "Finally a tutorial on [How to install Tensorflow GPU with CUDA 9.2, cudnn 7.1.4 and NCCL 2.2 for python on Ubuntu](http://www.python36.com/how-to-install-tensorflow-gpu-with-cuda-9-2-for-python-on-ubuntu/)\r\n\r\nUpdate : Article updated to support Ubuntu 18.04 too.", "@arunmandal53  I try this tutorial on ubuntu18.04\uff0cFailed\u3002", "@fo40225 I installed tensorflow-gpu1.8.0 with cuda 9.2, cudnn 7.1.4 for windows but i still get this error message when importing tensorflow:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\royba\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 75, in preload_check\r\n    ctypes.WinDLL(build_info.cudart_dll_name)\r\n  File \"C:\\Users\\royba\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\ctypes\\__init__.py\", line 348, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] The specified module could not be found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\royba\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\royba\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\royba\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Users\\royba\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit\r\n\r\nshouldn't it recall cudart64_92.dll rather than cudart64_90.dll?", "@fo40225 I get the same issue as @VRscience  above!\r\n", "...well I take that back. after exiting the command line and opening a new command window and re-activating the conda environment I did the installation in, going into python no longer showed the error above. \r\nrunning python without pre-activating the conda environment did complain.\r\ninstallation successful.", "@purpledawn777 Are you using CUDA 9.2 toolkit? No other CUDA toolkit is installed in your machine?\r\nI am still struggling with it but I do not really see how to solve the issue but downgrade to CUDA 9.0...", "@VRscience I am using toolkit 9.2 \r\nI installed in an anaconda environment and I first created a tensorflow conda environment, as instructed in the tensorflow instructions.\r\nwhen testing it complained about not finding cuda 9.0.\r\nI then installed the wheel nicely provided by fo40225 \r\nwhen I tested immediately it still had the error, but then when I reopened the command line, activate tensorflow and tested again, it worked.... sorta -- it now complained about missing cuDNN7, but I just had to install that from Nvidia's website into the cuda 9.2 directories and it works fully now.\r\n  ", "@purpledawn777 I did exactly the same but i keep on having the same issue. Also, it seems there is no more need of installing the wheel provided by @fo40225 as on (tensorflow)C:> pip install --ignore-installed --upgrade tensorflow-gpu the wheel installed is already tensorflow_gpu-1.8.0-cp36-cp36m-win_amd64.whl . \r\n\r\nAny idea?", "@mirekphd \r\nSorry for the slow response. Every PR for TensorFlow is unit tested across every platform we support and then internally run against an even large set of tests.  Adding another version of CUDA expands the matrix and we are currently using hundreds of GPUs just for the unit testing much less performance testing.  CUDA 9.1 ended up being a slight perf regression depending on how you look at the results and what is compared.  I like all the builds people do to try out new things.\r\n\r\nNVIDIA's official DGX-1 also was not upgraded and still, as of today, only supports CUDA 9.0 with the official image.\r\n\r\n@fo40225 You likely figured this out but you can just use the CUDA 9.0 cuDNN with CUDA 9.1.  That is what NVIDIA suggested when I saw that a few days back.  I would not bother with CUDA 9.1.\r\n\r\n@ViktorM  1.9 will be CUDA 9.0.  CUDA 9.1 seems to have a perf regression (check out my updated original post above) or I might have pushed for the upgrade after the driver for CUDA 9.2 was newer than I expected.  I am still working on NCCL 2.x as that provides a nice boost, but there are some license issues to work out.\r\n\r\n**Note**:  I think it is cool other people post how to compile.  The community likely does a better job than I would as I take short cuts and have some weird preferences as to how I like to install things.  I also only do linux and old python (@patrikhuber :-))  What I can do in the future is post how I compiled along with the sha-hash or branch where I did so.  Far from perfect and if other people are ahead of me that is great.  I have a small insight.  TensorFlow is part of the Brain team at Google.  While some might upgrade to the latest versions of cuDNN and such, it is not something I hear people talking about.  I am still hopeful that CUDA 10 will bring a new approach to drivers that makes it easier for us to roll out minor CUDA bumps with less pain.  \r\n\r\n**As a random note.**  I strongly suggest using Docker.  I use to deal with all of these different versions of CUDA in python virtual environments.  I feel kind of silly having not moved to docker sooner.  So much better.  \r\n\r\n", "If someone wants to install CUDA 9.2 to Ubuntu 18.04, use this.\r\n\r\n```\r\nsudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64/7fa2af80.pub\r\necho \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64 /\" | sudo tee /etc/apt/sources.list.d/cuda.list\r\nsudo apt update\r\nsudo apt -o Dpkg::Options::=\"--force-overwrite\" install cuda-9-2 cuda-drivers\r\nsudo reboot\r\n```", "I still think all of you are nuts (meant to be funny) not to just use docker and just keep your local device driver updated.  :-)  That is how I do the performance testing, if you were curious.  Total docker convert here and I fought it to the end.", "I build the cuda9.2 for TensorFlow1.8.0 on python3.6 use the ubuntu18.04\r\n\r\nhttps://github.com/mtianyan/tensorflow-linux-wheel", "I migrated to TensorFlow r1.8 with cuda 9.2.88+patch 1, cuDNN 7.1.4  from r1.3 20 days ago. Maybe some issues I experienced and found the way out would help you.\r\nhttps://github.com/tensorflow/tensorflow/issues/19371", "@alanhsieh2000  \r\nHi, I also have cuda 9.2.88 with patch1, cuDNN 7.1.4, and tensorflow-gpu 1.8 in conda virtue environment with python 3.6. But I got following problem. Do you have any ideas?\r\n\r\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\r\nThanks!\r\n", "@XiaoqiChai \r\nDid you build tensorflow r1.8 from source? It looks like your python is trying to load cuda 9.0 rather than cuda 9.2. This information is specified when you configure Bazel before you started to build. You have to give it 9.2 rather than 9, when the config tool asks you for the cuda version.", "I have recently created a Dockerfile that make it easy for anyone to compile tensorflow in Linux: https://github.com/hadim/docker-tensorflow-builder\r\n\r\n", "Install Cuda 9.2.88_windows 10, and cuDNN 7.1 for cuda 9.2. dll is copied to \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.2\\bin\".  \r\ninstalled tensorflow gpu python 3.6\r\nBut getting error while importing tensorflow\r\n(tf15) C:\\Users\\91966>python\r\nPython 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\91966\\Anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 75, in preload_check\r\n    ctypes.WinDLL(build_info.cudart_dll_name)\r\n  File \"C:\\Users\\91966\\Anaconda3\\envs\\tf15\\lib\\ctypes\\__init__.py\", line 348, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] The specified module could not be found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\91966\\Anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\91966\\Anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\91966\\Anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Users\\91966\\Anaconda3\\envs\\tf15\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit\r\n>>>\r\n\r\nI tried to downgrade to 9.0, but failed to so.\r\n\r\nIs there a solution for issue#1 and if not how do I downgrade to 9.0?", "@VRscience Have you found a solution to your issue yet? I am getting the exact same issue (and it looks like @Sri06006 has run into this issue as well). It does look like the wheel being installed when running `pip install --upgrade tensorflow-gpu` is the one that purports to be for cuda 9.2 (the one @fo40225 posted) and yet when you look into the `build_info` after installation, it definitely says the build version is for cuda 9.0. So I am confused. I've tried uninstalling and reinstalling, clearing my cache and then reinstalling, and nothing seems to work. The only thing I can think to do right now is to install cuda 9.0 alongside cuda 9.2 (they can coexist afaik) and see if that helps, but it seems like I will be missing out on any potential performance boosts with cuda 9.2. ", "problem is resolved.  Have found solution .\r\ncould not point to the right one. Here is what I did\r\nUninstalled all CUDA files in my system, cleared the registry\r\n\r\nInstalled CUDA 9.0 and unchecked the visual studio integration during installation\r\nand copied the dll from cuDNN to bin folder in v9.0/\r\nyou can try installing cuda 9.0 and set the environment Path to \r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\r\n\r\nRestart the computer after setting the environment variables\r\n\r\ninstall the tensorflow-gpu  \r\n", "@Sri06006 I was also able to get things working by installing CUDA 9.0. I installed it along side CUDA 9.2 since I was told they can coexist. Things are working, but I still think it's odd that the whl file's description would say it has CUDA 9.2 support if it only explicitly looks for CUDA 9.0. ", "I have successfully built and run tensorflow1.8 and 1.9rc1 against cuda9.2+patch1 and cudnn 7.1, with python3.5 on Ubuntu 16.04. I installed cuda9.2 stuffs in a separate test folder (use the .run files without sudo) \r\n\r\nI  source this script when building and whenever I run these versions of tf (tf1.9 compiled with openmpi. but need to change line 76 of tensorflow/tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc  from se to stream_executor or build would fail) \r\n\r\n$PYTHONUSERBASE is set to the test folder so pip3 install --user would install the test tf whl (only one of 1.8 or 1.9rc can exist of course)inside the test folder without messing up the system's version. To invoke it would need to prepend $PYTHONPATH accordingly. \r\n\r\nThis way it would invoke the test version of tf and it would point to the matching version of cuda (9.2 instead of system's 9.1)\r\n```\r\nexport PREFIX=/home/beew/opt/cuda_test/cuda92\r\nexport PATH=$PREFIX/cuda/bin:$PREFIX/bin:$PATH\r\nexport CUDA_SDK_ROOT_DIR=$PREFIX/samples/common\r\nexport TENSORRT_PATH=$PREFIX/TensorRT-4.0.1.6\r\n\r\nexport LD_LIBRARY_PATH=$PREFIX/cuda/lib64:$PREFIX/cuda/extras/CUPTI/lib64:$LD_LIBRRAY_PATH:$TENSORRT_PATH/lib\r\n\r\nexport PYTHONUSERBASE=$PREFIX\r\n\r\nexport PYTHONPATH=$PREFIX/lib/python3.5/site-packages:$PYTHONPATH\r\n\r\nexport MPI_HOME=/usr/lib/openmpi\r\n\r\nexport CPATH=$PREFIX/include:$CPATH\r\nexport LIBRARY_PATH=$PREFIX/lib:$LIBRARY_PATH\r\nexport LD_LIBRARY_PATH=$PREFIX/lib:$LD_LIBRARY_PATH\r\n\r\nalias nvblas92=\"LD_PRELOAD=$PREFIX/cuda/lib64/libnvblas.so\"\r\n```", "Nagging Assignee @tfboyd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "this issue can be closed, it's working with cuda 9.2 and cudnn 7.1 already", "@tfboyd I'm sorry that this will probably sound like a rant, but since you explicitly solicited for feedback...\r\n\r\nYou say that you want to cater for a wide audience and therefore not force an upgrade to a new driver, and I'd say that's the right approach. However, in my experience due to the combination of (1) TensorFlow requiring a specific version of CUDA, and (2) distributions generally not supporting having multiple distributor-provided CUDA versions simultaneously installed, TensorFlow is one of the most difficult pieces of software to get to work. Almost every time I have installed TensorFlow on a computer there has been a mismatch of CUDA/cublas/cudnn/whatever versions. This is a major hassle, to the extent that usually my first reaction to code that uses TensorFlow is to search for an implementation for one of the other deep learning frameworks (I do have a CPU-only version of TensorFlow installed on my development workstation currently). I just don't want to go through the hassle of maintaining manually installed parallel versions of CUDA. The fact that you praise Docker as a solution should be good evidence that things are not as easy as they should \u2013 though probably it's still good advice.\r\n\r\nRight now, a competing deep learning framework doesn't yet support CUDA 9.2, but I find that forgivable when they provide binaries for CUDA versions 8, 9.0 and 9.1, with 9.2 coming soon. I don't know how they manage it, but installing the other framework has never been a hassle, while installing TensorFlow has always been painful. \r\n\r\nI do think however (with little actual knowledge) that Linux distributions could provide coinstallable CUDA packages (like cuda-9.0, cuda-9.1, cuda-9.2), just like there can be multiple different-sonamed versions of libraries. I can't understand why it's not done like that; at least for the required libraries it seems the exact same problem.\r\n\r\nSo, if the goal is to cater for a wide audience, sorry to say but in my opinion it's not working.", "after thousands of trails which included adding the variables to the paths, installing cuda9.0 besides cuda9.2 and installing cudnn7.0 from the archive nothing solved the problem except when I restarted my machine. Not sure if  restarting would solve the problem without the other steps", "@sliedes  The part you may be missing is licensing and the legal ability to distribute something like CUDA, cuDNN (officially it is behind a login), or the other associated libraries.\r\n\r\nAs a side thing, I updated the install guide to include [installing everything from NVIDIA with apt-get](https://www.tensorflow.org/versions/r1.10/install/install_linux#tensorflow_gpu_support).  I have done this myself on a clean system and it seems to be smooth.  I would still do it from docker as it is easy to get the packages mixed up and get the versions misaligned.\r\n\r\nOn a positive side CUDA 10 will not require device driver updates and amusingly enough is going to be more backwards compatible than CUDA 9.2.  I and I am sure others have been working with NVIDIA to simplify everything.  ", "Hopefully, this wheel file below helps. \r\nTensorFlow 1.9.0 build with cuda 9.2, cudnn 7.1.4 and python 3.5 on ubuntu 16.04: \r\nhttps://github.com/fangyihao/tensorflow-wheels/blob/master/tensorflow-1.9.0-cp35-cp35m-linux_x86_64.whl", "hi is there a Windows build that works with Cuda 9.2?\r\n\r\n9.0 is 10 months out of date and tensorflow is unusable on windows. do people only update tensorflow once a year?", "I have been able to build tensorflow-gpu on Cuda 9.2 and Cuda 10 on Ubuntu 16.04, basically just configure, choose your options and install whatever missing. Shouldn't be a problem on  Centos if you have up to date bazel and Nvidia driver", "I have started a thread on CUDA 10. \r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/22706", "> Hopefully, this wheel file below helps.\r\n> TensorFlow 1.9.0 build with cuda 9.2, cudnn 7.1.4 and python 3.5 on ubuntu 16.04:\r\n> https://github.com/fangyihao/tensorflow-wheels/blob/master/tensorflow-1.9.0-cp35-cp35m-linux_x86_64.whl\r\n@fangyihao how have you built this one? Any chance you can share the dockerfile (if any)?"]}, {"number": 18905, "title": "the error message of \"OP_REQUIRES failed at mkl_concat_op.cc:784 : Aborted: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781            INFO:tensorflow:Error reported to Coordinator: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781    \"", "body": "When running the deeplab model (train.py) included in tensorflow, it keeps generating the log message such as following. I don't know what does it mean.\r\n```\r\n\r\n2018-04-26 13:37:54.472896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0                                                        \r\n2018-04-26 13:37:54.472907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N                                                        \r\nINFO:tensorflow:Restoring parameters from /user/DL-Phase3/DeepLab/ADE20K/train_on_train_set/train/model.ckpt-0                  \r\nINFO:tensorflow:Running local_init_op.                                                                                                            \r\nINFO:tensorflow:Done running local_init_op.                                                                                                       \r\nINFO:tensorflow:Starting Session.                                                                                                                 \r\nINFO:tensorflow:Saving checkpoint to path /user/DL-Phase3/DeepLab/ADE20K/train_on_train_set/train/model.ckpt                    \r\nINFO:tensorflow:Starting Queues.                                                                                                                  \r\n2018-04-26 13:38:17.513798: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at mkl_concat_op.cc:784 : Aborted: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781           \r\nINFO:tensorflow:Error reported to Coordinator: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781                                                                                             \r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]                                                                              \r\n\r\nCaused by op 'concat', defined at:\r\n  File \"train.py\", line 386, in <module>\r\n    tf.app.run()                        \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))                                                                                                        \r\n  File \"train.py\", line 278, in main                                                                                             \r\n    clones = model_deploy.create_clones(config, model_fn, args=model_args)                                                       \r\n  File \"/tmp/test/models/research/slim/deployment/model_deploy.py\", line 193, in create_clones                                   \r\n    outputs = model_fn(*args, **kwargs)                                                                                          \r\n  File \"train.py\", line 207, in _build_deeplab                                                                                   \r\n    fine_tune_batch_norm=FLAGS.fine_tune_batch_norm)                                                                             \r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 296, in multi_scale_logits                                             \r\n    fine_tune_batch_norm=fine_tune_batch_norm)                                                                                   \r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 461, in _get_logits                                                    \r\n    fine_tune_batch_norm=fine_tune_batch_norm)                                                                                   \r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 424, in _extract_features                                              \r\n    concat_logits = tf.concat(branch_logits, 3)                                                                                  \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1181, in concat\r\n    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)                                                               \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 949, in concat_v2\r\n    \"ConcatV2\", values=values, axis=axis, name=name)                                                                                        \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper                                                                                                                                          \r\n    op_def=op_def)                                                                                                                                \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op         \r\n    op_def=op_def)                                                                                                                                \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__          \r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access                                                            \r\n\r\nAbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781                                                                                                    \r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]                                                                              \r\nTraceback (most recent call last):                                                                                                                \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1327, in _do_call         \r\n    return fn(*args)                                                                                                                              \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1312, in _run_fn          \r\n    options, feed_dict, fetch_list, target_list, run_metadata)                                                                                    \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1420, in _call_tf_sessionrun                                                                                                                                                \r\n    status, run_metadata)                                                                                                                         \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__   \r\n    c_api.TF_GetCode(self.status.status))                                                                                                         \r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781                                                                                      \r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]                                                                              \r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception                                                                                                                                             \r\n    yield                                                                                                                                         \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 495, in run         \r\n    self.run_loop()                                                                                                                               \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 1030, in run_loop    \r\n    self._sv.global_step])                                                                                                                        \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 905, in run               \r\n    run_metadata_ptr)                                                                                                                             \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1140, in _run             \r\n    feed_dict_tensor, options, run_metadata)                                                                                                      \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run          \r\n    run_metadata)                                                                                                                                 \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call         \r\n    raise type(e)(node_def, op, message)                                                                                                          \r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781                                                                                      \r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]                                                                              \r\n\r\nCaused by op 'concat', defined at:\r\n  File \"train.py\", line 386, in <module>\r\n    tf.app.run()                        \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))                                                                                                        \r\n  File \"train.py\", line 278, in main                                                                                             \r\n    clones = model_deploy.create_clones(config, model_fn, args=model_args)                                                       \r\n  File \"/tmp/test/models/research/slim/deployment/model_deploy.py\", line 193, in create_clones                                   \r\n    outputs = model_fn(*args, **kwargs)                                                                                          \r\n  File \"train.py\", line 207, in _build_deeplab                                                                                   \r\n    fine_tune_batch_norm=FLAGS.fine_tune_batch_norm)                                                                             \r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 296, in multi_scale_logits                                             \r\n    fine_tune_batch_norm=fine_tune_batch_norm)                                                                                   \r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 461, in _get_logits                                                    \r\n    fine_tune_batch_norm=fine_tune_batch_norm)                                                                                   \r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 424, in _extract_features                                              \r\n    concat_logits = tf.concat(branch_logits, 3)                                                                                  \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1181, in concat\r\n    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)                                                               \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 949, in concat_v2\r\n    \"ConcatV2\", values=values, axis=axis, name=name)                                                                                        \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper                                                                                                                                          \r\n    op_def=op_def)                                                                                                                                \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op         \r\n    op_def=op_def)                                                                                                                                \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__          \r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access                                                            \r\n\r\nAbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781                                                                                                    \r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]                                                                              \r\n\r\n2018-04-26 13:38:18.049156: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at mkl_concat_op.cc:784 : Aborted: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781           \r\nINFO:tensorflow:Retrying training!                                                                                                                \r\n2018-04-26 13:38:18.592880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1394] Ignoring visible gpu device (device: 0, name: Quadro 5000, pci bus id: 0000:05:00.0, compute capability: 2.0) with Cuda compute capability 2.0. The minimum required Cuda capability is 3.0.                   \r\n2018-04-26 13:38:18.592940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:                                                                                                                                                 \r\n2018-04-26 13:38:18.592950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0                                                        \r\n2018-04-26 13:38:18.592958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N                                                        \r\nINFO:tensorflow:Restoring parameters from /user/DL-Phase3/DeepLab/ADE20K/train_on_train_set/train/model.ckpt-0                  \r\nINFO:tensorflow:Running local_init_op.                                                                                                            \r\nINFO:tensorflow:Done running local_init_op.                                                                                                       \r\nINFO:tensorflow:Starting Session.                                                                                                                 \r\nINFO:tensorflow:Saving checkpoint to path /user/DL-Phase3/DeepLab/ADE20K/train_on_train_set/train/model.ckpt                    \r\nINFO:tensorflow:Starting Queues.                                                                                                                  \r\n2018-04-26 13:38:42.322907: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at mkl_concat_op.cc:784 : Aborted: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781           \r\nINFO:tensorflow:Error reported to Coordinator: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781                                                                                             \r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]                                                                              \r\n\r\nCaused by op 'concat', defined at:\r\n  File \"train.py\", line 386, in <module>\r\n    tf.app.run()                        \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))                                                                                                        \r\n  File \"train.py\", line 278, in main                                                                                             \r\n    clones = model_deploy.create_clones(config, model_fn, args=model_args)                                                       \r\n  File \"/tmp/test/models/research/slim/deployment/model_deploy.py\", line 193, in create_clones                                   \r\n    outputs = model_fn(*args, **kwargs)                                                                                          \r\n  File \"train.py\", line 207, in _build_deeplab                                                                                   \r\n    fine_tune_batch_norm=FLAGS.fine_tune_batch_norm)                                                                             \r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 296, in multi_scale_logits                                             \r\n    fine_tune_batch_norm=fine_tune_batch_norm)                                                                                   \r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 461, in _get_logits                                                    \r\n    fine_tune_batch_norm=fine_tune_batch_norm)                                                                                   \r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 424, in _extract_features                                              \r\n    concat_logits = tf.concat(branch_logits, 3)                                                                                  \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1181, in concat\r\n    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)                                                               \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 949, in concat_v2\r\n    \"ConcatV2\", values=values, axis=axis, name=name)                                                                                        \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper                                                                                                                                          \r\n    op_def=op_def)                                                                                                                                \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op         \r\n    op_def=op_def)                                                                                                                                \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__          \r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access                                                            \r\n\r\nAbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781                                                                                                    \r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]                                                                              \r\nTraceback (most recent call last):                                                                                                                \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1327, in _do_call         \r\n    return fn(*args)                                                                                                                              \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1312, in _run_fn          \r\n    options, feed_dict, fetch_list, target_list, run_metadata)                                                                                    \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1420, in _call_tf_sessionrun                                                                                                                                                \r\n    status, run_metadata)                                                                                                                         \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__   \r\n    c_api.TF_GetCode(self.status.status))                                                                                                         \r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781                                                                                      \r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]                                                                              \r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception                                                                                                                                             \r\n    yield                                                                                                                                         \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 495, in run         \r\n    self.run_loop()                                                                                                                               \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 1030, in run_loop    \r\n    self._sv.global_step])                                                                                                                        \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 905, in run               \r\n    run_metadata_ptr)                                                                                                                             \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1140, in _run             \r\n    feed_dict_tensor, options, run_metadata)                                                                                                      \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run          \r\n    run_metadata)                                                                                                                                 \r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call         \r\n    raise type(e)(node_def, op, message)                                                                                                          \r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781                                                                                      \r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]\r\n\r\nCaused by op 'concat', defined at:\r\n  File \"train.py\", line 386, in <module>\r\n    tf.app.run()\r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"train.py\", line 278, in main\r\n    clones = model_deploy.create_clones(config, model_fn, args=model_args)\r\n  File \"/tmp/test/models/research/slim/deployment/model_deploy.py\", line 193, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\n  File \"train.py\", line 207, in _build_deeplab\r\n    fine_tune_batch_norm=FLAGS.fine_tune_batch_norm)\r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 296, in multi_scale_logits\r\n    fine_tune_batch_norm=fine_tune_batch_norm)\r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 461, in _get_logits\r\n    fine_tune_batch_norm=fine_tune_batch_norm)\r\n  File \"/tmp/test/models/research/deeplab/model.py\", line 424, in _extract_features\r\n    concat_logits = tf.concat(branch_logits, 3)\r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1181, in concat\r\n    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 949, in concat_v2\r\n    \"ConcatV2\", values=values, axis=axis, name=name)\r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\r\n    op_def=op_def)\r\n  File \"/user/virtualE/deeplab/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nAbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781\r\n         [[Node: concat = _MklConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ResizeBilinear_1, aspp0/Relu, aspp1_pointwise/Relu, aspp2_pointwise/Relu, aspp3_pointwise/Relu, concat/axis, DMT/_313, aspp0/Relu:1, aspp1_pointwise/Relu:1, aspp2_pointwise/Relu:1, aspp3_pointwise/Relu:1, DMT/_314)]]\r\n\r\n2018-04-26 13:38:42.846252: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at mkl_concat_op.cc:784 : Aborted: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:781\r\nINFO:tensorflow:Retrying training!\r\n2018-04-26 13:38:43.479830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1394] Ignoring visible gpu device (device: 0, name: Quadro 5000, pci bus id: 0000:05:00.0, compute capability: 2.0) with Cuda compute capability 2.0. The minimum required Cuda capability is 3.0.\r\n2018-04-26 13:38:43.479882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-04-26 13:38:43.479896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0\r\n2018-04-26 13:38:43.479906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N\r\nINFO:tensorflow:Restoring parameters from /user/DL-Phase3/DeepLab/ADE20K/train_on_train_set/train/model.ckpt-0\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Starting Session.\r\nINFO:tensorflow:Saving checkpoint to path /user/DL-Phase3/DeepLab/ADE20K/train_on_train_set/train/model.ckpt\r\nINFO:tensorflow:Starting Queues.\r\n\r\n\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "You will have to rollback to TF1.6 to get this resolved.\r\n\r\nRefer this issue for more details https://github.com/tensorflow/tensorflow/issues/17494", "Hi s-ravichandran, I rollbacked to TF1.6, and got the same problem. The python is 3.5", "Related to https://github.com/tensorflow/tensorflow/issues/17494 as @wenouyang also noticed. ", "Please follow #17494 and close this bug.", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "I also have this error.I need help"]}, {"number": 18904, "title": "Relevant fluctuations in activations depending on batch size, at test time", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: \r\n- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: GeForce GTX 1080 8GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm using the slim implementation of resnet-v1-50 . The logits seem to change depending on the test batch_size used.\r\n\r\nI would expect some instability due to parallelism mechanisms on GPU, but I found out this behavior after the model's accuracy changed when batch_size changed. Thus, some fluctuations might be so big that they change predictions, which is not irrelevant.\r\n\r\nIf this is not a bug, is there a way to prevent this / what is the recommended way to evaluate our models?\r\n\r\n### Source code / logs\r\nI attach source code that tests this scenario. It was tested on tf version 1.3 .\r\nto run: python test_batch_size.py --batch_size=1\r\n\r\nIt prints the logits for the first frame of the batch. It saves the frame so you can be sure it's the very same frame. It loads all the weights from a checkpoint, and batchnorm is disabled with is_training=False.\r\n\r\nplease vary the batch_size argument, and see that the activations change.\r\nhttps://www.dropbox.com/s/ns9j84t02zifdaa/test_batch_size.zip?dl=0", "comments": ["Sorry, it was my mistake :)"]}, {"number": 18903, "title": "Feature: tf.contrib.rnn Downsampling Wrapper ", "body": "### Feature description\r\n-  On sequential inputs with many timesteps (e.g. speech), it is common to down-sample the higher order representations in a multi-layer recurrent network to improve the computation time and eventually the attention weights learning [1]. The MultiRNNCell class in TensorFlow simplifies the construction of multi-layered RNNs but gives users no control to post-process the outputs of intermediate layers. Would it be possible to add a new cell wrapper implementing RNN layer output sub-sampling, or more general used-defined post-processing ? The simplest case could be down-sampling the outputs by a factor of 2, as in [1], section 3.1, but without concatenation.\r\n\r\nThanks,\r\nGeorge \r\n\r\n[1] https://arxiv.org/abs/1508.01211", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This is a feature, am I expected to fill in the template ?\r\nEugene ( @ebrevdo ), we've discussed several times about the rnn code, could you please suggest a neat way to achieve this behaviour ?\r\nThank you.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 18902, "title": "Read the model from external storage instead of assets (runtime) [android]", "body": "Would be great to read the model from external storage instead of assets.\r\nAssets is ok when your model doesn't change. But what if we need to load the model dynamically on runtime. \r\nThe usage example is for assets:\r\n`TensorFlowImageClassifier.create(-->AssetManager<--,...)`\r\n\r\n\r\n", "comments": ["Ok, so there's a constructor of TensorFlowInferenceInterface for inputStream, that's enough. Closing. "]}, {"number": 18901, "title": "contrib/pi_examples's Makefile is missing lib nsync.a", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Raspbian Stretch\r\n- **TensorFlow installed from (source or binary)**: source (not installed)\r\n- **TensorFlow version (use command below)**: 1.8.0rc1\r\n- **Python version**: -\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: 4.8\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: follow instructions here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples\r\n\r\n### Describe the problem\r\nAttempting to build the sample with `make` will fail in the linking stage with an `undefined reference to `nsync::nsync_cv_signal(nsync::nsync_cv_s_*)'`.\r\nAdding `-Ltensorflow/contrib/makefile/downloads/nsync/builds/default.linux.c++11` to `LDFLAGS` (taken from the env var TARGET_NSYNC_LIB) and `-l:nsync.a` to `LIBS` fixes the problem.\r\nSo far I hardcoded the paths, so I can't really make a PR (and I'm not experienced enough with shell scripts / makefiles to propose a decent fix).\r\n", "comments": ["Nagging Assignee @petewarden: It has been 95 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 18900, "title": "Adding Wrapper for Ridge Solver", "body": "Created a wrapper to run a sklearn.linear_model.Ridge solver in a Tensorflow Session to allow for faster convergence when optimizing a linear least squares + l2 regularization problem", "comments": ["Nagging Assignees @ekelsen, @rmlarsen: It has been 17 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi, could someone check this PR? Thanks!", "Nagging Assignees @ekelsen, @rmlarsen: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @ekelsen, @rmlarsen: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Seems like our bot mistakenly removed \"waiting for response\" label. Please address comments about tests on this PR. Thanks!", "It has been 28 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 18899, "title": "pi_examples/label_image.cc has wrong include order for libjpg.h", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Raspbian stretch\r\n- **TensorFlow installed from (source or binary)**: source (not installed though)\r\n- **TensorFlow version (use command below)**: 1.8.0rc1\r\n- **Python version**: -\r\n- **Bazel version (if compiling from source)**: Built using makefiles\r\n- **GCC/Compiler version (if compiling from source)**: 4.8\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: Follow instructions in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples\r\n\r\n### Describe the problem\r\nAs mentioned in [this issue](https://github.com/libjpeg-turbo/libjpeg-turbo/issues/17), `#include <libjpg.h>` has to be after `#include <stdio.h>` or else it won't have definitions for `FILE`, `size_t`, etc.\r\nIn the current version of label_image.cc the order of the includes is wrong ad thus the build fails.\r\nSwapping the two includes fixes the problem (I'll provide a PR as soon as I have time, if someone else doesn't beat me to it first)", "comments": ["We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18898, "title": "[r1.7][TensorRT] INT8 mode calibration is not worked", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat 4.8.5-16, Linux version 3.10.0-693.5.2.el7.x86_64\r\n- **TensorFlow installed from (source or binary)**: pip (python 2.7)\r\n- **TensorFlow version (use command below)**: tensorflow-gpu==1.7.0\r\n- **Python version**: python 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: gcc 5.3\r\n- **CUDA/cuDNN version**:  CUDA9.0, cuDNN7.0.5\r\n- **GPU model and memory**: Tesla P4, 8GB\r\n- **Exact command to reproduce**: My own script is coded based on the official test \"tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\", so I think you can reproduce this problem with this test. \r\n\r\n### Describe the problem\r\nI tried to use Tensorflow 1.7 to do the prediction under Python environment, which can integrate the TensorRT to optimize the GraphDef.\r\n\r\nThe optimization in FP32 mode is successfully done, but when I tried the INT8 mode, I'm confused about how to do the calibration. I checked the examples both from tensorflow source code and the NVidia dev guide but still not sure. \r\n\r\nBelow is part of the example that contained within tensorflow.\r\n```\r\ndef run_calibration(gdef, dumm_inp):\r\n  \"\"\"Run given calibration graph multiple times.\"\"\"\r\n  gpu_options = cpb2.GPUOptions(per_process_gpu_memory_fraction=0.50)\r\n  ops.reset_default_graph()\r\n  g = ops.Graph()\r\n  with g.as_default():\r\n    inp, out = importer.import_graph_def(\r\n        graph_def=gdef, return_elements=[\"input\", \"output\"])\r\n    inp = inp.outputs[0]\r\n    out = out.outputs[0]\r\n  with csess.Session(\r\n      config=cpb2.ConfigProto(gpu_options=gpu_options), graph=g) as sess:\r\n    # run over real calibration data here, we are mimicking a calibration set of\r\n    # 30 different batches. Use as much calibration data as you want\r\n    for _ in range(30):\r\n      val = sess.run(out, {inp: dumm_inp})\r\n  return val\r\n############################\r\n int8_calib_gdef = trt.create_inference_graph(\r\n     input_graph_def=orig_graph,\r\n     outputs=[\"output\"],\r\n     max_batch_size=inp_dims[0],\r\n     max_workspace_size_bytes=1 << 25,\r\n     precision_mode=\"INT8\",  # TRT Engine precision \"FP32\",\"FP16\" or \"INT8\"\r\n     minimum_segment_size=2  # minimum number of nodes in an engine\r\n )\r\n _ = run_calibration(int8_calib_gdef, dummy_input)\r\n int8_graph = trt.calib_graph_to_infer_graph(int8_calib_gdef)\r\n o5 = run_graph(int8_graph, dummy_input)\r\n```\r\nAbove code is copied from tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py\r\nThe function run_calibration seems just create a session and run 30 times with the same input, and the return of run_calibration seems not used at all. \r\n\r\nHow could the calibration be done in this way? \r\n\r\nThanks,", "comments": ["@oscarriddle the code above is an example. As written in the comment this is a dummy code just to work the machinery. For real calibration you need to run, as much as you want, with an input data set that is representative of your expected inference input. So you need to replace `for _ in range(30): sess.run()` with something that passes real data at every iteration. For example if you have a network classifying dogs, pass in pictures of the dogs instead of the same picture like we do to execute the machinery. More pictures you pass, better is the calibration. Let me know if this clarifies it.", "Hi samikama,\r\n\r\nI figured out the solution. The root cause that I can't get calibration successfully done is because calibration can't accept batch input. Now I changed to run session 1 image at a time in the calibration, and it indeed works.\r\n\r\nThanks for your reply. You convinced me on this."]}, {"number": 18897, "title": "Tensorflow model training working slow", "body": " I have arond 1500 images  with 7 classes i know its less but i am rookie in machine learning and object detection. Due to technical limitation i am currently training the model  using tensorflow cpu version. the machine is taking 20 second/step. and it took 3 days to reach 11000 steps. i want to reach atleast 40000 steps.  My question is it always take that long time for training the model in tensorflow-cpu or is there some problem? please answer my question as soon as possible\r\n\r\nI am using tensorflow-cpu version 1.5 the reason of using this version is that in tensorflow-1.7 i am getting the depracation warning and  was not able to train the model on my laptop\r\n\r\nIf i am doing something wrong please guide me \r\nthanking you in anticipation", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Sorry there is a mistake on my end which is I am using tensorflow 1.6 I am really sorry to misguide you earlier, The tensorflow is installed from pypi tensorflow-1.6.0rc1-cp36-cp36m-win_amd64.whl package. windows 8.1  x86 64 bit. CPU model.  I am currently at **INFO:tensorflow:global step 12719: loss = 0.0651 (22.916 sec/step)** in training of the model It is taking 15 to 22 second to complete one step. which is very slow. so please help me and again sorry for the mistake  i have done", "Nagging Assignee @michaelisard: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 18896, "title": "Fix some issues in official tf.nn.topk() in lite", "body": "Not sure if Google is planning a breaking change. If not:\r\n\r\n1. The topk_v2 implementation has its output **values** and **indices** in the opposite order.\r\n\r\n    Below is TensorFlow Python API behavior:\r\n\r\n    ```python\r\n    In [5]: x\r\n    Out[5]: <tf.Tensor 'x:0' shape=(100,) dtype=float32>\r\n\r\n    In [7]: y, z = tf.nn.top_k(x, k=10)\r\n\r\n    In [8]: y\r\n    Out[8]: <tf.Tensor 'TopKV2:0' shape=(10,) dtype=float32>\r\n\r\n    In [10]: z\r\n    Out[10]: <tf.Tensor 'TopKV2:1' shape=(10,) dtype=int32>\r\n    ```\r\n\r\n2. Output array types are not correctly propagated.\r\n3. First output array name should not be appended with `\":0\"` because it is deliberately removed [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/import_tensorflow.cc#L2039).\r\n4. If `k` is provided at run time, two output arrays will be dynamic, and have shape [..., 0] [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc#L1142-L1143). I changed toco to only check constant buffers instead, RFC.", "comments": []}, {"number": 18895, "title": "'concave points_mean' is not a valid scope name", "body": "I am running my models in **Google's Colaboratory Cloud Platform** and I never confronted this error message.\r\n\r\nPython Version (Colaboratory Notebook): `Python3`\r\nHardware Accelerator: `GPU`\r\n\r\n(before creating this issue I did my research but found no useful content)\r\n\r\nMy code has something like this,\r\n```\r\nperiods = 10\r\nsteps_per_period = steps / periods\r\n  \r\n# Create linear_classifier object and configure it.\r\nmy_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\r\nmy_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\r\nlinear_classifier = tf.estimator.LinearClassifier(\r\n    feature_columns = construct_feature_columns(training_examples),\r\n    optimizer = my_optimizer\r\n)\r\n```\r\nand inside a `for` loop, I am training my model like this,\r\n```\r\nfor period in range(0, periods):\r\n    linear_classifier.train(\r\n        input_fn = training_input_fn,\r\n        steps = steps_per_period\r\n    )\r\n```\r\nThe error below:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-44-b9598a3db7f4> in <module>()\r\n      6     training_targets = training_targets,\r\n      7     validation_examples = validation_examples,\r\n----> 8     validation_targets = validation_targets\r\n      9 )\r\n\r\n<ipython-input-43-0ca23946204e> in train_linear_classfication_model(learning_rate, steps, batch_size, training_examples, training_targets, validation_examples, validation_targets)\r\n     43     linear_classifier.train(\r\n     44         input_fn = training_input_fn,\r\n---> 45         steps = steps_per_period\r\n     46     )\r\n     47 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    353 \r\n    354     saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 355     loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    356     logging.info('Loss for final step: %s.', loss)\r\n    357     return self\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n    822       worker_hooks.extend(input_hooks)\r\n    823       estimator_spec = self._call_model_fn(\r\n--> 824           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n    825 \r\n    826       if self._warm_start_settings:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\r\n    803 \r\n    804     logging.info('Calling model_fn.')\r\n--> 805     model_fn_results = self._model_fn(features=features, **kwargs)\r\n    806     logging.info('Done calling model_fn.')\r\n    807 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/canned/linear.py in _model_fn(features, labels, mode, config)\r\n    316           optimizer=optimizer,\r\n    317           partitioner=partitioner,\r\n--> 318           config=config)\r\n    319 \r\n    320     super(LinearClassifier, self).__init__(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/canned/linear.py in _linear_model_fn(features, labels, mode, head, feature_columns, optimizer, partitioner, config)\r\n    156     logit_fn = _linear_logit_fn_builder(\r\n    157         units=head.logits_dimension, feature_columns=feature_columns)\r\n--> 158     logits = logit_fn(features=features)\r\n    159 \r\n    160     def _train_op_fn(loss):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/canned/linear.py in linear_logit_fn(features)\r\n     97         feature_columns=feature_columns,\r\n     98         units=units,\r\n---> 99         cols_to_vars=cols_to_vars)\r\n    100     bias = cols_to_vars.pop('bias')\r\n    101     if units > 1:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py in linear_model(features, feature_columns, units, sparse_combiner, weight_collections, trainable, cols_to_vars)\r\n    423     for column in sorted(feature_columns, key=lambda x: x.name):\r\n    424       with variable_scope.variable_scope(\r\n--> 425           None, default_name=column._var_scope_name):  # pylint: disable=protected-access\r\n    426         ordered_columns.append(column)\r\n    427         weighted_sum = _create_weighted_sum(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in __enter__(self)\r\n   1901 \r\n   1902     try:\r\n-> 1903       return self._enter_scope_uncached()\r\n   1904     except:\r\n   1905       if self._graph_context_manager is not None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _enter_scope_uncached(self)\r\n   2001           self._default_name)\r\n   2002       try:\r\n-> 2003         current_name_scope_name = current_name_scope.__enter__()\r\n   2004       except:\r\n   2005         current_name_scope.__exit__(*sys.exc_info())\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in __enter__(self)\r\n   5773       try:\r\n   5774         self._name_scope = g.name_scope(self._name)\r\n-> 5775         return self._name_scope.__enter__()\r\n   5776       except:\r\n   5777         self._g_manager.__exit__(*sys.exc_info())\r\n\r\n/usr/lib/python3.6/contextlib.py in __enter__(self)\r\n     79     def __enter__(self):\r\n     80         try:\r\n---> 81             return next(self.gen)\r\n     82         except StopIteration:\r\n     83             raise RuntimeError(\"generator didn't yield\") from None\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in name_scope(self, name)\r\n   3977         # (viz. '-', '\\', '/', and '_').\r\n   3978         if not _VALID_SCOPE_NAME_REGEX.match(name):\r\n-> 3979           raise ValueError(\"'%s' is not a valid scope name\" % name)\r\n   3980       else:\r\n   3981         # Scopes created in the root must match the more restrictive\r\n\r\nValueError: 'concave points_mean' is not a valid scope name\r\n```\r\n**Update**: I tried variables like `steps_per_period` as `global scope` and reran the model, but still the same issue persisting.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Actually as I mentioned, I am running `TensorFlow` on **Google Colaboratory Cloud Platform**. Hence no setup required and other information of `TensorFlow` installation and `Operating System`.", "I am so sorry. It was my mistake. My data set was not proper. My apologies.", "Hey @acesaif \r\n\r\nI am having same issue with my dataset. what was the issue with your dataset?\r\nkindly shre that.\r\n\r\nThank you", "See it is supposed to be `concave_points_mean` instead of `concave points_mean`. I hope you understand.", "Yes. I got it.\r\nThank you for your response"]}, {"number": 18894, "title": "TfLite Image classification score is not consistent it keeps increasing for same image untill it reaches to some saturation(actual score)", "body": "With same instance of 'interpreter' score is getting increased for same image until it reaches at some saturation.\r\n`Interpreter tflite = new Interpreter(loadModelFile(context));`\r\n\r\nCreate Instance for ImageClassifier and use the same instance to classify Frame and run inference for the same image.\r\n```\r\nImageClassifier(Activity activity) throws IOException {\r\n    tflite = new Interpreter(loadModelFile(activity));\r\n    labelList = loadLabelList(activity);\r\n    imgData =\r\n        ByteBuffer.allocateDirect(\r\n            DIM_BATCH_SIZE\r\n                * getImageSizeX()\r\n                * getImageSizeY()\r\n                * DIM_PIXEL_SIZE\r\n                * getNumBytesPerChannel());\r\n    imgData.order(ByteOrder.nativeOrder());\r\n    filterLabelProbArray = new float[FILTER_STAGES][getNumLabels()];\r\n    Log.d(TAG, \"Created a Tensorflow Lite Image Classifier.\");\r\n  }\r\n```\r\n\r\nClassifies a frame for the same image. Same image can be picked up from the Sd card.\r\n\r\n```\r\nprivate void classifyImage() {\r\n    if (classifier == null || getActivity() == null || cameraDevice == null) {\r\n      showToast(\"Uninitialized Classifier or invalid context.\");\r\n      return;\r\n    }\r\n    String imgPath =  \"/storage/emulated/0/DCIM/test.jpg\";\r\n    Log.d(\"Image Path is %s\", imgPath);\r\n    Bitmap bitmap = BitmapFactory.decodeFile(imgPath);\r\n    Bitmap newbitmap = Bitmap.createScaledBitmap(bitmap, 299, 299, false);\r\n    String textToShow = classifier.classifyFrame(newbitmap);\r\n    bitmap.recycle();\r\n    showToast(textToShow);\r\n  }\r\n```\r\n\r\nAt the first time when application gets launched score the image classification is 0.06 and then again if we called classifyImage() on some event click score gets increased to 0.13 and with same process it keeps increasing until it reached to 0.86(saturation).\r\n\r\nI am not sure why its happening but it happened for both type of TfLite models inceptionV3 and MobileNet.", "comments": ["I think this is because TF Lite reuses the input buffer during inference, so it will be slightly different next time. We are working on a fix for it.", "Thanks Andrehentz  for the reply.\r\nIts not slightly different it keeps increasing as i mentioned it started from 0.06 and goes upto 0.86.\r\nTo test the scenario and replicate the issue just put the image into somewhere phone memory/SD Card and use the same image to classify the frame.\r\n\r\nFor example : \r\n   ```\r\nString imgPath =  \"/storage/emulated/0/DCIM/test.jpg\";\r\n    Log.d(\"Image Path is %s\", imgPath);\r\n    Bitmap bitmap = BitmapFactory.decodeFile(imgPath);\r\n    Bitmap newbitmap = Bitmap.createScaledBitmap(bitmap, 299, 299, false);\r\n    String textToShow = classifier.classifyFrame(newbitmap);\r\n```", "Please try commenting out the following line in classifier.classifyFrame()\r\n\r\n    // Smooth the results across frames.\r\n    applyFilter();", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 46 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 61 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@princekumar15 , did @myth01' suggestion solve your problem?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This is actually fixed in the latest release (certainly the latest nightly, 1.10-rc1 also). the interpreter used to destroy the input buffer (and reuse it for temporaries during the computation). Closing now due to lack of recent activity (and it's already fixed).", "@aselle could you point to the commit of the fix?", "@aselle , @myth01 solution working for me. commented applyFilter();"]}]