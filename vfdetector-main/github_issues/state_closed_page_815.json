[{"number": 29085, "title": "Fixed a nccl broadcast bug", "body": "The `NcclBroadcastRecvKernel` in `tensorflow/core/kernels/nccl_ops.cc` mistakenly calls the `AddBroadcastSend` and the `NcclManager::AddParticipant` doesn't consider the situation when `participant->input` might be a nullptr, causing the segfault error (e.g., in the broadcast receive, the input is a nullptr).\r\n\r\nThese two problems are fixed in this PR.\r\n\r\nFYI. @nluehr ", "comments": ["@dubey There some 3 failed tests in Ubuntu Python 2/3. From the logs, it seems it is irrelevant to this PR. Could you please help check?"]}, {"number": 29084, "title": "Updated sigmoid activation function with arguments and returns.", "body": "I just added some documentation to the sigmoid function.", "comments": ["Changes have already been made."]}, {"number": 29083, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 7 Enterprise 64-bit (6.1, Build 7601)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): not sure\r\n- TensorFlow version:  1.13.1\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version:  cudatoolkit: 10.0.130/ cudnn: 7.3.1\r\n- GPU model and memory: Intel(R) HD Graphics 520, 1888 MB\r\n\r\n\r\n\r\n**Describe the problem**\r\nI installed tensorflow from anaconda and first installed everything in base (root), upon running `import tensorflow` I encountered this issue.\r\nThen per suggestions from #22794 , I followed the instructions from [link](https://www.pugetsystems.com/labs/hpc/The-Best-Way-to-Install-TensorFlow-with-GPU-Support-on-Windows-10-Without-Installing-CUDA-1187/) which is detailed below. But the same issue persisted.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nconda update conda\r\nconda update anaconda\r\nconda update python\r\nconda update --all\r\n\r\nconda create --name tf-gpu\r\ncmd\r\nconda activate tf-gpu\r\n\r\nconda install tensorflow-gpu keras-gpu  \r\nconda install -c aaronzs tensorflow-gpu\r\nconda install -c anaconda cudatoolkit\r\nconda install -c anaconda cudnn\r\n\r\npython\r\nimport tensorflow as tf\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n> ImportError: Traceback (most recent call last):\r\n>   File \"C:\\Users\\JOLOU\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n>     from tensorflow.python.pywrap_tensorflow_internal import *\r\n>   File \"C:\\Users\\JOLOU\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n>     _pywrap_tensorflow_internal = swig_import_helper()\r\n>   File \"C:\\Users\\JOLOU\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n>   File \"C:\\Users\\JOLOU\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n>     return load_dynamic(name, filename, file)\r\n>   File \"C:\\Users\\JOLOU\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n>     return _load(spec)\r\n> ImportError: DLL load failed: The specified module could not be found.\r\n> \r\n> \r\n> Failed to load the native TensorFlow runtime.\r\n> \r\n> See https://www.tensorflow.org/install/errors\r\n> \r\n> for some common reasons and solutions.  Include the entire stack trace\r\n> above this error message when asking for help.\r\n> \r\n> ", "comments": ["I have tried methods from #22872 by downgrading the packages, including tensorflow-gpu, cudatoolkit and cudnn, but the same error kept coming up.", "It worked after I removed tensorflow-gpu"]}, {"number": 29082, "title": "Fix reference count leak with scatter_nd", "body": "Fixes #27288\r\n\r\nPiperOrigin-RevId: 250102793", "comments": []}, {"number": 29081, "title": "A loss function for calculating categorical cross-entropy from the softmax probabilities", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI wish for a loss function that calculates categorical cross-entropy based on softmax predictions. As far as I have seen, there are only function that work with the logits. Why is there no way to use the softmax scores?\r\n\r\n**Will this change the current api? How?**\r\nYes, a function will be added.\r\n\r\n**Who will benefit with this feature?**\r\nPeople who wish to conceptually separate the model output and loss calculation. Also, in this way I do not have to change the model in order to use it for prediction.", "comments": ["Hi, did you already look at `tf.keras.losses.CategoricalCrossentropy`? It seems to work with both `from_logits = True/False`.\r\nAs last layer of your network you still want to use softmax right?", "> Hi, did you already look at `tf.keras.losses.CategoricalCrossentropy`? It seems to work with both `from_logits = True/False`.\r\n> As last layer of your network you still want to use softmax right?\r\n\r\nCompletely missed that one, thanks! And yes, I would like to be able to complete my model with a softmax layer."]}, {"number": 29080, "title": "Updated linear activation function with arguments, returns and note.", "body": "This is my first commit.\r\nPlease, feel free to comment on this small change.", "comments": []}, {"number": 29079, "title": "Error convert pb file to tflite", "body": "## System information\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Maybe, prelu function, See[link](https://github.com/sirius-ai/MobileFaceNet_TF/blob/bccb7bd7faf503ffb792f18d7ea3ed7ec6e1d092/nets/MobileFaceNet.py#L268)\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): 1.13\r\nPython version: 3.7.3\r\nBazel version (if compiling from source): not compile\r\n\r\n## Describe the current behavior\r\n\r\nI use the project of [MobileFaceNet_TF](https://github.com/sirius-ai/MobileFaceNet_TF)\r\n\r\nThe project has pretrained model in the path of [arch/pretrained_model](https://github.com/sirius-ai/MobileFaceNet_TF/tree/master/arch/pretrained_model).\r\n\r\nI want to convert [the freeze pb file](https://github.com/sirius-ai/MobileFaceNet_TF/blob/master/arch/pretrained_model/MobileFaceNet_9925_9680.pb) to tflite file, the pb file freezed by [the script](https://github.com/sirius-ai/MobileFaceNet_TF/blob/master/utils/freeze_graph.py)\r\n\r\n1. In the path of `arch/pretrained_model`, i use under tflite_conver command to convert model to tflite.\r\n\r\n```cmd\r\ntflite_convert  ^\r\n--output_file  MobileFaceNet_9925_9680.tflite  ^\r\n--graph_def_file  MobileFaceNet_9925_9680.pb    ^\r\n--input_arrays  \"input\"  ^\r\n--input_shapes  \"1,112,112,3\"  ^\r\n--output_arrays  embeddings  ^\r\n--output_format  TFLITE\r\n```\r\n\r\n2. I also use toco, but the error is same.\r\n\r\n```cmd\r\ntoco ^\r\n--output_file MobileFaceNet_9925_9680.tflite ^\r\n--graph_def_file MobileFaceNet_9925_9680.pb ^\r\n--output_format TFLITE ^\r\n--inference_type FLOAT ^\r\n--inference_input_type FLOAT ^\r\n--input_arrays input ^\r\n--input_shapes 1,112,112,3 ^\r\n--output_arrays embeddings\r\n```\r\n\r\n3. I use python api, the error is same.\r\n\r\n```py\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph('arch/pretrained_model/MobileFaceNet_9925_9680.pb',input_arrays=['input'],output_arrays=['embeddings'],input_shapes={'input':[1,112,112,3]})\r\ntflite_model = converter.convert()\r\nopen(\"test.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n4. I try tensorflow 2.0, but not found api which can import pb file.\ud83d\ude13\r\n\r\n## Code to reproduce the issue\r\n\r\n### the tflite_convert tool error infomation\r\n\r\n```cmd\r\n\u03bb tflite_convert  ^\r\nMore? --output_file  MobileFaceNet_9925_9680.tflite  ^\r\nMore? --graph_def_file  MobileFaceNet_9925_9680.pb    ^\r\nMore? --input_arrays  \"input\"  ^\r\nMore? --input_shapes  \"1,112,112,3\"  ^\r\nMore? --output_arrays  embeddings  ^\r\nMore? --output_format  TFLITE\r\n2019-05-28 15:32:07.380246: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2019-05-28 15:32:08.157890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:\r\nname: GeForce MX150 major: 6 minor: 1 memoryClockRate(GHz): 1.341\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 2.00GiB freeMemory: 1.62GiB\r\n2019-05-28 15:32:08.185527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-05-28 15:32:08.727623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-05-28 15:32:08.742876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0\r\n2019-05-28 15:32:08.753078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N\r\n2019-05-28 15:32:08.764321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1365 MB memory) -> physical GPU (device: 0, name: GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\Scripts\\tflite_convert-script.py\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 442, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 438, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 191, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 455, in convert\r\n    **converter_kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 442, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 205, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-05-28 15:32:13.074828: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2019-05-28 15:32:13.078767: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\r\n2019-05-28 15:32:13.079077: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\r\n2019-05-28 15:32:13.079438: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\r\n2019-05-28 15:32:13.079756: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\r\n2019-05-28 15:32:13.087213: E tensorflow/lite/toco/import_tensorflow.cc:2079] tensorflow::ImportGraphDef failed with status: Not found: Op type not registered 'Placeholder' in binary running on DESKTOP-TG1FKM4. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n2019-05-28 15:32:13.434412: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2747 operators, 4533 arrays (0 quantized)\r\n2019-05-28 15:32:13.816499: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1810 operators, 3076 arrays (0 quantized)\r\n2019-05-28 15:32:14.122395: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1810 operators, 3076 arrays (0 quantized)\r\n2019-05-28 15:32:14.124627: F tensorflow/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:98] Check failed: other_op->type == OperatorType::kMerge Found BatchNormalization as non-selected output from Switch, but only Merge supported.\r\n```\r\n\r\n### the toco tool error information\r\n\r\n```cmd\r\ntoco ^\r\nMore? --output_file MobileFaceNet_9925_9680.tflite ^\r\nMore? --graph_def_file MobileFaceNet_9925_9680.pb ^\r\nMore? --output_format TFLITE ^\r\nMore? --inference_type FLOAT ^\r\nMore? --inference_input_type FLOAT ^\r\nMore? --input_arrays input ^\r\nMore? --input_shapes 1,112,112,3 ^\r\nMore? --output_arrays embeddings\r\n2019-05-29 09:50:45.125226: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2019-05-29 09:50:45.877324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:\r\nname: GeForce MX150 major: 6 minor: 1 memoryClockRate(GHz): 1.341\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 2.00GiB freeMemory: 1.62GiB\r\n2019-05-29 09:50:45.899741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-05-29 09:50:46.412028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-05-29 09:50:46.424631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0\r\n2019-05-29 09:50:46.434346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N\r\n2019-05-29 09:50:46.441283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1365 MB memory) -> physical GPU (device: 0, name: GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\Scripts\\toco-script.py\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 442, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 438, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 191, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 455, in convert\r\n    **converter_kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 442, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 205, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-05-29 09:50:50.939448: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2019-05-29 09:50:50.942638: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\r\n2019-05-29 09:50:50.942917: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\r\n2019-05-29 09:50:50.943314: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\r\n2019-05-29 09:50:50.943634: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\r\n2019-05-29 09:50:50.950475: E tensorflow/lite/toco/import_tensorflow.cc:2079] tensorflow::ImportGraphDef failed with status: Not found: Op type not registered 'Placeholder' in binary running on DESKTOP-TG1FKM4. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n2019-05-29 09:50:51.309990: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2747 operators, 4533 arrays (0 quantized)\r\n2019-05-29 09:50:51.724318: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1810 operators, 3076 arrays (0 quantized)\r\n2019-05-29 09:50:52.042452: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1810 operators, 3076 arrays (0 quantized)\r\n2019-05-29 09:50:52.045060: F tensorflow/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:98] Check failed: other_op->type == OperatorType::kMerge Found BatchNormalization as non-selected output from Switch, but only Merge supported.\r\n```\r\n\r\n### the python api error information\r\n```py\r\n---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-7-5a3c093c4e77> in <module>\r\n      1 import tensorflow as tf\r\n      2 converter = tf.lite.TFLiteConverter.from_frozen_graph('arch/pretrained_model/MobileFaceNet_9925_9680.pb',input_arrays=['input'],output_arrays=['embeddings'],input_shapes={'input':[1,112,112,3]})\r\n----> 3 tflite_model = converter.convert()\r\n      4 open(\"test.tflite\", \"wb\").write(tflite_model)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)\r\n    453           input_tensors=self._input_tensors,\r\n    454           output_tensors=self._output_tensors,\r\n--> 455           **converter_kwargs)\r\n    456     else:\r\n    457       result = _toco_convert_graph_def(\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)\r\n    440   data = toco_convert_protos(model_flags.SerializeToString(),\r\n    441                              toco_flags.SerializeToString(),\r\n--> 442                              input_data.SerializeToString())\r\n    443   return data\r\n    444 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)\r\n    203       stderr = _try_convert_to_unicode(stderr)\r\n    204       raise ConverterError(\r\n--> 205           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    206   finally:\r\n    207     # Must manually cleanup files.\r\n\r\nConverterError: TOCO failed. See console for info.\r\n2019-05-29 09:43:46.962261: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2019-05-29 09:43:46.985465: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3499530000 Hz\r\n2019-05-29 09:43:46.987287: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a9808ffee0 executing computations on platform Host. Devices:\r\n2019-05-29 09:43:46.987353: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-05-29 09:43:47.089108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-05-29 09:43:47.089794: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a980904a30 executing computations on platform CUDA. Devices:\r\n2019-05-29 09:43:47.089868: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2019-05-29 09:43:47.090474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6575\r\npciBusID: 0000:42:00.0\r\ntotalMemory: 10.91GiB freeMemory: 9.87GiB\r\n2019-05-29 09:43:47.090496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-05-29 09:43:47.095453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-05-29 09:43:47.095478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-05-29 09:43:47.095487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-05-29 09:43:47.095829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9601 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)\r\n2019-05-29 09:43:47.227671: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2747 operators, 4533 arrays (0 quantized)\r\n2019-05-29 09:43:47.335840: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1810 operators, 3076 arrays (0 quantized)\r\n2019-05-29 09:43:47.418666: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1810 operators, 3076 arrays (0 quantized)\r\n2019-05-29 09:43:47.419336: F tensorflow/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:98] Check failed: other_op->type == OperatorType::kMerge Found BatchNormalization as non-selected output from Switch, but only Merge supported.\r\nAborted (core dumped)\r\n```\r\n", "comments": ["Hi,\r\n\r\nI believe this is caused by the control flow ops in your model. Currently the toco converter doesn't support converting control flow ops. We are actively working on that. Hopefully will get supported in the coming months.", "> Hi,\r\n> \r\n> I believe this is caused by the control flow ops in your model. Currently the toco converter doesn't support converting control flow ops. We are actively working on that. Hopefully will get supported in the coming months.\r\n\r\nHey,\r\n I'm getting the same error trying to convert MobileFaceNet from a .pb to .tflite file. I noticed you closed the issue and was wondering if there was a way to convert the model. Is there a workaround or a function I can tinker with to get it to work?", "so is anyone gonna give an answer to this post lmao, so much comments but zero solutions shown lol\r\n", "Has this been fixed? ", " Has Anyone solved this problem?", "> so is anyone gonna give an answer to this post lmao, so much comments but zero solutions shown lol\r\nHave you solve it?\r\n", "Has someone resolved this issue?, I want to convert the ssd_resnet50_v1 and ssd_inception_v2_coco and both of them throw the OperatorType::kMerge Found StridedSlice as non-selected output from Switch, but only Merge supported."]}, {"number": 29078, "title": "Many false positives in a custom SSD model with Tensorflow object detection API", "body": "My model has 2 classes (no background class) and is trained using transfer learning with ssd_mobilenet_v2_coco. It detects and classifies well the objects it was trained on. However, on new images it also detects many false positive bounding box's of the background. Sometimes the background objects that are detected are objects that existed in the coco data set (e.g. a cup), but not only - also a black screen is detected as an object.\r\n\r\nCan it be that my model features are still sensitive to the Coco data set objects?\r\nI think that on the config file, the relevant part for this issue is the hard_example_miner. However I did not understand how is this related and if I should change my current configuration.\r\nThis is the configuration I'm using:\r\n\r\nhard_example_miner {\r\n\r\nnum_hard_examples: 3000\r\n\r\niou_threshold: 0.99\r\n\r\nloss_type: CLASSIFICATION\r\n\r\nmax_negatives_per_positive: 3\r\n\r\nin_negatives_per_image: 3\r\n\r\n}\r\n\r\nShould I make any changes to this? Or any other solutions to improve the model on background images?", "comments": ["@YonitZall This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!", "@YonitZall Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "> My model has 2 classes (no background class) and is trained using transfer learning with ssd_mobilenet_v2_coco. It detects and classifies well the objects it was trained on. However, on new images it also detects many false positive bounding box's of the background. Sometimes the background objects that are detected are objects that existed in the coco data set (e.g. a cup), but not only - also a black screen is detected as an object.\r\n> \r\n> Can it be that my model features are still sensitive to the Coco data set objects?\r\n> I think that on the config file, the relevant part for this issue is the hard_example_miner. However I did not understand how is this related and if I should change my current configuration.\r\n> This is the configuration I'm using:\r\n> \r\n> hard_example_miner {\r\n> \r\n> num_hard_examples: 3000\r\n> \r\n> iou_threshold: 0.99\r\n> \r\n> loss_type: CLASSIFICATION\r\n> \r\n> max_negatives_per_positive: 3\r\n> \r\n> in_negatives_per_image: 3\r\n> \r\n> }\r\n> \r\n> Should I make any changes to this? Or any other solutions to improve the model on background images?\r\n\r\nhi,\r\ndid you find any method other than create more class for solve this problem?\r\nThanks", "@YonitZall \r\ndid you get any solutions? I am facing the same problem", "There are different parameters that affect this, but when I did enough training with appropriate learning rate values, I was able to train a model with higher fps and accuracy than the faster rcnn model. You have to find out for yourself which parameter should be edited. Although it is not certain, as a general solution, it is also used as a solution to train in more than one class and only show the object you are looking for on the screen.", "> There are different parameters that affect this, but when I did enough training with appropriate learning rate values, I was able to train a model with higher fps and accuracy than the faster rcnn model. You have to find out for yourself which parameter should be edited. Although it is not certain, as a general solution, it is also used as a solution to train in more than one class and only show the object you are looking for on the screen.\r\n\r\nHello @selmankaplan \r\nThanks for the reply.\r\nCan you tell me which parameters should I look on ? And on which file will I get those parameters.\r\nI have used ssd pet config and I am working on bird detection. I have used pretrained model of  the Coco data  and find model is detecting bird as person in some cases. Any idea?", "If you're training using tensorflow, your train and test images and its label frames are effective parameters for your training data. If you created the dataset properly, the training parameters are included in the .config file. First of all, you should pay attention to the learning rate parameter and data augmentation options parameters. Although data augmentation parameters seemed to be a good choice, there were negative effects while training. I would like to state that I do not know whether the labels size is data augmentation or not when pictures data augmentation. I have doubts about this. Finally, you should make sure that you finish the training at the appropriate time. In this way, you can train in a simple train.\r\nIf you did a single-class training and get a person output instead of a bird, you can set this in your .bptxt file instead of the training. If you have done a training with more than one class, I recommend that you review your training from the beginning."]}, {"number": 29077, "title": "Issue with tf.nn.softmax_cross_entropy_with_logits when label value is 100+", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:  Installed from Docker official repo\r\n- **TensorFlow version (use command below)**: Ver 1.12.0\r\n- **Python version**: python 3.6\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:  7.4\r\nCuda Toolkit: 10.1\r\n- **GPU model and memory**: Tesla P100\r\n\r\n\r\nI have written a custom CNN for a semantic segmentation problem. For the loss function, I have used \r\ntf.nn.softmax_cross_entropy_with_logits(labels=tf.cast(tf.squeeze(one_hot_labels),dtype=tf.float32),logits =tf.squeeze(pred))\r\nHere is the interesting part, when some of my components within the image are labelled with values such as 100+(such as 105) the network fails to converge during training. If the same components are labelled with less than 100 such as (97) the loss converges. What could be the root cause of this issue here? \r\n\r\n", "comments": ["@Raj-08 In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n"]}, {"number": 29076, "title": "TensorBoard UI issue with tf.function", "body": "The code does not behave like the code in https://www.tensorflow.org/tensorboard/r2/graphs. It is rather a blank you with 3 words. \r\n\r\n", "comments": ["<img width=\"1440\" alt=\"Screen Shot 2019-05-28 at 3 22 20 PM\" src=\"https://user-images.githubusercontent.com/8387388/58471566-9bf55900-815d-11e9-91bd-bd5e1ef8fe85.png\">", "I apologize for the inconvenience the problem was with Safari, everything works as expected with google chrome(shocker).  ", "We will be closing the issue since it looks like it is resolved. Please feel free to open new issue in case you have any problem. Thanks! "]}, {"number": 29075, "title": "tf.function with input_signature slower on unseen sequence length", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Linux Ubuntu 16.04:\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: `2.0.0-dev20190526`\r\n- Python version: 3.6.6\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GTX 1060\r\n\r\n**Describe the current behavior**\r\n\r\nWhen running a `tf.function` on 3D inputs (a batch of sequence), I found that the execution is slower on unseen sequence length even if a compatible `input_signature` is set. On a large graph, this results in a low GPU usage and a growing CPU memory usage for several iterations until most sequence lengths are seen. It is as if new graphs were compiled internally even though the function does not seem to be retraced.\r\n\r\nThis effect does not affect eager mode or V1 graph mode where the execution directly runs at its target speed and memory usage.\r\n\r\n**Describe the expected behavior**\r\n\r\n`tf.function` with an input signature should behave like graph mode with constant memory usage and no \"warmup\" phase.\r\n\r\n**Code to reproduce the issue**\r\n\r\nWhile this issue is very visible on large graphs, I tried to compile a small example to consistently show the effect:\r\n\r\n```python\r\nimport time\r\nimport itertools\r\nimport random\r\n\r\nimport tensorflow as tf\r\n\r\ndef generate_token_based_shapes(num_tokens=4096):\r\n    while True:\r\n        length = random.randint(1, 100)\r\n        batch_size = int(num_tokens / length)\r\n        yield (batch_size, length)\r\n\r\n# Generate 500k tensors of shape [None, None, 512] but with similar total size.\r\nshapes = list(itertools.islice(generate_token_based_shapes(), 500000))\r\ndataset = tf.data.Dataset.from_tensor_slices(shapes)\r\ndataset = dataset.shuffle(len(shapes))\r\ndataset = dataset.map(lambda shape: tf.zeros(tf.concat([shape, [512]], axis=0)))\r\ndataset = dataset.repeat()\r\ndataset = dataset.prefetch(1)\r\n\r\n# Define a model with some layers.\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Dense(1024),\r\n    tf.keras.layers.Dense(1024),\r\n    tf.keras.layers.Dense(1024),\r\n    tf.keras.layers.Dense(1024),\r\n    tf.keras.layers.Dense(1024)])\r\n\r\n@tf.function(input_signature=(tf.TensorSpec([None, None, 512], dtype=tf.float32),))\r\ndef run_step(inputs):\r\n    return model(inputs)\r\n\r\nseen_lengths = set()\r\nfor x in dataset:\r\n    length = x.shape[1]\r\n    start = time.time()\r\n    _ = run_step(x)\r\n    end = time.time()\r\n    print(length in seen_lengths, end - start)\r\n    seen_lengths.add(length)\r\n```\r\n\r\n**Other info / logs**\r\n\r\nThe above code produced the following logs when run on CPU:\r\n\r\n```text\r\nFalse 0.43003296852111816\r\nFalse 0.11496973037719727\r\nFalse 0.11308979988098145\r\nFalse 0.11620664596557617\r\nFalse 0.11439895629882812\r\nFalse 0.11322546005249023\r\nTrue 0.095062255859375\r\nFalse 0.11357808113098145\r\nFalse 0.11438512802124023\r\nFalse 0.11338496208190918\r\nFalse 0.1123197078704834\r\nFalse 0.11295366287231445\r\nFalse 0.11250948905944824\r\nFalse 0.11576318740844727\r\nFalse 0.1139533519744873\r\nFalse 0.11278915405273438\r\nFalse 0.11090493202209473\r\nTrue 0.09256935119628906\r\nFalse 0.11287093162536621\r\nFalse 0.11374545097351074\r\nFalse 0.11446619033813477\r\nFalse 0.11277508735656738\r\nFalse 0.11354255676269531\r\nFalse 0.11325383186340332\r\nFalse 0.1137855052947998\r\nFalse 0.11451315879821777\r\nFalse 0.11423110961914062\r\nTrue 0.09340834617614746\r\nFalse 0.1146705150604248\r\nFalse 0.11285781860351562\r\nFalse 0.11371898651123047\r\nTrue 0.09309053421020508\r\nTrue 0.09239482879638672\r\nTrue 0.09140896797180176\r\nFalse 0.11467862129211426\r\nFalse 0.11377716064453125\r\nFalse 0.11178278923034668\r\nFalse 0.11260485649108887\r\nTrue 0.09450674057006836\r\nTrue 0.09363818168640137\r\nTrue 0.09272456169128418\r\nFalse 0.11517977714538574\r\nFalse 0.11325454711914062\r\nTrue 0.09257698059082031\r\nFalse 0.11360836029052734\r\nTrue 0.09241485595703125\r\nFalse 0.11343145370483398\r\nTrue 0.09368515014648438\r\nFalse 0.11366653442382812\r\nTrue 0.09125065803527832\r\nFalse 0.1126089096069336\r\nFalse 0.11182904243469238\r\nTrue 0.09548735618591309\r\nTrue 0.09283709526062012\r\n```\r\n\r\nWhen the length is unseen, it takes about 0.113s but 0.092s after that.\r\n\r\nOn this example the effect is small but I'm trying to train a Transformer model with `tf.function` and it takes very long for the training to reach full speed. The CPU memory usage also keeps growing during this \"warmup\" phase. The same model works well when integrated with `tf.estimator` as I'm trying to move from Estimator to V2 custom loops.", "comments": ["@guillaumekln Able to reproduce the issue, but the numbers in the output are different from the numbers you mentioned.", "Any update? This is still valid as of `2.0.0.dev20190606`.", "@allenlavoie do we retrace even when a signature is passed?", "We retrace in some cases (e.g. distribution strategy changed), but not for newly shaped Tensors. Easy enough to add a Python nonlocal counter or a logging statement to the function body to check how many times it gets traced; that may be a good start to debugging.", "The `tf.function` itself is not retraced. For reference, it worked properly in the alpha release (to compare with the logs above):\r\n\r\n```text\r\nFalse 0.49825453758239746\r\nFalse 0.09595465660095215\r\nFalse 0.09451770782470703\r\nFalse 0.0943748950958252\r\nFalse 0.09402847290039062\r\nFalse 0.09326910972595215\r\nTrue 0.09315991401672363\r\nFalse 0.09505486488342285\r\nFalse 0.09238004684448242\r\nFalse 0.09103155136108398\r\nFalse 0.09470963478088379\r\nFalse 0.09449291229248047\r\nTrue 0.09190535545349121\r\nFalse 0.09163832664489746\r\nTrue 0.09249663352966309\r\nFalse 0.09634065628051758\r\nFalse 0.09385347366333008\r\nFalse 0.09270620346069336\r\nFalse 0.09623479843139648\r\nFalse 0.09488368034362793\r\nTrue 0.093353271484375\r\nFalse 0.09451007843017578\r\nFalse 0.09360551834106445\r\nFalse 0.09260439872741699\r\nFalse 0.09208202362060547\r\nFalse 0.09282684326171875\r\nTrue 0.09669733047485352\r\nFalse 0.09361767768859863\r\nFalse 0.09194278717041016\r\nFalse 0.09254956245422363\r\nFalse 0.09276223182678223\r\nFalse 0.09399724006652832\r\nTrue 0.09332799911499023\r\nFalse 0.09316015243530273\r\nTrue 0.09275269508361816\r\nFalse 0.09307003021240234\r\nTrue 0.0928955078125\r\nTrue 0.09315705299377441\r\nTrue 0.0956425666809082\r\nFalse 0.09328627586364746\r\nTrue 0.09452319145202637\r\nTrue 0.09224057197570801\r\nTrue 0.09405398368835449\r\nFalse 0.09274768829345703\r\nFalse 0.09326839447021484\r\n``` ", "So after bisecting the nightly builds, I found that this behavior was introduced in `2.0.0.dev20190329`. Then I ran `git bisect` on commits from 2019-03-27 to 2019-03-29 and found that this was likely introduced by 1e5407a33311da085932e007c186891e75bfd314. The commit content appears relevant to this issue.\r\n\r\ncc @er91.", "Tong, I think this is another problem which will disappear if we do the fix I suggested about resource shapes and dtypes.", "Hi Alex,\r\n\r\nThe change I made for TPU works like this:\r\n1. In eager runtime, when we execute a tf.function, we attach resource shapes & dtypes to instantiation options\r\n2. During instantiation, we attach resource shapes & dtypes to FunctionBody's _Arg nodes\r\n3. TPU rewrite pass can get resource shapes & dtypes from _Arg nodes\r\n\r\nEven if we move resource shapes & dtypes into ResourceHandle, we still need a way to pass the information into tf.function. 2) and 3) still need to be done.\r\n\r\nI think the cause of the delay in this issue is, now for same tf.function but different input variable shape, we will instantiate it multiple times. Two possible solutions:\r\na. If there is a way to pass resource shapes & dtypes into tf.function's FunctionBody without modifying the graph, we can use the same instantiation result for different resource shapes & dtypes. (I thought about this when I made that change, but failed to come up with a way =])\r\nb. Since GPU works just fine without my change before, we can introduce a flag to avoid this re-instantiation only for GPU (but TPU still needs that)", "But variable shapes are not changing here, so I don't understand why the\ninstantiation gets repeated.\n\nOn Wed, Jun 12, 2019 at 9:40 AM er91 <notifications@github.com> wrote:\n\n> Hi Alex,\n>\n> The change I made for TPU works like this:\n>\n>    1. In eager runtime, when we execute a tf.function, we attach resource\n>    shapes & dtypes to instantiation options\n>    2. During instantiation, we attach resource shapes & dtypes to\n>    FunctionBody's _Arg nodes\n>    3. TPU rewrite pass can get resource shapes & dtypes from _Arg nodes\n>\n> Even if we move resource shapes & dtypes into ResourceHandle, we still\n> need a way to pass the information into tf.function. 2) and 3) still need\n> to be done.\n>\n> I think the cause of the delay in this issue is, now for same tf.function\n> but different input variable shape, we will instantiate it multiple times.\n> Two possible solutions:\n> a. If there is a way to pass resource shapes & dtypes into tf.function's\n> FunctionBody without modifying the graph, we can use the same instantiation\n> result for different resource shapes & dtypes. (I thought about this when I\n> made that change, but failed to come up with a way =])\n> b. Since GPU works just fine without my change before, we can introduce a\n> flag to avoid this re-instantiation only for GPU (but TPU still needs that)\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29075?email_source=notifications&email_token=AAABHRLRUX5AGPKJLC3VI4DP2ERH5A5CNFSM4HQBU25KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXRA4SQ#issuecomment-501354058>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHROGQD6GOM7UOB23P7TP2ERH5ANCNFSM4HQBU25A>\n> .\n>\n\n\n-- \n - Alex\n", "In bug reporter's example, the input variable to tf.function() does change :-)", "We are getting this issue in our molecular dynamics project where proteins have different numbers of atoms\r\n\r\nEvery batch, it retraces the step function batch_size times. Any workaround?", "Any update on this?\r\n\r\nThe workaround I used is to get the next element in the `tf.function` directly, for example:\r\n\r\n```python\r\nimport time\r\nimport itertools\r\nimport random\r\n\r\nimport tensorflow as tf\r\n\r\ndef generate_token_based_shapes(num_tokens=4096):\r\n    while True:\r\n        length = random.randint(1, 100)\r\n        batch_size = int(num_tokens / length)\r\n        yield (batch_size, length)\r\n\r\n# Generate 500k tensors of shape [None, None, 512] but with similar total size.\r\nshapes = list(itertools.islice(generate_token_based_shapes(), 500000))\r\ndataset = tf.data.Dataset.from_tensor_slices(shapes)\r\ndataset = dataset.shuffle(len(shapes))\r\ndataset = dataset.map(lambda shape: tf.zeros(tf.concat([shape, [512]], axis=0)))\r\ndataset = dataset.repeat()\r\ndataset = dataset.prefetch(1)\r\niterator = iter(dataset)\r\n\r\n# Define a model with some layers.\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Dense(1024),\r\n    tf.keras.layers.Dense(1024),\r\n    tf.keras.layers.Dense(1024),\r\n    tf.keras.layers.Dense(1024),\r\n    tf.keras.layers.Dense(1024)])\r\n\r\n@tf.function\r\ndef run_step():\r\n    inputs = next(iterator)\r\n    return model(inputs)\r\n\r\nseen_lengths = set()\r\nwhile True:\r\n    start = time.time()\r\n    x = run_step()\r\n    end = time.time()\r\n    length = x.shape[1]\r\n    print(length in seen_lengths, end - start)\r\n    seen_lengths.add(length)\r\n```", "I recommend always getting the next element inside the function as this\nshould always have superior performance (more pipelining available to the\nruntime)\n\nOn Wed, Jul 3, 2019 at 1:34 AM Guillaume Klein <notifications@github.com>\nwrote:\n\n> Any update on this?\n>\n> The workaround I used is to get the next element in the tf.function\n> directly, for example:\n>\n> import timeimport itertoolsimport random\n> import tensorflow as tf\n> def generate_token_based_shapes(num_tokens=4096):\n>     while True:\n>         length = random.randint(1, 100)\n>         batch_size = int(num_tokens / length)\n>         yield (batch_size, length)\n> # Generate 500k tensors of shape [None, None, 512] but with similar total size.\n> shapes = list(itertools.islice(generate_token_based_shapes(), 500000))\n> dataset = tf.data.Dataset.from_tensor_slices(shapes)\n> dataset = dataset.shuffle(len(shapes))\n> dataset = dataset.map(lambda shape: tf.zeros(tf.concat([shape, [512]], axis=0)))\n> dataset = dataset.repeat()\n> dataset = dataset.prefetch(1)\n> iterator = iter(dataset)\n> # Define a model with some layers.\n> model = tf.keras.Sequential([\n>     tf.keras.layers.Dense(1024),\n>     tf.keras.layers.Dense(1024),\n>     tf.keras.layers.Dense(1024),\n>     tf.keras.layers.Dense(1024),\n>     tf.keras.layers.Dense(1024)])\n> @tf.functiondef run_step():\n>     inputs = next(iterator)\n>     return model(inputs)\n>\n> seen_lengths = set()while True:\n>     start = time.time()\n>     x = run_step()\n>     end = time.time()\n>     length = x.shape[1]\n>     print(length in seen_lengths, end - start)\n>     seen_lengths.add(length)\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29075?email_source=notifications&email_token=AAABHRKMHNZS5EXU6PRDXV3P5RQCPA5CNFSM4HQBU25KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZDWCUY#issuecomment-507994451>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRNH2WUD3232IXA2T4TP5RQCPANCNFSM4HQBU25A>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp I understand that as much as possible should be done inside the function, but that's not practical since the training loop will probably not be that simple.\r\n\r\nIf you're handling varying-length data, it means things like keras' `.fit()` will likely not work for you and so you'll need to write your training loop from scratch, including everything you might need from metrics to progress trackers. It might also mean that you can't just use some tf.data.Dataset's features such as `.batch()`, and that so your shuffling+batching logic might be unfit to do within the TF graph altogether.\r\nIt makes a lot of sense to have some parts of that loop in tf.functions while others stay outside the graph.\r\n\r\nNote that the performance difference pointed in this issue is narrow because the model used is rather simple. The example in #29578 shows differences of about *45x* in performance (eg: time to handle a particular sample went from 1.103001594543457 due to retrace down to 0.02424478530883789 when lengths had been previously seen).", "Sorry to bump this issue again but will this get fixed for the final TensorFlow 2.0 release? If not, maybe the documentation should clarify that there is a second level of cache in the TensorFlow runtime in addition to the `tf.function` input signatures.\r\n\r\nWhile this issue can be mitigated when using datasets as shown above, I also found that functions loaded from a V2 `SavedModel` are barely usable because of it.", "Same issue with multiple parameters with variable length. If one parameter's length hasn't been seen, then the time is much slower than the step with all the variable's length been seen. ", "Can you try if https://github.com/tensorflow/tensorflow/commit/bb4cacfe453686fbc458bc83d3e92e8761fcfe4d solves your issue?\r\n\r\nBTW that commit only removes normal input tensor shape from cache key; if you have different input resource variable shapes, we still have to instantiate the function again (due to some other requirements in Tensorflow). This won't change very soon.", "Thanks @er91 , I'll test as soon as it gets into the nightly build.", "I confirm this is fixed in `2.0.0.dev20190829`. When running the code to reproduce, there is no longer a noticeable time difference between seen and unseen sequence lengths:\r\n\r\n```text\r\nFalse 0.378192663192749\r\nFalse 0.11128377914428711\r\nFalse 0.11080718040466309\r\nFalse 0.10891008377075195\r\nFalse 0.10831356048583984\r\nFalse 0.10732555389404297\r\nFalse 0.10800600051879883\r\nFalse 0.10589814186096191\r\nFalse 0.1084296703338623\r\nFalse 0.10618948936462402\r\nFalse 0.10782027244567871\r\nFalse 0.10433292388916016\r\nFalse 0.10707211494445801\r\nFalse 0.1098027229309082\r\nTrue 0.10712003707885742\r\nFalse 0.10629463195800781\r\nTrue 0.10657715797424316\r\nFalse 0.1062629222869873\r\nFalse 0.10881710052490234\r\nFalse 0.10586357116699219\r\nTrue 0.10734868049621582\r\nFalse 0.1084589958190918\r\nFalse 0.1089639663696289\r\nFalse 0.10571050643920898\r\nTrue 0.10631895065307617\r\nFalse 0.10663580894470215\r\nFalse 0.10557937622070312\r\nTrue 0.10591363906860352\r\nTrue 0.10362792015075684\r\nFalse 0.10501718521118164\r\nFalse 0.107269287109375\r\nFalse 0.10628437995910645\r\nFalse 0.1069636344909668\r\nFalse 0.10788226127624512\r\nTrue 0.10770535469055176\r\n```\r\n\r\nI propose to cherry-pick this into `r2.0`, see #32080.", "Will be released in 2.0 RC1", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29075\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29075\">No</a>\n", "> I recommend always getting the next element inside the function as this should always have superior performance (more pipelining available to the runtime)\r\n> -- Alex\r\n\r\nHi @alextp @guillaumekln \r\nI am using your suggestion to forward the iterator object to the @tf.function decorated _train_step function, and I have a small issue. How do you know that you have iterated through the dataset entirely, in order to compute several metrics at the end of an epoch ? Writing `try: iter.__next__() except tf.errors.OutOfRangeError: return None` inside `_train_step` does not seem to work. Thanks.\r\n", "@georgesterpu TF graphs don't support exception handling, so you need to use alternative methods. I recommend either [get_next_as_optional](https://www.tensorflow.org/api_docs/python/tf/data/experimental/get_next_as_optional) or rephrasing your loop using dataset.reduce and friends, like we do internally in autograph https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/operators/control_flow.py#L584\r\n\r\nCC @jsimsa and @mdanatg ", "As a purely recreational example - a slightly overkill way to write this pattern without the try-except:\r\n\r\n```\r\n  # Set up a default value - graph mode doesn't support None. Can be anything, not just zeros.\r\n  data = tf.nest.map_structure(lambda shape, dtype: tf.zeros(shape, dtype=dtype), it.output_shapes, it.output_types)\r\n  for d in it:\r\n    data = d\r\n    break\r\n  return data\r\n```\r\n\r\nThat said, `get_next_as_optional` is all-around cleaner because the code above will create a `tf.while_loop` and and at least one `tf.cond`.", "Thanks for the advice, @alextp and @mdanatg \r\nI replaced `batch = iterator.__next__()` with `batch = tf.data.experimental.get_next_as_optional(iterator)` inside my `_train_step`, and it did not work.\r\n\r\n`TypeError: '_OptionalImpl' object is not subscriptable`\r\n\r\nThis happens in a pre-processing function that packs the data into a namedtuple (e.g. `return BatchedData(\r\n            inputs=batch[0][0],\r\n            inputs_length=tf.cast(batch[0][1], tf.int32), [...]\r\n        )`\r\n\r\nI remember once trying to return the namedtuple in a `dataset.map` transformation, but faced some errors as well.", "For the optional you need to have a little graphlet to see if it's there or\nnot and conditionally execute code in either case.\n\nOn Fri, Nov 1, 2019 at 10:31 AM George Sterpu <notifications@github.com>\nwrote:\n\n> Thanks for the advice, @alextp <https://github.com/alextp> and @mdanatg\n> <https://github.com/mdanatg>\n> I replaced batch = iterator.__next__() with batch =\n> tf.data.experimental.get_next_as_optional(iterator) inside my _train_step,\n> and it did not work.\n>\n> TypeError: '_OptionalImpl' object is not subscriptable\n>\n> This happens in a pre-processing function that packs the data into a\n> namedtuple (e.g. return BatchedData( inputs=batch[0][0],\n> inputs_length=tf.cast(batch[0][1], tf.int32), [...] )\n>\n> I remember trying once to return the namedtuple in a dataset.map\n> transformation, but faced some errors as well.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29075?email_source=notifications&email_token=AAABHRITGIRWRLPG2QRB7XLQRRRXXA5CNFSM4HQBU25KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEC3TBNQ#issuecomment-548876470>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRLMOZOFP6E6JVII36TQRRRXXANCNFSM4HQBU25A>\n> .\n>\n\n\n-- \n - Alex\n", "@georgesterpu the result of `get_next_as_optional` is an [Optional](https://www.tensorflow.org/api_docs/python/tf/data/experimental/Optional) which means you will have use `tf.cond` to check whether it contains a value (and if so extract the value using `get_value`) before indexing it.", "Here's a snippet that shows the use of Optional. Note the tf.nest trick to handle any structure your dataset may have. The choice of zeros for default value is entirely arbitrary:\r\n\r\nWith autograph:\r\n```\r\n  opt_data = tf.data.experimental.get_next_as_optional(it)\r\n  if opt_data.has_value():\r\n    return opt_data.get_value()\r\n  return tf.nest.map_structure(lambda shape, dtype: tf.zeros(shape, dtype=dtype), it.output_shapes, it.output_types)\r\n```\r\n\r\nWith tf.cond:\r\n```\r\n  opt_data = tf.data.experimental.get_next_as_optional(it)\r\n  return tf.cond(\r\n      opt_data.has_value(),\r\n      lambda: opt_data.get_value(),\r\n      lambda: tf.nest.map_structure(lambda shape, dtype: tf.zeros(shape, dtype=dtype), it.output_shapes, it.output_types))\r\n```\r\n\r\nThe two examples are equivalent.", "@alextp @jsimsa `get_value` might use an optional `default_value` argument to simplify this pattern.", "Thanks a lot for the examples.\r\nI've tried both variants, but I get:\r\n`ValueError: Cannot convert a partially known TensorShape to a Tensor: (None, None, 240)`\r\n```\r\noptional = tf.data.experimental.get_next_as_optional(iterator)\r\nif optional.has_value():\r\n    batch = optional.get_value()\r\nelse:\r\n    batch = tf.nest.map_structure(lambda shape, dtype: tf.zeros(shape, dtype), iterator.output_shapes, iterator.output_types)\r\n```\r\n\r\nStill, I don't understand the mechanism to signal the end of an epoch. Was initially thinking of something like:\r\n```\r\nif optional.has_value():\r\n    batch = optional.get_value()\r\nelse:\r\n    return None\r\n```\r\nand in the `train` function:\r\n```\r\nwhile True:\r\n    loss = _train_step(iterator)\r\n    if loss is None:\r\n        break\r\n```\r\nbut autograph expects both branches to have the same structure.", "Ah, I suspect the error comes from trying to call tf.zeros with a partially-known shape. Then my nest trick doesn't work :(. Instead you'll need to craft a structure by hand. Something like this should work - the important part it to use a structure and shapes consistent with those created by your dataset. Based on the error message, this should work:\r\n\r\n```\r\nif optional.has_value():\r\n    batch = optional.get_value()\r\nelse:\r\n    batch = tf.zeros((0, 0, 240))  # or whatever structure you get from get_value\r\n```\r\n\r\nAs for signaling the end of an epoch, I recommend setting up a separate return value. As long as you avoid using `None`, things should work:\r\n\r\n```\r\nif optional.has_value():\r\n    batch = optional.get_value()\r\n    is_done = False\r\nelse:\r\n    batch = tf.zeros((0, 0, 240))\r\n    is_done = True\r\nreturn batch, is_done\r\n```\r\n\r\nLmk if that works.", "Thanks a lot for your support, @mdanatg \r\nThis time it actually worked.\r\n\r\nThe Optional structure looks like this:\r\n```\r\nFirst structure:\r\n type=tuple str=((\r\n <tf.Tensor 'OptionalGetValue:0' shape=(None, None, 240) dtype=float32>, \r\n <tf.Tensor 'OptionalGetValue:1' shape=(None,) dtype=int64>,\r\n <tf.Tensor 'OptionalGetValue:2' shape=(None,) dtype=string>),\r\n \r\n (<tf.Tensor 'OptionalGetValue:3' shape=(None, None) dtype=int64>,\r\n  <tf.Tensor 'OptionalGetValue:4' shape=(None,) dtype=int64>,\r\n  <tf.Tensor 'OptionalGetValue:5' shape=(None,) dtype=string>,\r\n  <tf.Tensor 'OptionalGetValue:6' shape=(None,) dtype=string>))\r\n```\r\nso I wrote my code as follows:\r\n```\r\noptional = tf.data.experimental.get_next_as_optional(iterator)\r\nif optional.has_value():\r\n    batch = optional.get_value()\r\n    is_done = False\r\nelse:\r\n    batch = ((\r\n                 tf.zeros((0, 0, 240), dtype=tf.float32),\r\n                 tf.zeros((0,), dtype=tf.int64),\r\n                 tf.zeros((0,), dtype=tf.string)),\r\n             (\r\n                 tf.zeros((0, 0), dtype=tf.int64),\r\n                 tf.zeros((0,), dtype=tf.int64),\r\n                 tf.zeros((0,), dtype=tf.string),\r\n                 tf.zeros((0,), dtype=tf.string)\r\n             ))\r\n    is_done = True\r\n```\r\nIs there any workaround for the manual specification of the data structure ?\r\nI am using at least one other tfrecord with a different structure from this one.", "And one more issue, which occurred while decorating the `_eval_step` function.\r\nUnlike `train_step`, which has a simple return structure (a floating point scalar), `_eval_step` has to return a more complicated structure ([this one](https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq/FinalBeamSearchDecoderOutput) in particular). If I were to write an anonymous function for `tf.nest.map_structure` in this case, how would I obtain the structure without making a hard assumption ? At the point where I have decide whether to return `is_done=True` or to continue with the model evaluation on the fetched data there is no reference yet to the model output.", "> How do you know that you have iterated through the dataset entirely, in order to compute several metrics at the end of an epoch ? Writing try: iter.__next__() except tf.errors.OutOfRangeError: return None inside _train_step does not seem to work. \r\n\r\n@georgesterpu Would it work for you to catch the exception outside the `tf.function`?\r\n\r\nIf this help, I'm using [this construct](https://github.com/OpenNMT/OpenNMT-tf/blob/v2.1.1/opennmt/data/dataset.py#L408-L442) to iterate on datasets. The decorated function is turned into a callable that returns a generator over its outputs. The exception is used as the end condition.", "+1 @guillaumekln , catching the exception outside the tf.function should work as well. That would simplify your code quite a bit, and works so long as you don't need to wrap the outer loop in a function.\r\n\r\nAs for avoiding assumptions on the structure, or to write it by hand, we can craft a version of map_structure that can work with None shapes:\r\n\r\n```\r\n  def empty_or_zeros(shape, dtype):\r\n    empty_shape = [0 if s is None else s for s in shape]\r\n    return tf.zeros(empty_shape, dtype=dtype)\r\n  return tf.nest.map_structure(empty_or_zeros, it.output_shapes, it.output_types)\r\n```\r\n\r\n", "Thank you for your advice, @guillaumekln and @mdanatg \r\n\r\nThe code snippet of @mdanatg works well for the train step, and it returns several warnings:\r\n```\r\nOwnedIterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.data.get_output_shapes(iterator)`.\r\n\r\nOwnedIterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.data.get_output_types(iterator)`.\r\n```\r\nHowever, my other issue was with the evaluation loop, as explained in https://github.com/tensorflow/tensorflow/issues/29075#issuecomment-548928957\r\nMy step functions do not return a structure identical to the one of the iterator. Instead, they return either a scalar loss (train step) or a `tfa.seq2seq.FinalBeamSearchDecoderOutput` struct (eval step). On the `optional.has_value()` False branch I won't have a reference to an instance of that structure.\r\n\r\nI've also tried a slightly simplified version of @guillaumekln's construct. The step function takes as input a function that returns `iterator.__next__()`, and is called inside a try...except block of the infinite while loop. Within an epoch this seems to run as fast as the `Optional` code, however it seems to have an overhead at the start of each epoch that makes it significantly slower. I could see the warning below at the start of each epoch (I think it is related to an Embedding layer), suggesting that the graph was rebuilt every time:\r\n```\r\n/tensorflow_core/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n```\r\n \r\nAnd it also logs this warning:\r\n```\r\n2019-11-03 19:29:10.605954: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[IteratorGetNext/_20]]\r\n2019-11-03 19:29:10.605963: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n```\r\n", "If you have a colab where all these can be reproduced, it would be helpful to make sure I don't misunderstand anything.\r\n\r\n`FinalBeamSearchDecoderOutput` is a namedtuple, so `nest.map_structure` should be able to deal with it properly, but I may be missing something.\r\n\r\nAbout the second solution, if `_run_step` takes a function it might retrace excessively - what if you just directly pass the iterator? If you call `next(it)` inside the @tf.function, the `OutOfRangeError` should bubble all the way into the eager runtime.", "> I confirm this is fixed in `2.0.0.dev20190829`. When running the code to reproduce, there is no longer a noticeable time difference between seen and unseen sequence lengths:\r\n> \r\n> ```\r\n> False 0.378192663192749\r\n> False 0.11128377914428711\r\n> False 0.11080718040466309\r\n> False 0.10891008377075195\r\n> False 0.10831356048583984\r\n> False 0.10732555389404297\r\n> False 0.10800600051879883\r\n> False 0.10589814186096191\r\n> False 0.1084296703338623\r\n> False 0.10618948936462402\r\n> False 0.10782027244567871\r\n> False 0.10433292388916016\r\n> False 0.10707211494445801\r\n> False 0.1098027229309082\r\n> True 0.10712003707885742\r\n> False 0.10629463195800781\r\n> True 0.10657715797424316\r\n> False 0.1062629222869873\r\n> False 0.10881710052490234\r\n> False 0.10586357116699219\r\n> True 0.10734868049621582\r\n> False 0.1084589958190918\r\n> False 0.1089639663696289\r\n> False 0.10571050643920898\r\n> True 0.10631895065307617\r\n> False 0.10663580894470215\r\n> False 0.10557937622070312\r\n> True 0.10591363906860352\r\n> True 0.10362792015075684\r\n> False 0.10501718521118164\r\n> False 0.107269287109375\r\n> False 0.10628437995910645\r\n> False 0.1069636344909668\r\n> False 0.10788226127624512\r\n> True 0.10770535469055176\r\n> ```\r\n> \r\n> I propose to cherry-pick this into `r2.0`, see #32080.\r\nsame issue here. but it seems there is still a more important question remain to be done: even there is no difference between unseen sequence length, but tf.function is still much slower than eager mode when I run the example code. \r\n  In my situation, I also have different sequence length between batchs, after I use tf.funtion with input_signature, it runs 4-5x slower than eager mode and 10x slower than tf1, I tried 2.0, 2.1, 2.2 but problem still unsolved. that's really upset :(\r\n", "@szc11121 is it also an issue in tf-nightly? If so, please include a snippet of code to reproduce the slowness and reopen this thread.", "> @szc11121 is it also an issue in tf-nightly? If so, please include a snippet of code to reproduce the slowness and reopen this thread.\r\n\r\nsorry to reply late, but I finally can reproduce the problem now. I create a colab notebook [here](https://colab.research.google.com/drive/1EsNqxBelCHy3hmc9R4RXdXNOgR8ww2Dc) to reproduce the problem, in output you can see training step in graph mode is 10x slower than eager mode. It seems it is a problem about tf.keras.layers.Embedding(), not variable sequence length, so I annotate some code. \r\n\r\nupdate: it looks fine if we use tf.nn.embedding_lookup instead of tf.keras.layers.Embbeding", "@szc11121 indeed, looks like a performance issue with embedding layers. I modified your code a little and filed #38287 to track the issue separately.", "somehow this bug still happened on the TF 2.1 and TF-nightly. I need warm-up model with the input length from 1-300 to make sure maximize performance on practice. @alextp ", "@dathudeptrai does the model warm up faster if you use `tf.function(experimental_relax_shapes=True)`?", "@mdanatg i use saved graph, do i need tf.function? ", "I think saved graphs don't require tf.function (because it was already applied before saving them). @k-w-w thoughts?", "I think this bug is extremely affecting user decisions in NLP deployment. Everything is fine for me when I am aware of this and use a warm-up variable length trick to avoid this slow bug.", "@dathudeptrai Consider following #38287, it will help push for a faster resolution."]}, {"number": 29074, "title": "Cmake Project is abandoned?", "body": "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows/Ubuntu\r\n\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.12-1.14\r\n- Python version: 3.5/3.6\r\n- Bazel version (if compiling from source): 0.21-0.253\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: 10.0 7.5\r\n- GPU model and memory: 11G\r\n\r\nI found cmake project from 1.12 is abandoned.\r\nI want to build c++  dll on windows.\r\nThe ubuntu so is compiled easily by bazel. Windows is hard.\r\nWhat should I do?\r\n\r\n", "comments": ["@engineer1109 Unfortunately we don't provide support for the CMake build anymore. You may have more luck building with Bazel for Windows using -c dbg. Please have look on [build tensorflow from source](https://www.tensorflow.org/install/source_windows) for windows. Thanks!", "@gadagashwini  Command is bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow:tensorflow.dll\uff1f", "E:\\tensorflow_maskrcnn\\.\\include\\tensorflow/core/platform/default/logging.h(260): error C2589: '(': illegal token on ri\r\nght side of '::' [E:\\tensorflow_maskrcnn\\buildvs\\main.vcxproj]\r\nE:\\tensorflow_maskrcnn\\.\\include\\tensorflow/core/platform/default/logging.h(260): error C2059: syntax error: '::' [E:\\t\r\nensorflow_maskrcnn\\buildvs\\main.vcxproj]\r\nE:\\tensorflow_maskrcnn\\.\\include\\tensorflow/core/platform/default/logging.h(260): error C2143: syntax error: missing ';\r\n' before '{' [E:\\tensorflow_maskrcnn\\buildvs\\main.vcxproj]\r\n\r\nSee something wrong with \r\nTF_DEFINE_CHECK_OP_IMPL(Check_EQ,\r\n                        ==)  // Compilation error with CHECK_EQ(NULL, x)?\r\nTF_DEFINE_CHECK_OP_IMPL(Check_NE, !=)  // Use CHECK(x == NULL) instead.\r\nTF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)\r\nTF_DEFINE_CHECK_OP_IMPL(Check_LT, <)\r\nTF_DEFINE_CHECK_OP_IMPL(Check_GE, >=)\r\nTF_DEFINE_CHECK_OP_IMPL(Check_GT, >)", "There are VC complicts.\r\nif (TF_PREDICT_FALSE(v2 >= (std::numeric_limits<int>::max)())) { \r\nto solve", "c_api.lib(c_api.o) : error LNK2005: TF_GetCode already defined in tensorflow.lib(libtensorflow.so) [E:\\tensorflow_maskr\r\ncnn\\buildvs\\main.vcxproj]\r\nc_api.lib(c_api.o) : error LNK2005: TF_SetConfig already defined in tensorflow.lib(libtensorflow.so) [E:\\tensorflow_mas\r\nkrcnn\\buildvs\\main.vcxproj]\r\nc_api.lib(c_api.o) : error LNK2005: TF_SetStatus already defined in tensorflow.lib(libtensorflow.so) [E:\\tensorflow_mas\r\nkrcnn\\buildvs\\main.vcxproj]\r\n     Creating library E:/tensorflow_maskrcnn/buildvs/Release/main.lib and object E:/tensorflow_maskrcnn/buildvs/Release\r\n  /main.exp\r\nE:\\tensorflow_maskrcnn\\buildvs\\Release\\main.exe : fatal error LNK1169: one or more multiply defined symbols found [E:\\t\r\nensorflow_maskrcnn\\buildvs\\main.vcxproj]", "All the compiling is ok now.\r\n\r\nBut run a model meet this problem.\r\nNot found: No session factory registered for the given session options: {target: \"\" config: } Registered factories are {}.", "See https://github.com/tensorflow/tensorflow/issues/28388#issuecomment-497192950 about the question in title.\r\n\r\nAlso, some nit: please format code blocks using 3 backticks, to make them easier to read.", "@engineer1109 \r\n\r\nHave a look at the following example code:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/benchmark\r\n\r\nYou should be able to get that running with libnsync.lib a few abeil-cpp libs libprotobuf.lib and the tensorflow.dll\r\n\r\nThen you can run basically any model from the one binary, there are heaps of helpful hints about running a model in this file.", "@engineer1109 \r\n\r\nyou will also need this and its header\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/reporter.cc", "Sure it is abandoned"]}, {"number": 29073, "title": "Empty trainable variables in keras model (tf 2.0)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.1-2504-g2be59a5191 2.0.0-dev20190522\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: CUDA Version 10.0.130\r\n- GPU model and memory: Nvidia GeForce GTX 1080 Ti\r\n\r\n**Describe the current behavior**\r\nI want to create UNet using the Keras Model subclassing API:\r\nThe current code is:\r\n```python\r\nclass UNet(keras.Model):\r\n    \"\"\"\r\n    UNet Architecture concatenating encoder and decoder\r\n\r\n    Examples:\r\n        * Direct Usage:\r\n\r\n            .. testcode::\r\n\r\n                x = tf.ones((1, 512, 512, 3))\r\n                u_net = UNet(input_res = 512,\r\n                             min_res=4,\r\n                             kernel_size=4,\r\n                             initial_filters=64,\r\n                             filters_cap=512,\r\n                             channels=3)\r\n                y = u_net(x)\r\n                print(y.shape)\r\n\r\n            .. testoutput::\r\n                (1, 512, 512, 3)\r\n\r\n    \"\"\"\r\n\r\n    def __init__(\r\n        self,\r\n        input_res,\r\n        min_res,\r\n        kernel_size,\r\n        initial_filters,\r\n        filters_cap,\r\n        channels,\r\n        use_dropout_encoder=True,\r\n        use_dropout_decoder=True,\r\n        dropout_prob=0.3,\r\n        encoder_non_linearity=keras.layers.LeakyReLU,\r\n        decoder_non_linearity=keras.layers.ReLU,\r\n    ):\r\n        super().__init__()\r\n\r\n        # layer specification\r\n        self.use_dropout_encoder = use_dropout_encoder\r\n        self.use_dropout_decoder = use_dropout_decoder\r\n        self.dropout_probability = dropout_prob\r\n        self.encoder_non_linearity = encoder_non_linearity\r\n        self.decoder_non_linearity = decoder_non_linearity\r\n        self.kernel_size = kernel_size\r\n\r\n        # encoder layers is a list of list, each list is a \"block\",\r\n        # this makes easy the creation of decoder\r\n        self.encoder_layers = []\r\n        self.decoder_layers = []\r\n        self.concat_layers = []\r\n\r\n        # ########### Encoder creation\r\n        encoder_layers_spec = [128, 256, 512, 512, 512, 512, 512, 512]\r\n\r\n        decoder_layer_spec = []\r\n        for i, filters in enumerate(encoder_layers_spec):\r\n            self.encoder_layers.append(self.get_encoder_block(filters, use_bn=(i != 0)))\r\n\r\n        # ############## Decoder creation\r\n        decoder_layer_spec =[512, 512, 512, 512, 512, 256, 128]\r\n\r\n        for i, filters in enumerate(decoder_layer_spec):\r\n            self.concat_layers.append(keras.layers.Concatenate())\r\n            self.decoder_layers.append(\r\n                self.get_decoder_block(filters, use_dropout=(i < 3))\r\n            )\r\n\r\n        # final layer\r\n        initializer = tf.random_normal_initializer(0.0, 0.02)\r\n        self.final_layer = keras.layers.Conv2DTranspose(\r\n            channels,\r\n            self.kernel_size,\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            activation=keras.activations.tanh,\r\n            kernel_initializer=initializer,\r\n        )\r\n\r\n    def get_block(\r\n        self,\r\n        filters,\r\n        conv_layer=None,\r\n        use_bn=True,\r\n        use_dropout=False,\r\n        non_linearity=keras.layers.LeakyReLU,\r\n    ):\r\n        initializer = tf.random_normal_initializer(0.0, 0.02)\r\n        # Conv2D\r\n        block = [\r\n            conv_layer(\r\n                filters,\r\n                self.kernel_size,\r\n                strides=(2, 2),\r\n                padding=\"same\",\r\n                use_bias=False,\r\n                kernel_initializer=initializer,\r\n            )\r\n        ]\r\n\r\n        # Batch normalization\r\n        if use_bn:\r\n            block.append(keras.layers.BatchNormalization())\r\n\r\n        # dropout\r\n        if use_dropout:\r\n            block.append(keras.layers.Dropout(self.dropout_probability))\r\n\r\n        # Non linearity\r\n        block.append(non_linearity())\r\n\r\n        return block\r\n\r\n    def get_encoder_block(self, filters, use_bn=True):\r\n        return self.get_block(\r\n            filters,\r\n            conv_layer=keras.layers.Conv2D,\r\n            use_bn=use_bn,\r\n            use_dropout=self.use_dropout_encoder,\r\n            non_linearity=self.encoder_non_linearity,\r\n        )\r\n\r\n    def get_decoder_block(self, filters, use_bn=True, use_dropout=False):\r\n        return self.get_block(\r\n            filters,\r\n            conv_layer=keras.layers.Conv2DTranspose,\r\n            use_bn=use_bn,\r\n            use_dropout=self.use_dropout_decoder and use_dropout,\r\n            non_linearity=self.decoder_non_linearity,\r\n        )\r\n\r\n    def __call__(self, inputs, training=True):\r\n        # encoders evaluated\r\n        encoder_layer_eval = []\r\n        x = inputs\r\n\r\n        for block in self.encoder_layers:\r\n            for layer in block:\r\n                if isinstance(layer, keras.layers.BatchNormalization) or isinstance(\r\n                    layer, keras.layers.Dropout\r\n                ):\r\n                    x = layer(x, training=training)\r\n                else:\r\n                    x = layer(x)\r\n            encoder_layer_eval.append(x)\r\n\r\n        encoder_layer_eval = encoder_layer_eval[:-1]\r\n\r\n        for i, block in enumerate(self.decoder_layers):\r\n            for layer in block:\r\n                if isinstance(layer, keras.layers.BatchNormalization) or isinstance(\r\n                    layer, keras.layers.Dropout\r\n                ):\r\n                    x = layer(x, training=training)\r\n                else:\r\n                    x = layer(x)\r\n            x = self.concat_layers[i]([x, encoder_layer_eval[-1 - i]])\r\n\r\n        x = self.final_layer(x)\r\n\r\n        return x\r\n\r\n```\r\n\r\nWhen I evaluate the model using an input and check the trainable variables they are empty:\r\n\r\n```python\r\nx = tf.ones((1, 512, 512, 3))\r\nu_net = UNet(input_res = 512,\r\n                       min_res=4, \r\n                       kernel_size=4,\r\n                       initial_filters=64,\r\n                       filters_cap=512,\r\n                       channels=3)\r\n                y = u_net(x)               \r\n                print(u_net.trainable_variables) # it prints: []\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe code should print the list of trainable variables of the Net. The output is correct so the `__call__` method is correctly called.\r\n\r\n", "comments": ["Update: After some debugging I found the cause of this issue. \r\nThe problem is that keras does its magic under the hood. \r\nIn the UNet init:\r\n```python\r\nself.encoder_layers = []\r\nself.decoder_layers = []\r\nself.concat_layers = []\r\n```\r\nKeras intercepts the creation of the lists and initializes its attributes. Keras does not manage the `append` of layers to a list.\r\n\r\nChanging the above code in:\r\n\r\n```python\r\n    def __init__(\r\n        self,\r\n        input_res,\r\n        min_res,\r\n        kernel_size,\r\n        initial_filters,\r\n        filters_cap,\r\n        channels,\r\n        use_dropout_encoder=True,\r\n        use_dropout_decoder=True,\r\n        dropout_prob=0.3,\r\n        encoder_non_linearity=keras.layers.LeakyReLU,\r\n        decoder_non_linearity=keras.layers.ReLU,\r\n    ):\r\n        super().__init__()\r\n\r\n        # layer specification\r\n        self.use_dropout_encoder = use_dropout_encoder\r\n        self.use_dropout_decoder = use_dropout_decoder\r\n        self.dropout_probability = dropout_prob\r\n        self.encoder_non_linearity = encoder_non_linearity\r\n        self.decoder_non_linearity = decoder_non_linearity\r\n        self.kernel_size = kernel_size\r\n\r\n        # encoder layers is a list of list, each list is a \"block\",\r\n        # this makes easy the creation of decoder\r\n        # IMPORTANT! Do not initialize here instance attributes\r\n        encoder_layers = []\r\n        decoder_layers = []\r\n        concat_layers = []\r\n\r\n        # ########### Encoder creation\r\n        encoder_layers_spec =  [128, 256, 512, 512, 512, 512, 512, 512]\r\n\r\n        for i, filters in enumerate(encoder_layers_spec):\r\n            block = self.get_encoder_block(filters, use_bn=(i != 0))\r\n            encoder_layers.append(block)\r\n\r\n        # ############## Decoder creation\r\n        decoder_layer_spec = [512, 512, 512, 512, 512, 256, 128]\r\n\r\n        for i, filters in enumerate(decoder_layer_spec):\r\n            concat_layers.append(keras.layers.Concatenate())\r\n            block = self.get_decoder_block(filters, use_dropout=(i < 3))\r\n            decoder_layers.append(block)\r\n\r\n        # final layer\r\n        initializer = tf.random_normal_initializer(0.0, 0.02)\r\n        self.final_layer = keras.layers.Conv2DTranspose(\r\n            channels,\r\n            self.kernel_size,\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            activation=keras.activations.tanh,\r\n            kernel_initializer=initializer,\r\n        )\r\n       # intialize here object attributes!!!!!!!\r\n        self.encoder_layers = encoder_layers\r\n        self.decoder_layers = decoder_layers\r\n        self.concat_layers = concat_layers\r\n```\r\nSolves the issue. In this way the variables are correctly added to the trainable variables. I think this is a serious bug. It should be fixed or at least documented.", "We agree that this should be better documented. Would you be interested in adding examples and references in the base Layer docstring?", "Just ran this by @allenlavoie, this *may* have been fixed in newer versions of TensorFlow and is worth checking with the nightly. (It was initially broken, then fixed, then there was a regression with some of @qlzh727 layer refactoring changes, then may have been fixed again).", "I wasn't able to reproduce the error with nightly version of TF. Basically adding the layer to the list attribute of the subclass model should work. Nested list should work too, since we recursively find all the layer like objects.\r\n \r\n```python\r\nclass M(tf.keras.models.Model):\r\n\r\n    def __init__(self):\r\n        super(M, self).__init__()\r\n        self._list = []\r\n        self._list.append([tf.keras.layers.Dense(5), tf.keras.layers.Dense(5)])\r\n        self._list.append([tf.keras.layers.Dense(5), tf.keras.layers.Dense(5)])\r\n\r\n    def call(self, inputs):\r\n        output = inputs\r\n        for l_list in self._list:\r\n            for l in l_list:\r\n                output = l(output)\r\n        return output\r\n\r\nm = M()\r\nm(tf.ones((10, 10)))\r\nprint(len(m.trainable_variables)) # Got 8\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29073\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29073\">No</a>\n", "Update: this is fixed in version v1.12.1-2994-g5fa098e3b9 2.0.0-dev20190530"]}, {"number": 29072, "title": "Documenting the Ref keyword from operations input/output types", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nSome operations, like `Assign`, use a `Ref` keyword for their input and/or output. (example: tensorflow/core/ops/state_ops.cc). This keyword is not documented anywhere.\r\n\r\nAdditionally, I haven't found any way to combine `Ref` with `list` (i.e. make an operation take a list of mutable tensors as input).\r\n", "comments": ["@dorier,\r\nPlease take a look at [this documentation](https://www.tensorflow.org/api_docs/python/tf/Variable#ref) for the `ref()` function and let us know if this is what you're looking for. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 29071, "title": "Does tf.nn.batch_normalization support fp16", "body": "fp16 is new feature of Nvida GPUs, does batch_normalization support fp16?", "comments": ["https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization, the official docs only notice \" arbitrary dimensionality\"", "Running it on tensorflow cpu I got these results:\r\n`a = np.array([5, 5, 5], dtype='float16')`\r\n`tf.nn.batch_normalization(a, 1, 1, 0, 0, 0.001)`\r\nReturns `<tf.Tensor 'batchnorm_5/add:0' shape=(3,) dtype=float16>`", "got it thks"]}, {"number": 29070, "title": "tf_upgrade_v2 has no attribute __pasta__", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.5\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.7.3\r\n- GPU model and memory: cpu\r\n\r\n**Describe the current behavior**\r\nWhen running the tf2 upgrade script on any of my projects I would get the following error:\r\n```\r\n$ tf_upgrade_v2 --intree my_project --outtree my_project_upgrade\r\n\r\nINFO line 46:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 49:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 30:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 33:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 21:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 24:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 21:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 24:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 35:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 38:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 68:17: Added keywords to args of function 'tf.convert_to_tensor'\r\nINFO line 69:17: Added keywords to args of function 'tf.convert_to_tensor'\r\nINFO line 72:34: Renamed 'tf.log' to 'tf.math.log'\r\nINFO line 75:21: Added keywords to args of function 'tf.reduce_max'\r\nINFO line 76:15: Added keywords to args of function 'tf.reduce_mean'\r\nINFO line 56:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 59:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 75:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 78:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 41:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 43:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 65:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 67:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 41:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\r\nINFO line 43:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\nINFO line 45:22: Renamed 'tf.Summary' to 'tf.compat.v1.Summary'\r\nINFO line 84:22: Renamed 'tf.Summary' to 'tf.compat.v1.Summary'\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tf_upgrade_v2\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/tf_upgrade_v2_main.py\", line 123, in main\r\n    args.input_tree, output_tree, args.copy_other_files)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py\", line 624, in process_tree\r\n    _, l_report, l_errors = self.process_file(input_path, output_path)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py\", line 494, in process_file\r\n    temp_file)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py\", line 548, in process_opened_file\r\n    self.update_string_pasta(\"\".join(lines), in_filename))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py\", line 510, in update_string_pasta\r\n    t = pasta.parse(text)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/__init__.py\", line 25, in parse\r\n    annotator.visit(t)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 1190, in visit\r\n    super(AstAnnotator, self).visit(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 132, in visit\r\n    super(BaseVisitor, self).visit(node)\r\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\", line 262, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 47, in wrapped\r\n    f(self, node, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 220, in visit_Module\r\n    self.generic_visit(node)\r\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\", line 270, in generic_visit\r\n    self.visit(item)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 1190, in visit\r\n    super(AstAnnotator, self).visit(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 132, in visit\r\n    super(BaseVisitor, self).visit(node)\r\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\", line 262, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 95, in wrapped\r\n    f(self, node, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 381, in visit_ClassDef\r\n    self.visit(stmt)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 1190, in visit\r\n    super(AstAnnotator, self).visit(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 132, in visit\r\n    super(BaseVisitor, self).visit(node)\r\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\", line 262, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 95, in wrapped\r\n    f(self, node, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 411, in visit_FunctionDef\r\n    self.visit(stmt)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 1190, in visit\r\n    super(AstAnnotator, self).visit(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 132, in visit\r\n    super(BaseVisitor, self).visit(node)\r\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\", line 262, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 47, in wrapped\r\n    f(self, node, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 530, in visit_Assign\r\n    self.visit(node.value)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 1190, in visit\r\n    super(AstAnnotator, self).visit(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 132, in visit\r\n    super(BaseVisitor, self).visit(node)\r\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\", line 262, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 47, in wrapped\r\n    f(self, node, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 829, in visit_IfExp\r\n    self.visit(node.body)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 1190, in visit\r\n    super(AstAnnotator, self).visit(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 132, in visit\r\n    super(BaseVisitor, self).visit(node)\r\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\", line 262, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 47, in wrapped\r\n    f(self, node, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 700, in visit_BoolOp\r\n    self.visit(value)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 1190, in visit\r\n    super(AstAnnotator, self).visit(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 132, in visit\r\n    super(BaseVisitor, self).visit(node)\r\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\", line 262, in visit\r\n    return visitor(node)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 47, in wrapped\r\n    f(self, node, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 803, in visit_Dict\r\n    self.visit(key)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py\", line 1188, in visit\r\n    fmt.set(node, 'indent', self._indent)\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/formatting.py\", line 37, in set\r\n    _formatting_dict(node)[name] = value\r\n  File \"/usr/local/lib/python3.7/site-packages/pasta/base/formatting.py\", line 49, in _formatting_dict\r\n    return getattr(node, PASTA_DICT)\r\nAttributeError: 'NoneType' object has no attribute '__pasta__'\r\n```\r\n\r\nI have tried updating pasta (`pip3 install --upgrade pasta`) which now results in \r\n```\r\n$ tf_upgrade_v2 --intree my_project --outtree my_project_upgrade\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tf_upgrade_v2\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/tf_upgrade_v2_main.py\", line 123, in main\r\n    args.input_tree, output_tree, args.copy_other_files)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py\", line 624, in process_tree\r\n    _, l_report, l_errors = self.process_file(input_path, output_path)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py\", line 494, in process_file\r\n    temp_file)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py\", line 548, in process_opened_file\r\n    self.update_string_pasta(\"\".join(lines), in_filename))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py\", line 510, in update_string_pasta\r\n    t = pasta.parse(text)\r\nAttributeError: module 'pasta' has no attribute 'parse'\r\n```\r\nI was unable to find anyone with similar problems.\r\nWhat is the supported pasta version that is needed to run the tf2 upgrade script?\r\n", "comments": ["tf_upgrade_v2 utility is included automatically with pip install of TF2.0. Can you please try re-installing TF version and let us know if that resolves the issue. You can also refer this [link](https://medium.com/tensorflow/upgrading-your-code-to-tensorflow-2-0-f72c3a4d83b5) to more information. Thanks!", "No, not resolved. I believe it is linked to #26486", "@kriskorrel-cw : Just to verify whether it is fixed or not, can you try with pasta - 0.1.7 and let us know if that resolves it. Thanks!", "This particular issue is resolved with pasta 0.1.7, yes. However, it does raise another issue for which I shall open a new ticket :)", "same issue. win10 x64; tf-gpu 2.2.0; pasta 0.1 / 0.2  \r\nboth in base and custom conda environments"]}, {"number": 29069, "title": "Implement op nn.depthwise_conv2d_transpose", "body": "Addresses #9917 \r\n\r\nI had some investigation and found the depthwise_conv2d_transpose op could be implemented by calling gen_nn_ops.depthwise_conv2d_native_backprop_input, just like conv2d_transpose is implemnted by calling gen_nn_ops.conv2d_backprop_input.\r\n\r\nDon't know if any test cases is needed. Since this is the first time for me to add an op, so if there are any guidelines, please let me know. Thanks!", "comments": ["I ran 'bazel test --config=opt //tensorflow/tools/api/tests:api_compatibility_test' on the master branch where I didn't do any change, but the test case already fails. Then I updated my local master branch to the latest tensorflow version, but the problem is still there. Is this normal?\r\n\r\nThe error message is like below. See the attached file for the full log.\r\n\r\nE0531 12:53:28.745994 4558882240 api_compatibility_test.py:254] 1 differences found between API and golden.\r\nIssue 1\t: \r\n  path: \"tensorflow.summary\"\r\n  tf_module {\r\n    member {\r\n      name: \"SummaryWriter\"\r\n      mtype: \"<type \\'type\\'>\"\r\n    }\r\n    member {\r\n      name: \"experimental\"\r\n      mtype: \"<type \\'module\\'>\"\r\n\\+   }\r\n\\+   member_method {\r\n\\+     name: \"audio\"\r\n\\+     argspec: \"args=[\\'name\\', \\'data\\', \\'sample_rate\\', \\'step\\', \\'max_outputs\\', \\'encoding\\', \\'description\\'], varargs=None, keywords=None, defaults=[\\'3\\', \\'None\\', \\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"create_file_writer\"\r\n\r\n\r\n[test.log](https://github.com/tensorflow/tensorflow/files/3241419/test.log)\r\n", "Ignore the tf.summary stuff; I don't know why it is showing up there.\n\nOn Fri, May 31, 2019 at 6:45 AM Astropeak <notifications@github.com> wrote:\n\n> I ran 'bazel test --config=opt\n> //tensorflow/tools/api/tests:api_compatibility_test' on the master branch\n> where I didn't do any change, but the test case already fails. Then I\n> updated my local master branch to the latest tensorflow version, but the\n> problem is still there. Is this normal?\n>\n> The error message is like below. See the attached file for the full log.\n>\n> E0531 12:53:28.745994 4558882240 api_compatibility_test.py:254] 1\n> differences found between API and golden.\n> Issue 1 :\n> path: \"tensorflow.summary\"\n> tf_module {\n> member {\n> name: \"SummaryWriter\"\n> mtype: \"<type 'type'>\"\n> }\n> member {\n> name: \"experimental\"\n> mtype: \"<type 'module'>\"\n>\n>    - }\n>    - member_method {\n>    -\n>\n>    name: \"audio\"\n>\n>    -\n>\n>    argspec: \"args=[\\'name\\', \\'data\\', \\'sample_rate\\', \\'step\\', \\'max_outputs\\', \\'encoding\\', \\'description\\'], varargs=None, keywords=None, defaults=[\\'3\\', \\'None\\', \\'None\\'], \"\n>\n>    }\n>    member_method {\n>    name: \"create_file_writer\"\n>\n> test.log <https://github.com/tensorflow/tensorflow/files/3241419/test.log>\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/29069?email_source=notifications&email_token=AAABHRN3BT7DZZFABXUY2PLPYETVXA5CNFSM4HQAL62KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWVHP5I#issuecomment-497711093>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRITBOQAQPI55DM7GN3PYETVXANCNFSM4HQAL62A>\n> .\n>\n\n\n-- \n - Alex\n", "I updated the golden by running 'bazel-bin/tensorflow/tools/api/tests/api_compatibility_test --update_goldens True'.\r\n\r\nDo we need to write some tests for this op? Or the test cases could be omitted since this op is just based on another op?\r\n\r\n", "Please write tests that exercise the new name for this op so we can prevent it from breaking in the future.", "@astropeak Did you get a chance to look on reviewer comments? Please let us know on the update. Thanks!", "Any progress on this?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 29068, "title": "[T.F 2.0 API Docs] Examples for exp, expm1 and equal math functions", "body": "Reference Issue: #25802\r\n\r\nThis PR adds examples to the following math functions.\r\n\r\n1. equal\r\n2. exp\r\n2. expm1\r\n\r\nThanks in advance.", "comments": ["Hi @martinwicke \r\nI have made changes to the branch. I thought of pointing users about handling complex numbers in exponential function under `expm1` instead of re-iterating the same. That is the reason for adding the below line.\r\n\r\n```\r\nRefer `exp` for an explanation.\r\n```\r\n\r\nI have removed it for now. If you feel it is ok to add, I can make changes to it and push again.", "@martinwicke Completed changes. Please let me know if this looks good.", "Looks good after one more.comment. ", "> Looks good after one more.comment.\r\n\r\n@martinwicke Updated. Thanks a lot"]}, {"number": 29067, "title": "Unable to use tf.ragged_tensor with tf.from tensor_slices", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Looks like a spam. Closing the issue. Please open a new issue if you are stuck. Thanks!"]}, {"number": 29066, "title": "Fix a dead link in doc string of conv2d_transpose_v2", "body": "The link to the paper in the doc string is dead, replace it with a good one. Actually, that good link is used in the doc string of conv2d_transpose, so it should be the correct one.", "comments": []}, {"number": 29065, "title": "output of make_one_shot_iterator of TFRecord Dataset without eager disabled", "body": "*System information*\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (almost same as template)\r\n- OS Platform and Distribution : Linux Ubuntu 16.04\r\n- TensorFlow installed from : binary\r\n- TensorFlow version : 1.13.1\r\n- Python version: 3.5.2\r\n\r\nWith eager enabled:\r\ninput from TFRecordDataset with dimension (batchsize, data_shape) \r\nWithout eager:\r\ndimension are (?, data_shape)\r\n\r\nexpected the same behavior as with eager\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nSHUFFLE_BUFFER = 1000\r\nBATCH_SIZE = 32\r\nNUM_CLASSES = 12\r\n\r\nfeature_description = {\r\n    'feature0': tf.FixedLenFeature([32768], tf.float32),\r\n    'feature1': tf.FixedLenFeature([1], tf.int64)\r\n}\r\n\r\ndef _parse_function(example_proto):\r\n    parsed_example = tf.parse_single_example(example_proto, feature_description)\r\n    parsed_example[\"feature0\"] = tf.transpose(tf.reshape(parsed_example['feature0'], (256,128)))\r\n    return parsed_example\r\n\r\ndef create_dataset(filepath):\r\n    \r\n    dataset = tf.data.TFRecordDataset(filepath)\r\n    \r\n    dataset = dataset.map(_parse_function) #, num_parallel_calls=8)\r\n    \r\n    dataset = dataset.repeat()\r\n    \r\n    dataset = dataset.shuffle(SHUFFLE_BUFFER)\r\n    dataset = dataset.batch(BATCH_SIZE)\r\n    \r\n    iterator = dataset.make_one_shot_iterator()\r\n    \r\n    feature = iterator.get_next()\r\n    #print(feature)\r\n    lmfcc = feature[\"feature0\"]\r\n    label = feature[\"feature1\"]\r\n    \r\n    lmfcc = tf.reshape(lmfcc, [-1,128, 256, 1])\r\n    \r\n    label = tf.one_hot(label, NUM_CLASSES)\r\n    print(lmfcc.shape)\r\n    print(label.shape)\r\n\r\n    return lmfcc, label\r\n\r\n lmfcc, label = create_dataset(\"../data/debug/sample.tfrecords\")`\r\n```\r\noutput eager disabled\r\n\r\n(?, 128, 256)\r\n(?, 1, 12)", "comments": ["I could reproduce the issue with TF 1.13.1. Thanks!", "This is expected difference between eager mode and graph mode. The executes the ops eagerly and will those know the dimension of the data read from a file, while the latter will delay the execution to a `session.run` call and thus does not know the shape of the data.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29065\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29065\">No</a>\n"]}, {"number": 29064, "title": "What does GradientTape.gradient(target, ...) when target is a list of tensors and not a single tensor ?", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/GradientTape?hl=en#gradient\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nActually there is no way to know what does the gradient method when target is not a tensor but a list of tensors, like `target=[loss_1, loss_2]`. Does it compute the sum of the gradients of `loss_1` and `loss_2` ? It seems like no, from some tests I did. What does it do then ?\r\n\r\nI tried to follow the source code, without success. GradientTape.gradient calls tensorflow.python.eager.imperative_grad.imperative_grad, which calls tensorflow.python.pywrap_tensorflow.TFE_Py_TapeGradient, which is a C++ function calling ComputeGradient. But I couldn't find the code of ComputeGradient. I just found it mentioned in tensorflow/c/eager/tape.h. But I don't find tape.cc.\r\n\r\n\r\n### Usage example\r\n\r\nThere is no usage example for this case.", "comments": ["+1", "+1\r\n\r\nI can find \r\n\r\n`tensorflow.python.pywrap_tensorflow`\r\n\r\nbut not\r\n\r\n`tensorflow.python.pywrap_tensorflow.TFE_Py_TapeGradient`", "It appears to return the sum of the gradients for each target. \r\n\r\nI'm coming across this because I'm trying to compute the hessian of a real-valued function with vector input, so i need to take the gradient of a gradient. (`tf.hessians` doesn't work normally in v2, see https://github.com/tensorflow/tensorflow/issues/29781.) instead of returning the hessian, the second gradient appears to return the row-wise sum of the hessian (or, in other words, `sum(gradient(element) for element in first_gradient)`). this even happens if i `unstack` the first gradient into a list of individual tensors, and compute the gradient of that list of tensors. ", "I have a follow up question on this. What if we want to write a custom second derivative (instead of a custom gradient). The second gradient as the author mentioned, row-wise sum of the Hessian. I will have to address all partial derivatives and it's not clear at all in the documentation how this can be done.", "+1", "I also came across this problem : when there are several targets or when the target tensor has more than one element, the returned gradient is the sum of the gradient of each element in target with respect to the sources. The shape of the gradient and the shape of the sources will always be the same.\r\n```\r\na = tf.constant([[1.0, 2.0], [3.0, 4.0]])\r\nb = tf.constant([[2.0, 1.0], [0, 4.0]])\r\n\r\nwith tf.GradientTape() as tape:\r\n    tape.watch(a)\r\n    c = tf.math.reduce_mean(a)\r\n    d = tf.matmul(a, b)\r\n\r\ngrads_c = tape.gradient(c, a)  # tf.Tensor([[0.25 0.25], [0.25 0.25]], shape=(2, 2), dtype=float32)\r\ngrads_d = tape.gradient(d, a)  # tf.Tensor([[3. 4.], [3. 4.]], shape=(2, 2), dtype=float32)\r\ngrads_c_d = tape.gradient([c, d], a)  # tf.Tensor([[3.25 4.25], [3.25 4.25]], shape=(2, 2), dtype=float32)\r\n```\r\nThe real problem is that tape can be executed only once, so if you want to have the raw gradient and not the sum of the gradients per element, you need to run the loop 'with tf.GradientTape()' for each element in target.", "FWIW, it looks like the right way to do this is to use [`tape.jacobian`](https://www.tensorflow.org/guide/advanced_autodiff#jacobians) rather than `tape.gradient`.", "@durandg12,\r\nSorry for the delayed response. Can you please let us know if using [tape.jacobian](https://www.tensorflow.org/guide/advanced_autodiff#jacobians) has resolved your issue? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "+1 same confusion"]}, {"number": 29063, "title": "\"tensorflow.python.eager.core._FallbackException: Expecting int64_t value for attr strides, got numpy.int32\" + \"ValueError: Incompatible conversion from float32 to uint8\" when calling fit() on my model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12.2\r\n- Python version: 3.5\r\n- CUDA/cuDNN version: V8.0.61\r\n- GPU model and memory: Tesla P100-PCIE, 12193MiB\r\n\r\n**Describe the current behavior**\r\nWhen I call\r\n\r\n```\r\nmodel.fit(train, steps_per_epoch=int(np.ceil(num_train_samples / BATCH_SIZE)), epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=val, validation_steps=int(np.ceil(num_val_samples / BATCH_SIZE)))\r\n```\r\n\r\nI get the following error:\r\n\r\n```\r\nValueError: Incompatible type conversion requested to type 'uint8' for variable of type 'float32'\r\n```\r\n\r\nThis error occurs during handling of a first exception:\r\n\r\n```\r\ntensorflow.python.eager.core._FallbackException: Expecting int64_t value for attr strides, got numpy.int32\r\n```\r\n\r\nI only use NumPy to load ndarrays (using `np.load()`) after which they are immediately converted to TensorFlow tensors. I've also made sure those tensors contain TensorFlow data types, so I am puzzled as to how a NumPy datatypes manages to sneak through. I also couldn't find any variables with numpy.int32 type during debugging.\r\n\r\n**Code to reproduce the issue**\r\nMy full script is as follows:\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os\r\n\r\nCLASSES = [\"aluminium\", \"asphalt\", \"brick\", \"cloud\", \"concrete\", \"fabric\", \"foliage\", \"glass\", \"grass\", \"gravel\", \"iron\", \"living\", \"other\", \"plastic\", \"sky\", \"soil\", \"stone\", \"steel\", \"tile\", \"water\", \"wood\"]\r\nNUM_CLASSES = len(CLASSES)\r\nDIR_DATASET = \"/folder/to/numpyndarrays\"\r\nWIDTH = 512\r\nHEIGHT = 512\r\nBATCH_SIZE = 10\r\nNUM_EPOCHS = 10\r\nTRAIN_VAL_SPLIT = 0.9\r\nnum_samples = len([filename[:-4] for filename in os.listdir(DIR_DATASET + \"ndarrays/\")])\r\nnum_train_samples = round(num_samples * TRAIN_VAL_SPLIT)\r\nnum_val_samples = round(num_samples * (1 - TRAIN_VAL_SPLIT))\r\n\r\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\r\ntf.enable_eager_execution()\r\n\r\ndef train_sample_fetcher():\r\n    return sample_fetcher()\r\n\r\ndef val_sample_fetcher():\r\n    return sample_fetcher(is_validations=True)\r\n\r\ndef sample_fetcher(is_validations=False):\r\n    sample_names = [filename[:-4] for filename in os.listdir(DIR_DATASET + \"ndarrays/\")]\r\n    if not is_validations: sample_names = sample_names[:int(len(sample_names) * TRAIN_VAL_SPLIT)]\r\n    else: sample_names = sample_names[int(len(sample_names) * TRAIN_VAL_SPLIT):]\r\n    for sample_name in sample_names:\r\n        rgb = tf.image.decode_jpeg(tf.read_file(DIR_DATASET + sample_name + \".jpg\"))\r\n        rgb = tf.image.resize_images(rgb, (HEIGHT, WIDTH))\r\n        #d = tf.image.decode_jpeg(tf.read_file(DIR_DATASET + \"depth/\" + sample_name + \".jpg\"))\r\n        #d = tf.image.resize_images(d, (HEIGHT, WIDTH))\r\n        #rgbd = tf.concat([rgb,d], axis=2)\r\n        onehots = tf.convert_to_tensor(np.load(DIR_DATASET + \"ndarrays/\" + sample_name + \".npy\"), dtype=tf.float32)\r\n        yield rgb, onehots\r\n\r\ndef deconvolve(tensor, num_filters):\r\n    tensor = tf.layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(tensor)\r\n    tensor = tf.layers.BatchNormalization()(tensor)\r\n    tensor = tf.keras.layers.Activation('relu')(tensor)\r\n    tensor = tf.layers.Conv2D(num_filters, (3, 3), padding='same')(tensor)\r\n    tensor = tf.layers.BatchNormalization()(tensor)\r\n    tensor = tf.keras.layers.Activation('relu')(tensor)\r\n    tensor = tf.layers.Conv2D(num_filters, (3, 3), padding='same')(tensor)\r\n    tensor = tf.layers.BatchNormalization()(tensor)\r\n    tensor = tf.keras.layers.Activation('relu')(tensor)\r\n    return tensor\r\n\r\ndef dice_loss(y_true, y_pred):\r\n    smooth = 1.\r\n    y_true_f = tf.reshape(y_true, [-1]) # Flatten\r\n    y_pred_f = tf.reshape(y_pred, [-1]) # Flatten\r\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\r\n    dice_coefficient = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\r\n    loss = 1 - dice_coefficient\r\n    return loss\r\n\r\ntrain = tf.data.Dataset.from_generator(generator=train_sample_fetcher, output_types=(tf.uint8, tf.float32))\r\ntrain = train.repeat()\r\ntrain = train.batch(BATCH_SIZE)\r\ntrain = train.shuffle(10)\r\nval = tf.data.Dataset.from_generator(generator=val_sample_fetcher, output_types=(tf.uint8, tf.float32))\r\n\r\n# i = 0\r\n# for sample in train:\r\n#     i = i + 1\r\n#     print(sample[0].dtype)\r\n#     print(sample[1].dtype)\r\n\r\ninput = tf.keras.Input(shape=(HEIGHT, WIDTH, 3))\r\nresnet = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(HEIGHT, WIDTH, 3), pooling=None, classes=1000)(input)\r\ntensor = deconvolve(resnet, 512)\r\ntensor = deconvolve(tensor, 256)\r\ntensor = deconvolve(tensor, 128)\r\ntensor = deconvolve(tensor, 64)\r\ntensor = deconvolve(tensor, 32)\r\noutput = tf.layers.Conv2D(NUM_CLASSES, (1, 1), activation='sigmoid')(tensor)\r\n\r\nmodel = tf.keras.models.Model(inputs=[input], outputs=[output])\r\nadam = tf.train.AdamOptimizer()\r\nmodel.compile(optimizer=adam, loss=dice_loss, metrics=[dice_loss])\r\nhistory = model.fit(train, steps_per_epoch=int(np.ceil(num_train_samples / BATCH_SIZE)), epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=val, validation_steps=int(np.ceil(num_val_samples / BATCH_SIZE)))\r\n```\r\n\r\n**Other info / logs**\r\nHere are some of the NumPy arrays I read: https://we.tl/t-aml3GBKorK\r\n\r\nThe full stacktrace I get:\r\n```\r\n2019-05-27 19:05:49.960354: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-05-27 19:05:50.173624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \r\nname: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 11.91GiB freeMemory: 11.62GiB\r\n2019-05-27 19:05:50.345182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \r\nname: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:82:00.0\r\ntotalMemory: 11.91GiB freeMemory: 11.62GiB\r\n2019-05-27 19:05:50.345255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\r\n2019-05-27 19:05:50.969891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-05-27 19:05:50.969933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \r\n2019-05-27 19:05:50.969940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N N \r\n2019-05-27 19:05:50.969943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   N N \r\n2019-05-27 19:05:50.970428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11241 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0)\r\n2019-05-27 19:05:50.970865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11241 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-12GB, pci bus id: 0000:82:00.0, compute capability: 6.0)\r\npython3.5/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\r\n  warnings.warn('The output shape of `ResNet50(include_top=False)` '\r\nEpoch 1/10\r\n2019-05-27 19:06:03.844910: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 5 of 10\r\n2019-05-27 19:06:13.468298: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 9 of 10\r\n2019-05-27 19:06:15.918664: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:136] Shuffle buffer filled.\r\nTraceback (most recent call last):\r\n  File \"python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 976, in conv2d\r\n    \"data_format\", data_format, \"dilations\", dilations)\r\ntensorflow.python.eager.core._FallbackException: Expecting int64_t value for attr strides, got numpy.int32\r\n\r\nDuring handling of the above exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/dir/to/my/script.py\", line 89, in <module>\r\n    history = model.fit(train, steps_per_epoch=int(np.ceil(num_train_samples / BATCH_SIZE)), epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=val, validation_steps=int(np.ceil(num_val_samples / BATCH_SIZE)))\r\n  File \"python3.5/site-packages/tensorflow/python/keras/engine/training.py\", line 1614, in fit\r\n    validation_steps=validation_steps)\r\n  File \"python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py\", line 705, in fit_loop\r\n    batch_size=batch_size)\r\n  File \"python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py\", line 251, in iterator_fit_loop\r\n    model, x, y, sample_weights=sample_weights, training=True)\r\n  File \"python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py\", line 511, in _process_single_batch\r\n    training=training)\r\n  File \"python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py\", line 90, in _model_loss\r\n    outs, masks = model._call_and_compute_mask(inputs, **kwargs)\r\n  File \"python3.5/site-packages/tensorflow/python/keras/engine/network.py\", line 856, in _call_and_compute_mask\r\n    mask=masks)\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py\", line 1029, in _run_internal_graph\r\n    computed_tensor, **kwargs)\r\n  File \"python3.5/site-packages/tensorflow/python/keras/engine/network.py\", line 856, in _call_and_compute_mask\r\n    mask=masks)\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py\", line 1031, in _run_internal_graph\r\n    output_tensors = layer.call(computed_tensor, **kwargs)\r\n  File \"python3.5/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\r\n    return self.call(inp, filter)\r\n  File \"python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\r\n    name=self.name)\r\n  File \"python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 982, in conv2d\r\n    name=name, ctx=_ctx)\r\n  File \"python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1015, in conv2d_eager_fallback\r\n    _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter], _ctx)\r\n  File \"python3.5/site-packages/tensorflow/python/eager/execute.py\", line 195, in args_to_matching_eager\r\n    ret = [internal_convert_to_tensor(t, dtype, ctx=ctx) for t in l]\r\n  File \"python3.5/site-packages/tensorflow/python/eager/execute.py\", line 195, in <listcomp>\r\n    ret = [internal_convert_to_tensor(t, dtype, ctx=ctx) for t in l]\r\n  File \"python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"python3.5/site-packages/tensorflow/python/ops/variables.py\", line 828, in _TensorConversionFunction\r\n    \"of type '%s'\" % (dtype.name, v.dtype.name))\r\nValueError: Incompatible type conversion requested to type 'uint8' for variable of type 'float32'\r\n2019-05-27 19:06:16.022529: W tensorflow/core/kernels/data/generator_dataset_op.cc:78] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\r\n\t [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_INT64], token=\"pyfunc_2\"](arg0)]]\r\n```\r\n", "comments": ["Hi!\r\nDid you manage to solve the issue? :)", "@tommydino93 , Although the message is completely unrelated (strigs, int64, etc), I solved this by inspecting my input data and noticing they were of different types. Some inputs were float64, some were float32. Besides fixing this differente I also set the `dtype` arguments (not sure if necessary) and `tf.keras.backend.set_floatx(...)` to the type I was using. "]}, {"number": 29062, "title": "[Java] Reduce Sum operation not usable", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.1 Cinnamon\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Binary / jar file downloaded from Maven Repository\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: N/A\r\n- Java version: 11.0.3\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A (using CPU only)\r\n\r\n**Describe the current behavior**\r\nTrying to create an instance of the ReduceSum Operation causes the following exception:\r\n`Error: \r\njava.lang.IllegalArgumentException: Op type not registered 'ReduceSum' in binary running on lucah-Super-Server. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed. while building NodeDef 'reduce'\r\n\tat org.tensorflow.OperationBuilder.finish(Native Method)\r\n\tat org.tensorflow.OperationBuilder.build(OperationBuilder.java:58)\r\n\tat theGhastModding.tfTest.main.Cifar10.main(Cifar10.java:35)`\r\nThe same also occurs for the ReduceAll, ReduceAny, ReduceJoin, ReduceMax, ReduceMean, ReduceMin and ReduceProd Operations, every other Operation works as expected.\r\n\r\n**Describe the expected behavior**\r\nThe Operation is built successfully and can be used normally.\r\n\r\n**Code to reproduce the issue**\r\nThe following code causes the above Exception to be thrown at the third line:\r\n`Graph graph = new Graph();\r\n\r\nOperation pl = graph.opBuilder(\"Placeholder\", \"z\").setAttr(\"dtype\", DataType.FLOAT).build();\r\n\r\nOperation sum = graph.opBuilder(\"ReduceSum\", \"reduce\").addInput(pl.output(0)).build();`", "comments": ["The op is not called ReduceSum, it's called Sum.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29062\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29062\">No</a>\n"]}, {"number": 29061, "title": "InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with 'AAAAAAAAAAAAAAAA' ", "body": "**System information**\r\n- OS Platform and Distribution: MacOS Sierra 10.12.6\r\n- TensorFlow installed from (source or binary): with pip\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7.0\r\n\r\n**Describe the problem**\r\n\r\nI'm preparing my trained model (custom Keras) for deploy on Tensorflow Serving so that it receives image bytes and returns a prediction mask. Here's my `signature_def`:\r\n```\r\nsignature_def['predict_images']:\r\n  The given SavedModel SignatureDef contains the following input(s):\r\n    inputs['inputs'] tensor_info:\r\n        dtype: DT_STRING\r\n        shape: (-1)\r\n        name: image_bytes:0\r\n  The given SavedModel SignatureDef contains the following output(s):\r\n    outputs['outputs'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 256, 256, 1)\r\n        name: conv2d_23/Sigmoid:0\r\n  Method name is: tensorflow/serving/predict\r\n```\r\nMy `serving_input_receiver_fn` function is:\r\n```\r\ndef process_image(self, image_buffer):\r\n    image = tf.image.decode_jpeg(image_buffer, channels=3)\r\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\r\n    image = tf.expand_dims(image, 0)\r\n    image = tf.image.resize_bilinear(image, [256, 256], align_corners=False)\r\n    image = tf.squeeze(image, [0])\r\n    image = tf.cast(image, tf.float32) / 255.0\r\n    return image\r\n\r\ndef serving_input_receiver_fn(self):\r\n    input_ph = tf.placeholder(dtype=tf.string, shape=[None], name='image_bytes')\r\n    images_tensor = tf.map_fn(self.process_image, input_ph, back_prop=False, dtype=tf.float32)\r\n    return tf.estimator.export.ServingInputReceiver({'input_1': images_tensor}, {'image_bytes': input_ph})\r\n```\r\n\r\nWhen i load my image from S3 with the following code:\r\n```\r\nimage = load_image_from_s3('s3://bucket/path/to/image.png')\r\nbytes_image = base64.b64encode(image).decode('utf-8')\r\nwith tf.Session(graph=tf.Graph()) as sess:\r\n    model = tf.saved_model.loader.load(sess, [\"serve\"], 'gs://bucket/saved/model/dir/')\r\n    graph = tf.get_default_graph()\r\n    input_dict, output_dict = _signature_def_to_tensors(model.signature_def['predict_images'])\r\n    predictions = sess.run(output_dict, feed_dict={input_dict['inputs']: [bytes_image]})\r\n```\r\ni get the following error:\r\n```\r\nInvalidArgumentError (see above for traceback): Expected image (JPEG, PNG, or GIF), got unknown format starting with 'AAAAAAAAAAAAAAAA'\r\n```\r\nbut if i load the same image from local as follows:\r\n```\r\nimage_data = tf.gfile.GFile('/local/path/to/image.png', 'rb').read()\r\n```\r\nand call predictions as:\r\n```\r\npredictions = sess.run(output_dict, feed_dict={input_dict['inputs']: [image_data]})\r\n```\r\nIt does work. How can i get it to work with base64 encoding  so that i can then deploy and use it with Tensorflow Serving and my live application?\r\n\r\n\r\n**Notes**:\r\nThis works too:\r\n```\r\ntf.image.decode_jpeg(bytes_image, channels=3)\r\n<tf.Tensor 'DecodeJpeg:0' shape=(?, ?, 3) dtype=uint8>\r\n```\r\nI've already tried a similar versions of this issue [on StackOverflow](https://stackoverflow.com/questions/56275522/tensorflow-serving-how-to-decode-base64-encoded-png-images-during-preprocessing)\r\n\r\nThank you so much for the support! I hope it's a question relevant to this channel\r\n\r\n\r\n\r\n\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there and can provide better and quick help for such type of issues. Thanks!\r\n", "Thank you, i was just about to close the ticket. I solved it in a different way using [this](https://github.com/mhwilder/tf-keras-gcloud-deployment/) as an excellent guide\r\n"]}, {"number": 29060, "title": "\"Cache iterator is in an invalid state\" error", "body": "**System information**\r\n- OS Platform and Distribution: macOS High Sierra 10.13.6\r\n- TensorFlow for CPU installed from PyPI\r\n- TensorFlow version: v1.13.0-rc2-5-g6612da8951, 1.13.1\r\n- Python version: 3.6.6\r\n\r\n**Describe the current behavior**\r\n\r\nMinimal not working example:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework.errors_impl import OutOfRangeError\r\n\r\n\r\ndataset = tf.data.Dataset.range(10)\r\ndataset = dataset.cache('cache1')\r\ndataset = dataset.map(lambda a: a)\r\ndataset = dataset.batch(4)\r\n\r\nbatch = dataset.make_one_shot_iterator().get_next()\r\n\r\nwith tf.Session() as sess:\r\n    while True:\r\n        try:\r\n            res = sess.run(batch)\r\n            print(res)\r\n        except OutOfRangeError:\r\n            print('out-of-range')\r\n            break\r\n```\r\n\r\nThe code above properly iterates through the dataset only the first run when a cache doesn't exist. But when it loads the dataset from the cache file it crashes with an error:\r\n```\r\ntensorflow.python.framework.errors_impl.InternalError: Cache iterator is in an invalid state. (Perhaps GetNext called after end_of_sequence?)\r\n\t [[{{node IteratorGetNext}}]\r\n```\r\n\r\n**A workaround**\r\n\r\nIt happens because the `map` operation follows right after the `cache`. It starts working as expected if some other dataset operation is added between `cache` and `map` steps. For example:\r\n```python\r\n...\r\n\r\ndataset = tf.data.Dataset.range(10)\r\ndataset = dataset.cache('cache1')\r\ndataset = dataset.filter(lambda x: True)  # a fake filter is added\r\ndataset = dataset.map(lambda a: a)\r\ndataset = dataset.batch(4)\r\n\r\n...\r\n```", "comments": ["@apls777 I have executed the first part of the code in TF 1.12.0, did not receive any error. Please try and let us know how it progresses. Thanks!", "@muddham It works in TF 1.12.0. Just changed the filename to `./cache1` instead of `cache1`, otherwise, it throws an error for the first run:\r\n```\r\ntensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory\r\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?]], output_types=[DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\r\n```", "@apls777 As it is working now, are you happy for this issue to be closed?", "@muddham No, clearly it\u2019s a bug that should be fixed in the latest stable version.", "@apls777 I ran the code in TF 1.13 GPU the output I got was below.\r\n[0 1 2 3]\r\n[4 5 6 7]\r\n[8 9]\r\nout-of-range\r\n\r\nIn TF 1.13 CPU I got the below error.\r\nAttributeError: 'BatchDataset' object has no attribute 'make_one_shot_iterator'", "@muddham Did you run the code twice to load the dataset from a cache? Are you sure you're running it on TF 1.13 **.1**? What version of Python do you use?", "> @muddham Did you run the code twice to load the dataset from a cache? Are you sure you're running it on TF 1.13 **.1**? What version of Python do you use?\r\n\r\nI am able to reproduce the issue with TF 1.13.1 and Python 3.6.7. ", "@apls777 thank you for reporting the issue and providing a minimal reproducible example.\r\n\r\nI can confirm this is an issue. The problem is that the existing cache transformation produces an error if the dataset transformation that consumes its input asks for an input after the cache transformations has reached the end of its input. This happens in your repro because `.map(fn).batch(batch_size)` will get fused into `.map_and_batch(fn, batch_size)` which will ask for `batch_size` worth of elements at once. Because the input cardinality (10) is not divisible evenly by the batch size (4), the invalid cache op kernel behavior is triggered. Inserting a transformation between `map` and `batch` will prevent the fusion from happening (and so does disabling the fusion through tf.data [options](https://www.tensorflow.org/api_docs/python/tf/data/experimental/OptimizationOptions#map_and_batch_fusion).\r\n\r\nI have a fix for this and expect it to merged to master by the end of this week.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29060\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29060\">No</a>\n", "@apls777 \r\n\r\nI'm running into this issue when caching before `interleave`\r\n\r\n`tf 2.0.0-beta1` and `python 3.6.8`\r\n```python\r\n    filenames_dataset = filenames_dataset.cache(\"./some_path\")\r\n\r\n    return filenames_dataset.interleave(\r\n        lambda f: map_file_to_xy_dataset(f, predict_task_fn, params),\r\n        cycle_length=params[CYCLE_LENGTH_KEY],\r\n        block_length=params[BLOCK_LENGTH_KEY],\r\n        num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n```\r\n\r\n```\r\nIterator \"Iterator::Model::Prefetch::Batch::Shuffle::ParallelInterleaveV2\" returned OutOfRange without setting `*end_of_sequence`. This indicates that an error may have occurred. Original message: Attempting to call get_next after iteration should have finished. [Op:IteratorGetNextSync]\r\n```", "@devstein thank you for reporting the problem. This is a different issue, so please create a new issue for it and reference it here. Thank you.", "@jsimsa Will do!"]}, {"number": 29059, "title": "Not able to install tensorflow alpha on Mac OS", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Mojave 10.14.4\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0.0 alpha\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: Intel Iris Graphics 6100 - 1536 MB\r\n\r\n\r\n**Describe the problem**\r\n\r\nI'm not able to install tensorflow with the following command: `pip3 install tensorflow==2.0.0-alpha0`. Every time when I run the command I get the error zsh: 2.0.0-alpha0 not found. I tried different python3 versions, but none of them worked\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nJust install python 3.7.3 and run the command `pip3 install tensorflow==2.0.0-alpha0`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nError: `zsh: 2.0.0-alpha0 not found`", "comments": ["@keahie  Please find instructions in this [link](https://www.tensorflow.org/install/pip) which help you to install Tensorflow. Let us know how it progresses. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 29058, "title": "TfLite warning fix change", "body": "", "comments": ["Internal review decided to not follow with the size_t changes only in a subset of all affected files\r\n\r\nClosing this but if you want to do it in all affected files that would be great."]}, {"number": 29057, "title": "Static lib path fix for arm64 build", "body": "Updated the libtensorflow-lite.a path", "comments": []}, {"number": 29056, "title": "TFLite GPU delegate model inconsistencies: Mobilenet v1 1.0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 0.0.1-gpu-experimental\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\nThe [mobilenet v1 1.0](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/mobilenet_v1_1.0_224.tflite) model in the [guide](https://www.tensorflow.org/lite/performance/gpu) contains a squeeze operation that isn't supported by GPU, but the [mobilenet v1 1.0](http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224.tgz) at  [tensorflow/models](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md) does. AFAIK, squeeze isn't a supported operation, but both of them contain at least one. How come the operations are different even when the models are of the same version? Is the one in the guide deliberately modified? If so, would it be a better idea to have it noted in the guide? The page on tensor/models claims 569mil MACs, but the number of MACs this modified 1.0 has is unclear.\r\n\r\nWhat I've found is that the one provided in the guide contains 89 tensors but the one in tensorflow/models 88.\r\n\r\n**Describe the expected behavior**\r\n\r\nModels of the same version should be identical. Any modification should be explicitly documented.", "comments": ["I've dug a bit deeper. The one in the guide has this additional tensor:\r\n\r\n`< {'name': 'MobilenetV1/Logits/SpatialSqueeze_shape', 'index': 32, 'shape': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0)}`\r\n\r\nAnyone know why?\r\n\r\nHere's the list I got:\r\n\r\n```\r\nMobilenetV1/Conv2d_0/weights\r\nMobilenetV1/Conv2d_10_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_10_pointwise/weights\r\nMobilenetV1/Conv2d_11_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_11_pointwise/weights\r\nMobilenetV1/Conv2d_12_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_12_pointwise/weights\r\nMobilenetV1/Conv2d_13_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_13_pointwise/weights\r\nMobilenetV1/Conv2d_1_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_1_pointwise/weights\r\nMobilenetV1/Conv2d_2_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_2_pointwise/weights\r\nMobilenetV1/Conv2d_3_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_3_pointwise/weights\r\nMobilenetV1/Conv2d_4_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_4_pointwise/weights\r\nMobilenetV1/Conv2d_5_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_5_pointwise/weights\r\nMobilenetV1/Conv2d_6_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_6_pointwise/weights\r\nMobilenetV1/Conv2d_7_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_7_pointwise/weights\r\nMobilenetV1/Conv2d_8_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_8_pointwise/weights\r\nMobilenetV1/Conv2d_9_depthwise/depthwise_weights\r\nMobilenetV1/Conv2d_9_pointwise/weights\r\nMobilenetV1/Logits/AvgPool_1a/AvgPool\r\nMobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd\r\nMobilenetV1/Logits/Conv2d_1c_1x1/Conv2D_bias\r\nMobilenetV1/Logits/Conv2d_1c_1x1/weights\r\nMobilenetV1/Logits/SpatialSqueeze\r\nMobilenetV1/Logits/SpatialSqueeze_shape\r\nMobilenetV1/MobilenetV1/Conv2d_0/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_0/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_10_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_10_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_11_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_11_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_12_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_12_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_13_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_13_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_1_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_2_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_2_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_3_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_3_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_4_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_4_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_5_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_5_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_6_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_6_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_7_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_7_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_8_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_8_pointwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_9_depthwise/Relu6\r\nMobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_bias\r\nMobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_bias\r\nMobilenetV1/MobilenetV1/Conv2d_9_pointwise/Relu6\r\nMobilenetV1/Predictions/Reshape_1\r\ninput\r\n```", "@hoonkai \r\n\r\nIIRC the official model includes SQUEEZE, whereby the GPU-compatible model replaces the op with RESHAPE.   There can be multiple ways to represent a certain operation, and the one we present in the GPU page is rewritten to have no GPU-incompatible ops.\r\n\r\nI don't think going and updating the official MobileNet release is the scope of the GPU backend, and that may break some other people."]}]