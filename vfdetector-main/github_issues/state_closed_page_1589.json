[{"number": 5243, "title": "Bug with cifar10 ?", "body": "Hi everyone,\r\nI'm trying to make prediction with the cifar-10 model in /tensorflow/models/image/cifar10\r\nBut it don't work.\r\nHere is the code I tried : \r\n\r\n```\r\nfrom PIL import Image\r\nimport tensorflow as tf\r\nfrom tensorflow.models.image.cifar10 import cifar10\r\nimport itertools\r\nwidth = 24\r\nheight = 24\r\n\r\ncategories = [ \"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\" ]\r\n\r\nfilename = \"toto.jpg\" # absolute path to input image\r\nim = Image.open(filename)\r\nim.save(filename, format='JPEG', subsampling=0, quality=100)\r\nx = tf.placeholder(tf.float32, [None, 24, 24, 3])\r\nlogits = cifar10.inference(x)\r\n_, top_k_pred = tf.nn.top_k(logits, k=5)\r\ninit_op = tf.initialize_all_variables()\r\nwith tf.Session() as sess:\r\n # Restore variables from training checkpoint.\r\n    input_img = tf.image.decode_jpeg(tf.read_file(filename), channels=3)\r\n    tf_cast = tf.cast(input_img, tf.float32)\r\n    float_image = tf.image.resize_image_with_crop_or_pad(tf_cast, height, width)\r\n    images = tf.expand_dims(float_image, 0)\r\n    i = images.eval()\r\n    print (i)\r\n    sess.run(init_op, feed_dict={x: i})\r\n    variable_averages = tf.train.ExponentialMovingAverage(\r\n        cifar10.MOVING_AVERAGE_DECAY)\r\n    variables_to_restore = variable_averages.variables_to_restore()\r\n    saver = tf.train.Saver(variables_to_restore)\r\n    ckpt = tf.train.get_checkpoint_state('/tmp/cifar10_train')\r\n    if ckpt and ckpt.model_checkpoint_path:\r\n        print(\"ckpt.model_checkpoint_path \", ckpt.model_checkpoint_path)\r\n        saver.restore(sess, ckpt.model_checkpoint_path)\r\n    else:\r\n        print('No checkpoint file found')\r\n        exit(0)\r\n    _, top_indices = sess.run([_, top_k_pred])\r\n    for key, value in enumerate(top_indices[0]):\r\n        print (categories[value] + \", \" + str(_[0][key]))\r\n```\r\n\r\nAnd here is the error I got : \r\n```\r\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [18,384] rhs shape= [2304,384]\r\n     [[Node: save/Assign_5 = Assign[T=DT_FLOAT, _class=[\"loc:@local3/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](local3/weights, save/RestoreV2_5)]]\r\n```\r\n\r\nSo, it seems than Tensorflow is not happy because the shape of the single image I want to predict [1,24,24,3] don't fit with the shape of a normal batch [128,24,24,3]\r\nBut, for one single image, it's necessary like this.\r\n\r\nMaybe I miss something but I don't get it... Or maybe it's a bug ?\r\nI already asked the question on stackoverflow in first place, here : http://stackoverflow.com/questions/40266275/tensorflow-and-cifar-10-testing-single-images#\r\n\r\nBut since it could be a bug, and nobody answered, I post here..\r\n\r\nThanks in advance!\r\n", "comments": ["Let's wait for an answer in stackoverflow. You probably want to look at the eval script and mimic whatever is in there.\n", "Well, the code I took is already more or less mimiced on the eval script.\nBut I think the problem will be the same, cause if you want to run a single image, the shape will not be the same..\n[128,24,24,3] != [1,24,24,3]\n", "Could you send the full stack trace not just the part that says invalidargumentError (attach it as a file)?\n", "For the short term you can just broadcast the images tensor to to be shape 128,24,24,3 (i.e. copy the image 128 times).  i.e.\n\n``` python\nnew_shape = [BATCH_SIZE] + i.get_shape().as_list()\ni = i.tile(i, new_shape)\n```\n", "Automatically closing due to lack of recent activity, we will reopen if further information becomes available. Thanks!\n", "For this issue, added below as @aselle suggested. \r\n\r\nnew_shape = [128] + images.get_shape().as_list()\r\nimages = tf.tile(images, new_shape)\r\nlogits = cifar10.inference(images)\r\n\r\nGetting below error, (traceback)\r\nTraceback (most recent call last):\r\n  File \"cifar10_infer.py\", line 17, in <module>\r\n    images = tf.tile(images, new_shape)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3612, in tile\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2242, in create_op\r\n    set_shapes_for_outputs(ret)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1617, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1568, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 675, in _call_cpp_shape_fn_impl\r\n    raise ValueError(err.message)\r\nValueError: Shape must be rank 4 but is rank 5 for 'Tile' (op: 'Tile') with input shapes: [1,24,24,3], [5].\r\n\r\nI am not clear about how to convert [1,24,24,3] to [128,24,24,3] before passing to inference. Any help appreciated.\r\n", "@kushia were you able to resolve this?", "@pcfsanty No sorry. But always interested in the answer. If you find it, could you post it here ?\r\n\r\n(I use Keras now)", "@kushia \r\nused tile api with (images, [128,1,1,1] )\r\nNow tensor dimension matches with training. But accuracy top_5_pred is not correct. \r\nvery bad accuracy % with training max_steps = 500000", "@kushia I don't see any reason why the cifar10 inferenfce code should require a batch of 128. \r\nThe error message you posted is from an assign op - and there aren't any such ops in inference code. Are you sure that this isn't happening during restoring your model from checkpoint?\r\n\r\nCould you please post the full stack backtrace of the error - that way we can see what step was actually being run?\r\n", "I'm having the same issue trying to do the same thing. Here's my full stack backtrace of the error:\r\n\r\n`Traceback (most recent call last):\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1022, in _do_call\r\n    return fn(*args)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1004, in _run_fn\r\n    status, run_metadata)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [18,384] rhs shape= [2304,384]\r\n\t [[Node: save/Assign_5 = Assign[T=DT_FLOAT, _class=[\"loc:@local3/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](local3/weights, save/RestoreV2_5)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 51, in <module>\r\n    evaluate_images(images)\r\n  File \"test.py\", line 17, in evaluate_images\r\n    load_trained_model(logit)\r\n  File \"test.py\", line 26, in load_trained_model\r\n    saver.restore(sess, ckpt.model_checkpoint_path)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1439, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [18,384] rhs shape= [2304,384]\r\n\t [[Node: save/Assign_5 = Assign[T=DT_FLOAT, _class=[\"loc:@local3/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](local3/weights, save/RestoreV2_5)]]\r\n\r\nCaused by op 'save/Assign_5', defined at:\r\n  File \"test.py\", line 51, in <module>\r\n    evaluate_images(images)\r\n  File \"test.py\", line 17, in evaluate_images\r\n    load_trained_model(logit)\r\n  File \"test.py\", line 25, in load_trained_model\r\n    saver = tf.train.Saver()\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1051, in __init__\r\n    self.build()\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1081, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 675, in build\r\n    restore_sequentially, reshape)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 414, in _AddRestoreOps\r\n    assign_ops.append(saveable.restore(tensors, shapes))\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\r\n    self.op.get_shape().is_fully_defined())\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\r\n    use_locking=use_locking, name=name)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [18,384] rhs shape= [2304,384]\r\n\t [[Node: save/Assign_5 = Assign[T=DT_FLOAT, _class=[\"loc:@local3/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](local3/weights, save/RestoreV2_5)]]\r\n`", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you.", "you should change the batch_size in cifar10.py to 1, otherwise the default number is 128.  The size of  weights in local/3 is [input_batch * 2304 / batch_size]."]}, {"number": 5242, "title": "Windows GPU gradient always 0 but CPU works", "body": "Hello all,\nI was working on installing and testing the new windows gpu support and it does not seem to be working right for me. To start off, I was following [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md) and I have all of the same software as their windows 10 known good configuration, except I have Microsoft Visual Studio **Community** 2015 with Visual C++ 2015.\nMy github head is: 2cbb9b529a6723ebbe07663156b18c04fbaf4531\nAfter I few times of trying to get it to install, I managed to get it to install by changing to cmake 3.6 from 3.7. It installed fine but it does not seem to work properly. \nI downloaded some known good code, file [here](http://pastebin.com/AiTaaizs), and when I run it specifiying that tensorflow should use cpu, I get good output that looks like [this](http://pastebin.com/nQFcMZ07). If I allow it to run on gpu, I get bad output that looks like [this](http://pastebin.com/dcDYsfWr). I am not sure why. I feel like it is probably an issue with my install even though it had no errors. Any help would be greatly appreciated.\n", "comments": ["Sorry, it doesn't work on 3.7. We're amending the documentation PR #5103 . I think it's possible to make it work, but not out of the box.\n", "I know that it doesn't work on 3.7. I got it to install by changing from cmake 3.7 to cmake 3.6, but even though it installed, it does not run code properly on gpu for me. As shown by the above outputs, the code fails on gpu but works fine on cpu.\n", "We're still working on the windows GPU, which is an outstanding community contribution, so not everything works quite yet. We're hoping to get more fixes in the next few days.\n\n@guschmue FYI\n", "Thanks for the information. I will make sure to stay in tune. I will also mess around and see if I can get it to work.\n", "This sounds a lot like https://github.com/tensorflow/tensorflow/pull/5207. \nI ran your sample code on my box and it works ok.\n", "@Bren077s Please try @guschmue 's PR or wait until we merge. You can test a PR locally:\n\n```\ngit fetch origin pull/5207/head:pr5207\ngit checkout pr5207\n```\n", "I tried installing tensorflow, by using the commands you told me and I got new errors. I also tried downloading directly from @guschmue github fork of tensorflow and got the same errors. Here are the errors that I get: [Errors](http://pastebin.com/f8eb3Qrr)\n", "This was fixed with: https://github.com/tensorflow/tensorflow/pull/5157 and merged into the master yesterday. #5207 was merged today into the master.\nI have a jenkins for windows gpu following the master and its happy.\n", "Nice!\n"]}, {"number": 5241, "title": "Changed context creation to use primary context", "body": "Reopening of PR #5196, which was issued to the wrong branch.\n", "comments": ["@ptrendx, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @mrry and @guschmue to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "henline@, could you confirm your LGTM on this change? \n", "@tensorflow-jenkins test this please\n"]}, {"number": 5240, "title": "0.11.0rc1 linux 2.7 GPU nightlies ignore CUDA 7.5 installation, wants CUDA 8.0", "body": "A couple of days ago the 0.11.0rc1 nightly depended on CUDA 7.5 [#269 for example](https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/269/). I've just downloaded today's nightly and it seems to want CUDA 8.0. Is CUDA 8.0 the new pip binary dependency or is this a mistake?\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nN/A\n### Environment info\n\nOperating System: Ubuntu 16.04\n\nInstalled version of CUDA and cuDNN: CUDA 7.5 and cuDNN 4.0.7\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\n$ ls -l /usr/lib/x86_64-linux-gnu/libcud*\n-rw-r--r-- 1 root root   322936 Sep 19  2015 /usr/lib/x86_64-linux-gnu/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Mar 30  2016 /usr/lib/x86_64-linux-gnu/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Mar 30  2016 /usr/lib/x86_64-linux-gnu/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rw-r--r-- 1 root root   383336 Sep 19  2015 /usr/lib/x86_64-linux-gnu/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Sep 19  2015 /usr/lib/x86_64-linux-gnu/libcudart_static.a\nlrwxrwxrwx 1 root root       12 Jun  5 01:26 /usr/lib/x86_64-linux-gnu/libcuda.so -> libcuda.so.1\nlrwxrwxrwx 1 root root       17 Jun  5 01:26 /usr/lib/x86_64-linux-gnu/libcuda.so.1 -> libcuda.so.364.19\n-rw-r--r-- 1 root root 16963368 Apr 19  2016 /usr/lib/x86_64-linux-gnu/libcuda.so.364.19\nlrwxrwxrwx 1 root root       13 Aug 29 10:59 /usr/lib/x86_64-linux-gnu/libcudnn.so -> libcudnn.so.4\nlrwxrwxrwx 1 root root       17 Aug 29 10:59 /usr/lib/x86_64-linux-gnu/libcudnn.so.4 -> libcudnn.so.4.0.7\n-rwxr-xr-x 1 root root 61453024 Aug 29 10:59 /usr/lib/x86_64-linux-gnu/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Aug 29 10:59 /usr/lib/x86_64-linux-gnu/libcudnn_static.a\n```\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n   [link](https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl)\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n```\n$ python -c 'import tensorflow'\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 60, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File \"/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/home/sperkins/venv/tftest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\nImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory\n\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.\n```\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n### What other attempted solutions have you tried?\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n", "comments": ["Yes, \n\n```\nldd /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\n```\n\nshows the dependency. I don't know that we have a build for `7.5`, so at this point I'd recommend building from source.\n\n@gunan for potential additional insights.\n", "Thanks, might be worth changing the issue to track a documentation change - os_setup.md hints at CUDA 7.5 as the standard.\n", "Looks like we updated the branch for rc1, but when merging it back into master we missed that diff, and stayed with cuda7.5\n@yifeif FYI\n"]}, {"number": 5239, "title": "gemmlowp external dependency has been added to CMake.", "body": "Hi guys!\n\nWhile compiling tf_core_kernels in Ubuntu using cmake, I found out that 'gemmlowp' external dependency is missing from CMake file. I just added and everything compiled.\n", "comments": ["@kamcpp, thanks for your PR! By analyzing the history of the files in this pull request, we identified @mrry, @guschmue and @ageron to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please.\n", "Thanks for the contribution! I'm a little concerned that this will cause problems with the Windows CMake build (since IIRC `gemmlowp` uses some POSIX-specific headers), but we'll see how the tests look....\n", "It's OK! I'll make it work just for unix based systems if something goes wrong.\n", "Looks good, though I'm a little surprised... the file [`tensorflow/contrib/cmake/patches/gemmlowp/CMakeFiles.txt`](https://github.com/tensorflow/tensorflow/blob/2cbb9b529a6723ebbe07663156b18c04fbaf4531/tensorflow/contrib/cmake/patches/gemmlowp/CMakeLists.txt) doesn't seem to do anything (unless there's some CMake implicit behavior that I wasn't aware of...).\n\nWas the build _not_ working before you made this PR? I'm concerned it might be a no-op....\n", "Yes, me too !! I wasn't waiting for success for Windows build. I'll double check the issue and I'll post the errors I get.\n", "Thanks for looking into it!\n", "I cloned a fresh version of tensorflow form google repo. I started compilation on a fresh Ubuntu 16.04 LTS. Despite compiling zlib, grpc said it can't find the zlib.h .So I installed zlib1g-dev using apt-get. \nloading initial cache file /home/kamran/data/prj/tensorflow/tensorflow/contrib/cmake/build/grpc/tmp/grpc-cache-.cmake\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/kamran/data/prj/tensorflow/tensorflow/contrib/cmake/build/grpc/src/grpc\n[  1%] Performing build step for 'grpc'\n[ 19%] Built target gpr\n[ 19%] Building C object CMakeFiles/grpc_unsecure.dir/src/core/lib/compression/message_compress.c.o\n/home/kamran/data/prj/tensorflow/tensorflow/contrib/cmake/build/grpc/src/grpc/src/core/lib/compression/message_compress.c:41:18: fatal error: zlib.h: No such file or directory\ncompilation terminated.\nCMakeFiles/grpc_unsecure.dir/build.make:302: recipe for target 'CMakeFiles/grpc_unsecure.dir/src/core/lib/compression/message_compress.c.o' failed\nmake[5]: **\\* [CMakeFiles/grpc_unsecure.dir/src/core/lib/compression/message_compress.c.o] Error 1\nCMakeFiles/Makefile2:104: recipe for target 'CMakeFiles/grpc_unsecure.dir/all' failed\nmake[4]: **\\* [CMakeFiles/grpc_unsecure.dir/all] Error 2\nMakefile:83: recipe for target 'all' failed\nmake[3]: **\\* [all] Error 2\nCMakeFiles/grpc.dir/build.make:113: recipe for target 'grpc/src/grpc-stamp/grpc-build' failed\nmake[2]: **\\* [grpc/src/grpc-stamp/grpc-build] Error 2\nCMakeFiles/Makefile2:1595: recipe for target 'CMakeFiles/grpc.dir/all' failed\nmake[1]: **\\* [CMakeFiles/grpc.dir/all] Error 2\nMakefile:83: recipe for target 'all' failed\nmake: **\\* [all] Error 2\n\nCompilation continued. The next error was for gemmlowp. Here is the error I got:\n\n[ 45%] Building CXX object CMakeFiles/tf_core_ops.dir/home/kamran/data/prj/tensorflow/tensorflow/core/user_ops/fact.cc.o\n[ 45%] Built target tf_core_ops\nScanning dependencies of target tf_core_direct_session\n[ 46%] Building CXX object CMakeFiles/tf_core_direct_session.dir/home/kamran/data/prj/tensorflow/tensorflow/core/common_runtime/direct_session.cc.o\n[ 46%] Building CXX object CMakeFiles/tf_core_direct_session.dir/home/kamran/data/prj/tensorflow/tensorflow/core/debug/debug_io_utils.cc.o\n[ 46%] Building CXX object CMakeFiles/tf_core_direct_session.dir/home/kamran/data/prj/tensorflow/tensorflow/core/debug/debug_gateway.cc.o\n[ 46%] Building CXX object CMakeFiles/tf_core_direct_session.dir/home/kamran/data/prj/tensorflow/tensorflow/core/debug/debug_graph_utils.cc.o\n[ 46%] Built target tf_core_direct_session\nScanning dependencies of target tf_core_kernels\n[ 46%] Building CXX object CMakeFiles/tf_core_kernels.dir/home/kamran/data/prj/tensorflow/tensorflow/core/kernels/one_hot_op.cc.o\n[ 46%] Building CXX object CMakeFiles/tf_core_kernels.dir/home/kamran/data/prj/tensorflow/tensorflow/core/kernels/topk_op.cc.o\n[ 46%] Building CXX object CMakeFiles/tf_core_kernels.dir/home/kamran/data/prj/tensorflow/tensorflow/core/kernels/quantized_conv_ops.cc.o\n/home/kamran/data/prj/tensorflow/tensorflow/core/kernels/quantized_conv_ops.cc:21:29: fatal error: public/gemmlowp.h: No such file or directory\ncompilation terminated.\nCMakeFiles/tf_core_kernels.dir/build.make:110: recipe for target 'CMakeFiles/tf_core_kernels.dir/home/kamran/data/prj/tensorflow/tensorflow/core/kernels/quantized_conv_ops.cc.o' failed\nmake[2]: **\\* [CMakeFiles/tf_core_kernels.dir/home/kamran/data/prj/tensorflow/tensorflow/core/kernels/quantized_conv_ops.cc.o] Error 1\nCMakeFiles/Makefile2:3282: recipe for target 'CMakeFiles/tf_core_kernels.dir/all' failed\nmake[1]: **\\* [CMakeFiles/tf_core_kernels.dir/all] Error 2\nMakefile:83: recipe for target 'all' failed\nmake: **\\* [all] Error 2\n\nI did clone another fresh version and I applied the PR. Everything compiled successfully. I don\u2019t argue about the zlib right now but I think PR is not a no-op. About the Windows, there should be something preventing the gemmlowp entering the build process.\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Ah, now I get it - it's a headers-only library, so there's no build step required. OK, changes look good and I'll run the tests just to confirm no breakage. Thanks!\n", "@tensorflow-jenkins test this please.\n", "Thank you. Is there any mailing list to ask questions about TF?\n", "The best place for questions is the `[tensorflow]` tag on Stack Overflow!\n", "I meant that I want to ask questions and give suggestions about the way examples are built and libraries are produced. I want to discuss ideas.\n", "@tensorflow-jenkins test this please.\n", "It seems some tests were failed becuase of some internal error, right ?\n", "This is good to merge.\n"]}, {"number": 5238, "title": "gemmlopw has been added to external dependencies.", "body": "Hi guys,\nI was building tf using CMake in ubuntu. I found out that an external dependency (gemmlowp) is missing from the CMakeLists.txt file. The building failed while compiling tf_core_kernels files. I just added the dependency and everything went OK.\n", "comments": ["Can one of the admins verify this patch?\n", "@kamcpp, thanks for your PR! By analyzing the history of the files in this pull request, we identified @mrry, @guschmue and @ageron to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 5237, "title": "Problem compiling tensorflow for iOS ", "body": "**Environment info:**\nOperating System: macOS 10.11.6\u2028\nxcode 7.3.1\u2028\n\n**Steps to reproduce:**\nI follow the steps from here [ios_examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/ios_examples) and the steps specific to install for iOS described here\n[makefile](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile)\n\n**Basically what i did:**\n- Clone the repository\n- Download the graph\n- Build\n\n**Building all at once:** \n\n`tensorflow/contrib/makefile/build_all_ios.sh`\n\nResults in:\n\n```\n+ PROTOC_PATH=/Users/ppcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc\n+ [[ ! -f /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc ]]\n+ echo 'protoc not found at /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.'\nprotoc not found at /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.\n+ make_host_protoc /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host\n+ [[ ! -n /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host ]]\n+ HOST_GENDIR=/Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host\n+ ./autogen.sh\nGoogle Mock not present.  Fetching gmock-1.7.0 from the web...\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   129    0   129    0     0    172      0 --:--:-- --:--:-- --:--:--   172\n100  362k  100  362k    0     0   177k      0  0:00:02  0:00:02 --:--:--  349k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   129    0   129    0     0    176      0 --:--:-- --:--:-- --:--:--   176\n100  618k  100  618k    0     0   288k      0  0:00:02  0:00:02 --:--:--  511k\n+ autoreconf -f -i -Wall,no-obsolete\nconfigure.ac:30: error: possibly undefined macro: AC_PROG_LIBTOOL\n      If this token and others are legitimate, please use m4_pattern_allow.\n      See the Autoconf documentation.\nautoreconf: /usr/local/Cellar/autoconf/2.69/bin/autoconf failed with exit status: 1\n\n\n```\n\n**Building by hand:**\n\nI have downloaded all dependencies with the command:\n`tensorflow/contrib/makefile/download_dependencies.sh`\nResult:\n`download_dependencies.sh completed successfully.`\n\n**Than when I try to compile protobufs:**\n\n`tensorflow/contrib/makefile/compile_ios_protobuf.sh`\n\n**I have the following result, similar to the one from above:**\n\n```\n+ PROTOC_PATH=/Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc\n+ [[ ! -f /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc ]]\n+ echo 'protoc not found at /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.'\nprotoc not found at /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.\n+ make_host_protoc /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host\n+ [[ ! -n /Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host ]]\n+ HOST_GENDIR=/Users/appcenter/Documents/devDownloads/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host\n+ ./autogen.sh\n+ autoreconf -f -i -Wall,no-obsolete\nconfigure.ac:30: error: possibly undefined macro: AC_PROG_LIBTOOL\n      If this token and others are legitimate, please use m4_pattern_allow.\n      See the Autoconf documentation.\nautoreconf: /usr/local/Cellar/autoconf/2.69/bin/autoconf failed with exit status: 1\n\n\n```\n\n**Observation:**\n\nWhen I look into the folder from bellow it contains an empty folder named lib:\n`tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios`\n\nThe folder from bellow is empty:\n`tensorflow/tensorflow/contrib/makefile/gen/protobuf-host`\n\nConclusion: it seems to me that there is a problem building protobuf.\nWhat does the message \"Google Mock not present.\" exactly mean?\n", "comments": ["Google Mock is the testing framework, which is downloaded automatically. We've had problems with `glibtoolize` in the past. Let me see...\n", "Just making sure: `brew install libtool`?\n", "Yes, **libtool** is installed correctly.\nThe folder usr/local/Cellar have the following content:\n**cmake** -  installed a long time ago\n**autoconf** - installed recently v 2.69\n**automake** - installed recently v 1.15\n**libtool** - installed recently v 2.4.6\n\n**Comment:** \nI have parallel two versions of Xcode installed but I don't think it is causing any problem:\nApplications/Xcode - v 7.3.1\nApplications/Xcode8 - v 8\n", "Do you have aclocal as well? Can you run libtoolize --force?\n", "**When I try to install libtool:**\n\n```\nbrew install libtool\nWarning: libtool-2.4.6 already installed, it's just not linked\n\n```\n\n**When I try to install libtoolize:**\n\n```\nbrew install libtoolize\nError: No available formula for libtoolize \n==> Searching formulae...\n==> Searching taps...\n==> You haven't updated Homebrew in a while.\nA formula for libtoolize might have been added recently.\nRun `brew update` to get the latest Homebrew updates!\nMacBook-Air:tensorflow appcenter$ brew update\n\n```\n\n**I have libtool but not libtoolize :**\n/usr/local/Cellar/libtool/2.4.6/share/aclocal/libtool.m4\n", "this is the libtool m4 macro file, but not libtool itself.\ncan you try\n\n```\nwhich libtool\n```\n", "```\n$ which libtool\n/usr/bin/libtool\n```\n", "Same error.\n", "Fixed by reinstalling libtool: `brew uninstall libtool && brew install libtool`.\n", "When trying to \n`$ brew uninstall libtool && brew install libtool`\n\nIt displays the message:\n\n```\nError: The `brew link` step did not complete successfully\nThe formula built, but is not symlinked into /usr/local\nCould not symlink include/libltdl\n/usr/local/include is not writable.\n```\n\nCreate the folder (if not exist) and take ownership of it:\n`$ sudo mkdir /usr/local/include`\n`$ sudo chown -R $USER:admin /usr/local/include`\n\nCreate the symlink:\n`$ brew link libtool`\n\nNow try to build:\n`$ tensorflow/contrib/makefile/compile_ios_protobuf.sh`\nthan\n`$ tensorflow/contrib/makefile/compile_ios_tensorflow.sh`\n\n**I managed to compile tensorflow now.**\nI have observed only some deprecation warnings like this one:\n`warning: 'OSAtomicAdd32' is deprecated: first deprecated in macOS 10.12`\n\nMany thanks for help!\n", "Same here! \r\n\r\nFollowed all the discussion above, also did\r\n`brew uninstall libtool && brew install libtool`\r\n\r\nNow my error information is:\r\n`+ HOST_GENDIR=/Users/honghaoli/git_folder/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host\r\n+ ./autogen.sh\r\nGoogle Mock not present.  Fetching gmock-1.7.0 from the web...\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100   129    0   129    0     0    417      0 --:--:-- --:--:-- --:--:--   418\r\n100  362k  100  362k    0     0   440k      0 --:--:-- --:--:-- --:--:-- 2110k\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100   129    0   129    0     0    393      0 --:--:-- --:--:-- --:--:--   394\r\n100  618k  100  618k    0     0   611k      0  0:00:01  0:00:01 --:--:-- 2106k\r\n+ autoreconf -f -i -Wall,no-obsolete\r\nCan't exec \"libtoolize\": No such file or directory at /usr/local/share/autoconf/Autom4te/FileUtils.pm line 345, <GEN8> line 6.\r\nautoreconf: failed to run libtoolize: No such file or directory\r\nautoreconf: libtoolize is needed because this package uses Libtool`\r\n\r\n\r\nHelp please!", "` which libtool\r\n   /usr/bin/libtool`", "Now it works.\r\n\r\nturns out there is already Apple's own `libtool`;\r\n`\u21d2  brew uninstall libtool && brew install libtool\r\n  Uninstalling /usr/local/Cellar/libtool/2.4.6_1... (70 files, 3.7M)\r\n  ==> Downloading https://homebrew.bintray.com/bottles/libtool-2.4.6_1.sierra.bottle.tar.gz\r\n  Already downloaded: /Users/honghaoli/Library/Caches/Homebrew/libtool-2.4.6_1.sierra.bottle.tar.gz\r\n  ==> Pouring libtool-2.4.6_1.sierra.bottle.tar.gz\r\n  ==> Caveats\r\n  In order to prevent conflicts with Apple's own libtool we have prepended a \"g\"\r\n  so, you have instead: glibtool and glibtoolize.\r\n  ==> Summary\r\n  \ud83c\udf7a  /usr/local/Cellar/libtool/2.4.6_1: 70 files, 3.7M`\r\n\r\nSo I have to rename glibtool and glibtoolize back to libtool and libtoolize.\r\n\r\nJust post it here in case anyone has the same issue later."]}, {"number": 5236, "title": "Extend the info in the placement log to include the node type", "body": "Small suggestion:\n\nIn the function SimplePlacer::AssignAndLog, change the print and log to be:\n\n```\nprintf(\"%s (%s): %s\\n\", node->name().c_str(),\n       node->type_string().c_str(),\n       node->assigned_device_name().c_str());\n```\n", "comments": ["thanks! you could submit a PR and go through the review process.\n", "oops - didn't see your response. sorry. thanks for doing the work @burness.  nice job.\n"]}, {"number": 5235, "title": "ResourceExhaustedError on GPU", "body": "Environment info\n\nOperating System: Ubuntu 16.04\n\nInstalled version of CUDA and cuDNN: CUDA 8.0, cuDNN 5\n\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n\n/usr/local/cuda/lib64/libcudadevrt.a\n/usr/local/cuda/lib64/libcudart.so\n/usr/local/cuda/lib64/libcudart.so.8.0\n/usr/local/cuda/lib64/libcudart.so.8.0.27\n/usr/local/cuda/lib64/libcudart_static.a\n/usr/local/cuda/lib64/libcudnn.so\n/usr/local/cuda/lib64/libcudnn.so.5\n/usr/local/cuda/lib64/libcudnn.so.5.0.5\nIf installed from sources, provide the commit hash:\n2cbb9b529a6723ebbe07663156b18c04fbaf4531\n\nHi All, \nI am able to run the following code on CPU, but when on GPU, I got a `ResourceExhaustedError`, My GPU is an GTX1080 one, which has 8G memeory.\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nsess = tf.Session()\n\ninputs = tf.placeholder(tf.float32, shape=(30,224,224,512))\nwith tf.device('/gpu:0') as d:\n    kernel = tf.Variable(tf.truncated_normal([9,9,512,36], dtype=tf.float32,stddev=1e-1), name='weights')\n    conv = tf.nn.conv2d(inputs, kernel, [1, 1, 1, 1], padding='SAME')\n\ninputs_arr = np.random.random((30,224,224,512)).astype(np.float32)\nsess.run(tf.initialize_variables([kernel]))\ncc = sess.run(conv, feed_dict={inputs: inputs_arr})\n```\n\nError message:\n\n```\n---------------------------------------------------------------------------\nResourceExhaustedError                    Traceback (most recent call last)\n/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n    971     try:\n--> 972       return fn(*args)\n    973     except errors.OpError as e:\n\n/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\n    953                                  feed_dict, fetch_list, target_list,\n--> 954                                  status, run_metadata)\n    955 \n\n/home/xlws/anaconda3/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)\n     65             try:\n---> 66                 next(self.gen)\n     67             except StopIteration:\n\n/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()\n    462           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 463           pywrap_tensorflow.TF_GetCode(status))\n    464   finally:\n\nResourceExhaustedError: OOM when allocating tensor with shape[30,36,224,224]\n     [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_1, weights/read)]]\n     [[Node: Conv2D/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4_Conv2D\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nResourceExhaustedError                    Traceback (most recent call last)\n<ipython-input-1-92fd065a1eed> in <module>()\n     12 inputs_arr = np.random.random((30,224,224,512)).astype(np.float32)\n     13 sess.run(tf.initialize_variables([kernel]))\n---> 14 cc = sess.run(conv, feed_dict={inputs: inputs_arr})\n\n/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    715     try:\n    716       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 717                          run_metadata_ptr)\n    718       if run_metadata:\n    719         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    913     if final_fetches or final_targets:\n    914       results = self._do_run(handle, final_targets, final_fetches,\n--> 915                              feed_dict_string, options, run_metadata)\n    916     else:\n    917       results = []\n\n/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n    963     if handle is None:\n    964       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n--> 965                            target_list, options, run_metadata)\n    966     else:\n    967       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n    983         except KeyError:\n    984           pass\n--> 985       raise type(e)(node_def, op, message)\n    986 \n    987   def _extend_graph(self):\n\nResourceExhaustedError: OOM when allocating tensor with shape[30,36,224,224]\n     [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_1, weights/read)]]\n     [[Node: Conv2D/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4_Conv2D\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Conv2D', defined at:\n  File \"/home/xlws/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/xlws/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-92fd065a1eed>\", line 10, in <module>\n    conv = tf.nn.conv2d(inputs, kernel, [1, 1, 1, 1], padding='SAME')\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 394, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 748, in apply_op\n    op_def=op_def)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2403, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1305, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[30,36,224,224]\n     [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_1, weights/read)]]\n     [[Node: Conv2D/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4_Conv2D\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n```\n", "comments": ["It looks like you ran out of memory. Sadly, there's no easy fix for that. You could try stackoverflow with tag \"tensorflow\" to see what techniques are available.\n", "My GPU got 8G free memory.It should be able to put such a small network.\n", "nvidia-smi gives pretty good summaries, could you debug with that?\n", "Sorry for such a late replay, I was away for a holiday.\nAnyway, its indeed memory issue, closing. Thank you.\n"]}, {"number": 5234, "title": "tensorflow/core/framework/op_kernel.cc:968 Invalid argument: Could not parse example input", "body": "I'm trying to convert images (PNG) to `tf-records` files. When I read `tf-records` files. I saw lots of unreadable code on the screen. Please help to find the problem. I list my problems and code below:\n\nI need to convert a sequence of images (10 PNGs) into a single `tf-records` file. I have several sequences of images and each sequence (10 PNGs) is in a folder. Here is the code I used to convert images to `tf-records`:\n\n```\nimport os, sys\nimport tensorflow as tf\nimport numpy as np\nfrom PIL import Image\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef read():\n    # parent folder contains all sequence, each sequence (10 png) is in a sub-folder \n    parent_foler = sys.argv[1]\n    for folder in os.listdir(parent_foler):\n        images = read_images_from(parent_foler + '/' + folder)\n        num_examples = len(images)\n\n        print 'Number of images: ' + str(num_examples)\n        outputFile = os.path.join(parent_foler, folder + '.tfrecords')\n        writer = tf.python_io.TFRecordWriter(outputFile)\n        fs = {}\n        for index in range(num_examples):\n            image_raw = images[index].tostring()\n            image_name = 'move/' + str(index) + '/image/encoded'\n            fs[image_name] = _bytes_feature(image_raw)\n            print folder + ':' + image_name\n        print 'Size of Features:' + str(len(fs))\n        example = tf.train.Example(features=tf.train.Features(feature=fs))\n        writer.write(example.SerializeToString())\n        writer.close()\n\ndef read_images_from(folder_name):\n    images = []\n    files_to_read = [folder_name + '/' + folder_name.split('/')[-1] + '_' + str(i + 1) + '.png' for i in range(10)]\n    for filename in files_to_read:\n        im = Image.open(filename)\n        im = np.asarray(im, np.uint8)\n        images.append(im)\n    images = np.array(images)\n    print'shape of images: ' + str(images.shape)\n    return images\n\nif __name__ == \"__main__\":\n    read()\n```\n\nHere is the code to read these `tf-records` files: (adapted from [this code](https://github.com/tensorflow/models/blob/master/video_prediction/prediction_input.py))\n\n```\nORIGINAL_WIDTH = 2048\nORIGINAL_HEIGHT = 1536\nCOLOR_CHAN = 4\n\ndef build_tfrecord_input(tf_folder):\n    filenames = [foldername + '/' + tf_file for tf_file in os.listdir(tf_folder)]\n    filename_queue = tf.train.string_input_producer(filenames, shuffle=True)\n    reader = tf.TFRecordReader()\n    _, serialized_example = reader.read(filename_queue)\n    image_seq = []\n\n    # FLAGS.sequence_length = 10\n    for i in range(FLAGS.sequence_length): \n        image_name = 'move/' + str(i) + '/image/encoded'\n        features = {image_name: tf.FixedLenFeature([1], tf.string)}\n        features = tf.parse_single_example(serialized_example, features=features)\n        image = tf.decode_raw(features[image_name], tf.uint8)\n        image = tf.reshape(image, shape=[ORIGINAL_HEIGHT,ORIGINAL_WIDTH,COLOR_CHAN])\n        image.set_shape([ORIGINAL_HEIGHT, ORIGINAL_WIDTH, COLOR_CHAN])\n\n        crop_size = min(ORIGINAL_HEIGHT, ORIGINAL_WIDTH)\n        image = tf.image.resize_image_with_crop_or_pad(image, crop_size, crop_size)\n        image = tf.reshape(image, [1, crop_size, crop_size, COLOR_CHAN])\n        image = tf.image.resize_bicubic(image, [IMG_HEIGHT, IMG_WIDTH])\n        image = tf.cast(image, tf.float32) / 255.0\n        image_seq.append(image)\n\n        image_seq = tf.concat(0, image_seq)\n\n    return image_seq\n```\n\nWhen the training code runs to\n\n```\ntf.train.start_queue_runners(sess)\nsess.run(tf.initialize_all_variables())\n```\n\nI saw unreadable code:\n\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd|\ufffd\ufffd\ufffd|\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd}\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd}\ufffd\ufffd\ufffd}\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd}\ufffd\ufffd~|\ufffd~}{\ufffd~}{\ufffd~}{\ufffd~}{\ufffd~}{\ufffd\ufffd~|\ufffd\ufffd\ufffd}\ufffd\ufffd\ufffd}\ufffd\ufffd\ufffd}\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd|\ufffd\ufffd\ufffd|\ufffd\ufffd\ufffd|\ufffd\ufffd\ufffd|\ufffd\ufffd\ufffd}\ufffd\ufffd\ufffd~\ufffd\ufffd\ufffd}\ufffd\ufffd\ufffd{\ufffd~}y\ufffd}|x\ufffd|{w\ufffd|{w\ufffd}|x\ufffd|{w\ufffd{zv\ufffdzyu\ufffdxws\ufffdwvr\ufffdvuq\ufffdutp\ufffdtso\ufffdtso\ufffdtso\ufffdutp\ufffdtso\ufffdutp\ufffdutp\ufffdutp\ufffdtso\ufffdtso\ufffdutp\ufffdutp\ufffdtso\ufffdutp\ufffdutp\ufffdvuq\ufffdwvr\ufffdxws\ufffdyxt\ufffdzyu\ufffd{zv\ufffd|{w\ufffd}|x\ufffd}|x\ufffd}|x\ufffd}|x\ufffd}|x\ufffd}|x\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}y\ufffd~}x\ufffd\ufffd~y\ufffd\ufffd~w\ufffd\ufffd~w\ufffd\ufffd~w\ufffd\ufffd~w\ufffd\ufffd~w\ufffd\ufffd~w\ufffd\ufffd~w\ufffd\ufffd~w\ufffd\ufffd~w\ufffd\ufffd~W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: Could not parse example input, value: '\n\ufffd\ufffd\ufffd<\n\ufffd\ufffd\ufffd\ufffd\n\ufffdmove/7/image/encoded\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\nCan anyone tell me which part of the code is wrong?\n\nThanks very much in advance,\nAndy.\n", "comments": ["Yes, it's a common error. See:\nhttps://github.com/OliviaMG/xiaomeng/issues/1\n", "@drpngx I didn't see a solution in OliviaMG/xiaomeng#1. Can you please specify it? Thanks a lot. \n", "See https://github.com/tensorflow/models/issues/579 and https://github.com/OliviaMG/xiaomeng/issues/1. The original code is posted in the link in the report, and febert posted the solution.\n", "@drpngx, I'm not sure if this is the proper place to pursue this issue, but I am having the same problem, and after looking at the links you give, I am still confused.  Also, it does seem that there is a kind of bugginess here in that it does not give a sensible error message.  I am not even sure if the file being read is corrupt, but if so, TensorFlow should stop it being written in the first place.\n", "It's not a bug, it's just that the string is the raw image, being binary, is just printed as binary.\n", "@drpngx Thanks. I understand that author offered the original code in  tensorflow/models#579.\n\nBut I saw some code examples very similar to the one I listed (e.g. [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/fully_connected_reader.py)). But It caused the parse problem.\nSo, in the code I listed above, Could you please point out which inappropriate code caused this parse problem? It helps me to avoid this problem in the future.\n\nBtw, Tensorflow didn't raise a standard exception. It may need to be improved. \n\nThanks a lot. \n", "OK, I can take a look later. Please include everything that is needed for a repro.\n", "@drpngx  Thanks a lot! \n\nHere is the code: https://github.com/anjiefang/examplecodes_tensorflow.git\n1. By running `./download_data.sh`, a sample data will be download and save in folder `data`\n2. Convert images to `tf-records`:  `python convert_image.py ./data` (`tf-records` files will be store under `./data/`)\n3. Train the model: `python prediction_train.py --data_dir ./data` (only the `tf-records` files will be read)\n", "In my case, the writing code is:\n\n```\nassert cooked_data.shape == (60000,256,16)\nflattened_data = cooked_data.flatten()\nlistized_data = flattened_data.tolist()\ntf_example = tf.train.Example(\n    features = tf.train.Features(\n        feature = {\n            'data': tf.train.Feature(float_list = tf.train.FloatList(value = listized_data)),\n            'subject_id': tf.train.Feature(int64_list = tf.train.Int64List(value = [subject_id])),\n            'example_id': tf.train.Feature(int64_list = tf.train.Int64List(value = [example_id])),\n            'label': tf.train.Feature(float_list = tf.train.FloatList(value = [label]))\n        }\n    )\n)\nwriter.write(tf_example.SerializeToString())\n```\n\nand the reading code is:\n\n```\nkey, record_string = reader.read(queue)\nfeatures = tf.parse_single_example(\n    record_string,\n    features={\n        'data': tf.FixedLenFeature([60000*256*16], tf.float32),\n        'subject_id': tf.FixedLenFeature([1], tf.int64),\n        'example_id': tf.FixedLenFeature([1], tf.int64),\n        'label': tf.FixedLenFeature([1], tf.float32),\n    }\n)\n```\n\nIs the bug in this code?\n\nAlso, what is the rationale for using a non-self-describing format for tfrecords and also for using a non-standard format?  It seems to me hdf5 or a subset would be better.\n", "In my case, I have  problem same as anjiefang. Would you mind modify the code? @drpngx\n", "Will do.\n", "Wait... you're writing an `Example`, not `SequenceExample`?\n", "@drpngx\nOne sequence contains 10 PNGs stored in a folder (e.g. ./data/backward_1). A single `tf example` records these 10 PNGs and is serializes as a `tf-records` file. Is it what you wanna know?\nThanks.\n", "OK, I'm not 100% sure exactly what you intended to do, use PIL or tensorflow. But you can't decode the image twice. I'm not familiar with image channels but I think the `COLOR_CHAN=3` is the proper index, numbered from zero. If you feed the raw png bytes (just `open(filename, 'r') as f; im = f.read()` in the `convert_image.py`, then you'll decode with tensorflow (`prediction_input.py` has decode_png). It should get you going.\n\nWe should be getting easier error messages on parse errors, stay tuned for that.\n", "BTW, you should not import modules directly. For instance, use `tf.app` instead of `from .. import app`.\n", "@drpngx Either PIL or tensorflow is chosen in function `convert_to_image_per_folder` or `read_images_from` to decode PNGs string to `uint8` format. In function `read()`, `uint8` is converted to string again (`images[index].tostring()`) before serialization (`writer.write(example.SerializeToString())`). \n\nI used the way you suggested (`pen(filename, 'r') as f; im = f.read()`in `convert_image.py`). The parse problem is solved. Thanks a lot.\nI think your given solution is equivalent as my previous code, i.e. images string is used for serialization (`writer.write(example.SerializeToString())` in `convert_image.py`). So I'm still not quite sure why my previous code had parse problem. :-(\n\n> BTW, you should not import modules directly. For instance, use `tf.app` instead of `from .. import app.`\n\nThanks for your suggestion. We will improve our writing style in the future.\n\nThe updated code is committed to https://github.com/anjiefang/examplecodes_tensorflow.git @OliviaMG @greaber \n", "It might have been the `COLOR_CHAN`. Only indices `0` through `3` are allowed. It might have generated a parse error. Anyway, glad to see you figured it out!\n"]}, {"number": 5233, "title": "Better ARRAYSIZE macro for tensorflow/stream_executor/platform/port.h", "body": "taken from https://chromium.googlesource.com/chromium/chromium/+/master/base/basictypes.h#104\n", "comments": ["@j123123, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @josh11b and @vrv to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Can one of the admins verify this patch?\n", "I think I don't need to sign anything to contribute such small fix. Consider to do something like this https://github.com/dotnet/llilc/pull/1066#issuecomment-253989879 with your googlebot (to not sign anything if contribution is small enough)\n", "j123123@, I don't think we can merge any PR without CLA. \n\nmartinwicke@, could you confirm that a CLA is absolutely necessary? \n", "If you can't merge, close this PR and create a new same PR. This macro is in google chromium source, so I don't see any legal issue with it\n", "Yup, we can't merge without CLA. Sorry.\n"]}, {"number": 5232, "title": "added python tools to pip_package rules", "body": "for issue #5014\n", "comments": ["Can one of the admins verify this patch?\n", "@kashif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @meteorcloudy, @keveman and @vrv to be potential reviewers.\n", "@tensorflow-jenkins test this please\n", "Known flakiness, and infra failure.  This change doesn't affect Android so merging.\n"]}, {"number": 5231, "title": "[FEATURE REQUEST] More than 2D matmul", "body": "Hello!\nI just would like to know if high dimensional matmul will be supported in the future?\nFor example, I have a 3D tensor a and a matrix b as below:\n\n``` python\na = [[[1,1],\n         [1,1]],\n        [[2,2],\n         [2,2]]]\nb = [[1,1], [1,1]]\n```\n\nIn numpy, np.dot(a, b) will return\n\n``` python\n[[[2,2],\n   [2,2]],\n  [[4,4],\n    [4,4]]]\n```\n\nBut in tensorflow tf.matmul only supports 2D \\* 2D.\n\nActually using tf.conv2d and reshaping can do the same thing,  it would be more natural that tf.matmul could do as well. And such operators frequently occurr in NLP tasks like attention or memory network.\n\nForgive my offense and really thanks for any help\n", "comments": ["@rmlarsen for any additional thoughts.  It seems like a reasonable idea.\n", "@aselle on numpy parity.\n", "Note also `tf.batch_matmul`, which handle some of this (I think the plan is to eventually consolidate all cases into `tf.matmul`).\n", "The general form of this is called tensor contraction. The underlying Eigen library supports this, but the functionality is not currently exposed by TensorFlow (ironically, given the name). It is also possible to implement tensor contraction as a sequences of transpose->reshape->matmul->reshape->transpose ops, which can be quite efficient. We have such an implementation of this approach as well, but some work is needed on the shape inference part, but I think we should try to include it in the open source version.\n", "Update: The code is out for review. I expect it to land sometime next week.\n", "Got sidetracked (and asked to implement this as 'tensordot' instead) so still working on it. Getting close, though...", "The code was submitted and should be pushed to github within a few days. We settled on the op name \"tf.tensordot\" for numpy compatibility."]}, {"number": 5230, "title": "Cannot compile library  for iOS. Please see attached issues with compiling protobuf. ", "body": "checking whether the C compiler works... yes\nchecking for C compiler default output file name... a.out\nchecking for suffix of executables...\nchecking whether we are cross compiling... configure: error: in `/Users/arpit/Desktop/tensorflow-master/tensorflow/contrib/makefile/downloads/protobuf':\nconfigure: error: cannot run C compiled programs.\nIf you meant to cross compile, use`--host'.\nSee `config.log' for more details\n", "comments": ["do you have any more info about system? Please fill out whatever you can from the template.\n", "Automatically closing due to lack of recent activity, we will reopen if further information becomes available. Thanks!\n"]}, {"number": 5229, "title": "reimplement viterbi decoding in tensorflow way", "body": "The original viterbi decoding in `tensorflow.contrib.crf` is implemented in numpy way and can only be used in testing. This update reimplement viterbi decoding in tensorflow style, can provide more flexibility during model building.\n", "comments": ["Can one of the admins verify this patch?\n", "@jungle-cat, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener and @drpngx to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "this implementation contain some import issues to be resolved.\n"]}, {"number": 5228, "title": "Poor VGG performance in slim.", "body": "Hello,\n\nI have been following the slim tutorial:\nhttps://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb\n\nAnd decided to replace the Inception model v1 that is used in the example with VGG model\nfrom tensorflow. I took it from here:\nhttps://github.com/tensorflow/models/tree/master/slim#pre-trained-models\n\nI have changed the code to work with VGG, but I got a considerably worse accuracy\neven on simple images for VGG, while it works perfectly for Inception v1. Even though the\nreported accuracy for VGG and Inception v1 are more or less equal in the imagenet.\n\nI don't know if there is a bug in my code or the model is bad.\n\nHere is the code that I have used:\n\n```\n%matplotlib inline\n\nfrom matplotlib import pyplot as plt\n\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport urllib2\n\nfrom datasets import imagenet\nfrom nets import vgg\nfrom preprocessing import vgg_preprocessing\n\nslim = tf.contrib.slim\n\nimage_size = vgg.vgg_19.default_image_size\n\ncheckpoints_dir = '/tmp/checkpoints'\n\n\n\nwith tf.Graph().as_default():\n    url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\n    url = 'https://upload.wikimedia.org/wikipedia/commons/d/d9/First_Student_IC_school_bus_202076.jpg'\n    image_string = urllib2.urlopen(url).read()\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    processed_image = vgg_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\n    processed_images  = tf.expand_dims(processed_image, 0)\n\n    # Create the model, use the default arg scope to configure the batch norm parameters.\n    with slim.arg_scope(vgg.vgg_arg_scope()):\n        logits, _ = vgg.vgg_19(processed_images, num_classes=1000, is_training=False)\n    probabilities = tf.nn.softmax(logits)\n\n    init_fn = slim.assign_from_checkpoint_fn(\n        os.path.join(checkpoints_dir, 'vgg_19.ckpt'),\n        slim.get_model_variables('vgg_19'))\n\n    with tf.Session() as sess:\n        init_fn(sess)\n        np_image, probabilities = sess.run([image, probabilities])\n        probabilities = probabilities[0, 0:]\n        sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), key=lambda x:x[1])]\n\n    plt.figure()\n    plt.imshow(np_image.astype(np.uint8))\n    plt.axis('off')\n    plt.show()\n\n\n    names = imagenet.create_readable_names_for_imagenet_labels()\n    for i in range(5):\n        index = sorted_inds[i]\n        print('Probability %0.2f%% => [%s]' % (probabilities[index], names[index]))\n\n```\n", "comments": ["The issue was because for Resnet and VGG models the classes are shifted by 1.\nSo, inception has 1000 classes and one more for background while Resnet and VGG don't,\nso the shift is needed.\n\nMore information can be found here: https://github.com/tensorflow/models/tree/master/slim#pre-trained-models\n\nI think it makes sense to update the ipython notebook with a specific example for Resnet or VGG.\n"]}, {"number": 5227, "title": "Fix: For mac non-docker GPU builds fix handling of test concurrency. \u2026", "body": "\u2026(#5218)\n", "comments": ["@gunan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @tensorflower-gardener and @ebrevdo to be potential reviewers.\n", "All tests except windows passing.\nMerging.\n"]}, {"number": 5226, "title": "R0.11", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@vhtrivedi, thanks for your PR! By analyzing the history of the files in this pull request, we identified @yifeif, @caisq and @gunan to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 5225, "title": "Shape must be rank 0 but is rank 1, Potential issue with parse_single_sequence_example", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nSpent quite some time digging around didn't come up with anything from stack overflow or other issues that landed near my issues. I also debugged the stack trace all the way down into where it jumps out of python and didn't come up with anything particularly useful.  \n### Environment info\n\nOperating System:\nUbuntu 16.04 64bit\n\nInstalled version of CUDA and cuDNN: 8 and 5\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n-rw-r--r-- 1 root root 558720 Sep 14 19:02 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Sep 14 19:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root     19 Sep 14 19:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rw-r--r-- 1 root root 415432 Sep 14 19:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root 775162 Sep 14 19:02 /usr/local/cuda/lib64/libcudart_static.a\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python3 -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\n0.11.0rc1\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\n```\nimport tensorflow as tf\nimport tempfile\nfrom IPython import embed\n\nsequences = [[1, 2, 3], [4, 5, 1], [1, 2]]\nlabel_sequences = [[0, 1, 0], [1, 0, 0], [1, 1]]\n\ndef make_example(sequence, labels):\n\n    ex = tf.train.SequenceExample()\n\n    sequence_length = len(sequence)\n    ex.context.feature[\"length\"].int64_list.value.append(sequence_length)\n\n    fl_tokens = ex.feature_lists.feature_list[\"tokens\"]\n    fl_labels = ex.feature_lists.feature_list[\"labels\"]\n    for token, label in zip(sequence, labels):\n        fl_tokens.feature.add().int64_list.value.append(token)\n        fl_labels.feature.add().int64_list.value.append(label)\n    return ex\n\n\nwriter = tf.python_io.TFRecordWriter('./test.tfrecords')\nfor sequence, label_sequence in zip(sequences, label_sequences):\n    ex = make_example(sequence, label_sequence)\n    writer.write(ex.SerializeToString())\nwriter.close()\n\ntf.reset_default_graph()\n\nfile_name_queue = tf.train.string_input_producer(['./test.tfrecords'], num_epochs=None)\n\nreader = tf.TFRecordReader()\n\n\n\ncontext_features = {\n    \"length\": tf.FixedLenFeature([], dtype=tf.int64)\n}\nsequence_features = {\n    \"tokens\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n    \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n}\n\nex = reader.read(file_name_queue)\n\n# Parse the example (returns a dictionary of tensors)\ncontext_parsed, sequence_parsed = tf.parse_single_sequence_example(\n    serialized=ex,\n    context_features=context_features,\n    sequence_features=sequence_features\n)\n\n\ncontext = tf.contrib.learn.run_n(context_parsed, n=1, feed_dict=None)\nprint(context[0])\nsequence = tf.contrib.learn.run_n(sequence_parsed, n=1, feed_dict=None)\nprint(sequence[0])\n\n```\n### What other attempted solutions have you tried?\n\nThis was the quickest reproduction I could put together using some sample code from the web with a few tweaks. Initially I was trying to do this on a more serious problem with an entirely different dataset/proto, but same issue. I've considered skipping this and using some other file format. However, I think the binary format will be best.  \n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 594, in call_cpp_shape_fn\n    status)\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in **exit**\n    next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors.py\", line 463, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors.InvalidArgumentError: Shape must be rank 0 but is rank 1\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"my_test.py\", line 51, in <module>\n    sequence_features=sequence_features\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py\", line 640, in parse_single_sequence_example\n    feature_list_dense_defaults, example_name, name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/parsing_ops.py\", line 837, in _parse_single_sequence_example_raw\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 285, in _parse_single_sequence_example\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2382, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1783, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 596, in call_cpp_shape_fn\n    raise ValueError(err.message)\nValueError: Shape must be rank 0 but is rank 1\n", "comments": ["It looks like a usage issue. Could you crosspost on stackoverflow with tag \"tensorflow\"?\n", "Yup will do\n", "[Cross listed stackoverflow question](http://stackoverflow.com/questions/40275774/shape-must-be-rank-0-but-is-rank-1-parse-single-sequence-example)\n", "Got it and it was a bad assumption on my part, tf.TFRecordReader.read(queue, name=None) returns a tuple when I assumed it would have returned just the value not (key,value) which I was directly passing into the example parser. :P Please mark this solved/closed. \n", "Great to see that you found the answer!\n"]}, {"number": 5224, "title": "Branch 137329621", "body": "Merging internal changes. \n", "comments": ["@zheng-xq, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener and @terrytangyuan to be potential reviewers.\n", "@tensorflow-jenkins, test this please. \n"]}, {"number": 5223, "title": "dynamic_RNN fails on mac with unspecified batch_Size", "body": "tl;dr:\ndynamic_rnn fails on OS X with unspecified batch_size but works fine on Ubuntu 14.04/Python3.4.3.  It seems that on OS X the 'None != \"?\"' evaluates poorly, then at some point in ops/rnn.py +918 this equality fails:\n if const_batch_size != got_batch_size:\n(i.e. None != Dimension(\"?\"))\n\nMy best guess is that Dimension(\"?\") is hacked in such a way that any comparison using it returns some fake None which for some reason on OSX + python 3.4 means true (I tried explicitly \"if None:\" as a sanity check, it evaluates as false).  For now I've modified the offending code to be: \nif const_batch_size != got_batch_size:\n      if  (const_batch_size != got_batch_size) == got_batch_size or (const_batch_size != got_batch_size) == const_batch_size:\n            print(\"weird dimensions stuff in ops/rnn.py, what the shit python?\")\n            continue\n      raise ValueError(\n          \"Batch_size is not the same for all the elements in the input.\")\n\nThis\n### Environment info\n\nOperating System:\nOS X 10.12\nPython 3.4.1\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nN/A (CPU version)\n\nIf installed from binary pip package, provide:\n0.11.0rc1 (just installed wheel)\nalso fails on 0.10.0rc1, 0.10.0 (though it works on 0.10.0 on Linux)\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code).  It may work with less but this was a simpl\n\nimport tensorflow as tf\n\ninput_size = 256\nlength = 100\nnum_classes = 64\n\ndata = tf.placeholder(tf.float32, [None, length, input_size])\ntarget = tf.placeholder(tf.float32, [None, length, num_classes])\n\nmax_length = int(target.get_shape()[1])\nnum_classes = int(target.get_shape()[2])\n\nnetwork = tf.nn.rnn_cell.GRUCell(200)\noutput, new_state = tf.nn.dynamic_rnn(network, data, dtype=tf.float32)\n### What other attempted solutions have you tried?\n\nWorks fine on my Linux box with or without GPU\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\nTraceback (most recent call last):\n  File \"<my_directory>/tensorflow_mac_fail_test.py\", line 18, in <module>\n    output, new_state = tf.nn.dynamic_rnn(network, data, dtype=tf.float32)\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py\", line 836, in dynamic_rnn\n    dtype=dtype)\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py\", line 920, in _dynamic_rnn_loop\n    \"Batch_size is not the same for all the elements in the input.\")\nValueError: Batch_size is not the same for all the elements in the input.\n", "comments": ["It looks like you pretty much know what the problem is. Do you have a idea for a fix you could send?\n", "we could replace the existing comparison with:\nif const_batch_size != got_batch_size and not (const_batch_size == got_batch_size) == None:\n\n(if the dimensions aren't equal but also neither are unspecified) but it seems quite awkward.  I feel like a cleaner solution might be ensuring that None != Dimension(\"?\") evaluates to false instead of \nNone ==Dimension (\"?\")  => None, and the negation becomes true.\n\nEdit: If that change was made I would definitely advise putting a comment explaining the purpose, because it seems quite weird otherwise).\n", "@vrv possibly for any additional insight\n", "The fix seems reasonable to me, perhaps send a PR if you have one.\n", "created patch https://github.com/tensorflow/tensorflow/compare/master...pfaucon:patch-1\n", "Thanks! Feel free to send the PR.\n"]}, {"number": 5222, "title": "what is the feature layer of inception v1 model", "body": "As show in **classify_image.py** for inception v3 model, the feature layer is **pool_3:0**\n\n```\n# 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n#   float description of the image.\n```\n\nI print out the nodes of inception v1 model .pb file as below. I guess the feature layer is **avgpool0/reshape**, is that right? \n\ninput\nconv2d0_w\nconv2d0_b\nconv2d1_w\nconv2d1_b\nconv2d2_w\nconv2d2_b\n... \n...\n...\n...\nmixed5b/concat_dim\nmixed5b\n**avgpool0**\nhead0_pool\nhead0_bottleneck_pre_relu/conv\nhead0_bottleneck_pre_relu\nhead0_bottleneck\nhead0_bottleneck/reshape/shape\nhead0_bottleneck/reshape\nnn0_pre_relu/matmul\nnn0_pre_relu\nnn0\nnn0/reshape/shape\nnn0/reshape\nsoftmax0_pre_activation/matmul\nsoftmax0_pre_activation\nsoftmax0\nhead1_pool\nhead1_bottleneck_pre_relu/conv\nhead1_bottleneck_pre_relu\nhead1_bottleneck\nhead1_bottleneck/reshape/shape\nhead1_bottleneck/reshape\nnn1_pre_relu/matmul\nnn1_pre_relu\nnn1\nnn1/reshape/shape\nnn1/reshape\nsoftmax1_pre_activation/matmul\nsoftmax1_pre_activation\nsoftmax1\navgpool0/reshape/shape\n**avgpool0/reshape**\nsoftmax2_pre_activation/matmul\nsoftmax2_pre_activation\nsoftmax2\noutput\noutput1\noutput2\n", "comments": ["Hi, do you want to try stackoverflow (with tag \"tensorflow\")? \n", "OK\n", "Thanks!\n", "yes, It is correct. **avgpool0/reshape** is the feature layer. I test it in my local.\n", "OK, thanks for looping back.\n", "@civilmanxx have you managed to retrain the inception v1 model?\n\nI am currently trying to reshape the script retrain.py to retrain inception v1 model.\n\nWhere did you get the nodes above? I also tried to print them out in order to modify parameters BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME, and RESIZED_INPUT_TENSOR_NAME and got the following:\n\n```\n['input']\n['conv2d0_w']\n['input', '0']\n['conv2d0_w', '0']\n['conv2d0_pre_relu/conv']\n['conv2d0_b']\n['conv2d0_pre_relu/conv', '0']\n['conv2d0_b', '0']\n['conv2d0_pre_relu']\n['conv2d0_pre_relu', '0']\n['conv2d0']\n['conv2d0', '0']\n['maxpool0']\n['maxpool0', '0']\n...\n...\n...\n['softmax2_w']\n['avgpool0/reshape', '0']\n['softmax2_w', '0']\n['softmax2_pre_activation/matmul']\n['softmax2_b']\n['softmax2_pre_activation/matmul', '0']\n['softmax2_b', '0']\n['softmax2_pre_activation']\n['softmax2_pre_activation', '0']\n['softmax0']\n['softmax0', '0']\n['softmax1']\n['softmax1', '0']\n['softmax2']\n['softmax2', '0']\n['pool_3/_reshape', '0']\n```\n", "please use the code below in python to print out all the tensor names\n\n```\nfor tensor in tf.get_default_graph().as_graph_def().node:\n    print(tensor.name)\n```\n"]}, {"number": 5221, "title": "tf.nn.softmax on GPU causes CUDA_ERROR_ILLEGAL_ADDRESS (okay on CPU)", "body": "CentOS 7\nTensorflow 0.10.0\nTITAN X (Pascal) 367.44\n\nI restore a model previously saved with `tf.train.Saver()` and try to compute probabilities of outputs for a given input batch. Whenever I try to execute `tf.nn.softmax` on GPU, I get an error:\n\n```\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS :: No stack trace available\nF tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\n```\n\nbut same computations work just fine on CPU:\n\n```\nprint('run 1: logits')\nlogits = s.run(model.other.logits_labl, tf_run_args)\nprint(logits.shape) # (1001, 289)\nprint(np.max(logits), np.min(logits)) # 1.80996 -0.752239\n\nprint('run 2: probs in np')\nprobs = s.run(tf.nn.softmax(logits))\nprint(probs.shape) # (1001, 289)\nprint(np.sum(probs, axis=1)) # [ 1.   ...  1.00000012  1.          1.00000012]\n\nprint('run 3: probs on cpu')\nwith tf.device('/cpu:0'):\n    t = tf.nn.softmax(model.other.logits_labl)\nprint(s.run(t, tf_run_args)) # okay\n\nprint('run 4: probs on gpu')\nwith tf.device('/gpu:0'):\n    t2 = tf.nn.softmax(model.other.logits_labl)\nprint(s.run(t2, tf_run_args)) # error\n```\n\nproduces\n\n```\nrun 1: logits\n(1001, 289)\n1.80996 -0.752239\nrun 2: probs in np\n(1001, 289)\n[ 1.          0.99999994  1.         ...,  1.00000012  1.          1.00000012]\nrun 3: probs on cpu\n[[ 0.00353091  0.0032969   0.00355321 ...,  0.00368173  0.00337926\n   0.00326502]\n [ 0.00343715  0.00313538  0.00379693 ...,  0.00426536  0.0032676\n   0.0031463 ]\n [ 0.00346572  0.00300998  0.00389543 ...,  0.00458091  0.0031747\n   0.0030867 ]\n ...,\n [ 0.0035709   0.00302548  0.00384262 ...,  0.0042819   0.00318443\n   0.00299288]\n [ 0.00353101  0.00305104  0.00379521 ...,  0.00428836  0.0031993\n   0.0029559 ]\n [ 0.00352879  0.00302152  0.00380528 ...,  0.0043787   0.00318416\n   0.00294856]]\nrun 4: probs on gpu\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS :: No stack trace available\nF tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\nAborted\n```\n\n`gdb` does not give any additional details\n\n```\n... same as above\n[New Thread 0x7fff41ffb700 (LWP 26404)]\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS :: No stack trace available\nE tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\nF tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed\nF tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1\n\nProgram received signal SIGABRT, Aborted.\n[Switching to Thread 0x7fff5effd700 (LWP 26391)]\n0x00007ffff6a315f7 in raise () from /lib64/libc.so.6\nMissing separate debuginfos, use: debuginfo-install libX11-1.6.3-2.el7.x86_64 libXau-1.0.8-2.1.el7.x86_64 libXdmcp-1.1.1-6.1.el7.x86_64 libuuid-2.23.2-26.el7_2.3.x86_64\n```\n\nSurprisingly, this error occurred just recently. I have been working with this same codebase for months and before now nothing like this happened, but now it is 100% reproducible on my machine with this specific (code, driver version, etc), so it is not something that effects everyone, but rather pops up randomly. I might have changed operation device placement recently.\n\ncode (unfortunately, large piece of code that required certain data; failed to produce a minimal reproducing code): [[link]](https://gist.github.com/MInner/4faa684a1d0d7eac6fafb9d6b08adfc3)\n\nfull gdb output (without prints): [[link]](http://pastebin.com/q7ftuZcp)\n\nenvironment:\n\n```\n$ ls -l /usr/lib/libcu*\nlrwxrwxrwx. 1 root root      12 Oct  3 15:36 /usr/lib/libcuda.so -> libcuda.so.1\nlrwxrwxrwx. 1 root root      17 Oct  3 15:36 /usr/lib/libcuda.so.1 -> libcuda.so.367.44\n-rwxr-xr-x. 1 root root 7747600 Oct  3 15:36 /usr/lib/libcuda.so.367.44\n$ ls -l /usr/local/cuda/lib64/\nlrwxrwxrwx. 1 1000 users       13 Jul 27 01:55 libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx. 1 1000 users       17 Jul 27 01:55 libcudnn.so.5 -> libcudnn.so.5.1.5\n-rwxrwxr-x. 1 1000 users 79337624 Jul 27 01:53 libcudnn.so.5.1.5\n-rw-rw-r--. 1 1000 users 69756172 Jul 27 01:53 libcudnn_static.a\n```\n\nPossibly related issues: #2117 #1450 #2810 #665 #1060 #4425\n", "comments": ["Could you help narrowing down the error with `cuda-memcheck` from nvidia?\n\nTo make it more easier to trace, probably setting `CUDA_LAUNCH_BLOCK=1` and run with `--brain_gpu_sync_every_op`.\n", "@drpngx [memcheck](http://pastebin.com/KYV8rDwf) with CUDA_LAUNCH_BLOCK=1 . Do I have to re-build tensorflow from source to set `--brain_gpu_sync_every_op` or there's an easier way?\n", "Woops, you're right. It looks like you have to tweak `gpu_device_factory.cc`, but from the trace it's clear that it's in the eigen `ReduceInitKernel`, in the dense softmax.\n\n@zheng-xq for any additional insight. We don't have access to the data, but we have access to the source code. If that's an actual bug in tensorflow, it would be great to get to the bottom of this.\n", "To sync after each op, you'll have to build from source by modifying this line. \n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_device_factory.cc#L34\n\nIf you still have this problem with the latest driver, then we will need to know which kernel causes this problem. Combining that with memcheck and CUDA_LAUNCH_BLOCK=1 tends to give the best answer. \n", "@zheng-xq the memcheck above says it's in `ReduceInitKernel` from the eigen softmax. I wonder if there are diagnostics we could print (dimensions etc) of buffers vs expected op input\n", "here's the [tf-related part](https://gist.github.com/MInner/af316efe081dba2fc219391e12aa24ed) of the code above, if that is be helpful to understand device placement\n", "Would it be possible for you to create a repro that we could try locally?\n", "If you had a build with debug on, then we might be able to see what the intermediate stack frames are. `ReductionInitKernel` appears to have been passed `nullptr` + offset (maybe 300 or so), so it's pulled from a struct which has about 300 bytes worth of stuff before the output, and that struct instance pointer is nullptr, presumably.\n", "@benoitsteiner if you're interested.\n", "@MInner Can you try with the release candidate for 0.11 ? There was a bug in 0.10 that could explain your CUDA_ERROR_ILLEGAL_ADDRESS error and has been fixed since.\n", "@benoitsteiner Which commit fixed this bug? I encountered a same error in tensorflow 1.0.0 and try to reproduce it now.", "I also still encounter this problem when use large enough models with [`google/seq2seq`](https://github.com/google/seq2seq) during evaluation on same hardware as mentioned in the topic heading.", "@MInner to be clear, you are getting `CUDA_ERROR_ILLEGAL_ADDRESS`?", "@drpngx yes, and other random errors like shape mismatch in the middle of training; people in `seq2seq` issue tracker (referenced above) suggest that this might be related to race condition during concurrent training and evaluation in `contrib.learn.experiment.train_and_evaluate`. I also sometimes observe weird errors (not related to memory allocation) if I try running two processes concurrently even on different GPUs, and often if I run two processes on same GPU.", "Please link to issue on seq2seq\n\nOn Apr 13, 2017 7:45 AM, \"Ben Usman\" <notifications@github.com> wrote:\n\n> @drpngx <https://github.com/drpngx> yes, and other random errors like\n> shape mismatch in the middle of training; people in seq2seq issue tracker\n> (referenced above) suggest that this might be related to race condition\n> during concurrent training and evaluation in contrib.learn.experiment.\n> train_and_evaluate.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5221#issuecomment-293915757>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_Sbbomikr2D_5AN2rwEKTxqtJbBbTKks5rvjTvgaJpZM4Khtms>\n> .\n>\n", "I meant [this](https://github.com/google/seq2seq/issues/103#issuecomment-293796457) comment.", "Thanks! Closing this one in favor of the other one, so that we just have place to track.", "Have you figured it out?\r\n"]}, {"number": 5220, "title": "go", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\n\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n### What other attempted solutions have you tried?\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n", "comments": ["Could you fill in the template?\n", "Something went wrong in the process. Please file again.\n"]}, {"number": 5219, "title": "Branch 137307610", "body": "Merge resolution:\n- `tensorflow/core/framework/allocator.h`: (RequestedSize changed for windows (PR 5071)\n- `tensorflow/tensorboard/backend/server.py`: use `io_wrapper` (136889282) and PR 5035 (path prefix check)\n", "comments": ["@drpngx, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener and @terrytangyuan to be potential reviewers.\n", "One of the commits (CLs) introduced the mac failure (not sure which). IMO, we should fix the mac issue before pushing.\n", "After some investigation, I've narrowed it down to: CL/137211288 (https://github.com/tensorflow/tensorflow/pull/5219/commits/fad20053a9d33f1427a7c48100a8b2aef7e7f675). @keveman for any thoughts?\n", "Thanks for finding out! I have a fix for the windows stuff.\n", "Link to [log of the mac failure](https://ci.tensorflow.org/job/tensorflow-pull-requests-mac/2432/consoleFull).\n"]}, {"number": 5218, "title": "Fix: For mac non-docker GPU builds fix handling of test concurrency.", "body": "@mrry This should fix mac-gpu tests.\n@yifeif, let me test this. After that we should also cherrypick this into r0.11.\n\n@caisq I keep messing up this change, please feel free to point out any problems or concerns you see.\n", "comments": ["@gunan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @tensorflower-gardener and @ebrevdo to be potential reviewers.\n", "http://ci.tensorflow.org/job/tensorflow-pull-requests-mac-gpu/2/\n\nLet's see if this one can execute the tests correctly.\n", "LGTM\n", "To make sure if the cpu issue is a flake or not,\nJenkins, test this please.\n"]}, {"number": 5217, "title": "Add a GCS test to create a file and list it.", "body": "", "comments": ["@anand-c-goog, thanks for your PR! By analyzing the history of the files in this pull request, we identified @caisq to be a potential reviewer.\n", "Can one of the admins verify this patch?\n", "@tensorflow-jenkins  test this please.\n", "@anand-c-goog please squash the commits.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 5216, "title": "sparse tensor.shape method returns a tensor object  ", "body": "sparse tensor.shape method returns a tensor object which seems to be of no use to extract the actual shape of the sparse tensor without resorting to run function.\n\nTo clarify what I mean, first consider a sparse tensor:\n\n a = tf.SparseTensor(indices=[[0, 0, 0], [1, 2, 1]], values=[1.0+2j, 2.0], shape=[3, 4, 2])\n\na.shape returns:\n\n tf.Tensor 'SparseTensor_1/shape:0' shape=(3,) dtype=int64\n\nThis is kind of no use. \n\nNow, consider a dense tensor:\n\na = tf.constant(np.random.normal(0.0, 1.0, (4, 4)).astype(dtype=np.complex128))\n\na.get_shape() returns:\nTensorShape([Dimension(4), Dimension(4)])\n\nI can use this output and cast it into a list or tuple of integers without ever invoking run(). However, I cannot do the same for sparse tensor, unless I first convert sparse tensor to dense (which is _not_ implemented for complex sparse tensor yet) and then call get_shape() method on it, but this is kind of  redundant, defeats the purpose of using a sparse tensor in the first place and also leads to error down the road if the input sparse tensor is complex.\n\nIs there a way to obtain the shape of a sparse tensor without invoking run() or converting it to a dense tensor first?\n", "comments": ["Could you post on stackoverflow with tag \"tensorflow\"? We can continue the discussion there.\n", "posted it on stackoverflow as well. Sorry, I should have posted there directly, but thought this was related to feature request/enhancement, so posted it here. Thanks.\n", "Good point. Let's see what you get on stackoverflow first. If you don't get a pull there, let's continue here.\n", "No reply on stackoverflow yet. Any thoughts?\n", "`a.shape` is a Tensor representing the shape that was passed to SparseTensor's constructor.\n\nSo `tf.contrib.util.constant_value(a.shape)`   should give the numpy array corresponding to the shape of the sparse tensor:\n\n```\n  a = tf.SparseTensor(indices=[[0, 0, 0], [1, 2, 1]], values=[1.0+2j, 2.0], shape=[3, 4, 2])\n  print(tf.contrib.util.constant_value(a.shape))\n  print(type(tf.contrib.util.constant_value(a.shape)))\n\n```\n\nOutputs:\n\n```\n[3 4 2]\n<type 'numpy.ndarray'>\n```\n", "@amrit-poudel if you could cross-post the answer to stackoverflow, that would be great. Thanks!\n"]}, {"number": 5215, "title": "Fix test_tutorial failure due to d9d7fa", "body": "See https://github.com/tensorflow/tensorflow/commit/d9d7fa28a069eb34c829c1a0d4221e73a7677d5a\n\nSee tutorial test failure example at: http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/269/console\n", "comments": ["@caisq, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ebrevdo and @ilblackdragon to be potential reviewers.\n"]}, {"number": 5214, "title": "Unable to run \"bazel build tensorflow/examples/image_retraining:retrain", "body": "Hello! I was running the tensorflow example to retrain, and I got this error.\n\n/Users/student/Downloads/tf/tensorflow/core/BUILD:1030:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /Users/student/Downloads/tf/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\nERROR: /Users/student/Downloads/tf/tensorflow/core/BUILD:1030:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /Users/student/Downloads/tf/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\nERROR: /Users/student/Downloads/tf/tensorflow/core/BUILD:1030:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /Users/student/Downloads/tf/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\nERROR: Analysis of target '//tensorflow/examples/image_retraining:retrain' failed; build aborted.\nINFO: Elapsed time: 1.020s\n\nDoes anyone know what I am doing wrong?\n", "comments": ["Could it possibly be that you have an incomplete working copy of tensorflow?\n", "I downloaded tensorflow from [https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow), and then immediately followed the instructions of the tutorial at [https://www.tensorflow.org/versions/r0.11/how_tos/image_retraining/index.html](https://www.tensorflow.org/versions/r0.11/how_tos/image_retraining/index.html).\n", "Just to be clear, you ran configure?\n", "I ran configure, and now it's working. \n\nThank you very much!\n", "Hello, i met the same problem with you. I followed the installation instruction of the pip install way, so the tensorflow is located in usr/local/lib and no configure file available. Can you show me your solution on this in detail? @QuantumTCode @drpngx ", "I ran `./configure` in terminal of the main tensorflow directory.", "\r\nHi, I've the same problem with the installation, but when I'm trying to run './configure' in Ubuntu terminal I'm getting \"./configure: No such file or directory\". @QuantumTCode \r\n", "you have to run that from the main tensorflow directory, as pointed out above. If you don't have it, then you have an incomplete version of the code.", "@drpngx  I've installed tensorflow-0.12.1 in windows as described [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md) with the command `pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.1-cp35-cp35m-win_amd64.whl`.\r\nAfter the installation is complete, I can't find the configure file in \r\nC:\\Program Files\\Anaconda3\\Lib\\site-packages\\tensorflow.\r\n\r\nBelow is the package information I'm getting from pip.\r\n\r\n```\r\n> C:\\WINDOWS\\system32>pip show tensorflow\r\n> Name: tensorflow\r\n> Version: 0.12.1\r\n> Summary: TensorFlow helps the tensors flow\r\n> Home-page: http://tensorflow.org/\r\n> Author: Google Inc.\r\n> Author-email: opensource@google.com\r\n> License: Apache 2.0\r\n> Location: c:\\program files\\anaconda3\\lib\\site-packages\r\n> Requires: numpy, wheel, protobuf, six\r\n```", "This is a binary release, you need to build from source\n\nOn Jan 15, 2017 2:12 AM, \"gitDawn\" <notifications@github.com> wrote:\n\n> @drpngx <https://github.com/drpngx> I've installed tensorflow-0.12.1 in\n> windows as described here\n> <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md>\n> .\n> After the installation is complete, I can't find the configure file in\n> C:\\Program Files\\Anaconda3\\Lib\\site-packages\\tensorflow.\n>\n> Below is the package information I'm getting from pip.\n>\n> > C:\\WINDOWS\\system32>pip show tensorflow\n> > Name: tensorflow\n> > Version: 0.12.1\n> > Summary: TensorFlow helps the tensors flow\n> > Home-page: http://tensorflow.org/\n> > Author: Google Inc.\n> > Author-email: opensource@google.com\n> > License: Apache 2.0\n> > Location: c:\\program files\\anaconda3\\lib\\site-packages\n> > Requires: numpy, wheel, protobuf, six\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5214#issuecomment-272685702>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbUbrP2krCmuSh0kfjkRmrmY51xJdks5rSfEIgaJpZM4KhMtp>\n> .\n>\n", "Can you please provide how you filled the configure file?", "when promped to input I actually just did where python 2.7 was installed and it worked..."]}]