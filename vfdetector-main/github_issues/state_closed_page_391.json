[{"number": 42238, "title": "tf.ones returns zeroes in tf-nightly 2.4.0-dev20200811", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit\r\n- TensorFlow installed from (source or binary): binary \r\n- TensorFlow version (use command below): 2.4.0-dev20200811\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: 10.1.243\r\n- GPU model and memory: Nvidia GeForce 960M Notebooks\r\n\r\n**Describe the current behavior**\r\n```\r\n>>> import tensorflow as tf\r\n>>> tf.ones((3, 3))\r\n```\r\n\r\n> <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\r\n> array([[0., 0., 0.],\r\n>           [0., 0., 0.],\r\n>           [0., 0., 0.]], dtype=float32)>\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should return ones!\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. \r\n\r\n", "comments": ["@nicolas-gervais \r\nI ran the code shared on tf nightly and output is as expected, please find the [gist shared](https://colab.research.google.com/gist/Saduf2019/9d7026a9a87b492d72c53e4a048927d1/untitled359.ipynb).", "@Saduf2019 \r\n\r\nProblem was fixed by downgrading to Tensorflow 2.1, see Stack Overflow [thread here](https://stackoverflow.com/questions/63363859/tf-ones-returns-zeros-instead-of-ones/63364685#63364685). \r\n\r\nApparently, Anaconda doesn't support Tensorflow 2.3", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42238\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42238\">No</a>\n", "@nicolas-gervais \r\nThank you Nicolas glad to hear the issue is resolved, it works fine on my colab as shared with you, do you want to update your python version and try.", "I think it has to do more with Anaconda than the Python version. Please advise.", "@nicolas-gervais \r\nwe don't support Anaconda build related issues, so i will not be able to comment on whether they have build with 2.3.\r\n\r\nThis question is more suitable on Continuum Anaconda [repo](https://github.com/ContinuumIO/anaconda-issues/issues) since its related to TF installation with Anaconda.\r\nPlease post it on [Continuum Anaconda](https://github.com/ContinuumIO/anaconda-issues/issues).Thanks!\r\n"]}, {"number": 42237, "title": "Add SegmentProdGrad", "body": "Fixes https://github.com/tensorflow/tensorflow/issues/41090.", "comments": ["@rohan100jain Can you please take a look on this PR ? Thanks!"]}, {"number": 42236, "title": "Unrecognized device error when setting memory growth", "body": "\r\n**System information**\r\n- OS Platform and Distribution : Windows 10\r\n- TensorFlow installed from: PIP\r\n- TensorFlow version: tf-nightly-gpu 2.4.0-dev20200808\r\n- Python version: 3.7.4\r\n- Installed using virtualenv? PIP\r\n- CUDA/cuDNN version: CUDA 10.2\r\n- GPU model and memory: GeForce GTX 1050 Ti\r\n\r\n**Describe the problem**\r\nWhen listing available physical devices GPU does appear. Nonetheless, when setting memory growth (tf.config.experimental.set_memory_growth(gpu, True)), python does not recognize the device. \r\n\r\n**Any other info / logs**\r\nValueError: Unrecognized device: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n\r\n", "comments": ["@Echambouleyron \r\n\r\nPlease, provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42236\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42236\">No</a>\n"]}, {"number": 42235, "title": ":memo: Adding quick guide in Keras documentation", "body": "I had tried to add a quick guide to make the DNN model using  Keras API, which code be very beneficial for beginners and new to TensorFlow or Keras.\r\nI had tried to add short comments to give insights for the code. Being my first contribution there is the scope of error in depicting or any other mean if so, kindly guide me, I would definitely try to stand on community needs and be part of this community.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42235) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42235) for more info**.\n\n<!-- ok -->", "@qlzh727 \r\nSir, I am new to Open source, Kindly review and tell the scope of improvement and give a quick start to my open source journey.\r\nthanks\r\n", "Closing this PR since I don't think we will move forward on TF side. Feel free to reopen if you feel otherwise."]}, {"number": 42233, "title": "ModuleNotFoundError: No module named 'tensorflow.python'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.3\r\n- Python version: 3.7.7\r\n- Installed using virtualenv? pip? conda?: Neither `pip` or `conda` worked\r\n- CUDA/cuDNN version: 10.1, V10.1.243\r\n- GPU model and memory: Nvidia GeForce 960M Notebook\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI get this when I import tensorflow:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"C:\\Users\\nicol\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n>     from tensorflow.python.tools import module_util as _module_util\r\n> ModuleNotFoundError: No module named 'tensorflow.python'\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nconda create -n tf python=3.7\r\npip install tensorflow\r\npython\r\n```\r\n```\r\nimport tensorflow\r\n```\r\n\r\n**Any other info / logs**\r\n\r\nIf I run `help('modules')` in Python, I get:\r\n\r\n> Failed to import TensorFlow. Please note that TensorFlow is not installed by default when you install Gin-Config. This is so that users can decide whether to install the GPU-enabled TensorFlow package. To use Gin-Config, please install the most recent version of TensorFlow, by following instructions at https://tensorflow.org/install.\r\n", "comments": ["@nicolas-gervais \r\nRequest you to uninstall python and tensorflow .Please, install it again and see if the problem still persists.(You need a 64-bit version of Python and in your case are using a 32-bit version)\r\nMicrosoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019.\r\n\r\nI don't think Tensorflow support 32 bit architecture.Please, refer the issue #32315\r\n\r\nPlease, follow the instructions from [here](https://www.tensorflow.org/install/source_windows)..Thanks!\r\n\r\nPlease refer to these issues with similar error:\r\n#34722  [link](https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip) ", "@Saduf2019 \r\n\r\nHello and thanks for the response. May I ask what leads you to believe that my Python is 32bit? I have been using Tensorflow for a long time with no problem. I've been using RNNs more than usual and that's when the problem started. Now the problem is generalized to all my environments (venv, conda) and reinstalling hasn't worked. \r\n\r\nI will still do everything you listed to be absolutely sure. ", "> Python 3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\n> Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\n```\r\n>>> import sys\r\n>>> sys.version\r\n```\r\n\r\n> '3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)]'", "So I deleted this folder:\r\n```\r\nC:\\Users\\nicol\\AppData\\Roaming\\Python\\Python37\r\n```\r\nAnd everything fell into place, after a few days of not being able to do my work. For now, I guess it works...", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42233\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42233\">No</a>\n", "@nicolas-gervais \r\nThank you for your update,glad the issue is resolved."]}, {"number": 42232, "title": "Xscode dual license", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42232) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 42231, "title": "Quantization TOCO implementation", "body": "Hi,\r\n\r\ni am trying to understand how exactly TOCO does quantize an annotated model. Assume we have a keras model:\r\n```\r\nConv2D\r\nMaxPool\r\nConv2D\r\nMaxPool\r\nFlatten\r\nDense\r\nDense(SoftMax)\r\n```\r\nwhere the Conv2D layers have been annotated with for post-training quantization using a QuantizeConfig for quantizing weights and activations based on the following Quantizer: \r\n\r\n```\r\nLastValueQuantizer(num_bits=8, symmetric=True,\r\n narrow_range=False,\r\nper_axis=False)\r\n```\r\n\r\nAs far as i understand, converting a such annotated keras model to TFLite using TOCO should yield a a model where the Conv2D layers have been quantized to 8bit integers while the rest stays at 32bit float. Is that correct? If yes, how is the rounding from the input keras Conv2D layers in 32bit to int8 accomplished? Is the situation the same when using float16 instead of int8? What abot the siutuation where i set num_bits=4?\r\n\r\nThanks for your help!", "comments": ["Thanks for using the tooling and reaching out.\r\n\r\nYou are correct that the quantization tooling you are using is able to selectively quantize certain layers while leaving the rest in floating point (this offers well controlled trade-off between accuracy, speed, and model size). When a model has both int8 op and float op, there will be a \"quantization\" op inserted in between to do the conversion of int8 and float32.\r\n\r\nHope this helps.", "Hi,\r\n\r\nthank for your reply and confirming my assumptions, this does indeed help me. \r\n\r\nI am working on a research project using TF about analyzing quantization errors in CNN topologies and i need to know exactly what happens, but the converter optimizations are still an unknown factor.  Can you tell me what exactly happens when the optimization flag below is used or can you point me to a relevant paper?\r\n\r\n`converter.optimizations = [tf.lite.Optimize.DEFAULT]`\r\n\r\nThanks a lot for your help!", "@lorenz0890 \r\n\r\nPlease, see the [link ](https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/lite/python/lite.py#L92-L131)for the description of converter optimizations.Thanks!", "> @lorenz0890\r\n> \r\n> Please, see the [link ](https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/lite/python/lite.py#L92-L131)for the description of converter optimizations.Thanks!\r\n\r\nThanks!"]}, {"number": 42230, "title": "[tflite] remove duplicate num_threads flag in benchmark_model", "body": "When running benchmark_model, we saw message like `Duplicate flags: num_threads`\r\nbecause there is num_threads flag in benchmark_tflite_model.cc", "comments": ["Thanks for noticing this! This duplicate --num_threads flag comes from two independent modules:\r\n\r\nOne is from the benchmark_model library as you touched here. The flag is kept here because BenchmarkModel starts to be a general class and it has been used outside the TFLite model benchmarking context where --num_threads flag matters.\r\n\r\nThe other is from the TFLite delegate registrar (i.e. //tensorflow/lite/tools/delegates/) module. The same flag (admittedly we could use a different flag name, but --num_threads looks best) is defined there because the registrar module has been used in other non-benchmark-tooling contexts (like, kernel tests, task evaluation tools) where we also need a flag to specify number of CPU threads.\r\n\r\nAs a result, both flags are kept and the flag parsing library was changed (https://github.com/tensorflow/tensorflow/commit/f255fc685459368abe1313f7818785d0d3200f42) to handle such scenarios.", "Argh, thanks for the explanation. Will close this since this is not a bug :-)"]}, {"number": 42229, "title": "Tf-nightly 2.4.0 does not recognize Cuda 10.2", "body": "### System information\r\n-   **TF-nightly 2.4.0-dev20200808 installed with PIP**:\r\n-   **OS Platform and Distribution: Windows 10**:\r\n-   **Python version:  3.8.5**:\r\n-   **CUDA/cuDNN version: 10.2**:\r\n-   **GPU model and memory: GeForce GTX 1050 Ti**:\r\n\r\n### Describe the problem\r\nAfter installing tf-nightly and cuda 10.2 and changing the corresponding environmental variables, tensorflow does not recognize CUDA 10.2.\r\n### Source code / logs\r\nWhile importing tensorflow:\r\n2020-08-11 10:04:37.795114: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-08-11 10:04:37.798451: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n", "comments": ["@Echambouleyron,\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/38194#issuecomment-657233766) from a similar issue and let us know if it works. Thanks! \r\n", "Thank you for the answer. I renamed the folder in question as suggested in that post and even though I am not getting the error I mentioned above, the problem remains. When I run my model the ETA is very high, which suggests that tensorflow is not using GPU. Is quite strange because when I run tf.config.list_physical_devices(\"GPU\") I get: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')].", "@Echambouleyron,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42228, "title": "[colab TPU] [TF2.x] UnavailableError: Socket closed with LayerNormalization", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab environment with TPU  \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA \r\n- TensorFlow installed from (source or binary): binary \r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA \r\n- CUDA/cuDNN version: NA \r\n- GPU model and memory: High RAM\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI encountered this UnavailableError when running a classifier on the Colab TPU environment (with tensorflow.version = 2.3.0; Python version = 3.6.9). I was able to reproduce this error with the minimum lines of code. It turns out that the error stems from the LayerNormalization layer, and after removing this layer, the rest of the code just works fine.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf \r\nimport numpy as np\r\nfrom tensorflow.keras.layers import LSTM, Dense, ReLU\r\nfrom tensorflow.keras.layers import LayerNormalization, GlobalAveragePooling1D, TimeDistributed\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras import regularizers\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver()\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n```\r\n\r\n```python\r\nwith strategy.scope():\r\n  model = Sequential()\r\n  model.add(LSTM(units=50, return_sequences=True))\r\n  model.add(LayerNormalization())\r\n  model.add(GlobalAveragePooling1D(data_format='channels_last'))\r\n  model.add(Dense(7, activation='softmax'))\r\n  model.compile(optimizer='adam', \r\n                loss='categorical_crossentropy', \r\n                experimental_steps_per_execution=100,\r\n                metrics=['accuracy'])\r\n```\r\n\r\n```python\r\nx=-np.ones((150, 100, 4)).astype(np.float32)\r\ny=np.ones((150, 7)).astype(np.float32)\r\nmodel.fit(x, y, epochs=10)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nHere are the detailed log messages\r\n```\r\nEpoch 1/10\r\n---------------------------------------------------------------------------\r\nUnavailableError                          Traceback (most recent call last)\r\n<ipython-input-20-cf653c7d94da> in <module>()\r\n      3 y=np.ones((150, 7)).astype(np.float32)\r\n      4 # Train the model\r\n----> 5 model.fit(x, y, epochs=10)\r\n\r\n14 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1101               logs = tmp_logs  # No error, now safe to assign to logs.\r\n   1102               end_step = step + data_handler.step_increment\r\n-> 1103               callbacks.on_train_batch_end(end_step, logs)\r\n   1104         epoch_logs = copy.copy(logs)\r\n   1105 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)\r\n    438     \"\"\"\r\n    439     if self._should_call_train_batch_hooks:\r\n--> 440       self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)\r\n    441 \r\n    442   def on_test_batch_begin(self, batch, logs=None):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)\r\n    287       self._call_batch_begin_hook(mode, batch, logs)\r\n    288     elif hook == 'end':\r\n--> 289       self._call_batch_end_hook(mode, batch, logs)\r\n    290     else:\r\n    291       raise ValueError('Unrecognized hook: {}'.format(hook))\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_end_hook(self, mode, batch, logs)\r\n    307       batch_time = time.time() - self._batch_start_time\r\n    308 \r\n--> 309     self._call_batch_hook_helper(hook_name, batch, logs)\r\n    310 \r\n    311     if self._check_timing:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook_helper(self, hook_name, batch, logs)\r\n    340       hook = getattr(callback, hook_name)\r\n    341       if getattr(callback, '_supports_tf_logs', False):\r\n--> 342         hook(batch, logs)\r\n    343       else:\r\n    344         if numpy_logs is None:  # Only convert once.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)\r\n    959 \r\n    960   def on_train_batch_end(self, batch, logs=None):\r\n--> 961     self._batch_update_progbar(batch, logs)\r\n    962 \r\n    963   def on_test_batch_end(self, batch, logs=None):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _batch_update_progbar(self, batch, logs)\r\n   1014     if self.verbose == 1:\r\n   1015       # Only block async when verbose = 1.\r\n-> 1016       logs = tf_utils.to_numpy_or_python_type(logs)\r\n   1017       self.progbar.update(self.seen, list(logs.items()), finalize=False)\r\n   1018 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py in to_numpy_or_python_type(tensors)\r\n    535     return t  # Don't turn ragged or sparse tensors to NumPy.\r\n    536 \r\n--> 537   return nest.map_structure(_to_single_numpy_or_python_type, tensors)\r\n    538 \r\n    539 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)\r\n    633 \r\n    634   return pack_sequence_as(\r\n--> 635       structure[0], [func(*x) for x in entries],\r\n    636       expand_composites=expand_composites)\r\n    637 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in <listcomp>(.0)\r\n    633 \r\n    634   return pack_sequence_as(\r\n--> 635       structure[0], [func(*x) for x in entries],\r\n    636       expand_composites=expand_composites)\r\n    637 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py in _to_single_numpy_or_python_type(t)\r\n    531   def _to_single_numpy_or_python_type(t):\r\n    532     if isinstance(t, ops.Tensor):\r\n--> 533       x = t.numpy()\r\n    534       return x.item() if np.ndim(x) == 0 else x\r\n    535     return t  # Don't turn ragged or sparse tensors to NumPy.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in numpy(self)\r\n   1061     \"\"\"\r\n   1062     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\r\n-> 1063     maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n   1064     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr\r\n   1065 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _numpy(self)\r\n   1029       return self._numpy_internal()\r\n   1030     except core._NotOkStatusException as e:  # pylint: disable=protected-access\r\n-> 1031       six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access\r\n   1032 \r\n   1033   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nUnavailableError: Socket closed\r\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\r\n:{\"created\":\"@1597132573.936732336\",\"description\":\"Error received from peer ipv4:10.43.145.10:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\r\n```\r\nand the successful running log messages with the LayerNormalization removed \r\n```\r\nEpoch 1/10\r\n5/5 [==============================] - 2s 448ms/step - loss: 13.7076 - accuracy: 0.0000e+00\r\nEpoch 2/10\r\n5/5 [==============================] - 0s 10ms/step - loss: 13.7256 - accuracy: 0.0000e+00\r\nEpoch 3/10\r\n5/5 [==============================] - 0s 9ms/step - loss: 13.8872 - accuracy: 0.0000e+00\r\nEpoch 4/10\r\n5/5 [==============================] - 0s 9ms/step - loss: 14.1986 - accuracy: 0.0000e+00\r\nEpoch 5/10\r\n5/5 [==============================] - 0s 9ms/step - loss: 14.5464 - accuracy: 0.0000e+00\r\nEpoch 6/10\r\n5/5 [==============================] - 0s 8ms/step - loss: 14.8935 - accuracy: 0.0000e+00\r\nEpoch 7/10\r\n5/5 [==============================] - 0s 9ms/step - loss: 15.2337 - accuracy: 0.0000e+00\r\nEpoch 8/10\r\n5/5 [==============================] - 0s 9ms/step - loss: 15.5591 - accuracy: 0.0000e+00\r\nEpoch 9/10\r\n5/5 [==============================] - 0s 8ms/step - loss: 15.9003 - accuracy: 0.0000e+00\r\nEpoch 10/10\r\n5/5 [==============================] - 0s 10ms/step - loss: 16.2539 - accuracy: 0.0000e+00\r\n<tensorflow.python.keras.callbacks.History at 0x7f78b8ad6ac8>\r\n```\r\n\r\nThere is a same issue that I created under tensorflow/tpu https://github.com/tensorflow/tpu/issues/821, sorry if this has been repetitive ", "comments": ["@JerryLiuMY \r\nPlease refer the below links and let us know if it helps.\r\n#36996 [link](https://www.kaggle.com/dimitreoliveira/bug-report-unavailableerror-socket-closed) \r\n\r\nI am able to replicate this issue please find the [gist here](https://colab.research.google.com/gist/Saduf2019/8e863cb718ffb05e77f7b28be54502fb/untitled360.ipynb). Thanks!", "@Saduf2019 Hi, the issue described in https://github.com/tensorflow/tensorflow/issues/36996 was mainly because the the datatype of one-hot label vectors are set to np.float64, which is not supported by cloud TPUs. However, a) I have explicitly set the dtype of both feature and label arrays to np.float32 (which is supported by the TPUs) b) the code doesn't incur any error when LayerNormalziation is removed. \r\n\r\nhttps://cloud.google.com/tpu/docs/troubleshooting\r\n\"Currently, only the tf.float32, tf.int32, tf.bfloat16, and tf.bool data types are supported on the TPU. Other common data types, such as tf.uint8, tf.string, and tf.int64, must be converted to one of the supported data types during data pre-processing (that is, in the input_fn of TPUEstimator). See the MNIST tutorial for another example. As an example, this code snippet from MNIST converts an image tensor stored as tf.uint8 byte sequence to a tf.float32 tensor:\"\r\n\r\n__Edit__: I just tried replacing `LayerNormalization` with `BatchNormalization` and the code executes without any error, so I guess it is the problem with the `LayerNormalization` layer class? ", "Actually, keeping using the `LayerNormalization` and changing the 0th dimension of the feature size to multiples of 32, the training process is able to execute (although with some ignored exceptions) \r\n\r\n```Python\r\nx=-np.ones((32, 100, 4)).astype(np.float32)\r\ny=np.ones((32, 7)).astype(np.float32)\r\n```\r\n\r\n```\r\nEpoch 1/10\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d4456bb70>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d4456b780>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d4456b390>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d4455df60>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d4455db70>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d445b07b8>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d445b7cc0>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d445cd898>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d3b486f98>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d3b486ba8>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d3b4867b8>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d3b4863c8>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d3b477f98>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d3b4cb9b0>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d3b4bcb70>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f3d3b4657f0>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1282, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Resource input tensor contains an invalid device. This might happen when the client has connected to a different cluster, or some remote workers have been restarted. [Op:DeleteIterator]\r\n2/2 [==============================] - 1s 713ms/step - loss: 16.4232 - accuracy: 0.0000e+00\r\nEpoch 2/10\r\n2/2 [==============================] - 0s 11ms/step - loss: 16.4613 - accuracy: 0.0000e+00\r\nEpoch 3/10\r\n2/2 [==============================] - 0s 12ms/step - loss: 16.5462 - accuracy: 0.0000e+00\r\nEpoch 4/10\r\n2/2 [==============================] - 0s 10ms/step - loss: 16.6448 - accuracy: 0.0000e+00\r\nEpoch 5/10\r\n2/2 [==============================] - 0s 11ms/step - loss: 16.6587 - accuracy: 0.0000e+00\r\nEpoch 6/10\r\n2/2 [==============================] - 0s 12ms/step - loss: 16.6126 - accuracy: 0.0000e+00\r\nEpoch 7/10\r\n2/2 [==============================] - 0s 9ms/step - loss: 16.5298 - accuracy: 0.0000e+00\r\nEpoch 8/10\r\n2/2 [==============================] - 0s 10ms/step - loss: 16.4593 - accuracy: 0.0000e+00\r\nEpoch 9/10\r\n2/2 [==============================] - 0s 10ms/step - loss: 16.4105 - accuracy: 0.0000e+00\r\nEpoch 10/10\r\n2/2 [==============================] - 0s 9ms/step - loss: 16.3319 - accuracy: 0.0000e+00\r\n<tensorflow.python.keras.callbacks.History at 0x7f3d3471e358>```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42228\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42228\">No</a>\n", "... closed the issue by mistake, not intended", "@JerryLiuMY,\r\nIs this still an issue?\r\n\r\nI was able to run the code without any errors with TF v2.4, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/0737b1a44a64fae217c753842bcab2eb/42228.ipynb). Thanks!", "The issue persists in TensorFlow 2.4.1 ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42228\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42228\">No</a>\n", "> The issue persists in TensorFlow 2.4.1\r\n\r\n@sayakpaul,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!"]}, {"number": 42227, "title": "TensorFlow model in commercial projects", "body": "Hi, I  don't understand the various licenses well. Now I am working with my mobile app, and I would like to know: can I use tensorflow models (like posenet) in commercial projects? Thank you\r\n", "comments": ["Hi @swel4ik, \r\n\r\nTensorFlow's license is here: https://github.com/tensorflow/tensorflow/blob/master/LICENSE\r\nBeyond that, we can't provide any legal advice.  You may want to consult your own counsel if you have questions.\r\n\r\n"]}, {"number": 42226, "title": "tensorflow.python.framework.errors_impl.NotFoundError : when trying to run rasa init --no-prompt", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): **pip3 install --upgrade tensorflow rasa**\r\n**pip3 install --upgrade tensorflow-addons rasa**\r\n- TensorFlow version (use command below):tensorflow 2.3.0  , **v2.3.0-rc2-23-gb36436b087 2.3.0**\r\n- Python version: **Python 3.6.9**\r\n\r\n**Describe the current behavior**\r\nWhen I am trying to run rasa init command it throws me error tensorflow.python.framework.errors_impl.NotFoundError\r\n\r\n**Describe the expected behavior**\r\nIt should train the model.\r\n\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/aman/meraklis-pocs/RASA_POC/venv/lib/python3.6/site-packages/tensorflow_addons/custom_ops/activations/_activation_ops.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl11string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS8_EE", "comments": ["@garchaaman19,\r\nCould you please the complete code and the exact sequence of commands / steps that you executed before running into the problem? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42226\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42226\">No</a>\n"]}, {"number": 42225, "title": "Resolved an execution error when the path contains space", "body": "The python file configure.py does not execute if the env %configure_dir% contains spaces.\r\nThe error resolved with double quotes.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42225) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42225) for more info**.\n\n<!-- ok -->"]}, {"number": 42224, "title": "[TFLite micro] Max number of channels (kMaxChannels) for DepthwiseConv should be updated (CMSIS-NN)", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source): f63877d6371aa5e47391e520a29a6aa1ef2e0199\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Any\r\n\r\n**Describe the problem**\r\nThe current implementation of DepthwiseConv based on CMSIS-NN [defines the maximum number of channels as a constant value (set to 256)](https://github.com/tensorflow/tensorflow/blob/b4ab032959b2fb68022b2cf70de46e9564a50d6f/tensorflow/lite/micro/kernels/cmsis-nn/depthwise_conv.cc#L40). This can be a limitation for someone that want to run a model having one or more DepthwiseConv ops with a number of channels greater than 256. In fact, in that case, the assertion `TFLITE_DCHECK_LE(num_channels, kMaxChannels);` will become false and inference will stop.\r\nThere are several ways to solve this limitation, each having some pros and cons:\r\n\r\n- The simplest way is to increase the value of `kMaxChannels`, for example to 1024. This will increase the set of models that can be run such as MobileNet v1 with alpha=100 or 75. On the other hand, when we need to run a DepthwiseConv op with a number of channels less than 1024, we will allocate more memory (for `per_channel_output_multiplier` and `per_channel_output_shift`) than what is needed.\r\nI am also aware that when designing a model for a MCU, the 'keep-it-simple' (I would also say 'keep-it-small') principle is very important and useful in order to reduce memory and computational requirements. So, in this case, the value of `kMaxChannels` represent an important trade-off.\r\nA variant of this approach is to allow the user to set the max number of channels of all DepthwiseConv ops through compile-time constants and macros. For example, we can use the following code snippet to set it:\r\n```\r\n#if defined(TFLITE_DEPTHWISECONV_MAX_CHANNELS) && TFLITE_DEPTHWISECONV_MAX_CHANNELS > 0\r\n  constexpr int kMaxChannels = TFLITE_DEPTHWISECONV_MAX_CHANNELS;\r\n#else \r\n  constexpr int kMaxChannels = 256;\r\n#endif\r\n```\r\nThe user can re-define it at compile time according to the model to be run (for example compiling the source code with `-DTFLITE_DEPTHWISECONV_MAX_CHANNELS=1024`).\r\n\r\n- Another way is to use dynamic allocation in order to allocate only the needed memory for the temp buffers. On the other hand, dynamic memory allocation can result in memory fragmentation or runtime issues (especially when memory is not managed by a  RTOS or because it is general quite small in size), and so it is generally avoided (think about the use of the `tensor_arena`). However this approach could be quite useful to save memory and if the number of channels is not very high heap issues like overflow should not happen.\r\nI'm also wondering if it is possible to allocate memory for the needed buffers in the `tensor_arena`.\r\n\r\n- Other suggestions ?\r\n\r\nSo, my question is: can we handle `kMaxChannels` in a better way ?\r\n\r\nBest regards,\r\nBiagio.", "comments": ["I think we can close this issue. Fix [here](https://github.com/tensorflow/tensorflow/commit/b18a353b7819c4049e70c6b77594221df1563fe7#diff-0245be3835c3d7fa9d9e844a74d9db3bfc05afbd412f77b4368b3f2211b3b2ad).", "Great !", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42224\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42224\">No</a>\n"]}, {"number": 42223, "title": "Wrong output when decorating functions with @tf.function", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n    Complete test code(minimum version for reproducing the problem) below \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10, tf 2.2.0 py 3.6.8\r\n- TensorFlow installed from (source or binary): pip install tensorflow=2.2.0\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: Using cpu\r\n\r\n\r\n**Describe the current/expected behavior**\r\nThe following is a simple example for writing an iterative method to solve `Ax=b`, as the iterative step is\r\n```math\r\nx_{k+1} = x_k + \\alpha * (b - A x_k)\r\n```\r\nwhile adding/removing the `@tf.function` decorator in `Line 12` will result in different output.\r\nThe output with `@tf.function`:\r\n```\r\nStep  0: loss 1.00000000e+00\r\nStep  1: loss 1.00000000e+00\r\nStep  2: loss 1.00000000e+00\r\nStep  3: loss 1.00000000e+00\r\nStep  4: loss 1.00000000e+00\r\n...\r\n```\r\nThe output without `@tf.function` (correct):\r\n```\r\nStep  0: loss 1.00000000e+00\r\nStep  1: loss 7.73297510e-01\r\nStep  2: loss 6.05587767e-01\r\nStep  3: loss 4.81463411e-01\r\nStep  4: loss 3.89456113e-01\r\n...\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nclass MyFakeNN(tf.keras.Model):\r\n    def __init__(self, max_num_iter=100, **kwargs):\r\n        super(MyFakeNN, self).__init__(**kwargs)\r\n        self.max_num_iter  = max_num_iter\r\n        self.func = func\r\n        self.curr_iter = 0\r\n\r\n    @tf.function\r\n    def train_one_step(self, x, y):\r\n        x_next = self(x, y)\r\n        loss = loss_func(x_next, y)\r\n        return loss\r\n\r\n    def train(self, x, y):\r\n        for it in range(self.max_num_iter):\r\n            self.curr_iter = it\r\n            self.trainable = False\r\n            loss = self.train_one_step(x, y)\r\n            print(\"Step %2d: loss %14.8e\" % (it, loss.numpy()))\r\n\r\n    def call(self, x, y):\r\n        for _ in range(self.curr_iter):\r\n            r = y - self.func(x)\r\n            x += r * 2e-3\r\n        return x\r\n\r\n\r\nn = 8\r\ntf.keras.backend.set_floatx('float64')\r\n\r\na = np.eye(n, k=0) * 2 - np.eye(n, k=1) - np.eye(n, k=-1)\r\na[-1, 0] = -1\r\na[0, -1] = -1\r\na *= n ** 2\r\nfunc = lambda x: tf.matmul(x, a)\r\n\r\n\r\ndef loss_func(x, y):\r\n    return tf.reduce_mean(tf.norm(func(x) - y, axis=1)/tf.norm(y, axis=1))\r\n\r\n\r\nmodel = MyFakeNN()\r\nmodel.trainable = False\r\n\r\ny = np.array([[-9.38155831, -28.13152345, 7.78468155, 29.26619534,\r\n               -4.5831364, -25.87319867, 6.18001317, 24.73852678], [-9.83892541, -20.53029054, 20.69956084, 28.01860432,\r\n               -20.97012137, -35.88954846, 10.10948594, 28.40123469], [-21.04290567, -8.05650662, 16.85368166, 1.02738802,\r\n               -22.60513251, -2.13204921, 26.79435652, 9.16116781], [2.04530187, -2.93405974, -2.79706502, -1.04454986,\r\n               -2.07777548, -1.87090609, 2.82953863, 5.84951569], [-4.84959288, 6.48666613, 8.21196668, -4.87053449,\r\n               -9.2887852, 1.73155149, 5.92641139, -3.34768314], [7.66043654, 6.05170581, -3.87066543, 0.99382044,\r\n               10.04477309, 0.69216011, -13.8345442, -7.73768635], [2.54742214, -13.73492348, 0.23540163, 14.91811095,\r\n               -1.34494564, -17.6704306, -1.43787813, 16.48724313], [12.9314438, 3.94013919, -22.58640847, -11.10766707,\r\n               22.104958, 17.59432117, -12.44999333, -10.42679329]])\r\nx = np.zeros(y.shape, dtype='float64')\r\n\r\nmodel.train(x=x, y=y)\r\n```\r\n", "comments": ["I have tried in colab with TF version 2.2, nightly versions(`2.4.0-dev20200810`) and was able to reproduce the issue .Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/d9eb43b9cc99f7b091372b9f3f0a0236/untitled240.ipynb).Thanks!", "Possibly related to #32895? Although it doesn't look like the explanation provided in that issue applies to this case.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "The problem here is that self.curr_iter is captured once and doesn't change with tf.function. Moving the tf.function to def train() or passing in `it` explicitly to the tf.function would fix it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42223\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42223\">No</a>\n"]}, {"number": 42222, "title": "Please add tf 1.15's related cuda/cudnn version", "body": "Hi, the official documentation webpage gives the version table for tensorflow version and cuda/cudnn version:\r\n\r\nhttps://www.tensorflow.org/install/source#common_installation_problems\r\n\r\nHowever, there's no information about tensorflow 1.15.\r\n\r\nPlease consider adding it. Thanks.", "comments": ["@zchrissirhcz,\r\nPlease check the [GPU section](https://www.tensorflow.org/install/source#gpu) under tested build configurations. The table has TensorFlow v1.15 listed along with the compatible CUDA and cuDNN versions. \r\n\r\nScreenshot for reference:\r\n![image](https://user-images.githubusercontent.com/57165142/89875527-fc45ae80-dbda-11ea-9d7e-8e5b07c8d1c1.png)\r\n\r\nThanks!", "@amahendrakar OK, let me make it clear. \r\n\r\nThere **is** TensorFlow v1.15 in the **English** version of this webpage, but isn't in the **Chinese** version. It directly show me the Chinese version webpage thus I didn't find it.", "@zchrissirhcz,\r\nCould you please confirm if [this](https://www.tensorflow.org/install/source?hl=zh-cn#gpu) is the page you are referring to? Thanks!", "@amahendrakar Yes, you are right, [this](https://www.tensorflow.org/install/source?hl=zh-cn#gpu) is the page I'm refering to.", "@zchrissirhcz,\r\nThe [documentation](https://www.tensorflow.org/install/source?hl=zh-cn#gpu) has been updated and CUDA/cuDNN versions have been added for TensorFlow v1.15. \r\n\r\nClosing this issue as resolved. Please feel free to re-open if necessary. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42222\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42222\">No</a>\n", "@amahendrakar  Thanks for your contribution. \r\nRight now I can't access tensorflow official site, blocked by the GFW. When accesible, will try again for validation.", "![image](https://user-images.githubusercontent.com/3831847/107754570-a1913900-6d5c-11eb-9f1f-4949b42b8d1b.png)\r\n\r\n@amahendrakar Validated, fixed. Good job!"]}, {"number": 42221, "title": "version 2.3.0 build error: user_ops_gen_cc: undefined symbol", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  CentOS Linux release 7.8.2003\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.3.0\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: build from source\r\n- Bazel version (if compiling from source): 3.4.1 or 3.1.0 (both give the same error shown below)\r\n- GCC/Compiler version (if compiling from source): gcc 8.4.0\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: RTX2080; 10GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI am building version 2.3.0 from source and get this error:\r\n```\r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/cc/ops/user_ops_gen_cc: symbol lookup error: bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/cc/ops/user_ops_gen_cc: undefined symbol: _ZN10tensorflow8OpKernel11TraceS\r\ntringB5cxx11EPNS_15OpKernelContextEb\r\n```\r\nThe exact command that fails is:\r\n```\r\ncd ../tensorflow_cache_dir/_bazel_aznb/73fa4b3fd284d99232eec1bc01a9093d/execroot/org_tensorflow &&\r\nexec env - \\\r\nCUDA_TOOLKIT_PATH=/home/aznb/.linuxbrew/Cellar/cuda/11.0 \\\r\nCUDNN_INSTALL_PATH=/home/aznb/.linuxbrew/Cellar/cuda/11.0 \\\r\nGCC_HOST_COMPILER_PATH=/home/aznb/.linuxbrew/Cellar/gcc@8/8.4.0_1/bin/gcc-8 \\\r\nPATH=/usr/bin:/bin:/home/aznb/.linuxbrew/bin \\\r\nPYTHONPATH=/home/aznb/.pyenv/versions/venv-tensorflow-py3.8.5-cuda11.0/lib/python3.8/site-packages \\\r\nPYTHON_BIN_PATH=/home/aznb/.pyenv/shims/python3 \\\r\nPYTHON_LIB_PATH=/home/aznb/.pyenv/versions/venv-tensorflow-py3.8.5-cuda11.0/lib/python3.8/site-packages \\\r\nTF2_BEHAVIOR=1 \\\r\nTF_CONFIGURE_IOS=0 \\\r\nTF_CUDA_COMPUTE_CAPABILITIES=6.1,7.5 \\\r\nTF_CUDA_PATHS=/home/aznb/.linuxbrew/Cellar/cuda/11.0 \\\r\nTF_CUDA_VERSION=11.0 \\\r\nTF_CUDNN_VERSION='' \\\r\nTF_NEED_CUDA=1 \\\r\n/bin/bash bazel-out/k8-opt/bin/tensorflow/cc/user_ops_genrule.genrule_script.sh\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nexport CUDA_TOOLKIT_PATH=$CUDAPATH                                                                                                                                                                                 \r\nexport CUDNN_INSTALL_PATH=$CUDA_TOOLKIT_PATH                                                                                                                                                                       \r\nexport TF_CUDA_VERSION=\"$($CUDA_TOOLKIT_PATH/bin/nvcc --version | sed -n 's/^.*release \\(.*\\),.*/\\1/p')\"\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=$CUDACC\r\nexport TF_CUDA_PATHS=$CUDAPATH\r\nexport TF_NEED_CUDA=1\r\n\r\nexport TF_CUDA_CLANG=0\r\nexport TF_NEED_GCP=0\r\nexport TF_NEED_HDFS=0\r\nexport TF_NEED_OPENCL=0\r\nexport TF_NEED_JEMALLOC=1\r\nexport TF_ENABLE_XLA=0\r\nexport TF_NEED_VERBS=0\r\nexport TF_CUDNN_VERSION=\"$(sed -n 's/^#define CUDNN_MAJOR\\s*\\(.*\\).*/\\1/p' $CUDNN_INSTALL_PATH/include/cudnn.h)\"\r\nexport TF_NEED_MKL=0\r\nexport TF_DOWNLOAD_MKL=0\r\nexport TF_DOWNLOAD_CLANG=0\r\nexport TF_NEED_AWS=0\r\nexport TF_NEED_MPI=0\r\nexport TF_NEED_GDR=0\r\nexport TF_NEED_S3=0\r\nexport TF_NEED_ROCM=0\r\nexport TF_NEED_OPENCL_SYCL=0\r\nexport TF_SET_ANDROID_WORKSPACE=0\r\nexport TF_NEED_COMPUTECPP=0\r\n# for some reason, this gcc path can't be a symlink to the actual path\r\nexport GCC_HOST_COMPILER_PATH=$LINUXBREWHOME/bin/gcc-8\r\nexport CC_OPT_FLAGS=\"-march=native\"\r\n#export TF_SET_ANDROID_WORKSPACE=0\r\nexport TF_NEED_KAFKA=0\r\nexport TF_NEED_TENSORRT=0\r\n#output cache dir\r\nexport TEST_TMPDIR=\"../tensorflow_cache_dir\"\r\nexport TEMPOUTPUT=\"./output_dir\"\r\nbazel clean --async --expunge\r\nrm -rf ~/.cache/bazel\r\n./configure\r\n\r\nbazel build --explain=buildwhl.txt --verbose_explanations -s --verbose_failures --jobs 24 --crosstool_top=@local_config_cuda//crosstool:toolchain --config=noaws --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@Char-Aznable \r\n\r\nCan you please refer to below issues with the same error:\r\n#35115 [link](https://github.com/tensorflow/tensorflow/issues/15958#issuecomment-356146258) [link1](https://github.com/tensorflow/tensorflow/issues/35584#issuecomment-570920203)", "@Saduf2019 Those are irrelevant. I managed to build v2.1 with CUDA 10.2. I am using bazel 3.4.0 as required. The error is reproducible with all cache removed", "I got same error when building with bazel 3.1.0", "Can you try and reproduce this at `master` HEAD, please?", "It doesn't work. Same error", "@Char-Aznable,\r\n\r\nCan you try installing the latest stable version of tensorflow i.e 2.6.0 and lets us know if the issue still persists. You can follow this [guide](https://www.tensorflow.org/install/source) to build from source. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "I got the same error with 2.6.0", "@Char-Aznable,\r\n\r\nAre you following this [guide](https://www.tensorflow.org/install/source) and you have other configurations like Python version, GCC version,CUDA version and etc same as the tested build configurations in this [link](https://www.tensorflow.org/install/source#tested_build_configurations)?", "Also you have gcc 8.4.0 compiler, whereas most of the tested builds has GCC version 7.3.1, Can you fix this and try building to see if the issue persists? Thanks!", "@sanatmpa1 That was what I did. BTW, It would be much easier to locate the problem if someone from your team can point out the specific compiling commands involved in the error so that I don't have to go through the entire build process again and again. Also, there are a lot of things to try obviously but wouldn't it be more efficient for you to give me some hint on what went wrong with the error?", "@Char-Aznable,\r\nThis error might be when we install multiple versions of Tensorflow. Each Installation creates `/opt/tensorlibs` directory where gcc linking will be available. While building Tensorflow it takes static library directory.\r\n\r\nRecommend to uninstall existing Tensorflow version or create new virtual environment or  remove `/opt/tensorlibs` directory. clear the cache before running Bazel build command `bazel clean --expunge`. This should solve your problem.\r\nThanks!", "> Recommend to uninstall existing Tensorflow version or create new virtual environment or remove `/opt/tensorlibs` directory. clear the cache before running Bazel build command `bazel clean --expunge`. This should solve your problem. Thanks!\r\n\r\nThat was what I did in the OP -- the build script I posted remove all build cache before rebuild. I also tried building this on different machines from scratch. I don't think this is the cause of the problem\r\n", "@Char-Aznable,\r\nIssue is not reproducible on my system. \r\nCould you please try workaround mention on similar issue [#48064](https://github.com/tensorflow/tensorflow/issues/48064#issuecomment-811554566)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42221\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42221\">No</a>\n"]}, {"number": 42220, "title": "Typing mistake in the documentation of momentum optimization", "body": "In the documentation of momentum optimization, I noticed that it should '+' instead of '*'. This is definitely a typing mistake.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42220) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42220) for more info**.\n\n<!-- ok -->"]}, {"number": 42219, "title": "Wheel size increase from 2.0 to 2.1 onward", "body": "I am asking this here because I could not find any centralized patch notes that explain this.\r\n\r\nIf we go to pypi and look at tensorflow 2.0 for py3.6 win64 it has a big, but reasonable wheel size of ~50MB:\r\n\r\nhttps://pypi.org/project/tensorflow/2.0.0/#files\r\n\r\nHowever release 2.1 jumps that number to ~355 MB and release 2.2 goes to ~460 MB. This is an almost x10 size increase!\r\n\r\nI highly doubt that almost half a GB of raw code was added (was it?) so I am wondering what exactly was added since a Google search seems to yield no results.", "comments": ["TF 2.1 and later have a single pip package for both CPU and GPU. The GPU kernels and glue to CUDA take the additional space.\r\n\r\nWe are working on reducing size of pip package through multiple projects, including modularization, reducing number of CUDA capabilities we support, selective registration of kernels, etc.\r\n\r\nRelease notes, either in repo (https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md) or on individual releases (https://github.com/tensorflow/tensorflow/releases/) should contain more details about every step taken.", "@mihaimaruseac Thank you! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42219\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42219\">No</a>\n", "@mihaimaruseac Do you have any resource that explains how to use selective registration of kernels when build `tflite_runtime` with Flex delegates?"]}, {"number": 42218, "title": "[comp:data] link invalid in the \"Analyze tf.data performance with the TF Profiler\" guide", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/guide/data_performance_analysis\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/guide/data_performance_analysis#3_are_you_reaching_high_cpu_utilization\r\n\r\n## Description of issue (what needs changing):\r\n\r\nReferring to the following line:\r\n\r\n> tf.data achieves high throughput by trying to make the best possible use of available resources. In general, even when running your model on an accelerator like a GPU or TPU, the tf.data pipelines are run on the CPU. You can check your utilization with tools like sar and htop, or in the cloud monitoring console if you\u2019re running on GCP.\r\n\r\nThe link attached to \"cloud monitoring console\" is invalid.\r\n", "comments": ["I'dl like to take this up.", "I am closing this issue as it is resolved in `tf-nightly` through the https://github.com/tensorflow/docs/pull/1648 that was merged already. New change will be reflected soon. \r\n\r\n[here](https://cloud.google.com/monitoring/docs/monitoring_in_console) is the correct link. Thanks!"]}, {"number": 42217, "title": "Typo in TFLite CoreML framework build command example", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nThere is a single typo in build command example:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4b901e2a7ea0b849ad1d1cea311cd131bc089ebe/tensorflow/lite/experimental/ios/BUILD.apple#L82-L94\r\n\r\nThis introduce bazel build fails to newbies:\r\n\r\n```\r\nERROR: Skipping '//tensorflow/lite/experimental/ios:TensorFlowLiteCCoreMl_framework': no such target '//tensorflow/lite/experimental/ios:TensorFlowLiteCCoreMl_framework': target 'TensorFlowLiteCCoreMl_framework' not declared in package 'tensorflow/lite/experimental/ios' (did you mean 'TensorFlowLiteCCoreML_framework'?) defined by /Users/mumu/hpcnt/tensorflow/tensorflow/lite/experimental/ios/BUILD\r\nWARNING: Target pattern parsing failed.\r\nERROR: no such target '//tensorflow/lite/experimental/ios:TensorFlowLiteCCoreMl_framework': target 'TensorFlowLiteCCoreMl_framework' not declared in package 'tensorflow/lite/experimental/ios' (did you mean 'TensorFlowLiteCCoreML_framework'?) defined by /Users/mumu/hpcnt/tensorflow/tensorflow/lite/experimental/ios/BUILD\r\nINFO: Elapsed time: 21.011s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (1 packages loaded)\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nAt Line 82, `TensorFlowLiteCCoreMl_framework` should be fixed to `TensorFlowLiteCCoreML_framework`\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n", "comments": ["@kalaluthien Thanks for finding the typo. we have updated the doc and it is already reflecting in the `master` [branch](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/ios/BUILD.apple#L82).\r\n\r\nAs this is resolved, I am closing this issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42217\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42217\">No</a>\n"]}, {"number": 42216, "title": "make failed and it print this . The keywords is Undefine Reference", "body": "../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `void HugeCTR::create_pipeline_internal<long long>(std::unique_ptr<HugeCTR::DataReader<long long>, std::default_delete<HugeCTR::DataReader<long long> > >&, std::unique_ptr<HugeCTR::DataReader<long long>, std::default_delete<HugeCTR::DataReader<long long> > >&, std::vector<std::unique_ptr<HugeCTR::Embedding<long long>, std::default_delete<HugeCTR::Embedding<long long> > >, std::allocator<std::unique_ptr<HugeCTR::Embedding<long long>, std::default_delete<HugeCTR::Embedding<long long> > > > >&, std::vector<std::unique_ptr<HugeCTR::Network, std::default_delete<HugeCTR::Network> >, std::allocator<std::unique_ptr<HugeCTR::Network, std::default_delete<HugeCTR::Network> > > >&, std::shared_ptr<HugeCTR::GPUResourceGroup> const&, nlohmann::basic_json<std::map, std::vector, std::string, bool, long, unsigned long, double, std::allocator, nlohmann::adl_serializer>, unsigned long, bool, float)':\r\nparser.cpp:(.text+0xc233): undefined reference to `HugeCTR::EmbeddingCreator::create_localized_sparse_embedding_hash(std::vector<std::shared_ptr<HugeCTR::Tensor<long long> >, std::allocator<std::shared_ptr<HugeCTR::Tensor<long long> > > > const&, std::vector<std::shared_ptr<HugeCTR::Tensor<long long> >, std::allocator<std::shared_ptr<HugeCTR::Tensor<long long> > > > const&, HugeCTR::SparseEmbeddingHashParams_, std::string, std::shared_ptr<HugeCTR::GPUResourceGroup> const&)'\r\n../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `void HugeCTR::create_pipeline_internal<unsigned int>(std::unique_ptr<HugeCTR::DataReader<unsigned int>, std::default_delete<HugeCTR::DataReader<unsigned int> > >&, std::unique_ptr<HugeCTR::DataReader<unsigned int>, std::default_delete<HugeCTR::DataReader<unsigned int> > >&, std::vector<std::unique_ptr<HugeCTR::Embedding<unsigned int>, std::default_delete<HugeCTR::Embedding<unsigned int> > >, std::allocator<std::unique_ptr<HugeCTR::Embedding<unsigned int>, std::default_delete<HugeCTR::Embedding<unsigned int> > > > >&, std::vector<std::unique_ptr<HugeCTR::Network, std::default_delete<HugeCTR::Network> >, std::allocator<std::unique_ptr<HugeCTR::Network, std::default_delete<HugeCTR::Network> > > >&, std::shared_ptr<HugeCTR::GPUResourceGroup> const&, nlohmann::basic_json<std::map, std::vector, std::string, bool, long, unsigned long, double, std::allocator, nlohmann::adl_serializer>, unsigned long, bool, float)':\r\nparser.cpp:(.text+0x10df3): undefined reference to `HugeCTR::EmbeddingCreator::create_localized_sparse_embedding_hash(std::vector<std::shared_ptr<HugeCTR::Tensor<unsigned int> >, std::allocator<std::shared_ptr<HugeCTR::Tensor<unsigned int> > > > const&, std::vector<std::shared_ptr<HugeCTR::Tensor<unsigned int> >, std::allocator<std::shared_ptr<HugeCTR::Tensor<unsigned int> > > > const&, HugeCTR::SparseEmbeddingHashParams_, std::string, std::shared_ptr<HugeCTR::GPUResourceGroup> const&)'\r\n../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `HugeCTR::DataReader<long long>::create_heap_workers_()':\r\nparser.cpp:(.text._ZN7HugeCTR10DataReaderIxE20create_heap_workers_Ev[_ZN7HugeCTR10DataReaderIxE20create_heap_workers_Ev]+0x6f1): undefined reference to `tensorflow::io::RecordReaderOptions::CreateRecordReaderOptions(std::string const&)'\r\n../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `HugeCTR::DataReader<unsigned int>::create_heap_workers_()':\r\nparser.cpp:(.text._ZN7HugeCTR10DataReaderIjE20create_heap_workers_Ev[_ZN7HugeCTR10DataReaderIjE20create_heap_workers_Ev]+0x6f1): undefined reference to `tensorflow::io::RecordReaderOptions::CreateRecordReaderOptions(std::string const&)'\r\n../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `HugeCTR::TFrecordFileSource::process_features(float*)':\r\nparser.cpp:(.text._ZN7HugeCTR18TFrecordFileSource16process_featuresEPf[_ZN7HugeCTR18TFrecordFileSource16process_featuresEPf]+0x41): undefined reference to `tensorflow::io::RecordReader::ReadRecord(unsigned long long*, std::string*)'\r\nparser.cpp:(.text._ZN7HugeCTR18TFrecordFileSource16process_featuresEPf[_ZN7HugeCTR18TFrecordFileSource16process_featuresEPf]+0x36a): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&)'\r\nparser.cpp:(.text._ZN7HugeCTR18TFrecordFileSource16process_featuresEPf[_ZN7HugeCTR18TFrecordFileSource16process_featuresEPf]+0x1259): undefined reference to `google::protobuf::io::CodedInputStream::ReadString(std::string*, int)'\r\n../../lib/libhuge_ctr_static.a(parser.cpp.o): In function `HugeCTR::TFrecordFileSource::next_source()':\r\nparser.cpp:(.text._ZN7HugeCTR18TFrecordFileSource11next_sourceEv[_ZN7HugeCTR18TFrecordFileSource11next_sourceEv]+0x54): undefined reference to `tensorflow::Env::NewRandomAccessFile(std::string const&, std::unique_ptr<tensorflow::RandomAccessFile, std::default_delete<tensorflow::RandomAccessFile> >*)'\r\ncollect2: error: ld returned 1 exit status\r\nutest/parser/CMakeFiles/parser_test.dir/build.make:110: recipe for target 'bin/parser_test' failed\r\nmake[2]: *** [bin/parser_test] Error 1\r\nCMakeFiles/Makefile2:1781: recipe for target 'utest/parser/CMakeFiles/parser_test.dir/all' failed\r\nmake[1]: *** [utest/parser/CMakeFiles/parser_test.dir/all] Error 2\r\nMakefile:129: recipe for target 'all' failed\r\nmake: *** [all] Error 2", "comments": ["i solve this problem by  using **_cmake -DCMAKE_CXX_COMPILER=$(which g++) -DCMAKE_C_COMPILER=$(which gcc) -DCMAKE_BUILD_TYPE=Release -DSM=61 .._**  when cmake\uff0cand  make successfully", "@TSrain \r\n\r\nGlad to know that issue was resolved.Please, close this thread as your issue was resolved.Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42216\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42216\">No</a>\n"]}, {"number": 42214, "title": "TfLiteFlexDelegate invoke failed\uff01", "body": "**System information**\r\n- OS Platform and Distribution : MacOS TFLiteConverter ->TFLiteModel \r\n   && Android TF C++ library with FlexDelegate\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (or github SHA if from source): tf-nightly 2.4.0\r\n- Python version: 3.7\r\n- CPU version\r\n\r\n**TfliteConverter part**\r\nWe have a deeplabv3+ model with resnetv2-101 base-architecture, and we have successfully converted it to tflite model based on tf-nightly 2.4 version\u3002here is the python code\uff1a \r\n  ```\r\n     model = tf.saved_model.load(saved_model_dir)\r\n\r\n    concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\n\r\n    concrete_func.inputs[0].set_shape([1, 257, 257, 3])\r\n\r\n    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\n\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\n    converter.allow_custom_ops = True\r\n\r\n    converter.experimental_new_converter = True\r\n\r\n    tflite_model = converter.convert()\r\n\r\n    open('model_tflite.tflite', 'wb').write(tflite_model)\r\n\r\n```\r\n**Then we build TF C++ library with FlexDelegate, and we got libtensorflow_flex.so.**\r\n   \r\nHere is the C++ test code :\r\n\r\n```\r\n   TfLiteModel *model = TfLiteModelCreate(modelPath);\r\n\r\n    options = TfLiteInterpreterOptionsCreate();\r\n\t\r\n    TfLiteInterpreterOptionsSetNumThreads(options, 4);\r\n\r\n    interpreter = TfLiteInterpreterCreate(model, options);\r\n\r\n    TfLiteStatus status = TfLiteInterpreterAllocateTensors(interpreter);\r\n\r\n    TfLiteTensor *input_tensor = TfLiteInterpreterGetInputTensor(interpreter, 0);\r\n\r\n    TfLiteStatus cpystatus = TfLiteTensorCopyFromBuffer(input_tensor, inputData, input_tensor->bytes);\r\n\r\n    TfLiteStatus status = TfLiteInterpreterInvoke(interpreter);\r\n```\r\n\r\nBut we will get an error when executing the invoke\uff1a\r\n\r\n```\r\n2020-08-11 10:17:44.612 14278-15583/com.kimguo.tensorflow2 I/tflite: Initialized TensorFlow Lite runtime.\r\n2020-08-11 10:17:44.621 14278-15583/com.kimguo.tensorflow2 I/tflite: Created TensorFlow Lite delegate for select TF ops.\r\n2020-08-11 10:17:44.623 14278-14278/com.kimguo.tensorflow2 E/GraphicExt: GraphicExtModuleLoader::CreateGraphicExtInstance false\r\n2020-08-11 10:17:44.625 14278-14307/com.kimguo.tensorflow2 D/Surface: Surface::connect(this=0xe3eac000,api=1)\r\n2020-08-11 10:17:44.626 14278-15583/com.kimguo.tensorflow2 I/tflite: TfLiteFlexDelegate delegate: 5 nodes delegated out of 241 nodes with 3 partitions.\r\n2020-08-11 10:17:44.630 14278-14307/com.kimguo.tensorflow2 D/mali_winsys: EGLint new_window_surface(egl_winsys_display *, void *, EGLSurface, EGLConfig, egl_winsys_surface **, EGLBoolean) returns 0x3000\r\n2020-08-11 10:17:44.631 14278-14307/com.kimguo.tensorflow2 D/Surface: Surface::setBufferCount(this=0xe3eac000,bufferCount=3)\r\n2020-08-11 10:17:44.633 14278-14307/com.kimguo.tensorflow2 D/Surface: Surface::allocateBuffers(this=0xe3eac000)\r\n2020-08-11 10:17:44.709 14278-15583/com.kimguo.tensorflow2 I/tflite: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.\r\n2020-08-11 10:17:44.709 14278-15583/com.kimguo.tensorflow2 I/tflite: TfLiteFlexDelegate delegate: 2 nodes delegated out of 9 nodes with 2 partitions.\r\n2020-08-11 10:17:44.823 14278-15583/com.kimguo.tensorflow2 W/native: op_kernel.cc:1772 OP_REQUIRES failed at tensor_array_ops.cc:1035 : Not found: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)\r\n2020-08-11 10:17:44.823 14278-15583/com.kimguo.tensorflow2 E/tflite: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)\r\n    \t (while executing 'TensorArrayScatterV3' via Eager)\r\n2020-08-11 10:17:44.824 14278-15583/com.kimguo.tensorflow2 E/tflite: Node number 241 (TfLiteFlexDelegate) failed to invoke.\r\n```\r\n **There are some flex operators in our model\uff0csuch as \u201cFlexTensorArrayV3\u201d\uff0c\u201cFlexTensorArrayScatterV3\u201d,\r\n\u201cFlexTensorArraySizeV3\u201d\uff0c\u201cFlexTensorArrayGatherV3\u201d.. and I can find them from allowlisted_flex_ops.cc.  They can be well \u201cAllocate\u201d, But when \"invoke\", this error will be prompted\uff0cDoes anyone have a problem like this\uff1f**\u3002\r\n\r\n", "comments": ["@MannyKai \r\nI am unable to replicate the issue faced due to indentation error in code shared, can you please provide a colab gist with the error for us to analyse.", "> @MannyKai\r\n> I am unable to replicate the issue faced due to indentation error in code shared, can you please provide a colab gist with the error for us to analyse.\r\n\r\nThe code is whole test code\u3002\r\nDoes tensorflow lite c library support flex op well \uff1f", "@MannyKai \r\nPlease refer to [this link](https://www.tensorflow.org/lite/guide/ops_select#c) and let us know if it helps.", "I compiled `benchmark_model_plus_flex` and ran into the same issue. I was trying to benchmark the following model:\r\n\r\n<http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz>\r\n\r\nconverted into TFLite format with the following code:\r\n\r\n```python\r\ndef do_convert(saved_model, output_file):\r\n    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model)\r\n    converter.target_spec.supported_ops = [\r\n        tf.lite.OpsSet.TFLITE_BUILTINS,\r\n        tf.lite.OpsSet.SELECT_TF_OPS,\r\n    ]\r\n    model = converter.convert()\r\n    with open(output_file, \"wb\") as f:\r\n        f.write(model)\r\n```\r\n\r\nThe exact error is\r\n\r\n```text\r\nnative : op_kernel.cc:1763 OP_REQUIRES failed at tensor_array_ops.cc:1035 : Not found: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_774)\r\nERROR: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_774)\r\n         (while executing 'TensorArrayScatterV3' via Eager)\r\nERROR: Node number 276 (TfLiteFlexDelegate) failed to invoke.\r\n```\r\n\r\nand the command line is\r\n\r\n```shell\r\n./benchmark_model_plus_flex --graph=ssd_mobilenet_v1_coco_2018_01_28.tflite\r\n```\r\n\r\nI compiled TF master branch (was 4625f1d87f17537a8d50dc68a213d2da875c12ce) using SDK 30.0.2 and NDK r21d.\r\n\r\nAny help?"]}, {"number": 42213, "title": "tf.nn.max_pool3d crashes(floating point exception) when strides=0", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.6.9\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n`tf.nn.max_pool3d` crashes(floating point exception) when `input` is of type `np.float16` **AND** `strides=0` **AND** `padding='SAME'`\r\n\r\n**Describe the expected behavior**\r\nexpect no crashes\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n~~~python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ninput = tf.ones((1,1,1,1,1), dtype=np.float16)\r\ntf.nn.max_pool3d(input=input, ksize=1, strides=0, padding='SAME')\r\n~~~\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n~~~python\r\nFloating point exception (core dumped)\r\n~~~", "comments": ["@DNXie \r\n\r\nI tried in colab and i am not seeing any issue if we give give `stride >0` in code.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/a7183951523b0c440a894f53267c1e80/untitled237.ipynb).\r\nbut  `tf.nn.max_pool3d` crashes(floating point exception) when input is of type np.float16 AND strides=0 AND padding='SAME'.\r\n\r\nThanks!", "I am able to reproduce the issue in colab with TF 2.3, nightly versions(`2.4.0-dev20200810`).Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/b1538e804cb9ede63700c745e895c179/untitled238.ipynb).Thanks!", "@DNXie,\r\n1. We shouldn't set **`strides = 0`** neither in `Convolutional Layers` nor in `Pooling Layers`, as the minimum `Striding Window` should be of Size 1. \r\n2. Regarding the Input with **`Data Type`**, **`float16`**, the Model works fine if we use [Keras Mixed Precision Experimental Policy](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/Policy#how_to_use_mixed_precision_in_a_keras_model_2). Please find the [Gist with working code](https://colab.research.google.com/gist/rmothukuru/d4890716e32a22c21633716e132c26dd/untitled238.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42213\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42213\">No</a>\n", "@rmothukuru Thanks for the clarification! Though an exception sounds better than crash (segfault) :)"]}, {"number": 42212, "title": "tf.random.learned_unigram_candidate_sampler crashes(segfault) when true_classes contain large value", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.7.6\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n`tf.random.learned_unigram_candidate_sampler` crashes(segfault) when `true_classes` containa large value AND `num_true=rank(true_classes)[-1]`.\r\n\r\n**Describe the expected behavior**\r\nexpect no crashes\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n~~~python\r\nimport tensorflow as tf\r\ntrue_classes = [[1, 100000]]  # shape(1,2)\r\nnum_true = 2\r\ntf.random.learned_unigram_candidate_sampler(true_classes=true_classes, num_true=num_true, num_sampled=10, unique=False, range_max=1)\r\n~~~\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n~~~python\r\nSegmentation fault (core dumped)\r\n~~~", "comments": ["@DNXie,\r\nI was able to run the code without any issues on [TF v2.1](https://colab.research.google.com/gist/amahendrakar/ccf6ef3fea0c7a952867fc34d02ff0a1/42212-2-1.ipynb), [TF v2.3](https://colab.research.google.com/gist/amahendrakar/eb8091c6fed7dc4a5eb7fc8300cca5d7/42212.ipynb#scrollTo=OtuJ_qBYFRri) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/50618d2fba1e9b1f3f1a9411e25e84ba/42212.ipynb). Please find the attached gist.\r\n\r\nCould you please update TensorFlow to v2.3 or try running the code in a virtual environment and check if you are facing the same issue? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42211, "title": "/usr/bin/env: 'python': No such file or directory", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Built from Github source\r\n- TensorFlow version: Latest (2.2)\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: No virtual or conda used\r\n- Bazel version (if compiling from source): 3.4.1\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\nIssue \"Tensorflow does not build in a python3 only environment #15618\" is still a problem. \r\n\r\nRather than have to trawl through google posts and forums to find a solution it would be preferable if the build instructions mentioned the simple work-around of creating a Sym link to Python3 using the following\r\n\r\nsudo link /usr/bin/python3 /usr/bin/python\r\n\r\n", "comments": ["@leematthewshome \r\nPlease provide with all details/steps followed before the issue was faced, including the error log for us to analyse.", "This is a bazel issue, not TF", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42211\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42211\">No</a>\n"]}, {"number": 42210, "title": "module 'tensorflow' has no attribute 'get_default_graph'", "body": "Hello, I have a problem when I run a github code.\r\n\r\nInstalled using pip: tensorflow version = 2.3.0\r\n\r\nkeras = 2.2.4\r\n\r\nI imported so\r\n\r\n_`import keras`_\r\n\r\nand use these methods\r\n\r\n keras.utils.get_file\r\n\r\n````\r\nimport keras\r\n\r\nfrom .models.all_models import model_from_name\r\n\r\n\r\ndef model_from_checkpoint_path(model_config, latest_weights):\r\n\r\n    model = model_from_name[model_config['model_class']](\r\n        model_config['n_classes'], input_height=model_config['input_height'],\r\n        input_width=model_config['input_width'])\r\n    model.load_weights(latest_weights)\r\n    return model\r\n\r\n\r\ndef resnet_pspnet_VOC12_v0_1():\r\n```\r\n\r\n    model_config = {\r\n        \"output_height\": 96,\r\n        \"input_height\": 384,\r\n        \"input_width\": 576,\r\n        \"n_classes\": 151,\r\n        \"model_class\": \"resnet50_pspnet\",\r\n        \"output_width\": 144\r\n    }\r\n\r\n    REPO_URL = \"https://github.com/divamgupta/image-segmentation-keras\"\r\n    MODEL_PATH = \"pretrained_model_1/r2_voc12_resnetpspnet_384x576.24\"\r\n    model_url = \"{0}/releases/download/{1}\".format(REPO_URL, MODEL_PATH)\r\n    latest_weights = keras.utils.get_file(model_url.split(\"/\")[-1], model_url)\r\n\r\n    return model_from_checkpoint_path(model_config, latest_weights)`\r\n\r\n\r\nDoes anyone know another way for me to run this code?", "comments": ["@Caioww \r\n\r\nRequest you to share colab link or complete code snippet to reproduce the issue in our environment.It helps us in localizing the issue faster.\r\n\r\nAlso, refer [link1](https://stackoverflow.com/questions/61123134/module-tensorflow-has-no-attribute-get-default-graph-with-stocks-prediction), [link2 ](https://stackoverflow.com/questions/55496289/how-to-fix-attributeerror-module-tensorflow-has-no-attribute-get-default-gr) and see if it helps you.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42210\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42210\">No</a>\n"]}, {"number": 42209, "title": "Issue with batch size in backpropagation", "body": "I'm trying to implement a custom loss function related to Triplet Loss. Triplet loss has a provision to give custom distance metric, that returns pairwise distances between embeddings. I have defined a custom function that works fine on forward-propagation. But on backpropagation (that is what I assume ) it is throwing some error. Following is the error.\r\n\r\n`InvalidArgumentError:  slice index 16 of dimension 1 out of bounds.\r\n [[{{node TripletSemiHardLoss/PartitionedCall/while_1/body/_226/while_1/strided_slice}}]] [Op:__inference_train_function_31232]\r\nFunction call stack: train_function\r\n`\r\n\r\n16 is the batch size,my input had. I'm not using any while loop in the custom code. However, there is a for loop.\r\n\r\nI have tried the following.\r\n\r\nI retrieve the batch size using tf.size(input). Works fine on forward prop.\r\nI have tried both while loop and for loop. On forward propagation, both are working fine. Both are producing same results. Yet on backprop, both are throwing the same error.\r\n\r\nA sample of the code if below. I retrieved batch size from input from a previously calling function. Bt below, I have also gathered the same value by calling tf.size(hist_values). That also supposed to give the batch size only. It does work on forward propagation. But on backprop ( I'm assuming , it is backprop only) , it fails.\r\n\r\n`@tf.function'\r\ndef divide_one_row(hist_values,result,row_num,batch_size):\r\n    reshaped = tf.reshape(hist_values[:,row_num],shape=(hist_values.shape[0],1))\r\n    duplicated = tf.repeat(reshaped,repeats=tf.size(hist_values),axis=1)\r\n    r = tf.math.divide_no_nan(duplicated,hist_values)\r\n    result = result.write(row_num,r)\r\n    \r\n    return hist_values,result,row_num+1,batch_size\r\n`\r\n` \r\n@tf.function\r\ndef get_division_matrix(hist_values,batch_size):\r\n        \r\n    i = tf.constant(0)\r\n    result = tf.TensorArray(tf.float32,size=0,dynamic_size=True,clear_after_read=False)\r\n    \r\n    for i in tf.range(tf.size(hist_values)):        \r\n        hist_values,result,_,batch_size = divide_one_row(hist_values,result,i,tf.size(hist_values))\r\n        \r\n    return result.stack()`\r\n\r\n\r\nFollowing is the entire error stack : \r\n\r\n`InvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-24-70c4ddc79f73> in <module>\r\n     11                            epochs=25,\r\n     12                            callbacks=[checkpoint],\r\n---> 13                            verbose=1)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    322               'in a future version' if date is None else ('after %s' % date),\r\n    323               instructions)\r\n--> 324       return func(*args, **kwargs)\r\n    325     return tf_decorator.make_decorator(\r\n    326         func, new_func, 'deprecated',\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1827         use_multiprocessing=use_multiprocessing,\r\n   1828         shuffle=shuffle,\r\n-> 1829         initial_epoch=initial_epoch)\r\n   1830 \r\n   1831   @deprecation.deprecated(\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1096                 batch_size=batch_size):\r\n   1097               callbacks.on_train_batch_begin(step)\r\n-> 1098               tmp_logs = train_function(iterator)\r\n   1099               if data_handler.should_sync:\r\n   1100                 context.async_wait()\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    838         # Lifting succeeded, so variables are initialized and we can run the\r\n    839         # stateless function.\r\n--> 840         return self._stateless_fn(*args, **kwds)\r\n    841     else:\r\n    842       canon_args, canon_kwds = \\\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2827     with self._lock:\r\n   2828       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 2829     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2830 \r\n   2831   @property\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)\r\n   1846                            resource_variable_ops.BaseResourceVariable))],\r\n   1847         captured_inputs=self.captured_inputs,\r\n-> 1848         cancellation_manager=cancellation_manager)\r\n   1849 \r\n   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1922       # No tape is watching; skip to running the function.\r\n   1923       return self._build_call_outputs(self._inference_function.call(\r\n-> 1924           ctx, args, cancellation_manager=cancellation_manager))\r\n   1925     forward_backward = self._select_forward_and_backward_functions(\r\n   1926         args,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    548               inputs=args,\r\n    549               attrs=attrs,\r\n--> 550               ctx=ctx)\r\n    551         else:\r\n    552           outputs = execute.execute_with_cancellation(\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nInvalidArgumentError:  slice index 16 of dimension 1 out of bounds.\r\n\t [[{{node TripletSemiHardLoss/PartitionedCall/PartitionedCall/PartitionedCall_1/while/body/_258/while/PartitionedCall/strided_slice}}]] [Op:__inference_train_function_42705]\r\n\r\nFunction call stack:\r\ntrain_function\r\n`\r\n\r\n", "comments": ["Could this be because of this part?\r\n\r\nhist_values[:,row_num] in the function. Should tf.slice be used here?", "Closing this. The issue was indeed due to the numpy style array slicing. Using tf.slice resolved the issue."]}, {"number": 42208, "title": "tf.nn.conv2d crashes(Floating_Point_Exception) when there is 0 in filters.shape", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.6.9\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n`tf.nn.conv2d` crashes(Floating_Point_Exception) when any of the first three dimensions of `filters.shape`(4D) is 0\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n~~~python\r\nimport tensorflow as tf\r\ntf.nn.conv2d(input=tf.ones((1,1,1,1)), filters=tf.ones((1,1,0,1)), strides=1, padding='SAME')\r\n~~~\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n~~~python \r\nFloating point exception (core dumped)\r\n~~~", "comments": ["@DNXie  \r\nThe colab session crashes when we run the above shared code.\r\n\r\non making changes to your code, it works fine, please refer to the [gist here](https://colab.research.google.com/gist/Saduf2019/580da863441ecef38e95e8590a376285/untitled361.ipynb)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42208\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42208\">No</a>\n"]}, {"number": 42206, "title": "tf.nn.avg_pool3d crashes (floating point exception) in NDHWC mode", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.6.9\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n`tf.nn.avg_pool3d` crashes (floating point exception) when `data_format` = NDHWC AND 0 in input.shape, such as `(1,1,0,1,1)`.  Related #42205\r\n\r\n**Describe the expected behavior**\r\nexpect no crashes\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n~~~python\r\nimport tensorflow as tf\r\ninput=tf.ones((1,1,0,1,1))\r\ntf.nn.avg_pool3d(input=input,ksize=1,strides=1,padding='SAME', data_format='NDHWC')\r\n~~~\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n~~~python\r\nFloating point exception (core dumped)\r\n~~~\r\n\r\nRelated #42205", "comments": ["@DNXie,\r\nI was able to reproduce the issue with TF v2.1. However, with TF v2.3 I was able to run the code without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/c902187922a31c2a1223141677105020/42206.ipynb). Thanks!", "@amahendrakar  Seems like it is fixed in the nightly version.", "@DNXie,\r\nThank you for the update. Marking this issue as closed since it is resolved. Please feel free to re-open the issue if necessary. "]}]