[{"number": 54865, "title": "[mlir/tfg] Avoid name collision for identity node in the const dedupe hoist pass.", "body": "[mlir/tfg] Avoid name collision for identity node in the const dedupe hoist pass.\n\nAdding an Identity node with the same name as a constant makes the MLIR TFG export to the GraphDef fail.\nLet the name have `const_dedupe_hoist/` prefix followed by the const name. There is still a chance that this will lead to collision, but the surface is very limited.\nIt might worth to consider better unique name generation to avoid collisions, I left a TODO to address this.\n", "comments": []}, {"number": 54864, "title": "Internal experimental change.", "body": "Internal experimental change.\n", "comments": []}, {"number": 54863, "title": "[mhlo] Verifier for mhlo.BatchNormGradOp", "body": "[mhlo] Verifier for mhlo.BatchNormGradOp\n", "comments": []}, {"number": 54862, "title": "WIP fix random_index_shuffle_ops", "body": "WIP fix random_index_shuffle_ops\n", "comments": []}, {"number": 54861, "title": "Add set_tpu_infeed_layout.h and set_tpu_infeed_layout.cc.", "body": "Add set_tpu_infeed_layout.h and set_tpu_infeed_layout.cc.\n", "comments": []}, {"number": 54860, "title": "Change Redzone space limit for XLA GPU", "body": "This PR changes how the redzone space limit is set in the XLA gpu conv algorithm picker.\r\n1. It sets the numeric max of int64 for the input/output allocator. So, we can have consistent behavior with the gemm picker.\r\n2. It allows the adjustment of the space limit for the scratch allocator via an env var. So, users can adjust it via `XLA_FLAGS=--xla_gpu_redzone_scratch_max_megabytes=6144`.\r\n\r\ncc. @nluehr ", "comments": ["Hi @kaixih , could you provide some more context on what is the desired goal?", "@cheshire Sure. Basically, we found that the max space limit of redzone allocator for the XLA conv is set to be 4GB, which is insufficient for some models that expect large input/output tensors. In addition, we also noticed that this limit is not adjustable during runtime. So, compared to the XLA gemm, which has already set the limit of the input/output redzone allocator to the numeric max of int, we think it might be appropriate to follow it for the XLA conv. Moreover, we introduced a new env var to control the scratch redzone allocator max limit as well in case it needs to be adjusted.", "@cheshire Can you help check what blocks the merging? It seems some \"Google internal checks\" failed. Thanks.", "There was a merge conflict in xla.proto, you used the same tag as was already used in a recent change. I fixed that and got your PR merged.", "Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR."]}, {"number": 54859, "title": "Export more missing pybind simbols from op_def_util for windows builds.", "body": "Export more missing pybind simbols from op_def_util for windows builds.\n", "comments": []}, {"number": 54858, "title": "Inference output shape for tfl.reshape if `shape` is constant", "body": "Inference output shape for tfl.reshape if `shape` is constant\n", "comments": []}, {"number": 54857, "title": "Error while creating the wheel file for Raspberry pi. ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Build target = Raspberry Pi\r\n- TensorFlow version: 2.5.2\r\n- Python version: 3.8\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI tried creating the TensorFlow wheel file and was getting failed as it was unable to find the updates from [http://security.ubuntu.com/ubuntu/dists/xenial-security/main/binary-armhf/Packages](http://security.ubuntu.com/ubuntu/dists/xenial-security/main/binary-armhf/Packages) (No Xenial security branch)\r\n\r\n\r\n\r\n", "comments": ["@DeepakRamchandani1,\r\n\r\nWe see that the issue [template]( https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyze the issue [steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced and complete stack trace]. Thanks!\r\n\r\nCan you please install dependencies as mentioned in this [thread](https://github.com/PINTO0309/Tensorflow-bin#usage), may help you. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54857\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54857\">No</a>\n"]}, {"number": 54856, "title": "`tf.experimental.numpy.floor_divide` is inconsistent with numpy version when divide by zero", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nprint(np.floor_divide(0,0)) # Outputs 0\r\nprint(tf.experimental.numpy.floor_divide(0,0 )) # InvalidArgumentError: Integer division by zero [Op:FloorDiv]\r\n```\r\n\r\n**Describe the current behavior**\r\n[`tf.experimental.numpy.floor_divide`](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/floor_divide)  is TF's version of [numpy.floor_div](https://numpy.org/doc/stable/reference/generated/numpy.floor_divide.html?highlight=floor_div#numpy.floor_divide), and users would expect them to have the same behavior. In the special case of divide by zero, `numpy.floor_div` would throw `RuntimeWarning` but still give `0` as output, but `tf.experimental.numpy.floor_divide` would throw an error. \r\n\r\n\r\n**Describe the expected behavior**\r\nExpect  `tf.experimental.numpy.floor_divide`  to output `0`, consistent with `numpy.floor_divide`", "comments": ["Hi @chunduriv ! Could you please look at this issue? It is replicating in [2.7](https://colab.sandbox.google.com/gist/mohantym/d0fe070770a41fe3f114a1304f705dab/github_54856.ipynb#scrollTo=FNeG5wKCenf6), [2.8](https://colab.sandbox.google.com/gist/mohantym/07d3d19b45c1ceb4bb30a08216c32bdd/github_54856.ipynb#scrollTo=FNeG5wKCenf6) and [nightly](https://colab.sandbox.google.com/gist/mohantym/01ff188588ad69d85ae5b7b668d2ba6c/github_54856.ipynb#scrollTo=FNeG5wKCenf6)(2.9.0dev).", "I am not able to reproduce the same if i run as below \r\n\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nimport numpy as np\r\nprint(tf.experimental.numpy.floor_divide(0,0 )) # InvalidArgumentError: Integer division by zero [Op:FloorDiv]\r\n```\r\n\r\ncan you please check ", "Hi @rthadur , if I run the code in your comment, I can reproduce the issue (it throws InvalidArgumentError). Could you please provide which version of TF are you using, and what is the output you get?", "@ArrowIntoTheSky,\r\n\r\nThis is an intended behavior and the same can also be seen in all cases mentioned below\r\n\r\nUsing `math` module\r\n\r\n```\r\nimport math\r\nmath.floor(0/0)\r\n```\r\n\r\noutput:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nZeroDivisionError                         Traceback (most recent call last)\r\n[<ipython-input-1-054651c01b6b>](https://localhost:8080/#) in <module>()\r\n      1 import math\r\n      2 \r\n----> 3 math.floor(0/0)\r\n\r\nZeroDivisionError: division by zero\r\n```\r\n\r\nUsing Python\r\n\r\n`print('Floor value for 0/0:',0//0)  \r\n`\r\nOutput:\r\n```\r\n---------------------------------------------------------------------------\r\nZeroDivisionError                         Traceback (most recent call last)\r\n[<ipython-input-4-9fb0c9205c59>](https://localhost:8080/#) in <module>()\r\n----> 1 print('Floor value for 0/0:',0//0)\r\n\r\nZeroDivisionError: integer division or modulo by zero\r\n```\r\n\r\nUsing `tf.math.floordiv`\r\n\r\n```\r\nx=0\r\ny=0\r\ntf.math.floordiv( x, y, name=None)\r\n```\r\nOutput:\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-12-e18cb5fc9e77> in <module>()\r\n      3 y=0\r\n      4 tf.math.floordiv(\r\n----> 5     x, y, name=None\r\n      6 )\r\n\r\n1 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)\r\n   7184 def raise_from_not_ok_status(e, name):\r\n   7185   e.message += (\" name: \" + name if name is not None else \"\")\r\n-> 7186   raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\n   7187 \r\n   7188 \r\n\r\nInvalidArgumentError: Integer division by zero [Op:FloorDiv]\r\n```", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54856\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54856\">No</a>\n"]}, {"number": 54855, "title": "`tf.raw_ops.RGBToHSV` lack support for bfloat16", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimages = tf.random.uniform([1, 1, 3], dtype=tf.bfloat16)\r\ntf.raw_ops.RGBToHSV(images=images)\r\n```\r\nthrows error:\r\n```\r\nNotFoundError: Could not find device for node: {{node RGBToHSV}} = RGBToHSV[T=DT_BFLOAT16]\r\nAll kernels registered for op RGBToHSV:\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n [Op:RGBToHSV]\r\n```\r\n**Describe the current behavior**\r\n[`tf.raw_ops.RGBToHSV`](https://www.tensorflow.org/api_docs/python/tf/raw_ops/RGBToHSV) should support half, bfloat16, float32, float64 according to the document.", "comments": ["@chunduriv Was able to replicate the issue on colab using TF v2.8.0 and tf-nightly(2.9.0.dev20220303), please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/edac82db0255229e1a8a06989716e6d9/54855.ipynb#scrollTo=BxmihNCvCOid).Thanks!", "Added a PR #54972 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54855\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54855\">No</a>\n"]}, {"number": 54853, "title": "Check that the Support lib struct functions are not null.", "body": "Check that the Support lib struct functions are not null.\n", "comments": []}, {"number": 54852, "title": "Add tests to ensure that all cc_library rules are self-contained,", "body": "Add tests to ensure that all cc_library rules are self-contained,\ni.e. don't have any references to undefined symbols,\nunless they are tagged with 'allow_undefined_symbols'.\n", "comments": []}, {"number": 54851, "title": "`tf.ragged.segment_ids_to_row_splits` lack check for `out_type`", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nsegment_ids = [0,0,0,2,2,3,4,4,4]\r\nres=tf.ragged.segment_ids_to_row_splits(segment_ids, out_type=1) # pass\r\nprint(res)\r\n```\r\n\r\n**Describe the current behavior**\r\n[`tf.ragged.segment_ids_to_row_splits`](https://www.tensorflow.org/api_docs/python/tf/ragged/segment_ids_to_row_splits?hl=en) should check `out_type` is a valid DType. In the example code, `out_typt` is `1`, so it should raise an error instead of silently pass.", "comments": ["@chunduriv ,\r\nI was able to reproduce the issue in tf v2.8, v2.7 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/becdc149d8a4b7976fb2a19920100e56/54851.ipynb).", "@yongtang can you look into this as this should have been solved in https://github.com/tensorflow/tensorflow/pull/54441 however the issue is being reproduced. If not I can add the necessary python validations", "The `out_type` relies on `tf.dtypes.as_dtype` for dtype validation. In case of integer, out_type will inteperete the integer as enum of the dtype (`enum 1 == float32`), so a float32 is taken:\r\nhttps://www.tensorflow.org/api_docs/python/tf/dtypes/as_dtype\r\n\r\nOverall, passing `1` is working as expected in this case.", "Thanks @yongtang ! I didn't know that before!\r\nI will close this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54851\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54851\">No</a>\n"]}, {"number": 54850, "title": "Add SetTypeConstructor to \"Const\" op and fix \"Merge\" forward type inference", "body": "Add SetTypeConstructor to \"Const\" op and fix \"Merge\" forward type inference\n\nThe \"Merge\" op has two outputs. The second output is an int32 \"value_index\". (See core/ops/control_flow_ops.cc) Add this second output to the fulltype created by the full_type::Merge() forward type inference function. (Now that \"Const\" has a fulltype, core/grappler/optimizers:constant_folding_test uses the forward type inference function of \"Merge\".)\n\nThe `dtype` attribute is now required by the type constructor. Update the Const_ShapeFn test in array_ops_text.cc so that the \"Const\" op it creates has a `dtype` attribute.\n\nUpdate TestAddShapes in ops_test.py to expect \"Const\" op to have fulltype.\n", "comments": []}, {"number": 54847, "title": "Make \"cc_api_stable\" target self-contained.", "body": "Make \"cc_api_stable\" target self-contained.\n\nIn particular, move core/subgraph.cc from \"srcs\" of \"cc_api_experimental\" to\n\"srcs\" of \"cc_api_stable\" (which cc_api_experimental depends on).  This is\nneeded since interpreter.cc and interpreter_builder.cc in \"cc_api_stable\"\ncall methods that are defined in core/subgraph.cc.\n", "comments": []}, {"number": 54846, "title": "Add tf.random.experimental.index_shuffle().", "body": "Add tf.random.experimental.index_shuffle().\n\nIt maps an index in [0, maxval] to a new random index in [0, maxval]. This allows users to suffle a list {0, 1, ..., n} without materializing the full list in memory.\n\nThe operation is stateless and does not use the global random seed. The current implementation only works on CPU.\n", "comments": []}, {"number": 54845, "title": "Remove `AsGraphDef` friend declaration in `DatasetBase`.", "body": "Remove `AsGraphDef` friend declaration in `DatasetBase`.\n\nThis is unnecessary since cl/365597208 and obsolete since cl/431944979.\n", "comments": []}, {"number": 54844, "title": "[XLA] Write Log2Ceiling in a more symmetric way", "body": "[XLA] Write Log2Ceiling in a more symmetric way\n", "comments": []}, {"number": 54843, "title": "[tf.data] Remove unused `ctx` parameter from `AsGraphDef`.", "body": "[tf.data] Remove unused `ctx` parameter from `AsGraphDef`.\n\nThis is unused as of cl/240419515 (then in third_party/tensorflow/core/kernels/data/dataset_utils.cc).\n", "comments": []}, {"number": 54842, "title": "[XLA] Cache both positive and negative instruction reuse information, and update it online as fusions occur (roll forward):", "body": "[XLA] Cache both positive and negative instruction reuse information, and update it online as fusions occur (roll forward):\n\nThe object of this change is to avoid quadratic behaviors in computing operand reuse: after this change, we should not repeatedly revisit operators in fusion computations.\n\nThe previous version of this change unintentionally changed the semantics, when it was supposed to be a pure optimization. The issue stemmed from a misreading of the semantics. The XLA fusion logic does not consider an argument to be reused if it appears on two different paths.\n\nInstead the definition is: \"an operand to a fusion is reused if an operator that reuses its arguments appears on any path from the root of the fusion to that operand\".\n", "comments": []}, {"number": 54841, "title": "Unexpected outputs in MaxPooling layer", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.8.0\r\n- Python version: 3.7.12\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: using CPU\r\n- GPU model and memory: using CPU\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen I passes NaN inputs to the MaxPooling2D layer, it returns a large negative values -3.4028235e+38. \r\n\r\n**Describe the expected behavior**\r\nNormally, it should return NaN values in the corresponding location, just like the other frameworks, i.e. Theano.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nhttps://colab.research.google.com/drive/13SEcY5Lzj9fLQTv-JSNWA7cgnirNWnh6?usp=sharing#scrollTo=gZUgM5985nJs\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@kelvinlyy ,\r\nPlease post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues).\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "> @kelvinlyy ,\r\n> Please post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues).\r\n> To know more refer to:\r\n> https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\n\r\nOk. I just posted this issue on keras-team/keras repo: https://github.com/keras-team/keras/issues/16158.\r\nAnd I will close this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54841\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54841\">No</a>\n"]}, {"number": 54840, "title": "Enable test that is passing now.", "body": "Enable test that is passing now.\n", "comments": []}, {"number": 54839, "title": "[tf.data] Remove unused `ctx` parameter from `AsGraphDef`.", "body": "[tf.data] Remove unused `ctx` parameter from `AsGraphDef`.\n\nThis is unused as of cl/240419515 (then in third_party/tensorflow/core/kernels/data/dataset_utils.cc).\n", "comments": []}, {"number": 54838, "title": "Wrap cuFFT/hipFFT enums in `wrapper::Enum<>`.", "body": "Wrap cuFFT/hipFFT enums in `wrapper::Enum<>`.\n\nAdd `hipfftSetAutoAllocation()`.\n\nRemove dead code.\n", "comments": []}, {"number": 54837, "title": "Clarified TensorDescriptor::CanCreateTensorWithShape to handle more data types.", "body": "Clarified TensorDescriptor::CanCreateTensorWithShape to handle more data types.\n", "comments": []}, {"number": 54836, "title": "Always copy result of DynamicBroadcastInDimOp", "body": "Always copy result of DynamicBroadcastInDimOp\n", "comments": []}, {"number": 54835, "title": "IndexError: tuple index out of range in tf.Model.fit()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **I am using a tutorial script, adapted for a custom dataset** (Tutorial: Training and evaluation with the built-in methods)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows11 Home (10.0.22000 Build 22000)**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **n.a**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **v1.12.1-71979-ge2609918a1c 2.9.0-dev20220301**\r\n- Python version: **Python 3.10.2**\r\n- Bazel version (if compiling from source): **n.a.**\r\n- GCC/Compiler version (if compiling from source): **n.a.**\r\n- CUDA/cuDNN version: **n.a.**\r\n- GPU model and memory: **n.a.**\r\n\r\n**Describe the current behavior**\r\ntf.model.fit() does not show any output and eventually generates an error:\r\n\r\n**Traceback (most recent call last):\r\n  File \"g:\\My Drive\\Personal\\Spider\\Datasets\\ModelEGame.py\", line 92, in <module>\r\n    history = model.fit(\r\n  File \"C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"C:\\Users\\jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 908, in __getitem__\r\n    return self._dims[key]\r\nIndexError: tuple index out of range**\r\n\r\n**Describe the expected behavior**\r\nThe model should get trained with the data provided.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.python.ops.numpy_ops import np_config\r\n\r\n# Create a dictionary describing the features.\r\nobserv = {\r\n        'data' : tf.io.FixedLenFeature([104], tf.int64),\r\n        'label' : tf.io.FixedLenFeature([], tf.int64) }\r\n\r\n# Parse the input tf.train.Example proto using the dictionary above.\r\ndef _map_function_1(example_proto):\r\n  return tf.io.parse_single_example(example_proto, observ)\r\n\r\ndef split_data_label(sample):\r\n    return sample['data'].astype('int16'), sample['label'].astype('int16')\r\n\r\n# Import End game data\r\ndef load_data() :\r\n    dataset = tf.data.TFRecordDataset('EndGsh.tfrecords')\r\n    parsed_dataset = dataset.map(_map_function_1)\r\n    parsed_and_split_datased = parsed_dataset.map(split_data_label)\r\n\r\n    DATASET_SIZE = 10000 # 2836995\r\n    train_size = int(0.7 * DATASET_SIZE)\r\n    val_size = int(0.10 * DATASET_SIZE)\r\n    test_size = int(0.20 * DATASET_SIZE)\r\n\r\n    parsed_and_split_datased = parsed_and_split_datased.shuffle(DATASET_SIZE)\r\n\r\n    train_dataset = parsed_and_split_datased.take(train_size)\r\n    tAv_dataset = parsed_and_split_datased.skip(train_size)\r\n    val_dataset = tAv_dataset.take(val_size)\r\n    test_dataset = tAv_dataset.skip(val_size)\r\n\r\n    return train_dataset, test_dataset, val_dataset\r\n\r\n# Define model\r\nnp_config.enable_numpy_behavior()\r\n\r\nmodel = keras.Sequential()\r\nmodel.add(keras.Input(shape=(104,)))\r\nmodel.add(layers.Dense(64, activation=\"relu\", name=\"end_game_in\"))\r\nmodel.add(layers.Dense(32, activation=\"relu\", name=\"end_game_h1\"))\r\nmodel.add(layers.Dense(16, activation=\"relu\", name=\"end_game_h2\"))\r\nmodel.add(layers.Dense(1, activation=\"relu\", name=\"end_game_out\"))\r\nmodel.summary()\r\n\r\ntrain_dataset , test_dataset, val_dataset = load_data()\r\n\r\nmodel.compile(\r\n    optimizer=keras.optimizers.RMSprop(),  # Optimizer\r\n    # Loss function to minimize\r\n    loss=keras.losses.SparseCategoricalCrossentropy(),\r\n    # List of metrics to monitor\r\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\r\n)\r\n\r\nprint(\"Fit model on training data\")\r\nx_train =[]\r\ny_train = []\r\ncount = 0\r\nfor it in train_dataset :\r\n    x , y = it\r\n    x_train.append(x.astype(\"float32\"))\r\n    y_train.append(y.astype(\"float32\"))\r\n    count += 1\r\n    if count % 5000 == 0:\r\n        print(\"Train: \", count)\r\n\r\nx_val =[]\r\ny_val = []\r\ncount = 0\r\nfor it in val_dataset :\r\n    x , y = it\r\n    x_val.append(x.astype(\"float32\"))\r\n    y_val.append(y.astype(\"float32\"))\r\n    count += 1\r\n    if count % 5000 == 0:\r\n        print(\"Val: \", count)\r\n\r\nhistory = model.fit(\r\n    x_train,\r\n    y_train,\r\n    batch_size=64,\r\n    epochs=5,\r\n    verbose=2,\r\n    # We pass some validation for\r\n    # monitoring validation loss and metrics\r\n    # at the end of each epoch\r\n    validation_data=(x_val, y_val),\r\n)\r\n\r\n# rest of script happens after the error\r\nhistory.history\r\n\r\n# Evaluate the model on the test data using `evaluate`\r\nprint(\"Evaluate on test data\")\r\n\r\nx_test =[]\r\ny_test = []\r\ncount = 0\r\nfor it in val_dataset :\r\n    x , y = it\r\n    x_test.append(x.astype(\"float32\"))\r\n    y_test.append(y.astype(\"float32\"))\r\n    count += 1\r\n    if count % 5000 == 0:\r\n        print(\"Test: \", count)\r\n\r\nresults = model.evaluate(x_test, y_test, batch_size=128)\r\nprint(\"test loss, test acc:\", results)\r\n\r\n# Generate predictions (probabilities -- the output of the last layer)\r\n# on new data using predict\r\nprint(\"Generate predictions for 3 samples\")\r\npredictions = model.predict(x_test[:3])\r\nprint(\"predictions shape:\", predictions.shape)\r\n```\r\n\r\nAny data set of x_train.shape() = (104,) y_train.shape() = () produces the same behavior. Script provided uses 10,000 examples, but lower and higher numbers produce same result.\r\n\r\n**Other info / logs**\r\n\r\nI have tested it in a different computer and got a similar (yet different) error:\r\n\r\n**Traceback (most recent call last):\r\n  File \"C:\\Users\\jordi\\Google Drive\\Personal\\Spider\\Datasets\\modelegame.py\", line 92, in <module>\r\n    history = model.fit(\r\n  File \"C:\\Users\\jordi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"C:\\Users\\jordi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 902, in __getitem__\r\n    return self._dims[key].value\r\nIndexError: list index out of range**", "comments": ["Hi @jormajo ! You seem to be using a older version (1.x ) version of Tensorflow which is not supported any more . Please try in latest version 2.8.  But I think  **y_train.shape() = ()** might be the issue here (as it is  trying to index from a invalid shape).\r\n\r\nPlease post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues) for further assitance.\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54835\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54835\">No</a>\n"]}, {"number": 54834, "title": "[mhlo][ShapeAnalysis] Don't drop static knowledge when creating an expand_shape", "body": "[mhlo][ShapeAnalysis] Don't drop static knowledge when creating an expand_shape\n\nI missed the static info from the input when propagating ones to the output shape.\n", "comments": []}, {"number": 54833, "title": "Split RNG pattern to HLO->Arith pass.", "body": "Split RNG pattern to HLO->Arith pass.\n\nIt does not allocate anything. It creates a bunch of arithmetic operations and\nloads/stores from a global memref.\n", "comments": []}]