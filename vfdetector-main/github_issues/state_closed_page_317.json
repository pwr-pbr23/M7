[{"number": 44706, "title": "tf concatination layers compatible with tfp", "body": "Since tfp does not have `tf.keras.layers.Concatenate` does tf2.x support Concatenation of tfp layers?\r\n\r\nIf some changes are required then what? ", "comments": ["If you can attach a toy example depicting the behavior that will be great addition for the completeness of this issue. Thanks!", "```\r\nx1=tfp.layers.DenseFlipout(x)\r\nx2=tfp.layers.DenseFlipout(x_)\r\nx4=tf.keras.layers.Concatenate(x1,x)\r\n```\r\nwith tf_2.3 is it possible\r\nif tfp=tensorflow probability", "Are you saying that this is working with TF 2.4 or are you running into issues when trying it?", "I have not tested yet.", "@maxkaustav  I tried to test  the code provided [here](https://github.com/tensorflow/tensorflow/issues/44706#issuecomment-727166273) with the  latest TF version 2.8 on Colab  .Could you please refer to this [gist](https://colab.research.google.com/gist/sushreebarsa/7837be233c5cc50441144d0af81262fe/untitled83.ipynb) and let us know if it helps?\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 44705, "title": "Actor-critic model with LSTM layers runs out of GPU memory eventhough it shouldn't.", "body": "- Custom code\r\n- Windows 10\r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.7.9\r\n- CUDA/cuDNN version: 10.1 / 7.6.5\r\n- GPU model and memory: GTX 1660 6GB\r\n\r\n\r\nNetworks with LSTM layers run out of memory, using only batch at a time. Creating smaller layers don't help.By my calculations they should easily fit into the memory.\r\n\r\nSource code to recreate the issue is the following (in a few places it uses bogus values, it was only created to test if there are issues with the fit function):\r\n\r\n`\r\nimport os\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers     import LSTM, Dense, Dropout, Input, concatenate, Lambda\r\nfrom tensorflow.keras            import activations\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.models     import Model\r\nimport tensorflow.keras.backend as K\r\n\r\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n\r\ndelta = Input(shape=[1])\r\n\r\ninput_vision = Input(shape=(2* 5+1,2* 5+1))\r\nfirst_branch = LSTM(1024)(input_vision)#Input layer of the 1. branch\r\nfirst_branch = Dropout(0.2)(first_branch)       #Dropout for the input layer\r\n\r\nfirst_branch = Dense(512, activation=activations.relu)(first_branch)       #First layer of the 1. branch\r\nfirst_branch = Dropout(0.2)(first_branch)\r\n\r\nfirst_branch = Dense(256, activation=activations.relu)(first_branch)       #Second layer of the 1. branch\r\nfirst_branch = Dropout(0.2)(first_branch)\r\n\r\nfirst_branch = Model(inputs=input_vision, outputs=first_branch)      #The output of the first branch\r\n\r\ninput_memory  = Input(shape=(100,3))\r\nsecond_branch = LSTM(1024)(input_memory)       #Input layer of the 2. branch\r\nsecond_branch = Dropout(0.2)(second_branch)     #Dropout for the input layer\r\n\r\nsecond_branch = Dense(512, activation=activations.relu)(second_branch)     #Second layer of the 2. branch\r\nsecond_branch = Dropout(0.2)(second_branch)     #Dropout for the first layer\r\n\r\nsecond_branch = Dense(256, activation=activations.relu)(second_branch)     #Third layer of the 2. branch\r\nsecond_branch = Dropout(0.2)(second_branch)     #Dropout for the first layer\r\n\r\nsecond_branch = Model(inputs=input_memory, outputs=second_branch)    #The output of the first branch\r\n\r\ninput_task   = Input(shape=(5, 6) )\r\nthird_branch = LSTM(1024)(input_task)    #Input layer of the 3. branch\r\nthird_branch = Dropout(0.2)(third_branch)       #Dropout for the input layer\r\n\r\nthird_branch = Dense(512, activation=activations.relu)(third_branch) #Second layer of the 3. branch\r\nthird_branch = Dropout(0.2)(third_branch)       #Dropout for the first layer\r\n\r\nthird_branch = Dense(256, activation=activations.relu)(third_branch) #Third layer of the 3. branch\r\nthird_branch = Dropout(0.2)(third_branch)       #Dropout for the first layer\r\n\r\nthird_branch = Model(inputs=input_task, outputs=third_branch)#The output of the first branch\r\n\r\n#Combine all 3 branches into one:\r\n#combined = tf.keras.backend.expand_dims(combined, axis=-1)\r\ncombined = concatenate([first_branch.output, second_branch.output, third_branch.output])\r\ncombined = Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(combined)\r\n\r\n#Main branch:\r\n\r\nmain = LSTM(1024)(combined)       #The 1. layer of the main branch\r\nmain = Dropout(0.2)(main)\r\n\r\nmain = Dense(512, activation=activations.relu)(main)  #The 2. layer of the main branch\r\nmain = Dropout(0.2)(main)\r\n\r\nmain = Dense(256, activation=activations.relu)(main)  #The 3. layer of the main branch\r\nmain = Dropout(0.2)(main)\r\n\r\n#------------------------------------------------These are the outputs of the  models------------------------------------------------\r\n#This is the output of the critic model. The input is one because we just want the value of 1 action, which was taken by the actor.\r\nvalues = Dense(1, activation=activations.linear)(main)\r\n\r\n#This is the output of the actor model. We get the probabilities of each action, that is why softmax needed.\r\nprobabilities = Dense(32, activation=activations.softmax)(main)\r\n\r\n#This is the policy network needed to connect the actor and the critic:\r\n#y_true is an action that the actor took, and y_pred the probability of that action\r\ndef custom_logLikelihood(y_true, y_pred):\r\n     out     = K.clip(y_pred, 1e-8, 1-1e-8) #Clip the prediction so it can not be 0 or 1.\r\n     log_lik = y_true * K.log(out)\r\n\r\n     return K.sum(-log_lik * delta)\r\n\r\n#------------------------------------------------These are the  models------------------------------------------------\r\nactor = Model(inputs=[first_branch.input, second_branch.input, third_branch.input, delta], outputs=probabilities)\r\nactor.compile(loss=custom_logLikelihood, optimizer=Adam(lr=0.0001), experimental_run_tf_function=False)\r\ntf.config.experimental_run_functions_eagerly(True)  \r\n\r\ncritic = Model(inputs=[first_branch.input, second_branch.input, third_branch.input], outputs=values)\r\ncritic.compile(loss=\"mse\", optimizer=Adam(lr=0.0005))\r\n\r\nprev_state_vis=np.random.randint(0, 20, size=(11,11))\r\nprev_state_mem=np.random.randint(0, 20, size=(100,3))\r\nprev_state_task=np.random.randint(0, 20, size=(5,6))\r\ncurr_state_vis=np.random.randint(0, 20, size=(11,11))\r\ncurr_state_mem=np.random.randint(0, 20, size=(100,3))\r\ncurr_state_task=np.random.randint(0, 20, size=(5,6))  \r\n\r\nprev_state_v = prev_state_vis[np.newaxis, :]\r\nprev_state_m = prev_state_mem[np.newaxis, :]\r\nprev_state_t = prev_state_task[np.newaxis, :]\r\ncurr_state_v = curr_state_vis[np.newaxis, :]\r\ncurr_state_m = curr_state_mem[np.newaxis, :]\r\ncurr_state_t = curr_state_task[np.newaxis, :]\r\n\r\ncritic_value_prev = critic.predict_on_batch([prev_state_v,\r\n                                                          prev_state_m, \r\n                                                          prev_state_t])\r\ncritic_value_curr = critic.predict_on_batch([curr_state_v,\r\n                                                          curr_state_m, \r\n                                                          curr_state_t])\r\ntarget  = 10 + 0.99 * critic_value_curr * (1-int(0))\r\nd   = target - critic_value_prev\r\nactions = np.zeros([1, 32])\r\nactions[np.arange(1), 0] = 1.0\r\n\r\nfor i in range(0,500*100):\r\n    print(i)\r\n    actor.fit(x=[prev_state_v, prev_state_m, prev_state_t, d], y=actions, verbose=0)\r\n    critic.fit(x=[prev_state_v, prev_state_m, prev_state_t], y=target, verbose=0)\r\n`", "comments": ["I have tried in colab with TF version 2.3. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/df90560119494e74b2e26d6090f7033c/untitled504.ipynb).You are also seeing the same behavior?\r\n\r\nThanks!", "> I have tried in colab with TF version 2.3. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/df90560119494e74b2e26d6090f7033c/untitled504.ipynb).You are also seeing the same behavior?\r\n> \r\n> Thanks!\r\n\r\nThe fit of the actor and critic is in the for loop and for me fails after about 30 iterations. I tried running it in the linked gist, I got the same error as on my pc, but only after 120 fits.", "@mbalazs98 \r\n\r\nPlease, share the log of the error if any.Also, try setting hard limit on GPU as shown in this [guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth).Thanks!\r\n\r\n", "> @mbalazs98\r\n> \r\n> Please, share the log of the error if any.Also, try setting hard limit on GPU as shown in this [guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth).Thanks!\r\n\r\nI forgot to mention that I already tried hard limiting the memory usage, it didn't help. The error message is the following:\r\nInternalError: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 1024, 1, 768, 1, 1024]  [Op:CudnnRNNBackprop]", "@mbalazs98 \r\n\r\nCan you please refer similar issue #41444, #37942 and see if it helps you. Thanks!", "> @mbalazs98\r\n> \r\n> Can you please refer similar issue #41444, #37942 and see if it helps you. Thanks!\r\n\r\n#41444 doesn't seem to be the issue, since that is windows related and this code fails on colab also. I tried every suggestion already given in #37942 but the results didn't change. Also, I think that it is not related to the batches since these networks are given only one batch in an iteration.", "@mbalazs98 `model.fit` manages its own tf.function and runs training in graph mode for faster computations. When you run `model.fit` in a for-loop and provide numpy inputs (which is considered as different input signature each iteration in for-loop), each graph is traced separately and there will be `n` number of models in the memory and consume lot of memory. You can garbage collect and clear the memory or provide tensor inputs which is considered same input signature (in your-case) and the same graph model is used for all those iterations.\r\n\r\nSo, I converted inputs to Tensors and provided as inputs. The code runs upto 130 iterations and throws different error. Can you please check whether there is any issue in data or in `critic.fit(x=[prev_state_v, prev_state_m, prev_state_t], y=target, verbose=0)`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/f13df62639197a6d651015b194b008bd/untitled504.ipynb). Thanks!", "> @mbalazs98 `model.fit` manages its own tf.function and runs training in graph mode for faster computations. When you run `model.fit` in a for-loop and provide numpy inputs (which is considered as different input signature each iteration in for-loop), each graph is traced separately and there will be `n` number of models in the memory and consume lot of memory. You can garbage collect and clear the memory or provide tensor inputs which is considered same input signature (in your-case) and the same graph model is used for all those iterations.\r\n> \r\n> So, I converted inputs to Tensors and provided as inputs. The code runs upto 130 iterations and throws different error. Can you please check whether there is any issue in data or in `critic.fit(x=[prev_state_v, prev_state_m, prev_state_t], y=target, verbose=0)`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/f13df62639197a6d651015b194b008bd/untitled504.ipynb). Thanks!\r\n\r\nThe error is slightly different, but as I see it is still related to memory, and it is definitely not expected. It fails the same way without fitting the critic network, so it shouldn't be related to that either.", "Could you provide us with a memory profile?\r\n\r\nCf https://github.com/tensorflow/profiler\r\nhttps://www.tensorflow.org/guide/profiler\r\n\r\nWhat's the minimum batch size that you can run this model with?", "> Could you provide us with a memory profile?\r\n> \r\n> Cf https://github.com/tensorflow/profiler\r\n> https://www.tensorflow.org/guide/profiler\r\n> \r\n> What's the minimum batch size that you can run this model with?\r\n\r\nUnfortunately the model crashes before it can log anything. It fails with a batch size of 1, so that can't be decreased.", "I realised that the error is probably related to the custom likelihood function. When compiling the actor network 'tf.config.experimental_run_functions_eagerly' was set as true, otherwise tf gives the following error:\r\n\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: input_7:0\r\n\r\nCould I be right about this? If yes, how could this be solved? Maybe it would be important to note that using tf.config.run_functions_eagerly instead of tf.config.experimental_run_functions_eagerly doesn't help.", "> @mbalazs98 `model.fit` manages its own tf.function and runs training in graph mode for faster computations. When you run `model.fit` in a for-loop and provide numpy inputs (which is considered as different input signature each iteration in for-loop), each graph is traced separately and there will be `n` number of models in the memory and consume lot of memory. You can garbage collect and clear the memory or provide tensor inputs which is considered same input signature (in your-case) and the same graph model is used for all those iterations.\r\n> \r\n> So, I converted inputs to Tensors and provided as inputs. The code runs upto 130 iterations and throws different error. Can you please check whether there is any issue in data or in `critic.fit(x=[prev_state_v, prev_state_m, prev_state_t], y=target, verbose=0)`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/f13df62639197a6d651015b194b008bd/untitled504.ipynb). Thanks!\r\n\r\nHi folks, sorry if this is out of protocol but what @jvishnuvardhan is talking about happens to me constantly and seems to cover 90% of the problems with running a model in a loop bugs (since before TF2.0). The pandas Series and Dataframe objects, along with the numpy arrays seem to get 'stuck' in memory during a loop. I'm assuming these are the multiple graphs being produced. Even deleting the model object from my loop or creating it in my loop causes the same memory growth regardless.\r\n\r\nThe only known solution that's completely solved it has been disabling eager execution, which, and someone please correct me if I'm wrong, forces tensorflow to treat everything as a tensor instead? \r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\nHopefully someone who knows what they're talking about can look into this but disabling eager execution pretty much solves all memory accumulation errors in a TF loop. \r\n\r\nThis is on TF2.4 - GPU but I've had the same issues since TF2.0.\r\nPython 3.7.7\r\nWin10. ", "@mbalazs98 Is this still an issue for you? Can you please check with recent TF versions (`TF2.7` and `tf-nightly`) and let us know whether issue is still persisting. \r\n\r\nPlease note that Keras development moved to another repository to focus entirely on only keras. Could you please repost this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44705\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44705\">No</a>\n"]}, {"number": 44704, "title": "AttributeError: module 'tensorboard.summary._tf.summary' has no attribute '__file__'", "body": "The Docker file I used to build TensorFlow 2.3.1 is shown below along with the error trace. Everything builds properly, however, when I import TensorFlow I get the following error:\r\n\r\nAttributeError: module 'tensorboard.summary._tf.summary' has no attribute '__file__'\r\n\r\n\r\n    FROM nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04\r\n\r\n    RUN apt-get update && apt-get -y upgrade\r\n    RUN apt-get install -y --no-install-recommends \\\r\n             python3 \\\r\n             python3-pip \\\r\n             python3-dev \\\r\n             python3-setuptools \\\r\n             python3-setuptools \\\r\n             git-core \\\r\n             vim \\\r\n             libgl1-mesa-glx\r\n    RUN python3 -m pip install --upgrade pip\r\n    RUN pip3 install --upgrade pip\r\n    RUN pip3 install --upgrade \\\r\n                    numpy \\\r\n                    scikit-build \\\r\n                    opencv-python \\\r\n                    jupyter \\\r\n                    psutil \\\r\n                    scikit-image \\\r\n                    pycocotools\r\n    # Install Bazel to Install TF2 from source\r\n    # Need to install from source to build with tflite_with_xnnpack\r\n    RUN apt-get install -y --no-install-recommends libglib2.0-0\r\n    RUN apt-get install -y --no-install-recommends curl\r\n    RUN apt-get install -y --no-install-recommends openjdk-8-jdk\r\n    RUN echo \"deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8\" | tee /etc/apt/sources.list.d/bazel.list\r\n    RUN curl https://bazel.build/bazel-release.pub.gpg | apt-key add -\r\n    RUN apt-get update\r\n    RUN apt-get install -y --no-install-recommends bazel-3.1.0\r\n    RUN link /usr/bin/python3 /usr/bin/python\r\n    RUN git clone https://github.com/tensorflow/tensorflow.git\r\n    RUN touch WORKSPACE\r\n    WORKDIR tensorflow\r\n    RUN pip3 install --upgrade keras_preprocessing\r\n    RUN pip3 install absl-py\r\n    RUN pip3 install --upgrade google-api-python-client\r\n    RUN pip3 install --upgrade protobuf\r\n    RUN pip3 install wrapt\r\n    RUN pip3 install termcolor\r\n    RUN pip3 install --upgrade gast\r\n    RUN bazel-3.1.0 build --config=mkl -c opt --copt=-march=skylake-avx512 --copt=-mfpmath=sse --define tflite_with_xnnpack=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\nHere is the error log:\r\n    File \"tensorflow_benchmarking.py\", line 11, in <module>\r\n        import tensorflow\r\n    File \"/s/dmerric5/.local/lib/python3.6/site-packages/tensorflow/__init__.py\", line 54, in <module>\r\n        from ._api.v2 import compat\r\n    File \"/s/dmerric5/.local/lib/python3.6/site-packages/tensorflow/_api/v2/compat/__init__.py\", line 39, in <module>\r\n        from . import v1\r\n    File \"/s/dmerric5/.local/lib/python3.6/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 34, in <module>\r\n        from . import compat\r\n    File \"/s/dmerric5/.local/lib/python3.6/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 40, in <module>\r\n        from . import v2\r\n    File \"/s/dmerric5/.local/lib/python3.6/site-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py\", line 32, in <module>\r\n        from tensorflow._api.v2.compat.v2 import __operators__\r\n    File \"/s/dmerric5/.local/lib/python3.6/site-packages/tensorflow/_api/v2/compat/v2/__init__.py\", line 36, in <module>\r\n        from . import compat\r\n    File \"/s/dmerric5/.local/lib/python3.6/site-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py\", line 40, in <module>\r\n        from . import v2\r\n    File \"/s/dmerric5/.local/lib/python3.6/site-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py\", line 329, in <module>\r\n        [_module_util.get_parent_dir(summary)] + _current_module.__path__)\r\n    File \"/s/dmerric5/.local/lib/python3.6/site-packages/tensorflow/python/tools/module_util.py\", line 30, in get_parent_dir\r\n       return os.path.abspath(os.path.join(os.path.dirname(module.__file__), \"..\"))\r\n    AttributeError: module 'tensorboard.summary._tf.summary' has no attribute __file__", "comments": ["Thought Tensorboard would be installed with Tensorflow.\r\n\r\nSolved with: \r\n\r\n    pip3 install --upgrade tensorboard", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44704\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44704\">No</a>\n"]}, {"number": 44702, "title": "support SparseToDenseOp on GPU", "body": "Support SparseToDense operator on GPU, testing shows great performance improvement than on CPU.\r\n#8321", "comments": ["@concretevitamin Could you help to review this patch ?", "@rangjiaheng Can you please resolve conflicts? Thanks!", "@rangjiaheng Any update on this PR? Please. Thanks!", "@rangjiaheng I'm incredibly sorry I dropped the ball on this PR. :'(\r\nIt seems a SparseToDenseOp GPU kernel has been added recently in #47234. Are there additional changes you would like to make with this PR? ", "@rangjiaheng  Can you please check @penpornk's comments and keep us posted ? Thanks!", "@rangjiaheng Any update on this PR? Please. Thanks!", "It has been 19 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 44701, "title": " 3760 illegal hardware instruction  python3", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): KALI LINUX\r\n- TensorFlow installed from (source or binary): PIP3 INSTALL TENSORFLOW\r\n- TensorFlow version: \r\ntensorflow             2.3.1\r\ntensorflow-estimator   2.3.0\r\n\r\n- Python version:  Python 3.8\r\n- Installed using virtualenv? pip? conda?:  pip3\r\n\r\n- GPU model and memory: HP pavillion g4 intel i5 m480 6gb ram\r\n\r\n\r\n\r\n**Describe the problem**\r\nwhen ever i try to import tensorflow in my python program as tf\r\n\r\ni got this in output as error  :-  ' 3760 illegal hardware instruction  python3 '\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n>>> import tensorflow as tf\r\n[1]    3760 illegal hardware instruction  python3\r\n\r\n\r\n\r\n", "comments": ["@arun4ss \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements).\r\n\r\nAlso, refer this [SO link](https://stackoverflow.com/questions/49327879/illegal-hardware-instruction-when-trying-to-import-tensorflow) and see if it helps you. Thanks!\r\n\r\n\r\n", "> @arun4ss \n> \n> What is make/model of your cpu?\n> I suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements).\n> \n> Also, refer this [SO link](https://stackoverflow.com/questions/49327879/illegal-hardware-instruction-when-trying-to-import-tensorflow) and see if it helps you. Thanks!\n> \n> \n> \n\n    Cpu model is :- Intel Core i5-480M\nHow to cheak if my cpu support AVX or not?\n\nI have checked the [SO link](https://stackoverflow.com/questions/49327879/illegal-hardware-instruction-when-trying-to-import-tensorflow)\nBut  it's code is different from my issue \nIt is **4492 illegal hardware instruction (core dumped)  python**\n\nAnd \n\nMy issue is **3760 illegal hardware instruction python3**", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44701\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44701\">No</a>\n", "@arun4ss \r\n\r\nAs per Intel's [product specification](https://ark.intel.com/content/www/us/en/ark/products/52952/intel-core-i5-480m-processor-3m-cache-2-66-ghz.html), your CPU doesn't support AVX. For more information, please take a look at the [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements) to install TensorFlow with pip.\r\nAlternatively, you can build [TensorFlow from source](https://www.tensorflow.org/install/source) or use [Google Colab](https://colab.research.google.com/). Thanks!\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44701\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44701\">No</a>\n", "According to the hardware requirements, my CPU does support AVX but Tensorflow refuses to run. I have a `Intel(R) Core(TM) i7-3537U CPU @ 2.00GHz` and I'm running Ubuntu 20.04 LTS with Python 3.8.5.\r\n```\r\nPython 3.8.5 (default, Jul 28 2020, 12:59:40)\r\n[GCC 9.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\n[1]    54557 illegal hardware instruction (core dumped)  python\r\n```", "See #45744 and #45866", "Deduplicating to #45744 (randomly chosen among multiple duplicates)"]}, {"number": 44700, "title": "SegmentSum GPU OP has no incremental detection on segment_ids", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 8\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): r1.15\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Telsa V100\r\n\r\n**Describe the current behavior**\r\nIn `tf.segment_sum` GPU version, there is no incremental check on segment_ids. I tried an unsorted segment_ids, and get a wrong result without any exception or warning.\r\n\r\n**Describe the expected behavior**\r\nIf the segment_ids is required in an incremental sequence,  I think there should be an exception or warning in the implementation.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```python3\r\nimport tensorflow as tf\r\n\r\nwith tf.device('/GPU:0'):\r\n  data = tf.constant([[1,2], [3,4], [5,6], [7,8]], dtype=tf.float32)\r\n\r\n  seg_ids = tf.constant([0,0,1,0], dtype=tf.int32)\r\n\r\n  gpu_op = tf.segment_sum(data, seg_ids)\r\n  #Got [[16. 20.]].\r\n  #But an exception or warning is expected.\r\n```\r\n", "comments": ["@Lifann \r\nThere is support for 2.x only, Can you please upgrade your tf version and let us know if you face any issues on 2.x", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44700\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44700\">No</a>\n"]}, {"number": 44699, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError", "body": "hello, when  I run my code, the error mesage occurs:\r\nTraceback (most recent call last):\r\n  File \"/home/tj/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1607, in _create_c_op\r\n    c_op = c_api.TF_FinishOperation(op_desc)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 122904 and 12 for 'mul' (op: 'Mul') with input shapes: [122904], [12].\r\n\r\ndo you know how to solve it?", "comments": ["@tanjia123456 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44697, "title": "Incorrect Cupti dll name on W10", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 20H2\r\n- TensorFlow installed from (source or binary): Binary (pip)\r\n- TensorFlow version (use command below): 2.4.0-rc0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.0 / 8\r\n- GPU model and memory: Nvidia 2080Ti 11Gb\r\n\r\n**Describe the current behavior**\r\nOn Windows it looks for the dll 'cupti64_110.dll' however Cuda Toolkit 11 and others now installs as 'cupti64_2020.1.0.dll' on W10.\r\n\r\n**Describe the expected behavior**\r\nCorrectly identify the cupti dll name to work on W10 with the default Cuda Toolkit install.\r\n\r\n**Standalone code to reproduce the issue**\r\nAny training code with profiling or logging on W10.\r\n\r\n**Other info / logs** \r\nCan be fixed by copying/renaming the dll to 'cupti64_110.dll' in the 'Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\\extras\\CUPTI\\lib64' folder.\r\n", "comments": ["@peachthiefmedia \r\nCan you please paste the error log (using makrdown formatting around it) .", "Apologies, I'd corrected it before I took logs. Here they are\r\n\r\n```\r\n2020-11-10 09:58:31.729040: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\r\n2020-11-10 09:58:31.729156: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\r\n2020-11-10 09:58:31.729246: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\r\n2020-11-10 09:58:31.749207: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti64_110.dll'; dlerror: cupti64_110.dll not found\r\n2020-11-10 09:58:31.768347: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti.dll'; dlerror: cupti.dll not found\r\n2020-11-10 09:58:31.768472: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-11-10 09:58:31.768581: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\r\n2020-11-10 09:58:31.768812: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1496] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\r\n```\r\n\r\nIt should say \r\n\r\n```\r\n2020-11-10 08:30:03.445479: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\r\n2020-11-10 08:30:03.445562: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\r\n2020-11-10 08:30:03.445634: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\r\n2020-11-10 08:30:03.466975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cupti64_110.dll\r\n2020-11-10 08:30:03.562410: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\r\n2020-11-10 08:30:03.562604: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\r\n```", "@sanjoy can you take a look please?", "Would you be OK with a local work-around?\r\n\r\nReplace [this](https://github.com/tensorflow/tensorflow/blob/667244c2e450ed9491e8ad964a0db6b2945929dd/third_party/gpus/cuda_configure.bzl#L589) `_check_cuda_libs_params(...)` with `(cuda_config.config[\"cupti_library_dir\"] + \"/cupti64_2020.1.0.dll\", True)`\r\n\r\nWe have plans to streamline cuda_configure.bzl, which would be a good time to take care of this as well.", "This is already a duplicate of https://github.com/tensorflow/tensorflow/issues/43030 then we have https://github.com/tensorflow/tensorflow/issues/44291.\r\nI don't think that we could leave this open until TF 2.5.", "I simply made a copy of 'cupti64_2020.1.1.dll' and rename it to 'cupti64_110.dll', now everything works fine.", "@peachthiefmedia , Does the above comment resolve your issue? ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44697\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44697\">No</a>\n"]}, {"number": 44696, "title": "tensorflow/go: does not contain package go/core/protobuf/for_core_protos_go_proto", "body": "", "comments": ["@batara666 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nPlease share the error logs. [along with exact tf version]", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44696\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44696\">No</a>\n"]}, {"number": 44695, "title": "bazel build libtensorflowlite has issue during compiling", "body": "tizen5.0_cross_toolchain_vd_kant_target_armv7l_host_x86-64/bin/armv7l-tizen-linux-gnueabi-gcc -MD -MF bazel-out/armv7-opt/bin/external/mkl_dnn/_objs/mkldnn_single_threaded/simple_concat.d '-frandom-seed=bazel-out/armv7-opt/bin/external/mkl_dnn/_objs/mkldnn_single_threaded/simple_concat.o' -iquote external/mkl_dnn -iquote bazel-out/armv7-opt/bin/external/mkl_dnn -isystem external/mkl_dnn/include -isystem bazel-out/armv7-opt/bin/external/mkl_dnn/include -isystem external/mkl_dnn/src -isystem bazel-out/armv7-opt/bin/external/mkl_dnn/src -isystem external/mkl_dnn/src/common -isystem bazel-out/armv7-opt/bin/external/mkl_dnn/src/common -isystem external/mkl_dnn/src/cpu -isystem bazel-out/armv7-opt/bin/external/mkl_dnn/src/cpu -isystem external/mkl_dnn/src/cpu/gemm -isystem bazel-out/armv7-opt/bin/external/mkl_dnn/src/cpu/gemm -isystem external/mkl_dnn/src/cpu/xbyak -isystem bazel-out/armv7-opt/bin/external/mkl_dnn/src/cpu/xbyak -w -DAUTOLOAD_DYNAMIC_KERNELS -fPIC '-std=c++14' -fexceptions '-DMKLDNN_THR=MKLDNN_THR_SEQ' -c external/mkl_dnn/src/cpu/simple_concat.cpp -o bazel-out/armv7-opt/bin/external/mkl_dnn/_objs/mkldnn_single_threaded/simple_concat.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nIn file included from external/mkl_dnn/src/common/mkldnn_thread.hpp:20:0,\r\n                 from external/mkl_dnn/src/cpu/simple_concat.cpp:17:\r\nexternal/mkl_dnn/src/common/utils.hpp:45:1: error: static assertion failed: Intel(R) MKL-DNN supports 64 bit only\r\n static_assert(sizeof(void*) == 8, \"Intel(R) MKL-DNN supports 64 bit only\");\r\n ^~~~~~~~~~~~~\r\nTarget //tensorflow/lite:libtensorflowlite.so failed to build\r\n", "comments": ["@anglerbug123 \r\n\r\nRequest you to fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44695\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44695\">No</a>\n"]}, {"number": 44694, "title": "How to avoid unsupported ops during the tf lite conversion", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): pip installed tf\r\n- TensorFlow version (or github SHA if from source): See below for detailed info\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport torch\r\nimport torch.onnx\r\nimport tensorflow as tf\r\nimport onnx\r\nimport os\r\n\r\nfrom onnx_tf.backend import prepare\r\nfrom models.pytorch import models\r\nfrom models import vgg\r\nfrom models import googlenet\r\nfrom models import lenet\r\n\r\n\r\noutput_dir = \"./results/vgg/\"\r\n\r\nnetwork = vgg.VGG('VGG13')\r\n# network = lenet.LeNet()\r\n\r\n\r\nif not os.path.exists(output_dir):\r\n    os.makedirs(output_dir)\r\n\r\nnetwork.eval()\r\ninput_image = torch.randn(1, 3, 32, 32, requires_grad=True)\r\ntorch_out = network(input_image)\r\n\r\n# Export the model to ONNX\r\ntorch.onnx.export(network,               # model being run\r\n                  input_image,                         # model input (or a tuple for multiple inputs)\r\n                  output_dir + \"model.onnx\",   # where to save the model (can be a file or file-like object)\r\n                  export_params=True,        # store the trained parameter weights inside the model file\r\n                  opset_version=10,          # the ONNX version to export the model to\r\n                  do_constant_folding=True,  # whether to execute constant folding for optimization\r\n                  input_names = ['input'],   # the model's input names\r\n                  output_names = ['output'], # the model's output names\r\n                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\r\n                                'output' : {0 : 'batch_size'}})\r\n# Export the model to TF\r\nonnx_model = onnx.load(output_dir + 'model.onnx')  # load onnx model\r\ntf_rep = prepare(onnx_model)  # prepare tf representation\r\ntf_rep.export_graph(output_dir + 'tf_model')  # export the model\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=output_dir+'tf_model', signature_keys=['serving_default'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True\r\n\r\n# Uncomment this line to use tfops in tflite conversion, will not run on mobile devices\r\n# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\ntflite_model = converter.convert()\r\n\r\n\r\nwith open(output_dir + 'model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n--Under 2.2.0 (onnxtf only support >=2.2.0)\r\nloc(\"onnx_tf_prefix_Pad_25@__inference_cond_true_306_570_frozen\"): error: 'tfl.pad' op failed to verify that operand 0's rank e\r\nquals operand 1's size\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\macin\\.conda\\envs\\normaltf\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\macin\\.conda\\envs\\normaltf\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\macin\\.conda\\envs\\normalTF\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\macin\\.conda\\envs\\normaltf\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 93, in mai\r\nn\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"c:\\users\\macin\\.conda\\envs\\normaltf\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"c:\\users\\macin\\.conda\\envs\\normaltf\\lib\\site-packages\\absl\\app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"c:\\users\\macin\\.conda\\envs\\normaltf\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"c:\\users\\macin\\.conda\\envs\\normaltf\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 56, in exe\r\ncute\r\n    enable_mlir_converter)\r\nException: <unknown>:0: error: loc(\"onnx_tf_prefix_Pad_25@__inference_cond_true_306_570_frozen\"): 'tfl.pad' op failed to verify\r\n that operand 0's rank equals operand 1's size\r\n\r\n--Under 2.3.0\r\n....a lot of characters\r\nE6C3C3C21133B87CD213B7AEACD3B8219B83B43EBE8BBA4F8FFBB8F16FFBBC74C313CAD77963B48FC453CA0AF66BC2CCB35BB6DC30CBCC21323BC59E28DBA11\r\n17A83A7931A8BB15E826BCADD90EBC481C223CF6CA513C17E92B3CBA57D5B82DB97BBB4B465B3C795EC53B786FED3B69FCA2BB6E81DA3BDFFE3ABC93CA08BBB\r\nE8068BC1152553C225124BB5DF0DD3B0EEE3DBCEF8E02BC1F3A14BC4F0A28BC3415423B7CA785BA008236BBF1A75C3CF94F503CD367A13A0DC744BC30E47239\r\n072F77BB1B72F03B8EC518BA3A1E5D3CF5953C3CC33A4F3C0B562DBCE2334D3C2E33653C9050F2B9A71E073C9A3C26BCF63130BBA0D86A3CDD41D1BB43D045B\r\nBDD6A883B5594113CCCA3A43B6D08B3BB9B385F3BE4D90F3C99C5B8BB6E7F583CD103493CD9EC89BBD0C511B82838D63B8A49B1BBE3D92C3B60644F3BC68B02\r\n3C030400BCBC6F99BB2D9ECDBA25435B3C4A74BD3AEF522CBB3A67AB3B0E66183A6DEDF73B2B3A5EBB925F92BBD008DB3A0D2652BCE11C123C0FB468BC14E02\r\n93BB8E1F43AB857093C0AC9173BF0932DBCC06BA33BC9DF31BCB37F5A3C29B24D3B006908BC3C768B3B5526103B5AB2A3BBF87A7E3B8519BA3B530B323CD898\r\n6BBCFF61B33B413A893B9CD2B13B5AD147BB56B62FBB748E383CAECA4B3C88E0B03B069137BC8E02FAB96B5A64BC980850BCD434753B6F88D8BBFCBC093C07E\r\nEA73BEAA240BC28B18A3BC6A851BC1351DFBB50762C3C0D6ECDBA45150ABC94635CBC486A6ABCBE735F3C5A626DBC308543BB86C86BBCE670B73B74FA1DBC16\r\n9730BB21E4293C12C570BCFD1990BBCA8AB73B22D66C3A122870BCBF0E0FBCAEC26CBC3D9E4E3C42049D3BD41CF2BB2FD72CBCADCA2DBCD966563CCA946B3C7\r\nDE203BCC4FA0D3CD289E83BF7439ABBB2B920BC18C1033CC3E22CBCC6883C3BB877513CDB515A3C\"> : tensor<512xf32>} : () -> tensor<512xf32>\r\n  %cst_26 = \"std.constant\"() {value = dense<\"0x7460CA3B75992EBC01CB64BC4859043C8B26BABBE5BE90BB89EC193BF8C9C23A98BC093C3C04E93A\r\n2C2424BC681B0BBCE8AC8C3B2FC84DBCDD113CBC116F90BB1306B3BB5EB078BA6A0F7B3B23B6003C41648FBAC2D860BC38FD92BB581C16BCEC00CEBB44F84FB\r\nCF35314BCB63B02BC4B7239BC9EE30BBC9B851F3CF6D260396245A3BB86D442BCCEBC62BC63F969BBEB6E563CEA56B53B28FD573C98974B3C361671BCFB9C60\r\n3C0978603C733C4A3CDD7353BCC4782ABB0F0E6B3BF534F83BF93C8E3AB8E25D3C2493CF3AD439CE3A2428153CCAF95FBCAC4E703CF23823BC496BA83812CC1\r\n2BCCF4A833B7FFABF3BA87BB0BB84F96B3C4EF1F33B2D9FDD3B48D304BC6AAE693C2FFEF03BB110333BE69C4C3C480143BBB902263CF7B752BB817AC1BB180A\r\nC33A2E3819BCAD2CE93BF2313A3C34D9C73B6D5457BCBC5B403C054C09BC88276DBC42F891BBAE5F5F3C99A39ABBB9B958B9995396BBD270513C557D10BCA61\r\nC203CF12C543C2409223C8D7ECDBB07772D3AAAD71B3C41663DBC82F2D9BB622D703C54E5FF3A0CF9293B68A80CBC6D6FA0BBE56F8ABB2F444F3C18FE54BCBA\r\nC5473BE46AB7BA50B2B13B067E19BCDBE244BB5D7A63BB43752A3C689DC33A44986A3CB018133AFD5120BC5954F1BB0272D5BA07071ABC94BB34BC89D258BC3\r\nD14B53A700411BA52346DBBA0EEFFBB37544CBC1E663EBC8CC3E13B81656F3A5B98773BE8DF16BC805AA53B290DA7B94CDF4DBCB7DDE53B6A4E1FBCA59934BC\r\nB85CBDBBBA92213C3CB41A3CB58BCD3A61B782BBB80FE5BB692E65BC7D4603BC4B9A52BB7103DDBBFBF4003C07DF2CBC939D4CBC0645CF3B56F5853B0827FA3\r\nB8FD0493C92FD303BBCFE8C3B1E175F3C9890393C961A573C03212A3CFC022A3B8687DBBB0B46EA3A4D4A33BB85C93D3CFF7233BC9BA233BC512D5B3CB784A6\r\n3B583C12BB01121ABC2AE4C23B1ACF61BB21E2D2BBFCD36FBCC2DBB53B9380153B6A78D0BB315B683CFEB547392C4F42BCE726903B9376D8BBD37232BCD564D\r\n23BF2264FBCEE2B633C040CCFBB2AD0303B2FA456BC774E5FBB67F7423CFB2B893AAF1A7838B08D11BCA0C63EBC0FEAF6B90299913B5E112CBCCF67353C8F14\r\nA7BBB6DE48BC62E617BCE915C1BB920919BC7D50D23B3D0217BCCA0101BBF062B13B5A11663CD42CBD3B5D2CA03B3682983A03650D3C1C5E333CFDA46FBB59F\r\n4373CC2B8643C4F2D4EBC033DFC3BAFCDC4BAB2A73BBCD3FBEAB97B25B9BB1F655DBCDD60CBBB9E0E9D3B59FE303C672F013C0FB009BCFFAB17BC8EB76C3B32\r\n9327BC5477C3BB896DB9BB441FFDBB41D0A8BB8935C0BA2047B13B744CFA3B85CDDE3B22196F3A11E993BB37D0E8BB2E0B0D3B18C3A9BA40224F3B5B0C00BCD\r\n2B646BC76463CBB131FD83B9D10723B41C2B83B41F04ABBE57533BA210E8EBAA9B8883B80FF683BE4848D3BBC11D5BB989E2C3C6BF04EBC7691523CEB74603C\r\n037A5B3C39AB953BFEC80B3BD1448FB809BE043C41890D3C19D702BB2877513C6495E5BBEADA62BC2E65EDBBAB059ABB045A533C3629693CE91DE9BB1542A0B\r\nB0169033BBB5B5A3C7A053A3CF69F553BBAE716BBB032463C6E35CF3BCA0430BCF54910BCEAC5783BE6B36D3B75C355BC0D75D33B407CC4B9373841BCADBD37\r\n3C63222E3B2D337DB9FFDF51BB526EF23B519AF1B99E3F6F3CACEE2A3B14E48ABBB7CF5FB67EAB2E3CFEC447B943D65EBB2D5A563C551434BBC162ADBB5361D\r\n93BDE17233BD58A48BC2649933B139747BC53A25DBBA94B8EBBEE5DC43BC7D16D3CD1D288BB2C30393C41552EBCF2A06D398667C9BBDA5DBD3AB6BE3DBCE79A\r\n4F3C6538643A0B4D54BC30CA973B1D30AF3BCC062C3B6D9DE93B7B2C88BB5B8915BB37AE20BC82A1F33B498AD23BFEA8203C750B48BCF987D8B936ADAB3BE30\r\nA54BC90AA503B13DD6ABB247F5C3BB334693909FE1E3C5AF330BC33410C3CFE509D3BB516FDBB2466C83B740C523C71812CBC20EF16BC5DB4623CE030CABB83\r\n4F8F3B8443B0BB6263573CFBB5133C732946BCFC51E8BADC1940BC38095FBC4A400CBB6C1AE8BA34C2C73B8DC010BC5E26A5BB66724ABCBE65EBBB40003F3CA\r\n4FB193CE73327BC14622DBC1C64503AFD4814BCBD1424BC41174139C42352BC7F5D21BC11B294BBC3CAA83B6B565E3B1707513BA92DD8BA657383BABD259CBA\r\n716E293C681C973BC2412FBC87BF39BC25E24F3C51D7533C9319D3BB5C0C343CCEC8C3BB0759B4BB6D80503C6A804C3C1BAC2D3BADB02F3C8866AB39BCFCB0B\r\nBDFD8B43BD171C1BB64D8393C7F8E45BB1ECF533B4E88923BA8D44FBC69F88E3AE00B473C5E81803A2739A7BBF1656EBC50F7F83B892F5BBCACAA08BC093509\r\nBC527A93BB3D4CFEBA0F1B62BC8CC6C83BCA0CBC3A62008DBAA4AA70BC118216BCC7236FBC83173BBA636FA0BBE7F5233CE3862A3C93DF0C3C5F93503CA0F80\r\n93C9BA4F13B70AD023C871E0C3CE113ECBBE1F2F53BCF3EA63B88F600BCA2515D3CC2493DBB04DB433BEDF719BA6807283C1B74F2BBAE4131BC123DB7BB2169\r\n27BC2DE1B4BAD2D748BCF3C7433C70F50F3CCF6E6DBC6FA7473CE6A191BB8D59623C3C5787BB516302BCDCA7D43BFE2E19BC9F28663C2D4C663C6A944C3CAFA\r\n4063C0074A3BB4BCEA1B920250FBCC0D3E03B799935BC0271B7BBC69F41BC6495D4BB16CC0F3CBCF1CE371D4CE53A6994303C66C149BCCFA3A83B39A669BCB9\r\n53363C7668FF3BF57D1ABB74B4EC3B2FAB613CE05DAA3A42A4B7BB011114BC4A517A3BAFEBC0BB9079143C6D8968BC88B60CBC2A5A143C13E662BCEF34013C4\r\n7BB52BCA99D433C5F9B02BC6738503CF605663C4238DB3B62F2093C75A43DBCBF61313CEC6CD53B\"> : tensor<512xf32>} : () -> tensor<512xf32>\r\n  %cst_27 = \"std.constant\"() {value = dense<\"0x87236A3B5915D9B9F4955CBC1A453A3CEE1A4ABCC4746FBC09A51ABC09960D3C9E9F3CBC8C185CBB\r\n24CD5CBCBBF7A8BB1138603CE161053C0493A33B1D9C433C1E02193A0D4E44BC665BD5BBF2D2A33A6B231CBC11FB8EBB143A55BCBE28713C68BC3E3CA0B6C7B\r\nBC4D3263CCBC653BAEE36F33B85284E3C170C5C3CC3A8233C01D9873B5489B5BBCF3F6DBC574269BB23565F3B6511EC3B1DEA5FBC96D535BC1030B13B3218C2\r\n3BC006E33BB80760BC1BCC563C95572DBC414265BC99E339BCB2229F3BDB07BB3AB7E0C6BBEA4B6ABCF12E54BC92195ABC0D70483C26D69DBBC19281BBC470C\r\nEBA7912AF3B24E31EBBD796183CC2F73BBADA9A273C8D2D263B7EEE1DBC59EB023BBF6D193C6AB762BBAFF7ACBA1EABE0BB938AB2BBBF47673CD296473C0B45\r\nC03B31ADA6BA96A0203C83D49B3B6855CEBBDFA541BC08931BBC637A1BBCC4892FBC01A1233CCBE040BC1E93B53BE4A6593CB038DCBAB20E7B3B3A1813BCB54\r\n30ABC2BD014BC0CE340BCEB2153BC700B5F3C120630BCC5C933B82947883B859802BAB5151ABC3DC14B3AE04DE13B6FACEF3B113EAC3B3A25353CC02BC83BE6\r\n8CBCBB3EC7AA3BBB4A39BB89530B3CF08312BBD5013D3C8F721EBC0723203B05E94DBC8107353BCFB91439EBA6443BFB3D0EBC442AD6BB5ECA21BC672FC5BAE\r\n85CF4BAB39207BC5378133CB1093EBC0AF0403CC746673CF9C234BCC1414D3BF08FF5BBC2013DBA32316A3C3D947CBB66D02F3A4D844DBC4983E93B2703823B\r\n56DD3BBB206DC9BB54509FBB29931C3BCCC70F3C5C194FBBD7A109BBAA91EE3A99B168BC5FBA5DBCC8B768BB5FB787BBAA3A5FBC9FD75C3C1011E23B6E8ADB3\r\nBD0DF7FBBC2FCF43B46DCDA3B4046C439BB1645BC946CFEBBC80BBDBB6CA66F3C530DBF3B5CA867BC205833BC8C7037BC0CFA073CE7E2823BDC887EBA2EA136\r\nBCCCB7163CCBE0243C38CA4C3C1FDA20BBCC2CB83ACB175CBC2E6BAF3A557984B969EBC4BBD025433A557FCC3A1BC638BBA57517BC4D74D23BC968373C6D4B8\r\nABBEBD0683C87C1C03B1D16483C55A1D13B1352253CB530AF3BE79D1F3C7FCBC43923C52DBB2B6D5DBB00BB13BB92A608BC14D0583CAC5070BCB991E6BB218E\r\n7B3B48AE3BBCD9645C3CF0F41A3C4995493C46A75BBC92826A3CC25DD6BA61CC38BC2D625DBC83175F3BD64227BC15281BBBE8F5F93BC1892F3C9AC7D6B97B3\r\n9363C67269ABBC2DC483B93386D3CB984243C63F4293CC799F5BA3752B3BB8F53C1BBE0C7803B7898A33B953DBB3BA84B1F3BE19FBA3B741364BC205B1A3C7D\r\nA0283BBB8AC03B4EFB333C4417B6BA4C81023CB98113BC60D343BBE8C5363B1DEC173C02A13ABCB173243C66E6443CAA3C6EBCBF0D20BCB57E44BC9915053C0\r\n0DE6CBC3B0145BBC2F352BCD5E9163C611841BCF7DA543CC5F08EBB28EDA53BF0BE973BAF4D6ABBF3E25B3C4F5DB23B378159BCD273ECBAC888343C7752DFB9\r\n5C3B1DBA5B5F2C3B24A7273CD40667BB6FCD63BCD2CB323CC252043CF58A96BB226BA4BA7DB0BEBB58D635BB5F3913BC148E0E3C5149A13BB40A68B862C5653\r\nC9252003BCFF6293C09B8AEBB4EBB493A7799AEBA526F51BCD59A4E3C946A67BBD3CC9BBBD5D2303C23303CBC984C4E3BD582C1BBAD8FEB3B18F3803B049CB6\r\nB9A6E3DC3B7923333B034269BC8A60E63B916BE93B6C7F5CBC24DD9E3A1A2ECEBB4C55643C0D8339BC16E9FE3B924E33BC4BD7A0B847CD6A3B997E47BCF9BFB\r\nABB191844BC8BC759BCFB985CBC605DA33B642ED4BB684DA9B95686C13BA53FB3BB91F16FBABED41FBC4DE26E3C437C373C6E165F3C0F4EF4BB8987543CFFBC\r\nD73B23A39CBB85B955BCA2FBD33A39FFC53B8DC7B33AAB1A1ABC2DC206BCC8D8B03BB18B403A7AA520BC7132A13BD0FFD9BB4D5FC7BB84C62B3B07E0C4BAD72\r\nF88BB2DC8D9BBA923493CC6DD3DBB5319143BFAD563BC1F8812BCFFDE1EBC322E453C2C9302BC8BE6C4BB573109BBFCC17EBB90351E3B1ABC3DBC95BEFDBA5D\r\n06E3BB76B5C93A153226BBF99EF13A7ECAAF3A3EA419BC06604C3CE4EAD4BBB208FCBB636B5E3B51DB473CFCD7FDBBE457A53B848E48BC3215003B4D1F16BC8\r\n3D334BC1278BBBB5AE6543A23CB193C74251DBCCEB7583C800530BC61D702BC6BD8EBBA56D3503CB485693CD91641BCDD5AE6BBB97A5FBC81B200BC1A1C53BC\r\n7D6E4DB9862E0BBBEA245E3C27E1F63A6818C3BAF26B913B04EF1A3C174A13BCDF4213BCB954F9BBC21D293CF62D66BCD0102F3C742F01BC83D2773B27B55A3\r\nC59C5EBBBC72BDFBB206E5F3CAD993F3B85B65C3C1356553CCD9F9CB919C0243C53922FBC9E761C3C3C5DD53B8F7696BA1ADAE8BB27A7073B9D0CB93B277C13\r\n3CE21AA53A9B896D3C061AC43B2898F33A9D3B123CFC17B03BE04561BC9315A0BA492C0D3C0B4958BC01AD603C3066103CEC13E13BC90D72BB543085B9D972E\r\nABB18D6073C4754FC3B59115B3C823D463CA49EAF3BC38F843B8B06903B19305CBCC44B91BBFB020ABCE6A44FBCCE67F8BA2732ACBBBF0EA93BA507F73B6110\r\n023B782E38BCF87C8DBB740524BC37DC39BB689D283C9B58903B66CC55BC5EF09D3B890990BA9FE483BBDCAA633C2D437C391379FB3BFD96263BB4CFDCBB6E3\r\nC473C59043FBB94FF443C905851BC5DC21B3A0457323C3189183C0DE2BFBB2FA0B33BAAF64FBC5306633CC7D4E43B65EB8FBBF3FE08BCB2F94A3C5FCD47BCEF\r\nCF70BC30E5333C26FF9FBB016970BBC105DF3B8672F43BECF9D5BB5C40143C114CA03B0D7A21BCA45C56BC5A9EB1BB9E782D3C45BB0F3B9A9623BB8BA7483C9\r\n57CDFBB11789ABBDB3607BC37C3503BCFE8493CACD1853AA8FF153C27BB2A3C3B03823BDACFF33B\"> : tensor<512xf32>} : () -> tensor<512xf32>\r\n  %cst_28 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_29 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_30 = \"std.constant\"() {value = dense<0> : tensor<4x2xi32>} : () -> tensor<4x2xi32>\r\n  %0 = \"tfl.pad\"(%arg0, %cst) : (tensor<?x3x32x32xf32>, tensor<4x2xi32>) -> tensor<?x3x34x34xf32>\r\n  %1 = \"tfl.transpose\"(%0, %cst_3) : (tensor<?x3x34x34xf32>, tensor<4xi32>) -> tensor<?x34x34x3xf32>\r\n  %2 = \"tfl.split\"(%cst_1, %1) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x34x34x3xf32>) -> tensor<?x34x34x3xf32>\r\n  %3 = \"tfl.conv_2d\"(%2, %cst_8, %cst_18) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function\r\n= \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x34x34x3xf32>, tensor<64x3x3x3xf32>, tensor<64x\r\nf32>) -> tensor<?x32x32x64xf32>\r\n  %4 = \"tfl.transpose\"(%3, %cst_2) : (tensor<?x32x32x64xf32>, tensor<4xi32>) -> tensor<?x64x32x32xf32>\r\n  %5 = \"tfl.pad\"(%4, %cst) : (tensor<?x64x32x32xf32>, tensor<4x2xi32>) -> tensor<?x64x34x34xf32>\r\n  %6 = \"tfl.transpose\"(%5, %cst_3) : (tensor<?x64x34x34xf32>, tensor<4xi32>) -> tensor<?x34x34x64xf32>\r\n  %7 = \"tfl.split\"(%cst_1, %6) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x34x34x64xf32>) -> tensor<?x34x34x64xf32>\r\n  %8 = \"tfl.conv_2d\"(%7, %cst_9, %cst_19) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function\r\n= \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x34x34x64xf32>, tensor<64x3x3x64xf32>, tensor<6\r\n4xf32>) -> tensor<?x32x32x64xf32>\r\n  %9 = \"tfl.transpose\"(%8, %cst_2) : (tensor<?x32x32x64xf32>, tensor<4xi32>) -> tensor<?x64x32x32xf32>\r\n  %10 = \"tfl.transpose\"(%9, %cst_3) : (tensor<?x64x32x32xf32>, tensor<4xi32>) -> tensor<?x32x32x64xf32>\r\n  %11 = \"tfl.max_pool_2d\"(%10) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = \"NONE\", padding =\r\n\"VALID\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<?x32x32x64xf32>) -> tensor<?x16x16x64xf32>\r\n  %12 = \"tfl.transpose\"(%11, %cst_2) : (tensor<?x16x16x64xf32>, tensor<4xi32>) -> tensor<?x64x16x16xf32>\r\n  %13 = \"tfl.pad\"(%12, %cst) : (tensor<?x64x16x16xf32>, tensor<4x2xi32>) -> tensor<?x64x18x18xf32>\r\n  %14 = \"tfl.transpose\"(%13, %cst_3) : (tensor<?x64x18x18xf32>, tensor<4xi32>) -> tensor<?x18x18x64xf32>\r\n  %15 = \"tfl.split\"(%cst_1, %14) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x18x18x64xf32>) -> tensor<?x18x18x64xf32>\r\n  %16 = \"tfl.conv_2d\"(%15, %cst_10, %cst_20) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi\r\non = \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x18x18x64xf32>, tensor<128x3x3x64xf32>, tens\r\nor<128xf32>) -> tensor<?x16x16x128xf32>\r\n  %17 = \"tfl.transpose\"(%16, %cst_2) : (tensor<?x16x16x128xf32>, tensor<4xi32>) -> tensor<?x128x16x16xf32>\r\n  %18 = \"tfl.pad\"(%17, %cst) : (tensor<?x128x16x16xf32>, tensor<4x2xi32>) -> tensor<?x128x18x18xf32>\r\n  %19 = \"tfl.transpose\"(%18, %cst_3) : (tensor<?x128x18x18xf32>, tensor<4xi32>) -> tensor<?x18x18x128xf32>\r\n  %20 = \"tfl.split\"(%cst_1, %19) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x18x18x128xf32>) -> tensor<?x18x18x128xf32>\r\n  %21 = \"tfl.conv_2d\"(%20, %cst_11, %cst_21) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi\r\non = \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x18x18x128xf32>, tensor<128x3x3x128xf32>, te\r\nnsor<128xf32>) -> tensor<?x16x16x128xf32>\r\n  %22 = \"tfl.transpose\"(%21, %cst_2) : (tensor<?x16x16x128xf32>, tensor<4xi32>) -> tensor<?x128x16x16xf32>\r\n  %23 = \"tfl.transpose\"(%22, %cst_3) : (tensor<?x128x16x16xf32>, tensor<4xi32>) -> tensor<?x16x16x128xf32>\r\n  %24 = \"tfl.max_pool_2d\"(%23) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = \"NONE\", padding =\r\n\"VALID\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<?x16x16x128xf32>) -> tensor<?x8x8x128xf32>\r\n  %25 = \"tfl.transpose\"(%24, %cst_2) : (tensor<?x8x8x128xf32>, tensor<4xi32>) -> tensor<?x128x8x8xf32>\r\n  %26 = \"tfl.pad\"(%25, %cst) : (tensor<?x128x8x8xf32>, tensor<4x2xi32>) -> tensor<?x128x10x10xf32>\r\n  %27 = \"tfl.transpose\"(%26, %cst_3) : (tensor<?x128x10x10xf32>, tensor<4xi32>) -> tensor<?x10x10x128xf32>\r\n  %28 = \"tfl.split\"(%cst_1, %27) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x10x10x128xf32>) -> tensor<?x10x10x128xf32>\r\n  %29 = \"tfl.conv_2d\"(%28, %cst_12, %cst_22) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi\r\non = \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x10x10x128xf32>, tensor<256x3x3x128xf32>, te\r\nnsor<256xf32>) -> tensor<?x8x8x256xf32>\r\n  %30 = \"tfl.transpose\"(%29, %cst_2) : (tensor<?x8x8x256xf32>, tensor<4xi32>) -> tensor<?x256x8x8xf32>\r\n  %31 = \"tfl.pad\"(%30, %cst) : (tensor<?x256x8x8xf32>, tensor<4x2xi32>) -> tensor<?x256x10x10xf32>\r\n  %32 = \"tfl.transpose\"(%31, %cst_3) : (tensor<?x256x10x10xf32>, tensor<4xi32>) -> tensor<?x10x10x256xf32>\r\n  %33 = \"tfl.split\"(%cst_1, %32) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x10x10x256xf32>) -> tensor<?x10x10x256xf32>\r\n  %34 = \"tfl.conv_2d\"(%33, %cst_13, %cst_23) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi\r\non = \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x10x10x256xf32>, tensor<256x3x3x256xf32>, te\r\nnsor<256xf32>) -> tensor<?x8x8x256xf32>\r\n  %35 = \"tfl.transpose\"(%34, %cst_2) : (tensor<?x8x8x256xf32>, tensor<4xi32>) -> tensor<?x256x8x8xf32>\r\n  %36 = \"tfl.transpose\"(%35, %cst_3) : (tensor<?x256x8x8xf32>, tensor<4xi32>) -> tensor<?x8x8x256xf32>\r\n  %37 = \"tfl.max_pool_2d\"(%36) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = \"NONE\", padding =\r\n\"VALID\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<?x8x8x256xf32>) -> tensor<?x4x4x256xf32>\r\n  %38 = \"tfl.transpose\"(%37, %cst_2) : (tensor<?x4x4x256xf32>, tensor<4xi32>) -> tensor<?x256x4x4xf32>\r\n  %39 = \"tfl.pad\"(%38, %cst) : (tensor<?x256x4x4xf32>, tensor<4x2xi32>) -> tensor<?x256x6x6xf32>\r\n  %40 = \"tfl.transpose\"(%39, %cst_3) : (tensor<?x256x6x6xf32>, tensor<4xi32>) -> tensor<?x6x6x256xf32>\r\n  %41 = \"tfl.split\"(%cst_1, %40) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x6x6x256xf32>) -> tensor<?x6x6x256xf32>\r\n  %42 = \"tfl.conv_2d\"(%41, %cst_14, %cst_24) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi\r\non = \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x6x6x256xf32>, tensor<512x3x3x256xf32>, tens\r\nor<512xf32>) -> tensor<?x4x4x512xf32>\r\n  %43 = \"tfl.transpose\"(%42, %cst_2) : (tensor<?x4x4x512xf32>, tensor<4xi32>) -> tensor<?x512x4x4xf32>\r\n  %44 = \"tfl.pad\"(%43, %cst) : (tensor<?x512x4x4xf32>, tensor<4x2xi32>) -> tensor<?x512x6x6xf32>\r\n  %45 = \"tfl.transpose\"(%44, %cst_3) : (tensor<?x512x6x6xf32>, tensor<4xi32>) -> tensor<?x6x6x512xf32>\r\n  %46 = \"tfl.split\"(%cst_1, %45) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x6x6x512xf32>) -> tensor<?x6x6x512xf32>\r\n  %47 = \"tfl.conv_2d\"(%46, %cst_15, %cst_25) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi\r\non = \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x6x6x512xf32>, tensor<512x3x3x512xf32>, tens\r\nor<512xf32>) -> tensor<?x4x4x512xf32>\r\n  %48 = \"tfl.transpose\"(%47, %cst_2) : (tensor<?x4x4x512xf32>, tensor<4xi32>) -> tensor<?x512x4x4xf32>\r\n  %49 = \"tfl.transpose\"(%48, %cst_3) : (tensor<?x512x4x4xf32>, tensor<4xi32>) -> tensor<?x4x4x512xf32>\r\n  %50 = \"tfl.max_pool_2d\"(%49) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = \"NONE\", padding =\r\n\"VALID\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<?x4x4x512xf32>) -> tensor<?x2x2x512xf32>\r\n  %51 = \"tfl.transpose\"(%50, %cst_2) : (tensor<?x2x2x512xf32>, tensor<4xi32>) -> tensor<?x512x2x2xf32>\r\n  %52 = \"tfl.pad\"(%51, %cst) : (tensor<?x512x2x2xf32>, tensor<4x2xi32>) -> tensor<?x512x4x4xf32>\r\n  %53 = \"tfl.transpose\"(%52, %cst_3) : (tensor<?x512x4x4xf32>, tensor<4xi32>) -> tensor<?x4x4x512xf32>\r\n  %54 = \"tfl.split\"(%cst_1, %53) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x4x4x512xf32>) -> tensor<?x4x4x512xf32>\r\n  %55 = \"tfl.conv_2d\"(%54, %cst_16, %cst_26) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi\r\non = \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x4x4x512xf32>, tensor<512x3x3x512xf32>, tens\r\nor<512xf32>) -> tensor<?x2x2x512xf32>\r\n  %56 = \"tfl.transpose\"(%55, %cst_2) : (tensor<?x2x2x512xf32>, tensor<4xi32>) -> tensor<?x512x2x2xf32>\r\n  %57 = \"tfl.pad\"(%56, %cst) : (tensor<?x512x2x2xf32>, tensor<4x2xi32>) -> tensor<?x512x4x4xf32>\r\n  %58 = \"tfl.transpose\"(%57, %cst_3) : (tensor<?x512x4x4xf32>, tensor<4xi32>) -> tensor<?x4x4x512xf32>\r\n  %59 = \"tfl.split\"(%cst_1, %58) {num_splits = 1 : i32} : (tensor<i32>, tensor<?x4x4x512xf32>) -> tensor<?x4x4x512xf32>\r\n  %60 = \"tfl.conv_2d\"(%59, %cst_17, %cst_27) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi\r\non = \"RELU\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x4x4x512xf32>, tensor<512x3x3x512xf32>, tens\r\nor<512xf32>) -> tensor<?x2x2x512xf32>\r\n  %61 = \"tfl.transpose\"(%60, %cst_2) : (tensor<?x2x2x512xf32>, tensor<4xi32>) -> tensor<?x512x2x2xf32>\r\n  %62 = \"tfl.transpose\"(%61, %cst_3) : (tensor<?x512x2x2xf32>, tensor<4xi32>) -> tensor<?x2x2x512xf32>\r\n  %63 = \"tfl.max_pool_2d\"(%62) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = \"NONE\", padding =\r\n\"VALID\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<?x2x2x512xf32>) -> tensor<?x1x1x512xf32>\r\n  %64 = \"tfl.transpose\"(%63, %cst_2) : (tensor<?x1x1x512xf32>, tensor<4xi32>) -> tensor<?x512x1x1xf32>\r\n  %65 = \"tfl.pad\"(%64, %cst_30) : (tensor<?x512x1x1xf32>, tensor<4x2xi32>) -> tensor<?x512x1x1xf32>\r\n  %66 = \"tfl.transpose\"(%65, %cst_3) : (tensor<?x512x1x1xf32>, tensor<4xi32>) -> tensor<?x?x?x?xf32>\r\n  %67 = \"tfl.average_pool_2d\"(%66) {filter_height = 1 : i32, filter_width = 1 : i32, fused_activation_function = \"NONE\", paddin\r\ng = \"VALID\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<?x?x?x?xf32>) -> tensor<?x?x?x?xf32>\r\n  %68 = \"tfl.transpose\"(%67, %cst_2) : (tensor<?x?x?x?xf32>, tensor<4xi32>) -> tensor<?x?x?x?xf32>\r\n  %69 = \"tfl.shape\"(%68) : (tensor<?x?x?x?xf32>) -> tensor<4xi64>\r\n  %70 = \"tfl.gather\"(%69, %cst_4) {axis = 0 : i32} : (tensor<4xi64>, tensor<i64>) -> tensor<i64>\r\n  %71 = \"tfl.reshape\"(%70, %cst_29) : (tensor<i64>, tensor<1xi32>) -> tensor<1xi64>\r\n  %72 = \"tfl.concatenation\"(%71, %cst_5) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<1xi64>, tensor<1xi64>)\r\n-> tensor<2xi64>\r\n  %73 = \"tfl.equal\"(%72, %cst_4) : (tensor<2xi64>, tensor<i64>) -> tensor<2xi1>\r\n  %74 = \"tfl.where\"(%73) : (tensor<2xi1>) -> tensor<?x1xi64>\r\n  %75 = \"tfl.squeeze\"(%74) {squeeze_dims = [-1]} : (tensor<?x1xi64>) -> tensor<?xi64>\r\n  %76 = \"tfl.gather\"(%69, %75) {axis = 0 : i32} : (tensor<4xi64>, tensor<?xi64>) -> tensor<?xi64>\r\n  %77 = \"tfl.sparse_to_dense\"(%74, %cst_0, %76, %cst_4) : (tensor<?x1xi64>, tensor<1xi64>, tensor<?xi64>, tensor<i64>) -> tenso\r\nr<2xi64>\r\n  %78 = \"tf.AddV2\"(%72, %77) {device = \"\"} : (tensor<2xi64>, tensor<2xi64>) -> tensor<2xi64>\r\n  %79 = \"tfl.cast\"(%78) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %80 = \"tfl.reshape\"(%68, %79) : (tensor<?x?x?x?xf32>, tensor<2xi32>) -> tensor<?x?xf32>\r\n  %81 = \"tfl.shape\"(%80) : (tensor<?x?xf32>) -> tensor<2xi32>\r\n  %82 = \"tfl.strided_slice\"(%81, %cst_28, %cst_29, %cst_29) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32,\r\n new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<\r\ni32>\r\n  %83 = \"tfl.pack\"(%82, %cst_1) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %84 = \"tfl.reshape\"(%68, %83) : (tensor<?x?x?x?xf32>, tensor<2xi32>) -> tensor<?x?xf32>\r\n  %85 = \"tfl.fully_connected\"(%84, %cst_6, %cst_7) {fused_activation_function = \"NONE\", keep_num_dims = false, weights_format =\r\n \"DEFAULT\"} : (tensor<?x?xf32>, tensor<10x512xf32>, tensor<10xf32>) -> tensor<?x10xf32>\r\n  \"std.return\"(%85) : (tensor<?x10xf32>) -> ()\r\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"input\", outputs = \"Identity\"}, type = (tensor<?x3x3\r\n2x32xf32>) -> tensor<?x10xf32>} : () -> ()\r\n\r\nBut the issue is with AddV2\r\n\r\n\r\n--Under nightly\r\nerror: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.AddV2 {device = \"\"}\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 213, in toco_convert_protos\r\n    enable_mlir_converter)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py\", line 38, in wrapped_toco_convert\r\n    enable_mlir_converter)\r\nException: <unknown>:0: error: loc(callsite(callsite(\"add_10@__inference___call___388\" at \"PartitionedCall@__inference_signature_wrapper_441\") at \"PartitionedCall\")): 'tf.AddV2' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"PartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.AddV2 {device = \"\"}\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/macin/Documents/GitHub/torchToTFLite/converter.py\", line 49, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 739, in convert\r\n    result = _convert_saved_model(**converter_kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 637, in convert_saved_model\r\n    enable_mlir_converter=True)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 216, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(callsite(callsite(\"add_10@__inference___call___388\" at \"PartitionedCall@__inference_signature_wrapper_441\") at \"PartitionedCall\")): 'tf.AddV2' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"PartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.AddV2 {device = \"\"}\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://drive.google.com/file/d/1UPXTbUaXzWDzHJUz8W7plO_L6lgNCNVD/view?usp=sharing\r\n```\r\n\r\n**Failure details**\r\nThe saved model converted from PyTorch contains ops AddV2 and pad. Pad caused problems in 2.2.0 while AddV2 causes problems in 2.3.0 and nightly.\r\n\r\n", "comments": ["Can anyone help with this issue? I have been stuck on it for several weeks.", "It looks like your model uses add with Int64 types, TFLite doesn't support Add with Int64 types, and that's why it can't convert the TF op to the corresponding TFLite Op.\r\n\r\nYou can either,\r\n1) Change the Add to use I32 instead of I64.\r\n2) Add Cast before the Add op to cast from I64 to I32\r\n3) Use TFLite with Select options, which in this case the Add Op with Int64 will be run using TF not TFLite - there is some penalty for doing this. See more details [here](https://www.tensorflow.org/lite/guide/ops_select)", "Thank you for the advice!\r\nFor deployment reasons, it is hard for us to go with option 3 using TF ops.\r\nAs we are working with a long pipeline from PyTorch -> ONNX -> savedmodel -> TFLite, it appears hard to control dtype in the savedmodel stage, where the Int64 Add appears.\r\nI was hoping, is there any way to directly modify data type in the savedmodel encoding? So that we can keep the pipeline the same, modify datatype in savedmodel, then get to TFLite.", "@Makkiy You can load the model and update as you wish and save it again.\r\nSee guide\r\nhttps://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format", "I am going to close the issue, feel free to reopen or create a new one. If there is an issue you wish to report.\r\n\r\nThanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44694\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44694\">No</a>\n", "Sorry, we cannot fix the problem with your solution. The loaded model is empty.", "@slimwangyue I think you might have done something wrong. You're trying to convert this same model to TFLite, so it shouldn't be empty.", "@karimnosseir \r\nI'm in same situation as @Makkiy  that \"we are working with a long pipeline from PyTorch -> ONNX -> savedmodel -> TFLite, it appears hard to control dtype in the savedmodel stage, where the Int64 Add appears.\"\r\nI read the 'load and save' part, but still not get the point, could you please help how to fix? \r\n   \"1. Change the Add to use I32 instead of I64.\r\n    2. Add Cast before the Add op to cast from I64 to I32 \""]}, {"number": 44693, "title": "module 'tensorflow_lite_support.metadata.metadata_schema_py_generated' has no attribute 'ModelMetadataT' error", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not used\r\n- TensorFlow installed from (source or binary): Spyder in Anagonda Navigator (It was preinstalled)\r\n- TensorFlow version (use command below): Tensorflow 2\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: Not using GPU\r\n\r\n**Describe the current behavior**\r\nI have tried to run the sample code from https://www.tensorflow.org/lite/convert/metadata in anaconda prompt, which is\r\n\r\npython ./metadata_writer_for_image_classifier.py \\\r\n    --model_file=./model_without_metadata/mobilenet_v1_0.75_160_quantized.tflite \\\r\n    --label_file=./model_without_metadata/labels.txt \\\r\n    --export_directory=model_with_metadata\r\n\r\nI have downloaded \"mobilenet_v1_0.75_160_quantized.tflite\" file and placed it in Desktop/model_without_metadata, downloaded this file (https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/metadata/metadata_writer_for_image_classifier.py) and placed it in Desktop as well.  By running this code, it gives me\r\nmodule 'tensorflow_lite_support.metadata.metadata_schema_py_generated' has no attribute 'ModelMetadataT'\r\nerror.\r\nHow can I solve this?\r\n\r\n**Describe the expected behavior**\r\nMetadata should be added to mobilenet_v1_0.75_160_quantized.tflite in order to use it in MLkit for object classification.\r\n\r\n", "comments": ["@hiroki-oist \r\nPlease provide with simple stand alone code to replicate the issue or a colab gist with the error reported. [along with exact tf version]", "@Saduf2019 Thank you for answering!\r\nSorry, since I am absolute beginner for python and machine learning, this might not be exactly what you need, but anyway,\r\n\r\n\r\nmobilenet_v1_0.75_160_quantized.tflite : tffile I want to add metadata to. Path is Desktop/model_without_metadata/\r\n\r\nmetadata_writer_for_image_classifier.py : code for adding metadata (not customized. Totally copied). Path is Desktop/\r\n\r\nCode run in Anaconda Prompt : python ./metadata_writer_for_image_classifier.py --model_file=./model_without_metadata/mobilenet_v1_0.75_160_quantized_1_default_1.tflite --label_file=./model_without_metadata/labels.txt --export_directory=model_with_metadata\r\n\r\nCurrent directory : /Desktop\r\n\r\n\r\n[mobilenet_v1_0.75_160_quantized_1_default_1.txt](https://github.com/tensorflow/tensorflow/files/5508515/mobilenet_v1_0.75_160_quantized_1_default_1.txt)\r\n[metadata_writer_for_image_classifier.txt](https://github.com/tensorflow/tensorflow/files/5508520/metadata_writer_for_image_classifier.txt)\r\n", "@hiroki-oist I followed exactly what you did, and it seems working on my end. See:\r\n```\r\n$python ./metadata_writer_for_image_classifier.py --model_file=./mobilenet_v1_0.75_160_quantized_1_default_1.tflite --label_file=labels.txt --export_directory=model_with_metadata\r\nFinished populating metadata and associated file to the model:\r\n./mobilenet_v1_0.75_160_quantized_1_default_1.tflite\r\nThe metadata json file has been saved to:\r\nmodel_with_metadata/mobilenet_v1_0.75_160_quantized_1_default_1.json\r\nThe associated file that has been been packed to the model is:\r\n['labels.txt']\r\n```\r\n\r\nFrom the error message, seems like the tflite_support package is not installed successfully. Can you please reinstall the package again? Such as:\r\n```\r\npip install tflite-support --upgrade\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44693\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44693\">No</a>\n"]}, {"number": 44692, "title": "crosstool_wrapper_driver_is_not_gcc failed: error executing command", "body": "<em>\r\n</em>\r\n\r\n**System information**\r\n- Ubuntu20.04.1\r\n\r\n- tensorflow source (master branch):\r\n- TensorFlow version:\r\n- Python version:3.8.5\r\n\r\n- 3.1.0n (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):9.2\r\n- CUDA/cuDNN version:8\r\n- GPU model and memory:24GB\r\n- Graph Card Diver:455.23.04\r\n- NVIDIA Card:RTX3090\r\n- TensorRT:TensorRT-7.2.1.6\r\n\r\n\r\n\r\n**bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n**\r\n\r\n**/home/liushuai/tensorflow/tensorflow/core/grappler/costs/BUILD:146:1: C++ compilation of rule '//tensorflow/core/grappler/costs:robust_stats' failed (Exit 127): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/liushuai/.cache/bazel/_bazel_liushuai/aa8adcb58cbbd827a6e521843f232b82/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda-11.0 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-9 \\\r\n    PATH=/usr/local/cuda-11.0/bin:/usr/local/python-3.7.9/bin:/usr/local/cuda-11.0/bin:/usr/local/cuda-11.0/bin:/usr/local/cuda-11.0/bin:/home/liushuai/miniconda3/bin:/home/liushuai/miniconda3/condabin:/usr/local/cuda-11.0/bin:/home/liushuai/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/liushuai/.fzf/bin:/usr/local/go/bin:/usr/local/python-3.7.9/bin:/usr/local/go/bin:/usr/local/python-3.7.9/bin:/usr/local/go/bin:/usr/local/python-3.7.9/bin:/usr/local/go/bin:/usr/local/go/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=8.6 \\\r\n    TF_CUDA_PATHS=/usr/local/cuda-11.0,/usr/local/cuda-11.0/targets/x86_64-linux,/usr/local/TensorRT-7.2.1.6 \\\r\n    TF_CUDA_VERSION=11 \\\r\n    TF_CUDNN_VERSION=8 \\\r\n    TF_NCCL_VERSION='' \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_TENSORRT=1 \\\r\n    TF_TENSORRT_VERSION=7 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/core/grappler/costs/_objs/robust_stats/robust_stats.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/core/grappler/costs/_objs/robust_stats/robust_stats.pic.o' -iquote . -iquote bazel-out/k8-opt/bin -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -w -DAUTOLOAD_DYNAMIC_KERNELS '-march=native' -Wno-sign-compare '-std=c++14' -c tensorflow/core/grappler/costs/robust_stats.cc -o bazel-out/k8-opt/bin/tensorflow/core/grappler/costs/_objs/robust_stats/robust_stats.pic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\n/usr/bin/env: 'python': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /home/liushuai/tensorflow/tensorflow/lite/toco/python/BUILD:88:1 C++ compilation of rule '//tensorflow/core/grappler/costs:robust_stats' failed (Exit 127): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/liushuai/.cache/bazel/_bazel_liushuai/aa8adcb58cbbd827a6e521843f232b82/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda-11.0 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-9 \\\r\n    PATH=/usr/local/cuda-11.0/bin:/usr/local/python-3.7.9/bin:/usr/local/cuda-11.0/bin:/usr/local/cuda-11.0/bin:/usr/local/cuda-11.0/bin:/home/liushuai/miniconda3/bin:/home/liushuai/miniconda3/condabin:/usr/local/cuda-11.0/bin:/home/liushuai/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/liushuai/.fzf/bin:/usr/local/go/bin:/usr/local/python-3.7.9/bin:/usr/local/go/bin:/usr/local/python-3.7.9/bin:/usr/local/go/bin:/usr/local/python-3.7.9/bin:/usr/local/go/bin:/usr/local/go/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=8.6 \\\r\n    TF_CUDA_PATHS=/usr/local/cuda-11.0,/usr/local/cuda-11.0/targets/x86_64-linux,/usr/local/TensorRT-7.2.1.6 \\\r\n    TF_CUDA_VERSION=11 \\\r\n    TF_CUDNN_VERSION=8 \\\r\n    TF_NCCL_VERSION='' \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_TENSORRT=1 \\\r\n    TF_TENSORRT_VERSION=7 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/core/grappler/costs/_objs/robust_stats/robust_stats.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/core/grappler/costs/_objs/robust_stats/robust_stats.pic.o' -iquote . -iquote bazel-out/k8-opt/bin -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -w -DAUTOLOAD_DYNAMIC_KERNELS '-march=native' -Wno-sign-compare '-std=c++14' -c tensorflow/core/grappler/costs/robust_stats.cc -o bazel-out/k8-opt/bin/tensorflow/core/grappler/costs/_objs/robust_stats/robust_stats.pic.o)**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@bleedingfight \r\n\r\nPlease, see tested build configurations from [here](https://www.tensorflow.org/install/source#gpu).\r\n\r\nPlease, refer similar issues #22372, #13481 and see if it helps you. Thanks!", "> @bleedingfight\r\n> \r\n> Please, see tested build configurations from [here](https://www.tensorflow.org/install/source#gpu).\r\n> \r\n> Please, refer similar issues #22372, #13481 and see if it helps you. Thanks!\r\n@ravikyram thanks for your reply.I've browsed the build page\uff0cYou mean I need to downgrade my software\uff1fgcc9.2-->GCC 7.3.1 and bazel 3.1->Bazel 0.27.1? In fact, I have successfully compiled software on the same type of platform\u3002In my desktop\uff1a\r\nOS\uff1a5.8.16-2-MANJARO\r\nNVIDIA Graphic Card\uff1aGTX980m\r\nDriver\uff1a450.80.02\r\ngcc\uff1a10.1\r\nTensorRT\uff1aTensorRT-7.2.0.14\r\nCUDA\uff1a11.0\r\nbazel:3.1\r\nCUDNN:8.0\r\nIn this env,I compile tensorflow's master branch and success generator tensorflow2.4.whl.\r\n", "Maybe I had found the problem.because tensorflow unsupport cc8.6(RTX3090 support 8.6),I changed the cc to 7.5(volta),and compile it again,it successed,if someone need it ,you can download it from [here:](https://pan.baidu.com/s/1aWFV3AtmcQjM1BZomALReg)  \u63d0\u53d6\u7801: aytj ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44692\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44692\">No</a>\n", "For me, the command that works is:\r\n`bazel build --config=opt --per_file_copt=//tensorflow/.*\\.cc@-g,-O0 tensorflow/tools/pip_package:build_pip_package`", "> For me, the command that works is: `bazel build --config=opt --per_file_copt=//tensorflow/.*\\.cc@-g,-O0 tensorflow/tools/pip_package:build_pip_package`\r\n\r\nThanks for you replay,it's workded when I use this:\r\n`bazel build  --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" -s -c dbg //tensorflow/tools/pip_package:build_pip_package`"]}, {"number": 44691, "title": "Performance regression when MKL is enabled", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo.\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 18.04.5\r\n\r\n- TensorFlow installed from (source or binary):\r\nBinary\r\n\r\n- TensorFlow version (use command below):\r\n1.13.2 and 1.14.0\r\n\r\n**Describe the current behavior**\r\nTrain a ssdlite_mobilenet_v2 model with 1.13.2 and 1.14.0, the inference speed is very different. 1.14.0 one is about 50% to 100% slow with MKL enabled. When MKL is disabled, there is no obvious difference.\r\n\r\nbenchmark_model shows:\r\n1.13.2\r\n<pre>\r\n             _MklFusedConv2D           55       13.732      43.384%     43.384%  45625.535         55\r\n         NonMaxSuppressionV3           27        5.386      17.016%     60.401%     10.800         27\r\n    _MklDepthwiseConv2dNative          33        3.161       9.987%     70.387%  20275.297         33\r\n                    _MklToTf           72        2.027       6.404%     76.791%  23987.072         72\r\n                         Mul           51        1.783       5.633%     82.424%     15.336         51\r\n                         Add           81        1.772       5.598%     88.023%      0.016         81\r\n                   _MklRelu6           33        0.731       2.309%     90.332%     30.096         33\r\n                        NoOp            1        0.462       1.460%     91.792%      0.000          1\r\n                        Cast            6        0.383       1.210%     93.002%   1104.316          6\r\n                       Slice           33        0.272       0.859%     93.861%    414.072         33\r\n                    GatherV2           69        0.227       0.717%     94.579%    253.200         69\r\n                       Const          614        0.180       0.569%     95.147%      0.000        688\r\n                _MklConcatV2            6        0.168       0.531%     95.678%    358.848          6\r\n        TensorArrayScatterV3            5        0.151       0.477%     96.155%   1317.728          5\r\n                         Sub           44        0.133       0.420%     96.575%     15.336         44\r\n                     Sigmoid            1        0.132       0.417%     96.992%      0.000          1\r\n                      TopKV2            2        0.117       0.370%     97.362%     43.200          2\r\n                StridedSlice           54        0.076       0.240%     97.602%      0.088         54\r\n                       Shape           50        0.058       0.183%     97.785%      0.344         50\r\n         TensorArrayGatherV3            6        0.057       0.180%     97.965%   1082.416          6\r\n               TensorArrayV3           11        0.051       0.161%     98.127%      2.596         11\r\n                        Pack           24        0.046       0.145%     98.272%     30.956         24\r\n              ResizeBilinear            1        0.045       0.142%     98.414%   1080.000          1\r\n                    ConcatV2           27        0.039       0.123%     98.537%     10.800         27\r\n                      Select           33        0.038       0.120%     98.657%      0.000         33\r\n                        Less           31        0.038       0.120%     98.777%      2.704         35\r\n                       Enter           26        0.036       0.114%     98.891%      0.000         26\r\n                       Merge           10        0.035       0.111%     99.002%      0.040         20\r\n                        Fill           30        0.031       0.098%     99.100%     11.204         30\r\n                   ZerosLike           29        0.030       0.095%     99.194%     10.808         29\r\n                     Reshape           74        0.028       0.088%     99.283%      0.000         74\r\n                       Split            3        0.026       0.082%     99.365%    129.600          3\r\n                      Unpack            5        0.023       0.073%     99.438%     92.044          5\r\n               _MklTranspose            3        0.020       0.063%     99.501%     92.016          3\r\n                      Switch           10        0.019       0.060%     99.561%      0.000         20\r\n                       Range           14        0.018       0.057%     99.618%      1.244         14\r\n               NextIteration           10        0.014       0.044%     99.662%      0.000         10\r\n                     Squeeze            4        0.010       0.032%     99.694%      0.000          4\r\n          TensorArrayWriteV3            6        0.009       0.028%     99.722%      0.000          6\r\n                     Minimum            6        0.009       0.028%     99.750%      0.000          6\r\n                     Greater            6        0.009       0.028%     99.779%      2.705          6\r\n                  ExpandDims            7        0.009       0.028%     99.807%      0.000          7\r\n                     _Retval            4        0.007       0.022%     99.829%      0.000          4\r\n                         Exp            2        0.007       0.022%     99.852%      0.000          2\r\n           TensorArraySizeV3            6        0.006       0.019%     99.870%      0.024          6\r\n                     Maximum            4        0.006       0.019%     99.889%      0.000          4\r\n                       Where            1        0.005       0.016%     99.905%     21.600          1\r\n           TensorArrayReadV3            5        0.005       0.016%     99.921%      0.000          5\r\n                         Sum            1        0.004       0.013%     99.934%      0.004          1\r\n                  LogicalAnd            2        0.004       0.013%     99.946%      0.000          4\r\n                         Pad            3        0.003       0.009%     99.956%      0.000          3\r\n                GreaterEqual            1        0.003       0.009%     99.965%      2.700          1\r\n                       Equal            2        0.003       0.009%     99.975%      0.002          2\r\n                        Size            2        0.002       0.006%     99.981%      0.008          2\r\n                    LoopCond            2        0.002       0.006%     99.987%      0.000          4\r\n                      Assert            3        0.002       0.006%     99.994%      0.000          3\r\n                        _Arg            1        0.001       0.003%     99.997%      0.000          1\r\n                        Tile            1        0.001       0.003%    100.000%      0.000          1\r\n                    Identity            4        0.000       0.000%    100.000%      0.000          4           \r\n                        Exit            6        0.000       0.000%    100.000%      0.000          6\r\nTimings (microseconds): count=283 first=29518 curr=32211 min=29448 max=39857 avg=32586.2 std=1784\r\n</pre>\r\n\r\n1.14.0\r\n<pre>\r\n                  _MklConv2D           43       12.516      28.381%     28.381%  43239.328         43\r\n    _MklDepthwiseConv2dNative          33        7.580      17.188%     45.569%  20275.297         33\r\n         NonMaxSuppressionV3           27        5.294      12.005%     57.574%     10.800         27  \r\n                         Add          114        5.088      11.537%     69.111%      0.016        114 \r\n                    _MklToTf          100        4.871      11.045%     80.156%  52036.352        100 \r\n                   _MklRelu6           59        2.116       4.798%     84.955%     53.808         59  \r\n                         Mul           51        1.774       4.023%     88.977%     15.336         51  \r\n             _MklFusedConv2D           12        1.282       2.907%     91.884%   2386.208         12  \r\n                        NoOp            1        0.563       1.277%     93.161%      0.000          1   \r\n                        Cast            6        0.374       0.848%     94.009%   1104.316          6   \r\n                       Slice           33        0.294       0.667%     94.676%    414.072         33  \r\n                       Const          601        0.293       0.664%     95.340%      0.000        677 \r\n                    GatherV2           69        0.232       0.526%     95.866%    253.200         69  \r\n                _MklConcatV2            6        0.174       0.395%     96.261%    358.848          6   \r\n        TensorArrayScatterV3            5        0.173       0.392%     96.653%   1317.728          5   \r\n                        AddN           10        0.142       0.322%     96.975%      0.000         10  \r\n                         Sub           44        0.138       0.313%     97.288%     15.336         44  \r\n                     Sigmoid            1        0.132       0.299%     97.587%      0.000          1   \r\n                      TopKV2            2        0.121       0.274%     97.862%     43.200          2   \r\n                StridedSlice           54        0.085       0.193%     98.054%      0.088         54  \r\n                     Reshape           74        0.063       0.143%     98.197%      0.000         74  \r\n         TensorArrayGatherV3            6        0.060       0.136%     98.333%   1082.416          6   \r\n                       Shape           50        0.056       0.127%     98.460%      0.344         50  \r\n              ResizeBilinear            1        0.055       0.125%     98.585%   1080.000          1   \r\n                    ConcatV2           27        0.053       0.120%     98.705%     10.800         27  \r\n               TensorArrayV3           11        0.052       0.118%     98.823%      2.596         11  \r\n                        Pack           24        0.051       0.116%     98.939%     30.956         24  \r\n                      Select           33        0.043       0.098%     99.036%      0.000         33  \r\n                       Enter           26        0.042       0.095%     99.132%      0.000         26  \r\n                        Less           31        0.040       0.091%     99.222%      2.704         35  \r\n                       Merge           10        0.037       0.084%     99.306%      0.040         20  \r\n                        Fill           30        0.032       0.073%     99.379%     11.204         30  \r\n                   ZerosLike           29        0.031       0.070%     99.449%     10.808         29  \r\n                       Split            3        0.027       0.061%     99.510%    129.600          3   \r\n                      Unpack            5        0.025       0.057%     99.567%     92.044          5   \r\n                      Switch           10        0.022       0.050%     99.617%      0.000         20  \r\n               _MklTranspose            3        0.020       0.045%     99.662%     92.016          3   \r\n                       Range           14        0.017       0.039%     99.701%      1.244         14  \r\n               NextIteration           10        0.017       0.039%     99.739%      0.000         10  \r\n          TensorArrayWriteV3            6        0.012       0.027%     99.766%      0.000          6   \r\n                     Squeeze            4        0.010       0.023%     99.789%      0.000          4   \r\n                     Minimum            6        0.009       0.020%     99.810%      0.000          6   \r\n                     Greater            6        0.009       0.020%     99.830%      2.705          6   \r\n                  ExpandDims            7        0.009       0.020%     99.850%      0.000          7   \r\n                     _Retval            4        0.008       0.018%     99.868%      0.000          4   \r\n           TensorArrayReadV3            5        0.007       0.016%     99.884%      0.000          5   \r\n                         Exp            2        0.007       0.016%     99.900%      0.000          2   \r\n           TensorArraySizeV3            6        0.006       0.014%     99.914%      0.024          6   \r\n                  LogicalAnd            2        0.006       0.014%     99.927%      0.000          4   \r\n                       Where            1        0.005       0.011%     99.939%     21.600          1   \r\n                     Maximum            4        0.005       0.011%     99.950%      0.000          4   \r\n                         Sum            1        0.004       0.009%     99.959%      0.004          1   \r\n                         Pad            3        0.003       0.007%     99.966%      0.000          3   \r\n                GreaterEqual            1        0.003       0.007%     99.973%      2.700          1   \r\n                       Equal            2        0.003       0.007%     99.980%      0.002          2   \r\n                        Size            2        0.002       0.005%     99.984%      0.008          2   \r\n                    LoopCond            2        0.002       0.005%     99.989%      0.000          4   \r\n                      Assert            2        0.002       0.005%     99.993%      0.000          2   \r\n                        _Arg            1        0.001       0.002%     99.995%      0.000          1   \r\n                        Tile            1        0.001       0.002%     99.998%      0.000          1   \r\n\r\nTimings (microseconds): count=207 first=39464 curr=48545 min=38998 max=65787 avg=45005.9 std=4312\r\n</pre>", "comments": ["@YijinLiu \r\nAs there is support for 2.x only now,could you please upgrade ad let us know if you still face any issues in 2.x.", "Unfortunately, tf2 doesn't fully support the model I am using. I am stuck in tf1 for now.\r\nI use the C++ interface. I assume there is no much difference between tf1 and tf2?\r\nI tried tf1.5, which has the exact same issue. I guess it's related to some mkl C++ code that cannot handle conv2d for models trained with tf1.4+. Is it possible that you have some guy from Intel (whoever contributed https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/mkl_layout_pass.cc) take a look?\r\n", "@YijinLiu \r\nThere is Intel optimized Tensorflow 1.15.0up1.\r\nIt includes many bug and performance fix.\r\nWe have got good performance improvement feedback from customers.\r\n\r\nCould you try with it?\r\n\r\nInstallation:\r\n`pip install https://storage.googleapis.com/intel-optimized-tensorflow/intel_tensorflow-1.15.0up1-cp36-cp36m-manylinux2010_x86_64.whl \r\n`", "@YijinLiu \r\nIs there any feedback?", "I just tried it. Got illegal instruction...\r\nMy CPU is i7-10700. I hope running inside docker won't be a problem.", "@YijinLiu \r\nOh, could you share your log for the issue?\r\n\r\nIt's Tensorflow 1.15 base, so the script need to be changed from some API of Tensorflow 1.13 or 1.14 to 1.15.\r\nIs there same issue when run your script with stack/official TF 1.15?\r\n\r\nWhat's the guest OS in docker?\r\n", "@YijinLiu \r\nCould you share the log?\r\n\r\nHow do you 'set MKL is disabled' in TF 1.14.0?\r\n", "@YijinLiu \r\nIs your issue present?\r\nIf yes, could you answer above questions?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44691\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44691\">No</a>\n"]}, {"number": 44690, "title": "Expose Logging C API in pip package", "body": "While working on modular file systems, noticed that the logging\r\nC API headers are not included in tensorflow pip packages.\r\n\r\nThis limit the ability for plugins to add logging in the file system.\r\n\r\nThis PR adds logging C API header in pip package.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 44689, "title": "[Docs should enhance] The docs not tell me: How does a TPU cluster allocate memory for the model?", "body": "My issue in short words, I'm creating a model just a single LSTM layer (`layers.LSTM(units=16298, input_shape=(1, 16298))`), and my google cloud vm connect to the `v3-8` tpu which has total 128GB RAM, why I still got `ResourceExhaustedError` exception? It seems only use one TPU core (16GB RAM) to create model, not the total (16 * 8 = 128GB).\r\n\r\nCan some one tell me: How does a TPU cluster allocate memory for the model?\r\n\r\nThis is my issue details: https://stackoverflow.com/questions/64737657/how-much-memory-do-i-need-for-my-lstm-model", "comments": ["Hi @GF-Huang, you can see [here in the docs for tf.distribute.TPUStrategy](https://www.tensorflow.org/api_docs/python/tf/distribute/TPUStrategy) that when \"using distribution strategies, the variables created within the strategy's scope will be replicated across all the replicas.\"\r\n\r\nYou can determine the number of replicas with `strategy.num_replicas_in_sync` (I think this should return 8 in your case). With a distribution strategy, the model is not split up across the cores. The tf.distribute.Strategy API currently supports data parallelism, which means that there is a copy of the model on each replica. And it is the data in each batch that gets split up across replicas. TPUs provide an implementation of efficient all-reduce and other collective operations to keep the variables in sync across multiple TPU cores. The[ Distributed Training with TensorFlow guide](https://www.tensorflow.org/guide/distributed_training#tpustrategy) provides some more information on how strategies work. For reference, in terms of distributed training architecture, TPUStrategy is the same [MirroredStrategy](https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy). Hope this clears things up.", "> Hi @GF-Huang, you can see [here in the docs for tf.distribute.TPUStrategy](https://www.tensorflow.org/api_docs/python/tf/distribute/TPUStrategy) that when \"using distribution strategies, the variables created within the strategy's scope will be replicated across all the replicas.\"\r\n> \r\n> You can determine the number of replicas with `strategy.num_replicas_in_sync` (I think this should return 8 in your case). With a distribution strategy, the model is not split up across the cores. The tf.distribute.Strategy API currently supports data parallelism, which means that there is a copy of the model on each replica. And it is the data in each batch that gets split up across replicas. TPUs provide an implementation of efficient all-reduce and other collective operations to keep the variables in sync across multiple TPU cores. The[ Distributed Training with TensorFlow guide](https://www.tensorflow.org/guide/distributed_training#tpustrategy) provides some more information on how strategies work. For reference, in terms of distributed training architecture, TPUStrategy is the same [MirroredStrategy](https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy). Hope this clears things up.\r\n\r\nThanks for your detailed reply. So tensorflow doesn't supports model parallelism?", "Currently, the tf.distribute.Strategy API only supports data parallelism. If you want to try out model parallelism, you can take a look at [mesh tensorflow](https://github.com/tensorflow/mesh).\r\n\r\nClosing this issue now, since there is no bug."]}, {"number": 44687, "title": "How can I use micro_mutable_op_resolver.h instead of all_ops_resolver.h to run TensorFlow Lite for Microcontrollers exapmle?", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows subsystem for Linux, Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): \r\n- Tensorflow version (commit SHA if source): \r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): My own PC\r\n\r\n**Describe the problem**\r\n\r\nI'm running test on the hello_world example in TensorFlow Lite for Microcontrollers, on my own develop machine.\r\nIn [https://www.tensorflow.org/lite/microcontrollers/library](https://www.tensorflow.org/lite/microcontrollers/library) I found an option to use **micro_mutable_op_resolver.h** instead of **all_ops_resolver.h**, so that I can only pull in the ops I need.\r\nI've tried to change some lines in hello_world_test.cc, but still can't get it right.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\nI've change these lines in tensorflow\\lite\\micro\\examples\\hello_world\\hello_world_test.cc:\r\nline 16: \r\n`#include \"tensorflow/lite/micro/all_ops_resolver.h\"`\r\nto : \r\n`#include \"tensorflow/lite/micro/micro_mutable_op_resolver.h\"`\r\nline 41: \r\n`tflite::AllOpsResolver resolver;`\r\nto: \r\n```\r\nconst unsigned int tOpCount = 5;\r\ntflite::MicroMutableOpResolver<tOpCount> resolver;\r\n```\r\n\r\nthen I run the command: \r\n`sudo make -f tensorflow/lite/micro/tools/make/Makefile test_hello_world_test `\r\nBut It seems to pull in and compile all ops. Also, after printing out\"~~~ALL TESTS PASSED~~~'\", the process doesn't end.\r\n\r\nCould anyone help me please?\r\n\r\n", "comments": ["Hi, it's me again.\r\nI referred to another task--micro_speech, which uses micro_op_resolver.h in both main_functions.cc and micro_speech_test.cc.\r\nIt seems like I should make a list of all ops I need, so in `hello_world_test.cc`, I modify the following lines:\r\nline 18:\r\n`#include \"tensorflow/lite/micro/all_ops_resolver.h\"`\r\nto\r\n`#include \"tensorflow/lite/micro/micro_mutable_op_resolver.h\"`\r\nline 47:\r\n`tflite::AllOpsResolver resolver;`\r\nto\r\n```\r\n  tflite::MicroMutableOpResolver<5> resolver;\r\n  resolver.AddDequantize();\r\n  resolver.AddFullyConnected();\r\n  resolver.AddQuantize();\r\n  resolver.AddRelu();\r\n  resolver.AddReshape();\r\n```\r\n\r\nIn `hello_world/main_functions.cc` I modifiy:\r\nline 18:\r\n`#include \"tensorflow/lite/micro/all_ops_resolver.h\"`\r\nto\r\n`#include \"tensorflow/lite/micro/micro_mutable_op_resolver.h\"`\r\nline 67:\r\n`static tflite::AllOpsResolver resolver;`\r\nto\r\n```\r\n  static tflite::MicroMutableOpResolver<5> resolver(error_reporter);\r\n  if (resolver.AddDequantize() != kTfLiteOk) {\r\n    return;\r\n  }\r\n  if (resolver.AddFullyConnected() != kTfLiteOk) {\r\n    return;\r\n  }\r\n  if (resolver.AddQuantize() != kTfLiteOk) {\r\n    return;\r\n  }\r\n  if (resolver.AddRelu() != kTfLiteOk) {\r\n    return;\r\n  }\r\n  if (resolver.AddReshape() != kTfLiteOk) {\r\n    return;\r\n  }\r\n```\r\n\r\nActually I'm not sure how many ops should I use. When I was testing, I found that I can pass the test using only AddFullyConnected().\r\nAt least it works better than 3 days ago. If anyone knows how to check the ops used in a model, or spots some problem in my code, please leave a comment.\r\nThank you for helping.\r\n\r\n", "Hi @Dueschen!\r\nCould you post this issue in Stackoverflow /[TF forum ](https://discuss.tensorflow.org/)as there is a larger community to help you out .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44687\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44687\">No</a>\n"]}, {"number": 44686, "title": "Typo in tf.keras.callbacks.EarlyStopping example", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\r\n\r\n## Description of issue (what needs changing):\r\nThe following is from the `EarlyStopping` page on TensorFlow website.\r\n\r\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\r\n\r\nThis callback will stop the training when there is no improvement in the validation loss for three consecutive epochs.\r\n\r\nIn the above line, it should have been \"loss\" instead of \"validation loss\". \r\n\r\n### Clear description\r\nCheck above. Please check [this gist](https://colab.research.google.com/drive/1IL5tVIR_ulSeUQeBtDgrj0F5vZm7drYE#scrollTo=L9UTqnI3qd08) for an example.\r\n\r\n### Correct links\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\r\n\r\n### Submit a pull request?     \r\nYes\r\n\r\n\r\n", "comments": ["I am closing this issue as this was resolved. Thanks!"]}, {"number": 44685, "title": "Arguments have an HTML format issue", "body": "## URL(s) with the issue: https://www.tensorflow.org/api_docs/python/tf/image/extract_patches\r\n\r\nThe arguments need to be reformatted:\r\n\r\n![Screen Shot 2020-11-08 at 17 28 21](https://user-images.githubusercontent.com/8287111/98470714-dafb5b00-21e7-11eb-8221-96eb105b5e52.png)\r\n\r\n", "comments": ["Can you send a PR?", "Sure, I just learned how to do that. But it looks like it's fixed on the latest version. Should I fixed it for that specific doc version (2.3.0)?", "If it is fixed in master/2.4 then there is nothing left to do. Since we only update old versions only for security issues.", "@houseofai \r\n\r\nPlease, close this thread as the issue is fixed in latest version. Thanks!"]}, {"number": 44683, "title": "Not creating XLA devices, tf_xla_enable_xla_devices not set", "body": "Hi,\r\n\r\nI have recently upgraded my system to the following configuration:\r\n\r\nOS: ubuntu 18.04\r\ngcc: 7.5.0\r\ncuda: 10.2\r\ncuDNN:7.6.5\r\nTensorRT: 6.0.1.8\r\nTensorflow:2.5.0\r\nMy GPU spec: device: 0, name: GeForce GTX 1060 6GB\r\n\r\nOnce Tensorflow installation is completed, i checked the following cpde:\r\n\r\n`with tf.device('/gpu:0'):\r\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\nc = tf.matmul(a, b)\r\nwith tf.Session() as sess:\r\n   print (sess.run(c))\r\n`\r\n\r\nWhen I execute it in a terminal, I find the following:\r\n\r\n`>>> import tensorflow as tf\r\n2020-11-08 13:00:32.053030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n>>> with tf.device('/gpu:0'):\r\n...     a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\n...     b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\n...     c = tf.matmul(a, b)\r\n... \r\n2020-11-08 13:00:33.123388: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-08 13:00:33.123967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-11-08 13:00:33.137540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-08 13:00:33.137915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1724] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-11-08 13:00:33.137933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-11-08 13:00:33.139254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2020-11-08 13:00:33.139295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2020-11-08 13:00:33.140475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-11-08 13:00:33.140641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-11-08 13:00:33.141883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-11-08 13:00:33.142541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2020-11-08 13:00:33.145144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2020-11-08 13:00:33.145247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-08 13:00:33.145551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-08 13:00:33.145778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1866] Adding visible gpu devices: 0\r\n2020-11-08 13:00:33.146034: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-08 13:00:33.146315: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-08 13:00:33.146377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-08 13:00:33.146602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1724] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-11-08 13:00:33.146616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-11-08 13:00:33.146645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2020-11-08 13:00:33.145247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-08 13:00:33.145551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-08 13:00:33.145778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1866] Adding visible gpu devices: 0\r\n2020-11-08 13:00:33.146034: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-08 13:00:33.146315: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-08 13:00:33.146377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n\r\n`\r\n\r\nI would like to know how to resolve the `xla_devices not set` and `SysFS had negative value (-1)`issues.\r\n\r\nany suggestions?\r\n\r\nregards,", "comments": ["@Angit16,\r\nThe `Not creating XLA devices, tf_xla_enable_xla_devices not set` message is an information log which you can safely ignore. \r\n\r\nTo verify that TensorFlow has detected the GPU on you machine, please run the below code and check the number of GPUs available\r\n```\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n```\r\n\r\nThanks!", "okay, thanks. I would appreciate it if you can provide some insight on these warnings though, would be helpful for me to understand. I have been looking into it as well.\r\n\r\nregadrs,\r\n", "[RELEASE.md](https://github.com/tensorflow/tensorflow/blob/r2.4/RELEASE.md) reads:\r\n> XLA:CPU and XLA:GPU devices are no longer registered by default. Use TF_XLA_FLAGS=--tf_xla_enable_xla_devices if you really need them (to be removed).", "@Angit16,\r\nSorry for the delayed response. Could you please check @vmarkovtsev's comment and let us know if it helps. Thanks!", "thanks. It does.", "@Angit16,\r\nThank you for the update. Marking the issue as close, as it is resolved. Please feel free to re-open if necessary.", "I ran a same model using TF 2.3 with both CUDA 10.1 and 11.1. With CUDA 10.1 without XLA warning, it was much much faster and it used my GPU more efficient than CUDA 11.1 with XLA warning. To be specific, CUDA 10.1 trained my large model (BERT) with 60% GPU usage in about 3mins for each epoch and the batch size was much larger. However, CUDA 11.1 used only 8% GPU and ran each epoch in about 10 mins (> 3X slower)", "I notice that with XLA, the use of GPU  is almost 100%,, and much faster to finish the job.  Without, it is taking much more time, with less than 40% usage. ", "Also, would like to know, how to activate it on R, rstudio. ", "@ehsanaghaei, @rpsantosa,\r\nCould y'all please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "> Use TF_XLA_F\r\n\r\nI'm sorry. I have this problem too. How can I use TF_XLA_FLAGS=--tf_xla_enable_xla_devices. I mean what do I have to write to set this environment variable?", "On environment variable on windows. Type env on search bar. \n\n> Em 29 de dez. de 2020, \u00e0(s) 12:22, Omid Ghozatlou <notifications@github.com> escreveu:\n> \n> \ufeff\n> Use TF_XLA_F\n> \n> I'm sorry. I have this problem too. How can I use TF_XLA_FLAGS=--tf_xla_enable_xla_devices. I mean what do I have to write to set this environment variable?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or unsubscribe.\n", "To not leave anyone hanging: I had same problem with same warning and surprisingly slow performance on RTX 3090, CUDA 11.1, TF 2.5 nightly and adding the windows environment variable TF_XLA_FLAGS = --tf_xla_enable_xla_devices seems to have solved the problem. ", "I'm training CycleGAN network on RTX 3090 with CUDA 11.1.\r\nTraining the model on subset of dataset (celebA with certain attributes) which has around 3K images.\r\nBefore setting any flags each epoch took ~2399 secs. That's quite a lot of time.\r\nPreviously I used Google Colab. For some reason the GPU P100 took less time (~780-800 secs)whilst It should be T4(~1270-1300 secs).\r\nI've set this flag below.\r\n`export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda`\r\n`export TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\"`\r\n\r\nBoom!! Now each epoch is taking ~410-415secs.\r\nCrazy fast!!", "Can this be re-opened and some documentation be added on these flags, it is very trial and error at the moment.", "I'd like to know more as now I am seeing this recommended TF_XLA_FLAGS=--tf_xla_cpu_global_jit", "@ydennisy,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "@Arvindia how exactly can i can export or set variable to remove error: Not creating XLA devices, tf_xla_enable_xla_devices not set,  Thanks for your help.", "> \r\n> \r\n> @Arvindia how exactly can i can export or set variable to remove error: Not creating XLA devices, tf_xla_enable_xla_devices not set, Thanks for your help.\r\n\r\nset it in bashrc file", "I also have the same problem. could anyone please help me with how to set up with a full explanation?\r\n\r\nThanks,\r\nRegards,\r\nKumar\r\n\r\n", "@amahendrakar each time someone opens an issue related to this - it get closed.", "> @amahendrakar each time someone opens an issue related to this - it get closed.\r\n\r\n@ydennisy,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose), so that it can be tracked separately and where you'll be the owner for it. Thanks!", "> I also have the same problem. could anyone please help me with how to set up with a full explanation?\r\n> \r\n> Thanks,\r\n> Regards,\r\n> Kuma\r\n\r\n\r\n> I also have the same problem. could anyone please help me with how to set up with a full explanation?\r\n> \r\n> Thanks,\r\n> Regards,\r\n> Kumar\r\n\r\n1- Go to Environment Variables from search panel.\r\n2- You will see Local variables and System variables.\r\n3- Click new for system variables.\r\n4- Variables name = TF_XLA_FLAGS\r\n5- Variables value = --tf_xla_enable_xla_devices\r\n6- Save it and try your scripts (e.g. python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\")", "On Windows, use the following in the cmd window before executing your Python script:\r\n`SET TF_XLA_FLAGS=--tf_xla_enable_xla_devices`\r\nThen when you run your TF script you should see something like this:\r\n`2021-03-28 08:25:51.619986: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e1afc777c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2021-03-28 08:25:51.620281: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN X (Pascal), Compute Capability 6.1`", "I am using UDA 11.2 om windows 10 (GPU: Quadro P2200,) , and have the similar issue. Even after SET TF_XLA_FLAGS=--tf_xla_enable_xla_devices.  My application is the ANPR using easyOCR. The processing time for one license plate is 2+ seconds on CPU. I need to enable GPU for a better performance. \r\n\r\nHere is the log. Any advice or tips is appreciated. \r\n\r\n021-04-19 09:36:51.937087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\nWARNING:tensorflow:From C:/Users/mitchell/PycharmProjects/BT1-ph1/car_tracking/easyocr-ex1.1.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices('GPU')` instead.\r\n2021-04-19 09:36:56.910078: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-04-19 09:36:56.913620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021-04-19 09:36:56.940892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: Quadro P2200 computeCapability: 6.1\r\ncoreClock: 1.493GHz coreCount: 10 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 186.45GiB/s\r\n2021-04-19 09:36:56.941082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-04-19 09:36:57.240387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-04-19 09:36:57.240506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-04-19 09:36:58.220924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-04-19 09:36:58.317657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-04-19 09:36:58.421604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-04-19 09:36:58.527487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-04-19 09:36:58.576525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-04-19 09:36:58.576759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n\r\n\r\n2021-04-19 09:36:59.264539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-04-19 09:36:59.264639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \r\n2021-04-19 09:36:59.264691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \r\n2021-04-19 09:36:59.264860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 3825 MB memory) -> physical GPU (device: 0, name: Quadro P2200, pci bus id: 0000:65:00.0, compute capability: 6.1)\r\n2021-04-19 09:36:59.266013: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nUsing CPU. Note: This module is much faster with a GPU.\r\n\r\nprocessing time: 2.8133368492126465\r\nNum GPUs Available:  1\r\n[([[6, 4], [128, 4], [128, 34], [6, 34]], 'HR.26 BR.9044', 0.5728024956877317)]\r\n"]}, {"number": 44682, "title": "Tensorflow support for Nvidia geforce rtx 3090 - CUDA-11.1", "body": "The rtx 3090 has been a beast in deeplearning performance and yet tensorflow has no support for training on CUDA-11.1 and cuDNN-8.\r\n\r\nit would be great if added soon.", "comments": ["@JVedant \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\nThis issue is already reported, please refer to these existing issues with respect to rtx 3090 and CUDA 11.1  #44200, #44251, #43588 #44159", "It's my first time opening an issue here so i'm not aware about the issue template.\r\n\r\nI think i've got some help by checking the issue id's provided by you.\r\nI'll try it once and if I wont be able to achieve any results, i'll open an issue with 'build' tag.\r\n\r\nThanks for providing the solution!", "@JVedant \r\nThank you for the update, please move the ticket to closed status if resolved.", "@JVedant I got my 3090 yesterday and was in full panic mode as well, but if you have not installed everything here is my order that \"worked\" (atleast my custom training loops and non sequential models produce results that I expect, but with a major speedup compared to my old setup):\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/44159\r\n\r\nThe OP is a bit older, so the versions have slightly changed:\r\n\r\n- OS Platform and Distribution: Windows 10 Pro 64 bit\r\n- TensorFlow installed from (source or binary): pip install tf-nightly-gpu=2.5.0.dev20201110\r\n- Python version: 3.8.6 (don't forget to downgrade numpy because windows reasons)\r\n- Installed using virtualenv? pip? conda?: Pip (in conda env)\r\n- CUDA/cuDNN version: CUDA 11.1/cuDNN 8.4.0.30 *****\r\n- GPU model and memory: NVIDIA RTX 3090 (24 GB)\r\n\r\n\r\n***** As with the issue I simply installed CUDA 10.2 for the missing DLL file. Simple install, no change in env CUDA paths (these are changed automatically but do no matter?), no additional CUDNN, nothing. Afterwards it worked for me. Some in the other issue simply downloaded the missing DLL (10 versio nof cuda solver) and put it into their 11 folder to get it working.", "@fshofmann is your T.F. 2.5.0.dev20201110 recognized the 3090 GPU?\r\n\r\nI tried running:-\r\n\r\nfrom tensorflow.python.client import device_lib\r\ndevice_lib.list_local_devices()\r\n\r\nbut the output was Just CPU.", "@Thunder003 My TF installation definitely uses the GPU. Are you 100% sure that you installed the package tf-nightly-gpu=2.5.0.dev20201110 and not the gpu-less version tf-nightly? ", "@fshofmann yes, I used the command: **pip install tf-nightly-gpu==2.5.0.dev20201028**,......then check whether GPU recognized by TF or not using:-\r\n\r\n**from tensorflow.python.client import device_lib\r\ndevice_lib.list_local_devices()**\r\n\r\nwhich returned me CPU only. Did you use the above line of code to confirm whether the T.F. recognized the GPU? if not, then can you give a shot to those two lines of code and see whether it returns GPU or not,  maybe that code no longer works on new T.F. version which is why it is not returning any GPU. In such a case, do you know any command to check whether T.F. is recognizing GPU or not.", "> @fshofmann yes, I used the command: **pip install tf-nightly-gpu==2.5.0.dev20201028**,......then check whether GPU recognized by TF or not using:-\r\n> \r\n> **from tensorflow.python.client import device_lib device_lib.list_local_devices()**\r\n> \r\n> which returned me CPU only. Did you use the above line of code to confirm whether the T.F. recognized the GPU? if not, then can you give a shot to those two lines of code and see whether it returns GPU or not, maybe that code no longer works on new T.F. version which is why it is not returning any GPU. In such a case, do you know any command to check whether T.F. is recognizing GPU or not.\r\n\r\nYou can give a try to tf.test.is_gpu_available() \"i know it's gonna get depricated in new versions but it works as of now\".\r\n\r\nyou can check #44753 where I've mentioned the system config and #43947 is where i got my solution. If you're still facing the issue lemme know on here. I can write about the whole process i followed to get it running.", "> @fshofmann yes, I used the command: **pip install tf-nightly-gpu==2.5.0.dev20201028**,......then check whether GPU recognized by TF or not using:-\r\n> \r\n> **from tensorflow.python.client import device_lib device_lib.list_local_devices()**\r\n> \r\n> which returned me CPU only. Did you use the above line of code to confirm whether the T.F. recognized the GPU? if not, then can you give a shot to those two lines of code and see whether it returns GPU or not, maybe that code no longer works on new T.F. version which is why it is not returning any GPU. In such a case, do you know any command to check whether T.F. is recognizing GPU or not.\r\n\r\nI am usually using the following snippet at the start of my programs to double check my env:\r\n```\r\nif tf.test.gpu_device_name():\r\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\r\nelse:\r\n    print(\"Please install GPU version of TF\")\r\n```\r\n\r\nIn addition, for the past 12 days, I have been fully utilizing the new GPU to do GAN training, so it definetely works (it is constantly at 100% load) :) That's why I am so sure it works. \r\n\r\nAs I said before, this issue helped me a lot: https://github.com/tensorflow/tensorflow/issues/44159\r\nIt practically described what I already said here.", "@JVedant @fshofmann thanks for your answer. I figured out that it is libcusolver.so.10 issue( It is not present), I followed #43947 of creating a symlink https://github.com/tensorflow/tensorflow/issues/43947#issuecomment-715295153 but I'm getting another error:-\r\n\"\"failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\"\". Do you know the solution for it or else I'll ask on #43947", "> @JVedant @fshofmann thanks for your answer. I figured out that it is libcusolver.so.10 issue( It is not present), I followed #43947 of creating a symlink [#43947 (comment)](https://github.com/tensorflow/tensorflow/issues/43947#issuecomment-715295153) but I'm getting another error:-\r\n> \"\"failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\"\". Do you know the solution for it or else I'll ask on #43947\r\n\r\nI guess you've got cuda 11.1, if yes then find libcusolver.so.11 in your cuda path and make a copy of it named 'libcusolver.so.10' and paste it in your environment at **env -> lib -> python3.x -> site-packages -> tensorflow -> python** it works.\r\n\r\nFor me CUDA 11.1, cuDNN-8 and tf-2.4.0-rc1 worked perfectly.", "@JVedant thanks for your answer. My bug is fixed using by taking some references from https://github.com/NVIDIA/nvidia-docker/issues/1256", "> > @fshofmann yes, I used the command: **pip install tf-nightly-gpu==2.5.0.dev20201028**,......then check whether GPU recognized by TF or not using:-\r\n> > **from tensorflow.python.client import device_lib device_lib.list_local_devices()**\r\n> > which returned me CPU only. Did you use the above line of code to confirm whether the T.F. recognized the GPU? if not, then can you give a shot to those two lines of code and see whether it returns GPU or not, maybe that code no longer works on new T.F. version which is why it is not returning any GPU. In such a case, do you know any command to check whether T.F. is recognizing GPU or not.\r\n> \r\n> You can give a try to tf.test.is_gpu_available() \"i know it's gonna get depricated in new versions but it works as of now\".\r\n> \r\n> you can check #44753 where I've mentioned the system config and #43947 is where i got my solution. If you're still facing the issue lemme know on here. I can write about the whole process i followed to get it running.\r\n\r\n@JVedant could you give a more detailed description on how you got tensorflow to train on your gpu? I have tried tf-nightly-gpu and the 2.4.0 release candidates but I still cannot get my models to train on my gpu. Details at my [stack question](https://stackoverflow.com/questions/65056018/tensorflow-trains-on-cpu-instead-of-rtx-3000-series-gpu)", "> > > @fshofmann yes, I used the command: **pip install tf-nightly-gpu==2.5.0.dev20201028**,......then check whether GPU recognized by TF or not using:-\r\n> > > **from tensorflow.python.client import device_lib device_lib.list_local_devices()**\r\n> > > which returned me CPU only. Did you use the above line of code to confirm whether the T.F. recognized the GPU? if not, then can you give a shot to those two lines of code and see whether it returns GPU or not, maybe that code no longer works on new T.F. version which is why it is not returning any GPU. In such a case, do you know any command to check whether T.F. is recognizing GPU or not.\r\n> > \r\n> > \r\n> > You can give a try to tf.test.is_gpu_available() \"i know it's gonna get depricated in new versions but it works as of now\".\r\n> > you can check #44753 where I've mentioned the system config and #43947 is where i got my solution. If you're still facing the issue lemme know on here. I can write about the whole process i followed to get it running.\r\n> \r\n> @JVedant could you give a more detailed description on how you got tensorflow to train on your gpu? I have tried tf-nightly-gpu and the 2.4.0 release candidates but I still cannot get my models to train on my gpu. Details at my [stack question](https://stackoverflow.com/questions/65056018/tensorflow-trains-on-cpu-instead-of-rtx-3000-series-gpu)\r\n\r\ncan you please mention your OS. you can also try **tf.test.is_gpu_available()** to check whether the gpu is detected by tf or not, also try **tf.device('/gpu:0')** to force the training on gpu, there is a chance of the model not performing backward propagation (accuracy and loss won't change even if the model is getting trained). if you observe the accuracy not changing, i would recommend to reinstall everything including nvidia drivers, cudnn, cuda and tf(tf-nightly with gpu).\r\n\r\nIf you face any issues as mentioned in  #43947 , you can perform steps mentioned in [above](https://github.com/tensorflow/tensorflow/issues/44682#issuecomment-732283634) solutions\r\n\r\n(Also maybe you'll have to perform some manual changes in the folder directory if nothing works) if any such things happen you can reply to this ticket and we can try something else.", "Thanks for the tips, I am using windows 10 home."]}, {"number": 44681, "title": "How to implement custom delegate that supports dynamic-sized tensor", "body": "Hi,\r\n\r\nI'm implementing custom TFLite delegation for my accelerator.\r\nMy implemented the delegation largely referring [dummy delegate example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/utils/dummy_delegate)\r\nBut when I modify the graph using my delegate, I got following error.\r\n```\r\nERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.\r\n```\r\nSo I want to enable dynamic-sized tensor support in my delegate.\r\nBut I couldn't find any guidelines for that.\r\n\r\n**What should I do to support dynamic-sized tensors in my custom delegate?**\r\nDo tensorflow have such an example?\r\n\r\nThanks in advance!", "comments": ["Apologies for the delay in response. I think this question is better asked on [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow) since the use cases can be different for each user. You may find this [thread](https://github.com/tensorflow/tensorflow/issues/41194) useful to build a custom delegate. Thanks!"]}, {"number": 44680, "title": "Install tf-nightly 2.0", "body": "I need install ```tf-nightly 2.0```.  Where can I find older versions of the library?. On this site https://pypi.org/project/tf-nightly/#history the oldest is 2.4.0\r\n", "comments": ["@Rariusz,\r\nWe don't save nightly packages for longer period of time. Current archive collects nightly packages from the month of September 2020 till date.\r\n\r\nFor more information, please take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/37317#issuecomment-595382300) from a similar issue. Thanks!", "@amahendrakar Thanks for the answer!!! I wanted to compile yolo to tflite model based on this repository  [YOLO](https://github.com/guichristmann/edge-tpu-tiny-yolo?fbclid=IwAR0-OrnFUL-k9xXbTieLb4sJr3YS3xIdeLyfxGlaYWJu1rheyQoCUaM5iD4) and it is required there tf-nightly 2.0.\r\n\r\nNow I am working on compiling a tensorflow model to tflite or yolo to tflite for my own data \r\nhttps://github.com/tensorflow/tensorflow/issues/44435 \r\nhttps://github.com/google-coral/edgetpu/issues/248 \r\nhttps://github.com/tensorflow/tensorflow/issues/44610 \r\nand that was the reason why I asked about this particular version\r\n\r\n\r\n"]}, {"number": 44679, "title": "[keras/optimizer_v2/ftrl.py] Reflect defaults in docstring", "body": "I'm writing an open-source typed wrapped for TensorFlow [and other ML frameworks], to enable good errors; parameter optimisation and analysis; over other interfaces like CLI, GUIs and decoupled frontends, databases, RPC, and REST.\r\n\r\nThe docstrings must reflect the defaults in the `__init__` function, otherwise I'll need to extend my side to parse & merge the defaults\u2014e.g., from [`inspect.Signature`](https://docs.python.org/3/library/inspect.html#inspect.signature) or from [`ast`](https://docs.python.org/3/library/ast.html)\u2014with the `class`'s docstring.\r\n\r\nSo this'll probably be the first of many trivial change PRs I'll be sending over :+1: ", "comments": ["@SamuelMarks can you please check ubuntu sanity build failures ?", "@rthadur Fixed."]}, {"number": 44678, "title": "How to install tensorflow gpu on rtx 3070", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):both\r\n- TensorFlow version:2.3.0\r\n- Python version:3.7\r\n- Installed using virtualenv? pip? conda?:conda\r\n- Bazel version (if compiling from source):3.1.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:11.1;8.0\r\n- GPU model and memory:rtx 3070 8gb\r\n\r\n\r\n\r\n**Describe the problem**\r\n I have brought a rtx 3070 and I want to use tensorflow gpu on it. To use it I need to use cuda 11.1\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nSo tried building from source but that did not work , issue is here https://github.com/tensorflow/tensorflow/issues/44671. And I also tried using tf nightly but that has a bug in it of numpy falling sanity check.\r\n\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44678\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44678\">No</a>\n", "I solved the problem using the following command:\r\n```shell\r\n  pip install tf-nightly-gpu\r\n```"]}, {"number": 44677, "title": "Fail for tf.image.flip_left_right(img_input) where im_input is Input(shape=(None, None, 3), name='image')", "body": "I want to dump graph of tta for model.h5. But seems tf.image.flip_left_right not support dynamic input size. (tf version 2.3)\r\n\r\n    import tensorflow as tf \r\n    from tensorflow.keras.layers import Input\r\n    img_input = Input(shape=(None, None, 3), name='image')  \r\n    tf.image.flip_left_right(img_input)    \r\n\r\n\r\nOperatorNotAllowedInGraphError            Traceback (most recent call last)\r\n<ipython-input-4-6faed2643326> in <module>()\r\n----> 1 tf.image.flip_left_right(img_input)\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py in flip_left_right(image)\r\n    489     ValueError: if the shape of `image` not supported.\r\n    490   \"\"\"\r\n--> 491   return _flip(image, 1, 'flip_left_right')\r\n    492\r\n    493\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py in _flip(image, flip_index, scope_name)\r\n    548   with ops.name_scope(None, scope_name, [image]):\r\n    549     image = ops.convert_to_tensor(image, name='image')\r\n--> 550     image = _AssertAtLeast3DImage(image)\r\n    551     shape = image.get_shape()\r\n    552     if shape.ndims == 3 or shape.ndims is None:\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py in _AssertAtLeast3DImage(image)\r\n    195   \"\"\"\r\n    196   return control_flow_ops.with_dependencies(\r\n--> 197       _CheckAtLeast3DImage(image, require_static=False), image)\r\n    198\r\n    199\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py in _CheckAtLeast3DImage(image, require_static)\r\n    230         check_ops.assert_positive(\r\n    231             array_ops.shape(image)[-3:],\r\n--> 232             [\"inner 3 dims of 'image.shape' \"\r\n    233              'must be > 0.']),\r\n    234         check_ops.assert_greater_equal(\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py in assert_positive(x, data, summarize, message, name)\r\n    510           'x (%s) = ' % name, x]\r\n    511     zero = ops.convert_to_tensor(0, dtype=x.dtype)\r\n--> 512     return assert_less(zero, x, data=data, summarize=summarize)\r\n    513\r\n    514\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py in assert_less(x, y, data, summarize, message, name)\r\n    899 def assert_less(x, y, data=None, summarize=None, message=None, name=None):\r\n    900   return _binary_assert('<', 'assert_less', math_ops.less, np.less, x, y, data,\r\n--> 901                         summarize, message, name)\r\n    902\r\n    903\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py in _binary_assert(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\r\n    333       test_op = op_func(x, y)\r\n    334       condition = math_ops.reduce_all(test_op)\r\n--> 335       if condition:\r\n    336         return\r\n    337\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in __bool__(self)\r\n    875       `TypeError`.\r\n    876     \"\"\"\r\n--> 877     self._disallow_bool_casting()\r\n    878\r\n    879   def __nonzero__(self):\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _disallow_bool_casting(self)\r\n    488     else:\r\n    489       # Default: V1-style Graph execution.\r\n--> 490       self._disallow_in_graph_mode(\"using a `tf.Tensor` as a Python `bool`\")\r\n    491\r\n    492   def _disallow_iteration(self):\r\n\r\n/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _disallow_in_graph_mode(self, task)\r\n    477     raise errors.OperatorNotAllowedInGraphError(\r\n    478         \"{} is not allowed in Graph execution. Use Eager execution or decorate\"\r\n--> 479         \" this function with @tf.function.\".format(task))\r\n    480\r\n    481   def _disallow_bool_casting(self):\r\n\r\nOperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\r\n\r\n", "comments": ["I have tried in colab in TF 2.3 and was able to reproduce the issue. However the issue was resolved in TF nightly version(`2.5.0-dev20201108`).Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/250011705ca0a25c9059cd62117c129c/untitled495.ipynb).Please, verify once and close the issue.Thanks!", "@ravikyram  Great! Since it is solved closing this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44677\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44677\">No</a>\n"]}, {"number": 44676, "title": "Fix wrong new line", "body": "Fix wrong new line in docstring.", "comments": ["Is there something broken? Afaik this is the markdown syntax for hyperlinks and it should not be split on two lines", "Yeah, this change shouldn't matter. Though there is currently a forced line break on the page: https://www.tensorflow.org/api_docs/python/tf/keras/losses/Reduction?version=nightly\r\n\r\nIf we're stripping `# pylint: disable=line-too-long`, are we adding an extra `<br>`? cc: @yashk2810 ", "@albertvillanova  Any update on this PR? Please. Thanks!", "@albertvillanova  Can you please check @lamberta's comments and keep us posted ? Thanks!", "Hello @gbaned. I thought @lamberta question was addressed to @yashk2810.\r\n\r\nCurrently, there is a wrong line break in the docs: https://www.tensorflow.org/api_docs/python/tf/keras/losses/Reduction\r\n```\r\nPlease see the custom training guide\r\nfor more details on this.\r\n```\r\nI have made this pull request to fix it.\r\n\r\nApparently, as @lamberta pointed out, current `# pylint: disable=line-too-long` is creating a line break, so I removed it.\r\n", "In relation to the comment made by @mihaimaruseac, I have not invented split hyperlinks. Indeed they are already used many times in tensorflow project, e.g.:\r\n- https://github.com/tensorflow/tensorflow/blob/bd192e96bc1135cfdd28b169d1e1c3e5e3585c28/tensorflow/python/ops/math_ops.py#L1652\r\n- https://github.com/tensorflow/tensorflow/blob/bd192e96bc1135cfdd28b169d1e1c3e5e3585c28/tensorflow/python/ops/image_ops_impl.py#L1538\r\n- https://github.com/tensorflow/tensorflow/blob/bd192e96bc1135cfdd28b169d1e1c3e5e3585c28/tensorflow/python/tpu/tpu_embedding.py#L661\r\n- https://github.com/tensorflow/tensorflow/blob/bd192e96bc1135cfdd28b169d1e1c3e5e3585c28/tensorflow/python/lib/io/tf_record.py#L230"]}, {"number": 44674, "title": "metrics=[tf.keras.metrics.Accuracy()] gives ValueError", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n**Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n**Manjaro 20.2 Nibia, Kernel: x86_64 Linux 5.8.18-1-MANJARO**\r\n- TensorFlow installed from (source or binary):\r\n**pip**\r\n- TensorFlow version (use command below):\r\n**2.3.1**\r\n- Python version:\r\n**3.8.6**\r\n\r\n\r\n**Describe the current behavior**\r\nmetrics=[tf.keras.metrics.Accuracy()] gives ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\nwhile metrics=['accuracy'] works.\r\n\r\n**Describe the expected behavior**\r\nmetrics=[tf.keras.metrics.Accuracy()]  should work similar to metrics=['accuracy'] \r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nmnist = tf.keras.datasets.mnist\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n    tf.keras.layers.Dense(128, activation='relu'),\r\n    tf.keras.layers.Dropout(0.5),\r\n    tf.keras.layers.Dense(10)\r\n])\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(),\r\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n    metrics=[tf.keras.metrics.Accuracy()]\r\n)\r\nmodel.fit(x_train, y_train, epochs=5)\r\n```\r\n\r\n**Other info / logs**:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-24-af322e093f31> in <module>\r\n      1 #Train the model\r\n----> 2 model.fit(x_train, y_train, epochs=5)\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1096                 batch_size=batch_size):\r\n   1097               callbacks.on_train_batch_begin(step)\r\n-> 1098               tmp_logs = train_function(iterator)\r\n   1099               if data_handler.should_sync:\r\n   1100                 context.async_wait()\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    821       # This is the first call of __call__, so we have to initialize.\r\n    822       initializers = []\r\n--> 823       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    824     finally:\r\n    825       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    694     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)\r\n    695     self._concrete_stateful_fn = (\r\n--> 696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n    697             *args, **kwds))\r\n    698 \r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2853       args, kwargs = None, None\r\n   2854     with self._lock:\r\n-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2856     return graph_function\r\n   2857 \r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3211 \r\n   3212       self._function_cache.missed.add(call_context_key)\r\n-> 3213       graph_function = self._create_graph_function(args, kwargs)\r\n   3214       self._function_cache.primary[cache_key] = graph_function\r\n   3215       return graph_function, args, kwargs\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3063     arg_names = base_arg_names + missing_arg_names\r\n   3064     graph_function = ConcreteFunction(\r\n-> 3065         func_graph_module.func_graph_from_py_func(\r\n   3066             self._name,\r\n   3067             self._python_function,\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    984         _, original_func = tf_decorator.unwrap(python_func)\r\n    985 \r\n--> 986       func_outputs = python_func(*func_args, **func_kwargs)\r\n    987 \r\n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    599         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    601     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    602 \r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    971           except Exception as e:  # pylint:disable=broad-except\r\n    972             if hasattr(e, \"ag_error_metadata\"):\r\n--> 973               raise e.ag_error_metadata.to_exception(e)\r\n    974             else:\r\n    975               raise\r\n\r\nValueError: in user code:\r\n\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\r\n        outputs = model.train_step(data)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:759 train_step\r\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:409 update_state\r\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated\r\n        update_op = update_state_fn(*args, **kwargs)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:176 update_state_fn\r\n        return ag_update_state(*args, **kwargs)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:612 update_state  **\r\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:3208 accuracy  **\r\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\r\n    /usr/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\r\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\n\r\n    ValueError: Shapes (32, 10) and (32, 1) are incompatible\r\n```\r\n", "comments": ["I'm fixing the obvious error without much explanation. Hope you get them.\r\n\r\n```python\r\nimport tensorflow as tf\r\nmnist = tf.keras.datasets.mnist\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nx_train = x_train.reshape(60000, 28*28)/255.0\r\nx_test = x_test.reshape(10000, 28*28)/255.0\r\n\r\n\r\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\r\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\r\nprint(x_train.shape, y_train.shape)\r\n```\r\n\r\nThe modeling,\r\n\r\n```python\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Flatten(input_shape=(784,)),  # you need to send flatten 1D vector , not 2D, 2D for conv\r\n    tf.keras.layers.Dense(128, activation='relu'),\r\n    tf.keras.layers.Dropout(0.5),\r\n    tf.keras.layers.Dense(10)\r\n])\r\n\r\n\r\nmodel.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\r\n              metrics = tf.keras.metrics.CategoricalAccuracy(),\r\n              optimizer = tf.keras.optimizers.Adam())\r\nmodel.fit(x_train, y_train, epochs=1)\r\n```\r\n\r\n---\r\n\r\nHowever, If we don't want `one-hot` encoding the labels but pure integer. Then,\r\n\r\n```python\r\nmnist = tf.keras.datasets.mnist\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nx_train = x_train.reshape(60000, 28*28)/255.0\r\nx_test = x_test.reshape(10000, 28*28)/255.0\r\n\r\nprint(x_train.shape, y_train.shape)\r\n```\r\nAnd modeling,\r\n\r\n\r\n```python\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Flatten(input_shape=(784,)),\r\n    tf.keras.layers.Dense(128, activation='relu'),\r\n    tf.keras.layers.Dropout(0.5),\r\n    tf.keras.layers.Dense(10)\r\n])\r\n\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\r\n                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n                metrics=[tf.metrics.SparseCategoricalAccuracy()])\r\n\r\n\r\nmodel.fit(x_train, y_train, epochs=1)\r\n\r\n```", "@AnkS4 \r\nPlease update as per above comment.", "I can confirm that this works.", "@AnkS4\r\nCould you move to issue to closed status as its resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44674\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44674\">No</a>\n"]}, {"number": 44673, "title": "Separate TF 1.x from 2.x in PyPi", "body": "Let's separate TF 1.x from 2.x package names and PyPI repos  to enable auto-updates to latest versions of TF 1.x. (without the need to manually monitor the latest available 1.x version).\r\n\r\nPossibly just rename it to `tensorflow1==tensorflow` and `tensorflow2`, like with python 2.x and 3.x. These major versions of TF of equally incompatible, so they should not have the same package name IMHO.\r\n\r\nThe automatic code converter `tf_upgrade_v2` does not always work for Github data science projects and converting Kaggle Kernels and other Jupyter notebooks to `.py` format is an additional manual step required in practice (only to find that conversion did not work).\r\n\r\nMany thanks!", "comments": ["There are no more TF 1.x versions. TF 1.15 is the latest and won't get any more patches unless security issues discovered on Cloud VMs.\r\n\r\nTensorFlow uses SemVer, not PVP versioning. Hence, there is only one major version number, not 2 (the second being in the name).", "Ok, if TF 1.x has reached its release cycle, then the issue is Indeed irrelevant, and I will close the issue for now. \r\n\r\nTensorflow users can either:\r\na) switch to python 3.8 and be forced to upgrade to Tensorflow 2.x.y, or\r\nb) stay with python 3.7 until it's possible but pin Tensorflow at 1.15.4, or even\r\nc) switch to another DL framework that does not tie it's major versions to historical python versions.", "We don't pin TF versions to Py versions willingly. It's just a matter of controlling the support matrix size. As soon as a python version is out of life, we will drop support for it. When a new python version is released we pick it up by at most 1 additional TF release, depending on how/when our dependencies pick it up."]}, {"number": 44672, "title": "TensorFlow Hub BigGAN cannot be converted with TFLiteConverterV2", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary from PyPI\r\n- TensorFlow version (or github SHA if from source): 2.3.1\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n```py\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\n\r\ntf.compat.v1.disable_v2_behavior()\r\n\r\n\r\n@tf.function(\r\n    input_signature=[\r\n        tf.TensorSpec(shape=(1, 128), dtype=tf.float32, name=\"z\"),\r\n        tf.TensorSpec(shape=(), dtype=tf.float32, name=\"truncation\"),\r\n        tf.TensorSpec(shape=(1, 1000), dtype=tf.float32, name=\"y\"),\r\n    ]\r\n)\r\ndef sample(z, truncation, y):\r\n    f = hub.Module('https://tfhub.dev/deepmind/biggan-deep-128/1')\r\n    x = dict(y=y, z=z, truncation=truncation)\r\n    y = f(x)\r\n    return y\r\n\r\n\r\nf = sample.get_concrete_function()\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([f])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\nwith open(\"biggan.tflite\", \"wb\") as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n2020-11-07 11:52:43.193133: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/\r\n2020-11-07 11:52:43.193153: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nWARNING:tensorflow:From /home/carl/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nnon-resource variables are not supported in the long term\r\n2020-11-07 11:52:46.345076: W tensorflow/core/common_runtime/graph_constructor.cc:1517] Importing a graph with a lower producer version 27 into an existing graph with producer version 440. Shape inference will have run different parts of the graph with different producer versions.\r\n2020-11-07 11:52:49.611710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-11-07 11:52:49.645586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-07 11:52:49.645959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:09:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-11-07 11:52:49.646016: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/\r\n2020-11-07 11:52:49.647140: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-11-07 11:52:49.648287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-11-07 11:52:49.648431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-11-07 11:52:49.649664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-11-07 11:52:49.650368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-11-07 11:52:49.650409: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/\r\n2020-11-07 11:52:49.650416: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2020-11-07 11:52:49.650622: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-07 11:52:49.655923: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3493685000 Hz\r\n2020-11-07 11:52:49.656708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x25aa5450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-11-07 11:52:49.656725: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-11-07 11:52:49.657718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-11-07 11:52:49.657726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \r\nWARNING:absl:Using TF1 Hub format while building a function: sample. This can lead to errors if the function is not pruned.\r\n2020-11-07 12:01:32.785968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-07 12:01:32.786372: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\r\n2020-11-07 12:01:32.786452: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-11-07 12:01:32.872693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-07 12:01:32.873135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ebe0b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-11-07 12:01:32.873177: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-11-07 12:01:32.873442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-07 12:01:32.874172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:09:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-11-07 12:01:32.874300: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/\r\n2020-11-07 12:01:32.874321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-11-07 12:01:32.874334: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-11-07 12:01:32.874347: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-11-07 12:01:32.874360: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-11-07 12:01:32.874372: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-11-07 12:01:32.874423: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/\r\n2020-11-07 12:01:32.874433: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2020-11-07 12:01:32.874451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-11-07 12:01:32.874459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-11-07 12:01:32.874466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-11-07 12:01:36.376693: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\r\n2020-11-07 12:01:36.376728: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.006ms.\r\n2020-11-07 12:01:36.376734: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-11-07 12:02:43.747428: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-11-07 12:02:43.747463: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\nTraceback (most recent call last):\r\n  File \"/home/carl/.local/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 196, in toco_convert_protos\r\n    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n  File \"/home/carl/.local/lib/python3.8/site-packages/tensorflow/lite/python/wrap_toco.py\", line 32, in wrapped_toco_convert\r\n    return _pywrap_toco_api.TocoConvert(\r\nException: Merge node module/collect/body/cond/Merge has input that's not in any CondContext.\r\n        for node {{node module/collect/body/cond/Merge}}\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"convert_savedmodel_to_tflite.py\", line 24, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/carl/.local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 1076, in convert\r\n    return super(TFLiteConverterV2, self).convert()\r\n  File \"/home/carl/.local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 899, in convert\r\n    return super(TFLiteFrozenGraphConverterV2,\r\n  File \"/home/carl/.local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 629, in convert\r\n    result = _toco_convert_impl(\r\n  File \"/home/carl/.local/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 569, in toco_convert_impl\r\n    data = toco_convert_protos(\r\n  File \"/home/carl/.local/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 202, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: Merge node module/collect/body/cond/Merge has input that's not in any CondContext.\r\n        for node {{node module/collect/body/cond/Merge}}\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://tfhub.dev/deepmind/biggan-deep-128/1\r\n```\r\n\r\n**Failure details**\r\nCrashes on attempted conversion.", "comments": ["Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/7738f81c88629dfec31f94bdfec31511/44672-tf-nightly.ipynb). Thanks!", "Merge node is a control flow v1 op. TFLite does not have future plans to support control flow v1 ops. Sorry for encounting this issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44672\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44672\">No</a>\n"]}]