[{"number": 30151, "title": "Documentation Page - CSS is messed up", "body": "Bug Description:\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/java/reference/org/tensorflow/package-summary\r\n\r\n## Description of issue (what needs changing): Documentation page was unreadable on Safari for Mac. Please see the screenshot. On Subsequent page load it somehow loaded just fine.\r\n\r\n### Clear description\r\n\r\nSee above\r\n<img width=\"1494\" alt=\"Screen Shot 2019-06-25 at 2 29 37 PM\" src=\"https://user-images.githubusercontent.com/395039/60135239-1eba0580-9756-11e9-9094-3430ab265841.png\">\r\n\r\n\r\n### Correct links\r\n\r\nN/A\r\n\r\n### Parameters defined\r\n\r\nN/A\r\n\r\n### Returns defined\r\n\r\nN/A\r\n\r\n### Raises listed and defined\r\n\r\nN/A\r\n\r\n### Usage example\r\n\r\nSee attached screenshot\r\n\r\n### Request visuals, if applicable\r\n\r\nYes, see attached screenshot\r\n\r\n### Submit a pull request?\r\n\r\nNo", "comments": ["I was able to load the link successfully using safari browser on macbook pro. Please make sure you have strong internet connection and try again. Thanks!"]}, {"number": 30150, "title": "Update release notes for TensorFlow 1.13.2", "body": "This PR is intentionally incomplete. One of the Release Owners for 1.13.2\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 30149, "title": "Autograph \"Failed to parse source code\" error when using lambda in for loop", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMacOSX 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nVERSION=2.0.0-dev20190625\r\nGIT_VERSION=v1.12.1-4885-g71241a6afd\r\n- Python version:\r\n3.6.8\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\nI get an autograph error when running the following code (see the full stacktrace below):\r\n\r\n```python\r\nimport tensorflow as tf\r\nds = tf.data.Dataset.range(10).window(5, shift=1, drop_remainder=True)\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\n    print(window.numpy())\r\n```\r\n\r\nThe error is `ValueError: Failed to parse source code of <function <lambda> at 0x11194c488>`\r\n\r\n**Describe the expected behavior**\r\nEverything works fine when I define the dataset on the previous line like this:\r\n\r\n```python\r\nimport tensorflow as tf\r\nds = tf.data.Dataset.range(10).window(5, shift=1, drop_remainder=True)\r\nds = ds.flat_map(lambda window: window.batch(5))\r\nfor window in ds:\r\n    print(window.numpy())\r\n```\r\n\r\n**Code to reproduce the issue**\r\nSee above.\r\n\r\n**Other info / logs**\r\nFull stack trace with `AUTOGRAPH_VERBOSITY=10`:\r\n\r\n```\r\n2019-06-25 22:24:13.172683: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-06-25 22:24:13.197405: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5e8a657c0 executing computations on platform Host. Devices:\r\n2019-06-25 22:24:13.197445: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\nConverted call: <function <lambda> at 0x134b81488>\r\n    args: (<_VariantDataset shapes: (), types: tf.int64>,)\r\n    kwargs: {}\r\n\r\nNot whitelisted: <method-wrapper '__call__' of function object at 0x134b81488>: default rule\r\nNot whitelisted: <function <lambda> at 0x134b81488>: default rule\r\nEntity <function <lambda> at 0x134b81488> is not cached for key <code object <lambda> at 0x13b5f7ed0, file \"<ipython-input-1-8a83c4c9b193>\", line 4> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x13b641588>, frozenset())\r\nConverting <function <lambda> at 0x134b81488>\r\nWARNING: Logging before flag parsing goes to stderr.\r\nE0625 22:24:13.215670 140735810999168 ag_logging.py:133] Error converting <function <lambda> at 0x134b81488>\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 78, in parse_entity\r\n    return parse_str(source, preamble_len=len(future_features)), source\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 140, in parse_str\r\n    module_node = gast.parse(src)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py\", line 240, in parse\r\n    return ast_to_gast(_ast.parse(*args, **kwargs))\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 5\r\n    for window in ds.flat_map(lambda window: window.batch(5)):\r\n                                                             ^\r\nSyntaxError: unexpected EOF while parsing\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 118, in parse_entity\r\n    return parse_str(source, preamble_len=len(future_features)), source\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 140, in parse_str\r\n    module_node = gast.parse(src)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py\", line 240, in parse\r\n    return ast_to_gast(_ast.parse(*args, **kwargs))\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 5\r\n    for window in ds.flat_map(lambda window: window.batch(5)):\r\n                                                             ^\r\nSyntaxError: unexpected EOF while parsing\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 635, in to_graph\r\n    return conversion.convert(entity, program_ctx)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 322, in convert\r\n    free_nonglobal_var_names)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 240, in _convert_with_cache\r\n    entity, program_ctx)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 441, in convert_entity_to_ast\r\n    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 601, in convert_func_to_ast\r\n    node, source = parser.parse_entity(f, future_features=future_features)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 123, in parse_entity\r\n    ' source to:\\n{}\\nBut that did not work.'.format(source))\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 66, in raise_parse_failure\r\n    '{}'.format(entity, source, comment))\r\nValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nIf this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nBut that did not work.\r\nERROR: Error converting <function <lambda> at 0x134b81488>\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 78, in parse_entity\r\n    return parse_str(source, preamble_len=len(future_features)), source\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 140, in parse_str\r\n    module_node = gast.parse(src)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py\", line 240, in parse\r\n    return ast_to_gast(_ast.parse(*args, **kwargs))\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 5\r\n    for window in ds.flat_map(lambda window: window.batch(5)):\r\n                                                             ^\r\nSyntaxError: unexpected EOF while parsing\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 118, in parse_entity\r\n    return parse_str(source, preamble_len=len(future_features)), source\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 140, in parse_str\r\n    module_node = gast.parse(src)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py\", line 240, in parse\r\n    return ast_to_gast(_ast.parse(*args, **kwargs))\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 5\r\n    for window in ds.flat_map(lambda window: window.batch(5)):\r\n                                                             ^\r\nSyntaxError: unexpected EOF while parsing\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 635, in to_graph\r\n    return conversion.convert(entity, program_ctx)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 322, in convert\r\n    free_nonglobal_var_names)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 240, in _convert_with_cache\r\n    entity, program_ctx)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 441, in convert_entity_to_ast\r\n    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 601, in convert_func_to_ast\r\n    node, source = parser.parse_entity(f, future_features=future_features)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 123, in parse_entity\r\n    ' source to:\\n{}\\nBut that did not work.'.format(source))\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 66, in raise_parse_failure\r\n    '{}'.format(entity, source, comment))\r\nValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nIf this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nBut that did not work.\r\nError transforming entity <function <lambda> at 0x134b81488>\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 78, in parse_entity\r\n    return parse_str(source, preamble_len=len(future_features)), source\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 140, in parse_str\r\n    module_node = gast.parse(src)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py\", line 240, in parse\r\n    return ast_to_gast(_ast.parse(*args, **kwargs))\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 5\r\n    for window in ds.flat_map(lambda window: window.batch(5)):\r\n                                                             ^\r\nSyntaxError: unexpected EOF while parsing\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 118, in parse_entity\r\n    return parse_str(source, preamble_len=len(future_features)), source\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 140, in parse_str\r\n    module_node = gast.parse(src)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/gast/gast.py\", line 240, in parse\r\n    return ast_to_gast(_ast.parse(*args, **kwargs))\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 5\r\n    for window in ds.flat_map(lambda window: window.batch(5)):\r\n                                                             ^\r\nSyntaxError: unexpected EOF while parsing\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 635, in to_graph\r\n    return conversion.convert(entity, program_ctx)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 322, in convert\r\n    free_nonglobal_var_names)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 240, in _convert_with_cache\r\n    entity, program_ctx)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 441, in convert_entity_to_ast\r\n    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 601, in convert_func_to_ast\r\n    node, source = parser.parse_entity(f, future_features=future_features)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 123, in parse_entity\r\n    ' source to:\\n{}\\nBut that did not work.'.format(source))\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 66, in raise_parse_failure\r\n    '{}'.format(entity, source, comment))\r\nValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nIf this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nBut that did not work.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 528, in converted_call\r\n    experimental_optional_features=options.optional_features)\r\n  File \"/Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 639, in to_graph\r\n    entity, e.__class__.__name__, str(e)))\r\ntensorflow.python.autograph.impl.api.ConversionError: converting <function <lambda> at 0x134b81488>: ValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nIf this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nBut that did not work.\r\nW0625 22:24:13.223130 140735810999168 ag_logging.py:146] Entity <function <lambda> at 0x134b81488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function <lambda> at 0x134b81488>: ValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nIf this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nBut that did not work.\r\nWARNING: Entity <function <lambda> at 0x134b81488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function <lambda> at 0x134b81488>: ValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nIf this is a lambda function, the error may be avoided by creating the lambda in a standalone statement. Tried to strip down the source to:\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import unicode_literals\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nBut that did not work.\r\n2019-06-25 22:24:13.243343: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n[0 1 2 3 4]\r\n[1 2 3 4 5]\r\n[2 3 4 5 6]\r\n[3 4 5 6 7]\r\n[4 5 6 7 8]\r\n[5 6 7 8 9]", "comments": ["I have reproduced the issue in Colab using TF VERSION=2.0.0-dev20190625.Thanks!", "This is related to a limitation in Python's `inspect.getsource`, which can't always get the source code of lambda functions. Specifically, getsource returns the entire source code line, which isn't always well-formed Python code, as you could see from this example.\r\n\r\nThe workaround is to declare the lambda function on a single line, as the OP indicates.\r\n\r\nNormally, the error message should describe that (albeit in more detail), but it should definitely suggest the workaround of declaring the lambda on a separate line - @ageron can you confirm that the error message included that guidance?\r\n\r\nRelated, we should remove the extraneous imports from the error message. The message should spell just:\r\n\r\n```\r\nValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\n```", "Yes, I can confirm that the message `If this is a lambda function, the error may be avoided by creating the lambda in a standalone statement.` was part of the (very long) error message. But it's neither at the beginning nor at the end, so it's easily overlooked. I would recommend shortening the error message (except when AUTOGRAPH_VERBOSITY=10), to something like this:\r\n\r\n```python\r\nValueError: Failed to parse source code of <function <lambda> at 0x134b81488>, which Python reported as:\r\nfor window in ds.flat_map(lambda window: window.batch(5)):\r\nThe error may be avoided by creating the lambda in a standalone statement.\r\n```\r\n\r\nAlternatively, isn't it possible to parse this line to extract the lambda? After all, it's right there. :)", "I agree - will simplify the error message.\r\n\r\nYes, we do attempt to parse the line, but in this case is it not well-formed Python code - in our example, it's a for loop without a body. One could imagine a partial parser which attempts to parse as much as possible of the code that is well-formed, but the Python parser doesn't know how to do that, and even then there may still be situations of ambiguity where the results would be incorrect.\r\n\r\nA much more robust fix would be to fix the parser so that it records the exact extents of the lambda, with column numbers. Currently it only records the line number, which is the root of the problem.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30149\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30149\">No</a>\n"]}, {"number": 30148, "title": "[TF 2.0] TPU Estimator cannot function without steps or max_steps", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): No\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): tensorflow==2.0.0b0\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n- TPU: v2.8, TF Nightly.\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nTPU Estimator Cannot function without steps or max_steps.\r\nWhen provided, Any value of `max_steps` raises an `IteratorGetNext: End of Sequence Error`. However this error gets handled, and TPU Session Remains active even when there's no more code to execute.\r\n**Describe the expected behavior**\r\nTPU Estimator should run without `steps` or `max_steps` as mentioned in the documentation. It should stop the training process as soon as `tf.errors.OutOfRangeError` Rises.\r\n**More Information (along with Code to Reproduce)**\r\nRelated Issue: https://github.com/captain-pool/GSOC/issues/12\r\nCode: https://github.com/captain-pool/GSOC/blob/e7145c8d6c43545c4bcbde3cdd47f7cc53b1490c/E1_TPU_Sample/image_retraining_tpu.py\r\n\r\nCC: @vbardiovskyg @srjoglekar246 \r\n", "comments": ["@captain-pool I am unable to reproduce the issue on colab with Tensorflow 2.0.0.beta0. Please help us to reproduce the issue. When i ran it throws ```\r\nFATAL Flags parsing error: Unknown command line flag 'f'\r\nPass --helpshort or --helpfull to see help on flags.\r\nAn exception has occurred, use %tb to see the full traceback.\r\n\r\nSystemExit: 1\r\n``` Thanks!", "> @captain-pool I am unable to reproduce the issue on colab with Tensorflow 2.0.0.beta0. Please help us to reproduce the issue. When i ran it throws ```\r\n> FATAL Flags parsing error: Unknown command line flag 'f'\r\n> Pass --helpshort or --helpfull to see help on flags.\r\n> An exception has occurred, use %tb to see the full traceback.\r\n> \r\n> SystemExit: 1\r\n\r\nHey @gadagashwini There's no `f` flag defined anywhere in the code I gave. Try copy/pasting this and try out.\r\n```bash\r\npython3 image_retraining_tpu.py --tpu [TPU_NAME] \\\r\n--use_tpu --use_compat --data_dir gs://[BUCKET_NAME]/data_dir \\\r\n--model_dir gs://[BUCKET_NAME]/model_dir --batch_size=32 \\\r\n--iterations=8 --max_steps=8\r\n```\r\nI'm not sure about colab, I've been trying this on gcloud. So, it would be better if you can try out on a VM instance.", "@captain-pool Is this still an issue? Can you check with `TF2.0` and let us know whether the issue persists with latest TF version. Thanks!", "@captain-pool Is this still an issue? If not, please close this issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30148\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30148\">No</a>\n"]}, {"number": 30147, "title": "[ROCm] Adding ROCm support for the map_stage_op", "body": "This PR adds ROCm support for the map_stage_op\r\n\r\nThe changes in this PR are trivial...please review and merge. thanks.\r\n\r\n-------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg ", "comments": []}, {"number": 30146, "title": "[Intel MKL] Adding support for eigen unit tests in run_mkl.sh. ", "body": "This will allow us to triage which issues are unique to MKL.", "comments": []}, {"number": 30145, "title": "[ROCm] Adding ROCm support to gemm batched interface", "body": "This PR fixed the original flawed implementation from gemm batched interface, from the develop-upstream [PR437](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/pull/437). This PR has been thoroughly tested over the past two month. Without the PR, gemm batch interface is only able to handle strided buffer.\r\n\r\nThe changes in the PR is very narrowly scoped to the one function `DoBlasGemmBatchedInternal()`.\r\n\r\nA brief explanation of what it does quoting the original PR437\r\n\r\n> Adding a new subroutine AllocateStridedBuffer() to do memory allocation properly. The subroutine will take the shortcut when buffer is already allocated in a strided manner. And re-allocate when gemm batched buffer isn't properly strided.\r\n\r\n------\r\nTest passed: tensorflow/python/kernel_tests/batch_matmul_op_test\r\n@tatianashp @whchung @chsigg", "comments": []}, {"number": 30144, "title": "Converting unsupported operation: TFLite_Detection_PostProcess", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 1.1.2.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\nCommand:\r\n$ bazel run -c opt tensorflow/lite/toco:toco -- --input_file=/models/research/object_detection/training/output/tflite_graph.pb --output_file=/models/research/object_detection/training/output/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow-custom-ops\r\n\r\nError:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\nWe are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\n\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Which version of tf are you using? I tried 1.14 and had no problem. ", "Did you get chance to have a look on this [document](https://www.tensorflow.org/lite/guide/ops_select). Also try @WeiyiLi's solution and please let us know if that helps. Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I tried converting using tf 1.15 but I got the exact same error. "]}, {"number": 30143, "title": ".fit method fails with unnamed Input layer whereas training works with a custom function", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6\r\n- TensorFlow installed from (source or binary): from pip install\r\n- TensorFlow version (use command below): v1.12.1-3259-gf59745a381 2.0.0-beta0\r\n- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14\r\n\r\n**Describe the current behavior**\r\n\r\nI use a model written with the Functional API which uses a DenseFeatures layer. The `call` method of the model and a custom training function work well even if the `Input` layer is unnamed, but the `fit` method fails. This forces me to name the `Input` layer the same name as the key of the dictionary given as input. I am note sure if this is intended or not, but as this works with a custom training function I tend to think it may be a bug in the `fit` method.\r\n\r\n**Code to reproduce the issue**\r\n\r\nHere is a minimal working example reproducing the issue.\r\n\r\n```\r\nimport tensorflow as tf\r\nprint('Using Tensorflow version {} (git version {})'.format(tf.version.VERSION, tf.version.GIT_VERSION))\r\nimport numpy as np\r\nfrom tensorflow.data import Dataset\r\nfrom tensorflow.feature_column import numeric_column\r\nfrom tensorflow.keras import Input, Model\r\nfrom tensorflow.keras.layers import DenseFeatures, Dense\r\nfrom tensorflow.keras.losses import MeanSquaredError\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\ndef make_model():\r\n    fc1 = numeric_column('fc_name')\r\n    dict_input = {'fc_name': Input(1)}\r\n    \r\n    out = DenseFeatures(fc1)(dict_input)\r\n    out = Dense(5, name='dense_feature1')(out)\r\n    out = Dense(1, name='dense_ouput')(out)\r\n    \r\n    return Model(inputs=dict_input, outputs=out)\r\n\r\narray = np.ones((1000,1), dtype=np.float)\r\narray_target = np.ones((1000,1), dtype=np.float)\r\n\r\nbatch_size = 4\r\ndict_array = {'teddy_bear': array}\r\ninput_dataset = Dataset.from_tensor_slices(dict_array).batch(batch_size)\r\ntarget_dataset = Dataset.from_tensor_slices(array_target).batch(batch_size)\r\ncomplete_dataset = Dataset.zip((input_dataset, target_dataset)).shuffle(10000)\r\n\r\nmodel = make_model()\r\n#model.summary()\r\nfor x, y in complete_dataset.take(1):\r\n    print(model(x))\r\n    \r\nloss_fn = MeanSquaredError()\r\noptimizer = Adam(learning_rate=1e-3)\r\n\r\n@tf.function\r\ndef train_step(inputs, target):\r\n    with tf.GradientTape() as tape:\r\n        outputs = model(inputs)\r\n        loss = loss_fn(target, outputs)\r\n    grads = tape.gradient(loss, model.trainable_variables)\r\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n    return loss\r\n\r\nEPOCHS = 5\r\nloss = 0\r\nfor epoch in range(EPOCHS):\r\n    for x, y in complete_dataset:\r\n        loss = train_step(x, y)\r\n    print('Epoch n\u00b0{:d}, loss = {:5.4f}'.format(epoch + 1, loss))\r\nfor x, y in complete_dataset.take(1):\r\n    print(model(x))\r\n    \r\nmodel = make_model()\r\nmodel.summary()\r\nmodel.compile(optimizer, loss_fn)\r\nmodel.fit(complete_dataset, epochs=EPOCHS)\r\nfor x, y in complete_dataset.take(1):\r\n    print(model(x))\r\n```\r\n\r\nThe output of which is:\r\n\r\n```\r\nUsing Tensorflow version 2.0.0-beta0 (git version v1.12.1-3259-gf59745a381)\r\ntf.Tensor(\r\n[[-0.18571138]\r\n [-0.18571138]\r\n [-0.18571138]\r\n [-0.18571138]], shape=(4, 1), dtype=float32)\r\nEpoch n\u00b01, loss = 0.0035\r\nEpoch n\u00b02, loss = 0.0000\r\nEpoch n\u00b03, loss = 0.0000\r\nEpoch n\u00b04, loss = 0.0000\r\nEpoch n\u00b05, loss = 0.0000\r\ntf.Tensor(\r\n[[0.99999917]\r\n [0.99999917]\r\n [0.99999917]\r\n [0.99999917]], shape=(4, 1), dtype=float32)\r\nModel: \"model_1\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_2 (InputLayer)         [(None, 1)]               0         \r\n_________________________________________________________________\r\ndense_features_1 (DenseFeatu (None, 1)                 0         \r\n_________________________________________________________________\r\ndense_feature1 (Dense)       (None, 5)                 10        \r\n_________________________________________________________________\r\ndense_ouput (Dense)          (None, 1)                 6         \r\n=================================================================\r\nTotal params: 16\r\nTrainable params: 16\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nEpoch 1/5\r\n\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    446           if data[x].__class__.__name__ == 'DataFrame' else data[x]\r\n--> 447           for x in names\r\n    448       ]\r\n\r\n~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in <listcomp>(.0)\r\n    446           if data[x].__class__.__name__ == 'DataFrame' else data[x]\r\n--> 447           for x in names\r\n    448       ]\r\n\r\nKeyError: 'input_2'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-1-d41b98ef4a37> in <module>\r\n     59 model.summary()\r\n     60 model.compile(optimizer, loss_fn)\r\n---> 61 model.fit(complete_dataset, epochs=EPOCHS)\r\n     62 for x, y in complete_dataset.take(1):\r\n     63     print(model(x))\r\n\r\n~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    641         max_queue_size=max_queue_size,\r\n    642         workers=workers,\r\n--> 643         use_multiprocessing=use_multiprocessing)\r\n    644 \r\n    645   def evaluate(self,\r\n\r\n~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    692         shuffle=shuffle,\r\n    693         initial_epoch=initial_epoch,\r\n--> 694         steps_name='steps_per_epoch')\r\n    695 \r\n    696   def evaluate(self,\r\n\r\n~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\r\n    262 \r\n    263       is_deferred = not model._is_compiled\r\n--> 264       batch_outs = batch_function(*batch_data)\r\n    265       if not isinstance(batch_outs, list):\r\n    266         batch_outs = [batch_outs]\r\n\r\n~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)\r\n    894     x, y, sample_weights = self._standardize_user_data(\r\n    895         x, y, sample_weight=sample_weight, class_weight=class_weight,\r\n--> 896         extract_tensors_from_dataset=True)\r\n    897 \r\n    898     # If `self._distribution_strategy` is True, then we are in a replica context\r\n\r\n~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\r\n   2426           feed_input_shapes,\r\n   2427           check_batch_axis=False,  # Don't enforce the batch size.\r\n-> 2428           exception_prefix='input')\r\n   2429 \r\n   2430     if y is not None:\r\n\r\n~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    449     except KeyError as e:\r\n    450       raise ValueError('No data provided for \"' + e.args[0] + '\". Need data '\r\n--> 451                        'for each key in: ' + str(names))\r\n    452   elif isinstance(data, (list, tuple)):\r\n    453     if isinstance(data[0], (list, tuple)):\r\n\r\nValueError: No data provided for \"input_2\". Need data for each key in: ['input_2']\r\n\r\n```\r\nWe see on the output that the `call` method of the model works and that the training with  the custom function also works. We also see in the error log that the error is due to the `Input` layer, named `input_2`, not finding the key `input_2` in the dictionaries produced by `complete_dataset`.\r\n\r\nNow, in the code above, if we replace the line `dict_input = {'fc_name': Input(1)}` by `dict_input = {'fc_name': Input(1, name='teddy_bear')}`, everything works and the output looks like this:\r\n\r\n```\r\nUsing Tensorflow version 2.0.0-beta0 (git version v1.12.1-3259-gf59745a381)\r\ntf.Tensor(\r\n[[0.7686093]\r\n [0.7686093]\r\n [0.7686093]\r\n [0.7686093]], shape=(4, 1), dtype=float32)\r\nEpoch n\u00b01, loss = 0.0000\r\nEpoch n\u00b02, loss = 0.0000\r\nEpoch n\u00b03, loss = 0.0000\r\nEpoch n\u00b04, loss = 0.0000\r\nEpoch n\u00b05, loss = 0.0000\r\ntf.Tensor(\r\n[[0.99999994]\r\n [0.99999994]\r\n [0.99999994]\r\n [0.99999994]], shape=(4, 1), dtype=float32)\r\nModel: \"model_1\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nteddy_bear (InputLayer)      [(None, 1)]               0         \r\n_________________________________________________________________\r\ndense_features_1 (DenseFeatu (None, 1)                 0         \r\n_________________________________________________________________\r\ndense_feature1 (Dense)       (None, 5)                 10        \r\n_________________________________________________________________\r\ndense_ouput (Dense)          (None, 1)                 6         \r\n=================================================================\r\nTotal params: 16\r\nTrainable params: 16\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nEpoch 1/5\r\n250/250 [==============================] - 1s 2ms/step - loss: 0.0325\r\nEpoch 2/5\r\n250/250 [==============================] - 0s 1ms/step - loss: 3.5115e-14\r\nEpoch 3/5\r\n250/250 [==============================] - 0s 2ms/step - loss: 1.4211e-14\r\nEpoch 4/5\r\n250/250 [==============================] - 0s 1ms/step - loss: 1.4211e-14\r\nEpoch 5/5\r\n250/250 [==============================] - 0s 1ms/step - loss: 1.4211e-14\r\ntf.Tensor(\r\n[[1.0000002]\r\n [1.0000002]\r\n [1.0000002]\r\n [1.0000002]], shape=(4, 1), dtype=float32)\r\n```\r\n", "comments": ["I have tried on colab with TF version 2.0 beta0 and was able to reproduce the issue.Thanks!", "In order to tie the incoming feature columns with the proper Inputs, you should pass in the same name as given to the feature column to the Input. We should document this better in the feature column guide (CC jbgordon@ who I believe is working on that), but this is working as intended.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30143\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30143\">No</a>\n", "Sorry, meant @random-forests ", "> In order to tie the incoming feature columns with the proper Inputs, you should pass in the same name as given to the feature column to the Input. \r\n\r\nAs you see in my example, the feature column and the Input layer have different names and this works. On the one hand, the feature column and the dictionary key associated to the Input layer share one name, which is `'fc_name'`, on the other hand, the Input layer and the dictionary key associated to the input data share another name, which is `'teddy_bear'`.\r\n\r\n> We should document this better in the feature column guide (CC jbgordon@ who I believe is working on that), but this is working as intended.\r\n\r\nIf this works as intended then can you explain me the difference of behaviour between using the `fit` method and the custom training method? I feel that I can understand why naming the Input layer the same as the input data is important but then I don't understand why it works with the custom function then.\r\n\r\nOverall, I don't feel that you properly addressed the issue.", "Hi @karmel do you have any comment on my last post here ?\r\nThanks in advance", "I am not sure exactly why it didn't fail, but I'm guessing it's more that it accidentally works, rather than an intentional implementation. In some cases, .fit is more restrictive, as we can't make assumptions about incoming data. If you want a precise answer as to why there is a difference, I would invite you to help us debug and determine what exactly the difference is in this case."]}, {"number": 30142, "title": "[ROCm] Adding ROCm support for the where op", "body": "This PR adds ROCm support for the where op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n--------------------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg", "comments": []}, {"number": 30141, "title": "\"Iterator::Model::Prefetch::Batch::Shuffle::ParallelInterleaveV2\" returned OutOfRange without setting *end_of_sequence", "body": "See https://github.com/tensorflow/tensorflow/issues/29060#issuecomment-505539468 for more details \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX and Linux\r\n- TensorFlow installed from (source or binary): `pipenv install --pre tensorflow==2.0.0-beta1`\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\nI'm running into this issue when caching before `interleave`\r\n\r\n```python\r\n    filenames_dataset = filenames_dataset.cache(\"./some_path\")\r\n\r\n    return filenames_dataset.interleave(\r\n        lambda f: map_file_to_xy_dataset(f, predict_task_fn, params),\r\n        cycle_length=params[CYCLE_LENGTH_KEY],\r\n        block_length=params[BLOCK_LENGTH_KEY],\r\n        num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n```\r\n\r\n```\r\nIterator \"Iterator::Model::Prefetch::Batch::Shuffle::ParallelInterleaveV2\" returned OutOfRange without setting `*end_of_sequence`. This indicates that an error may have occurred. Original message: Attempting to call get_next after iteration should have finished. [Op:IteratorGetNextSync]\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nAble to cache the `filenames_dataset`\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nSee above\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n", "comments": ["Thank you for reporting this @devstein. I am able to reproduce the problem with the below code:\r\n\r\n```python\r\n  import tensorflow as tf\r\n\r\n  tf.enable_v2_behavior()\r\n\r\n  ds = tf.data.Dataset.range(5)\r\n  ds = ds.cache('/tmp/cache_dir' )\r\n  ds = ds.interleave(\r\n      lambda f: tf.data.Dataset.range(f),\r\n      cycle_length=2, num_parallel_calls=1)\r\n  ds = ds.repeat(2)\r\n\r\n  for e in ds:\r\n    tf.print(e)\r\n```\r\n\r\nI'm looking into the root cause and will message back when I have a fix.", "The issue is related to using parallel interleave. As a temporary workaround, try leaving `num_parallel_calls` unset.", "@aaudiber Appreciate the quick response, I'll try that workaround for now. ", "The fix is merged to master in https://github.com/tensorflow/tensorflow/commit/3398e887f5daa1e22c59eaa1c6f5ca731698ad2f", "@aaudiber Thanks! "]}, {"number": 30140, "title": "Fix funcdef lookup in auto_mixed_precision grappler pass", "body": "Non-inlined funcdefs only exist in the graph's function registry instead of the global op registry. Such ops (e.g., tf.nn.swish) previously caused the auto_mixed_precision grappler pass to fail.\r\n\r\nThis commit also adds a test for such cases.\r\n\r\nattn @reedwm \r\ncc @nluehr ", "comments": ["@benbarsdell Will auto_mixed_precision do the  automatic loss scaling? We only need to set auto_mixed_precision=True in ConfigProto?", "Loss scaling is not implemented within the grappler graph optimizer. Setting `auto_mixed_precision=True` in ConfigProto will convert FP32 ops in your graph to fp16, but will not insert the additional operations to implement loss scaling.\r\n\r\nYou can enable both loss scaling and the graph optimizer by wrapping your optimizer in `tf.train.experimental.enable_mixed_precision_graph_rewrite()`. See https://www.tensorflow.org/api_docs/python/tf/train/experimental/enable_mixed_precision_graph_rewrite for details."]}, {"number": 30139, "title": "[ROCm] Adding ROCm support to gemm strided batched interface", "body": "This PR add support to the gemm strided batched interface, from the develop-upstream [PR405](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/pull/405). This PR has been thoroughly tested over the past two month. \r\n\r\n-----\r\n@tatianashp @whchung @chsigg @deven-amd ", "comments": []}, {"number": 30138, "title": "Optimized packet load in gemm_pack_rhs (Packet16f/8f) for CuboidConv", "body": "When packet is split across 2 adjacent rows (on same column), we read it as two\r\n'partial' packets and then merge these into 1. This optimization is similar to\r\nthat implemented in SpatialConvolution (commid id:\r\ne048543b0543ab12fa6e74537a21227a0837fcd1)\r\n\r\nThis optimization shows significant speedup in CuboidalConvolution with certain\r\nparameters. Numbers from tensorflow/core/kernels:eigen_benchmark_cpu_test are\r\nbelow.\r\n\r\nFor AVX512, the patch speeds up 2 (out of 4) instances and leaves the other 2 as\r\nis. For AVX2, the patch speeds up 1 (out of 4) instances and leaves the other 3\r\nas is.\r\n\r\nAVX512\r\n\r\nParameters                                                 | Runtime without patch (ns) | Runtime with patch (ns) | Speedup\r\n-----------------------------------------------------------|----------------------------|-------------------------|---------\r\nBM_CUBOID_NAME(CuboidConvolution,2,8,25,25,25,4,16,5,5,5)  |         321454780          |         133686280       |  2.40X\r\nBM_CUBOID_NAME(CuboidConvolution,4,8,25,25,25,4,16,5,5,5)  |         160635090          |          67167930       |  2.39X\r\nBM_CUBOID_NAME(CuboidConvolution,8,8,25,25,25,4,16,5,5,5)  |          79329930          |          33715910       |  2.35X\r\nBM_CUBOID_NAME(CuboidConvolution,16,8,25,25,25,4,16,5,5,5) |          50762340          |          21891730       |  2.32X\r\nBM_CUBOID_NAME(CuboidConvolution,2,8,25,25,25,8,16,5,5,5)  |         287244580          |         162654990       |  1.77X\r\nBM_CUBOID_NAME(CuboidConvolution,4,8,25,25,25,8,16,5,5,5)  |         144165180          |          81628980       |  1.77X\r\nBM_CUBOID_NAME(CuboidConvolution,8,8,25,25,25,8,16,5,5,5)  |          72296380          |          41090350       |  1.76X\r\nBM_CUBOID_NAME(CuboidConvolution,16,8,25,25,25,8,16,5,5,5) |          46290810          |          27015430       |  1.71X\r\nBM_CUBOID_NAME(CuboidConvolution,2,2,9,31,31,64,64,5,5,5)  |          87803480          |          87431440       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,4,2,9,31,31,64,64,5,5,5)  |          44564890          |          44420390       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,8,2,9,31,31,64,64,5,5,5)  |          22709950          |          22677270       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,16,2,9,31,31,64,64,5,5,5) |          15299040          |          15405270       |  0.99X\r\nBM_CUBOID_NAME(CuboidConvolution,2,2,5,27,27,64,64,5,5,5)  |          37558060          |          37290600       |  1.01X\r\nBM_CUBOID_NAME(CuboidConvolution,4,2,5,27,27,64,64,5,5,5)  |          19069400          |          19132680       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,8,2,5,27,27,64,64,5,5,5)  |          10088400          |          10110880       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,16,2,5,27,27,64,64,5,5,5) |           6913840          |           6807780       |  1.02X\r\n\r\nAVX2\r\n\r\nParameters                                                 | Runtime without patch (ns) | Runtime with patch (ns) | Speedup\r\n-----------------------------------------------------------|----------------------------|-------------------------|---------\r\nBM_CUBOID_NAME(CuboidConvolution,2,8,25,25,25,4,16,5,5,5)  |         166535650          |         115406110       |  1.44X\r\nBM_CUBOID_NAME(CuboidConvolution,4,8,25,25,25,4,16,5,5,5)  |          83449610          |          57959210       |  1.44X\r\nBM_CUBOID_NAME(CuboidConvolution,8,8,25,25,25,4,16,5,5,5)  |          41960720          |          29059400       |  1.44X\r\nBM_CUBOID_NAME(CuboidConvolution,16,8,25,25,25,4,16,5,5,5) |          27584140          |          19657640       |  1.40X\r\nBM_CUBOID_NAME(CuboidConvolution,2,8,25,25,25,8,16,5,5,5)  |          62304280          |          62090900       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,4,8,25,25,25,8,16,5,5,5)  |          31291390          |          31224440       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,8,8,25,25,25,8,16,5,5,5)  |          15775900          |          15744130       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,16,8,25,25,25,8,16,5,5,5) |          10358790          |          10637100       |  0.97X\r\nBM_CUBOID_NAME(CuboidConvolution,2,2,9,31,31,64,64,5,5,5)  |         126984890          |         126675250       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,4,2,9,31,31,64,64,5,5,5)  |          63888330          |          63775570       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,8,2,9,31,31,64,64,5,5,5)  |          32098130          |          31990920       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,16,2,9,31,31,64,64,5,5,5) |          21573360          |          21775700       |  0.99X\r\nBM_CUBOID_NAME(CuboidConvolution,2,2,5,27,27,64,64,5,5,5)  |          53339690          |          53429810       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,4,2,5,27,27,64,64,5,5,5)  |          26970450          |          26968820       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,8,2,5,27,27,64,64,5,5,5)  |          13980030          |          13981490       |  1.00X\r\nBM_CUBOID_NAME(CuboidConvolution,16,2,5,27,27,64,64,5,5,5) |           9257860          |           9522870       |  0.97X\r\n\r\nBenchmarks are on Intel Skylake server (24 cores).\r\n\r\nThe patch also contains minor code refactor so that common helper class and function can be used by gemm_pack_rhs for both SpatialConvolution and CuboidConvolution.", "comments": ["@anuj-rawat please sign CLA", "> @anuj-rawat please sign CLA\r\n\r\nHi. I should already be on the CLA via Intel. In fact I have submitted patch to TensorFlow before #28205.\r\nIs it possible that this CLA check failure is erroneous?", "Hi, I have made the requested changes.\r\nThanks", "> Just noticed that some of the lines are waaaaay over 80 columns, could you please reformat all the changed files.\r\n\r\nSorry. I forgot to run `eigen_cuboid_convolution.h` through `clang-format`. I have now run all 3 `.h` files through `clag-format`.", "It fails presubmits with ```./third_party/tensorflow/core/kernels/eigen_cuboid_convolution.h:561:17: error: unused variable 'packetSize' [-Werror,-Wunused-variable]\r\n    const Index packetSize = internal::unpacket_traits<Packet>::size;```", "> It fails presubmits with `./third_party/tensorflow/core/kernels/eigen_cuboid_convolution.h:561:17: error: unused variable 'packetSize' [-Werror,-Wunused-variable] const Index packetSize = internal::unpacket_traits<Packet>::size;`\r\n\r\nI have removed the unused variable now. Sorry about that. The default build was not making unused variable warning into error.", "Yeah, that's annoying, I think that was the only problem with a build, should be merged shortly if nothing else will show up.", "> Yeah, that's annoying, I think that was the only problem with a build, should be merged shortly if nothing else will show up.\r\n\r\n@ezhulenev can you please approve again, thank you!"]}, {"number": 30137, "title": "[ROCm] Adding ROCm support for the sparse_xent op", "body": "This PR adds ROCm support for the sparse_xent op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n----------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg", "comments": []}, {"number": 30136, "title": "Update third-party BUILD files for NVIDIA Jetson (TF 1.14)", "body": "Why? The NVIDIA dev community is struggling hard to compile TensorFlow: https://devtalk.nvidia.com/default/topic/1055131/jetson-agx-xavier/building-tensorflow-1-13-on-jetson-xavier/post/5354734/\r\n\r\nBasically the same PR for 1.14 as the already approved https://github.com/tensorflow/tensorflow/pull/26985 for 2.0 beta except that I also had to slightly modify `third_party/gif.BUILD`. Let me know if you think this change can cause trouble. Changing the compiler config might also work, but I've already spent 7 days compiling TF in various configurations and would like to focus on something else now... THANK YOU :)\r\n\r\nMaybe you can release this with `v1.14.1` soon?\r\n\r\nMore information about the Jetson (Nano) in case haven't heard of it: https://developer.nvidia.com/embedded/jetson-nano-developer-kit", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30136) for more info**.\n\n<!-- need_sender_cla -->", "I've signed the CLA. Maybe it needs some time to update the status on GitHub?", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30136) for more info**.\n\n<!-- ok -->", "We've published our **libtensorflow 1.14.0** binaries for download: https://dl.photoprism.org/tensorflow/\r\n\r\nFrom what I understood, `S_IREAD` is deprecated in favor of `S_IRUSR`. I couldn't find a compiler or setting that would have compiled libgif without defining `S_IREAD`, `S_IWRITE` etc and it's the only library that needs it: https://github.com/photoprism/tensorflow/commit/31104dcca0912288b28e045b7d2c8158061d6ddf\r\n\r\nIf somebody can tell us how to compile libgif without those changes using GCC 4.8 / 4.9 (as recommended by the TF docs), we can remove them again. Otherwise and/or if there is no negative impact, I would remove the conditions and always define them (see referenced commit in our fork):\r\n\r\n```\r\n    defines = [\r\n        \"S_IREAD=S_IRUSR\",\r\n        \"S_IWRITE=S_IWUSR\",\r\n        \"S_IEXEC=S_IXUSR\"\r\n    ],\r\n```\r\n\r\nWe also provide a patch: https://dl.photoprism.org/tensorflow/linux/config/tensorflow-1.14.0.diff", "This will get into 1.14.1, which will be released soon. We don't yet have a timeline, but I wanted to update the PR."]}, {"number": 30135, "title": "[ROCm] Adding ROCm support for the softmax op", "body": "This PR adds ROCm support for the softmax op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n----------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg", "comments": []}, {"number": 30134, "title": "Extract result ( prediction ) from tflite android", "body": "I have converted a model with ( .ckpt files ) to .pb frozen model and I will convert this frozen model to tflite model to get it worked on Android device.\r\nIn effects, The model is trained using CNN facial landmarks project to get a prediction of eye region by drawing points ( landmarks ) on the contour of the eye like this:\r\n\r\n![dsaa](https://user-images.githubusercontent.com/19480228/60110918-3d77c680-976d-11e9-8716-d6121d8c3469.PNG)\r\n\r\n**System information**\r\n\r\n+ **Tensorflow Version** : 1.13\r\n+ **OS version** : Windows 10 x64\r\n+ **Android studio version** :3.4\r\n+ **Graphic Card**: Nvidia Geforce 840m\r\n\r\nMy question is how can I extract the points got from logits layer ( last layer )?\r\nNote that I have successfully print the coordinates of points : \r\n    `\r\nlogits = tf.layers.dense(\r\n        inputs=dense1,\r\n        units=80,\r\n        activation=None,\r\n        use_bias=True,\r\n        name=\"logits\")\r\n`\r\n `   predictions_dict = {\r\n        \"name\": features['name'],\r\n        \"logits\": logits  \r\n`\r\n` predictions = estimator.predict(input_fn=_predict_input_fn)\r\n        for _, result in enumerate(predictions):\r\n            img = cv2.imread(result['name'].decode('ASCII') + '.jpg')\r\n            print(result['logits']) # print the landmarks\r\n            marks = np.reshape(result['logits'], (-1, 2)) * IMG_WIDTH\r\n            for mark in marks:\r\n                cv2.circle(img, (int(mark[0]), int(\r\n                    mark[1])), 1, (0, 255, 0), -1, cv2.LINE_AA)\r\n            img = cv2.resize(img, (512, 512))\r\n            cv2.imshow('result', img)`\r\n\r\n", "comments": ["Just to verify you have converted .pb to Lite model .Thanks!", "I have converted the file to tflite ", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 30133, "title": "[ROCm] Adding ROCm support for the multinomial op", "body": "This PR adds ROCm support for the multinomial op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n--------------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg", "comments": []}, {"number": 30132, "title": "[ROCm] Adding ROCm support for the l2loss op", "body": "This PR adds ROCm support for the l2loss op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n--------------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg", "comments": []}, {"number": 30131, "title": "Unsupported cumsum, cumprod and scatter_nd ops", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): from binary\r\n- TensorFlow version (or github SHA if from source): 1.13.1\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ABS, ADD, CAST, CONCATENATION, EQUAL, EXPAND_DIMS, FULLY_CONNECTED, GATHER, LESS, MEAN, MUL, PACK, PAD, RANGE, REDUCE_MAX, RELU, RESHAPE, RSQRT, SHAPE, SIN, SOFTMAX, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: Cumprod, Cumsum, ScatterNd.\r\n```\r\n\r\n**Any other info / logs**\r\n\r\nI am trying to convert a transformer model built using [tensor2tensor](https://github.com/tensorflow/tensor2tensor), but the implementation in that repo uses `cumsum`, `cumprod` and `scatter_nd`, which makes it unusable with the TF Lite converter...", "comments": ["Sorry that it doesn't work out for you. We are continuously adding new ops into tflite, in the mean time you could also try implement those ops yourself as custom ops [1]. I believe you won't need implement `scatter_nd` since it's a supported tf select op. Just pass --target_ops=TFLITE_BUILTINS,SELECT_TF_OPS during conversion, thanks!\r\n\r\n[1]https://www.tensorflow.org/lite/guide/ops_custom", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30131\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30131\">No</a>\n"]}, {"number": 30130, "title": "[ROCm] Adding ROCm support for the histogram op", "body": "This PR adds ROCm support for the histogram op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg", "comments": ["This change is merged internally, waiting for automatic merge to happen."]}, {"number": 30129, "title": "TPU error in eager execution", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6\r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the current behavior**\r\nInternalError: Failed copying input tensor from /job:worker/replica:0/task:0/device:CPU:0 to /job:worker/replica:0/task:1/device:CPU:0 in order to run ExperimentalAutoShardDataset: Unable to parse tensor proto Additional GRPC error information: {\"created\":\"@1561473418.214771131\",\"description\":\"Error received from peer\",\"file\":\"external/grpc/src/core/lib/surface/call.cc\",\"file_line\":1\r\n\r\nI get the above error when running model.fit . For my input pipeline , I use tf.Records in conjunction with the Dataset API and feed in a batch of numpy arrays as input and labels to the model.fit function.\r\nI am fairly certain that I am not exceeding any tensor memory limits and all my operations are well within the 2Gb limit and all my dtypes are either float32 or int32\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@capilano How did you solve the issue?", "@jmgc I was using google colab's TPU and went back to using non eager mode, TF1.14 does not support eager training in TPU(or atleast its still buggy) and in google colab even if you update tensorflow to 2.0, the TPU machine still uses 1.14. So that was one issue.\r\nSo there are a couple of options.\r\n1.) Use TF 2.0 and do everything in eager mode(which is default), but you will need cloud TPU, not colab TPU.\r\n2.) Use TF 1.14 in non eager mode and shard the dataset, there are multiple ways to do it. I am currently using TF1.14 and using keras layers and models inside the distribute strategy and using custom training loops to train  a GAN model, but you can also use model.fit and pass a dataset to it directly after calling strategy.experimental_distribute_dataset. \r\n", "I was wondering if a Colab TPU is still Not able to use eager execution? If so, that would explain a lot of the errors I am running into. "]}, {"number": 30128, "title": "[ROCm] Adding ROCm support for the dynamic_partition_op", "body": "This PR adds ROCm support for the dynamic_partition op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n---------------------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg", "comments": []}, {"number": 30127, "title": "broken image link in recurrent_quickdraw.md", "body": "Description of issue: The image link for quickdraw_model.png is broken in document [recurrent_quickdraw.md](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/sequences/recurrent_quickdraw.md) \r\n\r\nThe current source url for the image points to non existent image location.\r\n\r\nUrl: [recurrent_quickdraw.md](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/sequences/recurrent_quickdraw.md)\r\n", "comments": ["Unable to locate the broken link in the markdown file referenced in the issue. Can you please try to elaborate? Thanks!", "the link to the image (Line 16)\r\n\r\n![RNN model structure](../../images/quickdraw_model.png) is not correct.\r\n\r\nit is below this paragraph\r\n\"In this tutorial we'll show how to build an RNN-based recognizer for this problem. The model will use a combination of convolutional layers, LSTM layers, and a softmax output layer to classify the drawings:\"\r\n\r\n", "Thanks. Fixed markdown for github"]}, {"number": 30126, "title": "Memory leaking in tf.data.Dataset in eager mode tensorflow1.12.0", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (MacBook Pro10.14):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (pip install tensorflow-gpu):\r\n- TensorFlow version (1.12.0):\r\n- Python version:3.6.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nAt the beginning of the program, the memory is only 190MB. After running for 1 minute, the memory reaches 6GB. Memory leak is very serious\r\n\r\n**Describe the expected behavior**\r\n\r\nThe program should always be the initial state of 190MB without memory leaks.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\nclass RecordDataset:\r\n    def __init__(self, configs):\r\n        assert(isinstance(configs, dict))\r\n        self.norm_h = 32\r\n        if 'norm_h' in configs:\r\n            self.norm_h = int(configs['norm_h'])\r\n        self.expand_rate = 1.0\r\n        if 'expand_rate' in configs:\r\n            self.expand_rate = float(configs['expand_rate'])\r\n        self.file_list = []\r\n        if 'file_list' in configs:\r\n            self.set_files(configs['file_list'])\r\n        self.num_parallel=4\r\n        if 'num_parallel' in configs:\r\n            self.num_parallel = int(configs['num_parallel'])\r\n        self.batch_size = 32\r\n        if 'batch_size' in configs:\r\n            self.batch_size = int(configs['batch_size'])\r\n\r\n        self.max_txtlen = 32\r\n        if 'max_txtlen' in configs:\r\n            self.max_txtlen = int(configs['max_txtlen'])\r\n        self.max_imglen = 1024\r\n        if 'max_imglen' in configs:\r\n            self.max_imglen = int(configs['max_imglen'])\r\n        self.min_imglen = 16\r\n        if 'min_imglen' in configs:\r\n            self.min_imglen = int(configs['min_imglen'])\r\n        self.BUFFER_SIZE = 4096\r\n        if 'BUFFER_SIZE' in configs:\r\n            self.BUFFER_SIZE = int(configs['BUFFER_SIZE'])\r\n\r\n        self.char_dict = configs['char_dict']\r\n        self.model_type = configs['model_type']\r\n        self.charset = Charset(self.char_dict, self.model_type)\r\n\r\n    def set_files(self, file_list):\r\n        assert(isinstance(file_list, (list, tuple)))\r\n        self.file_list = [file for file in file_list if os.path.isfile(file) and os.path.getsize(file)>0]\r\n\r\n    def get_idstr_by_charstr(self, charstr):\r\n        if isinstance(charstr, bytes):\r\n            charstr = charstr.decode('utf-8')\r\n        idxstr = self.charset.get_idxstr_by_charstr(charstr)\r\n        idxlen = len(idxstr.split(','))\r\n        return idxstr, idxlen\r\n\r\n    def parse_example(self, serial_example):\r\n        norm_h = self.norm_h\r\n        expand_rate = self.expand_rate\r\n        debug = False\r\n\r\n        feat_dict = tf.parse_single_example(serial_example,features={\r\n                                            'img_raw' : tf.FixedLenFeature([], tf.string), \\\r\n                                            'height'  : tf.FixedLenFeature([], tf.int64),  \\\r\n                                            'width'   : tf.FixedLenFeature([], tf.int64),  \\\r\n                                            'channel' : tf.FixedLenFeature([], tf.int64),  \\\r\n                                            'img_path': tf.FixedLenFeature([], tf.string), \\\r\n                                            'coord'   : tf.FixedLenFeature([], tf.string), \\\r\n                                            'label'   : tf.FixedLenFeature([], tf.string)})\r\n\r\n        img_raw = feat_dict['img_raw']\r\n        height = feat_dict['height']\r\n        width = feat_dict['width']\r\n        channel = feat_dict['channel']\r\n        img_path = feat_dict['img_path']\r\n        coord = feat_dict['coord']\r\n        img_text = feat_dict['label']\r\n        txt_index, txt_len = tf.py_func(self.get_idstr_by_charstr, [img_text], [tf.string, tf.int64])\r\n        txt_len = tf.to_int32(txt_len)\r\n\r\n        coord_val = tf.string_split([coord], ',').values\r\n        coord_val = tf.string_to_number(coord_val, out_type=tf.int32)\r\n        offset_w = coord_val[0]\r\n        offset_h = coord_val[1]\r\n        target_w = coord_val[2] - coord_val[0]\r\n        target_h = coord_val[3] - coord_val[1]\r\n\r\n        img_raw = tf.decode_raw(img_raw, tf.uint8)\r\n        orig_img = tf.reshape(img_raw, (height, width, channel))\r\n        crop_img = tf.image.crop_to_bounding_box(orig_img, offset_h, offset_w, target_h, target_w)\r\n\r\n        ratio = tf.to_float(norm_h / tf.to_float(target_h))\r\n        norm_w = tf.to_int32(tf.to_float(target_w) * expand_rate * ratio)\r\n        norm_img = tf.image.resize_images(crop_img, (norm_h, norm_w))\r\n\r\n        if debug:\r\n            norm_img = tf.cast(norm_img, tf.uint8)\r\n        else:\r\n            # convert RGB-->BGR\r\n            mean = [102.9801, 115.9465, 122.7717]\r\n            norm_img = norm_img[:, :, ::-1]\r\n            norm_img = norm_img - mean\r\n        return img_path, norm_img, img_text, txt_index, txt_len, coord, norm_w\r\n\r\n    def filter(self, img_path, norm_img, img_text, txt_index, txt_len, coord, norm_w):\r\n        img_len = tf.cast(norm_w, dtype=tf.int32)\r\n        txt_len = tf.cast(txt_len, dtype=tf.int32)\r\n        txt_len_logical = tf.logical_and(txt_len <= self.max_txtlen, txt_len >= 0)\r\n        img_len_logical = tf.logical_and(img_len <= self.max_imglen,img_len >= self.min_imglen)\r\n        return tf.logical_and(txt_len_logical, img_len_logical)\r\n\r\n    def data_reader_v0(self, repeat=0):\r\n        padded_shapes = ([], [self.norm_h, None, 3], [], [], [], [], [])\r\n        padding_values = ('', 0.0, '', '', 0, '', 0)\r\n        dataset = tf.data.TFRecordDataset(self.file_list)\r\n        if repeat != 0:\r\n            dataset = dataset.repeat(repeat)\r\n        dataset = dataset.map(map_func=self.parse_example, num_parallel_calls=self.num_parallel)\r\n        dataset = dataset.padded_batch(self.batch_size, padded_shapes, padding_values)\r\n        return dataset\r\n\r\n    def data_reader(self, repeat=0):\r\n        padded_shapes = ([], [self.norm_h, None, 3], [], [], [], [], [])\r\n        padding_values = ('', 0.0, '', '', 0, '', 0)\r\n        fileset = tf.data.Dataset.list_files(self.file_list)\r\n        dataset = fileset.apply(\r\n                    tf.data.experimental.parallel_interleave(\r\n                        lambda filename: tf.data.TFRecordDataset(\r\n                            filename, num_parallel_reads=self.num_parallel),\r\n                        cycle_length=32))\r\n\r\n        if repeat != 0:\r\n            dataset = dataset.repeat(repeat)\r\n        else:\r\n            dataset = dataset.repeat()\r\n        dataset = dataset.map(map_func=self.parse_example, num_parallel_calls=self.num_parallel)\r\n        dataset = dataset.filter(self.filter)\r\n        dataset = dataset.cache()\r\n        dataset = dataset.shuffle(self.BUFFER_SIZE).padded_batch(self.batch_size, padded_shapes, padding_values)\r\n        dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\r\n        #dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\r\n        return dataset\r\n\r\n\r\ndef RecordDatasetTest():\r\n    tf.enable_eager_execution()\r\n\r\n    configs = {}\r\n    configs['norm_h'] = 32\r\n    configs['expand_rate'] = 1.0\r\n    configs['file_list'] = ['tfrecord_dir/tfrecord.list.0', 'tfrecord_dir/tfrecord.list.1']\r\n    configs['num_parallel'] = 4\r\n    configs['batch_size'] = 1\r\n    configs['model_type'] = 'ctc'\r\n\r\n    configs['char_dict'] = 'char_dict.lst'\r\n    dataset = RecordDataset(configs)\r\n    dataset = dataset.data_reader()\r\n    total_count = 0\r\n    for line in dataset:\r\n        img_path, norm_img, img_text, txt_index, txt_len, coord, norm_w = line\r\n        norm_img = norm_img + [102.9801, 115.9465, 122.7717]\r\n        image = np.array(norm_img.numpy(), np.uint8)\r\n        img_path = img_path.numpy()\r\n        img_text = img_text.numpy()\r\n        txt_index = txt_index.numpy()\r\n        txt_len = txt_len.numpy()\r\n        total_count = total_count + txt_len\r\n    print(total_count)\r\n\r\n\r\nif __name__=='__main__':\r\n    RecordDatasetTest()\r\n\r\n", "comments": ["The main cause of memory leaks is dataset.cache, no memory leaks after comments are changed."]}, {"number": 30125, "title": "[ROCm] Adding ROCm support for the bincount op", "body": "This PR adds ROCm support for the bincount op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n-------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg", "comments": []}, {"number": 30124, "title": "Get input shape in tf.keras.Model (Imperative API)", "body": "I use Tensorflow 2.0 and I have a model that was defined in Imperative API. In call method I use something like this:\r\n\r\n```python\r\nb, h, w, c = images.shape\r\nk_h, k_w = kernels.shape[2], kernels.shape[3]\r\n\r\nimages = tf.transpose(images, [1, 2, 0, 3])  # (h, w, b, c)\r\nnew_shape = tf.TensorShape([1, h, w, b * c])\r\nimages = tf.reshape(images, new_shape)\r\n```\r\n\r\nWhen I train my model with custom loop -- no problem. But I want to porting my model to SavedModel format. I use the following function:\r\n\r\n```python\r\ntf.keras.experimental.export_saved_model(\r\n        model, file_path,\r\n        serving_only=True,\r\n        input_signature=[\r\n                tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32),\r\n            ]\r\n        )\r\n```\r\n\r\nAnd i got error:\r\n\r\n```\r\nTypeError: unsupported operand type(s) for *: 'NoneType' and 'int'\r\n```\r\n\r\nMoreover, I can't do it even If I specify shape=[1, None, None, 3], because I got:\r\n\r\n```\r\nValueError: Tried to convert 'shape' to a tensor and failed. Error: Cannot convert a partially known TensorShape to a Tensor: (1, None, None, 3)\r\n```\r\n\r\nIt means that I can't do reshape at all. But I need it. How can I do it?", "comments": ["Here is the code with necessary changes made. This should work!\r\n```\r\nimage_shape = tf.shape(images)\r\nkernel_shape = tf.shape(kernels)\r\nb, h, w, c = image_shape[0], image_shape[1], image_shape[2], image_shape[3], \r\nk_h, k_w = kernel_shape[2], kernel_shape[3]\r\n\r\nimages = tf.transpose(images, [1, 2, 0, 3])  # (h, w, b, c)\r\nnew_shape = tf.TensorShape([1, h, w, b * c])\r\nimages = tf.reshape(images, new_shape)\r\n```", "Need one minor fix: your code doesn't work with TensorShape, need to remove and use just a list with shape.\r\n\r\n@srihari-humbarwadi thank you! "]}, {"number": 30123, "title": "R1.14", "body": "1", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30123) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 30122, "title": "Getting validation steps from dict breaks keras fit TF 2.0.0-beta1", "body": "**System information**\r\n- TensorFlow installed from: pip\r\n- TensorFlow version: 2.0.0-beta1\r\n- Python version: 3.6\r\n\r\n\r\n**Describe the current behavior**\r\nWhen calling fit on a Keras model in 2.0.0-beta1 a ` KeyError: 0` is thrown when trying to call fit with validation_data given as a dict (this worked in the alpha)\r\n\r\ne.g.\r\n```\r\nmymodel.fit(x = {'input_0' : train_data_type_0, 'input_1':  train_data_type_1}, y = train_labels, \r\n         validation_data = ({'input_0' : val_data_type_0, 'input_1':  val_data_type_1}, val_labels) )\r\n```\r\nThe issue seems to have been introduced [here](https://github.com/tensorflow/tensorflow/commit/25380986954692d947bd230e4f5d3a2d11dd3064), as the line:\r\n`val_samples_or_steps = val_inputs and val_inputs[0].shape[0] or None`\r\nassumes an array will be found and fails for dicts. \r\n\r\n**Describe the expected behaviour**\r\n`val_inputs: Either a list or dictionary of arrays, or a dataset instance.`\r\n", "comments": ["Please provide us complete code to reproduce the issue.Thanks", "The following is sufficient to reproduce the issue:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\ntrain_input_0 = np.random.rand(1000, 1)\r\ntrain_input_1 = np.random.rand(1000, 1)\r\ntrain_labels  = np.random.rand(1000, 1)\r\n\r\nval_input_0 = np.random.rand(1000, 1)\r\nval_input_1 = np.random.rand(1000, 1)\r\nval_labels  = np.random.rand(1000, 1)\r\n\r\ninput_0 = tf.keras.Input(shape=(None,), name='input_0')\r\ninput_1 = tf.keras.Input(shape=(None,), name='input_1')\r\n\r\nclass my_model(tf.keras.Model):\r\n    def __init__(self):\r\n        super(my_model, self).__init__(self)\r\n        self.hidden_layer_0 = tf.keras.layers.Dense(100, activation=tf.nn.relu)\r\n        self.hidden_layer_1 = tf.keras.layers.Dense(100, activation=tf.nn.relu)\r\n        self.concat         = tf.keras.layers.Concatenate()\r\n\r\n        self.out_layer    = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\r\n\r\n    def call(self, inputs =  [input_0, input_1]):\r\n        activation_0 = self.hidden_layer_0(inputs['input_0'])\r\n        activation_1 = self.hidden_layer_1(inputs['input_1'])\r\n        concat       = self.concat([activation_0, activation_1])\r\n      \r\n        return self.out_layer(concat)\r\n\r\nmodel = my_model()\r\nopt = tf.optimizers.Adam()\r\nloss = tf.keras.losses.MeanAbsoluteError()\r\nmodel.compile(opt, loss)\r\n\r\nmodel.fit(x = {'input_0' : train_input_0, 'input_1':  train_input_1}, y = train_labels, \r\n         validation_data = ({'input_0' : val_input_0, 'input_1':  val_input_1}, val_labels) )\r\n```\r\n\r\nThis runs with 2.0.0-alpha0, but fails with 2.0.0-beta1\r\n", "I am able to reproduce the issue in Colab ,works with  TF 2.0.0-alpha0, and fails with 2.0.0-beta1.Thanks!", "Added a PR #30258 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30122\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30122\">No</a>\n"]}]