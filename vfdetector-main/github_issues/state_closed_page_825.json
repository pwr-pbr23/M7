[{"number": 28780, "title": "c api for CheckpointReader", "body": "c api for the CheckpointReader\r\n\r\n- [x] c wrapper type\r\n- [X] function for load all the variables\r\n- [X] has tensor\r\n- [X] get tensor\r\n- [X]  get variable datatype\r\n- [x] get variable shape\r\n- [x] handle status\r\n- [x] docs", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28780) for more info**.\n\n<!-- need_sender_cla -->", "@chengchingwen thanks for your contribution , let me know once it is ready for review.", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28780) for more info**.\n\n<!-- ok -->", "@rthadur hi, I think it is ready for review.", "Thanks for adding this, Peter! Pinging @pschuh and @eaplatanios to check that this approach makes sense for the Swift and Scala frontends \ud83d\ude42."]}, {"number": 28779, "title": "cannot really use eager execution to see tensors inside of a layer.", "body": "i am using tf-nightly-gpu-2.0-preview dev20190516 on ubuntu 18.04.\r\n\r\nwhenever I try to convert a tensor into a numpy array from inside the \"call\" function of a custom keras layer i get the following stack trace when I start execution:\r\n\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/zadeck/learning/tfkeras/interrow/trainPlant.py\", line 101, in main\r\n    modelObj.add (recLayer)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 192, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 629, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 90, in wrapper\r\n    ), args, kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n  File \"/tmp/tmp1ojmi3gq.py\", line 9, in tf__call\r\n    ag__.converted_call('plotPicture', viewImage, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (ag__.converted_call('numpy', x, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None), 0), None)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 219, in converted_call\r\n    f = getattr(owner, f)\r\nAttributeError: 'Tensor' object has no attribute 'numpy'\r\n\r\nThis happens very early in my eager execution as if someone behind the scenes is calling the compiler on each layer before execution begins.   If i try to use the numpy attribute outside of the keras layers i have no problem.   \r\n\r\nI do not explicitly call the \"compile\" function for my model.\r\n\r\nI am able to trick the system into making this work hiding the access to the numpy call inside of an indirect function call.\r\n\r\ncode within keras layer that works properly:\r\n\r\ndef build (self, input_shape):\r\n    ...\r\n    self.indirect = self.nothing\r\n\r\ndef call (self, x):\r\n    self.indirect (x)\r\n    self.indirect = self.useXnumpy\r\n\r\ndef nothing (self, x):\r\n    y = 1\r\n\r\ndef useXnumpy (self, x):\r\n    ... =  x.numpy ()\r\n\r\n\r\nwhat does not work is either have the call to x.numpy () directly in the \"call\" function for a keras layer or to directly call the useXnumpy routine from the \"call\" function of a keras layer.   Having the indirect call fools the compiler or preprocessor sufficiently to allow the values to be executed.   \r\n\r\nI do not know if the real bug is that the preprocessing step should not be executed on the layer when in eager mode or if it simply needs to be told that calling numpy() is ok on tensors.     \r\n\r\nI do know that i am in eager mode because i have no problem accessing the numpy function on tensors inside the loss function.    it is simply trying to do that from within a keras layer that causes problems.", "comments": ["Will it be possible to provide minimal code snippet that can reproduce the issue. It would definitely help us to debug the issue faster. Thanks! ", "try this:\r\n================\r\nlorien:~/work(44) python3\r\nPython 3.6.7 (default, Oct 22 2018, 11:32:17) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tfkeras.bugs.badnumpy as bn\r\n>>> bn.main ()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/zadeck/learning/tfkeras/bugs/badnumpy.py\", line 24, in main\r\n    modelObj.add (myLayer)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 192, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 629, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 90, in wrapper\r\n    ), args, kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n  File \"/tmp/tmpze72bong.py\", line 6, in tf__call\r\n    print(ag__.converted_call('numpy', x, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 219, in converted_call\r\n    f = getattr(owner, f)\r\nAttributeError: 'Tensor' object has no attribute 'numpy'\r\n>>> \r\n===========================\r\nbadnumpy.py follows\r\n===========================\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as B\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import InputLayer\r\nfrom tensorflow.keras import optimizers\r\nfrom tensorflow.keras.layers import Layer\r\n\r\n\r\ndef main ():\r\n    trainData = [1.,2.,3.,4.,5.,6.,7.,8.]\r\n    trainLabel = [1.,2.,3.,4.,5.,6.,7.,8.]\r\n\r\n    B.set_floatx('float32')\r\n    B.set_image_data_format('channels_last')\r\n\r\n    inputLayer = InputLayer (input_shape = (1),\r\n                             dtype = \"float32\", name = \"InputLayer\")\r\n    myLayer = MyLayer ()\r\n    optimizerObj = optimizers.Adam()\r\n    modelObj = Sequential ()\r\n    modelObj.add (inputLayer)\r\n    modelObj.add (myLayer)\r\n\r\n    lossObj = MyLoss ()\r\n    \r\n    labelIndex = 0\r\n    lossHistory = []\r\n    for (batchIdx, data) in enumerate(trainData):\r\n        target = trainLabel[batchIdx]\r\n        with tf.GradientTape() as tape:\r\n            logits = modelObj(data, training=True)\r\n            batchLossVec = lossObj(target, logits)\r\n\r\n        batchLoss = batchLossVec.numpy ().sum ()\r\n        lossHistory.append(batchLossVec.numpy().mean())\r\n        grads = tape.gradient(batchLossVec, modelObj.trainable_variables)\r\n        optimizer.apply_gradients(zip(grads, modelObj.trainable_variables))\r\n\r\nclass MyLoss ():\r\n    def __init__(self, *args, **kwargs):\r\n        super(MyLoss, self).__init__(*args, **kwargs)\r\n\r\n    def __call__ (self, y_true, y_pred, *args, **kwargs):\r\n        return 1\r\n        \r\nclass MyLayer (Layer):\r\n    def __init__(self, *args, **kwargs):\r\n        super(MyLayer, self).__init__(*args, **kwargs)\r\n\r\n    def call (self, x):\r\n        print (x.numpy ())\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 28778, "title": "TF Lite can't run example project of select tensorflow operators on iOS", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r1.13\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 0.19.2\r\n- GCC/Compiler version (if compiling from source): 4.2.1\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nFollowing guide: [Select TensorFlow operators to use in TensorFlow Lite](https://www.tensorflow.org/lite/guide/ops_select)\r\n\r\nBuilt with command\r\n`tensorflow/contrib/makefile/build_all_ios_with_tflite.sh -a arm64`\r\n\r\nRan example project in XCode\r\n`tensorflow/lite/examples/ios/camera/tflite_camera_example_with_select_tf_ops.xcodeproj`\r\n\r\nGot a list of 20 errors in cstring that look like\r\n`No member named 'memcpy' in the global namespace`\r\n`No member named 'memmove' in the global namespace; did you mean 'remove'?`\r\n`No member named 'strcpy' in the global namespace`\r\n`No member named 'strncpy' in the global namespace`\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Is there a commit / branch / tag where I can run this example tflite_camera_example_with_select_tf_ops.xcodeproj successfully?", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28778\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28778\">No</a>\n"]}, {"number": 28777, "title": "Conv2D breaking when used with keras Model subclassing", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0 alpha gpu \r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nI am trying to use `tf.keras.Model` subclassing to define my model but it is failing on the first conv layer. Here is the code I am using:\r\n\r\n```python\r\n\r\nclass CustomModel(tf.keras.Model):\r\n  def __init__(self, **kwargs):\r\n    super(CustomModel, self).__init__(**kwargs)\r\n    self.conv1   = Conv2D(32, (3, 3), padding='same')\r\n    self.conv2   = Conv2D(64, (3, 3), padding='same')\r\n    self.pool    = MaxPooling2D(pool_size=(2, 2))\r\n    self.bn      = BatchNormalization()\r\n    self.relu    = Activation(\"relu\")\r\n    self.softmax = Activation(\"softmax\")\r\n    self.drop1   = Dropout(0.25)\r\n    self.drop2   = Dropout(0.5)\r\n    self.dense1  = Dense(512)\r\n    self.dense2  = Dense(10)\r\n    self.flat    = Flatten()\r\n    \r\n  \r\n  \r\n  def call(self, inputs, train):\r\n    z = self.conv1(inputs)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    \r\n    z = self.conv1(z)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    z = self.pool(z)\r\n    z = self.drop1(z, training=train)\r\n    \r\n    z = self.conv2(z)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    \r\n    z = self.conv2(z)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    z = self.pool(z)\r\n    z = self.drop1(z, training=train)\r\n    \r\n    z = self.flat(z)\r\n    z = self.dense1(z)\r\n    z = self.relu(z)\r\n    z = self.drop2(z, training=train)\r\n    z = self.dense2(z)\r\n    z = self.softmax(z)\r\n    \r\n    return z\r\n```\r\nIn order to check if the model is working fine, I am passing a random input to the model in this way:\r\n\r\n```\r\nrandom_input = np.random.rand(32,32, 3).astype(np.float32)\r\nrandom_input = np.expand_dims(random_input, axis=0)\r\npreds = model(random_input, train=False)\r\n```\r\n\r\nBut this throws the following error: `InvalidArgumentError: input depth must be evenly divisible by filter depth: 32 vs 3 [Op:Conv2D]`\r\n\r\nThe same model works fine with `Sequential/Functional` API. So either I am missing out on something or there is something wrong with the subclassing. Can you please look into it?", "comments": ["@AakashKumarNain In order to expedite the trouble-shooting process, please provide a minimum code snippet to reproduce the issue reported here. Thanks!", "@gadagashwini except for the `import` statements, what I have provided is the code snippet. Anyways, here is the full code:\r\n\r\n```python\r\nimport os\r\nimport glob\r\nimport h5py\r\nimport math\r\nimport shutil\r\n\r\n\r\nimport numpy as np \r\nfrom pathlib import Path\r\nimport matplotlib.pyplot as plt\r\nimport matplotlib.pylab as pl\r\n\r\n\r\nfrom tensorflow.keras.models import Sequential, Model, load_model\r\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation\r\nfrom tensorflow.keras.layers import Input, Flatten, SeparableConv2D, BatchNormalization\r\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\r\nfrom tensorflow.keras.utils import to_categorical\r\n\r\nfrom tensorflow.keras import backend as K\r\nimport tensorflow as tf\r\n\r\nclass CustomModel(tf.keras.Model):\r\n  def __init__(self, **kwargs):\r\n    super(CustomModel, self).__init__(**kwargs)\r\n    self.conv1   = Conv2D(32, (3, 3), padding='same')\r\n    self.conv2   = Conv2D(64, (3, 3), padding='same')\r\n    self.pool    = MaxPooling2D(pool_size=(2, 2))\r\n    self.bn      = BatchNormalization()\r\n    self.relu    = Activation(\"relu\")\r\n    self.softmax = Activation(\"softmax\")\r\n    self.drop1   = Dropout(0.25)\r\n    self.drop2   = Dropout(0.5)\r\n    self.dense1  = Dense(512)\r\n    self.dense2  = Dense(10)\r\n    self.flat    = Flatten()\r\n    \r\n  \r\n  \r\n  def call(self, inputs, train):\r\n    z = self.conv1(inputs)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    \r\n    z = self.conv1(z)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    z = self.pool(z)\r\n    z = self.drop1(z, training=train)\r\n    \r\n    z = self.conv2(z)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    \r\n    z = self.conv2(z)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    z = self.pool(z)\r\n    z = self.drop1(z, training=train)\r\n    \r\n    z = self.flat(z)\r\n    z = self.dense1(z)\r\n    z = self.relu(z)\r\n    z = self.drop2(z, training=train)\r\n    z = self.dense2(z)\r\n    z = self.softmax(z)\r\n    \r\n    return z\r\n\r\nmodel =CustomModel()\r\nrandom_input = np.random.rand(32,32, 3).astype(np.float32)\r\nrandom_input = np.expand_dims(random_input, axis=0)\r\npreds = model(random_input, train=False)\r\n```", "@AakashKumarNain Thanks for the information.", "@gadagashwini You are welcome", "I am able to reproduce the issue on colab with TF 2.0alpha . This is the error message I got InvalidArgumentError: input depth must be evenly divisible by filter depth: 32 vs 3 [Op:Conv2D]", "Any updates on this? I think this is a major bug", "Not sure what do you mean by it's working in Functional API...\r\nThe problem here is you call:\r\nz = conv1(inputs)\r\nwhich builds the layer to accepts an input of 3 channels\r\n\r\nthen you call:\r\nz = conv1(z)\r\nwhich is an input of 32 channels\r\n\r\nThis is confusing `conv1`, I think it fails with all subclass/functional/sequential, can you double check?\r\n\r\nThe error definitely needs improvement, but using colab I do see that the error message is much clearer in 1.14.", "When I say\r\n`z = conv1(z)`\r\nI mean that I want to add another layer that has 32 output channels and a filter of size (3,3). So, `conv1` is a layer with `32` output channels which I should be able to use at multiplt places in my net. Is it clear now?", "Like mentioned above, we don't have a layer that accepts dynamic number of channels. If you run conv1 with input of (1, 32, 32, 3), the weight inside layer will be shape of (3, 3, 3, 32), which stands for (kernel_size, kernel_size, input_channels, output_channels). And now you pass another input which is 32 channels, so the weight will have to change shape to (3, 3, 32, 32), it's not possible.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28777\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28777\">No</a>\n", "Instead make another conv layer would help fix this", "But then I have to write all the layers in `__init__` and then call every layer in `call` method which doesn't seem optimal to me. Is there any example you can point to for ref?", "You can write smaller blocks that does this, for reference, checkout keras applications:\r\nhttps://github.com/keras-team/keras-applications/blob/master/keras_applications/densenet.py#L93-L120", "I am aware of that but that is `Functional` API which works fine. This one is the case of `subclassing` and `eager` mode", "Do you have a minimal code snippet for functional model?", "Yeah sure. Here is the code for functional model:\r\n```\r\ndef build_functional_model():\r\n  img_input = Input(shape=(224,224,3))\r\n  x = Conv2D(32, (3,3), activation='relu')(img_input)\r\n  x = Conv2D(32, (3,3), activation='relu')(x)\r\n  x = MaxPooling2D((2,2))(x)\r\n  \r\n  x = Conv2D(64, (3,3), activation='relu')(x)\r\n  x = Conv2D(64, (3,3), activation='relu')(x)\r\n  x = MaxPooling2D((2,2))(x)\r\n  \r\n  x = Flatten()(x)\r\n  x = Dropout(0.25)(x)\r\n  x = Dense(512, activation='relu')(x)\r\n  x = Dropout(0.5)(x)\r\n  x = Dense(10, activation='softmax')(x)\r\n  \r\n  model= Model(img_input, x)\r\n  return model\r\n\r\n```\r\nIf I write the `custom model` as I have shown above in the original post, which I think is the right way to do it, then it throws the error. If you need to run it by yourself, then you can check out this notbeook: https://colab.research.google.com/drive/1mBf1mErwN0lDEFqu6fQI-SpK7PpSp5Xl", "This functional model is completely legitimate because you indeed created two different Conv2D layers, one for input shape (224,224,3), one for (224,224,32)....The subclass model will not work because you're reusing the same layer", "I think we are still not on the same page. Let me try to elaborate it again:\r\n1) I want to build a model using subclassing\r\n2) In my model, I can have one particular type of layer repeated. For example, a `Conv2D` layer with `32` filters can be used in multiple places as shown in the above example.\r\n3) If this isn't the right way to declare all the types of layer I am going to use in my model, can you please show me an example of how to do that? ", "@AakashKumarNain Based on comments from @tanzhenyu , here is the model (modified couple of lines in your code) that works. Please let's know what you think.\r\n\r\n```\r\nimport os\r\nimport glob\r\nimport h5py\r\nimport math\r\nimport shutil\r\n\r\n\r\nimport numpy as np \r\nfrom pathlib import Path\r\nimport matplotlib.pyplot as plt\r\nimport matplotlib.pylab as pl\r\n\r\n\r\nfrom tensorflow.keras.models import Sequential, Model, load_model\r\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation\r\nfrom tensorflow.keras.layers import Input, Flatten, SeparableConv2D, BatchNormalization\r\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\r\nfrom tensorflow.keras.utils import to_categorical\r\n\r\nfrom tensorflow.keras import backend as K\r\nimport tensorflow as tf\r\n\r\nclass CustomModel(tf.keras.Model):\r\n  def __init__(self, **kwargs):\r\n    super(CustomModel, self).__init__(**kwargs)\r\n    self.conv1   = Conv2D(32, (3, 3), padding='same')\r\n    self.conv2   = Conv2D(32, (3, 3), padding='same')\r\n    self.conv3   = Conv2D(64, (3, 3), padding='same')\r\n    self.conv4   = Conv2D(64, (3, 3), padding='same')\r\n    self.pool    = MaxPooling2D(pool_size=(2, 2))\r\n    self.bn      = BatchNormalization()\r\n    self.relu    = Activation(\"relu\")\r\n    self.softmax = Activation(\"softmax\")\r\n    self.drop1   = Dropout(0.25)\r\n    self.drop2   = Dropout(0.5)\r\n    self.dense1  = Dense(512)\r\n    self.dense2  = Dense(10)\r\n    self.flat    = Flatten()\r\n    \r\n  \r\n  \r\n  def call(self, inputs, train):\r\n    z = self.conv1(inputs)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    \r\n    z = self.conv2(z)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    z = self.pool(z)\r\n    z = self.drop1(z, training=train)\r\n    \r\n    z = self.conv3(z)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    \r\n    z = self.conv4(z)\r\n    z = self.bn(z, training=train)\r\n    z = self.relu(z)\r\n    z = self.pool(z)\r\n    z = self.drop1(z, training=train)\r\n    \r\n    z = self.flat(z)\r\n    z = self.dense1(z)\r\n    z = self.relu(z)\r\n    z = self.drop2(z, training=train)\r\n    z = self.dense2(z)\r\n    z = self.softmax(z)\r\n    \r\n    return z\r\n\r\nmodel =CustomModel()\r\nrandom_input = np.random.rand(32,32, 3).astype(np.float32)\r\nrandom_input = np.expand_dims(random_input, axis=0)\r\npreds = model(random_input, train=False)\r\n```", "Thanks. I got that. The only thing is that it is not a very good design IMO because you are declaring  same thing with two diff variables in `__init__`. \r\n\r\nMaybe, it's just the limitation as we have to check for the shapes. So, I will digest it for now anyways. Thanks again", "Hi @AakashKumarNain, I was struggling with the same problem and it was strange to me to define \"same\" layer multiple times, too. However after realising I should do this, I implemented a workaround (which is not really nice, but it works). What I did was:\r\n\r\n```self.conv   = [Conv2D(32, (3, 3), padding='same') for layer in range(4)]```\r\n\r\nand then do\r\n\r\n```\r\nz = self.conv[0](z)\r\nz = self.conv[1](z)\r\nz = self.conv[2](z)\r\nz = self.conv[3](z)", "@tanzhenyu  Hi I am struggling with the same issue. Here is the code snippet if somebody can help out:-\r\n\r\nconv_output = tensorflow.keras.backend.conv2d(input_tensor, kernel=modified_weights, strides=(1, 1), padding='same', dilation_rate=(1,1), data_format='channels_last')\r\n\r\ninput_tensor.shape( )= (1, 56, 56, 64)\r\nmodifies_weights.shape( ) = (64, 3, 3, 64)\r\n\r\n\r\nTried with channels_first also ; same error;\r\n\r\nThis some experimentation from resnet50 model from the where the required layer output and weights have been correctly extracted; The dimensions have been confirmed to be correct from there.\r\n\r\n", "@AakashKumarNain @gasar8 Try layer subclassing. You can define a new layer (or a sequence of layers) once and then re-use them as you build your model. Here is a good example https://www.linkedin.com/pulse/model-sub-classing-custom-training-loop-from-scratch-tensorflow\r\n\r\n"]}, {"number": 28776, "title": "Add support for handling uint32 and uint64 dtypes in batch_util CopySliceToElement and MaybeMoveSliceToElement", "body": "This adds support for handling cases of uint32 and uint64 dtypes in `batch_util` `CopySliceToElement` and `MaybeMoveSliceToElement`. Previously, these types cause an error `Unimplemented: CopySliceToElement Unhandled data type: 22`. These functions are used in a number of ops including `from_tensor_slices` and `unbatch` in `tf.data.Dataset` that will also fail when encountering uint32 and uint64 dtypes.\r\n\r\nFixes #28775 ", "comments": ["@jsimsa and @feihugis if you could take a look that would be great, thanks!", "Thanks @feihugis !", "Thanks @jsimsa , I'll add the additional Python tests you mentioned", "Thanks @jsimsa , I didn't see that `unbatch` had been changed after I rebased. I'm fixing that now.", "@jsimsa this has passed tests now, please take another look. Thanks!"]}, {"number": 28775, "title": "batch_util CopySliceToElement does not support uint32, uint64 dtypes", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): master\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 0.25.1\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen batch_util::CopySliceToElement gets a dtype of uint32 or uint64, it fails with error:\r\n`Unimplemented: CopySliceToElement Unhandled data type: 22`  (this is uint32)\r\n\r\nThis is an issue for using tensor_slice_dataset_op, which can calls this function and should also support these dtypes.\r\n\r\n**Describe the expected behavior**\r\nThis function should handle these primitive types\r\n\r\n**Code to reproduce the issue**\r\nUnit tests in tensor_slice_dataset_op_test.cc fail when these dtypes are added\r\n\r\n**Other info / logs**\r\nNA\r\n", "comments": ["@BryanCutler Please provide simple reproducible code to investigate further.", "@muddham the additions to the test in #28776 reproduce the issue, but also here is a simple script\r\n\r\n```python\r\nc = tf.constant(0, shape=[4, 1, 2], dtype=tf.dtypes.uint32)\r\nds = tf.data.Dataset.from_tensor_slices(c)\r\nit = ds.make_one_shot_iterator()\r\nn = it.get_next()\r\nwith tf.Session() as sess:\r\n    print(sess.run(n))\r\n```\r\n\r\nproduces error:\r\n```\r\nUnimplementedError (see above for traceback): CopySliceToElement Unhandled data type: 22\r\n\t [[node IteratorGetNext (defined at <ipython-input-9-74466e672a7d>:1) ]]\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28775\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28775\">No</a>\n"]}, {"number": 28774, "title": "[LITE] Fix aarch64 build error", "body": "I was building TF Lite for ARM64 board and encountered this error. Please review the fix.\r\n```\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:22:0,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:29:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h: In static member function \u2018static void tflite::optimized_ops::depthwise_conv::WorkspacePrefetchWrite<(tflite::DepthwiseConvImplementation)3>::Run(int8, int, int8*)\u2019:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5783:71: note: use -flax-vector-conversions to permit conversions between vectors with differing element types or numbers of subparts\r\n       vst1_lane_u32(reinterpret_cast<uint32_t*>(ptr), fill_data_vec, 0);\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5783:71: error: cannot convert \u2018const int8x8_t {aka const __vector(8) signed char}\u2019 to \u2018uint32x2_t {aka __vector(2) unsigned int}\u2019 for argument \u20182\u2019 to \u2018void vst1_lane_u32(uint32_t*, uint32x2_t, int)\u2019\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5786:35: error: cannot convert \u2018const int8x8_t {aka const __vector(8) signed char}\u2019 to \u2018uint32x2_t {aka __vector(2) unsigned int}\u2019 for argument \u20182\u2019 to \u2018void vst1_lane_u32(uint32_t*, uint32x2_t, int)\u2019\r\n                   fill_data_vec, 0);\r\n                                   ^\r\ntensorflow/lite/tools/make/Makefile:225: recipe for target '/home/siju/workspace/tensorflow-1/tensorflow/lite/tools/make/gen/aarch64_armv8-a/obj/tensorflow/lite/kernels/depthwise_conv.o' failed\r\nmake: *** [/home/siju/workspace/tensorflow-1/tensorflow/lite/tools/make/gen/aarch64_armv8-a/obj/tensorflow/lite/kernels/depthwise_conv.o] Error 1\r\n````", "comments": ["Hi Samuel, have a fix here: https://github.com/tensorflow/tensorflow/commit/5fa9e98d335fdf42d6fa621239ea3321a257e027, can you try if that work for you? thanks", "similar changes are pushed , so closing this PR."]}, {"number": 28773, "title": "TensorFlow 1.14 changes Keras callback order relative to model build", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): r1.14 branch built  from source\r\n- TensorFlow version (use command below): r1.14\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nTensorFlow 1.14 changes the relative call order of building the model and the set_model callback in the tf.keras fit_generator path. (As of commit cd701ec in the r1.14 branch).\r\n\r\nThe keras/engine/training.py `_make_train_function` adds the optimizer update ops / aka, the backward prop phase, and fills out the model's graph. Callbacks that need full graph visibility need their `set_model` function called after the full graph is created.\r\n\r\nThe order of the operations are as follows:\r\n\r\ntf.keras fit():  1. `_make_train_function`  2. `set_model`\r\ntf.keras fit_generator():  1. `set_model` 2. `_make_train_function`\r\nkeras_team Keras fit():  1. `_make_train_function`  2. `set_model`\r\nkeras_team Keras fit_generator():  1. `_make_train_function`  2. `set_model`\r\n\r\nThe tf.keras fit_generator() path stands out as being different from the rest.\r\n\r\nCommit https://github.com/tensorflow/tensorflow/commit/a332fea0be8def4aa5985499ad807ef78d029142 fixed this for the non-eager mode case and added a test case to help prevent future regression.  Commit https://github.com/tensorflow/tensorflow/commit/615182adb3d01fd8357e574bd8920c0995c6bbb8#diff-6561418ac6882a842d78dad52731895b regressed this order, and also removed the test case that was intended to catch regressions.\r\n\r\nAnother side effect of the current code is that the `_make_train_function` is called from `model.train_on_batch` so in the fit_generator path this is now being called on every iteration. While the majority of the `_make_train_function` is guarded by a check that won't do actual work, there are somethings in that method that will run and waste cycles on every iteration.\r\n\r\n**Describe the expected behavior**\r\nThe Keras callback `set_model` method should be called after the whole model is populated. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["HI~\r\n    When i using  from tensorflow_model_optimization.sparsity import keras as sparsity like document, i got an ImportError: asking me to upgrade tensorflow to 1.14.0, but i cannot find version 1.14.0 by pip3 install --upgrade tensorflow==1.14.0.  ", "@smatzek : Thank you for your support to the community. Will it be possible to provide a minimum code snippet that can depict the scenario? This would really help us. Thanks!", "Here is the fit_generator case that does not work, adapted from the test case that was removed:\r\n\r\n```\r\nfrom tensorflow.python.keras import testing_utils\r\nimport numpy as np\r\nfrom tensorflow.python import keras\r\nfrom tensorflow.python.framework import ops\r\n\r\nclass TestCallback(keras.callbacks.Callback):\r\n    def set_model(self, model):\r\n        # Check the model operations for the optimizer operations that\r\n        # the _make_train_function adds under a named scope for the\r\n        # optimizer. This ensures the full model is populated before the\r\n        # set_model callback is called.\r\n        optimizer_name_scope = 'training/' + model.optimizer.__class__.__name__\r\n        graph_def = ops.get_default_graph().as_graph_def()\r\n        for node in graph_def.node:\r\n          if node.name.startswith(optimizer_name_scope):\r\n            return\r\n        raise RuntimeError('The optimizer operations are not present in the '\r\n                           'model graph when the Callback.set_model function '\r\n                           'is called')\r\nnp.random.seed(1337)\r\n\r\ndef generator():\r\n    x = np.random.randn(10, 100).astype(np.float32)\r\n    y = np.random.randn(10, 10).astype(np.float32)\r\n    while True:\r\n        yield x, y\r\n\r\nmodel = testing_utils.get_small_sequential_mlp(\r\n  num_hidden=10, num_classes=10, input_dim=100)\r\nmodel.compile(\r\n  loss='categorical_crossentropy',\r\n  optimizer='sgd',\r\n  metrics=['accuracy'])\r\nmodel.fit_generator(\r\n  generator(),\r\n  steps_per_epoch=2,\r\n  epochs=1,\r\n  validation_data=generator(),\r\n  validation_steps=2,\r\n  callbacks=[TestCallback()],\r\n  verbose=0)\r\n```\r\n\r\nHere is the fit() case that does work:\r\n```\r\nfrom tensorflow.python.keras import testing_utils\r\nimport numpy as np\r\nfrom tensorflow.python import keras\r\nfrom tensorflow.python.framework import ops\r\n\r\nclass TestCallback(keras.callbacks.Callback):\r\n    def set_model(self, model):\r\n        # Check the model operations for the optimizer operations that\r\n        # the _make_train_function adds under a named scope for the\r\n        # optimizer. This ensures the full model is populated before the\r\n        # set_model callback is called.\r\n        optimizer_name_scope = 'training/' + model.optimizer.__class__.__name__\r\n        graph_def = ops.get_default_graph().as_graph_def()\r\n        for node in graph_def.node:\r\n          if node.name.startswith(optimizer_name_scope):\r\n            return\r\n        raise RuntimeError('The optimizer operations are not present in the '\r\n                           'model graph when the Callback.set_model function '\r\n                           'is called')\r\nnp.random.seed(1337)\r\n\r\n\r\nmodel = testing_utils.get_small_sequential_mlp(\r\n  num_hidden=10, num_classes=10, input_dim=100)\r\nmodel.compile(\r\n  loss='categorical_crossentropy',\r\n  optimizer='sgd',\r\n  metrics=['accuracy'])\r\n\r\n(x_train, y_train), (x_test, y_test) = testing_utils.get_test_data(\r\n    train_samples=3,\r\n    test_samples=1,\r\n    input_shape=(100,),\r\n    num_classes=10)\r\ny_test = keras.utils.to_categorical(y_test)\r\ny_train = keras.utils.to_categorical(y_train)\r\n\r\nmodel.fit(x_train, y_train, batch_size=1, epochs=1,\r\n          callbacks=[TestCallback()])\r\n```", "@omalleyt12 Any thoughts here? This change in callback ordering is at the very least confusing, but as @smatzek mentions, this also affects any other callbacks that need full graph visibility.", "@robieta for thoughts as well.\r\nSorry for the thread-bump ya'll, but this negatively affects an extension we have so w'd like to find out if this change was intentional or not.\r\n\r\nThx!", "Trying with the lastest tf-nightly-2.0-preview, this fails even if I change `ops.get_default_graph()` to `keras.backend.get_graph()` and `set_model` to `on_epoch_end`. Could you share an example of why you want to access the optimizer ops? There may be a better workaround that is more future-proof", "The use case that wants to see the optimizer ops is TensorFlow Large Model Support module that was originally proposed via PR to tensorflow.contrib but moved out to a separate repo with the sunset of contrib. The module is here:\r\nhttps://github.com/IBM/tensorflow-large-model-support\r\n\r\nThe Keras callback is here:\r\nhttps://github.com/IBM/tensorflow-large-model-support/blob/master/tensorflow_large_model_support/lms.py#L924\r\n", "I also cannot reproduce your working example on tf-nightly, but I made a small tweak to the string check that captures the spirit:\r\n\r\n```\r\nclass TestCallback(keras.callbacks.Callback):\r\n    def set_model(self, model):\r\n        # Check the model operations for the optimizer operations that\r\n        # the _make_train_function adds under a named scope for the\r\n        # optimizer. This ensures the full model is populated before the\r\n        # set_model callback is called.\r\n        optimizer_op_str = \"gradients/loss\"\r\n        graph_def = ops.get_default_graph().as_graph_def()\r\n        for node in graph_def.node:\r\n          if optimizer_op_str in node.name:\r\n            return\r\n        raise RuntimeError('The optimizer operations are not present in the '\r\n                           'model graph when the Callback.set_model function '\r\n                           'is called')\r\nnp.random.seed(1337)\r\n\r\ndef generator():\r\n    x = np.random.randn(10, 100).astype(np.float32)\r\n    y = np.random.randn(10, 10).astype(np.float32)\r\n    while True:\r\n        yield x, y\r\n\r\n# ====================================\r\n# << See comment on unrelated model >>\r\n# ====================================\r\n\r\nmodel = testing_utils.get_small_sequential_mlp(\r\n  num_hidden=2, num_classes=10, input_dim=100)\r\nmodel.compile(\r\n  loss='categorical_crossentropy',\r\n  optimizer='sgd',\r\n  metrics=['accuracy'])\r\nmodel.fit_generator(\r\n  generator(),\r\n  steps_per_epoch=2,\r\n  epochs=1,\r\n  validation_data=generator(),\r\n  validation_steps=2,\r\n  callbacks=[TestCallback()],\r\n  verbose=0)\r\n```\r\n\r\nHowever you'll note that a seemingly unrelated bit of code causes your callback to succeed. (Though you seem familiar enough with the codebase that I'm sure it won't come as a surprise.)\r\n```\r\nunrelated_input = keras.Input(shape=(100,))\r\nunrelated_model = keras.models.Model(unrelated_input, keras.layers.Dense(10)(unrelated_input))\r\nunrelated_model.compile(loss=\"mse\", optimizer=\"sgd\")\r\nx = np.random.randn(10, 100).astype(np.float32)\r\ny = np.random.randn(10, 10).astype(np.float32)\r\nunrelated_model.fit(x, y, steps_per_epoch=2, epochs=1, verbose=0, callbacks=[TestCallback()])\r\n```\r\n\r\nThis is due to Keras' use of a single global graph. This is an implementation detail rather than an API promise. (The fact that it is the tf default graph is also in that category, and `tf.keras.backend.get_graph` is not a public method.)\r\n\r\nIn general I think having a callback that tries to effectively side channel changes to the implementation is going to be quite brittle and be frequently broken by our own internal refactors. That said, various kinds of keras specific graph rewrites are something that I'm very interested in enabling, and if there is external interest I'm very open to exposing a public API to enable them. It looks like you already have a Grappler plugin, and that's really where I would expect this to live for the time being. Could you give some color on why it specifically needs to be in a callback?", "I agree that the current way we are triggering the graph modifications is brittle. While this module is doing graph modifications to introduce things like GPU-CPU tensor swapping and synchronization to avoid out of memory options, it is not a Grappler plugin. The reason for this is that the code is pure Python and operating at the Python op/graph layer to allow faster development and iterating on different ideas than doing so down in the C/C++ Grappler layer. My understanding of Grappler may be erroneous or outdated but I am not aware of Python plugins for it.\r\n\r\nThe calls to this Python module to do graph modification do not specifically need to be in a callback. In order for the modifications to work it needs a view of the whole graph, including the optimizer ops, and it needs this before the graph is run through a session since graph modifications are not allowed after the graph has been run in a session. The Keras callback, in the `set_model` method has historically provided that correct timing window in both Keras and tf.keras.\r\n\r\nFrom an external \"add-on\" view that was the easiest (or only) way to get called without doing hacky things like overriding or doing runtime patching (monkey patching) of internal methods, which would have been more brittle.\r\n\r\nHaving an API mechanism to provide model/graph visibility on the fully created graph before it goes into a session and becomes locked to modification would be great.", "@smatzek \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28773\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28773\">No</a>\n"]}, {"number": 28772, "title": "Typo in backprop.py", "body": "", "comments": []}, {"number": 28771, "title": "Bump rocprim version", "body": "The current rocprim is out-of-date and introduces linker error at compilation times. Updating to new version of rocprim that fix the linker error.\r\n\r\n@whchung ", "comments": ["errors in test targets are stemmed from XLA CPU logic and has nothing to do with this PR. suggest continue to merge it.", "The XLA CPU issue should be fixed now.\n\nOn Fri, May 17, 2019, 17:13 Wen-Heng (Jack) Chung <notifications@github.com>\nwrote:\n\n> errors in test targets are stemmed from XLA CPU logic and has nothing to\n> do with this PR. suggest continue to merge it.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/28771?email_source=notifications&email_token=ABZM5DVTHARDKWOIK7AV7WTPV3DSTA5CNFSM4HNN4PO2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVVAQCQ#issuecomment-493488138>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABZM5DSH4URUWIVSZHKNX2LPV3DSTANCNFSM4HNN4POQ>\n> .\n>\n"]}, {"number": 28770, "title": "Cherry pick version updates", "body": "Cherry pick for 91b6e29b5006cc644da1e2578d9cffe502fc8551 and 87920ddf80aa0c65a81ff61b3d154523c1212946", "comments": []}, {"number": 28769, "title": "[ROCm] Fix for the broken `--config=rocm` build.", "body": "The --config=rocm build was broken by the following commit.\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/7bc1c3c37ce4e591012f4325ab7a25ae387773c7\r\n\r\nThe changes made by the above commit were incomplete for the ROCm platform, which was leading to the build failure.\r\n\r\nThis PR has two commits (copy-pasting their description here for convenience)\r\n\r\n1.  Making `cc_toolchain_config_file` a template variable. This is needed because the toolchain config file is different for the CUDA and ROCm platforms and hence should not be hardcoded into the `crosstool/BUILD.tpl` file\r\n\r\n2.  Updating the rocm configuration files to get `--config=rocm` build passing again.\r\n The changes to `hipcc_cc_toolchain_config.bzl.tpl` can be reviewed better, if you diff them against `cc_toolchain_config.bzl.tpl` file. That will highlight all the things we need to differently to make ROCm work.\r\n Note that `hipcc_cc_toolchain_config.bzl.tpl` was created using `cc_toolchain_config.bzl.tpl` as the base. The sections in `cc_toolchain_config.bzl.tpl` which deal with support for Mac (darwin) and Windows were left intact, even though ROCm currently does not support those platforms. This was done for two reasons\r\n    * It allows to use `diff` to highlight the ROCm specific differences\r\n    * Ideally we would like to get rid of the `hipcc_cc_toolchain_config.bzl.tpl` file, and have a single `cc_toolchain_config.bzl.tpl` if possible. So we want to keep the two files as similar as possible\r\n\r\n\r\nI ran the \"buildifier\" tool on the `rocm_configure.bzl` file, but it does not seem to wrap lines that are greater 80-cols wide, and hence there are some lines in there that exceed that width :(\r\n\r\nNote that this change looks \"large\" only because I have updated the `hipcc_cc_toolchain_config.bzl.tpl` to contain everything within `cc_toolchain_config.bzl.tpl`. When view as diff against that file, the changes are much smaller!\r\n\r\n----------------------------\r\n\r\n@tatianashp , @whchung, @chsigg  just FYI\r\n\r\nPlease approve and merge. As with other such PRs this week, the changes here are only applicable for the --config=rocm build.\r\n\r\nthanks\r\n\r\n\r\n", "comments": []}, {"number": 28768, "title": "Uncomment execution device option in golang bindings", "body": "Since r1.13 has been out for a while, uncomment device binding option, which allows Go application to bind graph processing to specified GPU device(s)\r\n\r\nFor discussion about this patch (and its C-counterpart), please see #20412 and https://github.com/tensorflow/tensorflow/pull/27891", "comments": []}, {"number": 28767, "title": "tf.keras.callbacks.Tensorboard: write_images does not visualize Conv2D weights", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- TensorFlow version (use command below): v1.12.2-0-gcf74798993 1.12.2\r\n- Python version: 3.6.5\r\n\r\n**Describe the current behavior**\r\nWhen I want to have a look at the weights of Conv2D filters in TensorBoard, only their biases get logged (see attached image). I looked for the corresponding source code and found the following snippet:\r\nhttps://github.com/tensorflow/tensorflow/blob/6612da89516247503f03ef76e974b51a434fb52e/tensorflow/python/keras/callbacks.py#L951-L983\r\nThe problem seems to be that Conv2D weights have a 4d shape [H_kernel, W_kernel, C_in, C_out], which is not intended as convolutional layers case in the above code.\r\n\r\n\r\n**Describe the expected behavior**\r\nI would expect that the convolutional weights are visualized. I know this would be a huge amount of images (C_in * C_out), but I think the current behaviour is confusing.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\ncifar10 = tf.keras.datasets.cifar10\r\n\r\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\nprint(type(x_train))\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.InputLayer(input_shape=(32, 32, 3)),\r\n    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\r\n    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(128, activation='relu'),\r\n    tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\nmodel.summary()\r\n\r\ntensorboard = tf.keras.callbacks.TensorBoard(log_dir=f\"../../../logs\", histogram_freq=1,\r\n                                             write_images=True, write_grads=True)\r\ncsvlogger = tf.keras.callbacks.CSVLogger('train.log')\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5, callbacks=[tensorboard, csvlogger], validation_data=(x_test, y_test))\r\n```\r\n**Other info / logs**\r\n![image](https://user-images.githubusercontent.com/34747372/57854395-6f9a1e00-77e8-11e9-9223-bdd8845ac478.png)\r\n\r\n", "comments": ["@maxstrobel As this issue is relating to tensorboard, please post your query in that repository [link](https://github.com/tensorflow/tensorboard/issues/new)"]}, {"number": 28766, "title": "Statefulness in Text generation using a RNN with eager execution", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/sequences/text_generation\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\n* Two questions regarding the `stateful` defined in the tutorial. \r\n* The input data was originally a long text. It got cut into sequences with length 100, shuffled, and packed into batches of size 64. However, according to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN) for the `statefulness`\r\n> You can set RNN layers to be 'stateful', which means that the states\r\ncomputed for the samples in one batch will be reused as initial states\r\nfor the samples in the next batch. This assumes a one-to-one mapping\r\nbetween samples in different successive batches.\r\n\r\nAfter pre-processing the data as discussed above, there is no such one-to-one mapping is not there, i.e. the samples in different batches are independent instead of related. This is confirmed by running the following code after the code for create training batches, which print out the successive samples with index `0` in the first two batches. \r\n```Python\r\nfor input_example, target_example in  dataset.take(2):\r\n  print ('Input data: ', repr(''.join(idx2char[input_example[0, :].numpy()])))\r\n```\r\noutputs\r\n```Python\r\nInput data:  'n that perished vessel the dowry of his\\nsister. But mark how heavily this befell to the\\npoor gentlew'\r\nInput data:  \"y enrich'd\\nWith politic grave counsel; then the king\\nHad virtuous uncles to protect his grace.\\n\\nFirs\"\r\n```\r\n---\r\n* In addition, if `stateful=True`, it is suggested to set `shuffle=False` in the `model.fit()`, which is also missing in the tutorial. \r\n> specify `shuffle=False` when calling fit().\r\n\r\n* The problems above are really confusing and any discussions are welcome. ", "comments": ["https://www.tensorflow.org/beta/tutorials/text/text_classification_rnn\r\n\r\nThe same thing is true about the same tutorial for TF 2.0 and it is very confusing.", "@ZhiliangWu \r\nIs this still an issue", "No. This is fixed."]}, {"number": 28765, "title": "import issue tensorflow v2 and v1 ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Windows Server 2016 Standard:\r\n- CPU Xeon (R) CPU E5-2698 v4\r\n- AVX2\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.0.0-alpha0 \r\n- Python version: 3.6.8\r\n- Installed using: Tried with: virtualenv, pip and  conda\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\nInstallation works fine but  import tensorlfow does not work\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nimport tensorflow as tf\r\n\r\n**Any other info / logs**\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\testtf\\lib\\site-packages\\tensorflow\\__init__.py\", line 27, in <module>\r\n    from tensorflow._api.v2 import audio\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\testtf\\lib\\site-packages\\tensorflow\\_api\\v2\\audio\\__init__.py\", line 8, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\testtf\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\testtf\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\testtf\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\testtf\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\testtf\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\testtf\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\testtf\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n```\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["@ivanjacobs Did you Download and install the Microsoft Visual C++ 2015 Redistributable Update 3. Also have look https://www.tensorflow.org/install/pip (select windows). Thanks!", "Installed Microsoft Visual C++ 2015 Redistributable Update 3  and did all the steps under  https://www.tensorflow.org/install/pip (select windows). \r\n\r\nreintsalled python,pip,virtualenv nothing helps. The only version that runs is the tensorflow==1.5\r\n\r\n\r\n\r\nLog:\r\n```\r\nC:\\code\\tensorflowtest\\tensorflowtest\\Scripts\\python.exe C:/code/tensorflowtest/test.py\r\nTraceback (most recent call last):\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/code/tensorflowtest/test.py\", line 2, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\__init__.py\", line 27, in <module>\r\n    from tensorflow._api.v2 import audio\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\_api\\v2\\audio\\__init__.py\", line 8, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\code\\tensorflowtest\\tensorflowtest\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\n\r\n\r\n", "The only other reason I can think of is, if you installed the GPU version of TF without having a GPU. Other than that, CPU not having AVX and MSVC redistributable are the only cases I have seen this failure.", "@ivanjacobs  Is this still an issue?", "@gadagashwini \r\nThis is still an issue.\r\n@gunan I am confident that I didn't install gpu version. \r\nthe only version of tf I was able to install is the one compiled by intel\r\nhttps://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide\r\n\r\n", "Your cpu does not support AVX instruction sets.\r\nSee https://ark.intel.com/content/www/us/en/ark/products/91753/intel-xeon-processor-e5-2698-v4-50m-cache-2-20-ghz.html\r\nTF 1.6 and above binaries require AVX instruction sets.\r\nSee https://www.tensorflow.org/install/pip#hardware-requirements", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28765\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28765\">No</a>\n"]}, {"number": 28764, "title": "Update farmhash", "body": "https://github.com/google/farmhash/commit/6193375f121f1e2288f0d9282c4d9be1547e2c0f include fix for farmhash on Windows.", "comments": ["Oops. Can not download archive. Will fix soon.", "Ah, it is served from mirror.tensorflow.org. Could you please update cache on mirror?", "Build error with latest commit of farmhash.\r\n\r\n```\r\ng++ -O3 -DNDEBUG -fPIC  --std=c++11 -fext-numeric-literals -D__LITTLE_ENDIAN__ -I. -IC:/dev/tensorflow/tensorflow/lite/tools/make/../../../../../ -IC:/dev/tensorflow/tensorflow/lite/tools/make/../../../../../../ -IC:/dev/tensorflow/tensorflow/lite/tools/make/downloads/ -IC:/dev/tensorflow/tensorflow/lite/tools/make/downloads/eigen -IC:/dev/tensorflow/tensorflow/lite/tools/make/downloads/absl -IC:/dev/tensorflow/tensorflow/lite/tools/make/downloads/gemmlowp -IC:/dev/tensorflow/tensorflow/lite/tools/make/downloads/neon_2_sse -IC:/dev/tensorflow/tensorflow/lite/tools/make/downloads/farmhash/src -IC:/dev/tensorflow/tensorflow/lite/tools/make/downloads/flatbuffers/include -I -I/usr/local/include \\\r\n\r\n-o C:/dev/tensorflow/tensorflow/lite/tools/make/gen/windows_x86_64/bin/minimal C:/dev/tensorflow/tensorflow/lite/tools/make/gen/windows_x86_64/obj/tensorflow/lite/examples/minimal/minimal.o \\\r\n\r\n C:/dev/tensorflow/tensorflow/lite/tools/make/gen/windows_x86_64/lib/libtensorflow-lite.a  -lstdc++ -lpthread -lm -lz\r\n\r\nC:/dev/tensorflow/tensorflow/lite/tools/make/gen/windows_x86_64/lib/libtensorflow-lite.a(conv.o):conv.cc:(.text$_ZN3ruy11DispatchMulILNS_4PathE3EaaaNS_9BasicSpecIiaEEEEvRKNS_6MatrixIT0_EERKNS4_IT1_EERKT3_PNS_7ContextEPNS4_IT2_EE[_ZN3ruy11DispatchMulILNS_4PathE3EaaaNS_9BasicSpecIiaEEEEvRKNS_6MatrixIT0_EERKNS4_IT1_EERKT3_PNS_7ContextEPNS4_IT2_EE]+0x1d6): undefined reference to `ruy::TrMul(ruy::TrMulParams*, ruy::Context*)'\r\n\r\ncollect2.exe: error: ld returned 1 exit status\r\nmingw32-make: *** [tensorflow\\lite\\tools\\make\\Makefile:266: C:/dev/tensorflow/tensorflow/lite/tools/make/gen/windows_x86_64/bin/minimal] Error 1\r\n```\r\n", "@mattn  Did you get a chance to look on reviewer comments? Please let us know on the update. Thanks!", "What should I do?", "Please update all of the associated dependencies as shown here: https://github.com/tensorflow/tensorflow/search?q=816a4ae622e964763ca0862d9dbd19324a1eaf45&unscoped_q=816a4ae622e964763ca0862d9dbd19324a1eaf45", "Sorry, my delay. Updated dependencies.", "@mattn Could you please address the build failures? Thanks!", "@gbaned it is failing since mirror server does not work.\r\n\r\nhttp://mirror.tensorflow.org/github.com/google/farmhash/archive/0d859a811870d10f53a594927d0d0b97573ad06d.tar.gz", "@mattn Could you please resolve the conflicts? Thanks!", "As I mentioned in above, I need https://github.com/google/farmhash/commit/6193375f121f1e2288f0d9282c4d9be1547e2c0f\r\n\r\nBut mirror repository does not have the archive contains the commit.", "Can one of the admins verify this patch?", "closing this PR as contrib folder will be depricated in 2.0, thank you.\r\nCC @mihaimaruseac"]}, {"number": 28763, "title": "Name of losses.Reduction.SUM_BY_NONZERO_WEIGHTS is misleading", "body": "**Describe the current behavior**\r\n`losses.Reduction.SUM_BY_NONZERO_WEIGHTS` calculates the mean, not the sum. (The behavior is in sync with the [docs](https://www.tensorflow.org/api_docs/python/tf/losses/Reduction).)\r\n**Describe the expected behavior**\r\nI would expect `losses.Reduction.SUM_BY_NONZERO_WEIGHTS` to calculate the sum, not the mean.\r\n", "comments": ["@hannagabor,\r\nAs per [this documentation page](https://www.tensorflow.org/api_docs/python/tf/compat/v1/losses/Reduction), `SUM_BY_NONZERO_WEIGHTS` is deprecated. Currently, [tf.keras.losses.Reduction](https://www.tensorflow.org/api_docs/python/tf/keras/losses/Reduction) has the value `SUM_OVER_BATCH_SIZE`.\r\n\r\nMarking the issue as closed. Please feel free to re-open if necessary. Thanks!"]}, {"number": 28762, "title": "[tensorflow/docs]Translate variables.md from English to Chinese.", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["This would be a great project for an upcoming global TensorFlow Docs Sprint, or for the Chinese translation group. cc: @lamberta ", "Yes! Consider joining the [Chinese docs list](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-zh-cn): docs-zh-cn@tensorflow.org \r\n\r\n@duanw0916 is coordinating some Chinese translation efforts, perhaps he can point you in the right direction?", "@Mr-Nineteen Is there any actionable item like raising PR? \r\n\r\nSince the issue opened, there were lot of improvements in the TF docs of several languages but `variables.md` is not there. \r\n\r\nCan we close this issue here. Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 28761, "title": "Can't set an initial state for the Bidirectional LSTM Layer of tf.keras 2.0 under eager execution mode", "body": "**System information**\r\n- Have I written custom code: No\r\n- OS Platform and Distribution: MacOS 10.14.4 \r\n- TensorFlow installed from: pip install tensorflow==2.0.0-alpha0 \r\n- TensorFlow version: v1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n- Python version: 3.7.3\r\n\r\n**Describe the current behavior**\r\n- Get an Error when setting an initial state for the Bidirectional LSTM Layer of tf.keras 2.0 under eager execution mode\r\n\r\n**Describe the expected behavior**\r\n- The code should work with eager execution mode.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nhidden_units = 64\r\ntime_step = 50\r\nvocab_size = 100\r\nembed_size = 64\r\nbatch_size = 10\r\n\r\nembedding = tf.keras.layers.Embedding( vocab_size, embed_size, input_length=time_step, trainable=False )\r\nlstm =  tf.keras.layers.LSTM(hidden_units, return_sequences=False, return_state=True )\r\nbilstm_1 =  tf.keras.layers.Bidirectional(lstm, name='bilstm1')\r\nbilstm_2 =  tf.keras.layers.Bidirectional(lstm, name='bilstm2')\r\nconcat =  tf.keras.layers.Concatenate()\r\ndense = tf.keras.layers.Dense(vocab_size, activation='softmax')\r\n\r\ndef mod(input_1,input_2):\r\n    \r\n    input_1 = embedding(input_1)\r\n    input_2 = embedding(input_2)\r\n    output_1, forward_h, forward_c, backward_h, backward_c = bilstm_1(input_1)\r\n    output_2, _,_,_,_ = bilstm_2(input_2, initial_state=(forward_h, forward_c, backward_h, backward_c))\r\n    output = dense(concat([output_1,output_2]))\r\n    return output\r\n\r\ninput_1=np.random.randint(0,99,size=[batch_size, time_step])\r\ninput_2=np.random.randint(0,99,size=[batch_size, time_step])\r\ntarget = np.random.randint(2,size=[batch_size])\r\n\r\n#test the model\r\nmod(input_1,input_2)\r\n\r\n```\r\n\r\n**Other info / logs**\r\nThe Error detail\uff1a\r\n`InvalidArgumentError: Incompatible shapes: [2,256] vs. [50,256] [Op:Add] name: bilstm2/add/`", "comments": ["@Liu-Da Able to reproduce the issue with the provided code.", "Thanks for reporting the issue, will send out the fix very soon.", "This should be fixed by 2a8f9b1ccfaaebd6f9cf5b5eb972c2dafded4f5e now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28761\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28761\">No</a>\n", "@qlzh727 Same problem in the `Bidirectional` code leads to a different issue in tf 1.14 (graph mode):\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nlstm = tf.keras.layers.LSTM(units=10)\r\nbidirectional = tf.keras.layers.Bidirectional(lstm)\r\n\r\ninputs = tf.placeholder(tf.float32, [32, 10, 20])\r\nfw_state = [tf.zeros([32, 10]), tf.zeros([32, 10])]\r\nbw_state = [tf.zeros([32, 10]), tf.zeros([32, 10])]\r\ninitial_state = fw_state + bw_state\r\n\r\noutput = bidirectional(\r\n    inputs=inputs, initial_state=initial_state)\r\n``` \r\n\r\n**Other info / logs**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  ...\r\n  File \".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/wrappers.py\", line 592, in __call__\r\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\r\n  File \".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 634, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/wrappers.py\", line 629, in call\r\n    initial_state=forward_state, **kwargs)\r\n  File \".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 2533, in call\r\n    inputs, mask=mask, training=training, initial_state=initial_state)\r\n  File \".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 678, in call\r\n    inputs, initial_state, constants)\r\n  File \".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 787, in _process_inputs\r\n    if len(initial_state) != len(self.states):\r\nTypeError: object of type 'Tensor' has no len()\r\n```\r\n\r\nDo you think this can be solved in tf 1.x, too, at some point?\r\n\r\nThanks!"]}, {"number": 28760, "title": "TF2.0 custom dynamic rnn with autograph and tensorflow datasets fails to run", "body": "When I followed the effective tensorflow2 instructions to try custom dynamic loop optimized with autograph, I encountered the following errors. It seems the sequence length used in dynamic rnn became None. Everything is fine if I disable tf.function and replace DynamicRNN with DynamicRNNV2, which uses eager execution.\r\n```python\r\n# model.py\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\n\r\n\r\nclass Model(tf.keras.Model):\r\n  def __init__(self, vocab_size, emb_size, rnn_size):\r\n    super(Model, self).__init__()\r\n    self.embedding = layers.Embedding(vocab_size, emb_size)\r\n    self.rnn = DynamicRNN(rnn_size)\r\n\r\n  def call(self, x):\r\n    x = self.embedding(x)\r\n    x, _ = self.rnn(x)\r\n    return x\r\n\r\nclass DynamicRNN(layers.Layer):\r\n  def __init__(self, rnn_size):\r\n    super(DynamicRNNV1, self).__init__()\r\n    self.rnn_size = rnn_size\r\n    self.cell = layers.GRU(rnn_size, return_state=True)\r\n\r\n  @tf.function\r\n  def call(self, input_data):\r\n    outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\r\n    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)\r\n    for i in tf.range(input_data.shape[1]):\r\n      print(input_data)\r\n      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)\r\n      outputs = outputs.write(i, output)\r\n    return tf.transpose(outputs.stack(), [1, 0, 2]), state\r\n\r\nclass DynamicRNNV2(layers.Layer):\r\n  def __init__(self, rnn_size):\r\n    super(DynamicRNNV2, self).__init__()\r\n    self.rnn_size = rnn_size\r\n    self.cell = layers.GRU(rnn_size, return_state=True)\r\n\r\n  def call(self, input_data):\r\n    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)\r\n    outputs = []\r\n    for i in range(input_data.shape[1]):\r\n      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)\r\n      outputs.append(tf.expand_dims(output, 1))\r\n    return tf.concat(outputs, axis=1), state\r\n```\r\n\r\n```\r\n2019-05-16 08:15:39.248597: I tensorflow/stream_executor/platform/default/dso_loader.cc:43] Successfully opened dynamic library libcublas.so.10.0\r\nI0516 08:15:39.560903 140231802230528 train.py:55] (256, 120, 16)\r\nTensor(\"input_data:0\", shape=(256, 160, 16), dtype=float32)\r\nI0516 08:15:40.161331 140231802230528 train.py:55] (256, 160, 16)\r\nTensor(\"input_data:0\", shape=(256, None, 16), dtype=float32)\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 59, in <module>\r\n    app.run(main)\r\n  File \"/opt/conda/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/opt/conda/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"train.py\", line 54, in main\r\n    output = model(question)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 678, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/workspace/code/tf_workspace/dataset_test/model.py\", line 36, in call\r\n    x, _ = self.rnn(x)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 678, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 424, in __call__\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1305, in __call__\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1625, in _maybe_define_function\r\n    args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1527, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 713, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 329, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2126, in bound_method_wrapper\r\n    return wrapped_fn(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 705, in wrapper\r\n    ), args, kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 360, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n  File \"/tmp/tmppfaea7ty.py\", line 20, in tf__call\r\n    outputs, state = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (input_data.shape[1],), None), None, loop_body, (outputs, state))\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 264, in converted_call\r\n    return _call_unconverted(f, args, kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 173, in _call_unconverted\r\n    return f(*args)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1305, in range\r\n    limit = ops.convert_to_tensor(limit, dtype=dtype, name=\"limit\")\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1086, in convert_to_tensor\r\n    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1144, in convert_to_tensor_v2\r\n    as_ref=False)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1223, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 305, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 246, in constant\r\n    allow_broadcast=True)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 284, in _constant_impl\r\n    allow_broadcast=allow_broadcast))\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 455, in make_tensor_proto\r\n    raise ValueError(\"None values not supported.\")\r\nValueError: None values not supported.\r\n```\r\n\r\n```python\r\n# train.py\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport os\r\nimport sys\r\n\r\nfrom absl import app\r\nfrom absl import flags\r\nfrom absl import logging\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\nfrom tensorflow.python.ops import control_flow_util\r\n\r\nfrom model import Model\r\n\r\nsys.path.append(os.path.dirname(os.path.dirname(sys.path[0])))\r\n\r\ncontrol_flow_util.ENABLE_CONTROL_FLOW_V2 = True\r\n\r\nFLAGS = flags.FLAGS\r\n\r\nflags.DEFINE_integer(\"batch_size\", 256, \"Batch size.\")\r\n\r\n\r\ndef main(_):\r\n  dataset_train, info = tfds.load(name=\"squad/bytes\",\r\n                                  split=tfds.Split.TRAIN, with_info=True,\r\n                                  data_dir=\"tensorflow_datasets\",\r\n                                  batch_size=FLAGS.batch_size)\r\n\r\n  vocab_size = info.features[\"question\"].encoder.vocab_size\r\n  model = Model(vocab_size=vocab_size, emb_size=16, rnn_size=16)\r\n\r\n  for i in range(1):\r\n    for features in dataset_train:\r\n      question = features[\"question\"]\r\n      output = model(question)\r\n      logging.info(output.shape)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n  app.run(main)\r\n```\r\n", "comments": ["@npuichigo Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "@muddham Related information is listed below.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0 / 7.5\r\n- GPU model and memory: Tesla P100 16G\r\n\r\n**Describe the current behavior**\r\nTensorflow dataset doesn't work well with custom dynamic loop (for-clause) with autograph.\r\n\r\n**Describe the expected behavior**\r\nCustom for loop with eager execution use sequence length as condition. When adding tf.function decorator to it, the sequence length used in dynamic rnn became None after two steps. Everything is fine if I disable tf.function and replace DynamicRNN with DynamicRNNV2, which uses eager execution.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\n# model.py\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\n\r\n\r\nclass Model(tf.keras.Model):\r\n  def __init__(self, vocab_size, emb_size, rnn_size):\r\n    super(Model, self).__init__()\r\n    self.embedding = layers.Embedding(vocab_size, emb_size)\r\n    self.rnn = DynamicRNN(rnn_size)\r\n\r\n  def call(self, x):\r\n    x = self.embedding(x)\r\n    x, _ = self.rnn(x)\r\n    return x\r\n\r\nclass DynamicRNN(layers.Layer):\r\n  def __init__(self, rnn_size):\r\n    super(DynamicRNNV1, self).__init__()\r\n    self.rnn_size = rnn_size\r\n    self.cell = layers.GRU(rnn_size, return_state=True)\r\n\r\n  @tf.function\r\n  def call(self, input_data):\r\n    outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\r\n    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)\r\n    for i in tf.range(input_data.shape[1]):\r\n      print(input_data)\r\n      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)\r\n      outputs = outputs.write(i, output)\r\n    return tf.transpose(outputs.stack(), [1, 0, 2]), state\r\n\r\nclass DynamicRNNV2(layers.Layer):\r\n  def __init__(self, rnn_size):\r\n    super(DynamicRNNV2, self).__init__()\r\n    self.rnn_size = rnn_size\r\n    self.cell = layers.GRU(rnn_size, return_state=True)\r\n\r\n  def call(self, input_data):\r\n    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)\r\n    outputs = []\r\n    for i in range(input_data.shape[1]):\r\n      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)\r\n      outputs.append(tf.expand_dims(output, 1))\r\n    return tf.concat(outputs, axis=1), state\r\n```\r\n```python\r\n# train.py\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport os\r\nimport sys\r\n\r\nfrom absl import app\r\nfrom absl import flags\r\nfrom absl import logging\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\nfrom tensorflow.python.ops import control_flow_util\r\n\r\nfrom model import Model\r\n\r\nsys.path.append(os.path.dirname(os.path.dirname(sys.path[0])))\r\n\r\ncontrol_flow_util.ENABLE_CONTROL_FLOW_V2 = True\r\n\r\nFLAGS = flags.FLAGS\r\n\r\nflags.DEFINE_integer(\"batch_size\", 256, \"Batch size.\")\r\n\r\n\r\ndef main(_):\r\n  dataset_train, info = tfds.load(name=\"squad/bytes\",\r\n                                  split=tfds.Split.TRAIN, with_info=True,\r\n                                  data_dir=\"tensorflow_datasets\",\r\n                                  batch_size=FLAGS.batch_size)\r\n\r\n  vocab_size = info.features[\"question\"].encoder.vocab_size\r\n  model = Model(vocab_size=vocab_size, emb_size=16, rnn_size=16)\r\n\r\n  for i in range(1):\r\n    for features in dataset_train:\r\n      question = features[\"question\"]\r\n      output = model(question)\r\n      logging.info(output.shape)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n  app.run(main)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n2019-05-16 08:15:39.248597: I tensorflow/stream_executor/platform/default/dso_loader.cc:43] Successfully opened dynamic library libcublas.so.10.0\r\nI0516 08:15:39.560903 140231802230528 train.py:55] (256, 120, 16)\r\nTensor(\"input_data:0\", shape=(256, 160, 16), dtype=float32)\r\nI0516 08:15:40.161331 140231802230528 train.py:55] (256, 160, 16)\r\nTensor(\"input_data:0\", shape=(256, None, 16), dtype=float32)\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 59, in <module>\r\n    app.run(main)\r\n  File \"/opt/conda/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/opt/conda/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"train.py\", line 54, in main\r\n    output = model(question)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 678, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/workspace/code/tf_workspace/dataset_test/model.py\", line 36, in call\r\n    x, _ = self.rnn(x)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 678, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 424, in __call__\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1305, in __call__\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1625, in _maybe_define_function\r\n    args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1527, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 713, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 329, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2126, in bound_method_wrapper\r\n    return wrapped_fn(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 705, in wrapper\r\n    ), args, kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 360, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n  File \"/tmp/tmppfaea7ty.py\", line 20, in tf__call\r\n    outputs, state = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (input_data.shape[1],), None), None, loop_body, (outputs, state))\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 264, in converted_call\r\n    return _call_unconverted(f, args, kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 173, in _call_unconverted\r\n    return f(*args)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1305, in range\r\n    limit = ops.convert_to_tensor(limit, dtype=dtype, name=\"limit\")\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1086, in convert_to_tensor\r\n    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1144, in convert_to_tensor_v2\r\n    as_ref=False)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1223, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 305, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 246, in constant\r\n    allow_broadcast=True)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 284, in _constant_impl\r\n    allow_broadcast=allow_broadcast))\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 455, in make_tensor_proto\r\n    raise ValueError(\"None values not supported.\")\r\nValueError: None values not supported.\r\n```", "@npuichigo After I execute the provided code in google colab, I get the below message.\r\nFATAL Flags parsing error: Unknown command line flag 'f'\r\nPass --helpshort or --helpfull to see help on flags.\r\nAn exception has occurred, use %tb to see the full traceback.\r\n\r\nSystemExit: 1", "In order to run in google colab, you need to remove absl app.\r\n\r\n```python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\n# Install TensorFlow\r\n!pip install tensorflow==2.0.0-alpha0\r\n!pip install tensorflow_datasets\r\n\r\nimport os\r\nimport sys\r\n\r\nfrom absl import logging\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\nfrom tensorflow.python.ops import control_flow_util\r\n\r\n\r\ncontrol_flow_util.ENABLE_CONTROL_FLOW_V2 = True\r\n\r\nBATCH_SIZE = 32\r\n\r\n\r\nfrom tensorflow.keras import layers\r\n\r\n\r\nclass Model(tf.keras.Model):\r\n  def __init__(self, vocab_size, emb_size, rnn_size):\r\n    super(Model, self).__init__()\r\n    self.embedding = layers.Embedding(vocab_size, emb_size)\r\n    self.rnn = DynamicRNN(rnn_size)\r\n\r\n  def call(self, x):\r\n    x = self.embedding(x)\r\n    x, _ = self.rnn(x)\r\n    return x\r\n\r\nclass DynamicRNN(layers.Layer):\r\n  def __init__(self, rnn_size):\r\n    super(DynamicRNN, self).__init__()\r\n    self.rnn_size = rnn_size\r\n    self.cell = layers.GRU(rnn_size, return_state=True)\r\n\r\n  @tf.function\r\n  def call(self, input_data):\r\n    outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\r\n    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)\r\n    for i in tf.range(input_data.shape[1]):\r\n      print(input_data)\r\n      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)\r\n      outputs = outputs.write(i, output)\r\n    return tf.transpose(outputs.stack(), [1, 0, 2]), state\r\n\r\n  \r\nclass DynamicRNNV2(layers.Layer):\r\n  def __init__(self, rnn_size):\r\n    super(DynamicRNNV2, self).__init__()\r\n    self.rnn_size = rnn_size\r\n    self.cell = layers.GRU(rnn_size, return_state=True)\r\n\r\n  def call(self, input_data):\r\n    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)\r\n    outputs = []\r\n    for i in range(input_data.shape[1]):\r\n      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)\r\n      outputs.append(tf.expand_dims(output, 1))\r\n    return tf.concat(outputs, axis=1), state\r\n\r\n\r\ndataset_train, info = tfds.load(name=\"squad/bytes\",\r\n                                split=tfds.Split.TRAIN, with_info=True,\r\n                                data_dir=\"tensorflow_datasets\",\r\n                                batch_size=BATCH_SIZE)\r\n\r\nvocab_size = info.features[\"question\"].encoder.vocab_size\r\nmodel = Model(vocab_size=vocab_size, emb_size=16, rnn_size=16)\r\n\r\nfor i in range(1):\r\n  for features in dataset_train:\r\n    question = features[\"question\"]\r\n    output = model(question)\r\n    logging.info(output.shape)\r\n```", "@muddham ", "@npuichigo Able to reproduce the issue in 2.0.0-alpha0, tf nightly.", "I wasn't able to reproduce this issue with tf-nightly-2.0-preview, which means this issue was somehow fixed between alpha release and nightly. @npuichigo, could u try on nightly version?", "Also, by looking at your code, I think the dynamic RNN doesn't make much sense from RNN model building perspective.\r\n\r\nThe cell field you used, which is a keras.layer.GRU, is actually a whole GRU layer, not just a cell. It will take care of looping through all the timesteps, and you don't have to manage the looping by the for loop. Since the GRU/LSTM can handle dynamic timestep size, you actually can just feed the input tensor to it, which might have a dynamic timestep size.\r\n\r\nSo your implementation of DynamicRNN is just a builtin GRU layer.\r\n\r\nIf you want to build your owner GRU layer with some custom behavior, instead of using keras.layers.GRU as a cell, you should use keras.layers.GRUCell, which will take a 2D input (one step at a time).", "@qlzh727 Thank you for your advice! I found the bug when I tried to implement a seq2seq decoder using custom dynamic rnn with autograph, so the code above is just to illustrate the problem. I used tf-nightly-2.0-preview and the bug seems to have been fixed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28760\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28760\">No</a>\n", "demo for  custom dynamic rnn with autograph ."]}, {"number": 28759, "title": "Tf.dataset shuffle buffer cannot release", "body": "**System information**\r\n- TensorFlow version (you are using): 2.0 alpha gpu\r\n\r\n**Describe the feature and the current behavior/state.**\r\n- When using shuffle op of tf.dataset, the buffer cannot release when the dataset instance is deleted. \r\nFor example, i train my model with 2 datasets in sequence.\r\ndataset1.shuffle(buffer_size = 1000)\r\nmodel.fit(dataset1)   memory consumption: 50%\r\ndel dataset1\r\ndataset2.shuffle(buffer_size = 1000) memory consumption: 80%\r\nmodel.fit(dataset2)\r\n\r\nThis is not a matter when shuffle filenames, but serious for img dataset comes form a tfrecord file.\r\nFor instance in my case, 1000 imgs(600 X 600 X 3, FP32) in the buffer consumed 30% resource of machine which is really a big matter for automatic train process\r\n\r\n\r\n\r\n", "comments": ["@ziyigogogo In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "I'm able to reproduce whilst running the transformer example verbatim: https://www.tensorflow.org/alpha/tutorials/text/transformer\r\nNightly is frying my laptop  so maybe I just can't tell. (because addons needs to be compiled from source)\r\n\r\nEach dataset shufflebuffer (per epoch) adds 800mb that is never garbage collected and emits a warning: \r\n\r\n2019-05-27 09:46:32.476634: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2019-05-27 09:46:32.598754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-05-27 09:46:32.599730: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x264dee0 executing computations on platform CUDA. Devices:\r\n2019-05-27 09:46:32.599747: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): GeForce GTX 1060, Compute Capability 6.1\r\n2019-05-27 09:46:32.619199: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\r\n2019-05-27 09:46:32.619762: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x265ef30 executing computations on platform Host. Devices:\r\n2019-05-27 09:46:32.619780: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-05-27 09:46:32.619946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties: \r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 2.95GiB freeMemory: 2.51GiB\r\n2019-05-27 09:46:32.619961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0\r\n2019-05-27 09:46:32.620005: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-05-27 09:46:32.620882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-05-27 09:46:32.620896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 \r\n2019-05-27 09:46:32.620903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N \r\n2019-05-27 09:46:32.621000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2267 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n(1, 50, 512)\r\n2019-05-27 09:48:53.636165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\nLatest checkpoint restored!!\r\n2019-05-27 09:48:54.436479: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.\r\n2019-05-27 09:49:04.435295: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:103] Filling up shuffle buffer (this may take a while): 17171 of 150000\r\n2019-05-27 09:49:14.435516: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:103] Filling up shuffle buffer (this may take a while): 34489 of 150000"]}, {"number": 28758, "title": "added `ResizeBilinearKernel_faster`", "body": "`ResizeBilinearKernel_faster` is 30 ~ 50% faster than `ResizeBilinearKernel`. It eliminates redundant computation by only spawning at most 8 threads to iterate through the channel dimension and having each thread iterate through the batch dimension.\r\n\r\nprerequisite is:\r\n1. channels must be a multiple of 4\r\n2. `sizeof(T) == sizeof(float)`\r\n\r\nWhen the prerequisite is not met, `ResizeBilinearKernel` is used.", "comments": ["@chsigg\r\nPR of optimized bilinear kernel code we have been discussing.\r\n\r\nHere are some results comparing `ResizeBilinearKernel_faster` (my_kernel) to ResizeBilinearKernel` (tf_kernel):\r\n\r\nbatch = 2\r\nchannel = 128\r\ninput_height = 256\r\ninput_width = 256\r\nheight_scale = 0.25\r\nwidth_scale = 0.25\r\n\r\ntf_kernel_time = 7268ms\r\nmy_kernel_time = 5705ms\r\n\r\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\r\n\r\nbatch = 2\r\nchannel = 128\r\ninput_height = 128\r\ninput_width = 128\r\nheight_scale = 0.125\r\nwidth_scale = 0.125\r\n\r\ntf_kernel_time = 14090ms\r\nmy_kernel_time = 9561ms\r\n\r\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\r\n\r\nbatch = 2\r\nchannel = 128\r\ninput_height = 64\r\ninput_width = 64\r\nheight_scale = 0.0625\r\nwidth_scale = 0.0625\r\n\r\ntf_kernel_time = 14450ms\r\nmy_kernel_time = 9851ms\r\n\r\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\r\n\r\nbatch = 1\r\nchannel = 64\r\ninput_height = 512\r\ninput_width = 512\r\nheight_scale = 0.5\r\nwidth_scale = 0.5\r\n\r\ntf_kernel_time = 3705ms\r\nmy_kernel_time = 2944ms\r\n\r\n---------------------\r\n\r\nbatch = 10\r\nchannel = 64\r\ninput_height = 256\r\ninput_width = 256\r\nheight_scale = 0.5\r\nwidth_scale = 0.5\r\n\r\ntf_kernel_time =\u00a09377ms\r\nmy_kernel_time =\u00a06963ms\r\n\r\n---------------------\r\nbatch = 25\r\nchannel = 64\r\ninput_height = 256\r\ninput_width = 256\r\nheight_scale = 0.5\r\nwidth_scale = 0.5\r\n\r\ntf_kernel_time = 26112ms\r\nmy_kernel_time = 17152ms\r\n\r\n---------------------\r\n\r\nbatch = 100\r\nchannel = 64\r\ninput_height = 128\r\ninput_width = 128\r\nheight_scale = 0.5\r\nwidth_scale = 0.5\r\n\r\ntf_kernel_time = 27441ms\r\nmy_kernel_time = 15623ms\r\n\r\n---------------------\r\n\r\nbatch = 800\r\nchannel = 32\r\ninput_height = 32\r\ninput_width = 32\r\nheight_scale = 0.5\r\nwidth_scale = 0.5\r\n\r\ntf_kernel_time = 5896ms\r\nmy_kernel_time = 4694ms\r\n", "@ThisIsIsaac could you please resolve the conflicts? Thanks!", "@gbaned\r\nthanks for the notification. Done!", "@chsigg \r\nSorry for the delay. I am going to make one more pull request on another kernel optimization and get to this asap. Will be able to adjust for all the feedback by this Friday.\r\n\r\nThanks ", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28758) for more info**.\n\n<!-- need_author_cla -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28758) for more info**.\n\n<!-- cla_yes -->", "@chsigg \r\nAfter changing to `float4`, the performance boost is as follows:\r\n\r\n* GTX 1080: ~300%\r\n* V100: ~460%\r\n\r\nI am having a difficult time building tensorflow code from source which is delaying the updates you have suggested. ( I am able to test the CUDA kernels separately because I do not need Tensorflow to test and develop, but the code that launches the CUDA kernels from Tensorflow requires building Tensorflow in order to test. ) will commit new code as soon as i am able to build Tenosrflow form source.", "Sorry for the terribly long delay. I will work on doing a final review and getting it merged. For this I will have to mark this PR as 'ready to pull' (internal tools requirement).", "@chsigg  \r\nNo problem. Thanks for getting back :)\r\n\r\nJust wanted to clarify that I have not fully implemented some crucial components ( the kernel itself is ready, but calling the kernel from the host code needs some modifications and testing ).", "I patched your PR and started making some minor changes. I also noticed that we weren't testing the GPU path, so first I need to fix that.", "Thanks. Make sure to replace \u2018four_floats\u2019 to \u2018float4\u2019", "I've merged your code with some changes but somehow GitHub does not mark it merged. Could you please take a look to make sure I didn't make any mistakes and close this PR if you are happy?\r\n\r\nThanks a lot for you contribution!", "@chsigg \r\nThanks so much for your help. I see that you haven't renamed the kernel to `ResizeBilinearKernelUnrolled`. It is perfectly fine for me either ways.\r\n\r\nThe code looks fine but I will run a few of my own tests before I confirm. I'll **get back to you early next week**.\r\n\r\nThanks again for this great opportunity to contribute! Really look forward to further contributions."]}, {"number": 28757, "title": "voice activity detection implementation", "body": "I found that voice activity detection is implemented in the paper \"Small-Footprint Keyword Spotting Using Deep Neural Networks\". But I did not find anything related to voice activity detection in the paper \"Convolutional Neural Networks for Small-footprint Keyword Spotting\".\r\nMy question is that is voice activity detection implemented in this code or not?\r\n", "comments": ["@delowarcse Please provide the link for the paper mentioned here. Is this related to tensorflow.org website?", "The paper title is \"Convolutional Neural Networks for Small-footprint Keyword Spotting\" and link is https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43969.pdf. This paper is implemented in Speech Commands Example and Link is https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/speech_commands. \r\n\r\nMy question is that is voice activity detection implemented in this code or not?", "@delowarcse Were you able to detect voice activity using tensorflow lite?", "Yes, it has been implemented in this code. The instructions are [here](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md).\r\n\r\nYou can also use this with TFLite micro. ([example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech), [training](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech/train))\r\n\r\nThe only issue is that it uses TensorFlow 1 (and not the latest TensorFlow 2 version), otherwise the code should work as per the instructions provided."]}, {"number": 28756, "title": "build: install TensorRT directly in dockerfiles", "body": "@angersson I see TRT available in [https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1804/x86_64/](https://developer.download.nvidia.cn/compute/machine-learning/repos/ubuntu1804/x86_64/) so there is no need to install a local repo.\r\n\r\nUnfortunately, the case is not true for ppc64le. Ping @tjakob to double-check.", "comments": ["It is my understanding that NVIDIA has no current plans to upload TensorRT packages for ppc64le.\r\nSo the ppc64le check will need to stay.", "> It is my understanding that NVIDIA has no current plans to upload TensorRT packages for ppc64le.\r\n> So the ppc64le check will need to stay.\r\n\r\n@tjakob TRT5.1 GA has ppc64 packages: https://developer.nvidia.com/tensorrt-5136ubuntu-18042ppc64le-gnucuda-101cudnn75.tar.gz", "Ping @aaroey; I see 220e8e059a2514567b33cc2614fea0935bd3f631 and I presume this PR is obsolete.\r\n\r\n", "@pooyadavoodi They only have .tar.gz packages for ppc64le (no rpms or debs). So additional work would need to be done for TensorRT and ppc64le (pulling that tar file, and extracting it to the correct location).", "@byronyi that commit was rolled back and I'll redo that later.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 28755, "title": "[Intel Mkl] This PR upgrades the libpng and sqlite dependencies.", "body": "", "comments": ["These were upgraded earlier today"]}, {"number": 28754, "title": "Generate box proposals op", "body": "This PR adds GenerateBoxProposals op for accelerating FPN based networks such as MaskRCNN. It requires #28745 to be merged.", "comments": ["Pinging @tfboyd @tatianashp. This is the third part of ops to accelerate FPN based networks.", "Hi @alextp and @pengchongjin, would you help to review the API part of this PR? Thanks", "@alextp thanks for the review. I will make the necessary changes. But this PR depends on #28745  and can not be merged before it is merged. @aaroey should I delay changes until first PR is merged?", "@samikama I think the interface of NonMaxSuppressionV2 is fixed, then why does this PR depend on #28745? ", "@pengchongjin, would you help to provide review for the interface from the perspective of object detection?\r\n\r\nThanks.", "@smit-hinsu, would you please help to look at the implementation after API review is done? Thanks.", "@wujingyue just in case you're interested in this op.", "Sorry for not responding. Vacation and a few other things got in the way. I will get back to this as soon as possible.", "`correct_transform_coords` is not necessarily correct. The transform logic in this inference op is correct only when it is the inverse of the transform logic during training. \r\nThe history of the \"correct_transform_coords\", I believe, comes from a [bug in the py-faster-rcnn project](https://github.com/rbgirshick/py-faster-rcnn/blob/781a917b378dbfdedb45b6a56189a31982da1b43/lib/fast_rcnn/bbox_transform.py#L30-L61) (and also many derived projects from it), where the box encoding and decoding are not the exact inverse of each other.\r\nIn other words, `correct_transform_coords=True` is correct only when the encoding during training uses the same implementation in [py-faster-rcnn](https://github.com/rbgirshick/py-faster-rcnn/blob/781a917b378dbfdedb45b6a56189a31982da1b43/lib/fast_rcnn/bbox_transform.py#L10-L24), but different implementations do exist. For example, in Facebook we're [dropping](https://github.com/pytorch/pytorch/blob/master/caffe2/operators/generate_proposals_op_util_boxes.h#L43-L81) the old implementation in py-faster-rcnn/Detectron with the `legacy_plus_one` option.\r\n\r\nAlso I don't know why `correct_transform_coords=False` could be useful in any situation except to match results of legacy buggy implementation. I couldn't understand why an op added to TensorFlow should take care of certain buggy 3rd-party implementation of papers.", "@samikama I feel the same way, if `correct_transform_coords` is added only for a legacy but buggy usage I don't think we should add that. ", "Can one of the admins verify this patch?", "@ppwwyyxx and @aaroey Unfortunately, probably due to rush to publication and recognition, authors are publishing buggy code and that code is becoming a reference in the community which sometimes results in new code to be compared against. I believe that buggy code @ppwwyyxx referencing is still quite prevalent in the community and still used same way. I added that flag to be able to satisfy requirements of users still keeping that offset. I will shortly remove it.\r\n@ppwwyyxx is there an errata or public page that shows that offset was a bug that never should have been there in the first place so that if users complain about op behaving differently then we can point them to and ask fixing their models?\r\n", "The original repo (py-faster-rcnn) is unmaintained. There is only one report I found about this bug  https://github.com/rbgirshick/py-faster-rcnn/issues/852.\r\n\r\nIt was acknowledged as a bug in https://github.com/facebookresearch/Detectron/issues/298#issuecomment-373942633 (3).\r\n\r\nI'm not aware of other resources that mention this problem. But we plan to explain and fix these historical issues together with the next version of Detectron to be released later this year.", "@ppwwyyxx So this bug is not widely known and not really easy to find out. That is in line with my understanding of the situation. @aaroey @alextp are you sure you want to remove compatibility flag, considering that most networks inspired by detectron will likely to have the bug still and will not be able to use this op without changing their networks? ", "@tatianashp as discussed in meeting last week, I removed the support for the legacy implementation. If it turned out to be a problem, last commit can be reverted and other changes can be reapplied.\r\n@pengchongjin I added relevant comments to the api_def files since I have been asked to move the documentation to that files above. Inputs scores can be unsorted, op will sort them internally, output will be sorted by scores in descending order.\r\nTo be merged after #30893", "@pengchongjin @alextp @aaroey As requested, I removed the legacy mode option. I still believe it is a bad choice since the **bug** is not documented, not fixed, not known by anybody other than a handful of people and still being used in models. I believe removing it will lead to confusion and head scratching. \r\nDo you have any other concerns?\r\n", "@aaroey, Just pushed the fixes for api files. Thanks", "@aaroey @rthadur please merge this after #30893 since it contains fixes that are used by this op as well.", "@pkulzc  can we pull this in ?", "@rthadur please wait until I make another commit since during the review process, there were some api changes in consumers and at current state it would require unnecessary operations to wire it up.  I will reformat the data layouts to match users.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Hi, Yes this is still being worked on. Waiting for some internal updates.", "@aaroey  @pkulzc This should be good to go now.", "Can this op live in tf-addons?", "Hi, @alextp I don't intend to move this to tf-addons, especially not after more than 6 months of going back on forth in this PR."]}, {"number": 28753, "title": "Tflite metal gpu ios model reload", "body": "My target is ios device ,Target backend is metal gpu , Durining our test ,I found that 'memory leak'  occured when switch different models  about 100 times ,so  how to release last neural models ?like below:\r\ninterpreter=nullptr\r\nDeleteGpuDelegate(delegate)\r\nis it right ?", "comments": ["@zuoshaobo It looks, This question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide greater support. If you think it is a bug. Please let us know. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28752, "title": "\"ValueError: Unknown layer: name\" when creating deep copy of model", "body": "I created a custom layer, which looks as follows:\r\n\r\n```\r\nclass NoisyLayer(keras.layers.Layer):\r\n\r\n    def __init__(self, in_shape=(1,2592), out_units=256, activation=tf.identity): \r\n        super(NoisyLayer, self).__init__()\r\n        self.in_shape = in_shape\r\n        self.out_units = out_units\r\n        self.mu_interval = 1.0/np.sqrt(float(self.out_units))\r\n        self.sig_0 = 0.5\r\n        self.activation = activation\r\n        self.assign_resampling()\r\n\r\n    def build(self, input_shape):\r\n        # Initializer\r\n        self.mu_initializer = tf.initializers.random_uniform(minval=-self.mu_interval, maxval=self.mu_interval)\r\n        self.si_initializer = tf.initializers.constant(self.sig_0/np.sqrt(float(self.out_units)))\r\n\r\n        # Weights\r\n        self.w_mu = tf.Variable(initial_value=self.mu_initializer(shape=(self.in_shape[-1], self.out_units), dtype='float32'), trainable=True)\r\n        self.w_si = tf.Variable(initial_value=self.si_initializer(shape=(self.in_shape[-1], self.out_units), dtype='float32'), trainable=True)\r\n\r\n        # Biases\r\n        self.b_mu = tf.Variable(initial_value=self.mu_initializer(shape=(self.in_shape[0], self.out_units), dtype='float32'), trainable=True)\r\n        self.b_si = tf.Variable(initial_value=self.si_initializer(shape=(self.in_shape[0], self.out_units), dtype='float32'), trainable=True)\r\n\r\n        super(NoisyLayer, self).build(input_shape)\r\n\r\n    def call(self, inputs, resample_noise_flag):\r\n        if resample_noise_flag:\r\n            self.assign_resampling()\r\n\r\n        # Putting it all together\r\n        self.w = tf.math.add(self.w_mu, tf.math.multiply(self.w_si, self.w_eps))\r\n        self.b = tf.math.add(self.b_mu, tf.math.multiply(self.b_si, self.q_eps))\r\n\r\n        return self.activation(tf.linalg.matmul(inputs, self.w) + self.b)\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return (input_shape[0], self.out_units)\r\n\r\n.......\r\n```\r\n\r\nThe layer itself seems to work. However, the error arises when working with the following model, which makes use of the layer :\r\n\r\n```\r\nclass Network:\r\n    def __init__(self, actionspace_size, learning_rate, gradient_momentum, gradient_min):\r\n        frames_input = keras.layers.Input((84, 84, 4))\r\n        actions_input = keras.layers.Input((actionspace_size,))\r\n\r\n        conv1 = keras.layers.Conv2D(16, (8, 8), strides=(4, 4), activation=\"relu\")(frames_input)\r\n        conv2 = keras.layers.Conv2D(32, (4, 4), strides=(2, 2), activation=\"relu\")(conv1)\r\n\r\n        flattened = keras.layers.Flatten()(conv2)\r\n\r\n        # NoisyNet        \r\n        hidden = NoisyLayer(activation=tf.nn.relu)(inputs=flattened, resample_noise_flag=True)\r\n        output = NoisyLayer(in_shape=(1,256), out_units=actionspace_size)(inputs=hidden, resample_noise_flag=True)\r\n        \r\n        filtered_output = keras.layers.merge.Multiply()([output, actions_input])\r\n\r\n        self.model = keras.models.Model(inputs=[frames_input, actions_input], outputs=filtered_output)\r\n\r\n        self.model.compile(loss='mse', optimizer=keras.optimizers.RMSprop(lr=learning_rate, rho=gradient_momentum, epsilon=gradient_min))\r\n```\r\n\r\nParticularly, the error occurs when I try to make a deepcopy of the network, which looks as follows:\r\n\r\n```\r\nimport copy\r\nq_net = Network(actionspace_size, learning_rate, gradient_momentum, gradient_min).model\r\ntarget_net = copy.deepcopy(q_net)\r\n```\r\n\r\nThe error raised looks as follows:\r\n\r\n```\r\n2019-05-16 00:35:37.698461: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nTraceback (most recent call last):\r\n  File \"DQN_tf_NoisyNet.py\", line 318, in <module>\r\n    main()\r\n  File \"DQN_tf_NoisyNet.py\", line 255, in main\r\n    target_net = copy.deepcopy(q_net)\r\n  File \"/usr/lib/python3.5/copy.py\", line 182, in deepcopy\r\n    y = _reconstruct(x, rv, 1, memo)\r\n  File \"/usr/lib/python3.5/copy.py\", line 299, in _reconstruct\r\n    y.__setstate__(state)\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\", line 1266, in __setstate__\r\n    model = saving.unpickle_model(state)\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\", line 435, in unpickle_model\r\n    return _deserialize_model(f)\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\", line 225, in _deserialize_model\r\n    model = model_from_config(model_config, custom_objects=custom_objects)\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\", line 458, in model_from_config\r\n    return deserialize(config, custom_objects=custom_objects)\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/__init__.py\", line 55, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\", line 145, in deserialize_keras_object\r\n    list(custom_objects.items())))\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\", line 1022, in from_config\r\n    process_layer(layer_data)\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\", line 1008, in process_layer\r\n    custom_objects=custom_objects)\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/__init__.py\", line 55, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\", line 138, in deserialize_keras_object\r\n    ': ' + class_name)\r\nValueError: Unknown layer: NoisyLayer\r\n```\r\n\r\nApparently, Tensorflow seems to be incapable of making a deepcopy of the custom layer, since, as soon as I replace the two instances of the custom layer by dense layers, the code works again. \r\n\r\nSo, I was  wondering whether there is some way to tell Tensorflow how to interpret the custom layer when executing the deepcopy command.\r\n\r\nI am using Tensorflow 1.12.0 in Python3.5.2 on Ubuntu 16.04. Thanks in advance!", "comments": ["Is there maybe an alternative how I can circumvent making a copy of the entire network, just copying single weights and biases between equivalent network architectures, instead?", "Found a solution:\r\n[Copying model including custom layer](https://stackoverflow.com/questions/56104823/valueerror-unknown-layer-when-calling-copy-deepcopynetwork-using-tens)"]}, {"number": 28751, "title": "Error then try to feed sparse data to tensorflow dataset api", "body": "Tensorflow 1.13.1\r\n\r\nI have a sparse numpy array and trying to feed it to dataset api and dynamically pad in every batch.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nX = np.array([np.ones((np.random.randint(5, 10), 1)) for i in range(10)])\r\ny = np.ones(10).reshape(-1, 1)\r\n\r\n\r\ndata = tf.data.Dataset.from_tensor_slices((X, y))\r\ndata = data.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=2))\r\ndata = data.padded_batch(10, padded_shapes=([None, 1], []))\r\niterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes)\r\nbatch = iterator.get_next()\r\ninit_op = iterator.make_initializer(data)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init_op)\r\n    batch_out = sess.run(batch)\r\n    print(batch_out)\r\n```\r\n\r\nBut get error\r\n```\r\nExpected binary or unicode string, got array([[1.],\r\n       [1.],\r\n       [1.],\r\n       [1.],\r\n       [1.],\r\n       [1.],\r\n       [1.]])\r\n```", "comments": ["@hadaev8 Able to reproduce the issue with provided code.\r\n\r\nTypeError: Expected binary or unicode string, got array([[1.],\r\n       [1.],\r\n       [1.],\r\n       [1.],\r\n       [1.],\r\n       [1.]])", "The problem is that the `X` value you are trying to pass into `from_tensor_slices` is not convertible to a tensor (which is what the implementation of `from_tensor_slices` will attempt to do):\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf.enable_v2_behavior\r\n\r\nX = np.array([np.ones((np.random.randint(5, 10), 1)) for i in range(10)])\r\n\r\nprint(tf.convert_to_tensor(X))\r\n```\r\n\r\nproduces the same error.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28751\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28751\">No</a>\n"]}]