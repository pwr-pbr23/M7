[{"number": 17607, "title": "Fix inconsistency of eq for TensorShape", "body": "\r\nThis fix tries to address the inconsistency of eq for TensorShape.\r\n\r\nFor TensorShape, the dimension of Dimension(None) should be considered not equal to Dimension(None). However, if the same Dimension(None) is reused, the behavior changes. For example,\r\n```\r\n$ python\r\nPython 2.7.12 (default, Dec  4 2017, 14:50:18)\r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.TensorShape([None]) == tf.TensorShape([None])\r\nFalse\r\n>>> tf.TensorShape([tf.Dimension(None)]) == tf.TensorShape([tf.Dimension(None)])\r\nFalse\r\n>>> dim = tf.Dimension(None)\r\n>>> tf.TensorShape([dim]) == tf.TensorShape([dim])\r\nTrue\r\n>>>\r\n```\r\n\r\nThe issue was that when dims is passed to the constructor of TensorShape through `as_dimension`, the dimension is directly assigned. This fix changes the implementaion of `as_dimension` so that a copy is always performs. In this way, Dimensions in TensorShape will always have the differnet id so an `__eq__` op will always be performed.\r\n\r\nThis fix fixes #17593.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["I don't have ownership or understanding of this code, so I requested a review instead from @shoyer (whom GitHub suggested).", "I'm not sure why GitHub suggested me for this -- maybe because I reviewed some other Dimension code recently in https://github.com/tensorflow/tensorflow/pull/17545.\r\n\r\nBut I'm also not confident to review this. I did not write or review any of the other Dimension/TensorShape related code.\r\n\r\nIt seems plausible to me that maintaining dimension identity is a feature, not a bug. That way two tensors derived from the same original tensor will reuse the same logical dimension.", "@mrry this is the original PR -- you suggested to test for `assertIs(None, v1 == v2)`, but that's not what this does, can you explain here?", "Sure. The original design was for `TensorShape` equality and inequality to be tri-valued, a bit like SQL `NULL`:\r\n\r\n* Returning `True` means that the shapes are identical. (To me, that means that the current behavior is *not* a bug, because `t.shape == t.shape` should be `True`.)\r\n* Returning `False` means that the shapes are definitely not the same.\r\n* Returning `None` means that we don't know, because we're comparing two unknown dimensions that might or might not have the same value at runtime.", "Thanks @mrry. For comparison of `Dimension`s, I could see the `None` case still hold:\r\n```\r\n    # Works before and after the PR:\r\n    dim = tensor_shape.Dimension(None)\r\n\r\n    self.assertIs(None, dim == dim)\r\n    self.assertIs(None, dim == tensor_shape.Dimension(None))\r\n    self.assertIs(None, tensor_shape.Dimension(None) == tensor_shape.Dimension(None))\r\n\r\n    self.assertIs(None, dim == tensor_shape.as_dimension(dim))\r\n    self.assertIs(None, dim == tensor_shape.as_dimension(tensor_shape.Dimension(None)))\r\n    self.assertIs(None, tensor_shape.Dimension(None) == tensor_shape.as_dimension(tensor_shape.Dimension(None)))\r\n\r\n    self.assertIs(None, dim == tensor_shape.as_dimension(dim))\r\n    self.assertIs(None, dim == tensor_shape.as_dimension(tensor_shape.Dimension(None)))\r\n    self.assertIs(None, tensor_shape.Dimension(None) == tensor_shape.as_dimension(tensor_shape.Dimension(None)))\r\n\r\n    self.assertIs(None, tensor_shape.as_dimension(dim) == tensor_shape.as_dimension(dim))\r\n    self.assertIs(None, tensor_shape.as_dimension(dim) == tensor_shape.as_dimension(tensor_shape.Dimension(None)))\r\n    self.assertIs(None, tensor_shape.as_dimension(tensor_shape.Dimension(None)) == tensor_shape.as_dimension(tensor_shape.Dimension(None)))\r\n```\r\n\r\nBut for comparison with `TensorShape`s, because the comparison is either compare against `None`, or a list of `Dimension`s (`[dims..]`), the comparison of `__eq__` will not return `None` (only `True` or `False`):\r\nhttps://github.com/tensorflow/tensorflow/blob/004194ff4c7ee089312fced794fa870ce352f0df/tensorflow/python/framework/tensor_shape.py#L917-L923\r\n\r\nI tested with the following cases and they fail both before and after this PR:\r\n```\r\n    # Fail before and after the PR\r\n    dim = tensor_shape.Dimension(None)\r\n\r\n    v1 = tensor_shape.TensorShape([None])\r\n    v2 = tensor_shape.TensorShape([None])\r\n    self.assertIs(None, v1 == v2)\r\n\r\n    v3 = tensor_shape.TensorShape([dim])\r\n    v4 = tensor_shape.TensorShape([tensor_shape.Dimension(None)])\r\n    self.assertIs(None, v3 == v4)\r\n\r\n    v5 = tensor_shape.TensorShape([dim])\r\n    v6 = tensor_shape.TensorShape([dim])\r\n    self.assertIs(None, v5 == v6)\r\n```\r\n\r\nShould the `__eq__` of `TensorShape` be changed to reflect the described tri-valued?", "Nagging Reviewer @mrry: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @mrry: It has been 33 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @mrry: It has been 48 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @mrry: It has been 63 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "@mrry did you merge this?", "Nagging Reviewer @mrry: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @mrry: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 29 days with no activity and the `awaiting review` label has been applied.", "@mrry what's the status of this? ", "I still consider this change to be a regression in existing behavior, and the case described in #17593 to be working as intended.", "@mrry Let me close the PR. Thanks for the help during the process and sorry for the inconvenience that may have caused."]}, {"number": 17606, "title": "Include links to new announce@ list", "body": "We have set up an announce@ list which only carries important announcements, such as new releases and security notifications. This PR links these from the README and community documentation: we want to encourage as many users as possible to join the list.", "comments": []}, {"number": 17605, "title": "MKL DNN: fix the TF1.6 speed issue by fixing MKL DNN LRN taking the optimum path", "body": "There is a performance regression for TF 1.6 comparing to TF 1.5 for cifar 10. The root cause it cifar 10 uses depth radius = 4, for which MKL DNN takes unoptimized path. Thus we fix this issue by using following strategy:\r\n If the depth_radius of LRN is not 2, then MKL DNN takes unoptimized path. The unoptimized path is slow. Thus we dont rewrite the node  and use default Eigen. But for depth_radius=2, MKL DNN optimized \r\npath is taken, i.e., eigen LRN node is rewritten by MKl DNN LRN node.", "comments": ["Thank you for the fix!. The speed issue is the one described in #17383, correct?", "@tatianashp Yes"]}, {"number": 17604, "title": "Fix broken graphviz download link and change to https", "body": "The graphviz download link has been changed to\r\nhttps://www.graphviz.org/download/\r\n\r\nThis fix fixes the broken link in jit.md.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 17603, "title": "Branch 188540944", "body": "", "comments": ["I disabled a flaky test"]}, {"number": 17602, "title": "Update fold_old_batch_norms.cc to accommodate 'NCHW' format.", "body": "Fixes the problem of using fused batch normalization and this transform, only shows up when using 'NCHW' as the default is 'NHWC'.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@mingxingtan Added the check as requested.", "@mingxingtan can you take another look?"]}, {"number": 17601, "title": "Update bazel toolchains dependency.", "body": "PiperOrigin-RevId: 186650360", "comments": ["Let's merge this with the other PR as they collectively fix many issues.", "I mean, let's create one PR that contains both."]}, {"number": 17600, "title": "TensorBoard tutorial links to the wrong MNIST tutorial and example code", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: 1.6\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\nSorry if this is better suited as an issue for TensorBoard, but since it's about documentation on tensorflow.org I thought it should go here.\r\n\r\nThe TensorBoard guide at https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard contains example code that it says \"is a modification of the [simple MNIST tutorial](https://www.tensorflow.org/tutorials/layers), in which we have added some summary ops.\" But the tutorial it links to, https://www.tensorflow.org/tutorials/layers, is very different from the example code it gives -- that tutorial uses the tf.layers module to create a CNN, while the example code manually defines a one-hidden-layer fully-connected network. I'm not even sure what the example code is based on, since it doesn't seem that similar to https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/examples/tutorials/mnist/mnist.py. \r\n\r\nAt the very least the link should be fixed to point to the correct original example code, but even better would be if the tutorial could be updated to show how to use TensorBoard with a network created with tf.layers.", "comments": ["Created a PR #17640 to fix this to point to [mnist.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py)"]}, {"number": 17599, "title": "Disable tensorflow/contrib/learn:monitors_test for pip gpu", "body": "", "comments": []}, {"number": 17598, "title": "Including the original path to find bazel.", "body": "", "comments": []}, {"number": 17597, "title": "SECURITY.md: minor sp, permisisons->permissions", "body": "", "comments": []}, {"number": 17596, "title": "Fix pylint error in single_return.py", "body": "", "comments": []}, {"number": 17595, "title": "Feature Request: quantize_weights does a signed_quantization [-127,+127] as well", "body": "- **OS Platform and Distribution: Linux Ubuntu 14.04/16.04\r\n- **TensorFlow installed from (source or binary)**: Source v1.3\r\n- **Bazel version (if compiling from source)**: bazel release 0.5.4\r\n- **CUDA/cuDNN version**:  v8\r\n- **GPU model and memory**: NVIDIA gtx1060\r\n- **Have I written custom code**: No\r\n- **Exact command to reproduce**:\r\n\r\n> tensorflow/tools/graph_transforms:transform_graph\r\n\r\nOnly does an unsigned quantization of the weights. I think it is useful for many that we have a signed quantization so that a normal distribution having a median of zero (`0.0f`) converts to a `TF-8 0`. This is useful in general. Thanks. \r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nTensorFlow version", "Thanks for your suggestion.  I need to understand it better before I can refer it to the correct person.  transform_graph is a tool that can do many things.  Which quantization operation is not satisfactory,  and exactly how would you like it changed?  Is it possible that you could get what you want by applying some kind of absolute value or normalization operation prior to the quantization?", "@poxvoculi, Specifically, I was referring to `quantize_weight.cc` and `quantize_node.cc`. The way I understood by looking at the code is that it only considers the min and the max and maps the remaining weights inside the span. However, it would be useful to consider `0.0f` as well and map them to `128 tf-8` so that the value zero remains unique in the quantized model. \r\nYes. There are a number of other methods available to do that but each has some pros and cons. The best practice, in my reckoning, here is to produce a signed 8-bits representing the value 0f to 0 tf-8.  Thanks", "@petewarden is this contributions welcome?", "Nagging Assignees @petewarden, @poxvoculi: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @petewarden, @poxvoculi: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @petewarden, @poxvoculi: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @petewarden, @poxvoculi: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @petewarden, @poxvoculi: It has been 75 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @petewarden, @poxvoculi: It has been 90 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @petewarden, @poxvoculi: It has been 105 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @suharshs: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Really sorry about the delay here!\r\n\r\nWe have focused quantization efforts to TensorFlow Lite. So we will likely not update the graph transform tool's quantization code.\r\n\r\nYour observation is absolutely correct, and we go to measures to make sure that floating point 0.0 maps exactly to a quantized uint8 value. Closing since we have addressed this in TensorFlow Lite. Thanks @amirjamez !"]}, {"number": 17594, "title": "Fix the broken link of tf-learn's iris tutorial also some format and typo", "body": "This PR is to fix:\r\n- As we can see in [TensorFlow Debugger](https://www.tensorflow.org/programmers_guide/debugger), the link of {$tflearn$tf-learn's iris tutorial} is broken since there was no tflearn.md any more in the latest master branch, I tried to fix this thru linking it to previous branch doc version;\r\n- The format of below sentence is messed up, tried to fix this messed up format with a blank line;\r\n>```# For LocalCLIDebugHook hooks = [tf_debug.LocalCLIDebugHook(dump_root=\"/with/lots/of/space\")] `` Make sure that the directory pointed to by dump_root is empty or nonexistent. tfdbg cleans up the dump directories before exiting. * Reduce the batch size used during the runs. * Use the filtering options of tfdbg'srun` command to watch only specific nodes in the graph. For example:", "comments": []}, {"number": 17593, "title": "tf.TensorShape equality comparison can return True for non-fully defined shapes", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, but trivial one-liner code.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: platform independent problem\r\n- **TensorFlow installed from (source or binary)**: either\r\n- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039 1.6.0\r\n- **Python version**:  tested in 3.5 and 3.6\r\n- **Bazel version (if compiling from source)**: not relevant\r\n- **GCC/Compiler version (if compiling from source)**: not relevant\r\n- **CUDA/cuDNN version**: not relevant\r\n- **GPU model and memory**: not relevant\r\n- **Exact command to reproduce**: see source one-liner below\r\n\r\n### Describe the problem\r\ntf.TensorShape equality comparison is designed to return None if any of its dimensions has a value of None. However, there is one case when this behavior fails and returns True when it shouldn't.\r\n\r\n### Source code / logs\r\n```python\r\ndim = tf.Dimension(None)\r\ntf.TensorShape(dim) == tf.TensorShape(dim) # Returns True instead of None.\r\ntf.TensorShape([None]) == tf.TensorShape([None]) # Correctly returns None.\r\n```\r\n\r\nThis can, of course, inadvertently appear in more complex shape manipulation codes and lead to unexpected results.\r\n\r\nA bit of debugging suggests that if the dimension objects inside the TensorShape have the same id, they are skipped when invoking `tf.Dimension.__eq__`. This might be because dimension comparison is triggered through the list containing them rather than individually iterating them.", "comments": ["In the implementation of `tf.Dimension`, I could see the return value will be None for `==` if any of the dimensions compared is None. However, I couldn't find any reference pointing to the same behavior of TensorShape. Not sure if None should be returned for '==' against TensorShape.\r\n\r\nI did find an issue related to the equality of TensorShape and that is related to the issue mentioned here:\r\n```\r\n# python\r\nPython 2.7.12 (default, Dec  4 2017, 14:50:18) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.TensorShape([None]) == tf.TensorShape([None])\r\nFalse\r\n>>> tf.TensorShape([tf.Dimension(None)]) == tf.TensorShape([tf.Dimension(None)])\r\nFalse\r\n>>> dim = tf.Dimension(None)\r\n>>> tf.TensorShape([dim]) == tf.TensorShape([dim])\r\nTrue\r\n>>> \r\n```\r\n\r\nThe inconsistency is caused by the implementation in `as_dimension` where dimension is directly assigned. Created a PR #17607 so that a copy of the value is performed (so that id will differ) to fix this issue.", "Looks like @yongtang is on this -- I'll assign the issue to him. Thanks Yong!", "The PR #17607 is pending review. Will update the status once PR #17607 is merged.", "Nagging Assignee @yongtang: It has been 122 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "See related discussion:\r\nhttps://github.com/tensorflow/tensorflow/pull/17607#issuecomment-415445235\r\nI think this issue could be closed as it is expected behavior."]}, {"number": 17592, "title": "C++ gradient for Slice", "body": "See https://github.com/tensorflow/tensorflow/issues/9645", "comments": ["Nagging Assignee @suharshs: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Reviewer @suharshs: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Assignee @suharshs: It has been 22 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@kbsriram, sorry for the delay.\r\nCould you rebase the changes, looks like we can merge as soon as all conflict are resolved.", "@gunan - no worries. I rebased (which also seems to have invalidated the lgtm; the changes should be identical however.)", "@suharshs could you take a look.", "Nagging Assignee @suharshs: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I find `tensorflow v1.9.0-rc2 ` supports `SliceGrad` whereas `tensorflow v1.9.0` throws `No gradient defined for op: Slice`."]}, {"number": 17591, "title": "Support other dtypes in BeamSearchDecoder initialization", "body": "The `BeamSearchDecoder` initialization failed when other dtypes were used (e.g. `tf.float16`). This PR correctly converts the scalar values to tensors with the current dtype.", "comments": ["Hi.\n\n\nBhasha\n\nOn Mar 14, 2018 20:48, \"ebrevdo\" <notifications@github.com> wrote:\n\n> Merged #17591 <https://github.com/tensorflow/tensorflow/pull/17591>.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/17591#event-1521199538>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ARHGmN51uLnXbXFfDVGHpIvFQ2-_2k7Xks5teTSzgaJpZM4SkQLc>\n> .\n>\n"]}, {"number": 17590, "title": "Leak when creating many tf.layers.Conv2D with tf.eager", "body": "\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04.3 LTS\r\n- **TensorFlow installed from (source or binary)**:  binary\r\n- **TensorFlow version (use command below)**: ('v1.5.0-0-g37aa430d84', '1.5.0')\r\n- **Python version**: Python 3.5.2\r\n- **CUDA/cuDNN version**:  cuda-9.0 \r\n- **GPU model and memory**: TITAN X (Pascal)\r\n\r\n- **Exact command to reproduce**:\r\n\r\nsee gist https://gist.github.com/matpalm/93680534c5c53d6e7836d3aea1a3bbb3\r\nfor minimal reproduction. run this script and watch loop times increase.\r\n\r\n### Describe the problem\r\n\r\neach creation of a tf.layers.Conv2D is slower than the one before. have a project based on evolutionary algorithm that creates many instances of tf.layers.Conv2D for fitness evaluation and over time entire process slows down. it's not expected this loop should slow down.\r\n\r\n### Source code / logs\r\nsee gist above", "comments": ["just upgraded to `v1.6.0-0-gd2e24b6039 1.6.0` & same behaviour\r\n", "Will finish investigating on Monday. Looks like it's due to some overzealous caching.\r\n\r\nThank you for the excellent bug report.", "The more worrying/unexpected issues here were PyObject leaks due to missing Py_DECREFs in our C code. Those are now fixed, although some of the changes haven't synced to github yet (give them a day or so).\r\n\r\nThe main issue is that there's a bit of `variable_scope` code run by `Layer`s which means creating new `Layer`s in a loop will take quadratic time (closing a `variable_scope` is linear in the number of existing `variable_scope`s). We'll fix that eventually (potentially by removing `variable_scope` in TF2.x), but there's a relatively easy workaround in the meantime. You can either wrap your `Layer` creation in a `with tfe.EagerVariableStore().as_default():` block or reset the default graph on each iteration. This will ensure that `variable_scope` names don't build up in this dictionary.", "Awesome! Thanks for the work around, I'll give that a go ASAP. Do you want\nme to close?\n\nOn Tue, Mar 13, 2018, 09:01 Allen Lavoie <notifications@github.com> wrote:\n\n> The more worrying/unexpected issues here were PyObject leaks due to\n> missing Py_DECREFs in our C code. Those are now fixed, although some of the\n> changes haven't synced to github yet (give them a day or so).\n>\n> The main issue is that there's a bit of variable_scope code run by Layers\n> which means creating new Layers in a loop will take quadratic time\n> (closing a variable_scope is linear in the number of existing\n> variable_scopes). We'll fix that eventually (potentially by removing\n> variable_scope in TF2.x), but there's a relatively easy workaround in the\n> meantime. You can either wrap your Layer creation in a with\n> tfe.EagerVariableStore().as_default(): block or reset the default graph\n> on each iteration. This will ensure that variable_scope names don't build\n> up in this dictionary.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17590#issuecomment-372476513>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABULd8zrKtsV3bz37zM060ecs5rIhQzks5tdvAagaJpZM4SkNEM>\n> .\n>\n", "You may want to use a build after https://github.com/tensorflow/tensorflow/commit/e2020e64360a4f9beeb48f388fb74ab1c4b1f847#diff-62c686d1c3d926dc05023a1ccd4d603c to avoid the PyObject leaks. Let me know if you run into any issues."]}, {"number": 17589, "title": "Device mapping: no known devices. 2018-03-09 15:46:04.512611: I tensorflow/core/common_runtime/direct_session.cc:299] Device mapping:", "body": "Hi folks,\r\n\r\nI am sure this question has been asked many many times everywhere but I couldn't get my problem resolved!\r\nhere is the error message after I execute:\r\n`sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))`\r\n \r\n\r\nthe error:\r\n```\r\n2018-03-09 15:45:58.393237: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2018-03-09 15:45:58.929878: E tensorflow/core/common_runtime/direct_session.cc:170] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY; total memory reported: 11719016448\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ist/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1482, in __init__\r\n    super(Session, self).__init__(target, graph, config=config)\r\n  File \"/home/ist/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 622, in __init__\r\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\r\n  File \"/home/ist/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.\r\n```\r\n\r\nand when I try again I receive this message:\r\n```\r\nDevice mapping: no known devices.\r\n2018-03-09 15:46:04.512611: I tensorflow/core/common_runtime/direct_session.cc:299] Device mapping:\r\n\r\n```\r\nI am working on a Ubuntu remote server which I access  from a Windows 10 Remote Desktop.\r\nThe info of Ubuntu as follows:\r\n\r\n lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 16.04.3 LTS\r\nRelease:        16.04\r\nCodename:       xenial\r\n\r\n\r\nwhen I execute nvidia-smi\r\n\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.25     Driver Version: 390.25                                           |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name: Persistence-M| Bus-Id   Disp.A | Volatile Uncorr. ECC           |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap | Memory-Usage | GPU-Util  Compute M. |\r\n|==============================================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |  N/A                      |\r\n| 47%   66C    P2   244W / 250W |  11146MiB / 11176MiB |  83% Default  |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+------------------------------------------------------------------------------------+\r\n| Processes:                                                                                     GPU Memory |\r\n|  GPU       PID   Type   Process name                                                    Usage      |\r\n|==================================================|\r\n|    0      1168      G   /usr/lib/xorg/Xorg                                                     89MiB |\r\n|    0      1957      G   compiz                                                                       90MiB |  \r\n|    0      2847      C   python                                                                  10937MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\nand  nvcc --version:\r\n\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2016 NVIDIA Corporation\r\nBuilt on Tue_Jan_10_13:22:03_CST_2017\r\nCuda compilation tools, release 8.0, V8.0.61\r\n\r\nPython 3.6.4\r\nTensorflow-gpu 1.4.1\r\n\r\nHave I written custom code? \r\nI just run a small piece of code to make sure if the GPU is utilized and the is mentioned above!\r\nOS Platform and Distribution\r\nalso mentioned this above\r\nTensorFlow installed from sudo pip3 install tensorflow-gpu==1.4.1\r\nTensorFlow version 1.4.1\r\nBazel version didn't install it!\r\nCUDA/cuDNN version 8.0.x / 6\r\nGPU model and memory \r\n\r\n` sudo lshw -C \"display\"\r\n  *-display\r\n       description: VGA compatible controller\r\n       product: NVIDIA Corporation\r\n       vendor: NVIDIA Corporation\r\n       physical id: 0\r\n       bus info: pci@0000:01:00.0\r\n       version: a1\r\n       width: 64 bits\r\n       clock: 33MHz\r\n       capabilities: pm msi pciexpress vga_controller bus_master cap_list rom\r\n       configuration: driver=nvidia latency=0\r\n       resources: irq:148 memory:de000000-deffffff memory:c0000000-cfffffff memory:d0000000-d1ffffff ioport:e000(size=128) memory:c0000-dffff\r\n  *-display UNCLAIMED\r\n       description: Display controller\r\n       product: Intel Corporation\r\n       vendor: Intel Corporation\r\n       physical id: 2\r\n       bus info: pci@0000:00:02.0\r\n       version: 00\r\n       width: 64 bits\r\n       clock: 33MHz\r\n       capabilities: pciexpress msi pm cap_list\r\n       configuration: latency=0\r\n       resources: memory:dd000000-ddffffff memory:b0000000-bfffffff ioport:f000(size=64)`\r\n\r\nExact command to reproduce\r\n```\r\nimport tensorflow as tf\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n\r\n```\r\nwhat should I do!\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Based on your nvidia-smi, the line \"`0 2847 C python 10937MiB`\" indicates you already have a TensorFlow process running that is using all the memory (perhaps in an interactive Python shell). Try killing that process and trying again.", "@reedwm  I will check and get back to you because I am not the only one using this GPU\r\n@tensorflowbutler  thanks for your following, I updated my post, I hope it is enough! :)", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to inactivity. Please reopen if this is still an issue.", "Hi @Mark010 , any luck with this error? I'm getting the same error on my Ubuntu 16.04 machine, using tensorflow CPU 1.9.0. ", "Hi @santo4ul , it turned out that someone was occupying the whole memory!"]}, {"number": 17588, "title": "AttentionWrapper bug with shape inference", "body": "This is my [source code](https://github.com/soloice/tf-tutorial/blob/master/src/att_seq2seq_minimal_error.py), which receives an integer sequence, delete odd numbers, and copy the remaining even number sequence twice. For example, input: [1, 2, 3, 4, 5, 6], output: [2, 4, 6, 2, 4, 6]. Of course, padding is used during training.\r\n\r\nIf I comment [L124](https://github.com/soloice/tf-tutorial/blob/6675b3b4d3b0b1dbcc3d2541a0637cabbdd27681/src/att_seq2seq_minimal_error.py#L124) out, the code runs very well. However, if this line is enabled, it will raise the following error:\r\n\r\n> ValueError: The shape for decoder/decoder/while/Merge_7:0 is not an invariant for the loop. It enters the loop with shape (64, 50), but has shape (?, 50) after one iteration. Provide shape invariants using either the `shape_invariants` argument of tf.while_loop or set_shape() on the loop variables.\r\n\r\nThis line is intended to disable input feeding scheme in paper \"Effective Approaches to Attention-based Neural Machine Translation\", which is the default behavior of AttentionWrapper.\r\n\r\nCurrently both my batch_size and num_steps are `None`. If I fix the batch size, i.e.: change placeholders to\r\n```\r\nencoder_inputs = tf.placeholder(shape=[batch_size, None], dtype=tf.int32, name='encoder_inputs')\r\ndecoder_targets = tf.placeholder(shape=[batch_size, None], dtype=tf.int32, name='decoder_targets')\r\ndecoder_inputs = tf.placeholder(shape=[batch_size, None], dtype=tf.int32, name='decoder_inputs')\r\nencoder_length = tf.placeholder(shape=[batch_size], dtype=tf.int32, name='encoder_length')\r\ndecoder_length = tf.placeholder(shape=[batch_size], dtype=tf.int32, name='decoder_length')\r\n```\r\n, everything works fine again.\r\n\r\nThe code is so simple, so probably it is a bug with shape inference.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Thanks for your following up.\r\n>Have I written custom code?\r\n\r\nYes. See [here](https://github.com/soloice/tf-tutorial/blob/master/src/att_seq2seq_minimal_error.py).\r\n\r\n>OS/TF/CUDA/Bazel/GPU version\r\n\r\nThis seems to be irrelevant. I believe this error could be reproduced in most environments.\r\nBut for your reference, both of the following environments raised the error: \r\n- Windows 7 + Anaconda 4.2.0 64-bit (with Python 3.5.2) + TF 1.5.0 installed by `pip install tensorflow` + CPU\r\n- Ubuntu 16.04 LTS + Python 3.5.2 + TF 1.4.0-rc1 (probably built by Bazel 0.6.1) + CUDA 8.0.61 + GTX 1080 Ti\r\n\r\n>Exact command to reproduce\r\n\r\n`python att_seq2seq_minimal_error.py`\r\nPython 3 recommended.", "Nagging Assignee @aselle: It has been 122 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Since this is contrib, it is not officially supported. @ebrevdo, could you please suggest a fix? It may be that the attentionwrapper doesn't support partially specified shapes.", "Looks like a failure in shape inference on the python side", "I'll try to look tomorrow and run your code.", "Your script works for me on a recent TF nightly:\r\n\r\n```\r\nbatch 0\r\n  minibatch loss: 2.396763324737549\r\nbatch 100\r\n  minibatch loss: 1.7288659811019897\r\nbatch 200\r\n  minibatch loss: 1.5466532707214355\r\n```\r\n\r\nI probably fixed the shape propagation issues some time ago.  Try it again with the recent version of TF.  Reopen this bug if it's still an issue for you.", "Thanks for your attention. I'll try it.", "@ebrevdo Confirmed. With TF 1.8.0 on Mac OS X, this code works fine.\r\nSo it might have been fixed somewhere between TF 1.5 and TF 1.8."]}, {"number": 17587, "title": "s390x build fails with boringssl error", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: master\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **CUDA/cuDNN version**: Not used\r\n- **Exact command to reproduce**: bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nTensorFlow master build is failing with below error: \r\n```\r\nERROR: /data/TF_tmp/_bazel_root/be3f47674f2731fd84874c35a2feb28b/external/kafka/BUILD:8:1: C++ compilation of rule '@kafka//:kafka' failed (Exit 1)\r\nIn file included from external/boringssl/src/include/openssl/ssl.h:145:0,\r\n                 from external/kafka/src/rdkafka_int.h:53,\r\n                 from external/kafka/src/rdkafka_conf.c:29:\r\nexternal/boringssl/src/include/openssl/base.h:114:2: error: #error \"Unknown target CPU\"\r\n #error \"Unknown target CPU\"\r\n```\r\nWe have disabled support for Apache Kafka Platform support through `./configure`. \r\n\r\n\r\n", "comments": ["@gunan Looks like Apache Kafka support also depends on boringssl. \r\nLooks similar to  [this](https://github.com/tensorflow/tensorflow/issues/14039#issuecomment-355439575) issue. ", "Thanks for catching this!\r\nThe recurrence of this problem just makes me think, is there an alternative SSL library we can substitute for boringSSL on s390x?\r\nMaybe that will be a better fix?", "@Nayana-ibm @gunan I updated the PR #17565 so that kafka (and boringSSL dependency) build could be skipped with `with_kafka_support=False`. Please take a look.", "@Nayana-ibm Can you confirm that the problem is now resolved?", "@rohan100jain Now build is successful on s390x. \r\nConfigured with export TF_NEED_KAFKA=0", "Closing the issue \r\nThanks,"]}, {"number": 17586, "title": "Not found: FeedInputs: unable to find feed output ", "body": "@GeorgeBohw\r\nhello,i also meet this problem.could you tell me how do you solve this problem?\r\n@tensorflowbutler \r\ni have use the the summarize_graph tool to guesses about likely input and output nodes,this is the command:bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=/home/biao/test/occ_detect.pb\r\nhere is the message:\r\n\r\nNo inputs spotted.\r\nNo variables spotted.\r\nFound 1 possible outputs: (name=softmax_linear/softmax_linear_1, op=Add) \r\nFound 850090 (850.09k) const parameters, 0 (0) variable parameters, and 0 control_edges\r\nOp types used: 18 Const, 13 Identity, 5 Add, 5 Relu, 3 BiasAdd, 3 MaxPool, 3 MatMul, 3 LRN, 3 Conv2D, 2 Mul, 1 Floor, 1 QueueDequeueManyV2, 1 RandomShuffleQueueV2, 1 RandomUniform, 1 RealDiv, 1 Reshape, 1 Sub\r\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\r\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=/home/biao/test/occ_detect.pb --show_flops --input_layer= --input_layer_type= --input_layer_shape= --output_layer=softmax_linear/softmax_linear_1\r\n\r\ni guess the problem is my .pb file is fault?\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@tensorflowbutler \r\nI am sorry that I forgot to reply! I have solve this problem,the reason is my training codes has fault.\r\nthank you remember me this issue. ", "Not found: FeedInputs: unable to find feed output  phase_train:\r\ni also meet this issue, and how to find you training codes has fault??\r\nthanks", "@cvJie \r\nmy reason is that i forget put the input to the placeholder,you can check your training codes!\r\ni think it also has other reasons if your training codes are ok!\r\n", "`Placeholder` is depreciated in Tensorflow 2.x version and Tensorflow 1.x is not supported anymore. Please try the latest [Tensorflow version](https://www.tensorflow.org/install/pip) and let us know if the problem still persists. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 17585, "title": "Tensorflow finding only 9gb of free memory but 11gb total for gtx 1080 ti GPU", "body": "We found on both Windows 10 and Linux machines that Tensorflow will only find 9gb of the 11gb available for GTX 1080 ti GPUs from both EVGA and MSI.  Having trouble finding a fix - does anyone know why it is doing this and how to fix it so it can get access to all the memory?", "comments": ["I'm getting the same issue when investigating in CUDA directly, so it's not a Tensorflow issue."]}, {"number": 17584, "title": "contrib:get_variables_and_layers", "body": "Here are two function to extract layer names and respective variable values, also an example provided in jupyter-notebook. ", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "Moved the example notebook to tensorflow/examples, but still not sure about the  right place. Suggest if any changes still required. ", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Used different email address while committing changes. No objections in the contribution. please approve the cla and review the changes.", "I signed it!", "@frankchn I've updated as suggested. ", "Yeah I am still not sure you should place an ipynb file in tensorflow/examples. Let me bring in @wolffg and @MarkDaoust, who might have a better idea of where to put this.", "@frankchn @wolffg @MarkDaoust \r\nHowever, the notebook is just to show how to use my two main contributions, i.e., `tensorflow/python/util/get_layer_names.py` and `tensorflow/python/util/get_variable_values.py`. These two are the main features, which automatically extracts Parameters of the model from a saved model. ", "@googlebot cla-signed please update the label.", "> \ud83d\ude15 The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter. We need to confirm that all authors are ok with their commits being contributed to this project. Please have them confirm that here in the pull request.\r\n@googlebot @tensorflowbutler @frankchn \r\nWith respect to the above statement, I would like to confirm that I am okay with the contributions or comments. So, I request to please approve and proceed further. \r\n"]}, {"number": 17583, "title": "Update RELEASE.md", "body": "", "comments": []}, {"number": 17582, "title": "sparse variable request or any alternate?", "body": "In tensor flow (TF) , to compute gradients we have to pass some variable. Sparse tensors cannot be used as variables. Can you please tell me is there any solution for sparse matrix gradient ?\r\nN/A\r\nTensorflow version 1.4", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17581, "title": "Fix cmake build errors for Linux", "body": "When trying to build TensorFlow with cmake for Linux, as was specified:\r\n```\r\ntensorflow/tools/ci_build/ci_build.sh CMAKE tensorflow/tools/ci_build/builds/cmake.sh\r\n```\r\n\r\nThe following error encountered:\r\n```\r\ngrpc/src/grpc/libgrpc_unsecure.a(grpc_ares_wrapper.cc.o): In function `on_txt_done_cb(void*, int, int, unsigned char*, int)':\r\ngrpc_ares_wrapper.cc:(.text+0x256): undefined reference to `ares_parse_txt_reply_ext'\r\ngrpc_ares_wrapper.cc:(.text+0x267): undefined reference to `ares_strerror'\r\ngrpc_ares_wrapper.cc:(.text+0x363): undefined reference to `ares_free_data'\r\n```\r\n\r\nThis fix fixes the above issue with libcares.a in cmake file.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 17580, "title": "Make spinn_test less flaky", "body": "", "comments": ["@yifeif Instead of disabling the entire test, can you just comment out this line? https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/spinn/spinn_test.py#L420\r\n\r\nThe flaky part is the ML training part. All other parts shouldn't be flaky and I'd like to be covered.\r\n\r\nSorry about the inconvenience."]}, {"number": 17579, "title": "streaming curve points bug", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9/7\r\n- **GPU model and memory**: titan x 12g\r\n- **Exact command to reproduce**: eval_train_classifier.py\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nIn the metrics_ops, there is streaming_curve_points. I added it to evaluation below code.\r\nEverything else works flawless, but the ROC curve doesn't.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nSource code:\r\n`   # Define the metrics:\r\n    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\r\n        'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),\r\n        'FPs': slim.metrics.streaming_false_positives(predictions, labels),\r\n        'FNs': slim.metrics.streaming_false_negatives(predictions, labels),\r\n        'TPs': slim.metrics.streaming_true_positives(predictions, labels),\r\n        'TNs': slim.metrics.streaming_true_negatives(predictions, labels),\r\n        'AUC': slim.metrics.streaming_auc(predictions, labels),\r\n        'ROC curve': slim.metrics.streaming_curve_points(labels=labels,\r\n                                                         predictions=tf.cast(predictions, tf.float32)),\r\n    })\r\n`\r\n\r\nLogs:\r\n\r\n> 2018-03-09 01:26:50.313306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Found device 0 with properties:                                                                                                                 [157/1802]\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155\r\npciBusID: 0000:03:00.0\r\ntotalMemory: 11.92GiB freeMemory: 11.80GiB\r\n2018-03-09 01:26:50.313398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Adding visible gpu device 0\r\n2018-03-09 01:26:50.674278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:987] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11431 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci b\r\nus id: 0000:03:00.0, compute capability: 5.2)\r\nINFO:tensorflow:Restoring parameters from /tmp/glaucoma-models/resnet_v2_152_new/model.ckpt-3013\r\nINFO:tensorflow:Evaluation [1/2]\r\nINFO:tensorflow:Evaluation [2/2]\r\neval/FNs[21]\r\neval/FPs[11]eval/TNs[44]\r\neval/TPs[34]\r\n\r\neval/Accuracy[0.709090889]\r\nTraceback (most recent call last):\r\n  File \"eval_image_classifier.py\", line 196, in <module>\r\n    tf.app.run()\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"eval_image_classifier.py\", line 192, in main\r\n    variables_to_restore=variables_to_restore)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py\", line 212, in evaluate_once\r\n    config=session_config)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/evaluation.py\", line 212, in _evaluate_once\r\n    session.run(eval_ops, feed_dict)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 651, in __exit__\r\n    self._close_internal(exception_type)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 683, in _close_internal\r\n    h.end(self._coordinated_creator.tf_sess)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py\", line 311, in end\r\n    summary_str = session.run(self._summary_op, self._feed_dict)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1128, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1344, in _do_run\r\n    options, run_metadata)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1363, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: tags and values not the same shape: [] != [200,2] (tag 'eval/ROC_curve')\r\n         [[Node: eval/ROC_curve = ScalarSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](eval/ROC_curve/tags, curve_points/stack_1/_5417)]]\r\n\r\nCaused by op u'eval/ROC_curve', defined at:\r\n  File \"eval_image_classifier.py\", line 196, in <module>\r\n    tf.app.run()\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"eval_image_classifier.py\", line 168, in main\r\n    op = tf.summary.scalar(summary_name, value, collections=[])\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 100, in scalar\r\n    val = _gen_logging_ops._scalar_summary(tags=tag, values=tensor, name=scope)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 402, in _scalar_summary\r\n    \"ScalarSummary\", tags=tags, values=values, name=name)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1617, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): tags and values not the same shape: [] != [200,2] (tag 'eval/ROC_curve')\r\n         [[Node: eval/ROC_curve = ScalarSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](eval/ROC_curve/tags, curve_points/stack_1/_5417)]]\r\n", "comments": ["@sguada , About the problem above, it looks like it is because of the tf.summary.scalar in eval_image_classifier.py. Since the tf.summary.scalar function returns only a scalar value, the array of streaming curve points and streaming concat (it had also the same problem) was not the proper format  for the input. \r\n\r\nSo, I changed the tf.summary.scalar to tf.summary.tensor_summary. It worked without any errors. If that was the case, I will close this issue. ", "Nagging Assignee @sguada: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I think that was the issue, so feel free to close it."]}, {"number": 17578, "title": "Disable checkpointable_utils_test", "body": "failed http://ci.tensorflow.org/view/Release/job/release-debian-cpu/99/consoleFull", "comments": ["Huh, the garbage collection parts of the test. This is not  related to b/74395663, it's probably due to differences in the Python environment. I'll look into it but I don't think it's something anyone else needs to worry about (so disabling LGTM).", "Thanks Allen!"]}]