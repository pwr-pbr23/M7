[{"number": 27121, "title": "Build from source error on knl", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.13\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.20\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nBuild failed with following command\r\n\r\nbazel build --config=mkl --copt=\"-DEIGEN_USE_VML\" --copt=\"-mfma\" --copt=\"-mavx2\"  --copt=\"-O3\" -s -c opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nERROR: /global/cscratch1/sd/jw447/tensorflow/tensorflow/core/kernels/BUILD:3206:1: C++ compilation of rule '//tensorflow/core/kernels:reduction_ops' failed (Exit 1)\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:124:0,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/kernels/reduction_ops_common.h:27,\r\n                 from tensorflow/core/kernels/reduction_ops_sum.cc:16:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h: In static member function 'static void std::_Function_handler<void(_ArgTypes ...), _Functor>::_M_invoke(const std::_Any_data&, _ArgTypes&& ...) [with _Functor = Eigen::internal::TensorExecutor<Expression, Eigen::ThreadPoolDevice, Vectorizable, Tileable>::run(const Expression&, const Eigen::ThreadPoolDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 0, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::IndexList<Eigen::type2index<0> >, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 1, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer> >; bool Vectorizable = true; bool Tileable = false]::<lambda(Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 0, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::IndexList<Eigen::type2index<0> >, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 1, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, false>::StorageIndex, Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 0, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::IndexList<Eigen::type2index<0> >, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 1, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, false>::StorageIndex)>; _ArgTypes = {long int, long int}]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h:801:9: internal compiler error: in emit_move_insn, at expr.c:3698\r\n         values[i] = internal::InnerMostDimReducer<Self, Op>::reduce(*this, firstIndex + i * num_values_to_reduce,\r\n         ^~~~~~\r\n0x8c3a4a emit_move_insn(rtx_def*, rtx_def*)\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/expr.c:3697\r\n0x8b3ddd store_bit_field_1\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/expmed.c:814\r\n0x8b4448 store_bit_field(rtx_def*, unsigned long, unsigned long, unsigned long, unsigned long, machine_mode, rtx_def*, bool)\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/expmed.c:1122\r\n0x8ce4ae store_field\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/expr.c:6974\r\n0x8cbadb expand_assignment(tree_node*, tree_node*, bool)\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/expr.c:5209\r\n0x7dd681 expand_call_stmt\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/cfgexpand.c:2656\r\n0x7dd681 expand_gimple_stmt_1\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/cfgexpand.c:3571\r\n0x7dd681 expand_gimple_stmt\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/cfgexpand.c:3737\r\n0x7de85f expand_gimple_basic_block\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/cfgexpand.c:5744\r\n0x7e39c6 execute\r\n\t../../cray-gcc-7.3.0-201801270210.d61239fc6000b/gcc/cfgexpand.c:6357\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nPlease include the complete backtrace with any bug report.\r\nSee <https://gcc.gnu.org/bugs/> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 143.389s, Critical Path: 110.81s\r\nINFO: 537 processes: 537 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\nCould anyone please help? Thanks!", "comments": ["Could you please confirm if this error occurs while building without --config=mkl flag?", "closed due to inactivity. Please reopen if need further support.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27121\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27121\">No</a>\n"]}, {"number": 27120, "title": "tf.function-decorated function tried to create variables on non-first call", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian Testing\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.0.0.dev20190227\r\n- Python version: 3.7\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nA function which correctly works when in eager mode does not work anymore when annotated with `tf.function`.\r\n\r\nIn particular, it complains about `ValueError: tf.function-decorated function tried to create variables on non-first call.`, even though the function is always called with different parameters.\r\n\r\nThis is a continuation of https://github.com/tensorflow/tensorflow/issues/26812#issuecomment-475600836.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe `apply_gradients_once()` function should work even when annotated with `tf.function`.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python3\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nfast_optimizer = tf.keras.optimizers.Adam(\r\n        learning_rate=1e-3)\r\n\r\nslow_optimizer = tf.keras.optimizers.Adam(\r\n        learning_rate=1e-3 * 1e-9)\r\n\r\n\r\n@tf.function\r\ndef apply_gradients_once(optimizer, grads, vars):\r\n    grads = [grads]\r\n    optimizer.apply_gradients(zip(grads, vars))\r\n\r\n\r\ndef apply_grads(use_fast, grads_per_model, vars):\r\n    for i in range(2):\r\n        if use_fast[i]:\r\n            apply_gradients_once(fast_optimizer, grads_per_model[i], vars[i])\r\n        else:\r\n            apply_gradients_once(slow_optimizer, grads_per_model[i], vars[i])\r\n\r\n\r\ndef compute_loss(w, x, y):\r\n    r = (w * x - y)**2\r\n    r = tf.math.reduce_mean(r)\r\n    return r\r\n\r\ndef compute_gradients(model):\r\n    with tf.GradientTape() as tape:\r\n        tape.watch(model)\r\n        loss = compute_loss(model, x, y)\r\n    grads = tape.gradient(loss, model)\r\n    return grads\r\n\r\n\r\nw = [\r\n    tf.Variable(0.0),\r\n    tf.Variable(1.0)]\r\n\r\nx = np.array([1, 2, 3])\r\ny = np.array([1, 2, 3])\r\n\r\nvars = []\r\ngrads = []\r\nfor i in range(2):\r\n    vars.append([w[i]])\r\n    grads.append(compute_gradients(w[i]))\r\n\r\napply_grads([True, False], grads, vars)\r\n```\r\n\r\n\r\n**Other info / logs**\r\n\r\nError log:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 52, in <module>\r\n    apply_grads([True, False], grads, vars)\r\n  File \"main.py\", line 23, in apply_grads\r\n    apply_gradients_once(slow_optimizer, grads_per_model[i], vars[i])\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 414, in __call__\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1254, in __call__\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1577, in _maybe_define_function\r\n    args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1479, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 685, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 317, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 677, in wrapper\r\n    ), args, kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 392, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n  File \"/tmp/tmpr2ti5o1e.py\", line 4, in tf__apply_gradients_once\r\n    ag__.converted_call('apply_gradients', optimizer, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (zip(grads, vars),), {})\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 267, in converted_call\r\n    return _call_unconverted(f, args, kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 188, in _call_unconverted\r\n    return f(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 399, in apply_gradients\r\n    self._create_hypers()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 558, in _create_hypers\r\n    aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 727, in add_weight\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 622, in _add_variable_with_custom_getter\r\n    **kwargs_for_getter)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\", line 152, in make_variable\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 212, in __call__\r\n    return cls._variable_v1_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 175, in _variable_v1_call\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 58, in getter\r\n    return captured_getter(captured_previous, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 375, in invalid_creator_scope\r\n    \"tf.function-decorated function tried to create \"\r\nValueError: tf.function-decorated function tried to create variables on non-first call.\r\n```", "comments": ["That's interesting. In this case it looks like you can move the decorator to `apply_grads` as a workaround.\r\n\r\nWe don't have a particularly good reason I can think of for disallowing variable creation when different Python objects are passed, or even different shapes/dtypes. Can you think of any, @alextp ? We'd basically have to invert the current relationship between tf.function and defun, where each function in defun's cache would do the double-trace thing for variable initialization. (For things that work with tf.function as-is, only one cached double-tracer would see new variables on its first trace.)", "For different shapes / dtypes we chose to disallow variable creation due to preserving the behavior of existing v1 code which could accidentally create variables on different shapes leading to an untrainable model.\r\n\r\nI am fine relaxing the restriction on python objects, but I'd like to see if there's a better workaround here (and the one of decorating apply_grads instead and making use_fast a tensor is one that comes to mind for me).", "I have tried taking an approach with annotating `apply_grads()` with tf.function(), in my real code.\r\n\r\nThe problem seems to be that the values are not actually used (somehow).\r\n\r\nOn a first iteration, I call it with `[True, False]`, and then on a second one the parameters become `[False, True]`, but it seems as though it still thinks that it was called with the original ones:\r\n\r\n```\r\n# This works ok!\r\napply_grads([True, False], grads, vars)\r\n\r\n# This still trains the first model, not the second one.\r\napply_grads([False, True], grads, vars)\r\n```\r\n\r\nHowever, if I remove the `tf.function()` annotation from `apply_grads()`, then everything works as it should.\r\n\r\n", "Huh, that's a bug. I'll investigate.\n\nOn Fri, Mar 29, 2019 at 12:09 AM Eric Stavarache <notifications@github.com>\nwrote:\n\n> I have tried taking an approach with annotating apply_grads() with\n> tf.function(), in my real code.\n>\n> The problem seems to be that the values are not actually used (somehow).\n>\n> On a first iteration, I call it with [True, False], and then on a second\n> one the parameters become [False, True], but it seems as though it still\n> thinks that it was called with the original ones:\n>\n> # This works ok!\n> apply_grads([True, False], grads, vars)\n>\n> # This still trains the first model, not the second one.\n> apply_grads([False, True], grads, vars)\n>\n> However, if I remove the tf.function() annotation from apply_grads(),\n> then everything works as it should.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/27120#issuecomment-477892249>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxfUapy7BAVi97vPT_fg5qoFhvXaEks5vbbwagaJpZM4cJW0Z>\n> .\n>\n\n\n-- \n - Alex\n", "I guess that error is somewhere in tensorflow/python/eager/function.py/defun ", "```\r\nclass SeqToSeq(models.Model):\r\n    def __init__(self,hidden_dim,en_voc_size,vi_voc_size,loss_decay):\r\n        super(SeqToSeq, self).__init__(self)\r\n        self.en_word_embedding = layers.Embedding(en_voc_size+1,300,mask_zero=True)\r\n        self.vi_word_embedding = layers.Embedding(vi_voc_size+1,300,mask_zero=True)\r\n        self.enc_lstm = layers.LSTM(hidden_dim,return_state=True)\r\n        self.dec_lstm = layers.LSTM(128,return_sequences=True,return_state=True)\r\n        self.output_dense = layers.TimeDistributed(layers.Dense(vi_voc_size+1,use_bias=False))\r\n        self.loss_decay = loss_decay\r\n        self.target_vocab_size = vi_voc_size+1\r\n\r\n    def encode(self,seq):\r\n        enc_output,enc_h,enc_c = self.enc_lstm(seq)\r\n        return (enc_h,enc_c)\r\n\r\n    def decode(self,seq,state=None):\r\n        dec_output,dec_h,dec_c = self.dec_lstm(seq,initial_state=state)\r\n        return dec_output,(dec_h,dec_c)\r\n    @tf.function\r\n    def loss(self,y,target):\r\n        return tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=tf.reshape(y,shape=(-1,self.target_vocab_size)), labels=tf.reshape(target,shape=(-1,))))/self.loss_decay\r\n\r\n    @tf.function\r\n    def call(self,x1,x2):\r\n        with tf.device(\"cpu\"):\r\n            x1 = self.en_word_embedding(x1)\r\n            x2 = self.vi_word_embedding(x2)\r\n        enc_state = self.encode(x1)\r\n        dec_output,_ = self.decode(x2,enc_state)\r\n        y = self.output_dense(dec_output)\r\n        return y\r\n@tf.function\r\ndef train_one_step(model,x1,x2,target):\r\n    with tf.GradientTape() as tape:\r\n        y = model(x1,x2)\r\n        loss = model.loss(y,target)\r\n        grad = tape.gradient(loss,model.trainable_variables)\r\n        clipped_gradients, _ = tf.clip_by_global_norm(grad,5)\r\n        optim.apply_gradients(zip(grad, model.trainable_variables))\r\n    return loss\r\n@tf.function\r\ndef train(model,epochs=5):\r\n    start=time.time()\r\n    step = 0\r\n    for idx in tf.range(epochs):\r\n        tf.print(\"-\"*20,\"epoch\",idx,\"-\"*20)\r\n        for x1,x2,target in ds:\r\n            loss = train_one_step(model,x1,x2,target)\r\n            if step % 10 ==0:\r\n                tf.print(f\"step {step}\\tloss {loss}\\ttime(s) {time.time()-start}\")\r\n                start = time.time()\r\n            step+=1\r\nmodel = SeqToSeq(128,en_size,vi_size,BATCH_SIZE*MAX_LEN)\r\ntrain(model)\r\n```\r\nI have the same problem, when train function annotated with tf.function.\r\n\r\nSystem information\r\n\r\n* OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18\r\n* TensorFlow installed from (source or binary): Binary\r\n* TensorFlow version (use command below): 2.0.0-alpha0\r\n* Python version: 3.7\r\n\r\nerror info:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-52-9d3046b5d0d4> in <module>\r\n----> 1 train(model)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    424     # This is the first call of __call__, so we have to initialize.\r\n    425     initializer_map = {}\r\n--> 426     self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n    427     if self._created_variables:\r\n    428       try:\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    368     self._concrete_stateful_fn = (\r\n    369         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 370             *args, **kwds))\r\n    371 \r\n    372     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   1311     if self._input_signature:\r\n   1312       args, kwargs = None, None\r\n-> 1313     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   1314     return graph_function\r\n   1315 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   1578           or call_context_key not in self._function_cache.missed):\r\n   1579         self._function_cache.missed.add(call_context_key)\r\n-> 1580         graph_function = self._create_graph_function(args, kwargs)\r\n   1581         self._function_cache.primary[cache_key] = graph_function\r\n   1582         return graph_function, args, kwargs\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   1510             arg_names=arg_names,\r\n   1511             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 1512             capture_by_value=self._capture_by_value),\r\n   1513         self._function_attributes)\r\n   1514 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    692                                           converted_func)\r\n    693 \r\n--> 694       func_outputs = python_func(*func_args, **func_kwargs)\r\n    695 \r\n    696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    315         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    316         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 317         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    318     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    319 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    684                   optional_features=autograph_options,\r\n    685                   force_conversion=True,\r\n--> 686               ), args, kwargs)\r\n    687 \r\n    688         # Wrapping around a decorator allows checks like tf_inspect.getargspec\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)\r\n    390     return _call_unconverted(f, args, kwargs)\r\n    391 \r\n--> 392   result = converted_f(*effective_args, **kwargs)\r\n    393 \r\n    394   # The converted function's closure is simply inserted into the function's\r\n\r\n/tmp/tmp94ct_k8c.py in tf__train(model, epochs)\r\n     26     step_2, start_3 = ag__.for_stmt(ds, None, loop_body, (step_2, start_3))\r\n     27     return step_2, start_3\r\n---> 28   step, start = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (epochs,), {}), None, loop_body_1, (step, start))\r\n     29 \r\n     30 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in for_stmt(iter_, extra_test, body, init_state)\r\n     64   \"\"\"\r\n     65   if tensor_util.is_tensor(iter_):\r\n---> 66     return _known_len_for_stmt(iter_, extra_test, body, init_state)\r\n     67   elif isinstance(iter_, dataset_ops.DatasetV2):\r\n     68     # Check for undefined symbols and report an error. This prevents the error\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in _known_len_for_stmt(iter_, extra_test, body, init_state)\r\n    116       init_state=(0,) + init_state,\r\n    117       extra_deps=(iter_,),\r\n--> 118       opts=dict(maximum_iterations=n))\r\n    119 \r\n    120   # Dropping the iteration index because it's not syntactically visible.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in while_stmt(test, body, init_state, extra_deps, opts)\r\n    192           'to a Tensor, Variable or TensorArray before the loop: {}'\r\n    193           .format(tuple(undefined_symbols)))\r\n--> 194     return _tf_while_stmt(test, body, init_state, opts)\r\n    195   else:\r\n    196     return _py_while_stmt(test, body, init_state, opts)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in _tf_while_stmt(test, body, init_state, opts)\r\n    216   opts['return_same_structure'] = True\r\n    217 \r\n--> 218   retval = control_flow_ops.while_loop(test, body, init_state, **opts)\r\n    219   return retval\r\n    220 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\r\n   3401         maximum_iterations=maximum_iterations,\r\n   3402         name=name,\r\n-> 3403         return_same_structure=return_same_structure)\r\n   3404 \r\n   3405   with ops.name_scope(name, \"while\", loop_vars):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure)\r\n    171         func_graph=util.WhileBodyFuncGraph(\r\n    172             body_name, collections=ops.get_default_graph()._collections),  # pylint: disable=protected-access\r\n--> 173         add_control_dependencies=add_control_dependencies)\r\n    174     # Add external captures of body to the list of loop vars.\r\n    175     # Note that external tensors will be treated as loop invariants, i.e.,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    692                                           converted_func)\r\n    693 \r\n--> 694       func_outputs = python_func(*func_args, **func_kwargs)\r\n    695 \r\n    696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py in wrapped_body(loop_counter, maximum_iterations_arg, *args)\r\n    150       # `orig_loop_vars` and `args`, converts flows in `args` to TensorArrays\r\n    151       # and packs it into the structure of `orig_loop_vars`.\r\n--> 152       outputs = body(*_pack_sequence_as(orig_loop_vars, args))\r\n    153       if not nest.is_sequence(outputs):\r\n    154         outputs = [outputs]\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in while_body(iterate_index, *state)\r\n     98   def while_body(iterate_index, *state):\r\n     99     iterate = iter_[iterate_index]\r\n--> 100     new_state = body(iterate, *state)\r\n    101 \r\n    102     state = (iterate_index + 1,)\r\n\r\n/tmp/tmp94ct_k8c.py in loop_body_1(loop_vars, step_2, start_3)\r\n     24       step_1 += 1\r\n     25       return step_1, start_2\r\n---> 26     step_2, start_3 = ag__.for_stmt(ds, None, loop_body, (step_2, start_3))\r\n     27     return step_2, start_3\r\n     28   step, start = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (epochs,), {}), None, loop_body_1, (step, start))\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in for_stmt(iter_, extra_test, body, init_state)\r\n     77           .format(tuple(undefined_symbols)))\r\n     78 \r\n---> 79     return _dataset_for_stmt(iter_, extra_test, body, init_state)\r\n     80   else:\r\n     81     return _py_for_stmt(iter_, extra_test, body, init_state)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in _dataset_for_stmt(ds, extra_test, body, init_state)\r\n    143 \r\n    144   if init_state:\r\n--> 145     return ds.reduce(init_state, reduce_body)\r\n    146 \r\n    147   # Workaround for Datset.reduce not allowing empty state tensors - create\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in reduce(self, initial_state, reduce_func)\r\n   1274           input_structure=structure_lib.NestedStructure(\r\n   1275               (state_structure, self._element_structure)),\r\n-> 1276           add_to_graph=False)\r\n   1277 \r\n   1278       # Extract and validate class information from the returned values.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\r\n   2386           ops.GraphKeys.TABLE_INITIALIZERS))\r\n   2387 \r\n-> 2388       self._function = wrapper_fn._get_concrete_function_internal()\r\n   2389       if add_to_graph:\r\n   2390         self._function.add_to_graph(ops.get_default_graph())\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal(self, *args, **kwargs)\r\n   1317     \"\"\"Bypasses error checking when getting a graph function.\"\"\"\r\n   1318     graph_function = self._get_concrete_function_internal_garbage_collected(\r\n-> 1319         *args, **kwargs)\r\n   1320     # We're returning this concrete function to someone, and they may keep a\r\n   1321     # reference to the FuncGraph without keeping a reference to the\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   1311     if self._input_signature:\r\n   1312       args, kwargs = None, None\r\n-> 1313     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   1314     return graph_function\r\n   1315 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   1578           or call_context_key not in self._function_cache.missed):\r\n   1579         self._function_cache.missed.add(call_context_key)\r\n-> 1580         graph_function = self._create_graph_function(args, kwargs)\r\n   1581         self._function_cache.primary[cache_key] = graph_function\r\n   1582         return graph_function, args, kwargs\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   1510             arg_names=arg_names,\r\n   1511             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 1512             capture_by_value=self._capture_by_value),\r\n   1513         self._function_attributes)\r\n   1514 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    692                                           converted_func)\r\n    693 \r\n--> 694       func_outputs = python_func(*func_args, **func_kwargs)\r\n    695 \r\n    696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in wrapper_fn(*args)\r\n   2379           attributes=defun_kwargs)\r\n   2380       def wrapper_fn(*args):  # pylint: disable=missing-docstring\r\n-> 2381         ret = _wrapper_helper(*args)\r\n   2382         ret = self._output_structure._to_tensor_list(ret)\r\n   2383         return [ops.convert_to_tensor(t) for t in ret]\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in _wrapper_helper(*args)\r\n   2324         nested_args = (nested_args,)\r\n   2325 \r\n-> 2326       ret = func(*nested_args)\r\n   2327       # If `func` returns a list of tensors, `nest.flatten()` and\r\n   2328       # `ops.convert_to_tensor()` would conspire to attempt to stack\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in reduce_body(state, iterate)\r\n    139 \r\n    140   def reduce_body(state, iterate):\r\n--> 141     new_state = body(iterate, *state)\r\n    142     return new_state\r\n    143 \r\n\r\n/tmp/tmp94ct_k8c.py in loop_body(loop_vars, step_1, start_2)\r\n     10     def loop_body(loop_vars, step_1, start_2):\r\n     11       x1, x2, target = loop_vars\r\n---> 12       loss = ag__.converted_call(train_one_step, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_3, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (model, x1, x2, target), {})\r\n     13       cond = step_1 % 10 == 0\r\n     14 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)\r\n    265 \r\n    266   if not options.force_conversion and conversion.is_whitelisted_for_graph(f):\r\n--> 267     return _call_unconverted(f, args, kwargs)\r\n    268 \r\n    269   # internal_convert_user_code is for example turned off when issuing a dynamic\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in _call_unconverted(f, args, kwargs)\r\n    186     return f.__self__.call(args, kwargs)\r\n    187 \r\n--> 188   return f(*args, **kwargs)\r\n    189 \r\n    190 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    412       # In this case we have created variables on the first call, so we run the\r\n    413       # defunned version which is guaranteed to never create variables.\r\n--> 414       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    415     elif self._stateful_fn is not None:\r\n    416       # In this case we have not created variables on the first call. So we can\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   1285   def __call__(self, *args, **kwargs):\r\n   1286     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n-> 1287     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   1288     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1289 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   1609           relaxed_arg_shapes)\r\n   1610       graph_function = self._create_graph_function(\r\n-> 1611           args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\r\n   1612       self._function_cache.arg_relaxed[rank_only_cache_key] = graph_function\r\n   1613 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   1510             arg_names=arg_names,\r\n   1511             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 1512             capture_by_value=self._capture_by_value),\r\n   1513         self._function_attributes)\r\n   1514 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    692                                           converted_func)\r\n    693 \r\n--> 694       func_outputs = python_func(*func_args, **func_kwargs)\r\n    695 \r\n    696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    315         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    316         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 317         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    318     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    319 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    684                   optional_features=autograph_options,\r\n    685                   force_conversion=True,\r\n--> 686               ), args, kwargs)\r\n    687 \r\n    688         # Wrapping around a decorator allows checks like tf_inspect.getargspec\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)\r\n    390     return _call_unconverted(f, args, kwargs)\r\n    391 \r\n--> 392   result = converted_f(*effective_args, **kwargs)\r\n    393 \r\n    394   # The converted function's closure is simply inserted into the function's\r\n\r\n/tmp/tmpzpbq_gx6.py in tf__train_one_step(model, x1, x2, target)\r\n      8     grad = ag__.converted_call('gradient', tape, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_2, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (loss, model.trainable_variables), {})\r\n      9     clipped_gradients, _ = ag__.converted_call('clip_by_global_norm', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_3, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (grad, 5), {})\r\n---> 10     ag__.converted_call('apply_gradients', optim, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_4, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (zip(grad, model.trainable_variables),), {})\r\n     11   do_return = True\r\n     12   retval_ = loss\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)\r\n    265 \r\n    266   if not options.force_conversion and conversion.is_whitelisted_for_graph(f):\r\n--> 267     return _call_unconverted(f, args, kwargs)\r\n    268 \r\n    269   # internal_convert_user_code is for example turned off when issuing a dynamic\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in _call_unconverted(f, args, kwargs)\r\n    186     return f.__self__.call(args, kwargs)\r\n    187 \r\n--> 188   return f(*args, **kwargs)\r\n    189 \r\n    190 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in apply_gradients(self, grads_and_vars, name)\r\n    399     self._create_hypers()\r\n    400     with ops.init_scope():\r\n--> 401       self._create_slots(var_list)\r\n    402 \r\n    403     self._prepare(var_list)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adam.py in _create_slots(self, var_list)\r\n    147     # Separate for-loops to respect the ordering of slot variables from v1.\r\n    148     for var in var_list:\r\n--> 149       self.add_slot(var, 'm')\r\n    150     for var in var_list:\r\n    151       self.add_slot(var, 'v')\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in add_slot(self, var, slot_name, initializer)\r\n    529           dtype=var.dtype,\r\n    530           trainable=False,\r\n--> 531           initial_value=initial_value)\r\n    532       backend.track_variable(weight)\r\n    533       slot_dict[slot_name] = weight\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    212       return cls._variable_v1_call(*args, **kwargs)\r\n    213     elif cls is Variable:\r\n--> 214       return cls._variable_v2_call(*args, **kwargs)\r\n    215     else:\r\n    216       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation)\r\n    206         constraint=constraint,\r\n    207         synchronization=synchronization,\r\n--> 208         aggregation=aggregation)\r\n    209 \r\n    210   def __call__(cls, *args, **kwargs):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in getter(**kwargs)\r\n     56   \"\"\"To avoid capturing loop variables.\"\"\"\r\n     57   def getter(**kwargs):\r\n---> 58     return captured_getter(captured_previous, **kwargs)\r\n     59   return getter\r\n     60 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in invalid_creator_scope(*unused_args, **unused_kwds)\r\n    373       \"\"\"Disables variable creation.\"\"\"\r\n    374       raise ValueError(\r\n--> 375           \"tf.function-decorated function tried to create \"\r\n    376           \"variables on non-first call.\")\r\n    377 \r\n\r\nValueError: tf.function-decorated function tried to create variables on non-first call.\r\n```", "@liuneng1994 what is optim in your code?\r\n\r\nCould you be recreating instances of the optimizer in every training iteration?", "optimizer code:\r\n```\r\noptim = optimizers.Adam(0.001)\r\n```\r\nI tried to create new optimizer instance in every training step:\r\n```\r\n@tf.function\r\ndef train_one_step(model,x1,x2,target):\r\n    optim = optimizers.Adam(0.001)\r\n    with tf.GradientTape() as tape:\r\n        y = model(x1,x2)\r\n        loss = model.loss(y,target)\r\n        grad = tape.gradient(loss,model.trainable_variables)\r\n        clipped_gradients, _ = tf.clip_by_global_norm(grad,5)\r\n        optim.apply_gradients(zip(grad, model.trainable_variables))\r\n    return loss\r\n```\r\nI updated new version tf_nightly_gpu_2.0_preview-2.0.0.dev20190504-cp37-cp37m-manylinux1_x86_64.whl,  I got same error, :\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-19-c34c26bde61f> in <module>\r\n     12             step+=1\r\n     13 model = SeqToSeq(128,en_size,vi_size,BATCH_SIZE*MAX_LEN)\r\n---> 14 train(model)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    424     # This is the first call of __call__, so we have to initialize.\r\n    425     initializer_map = {}\r\n--> 426     self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n    427     if self._created_variables:\r\n    428       try:\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    368     self._concrete_stateful_fn = (\r\n    369         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 370             *args, **kwds))\r\n    371 \r\n    372     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   1311     if self._input_signature:\r\n   1312       args, kwargs = None, None\r\n-> 1313     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   1314     return graph_function\r\n   1315 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   1578           or call_context_key not in self._function_cache.missed):\r\n   1579         self._function_cache.missed.add(call_context_key)\r\n-> 1580         graph_function = self._create_graph_function(args, kwargs)\r\n   1581         self._function_cache.primary[cache_key] = graph_function\r\n   1582         return graph_function, args, kwargs\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   1510             arg_names=arg_names,\r\n   1511             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 1512             capture_by_value=self._capture_by_value),\r\n   1513         self._function_attributes)\r\n   1514 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    692                                           converted_func)\r\n    693 \r\n--> 694       func_outputs = python_func(*func_args, **func_kwargs)\r\n    695 \r\n    696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    315         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    316         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 317         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    318     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    319 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    684                   optional_features=autograph_options,\r\n    685                   force_conversion=True,\r\n--> 686               ), args, kwargs)\r\n    687 \r\n    688         # Wrapping around a decorator allows checks like tf_inspect.getargspec\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)\r\n    390     return _call_unconverted(f, args, kwargs)\r\n    391 \r\n--> 392   result = converted_f(*effective_args, **kwargs)\r\n    393 \r\n    394   # The converted function's closure is simply inserted into the function's\r\n\r\n/tmp/tmprqj3uekp.py in tf__train(model, epochs)\r\n     26     step_2, start_3 = ag__.for_stmt(ds, None, loop_body, (step_2, start_3))\r\n     27     return step_2, start_3\r\n---> 28   step, start = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (epochs,), {}), None, loop_body_1, (step, start))\r\n     29 \r\n     30 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in for_stmt(iter_, extra_test, body, init_state)\r\n     64   \"\"\"\r\n     65   if tensor_util.is_tensor(iter_):\r\n---> 66     return _known_len_for_stmt(iter_, extra_test, body, init_state)\r\n     67   elif isinstance(iter_, dataset_ops.DatasetV2):\r\n     68     # Check for undefined symbols and report an error. This prevents the error\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in _known_len_for_stmt(iter_, extra_test, body, init_state)\r\n    116       init_state=(0,) + init_state,\r\n    117       extra_deps=(iter_,),\r\n--> 118       opts=dict(maximum_iterations=n))\r\n    119 \r\n    120   # Dropping the iteration index because it's not syntactically visible.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in while_stmt(test, body, init_state, extra_deps, opts)\r\n    192           'to a Tensor, Variable or TensorArray before the loop: {}'\r\n    193           .format(tuple(undefined_symbols)))\r\n--> 194     return _tf_while_stmt(test, body, init_state, opts)\r\n    195   else:\r\n    196     return _py_while_stmt(test, body, init_state, opts)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in _tf_while_stmt(test, body, init_state, opts)\r\n    216   opts['return_same_structure'] = True\r\n    217 \r\n--> 218   retval = control_flow_ops.while_loop(test, body, init_state, **opts)\r\n    219   return retval\r\n    220 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\r\n   3401         maximum_iterations=maximum_iterations,\r\n   3402         name=name,\r\n-> 3403         return_same_structure=return_same_structure)\r\n   3404 \r\n   3405   with ops.name_scope(name, \"while\", loop_vars):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure)\r\n    171         func_graph=util.WhileBodyFuncGraph(\r\n    172             body_name, collections=ops.get_default_graph()._collections),  # pylint: disable=protected-access\r\n--> 173         add_control_dependencies=add_control_dependencies)\r\n    174     # Add external captures of body to the list of loop vars.\r\n    175     # Note that external tensors will be treated as loop invariants, i.e.,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    692                                           converted_func)\r\n    693 \r\n--> 694       func_outputs = python_func(*func_args, **func_kwargs)\r\n    695 \r\n    696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py in wrapped_body(loop_counter, maximum_iterations_arg, *args)\r\n    150       # `orig_loop_vars` and `args`, converts flows in `args` to TensorArrays\r\n    151       # and packs it into the structure of `orig_loop_vars`.\r\n--> 152       outputs = body(*_pack_sequence_as(orig_loop_vars, args))\r\n    153       if not nest.is_sequence(outputs):\r\n    154         outputs = [outputs]\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in while_body(iterate_index, *state)\r\n     98   def while_body(iterate_index, *state):\r\n     99     iterate = iter_[iterate_index]\r\n--> 100     new_state = body(iterate, *state)\r\n    101 \r\n    102     state = (iterate_index + 1,)\r\n\r\n/tmp/tmprqj3uekp.py in loop_body_1(loop_vars, step_2, start_3)\r\n     24       step_1 += 1\r\n     25       return step_1, start_2\r\n---> 26     step_2, start_3 = ag__.for_stmt(ds, None, loop_body, (step_2, start_3))\r\n     27     return step_2, start_3\r\n     28   step, start = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (epochs,), {}), None, loop_body_1, (step, start))\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in for_stmt(iter_, extra_test, body, init_state)\r\n     77           .format(tuple(undefined_symbols)))\r\n     78 \r\n---> 79     return _dataset_for_stmt(iter_, extra_test, body, init_state)\r\n     80   else:\r\n     81     return _py_for_stmt(iter_, extra_test, body, init_state)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in _dataset_for_stmt(ds, extra_test, body, init_state)\r\n    143 \r\n    144   if init_state:\r\n--> 145     return ds.reduce(init_state, reduce_body)\r\n    146 \r\n    147   # Workaround for Datset.reduce not allowing empty state tensors - create\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in reduce(self, initial_state, reduce_func)\r\n   1274           input_structure=structure_lib.NestedStructure(\r\n   1275               (state_structure, self._element_structure)),\r\n-> 1276           add_to_graph=False)\r\n   1277 \r\n   1278       # Extract and validate class information from the returned values.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\r\n   2386           ops.GraphKeys.TABLE_INITIALIZERS))\r\n   2387 \r\n-> 2388       self._function = wrapper_fn._get_concrete_function_internal()\r\n   2389       if add_to_graph:\r\n   2390         self._function.add_to_graph(ops.get_default_graph())\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal(self, *args, **kwargs)\r\n   1317     \"\"\"Bypasses error checking when getting a graph function.\"\"\"\r\n   1318     graph_function = self._get_concrete_function_internal_garbage_collected(\r\n-> 1319         *args, **kwargs)\r\n   1320     # We're returning this concrete function to someone, and they may keep a\r\n   1321     # reference to the FuncGraph without keeping a reference to the\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   1311     if self._input_signature:\r\n   1312       args, kwargs = None, None\r\n-> 1313     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   1314     return graph_function\r\n   1315 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   1578           or call_context_key not in self._function_cache.missed):\r\n   1579         self._function_cache.missed.add(call_context_key)\r\n-> 1580         graph_function = self._create_graph_function(args, kwargs)\r\n   1581         self._function_cache.primary[cache_key] = graph_function\r\n   1582         return graph_function, args, kwargs\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   1510             arg_names=arg_names,\r\n   1511             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 1512             capture_by_value=self._capture_by_value),\r\n   1513         self._function_attributes)\r\n   1514 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    692                                           converted_func)\r\n    693 \r\n--> 694       func_outputs = python_func(*func_args, **func_kwargs)\r\n    695 \r\n    696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in wrapper_fn(*args)\r\n   2379           attributes=defun_kwargs)\r\n   2380       def wrapper_fn(*args):  # pylint: disable=missing-docstring\r\n-> 2381         ret = _wrapper_helper(*args)\r\n   2382         ret = self._output_structure._to_tensor_list(ret)\r\n   2383         return [ops.convert_to_tensor(t) for t in ret]\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in _wrapper_helper(*args)\r\n   2324         nested_args = (nested_args,)\r\n   2325 \r\n-> 2326       ret = func(*nested_args)\r\n   2327       # If `func` returns a list of tensors, `nest.flatten()` and\r\n   2328       # `ops.convert_to_tensor()` would conspire to attempt to stack\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py in reduce_body(state, iterate)\r\n    139 \r\n    140   def reduce_body(state, iterate):\r\n--> 141     new_state = body(iterate, *state)\r\n    142     return new_state\r\n    143 \r\n\r\n/tmp/tmprqj3uekp.py in loop_body(loop_vars, step_1, start_2)\r\n     10     def loop_body(loop_vars, step_1, start_2):\r\n     11       x1, x2, target = loop_vars\r\n---> 12       loss = ag__.converted_call(train_one_step, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_3, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (model, x1, x2, target), {})\r\n     13       cond = step_1 % 10 == 0\r\n     14 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)\r\n    265 \r\n    266   if not options.force_conversion and conversion.is_whitelisted_for_graph(f):\r\n--> 267     return _call_unconverted(f, args, kwargs)\r\n    268 \r\n    269   # internal_convert_user_code is for example turned off when issuing a dynamic\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in _call_unconverted(f, args, kwargs)\r\n    186     return f.__self__.call(args, kwargs)\r\n    187 \r\n--> 188   return f(*args, **kwargs)\r\n    189 \r\n    190 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    436         # Lifting succeeded, so variables are initialized and we can run the\r\n    437         # stateless function.\r\n--> 438         return self._stateless_fn(*args, **kwds)\r\n    439     else:\r\n    440       canon_args, canon_kwds = self._canonicalize_function_inputs(args, kwds)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   1285   def __call__(self, *args, **kwargs):\r\n   1286     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n-> 1287     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   1288     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1289 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   1578           or call_context_key not in self._function_cache.missed):\r\n   1579         self._function_cache.missed.add(call_context_key)\r\n-> 1580         graph_function = self._create_graph_function(args, kwargs)\r\n   1581         self._function_cache.primary[cache_key] = graph_function\r\n   1582         return graph_function, args, kwargs\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   1510             arg_names=arg_names,\r\n   1511             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 1512             capture_by_value=self._capture_by_value),\r\n   1513         self._function_attributes)\r\n   1514 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    692                                           converted_func)\r\n    693 \r\n--> 694       func_outputs = python_func(*func_args, **func_kwargs)\r\n    695 \r\n    696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    315         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    316         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 317         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    318     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    319 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    684                   optional_features=autograph_options,\r\n    685                   force_conversion=True,\r\n--> 686               ), args, kwargs)\r\n    687 \r\n    688         # Wrapping around a decorator allows checks like tf_inspect.getargspec\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)\r\n    390     return _call_unconverted(f, args, kwargs)\r\n    391 \r\n--> 392   result = converted_f(*effective_args, **kwargs)\r\n    393 \r\n    394   # The converted function's closure is simply inserted into the function's\r\n\r\n/tmp/tmputhqh9oi.py in tf__train_one_step(model, x1, x2, target)\r\n      9     grad = ag__.converted_call('gradient', tape, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_3, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (loss, model.trainable_variables), {})\r\n     10     clipped_gradients, _ = ag__.converted_call('clip_by_global_norm', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_4, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (grad, 5), {})\r\n---> 11     ag__.converted_call('apply_gradients', optim, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_5, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (zip(grad, model.trainable_variables),), {})\r\n     12   do_return = True\r\n     13   retval_ = loss\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)\r\n    265 \r\n    266   if not options.force_conversion and conversion.is_whitelisted_for_graph(f):\r\n--> 267     return _call_unconverted(f, args, kwargs)\r\n    268 \r\n    269   # internal_convert_user_code is for example turned off when issuing a dynamic\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in _call_unconverted(f, args, kwargs)\r\n    186     return f.__self__.call(args, kwargs)\r\n    187 \r\n--> 188   return f(*args, **kwargs)\r\n    189 \r\n    190 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in apply_gradients(self, grads_and_vars, name)\r\n    397     var_list = [v for (_, v) in grads_and_vars]\r\n    398 \r\n--> 399     self._create_hypers()\r\n    400     with ops.init_scope():\r\n    401       self._create_slots(var_list)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in _create_hypers(self)\r\n    556             dtype=dtypes.int64,\r\n    557             trainable=False,\r\n--> 558             aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)\r\n    559         self._weights.append(self._iterations)\r\n    560     for name, value in self._hyper.items():\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in add_weight(self, name, shape, dtype, initializer, trainable, synchronization, aggregation)\r\n    725         use_resource=True,\r\n    726         synchronization=synchronization,\r\n--> 727         aggregation=aggregation)\r\n    728     backend.track_variable(variable)\r\n    729 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\r\n    620     new_variable = getter(\r\n    621         name=name, shape=shape, dtype=dtype, initializer=initializer,\r\n--> 622         **kwargs_for_getter)\r\n    623 \r\n    624     # If we set an initializer and the variable processed it, tracking will not\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\r\n    150       collections=collections,\r\n    151       synchronization=synchronization,\r\n--> 152       aggregation=aggregation)\r\n    153   return v\r\n    154 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    210   def __call__(cls, *args, **kwargs):\r\n    211     if cls is VariableV1:\r\n--> 212       return cls._variable_v1_call(*args, **kwargs)\r\n    213     elif cls is Variable:\r\n    214       return cls._variable_v2_call(*args, **kwargs)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation)\r\n    173         use_resource=use_resource,\r\n    174         synchronization=synchronization,\r\n--> 175         aggregation=aggregation)\r\n    176 \r\n    177   def _variable_v2_call(cls,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in getter(**kwargs)\r\n     56   \"\"\"To avoid capturing loop variables.\"\"\"\r\n     57   def getter(**kwargs):\r\n---> 58     return captured_getter(captured_previous, **kwargs)\r\n     59   return getter\r\n     60 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in invalid_creator_scope(*unused_args, **unused_kwds)\r\n    373       \"\"\"Disables variable creation.\"\"\"\r\n    374       raise ValueError(\r\n--> 375           \"tf.function-decorated function tried to create \"\r\n    376           \"variables on non-first call.\")\r\n    377 \r\n\r\nValueError: tf.function-decorated function tried to create variables on non-first call.\r\n```\r\n", "The following will not work:\r\n\r\n```\r\n@tf.function\r\ndef train_one_step(model,x1,x2,target):\r\n    optim = optimizers.Adam(0.001)  #this line means you'll try to create variables after the first call, which is not allowed\r\n    with tf.GradientTape() as tape:\r\n        y = model(x1,x2)\r\n        loss = model.loss(y,target)\r\n        grad = tape.gradient(loss,model.trainable_variables)\r\n        clipped_gradients, _ = tf.clip_by_global_norm(grad,5)\r\n        optim.apply_gradients(zip(grad, model.trainable_variables))\r\n    return loss\r\n```\r\n\r\nHowever the following should work:\r\n\r\n```\r\noptim = optimizers.Adam(0.001)\r\n\r\n@tf.function\r\ndef train_one_step(model,x1,x2,target):\r\n    with tf.GradientTape() as tape:\r\n        y = model(x1,x2)\r\n        loss = model.loss(y,target)\r\n    grad = tape.gradient(loss,model.trainable_variables)\r\n    clipped_gradients, _ = tf.clip_by_global_norm(grad,5)\r\n    optim.apply_gradients(zip(grad, model.trainable_variables))\r\n    return loss\r\n```", "I got the same error, because I forgot to initialize the model. \r\n`model.build(input_shape=(batch_size, sequence_length))` fixed it.", "Same issue. Initializing the model is irrelevant. I did the .build method. Still not working.", "You might need to initialize the optimizers as well.\n\nOn Tue, Jun 11, 2019 at 12:54 AM Alex <notifications@github.com> wrote:\n\n> Same issue. Initializing the model is irrelevant. I did the .build method.\n> Still not working.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/27120?email_source=notifications&email_token=AAABHRIAMEYBSTCDVXKJPITPZ5K2TA5CNFSM4HBFNUM2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXMH4VA#issuecomment-500727380>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRKPJ54MD6Z47KQGZG3PZ5K2TANCNFSM4HBFNUMQ>\n> .\n>\n\n\n-- \n - Alex\n", "I solved it, or at least I knew how to go around it. When I run everything for the first time, no problem at all. But, when I attempt to instantiate a second neural net model, the error shows up as soon as I start training. The reason is because of train_one_step() function is decorated with @tf.function and it takes in the model as an input. So, I need to redefine it to build a graph for the new model and everything will work.\r\nAdditionally, my train_one_step has got various training mode inside it. As I start with the first mode, everything is ok.  But, when I decide to switch to other mode, I get the error:\r\ntf.function-decorated function tried to create variables on non-first call \r\nTo fix it, I just re run the definition of train_one_step just like I did before. My simple understanding is that the graph is not complete and it is built only once when you define the function.\r\nFinally, for completion, you said I have to initialize the optimizers, how can I do that? this is not something I'm aware of or I usually do.\r\nThanks", "calling apply_gradients on an optimizer for the first time will create its\ninternal variables. Sadly there's currently no public API to just\ninitialize the optimizer state but not update\n\nOn Tue, Jun 11, 2019 at 11:48 AM Alex <notifications@github.com> wrote:\n\n> I solved it, or at least I knew how to go around it. When I run everything\n> for the first time, no problem at all. But, when I attempt to instantiate a\n> second neural net model, the error shows up as soon as I start training.\n> The reason is because of train_one_step() function is decorated with\n> @tf.function and it takes in the model as an input. So, I need to redefine\n> it to build a graph for the new model and everything will work.\n> Additionally, my train_one_step has got various training mode inside it.\n> As I start with the first mode, everything is ok. But, when I decide to\n> switch to other mode, I get the error:\n> tf.function-decorated function tried to create variables on non-first call\n> To fix it, I just re run the definition of train_one_step just like I did\n> before. My simple understanding is that the graph is not complete and it is\n> built only once when you define the function.\n> Finally, for completion, you said I have to initialize the optimizers, how\n> can I do that? this is not something I'm aware of or I usually do.\n> Thanks\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/27120?email_source=notifications&email_token=AAABHRPODLD7YZL7LVTQDB3PZ7XOHA5CNFSM4HBFNUM2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXODNLY#issuecomment-500971183>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRMAYJ3FJJYUCHBIFE3PZ7XOHANCNFSM4HBFNUMQ>\n> .\n>\n\n\n-- \n - Alex\n", "this issue happened to us while doing hyperparameter optimization with skopt -- the first model works. second model crashes because Adam makes variables.", "if we can't re-make Adam because tf.function cannot handle this, how do we change the learning rate hyperparameter?", "well, fixed it by putting the definition of the run_step @tf.function inside the definition of the trial function... this forces it to retrace every time we run a new model with new hyperparameters, but it would be ideal if we didn't have to re-build a whole function graph just so we can change 1 floating point learning rate number!", "@bionicles\r\nYou're correct. This forced me to redesign my nerual net such that the hyperparamters are actually inputs just like the data. :( it is really inconvenient.", "> The following will not work:\r\n> \r\n> ```\r\n> @tf.function\r\n> def train_one_step(model,x1,x2,target):\r\n>     optim = optimizers.Adam(0.001)  #this line means you'll try to create variables after the first call, which is not allowed\r\n>     with tf.GradientTape() as tape:\r\n>         y = model(x1,x2)\r\n>         loss = model.loss(y,target)\r\n>         grad = tape.gradient(loss,model.trainable_variables)\r\n>         clipped_gradients, _ = tf.clip_by_global_norm(grad,5)\r\n>         optim.apply_gradients(zip(grad, model.trainable_variables))\r\n>     return loss\r\n> ```\r\n> \r\n> However the following should work:\r\n> \r\n> ```\r\n> optim = optimizers.Adam(0.001)\r\n> \r\n> @tf.function\r\n> def train_one_step(model,x1,x2,target):\r\n>     with tf.GradientTape() as tape:\r\n>         y = model(x1,x2)\r\n>         loss = model.loss(y,target)\r\n>     grad = tape.gradient(loss,model.trainable_variables)\r\n>     clipped_gradients, _ = tf.clip_by_global_norm(grad,5)\r\n>     optim.apply_gradients(zip(grad, model.trainable_variables))\r\n>     return loss\r\n> ```\r\n\r\nWhat you've done is basically taking the optimizer out of the train_one_step function. Suppose that I want to change the learning rate after each step, do you recommend doing it oustide, then, passing the optimizer as an argument to train_one_step ?", "Is there any progress on this? I currently have a training function that takes an optimizer and a NN model as input. It works fine when running it the first time after declaring the tf_function. However, on subsequent runs (with a new optimizer and network) it fails to run due to the reasons above, I believe.\r\n\r\nIf the training function encounters a new optimizer or model, the optimizer creates a new variable, which is not allowed inside the @tf.function decorator. As suggested above, an easy hotfix is to run apply_gradients with the new optimizer or model before passing it to the decorated function.", "> I solved it, or at least I knew how to go around it. When I run everything for the first time, no problem at all. But, when I attempt to instantiate a second neural net model, the error shows up as soon as I start training. The reason is because of train_one_step() function is decorated with @tf.function and it takes in the model as an input. So, I need to redefine it to build a graph for the new model and everything will work.\r\n> Additionally, my train_one_step has got various training mode inside it. As I start with the first mode, everything is ok. But, when I decide to switch to other mode, I get the error:\r\n> tf.function-decorated function tried to create variables on non-first call\r\n> To fix it, I just re run the definition of train_one_step just like I did before. My simple understanding is that the graph is not complete and it is built only once when you define the function.\r\n> Finally, for completion, you said I have to initialize the optimizers, how can I do that? this is not something I'm aware of or I usually do.\r\n> Thanks\r\n\r\nHi, could you please show your solution detailedly? Thanks.", "A related minimal example:\r\n\r\n```python\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense\r\n\r\n@tf.function\r\ndef model(inputs):\r\n  outs = Dense(5)(inputs)\r\n  return outs\r\n\r\nmodel(tf.constant([[1.,2.],[3.,4.]]))\r\n```\r\n\r\nThis works as expected without `tf.function`, but as written gives \r\n```ValueError: tf.function-decorated function tried to create variables on non-first call.```\r\n This issue somehow seems related to https://github.com/tensorflow/tensorflow/issues/23873. ", "Sorry to exhume this thread, but I would just like to detail my solution for this.\r\n\r\nI wanted to use the same function for training multiple models, but when I ran the @tf.function function on a second model, the error above appeared. I didn't want to initialise the function every time (essentially eager execution), but just wanted the function initialized for each different model.\r\n\r\nSo I made a wrapper function like:\r\n```\r\ndef get_apply_grad_fn():\r\n    @tf.function\r\n    def apply_grad(X, Y, model, loss_fn, optimizer):\r\n        with tf.GradientTape() as t:\r\n\r\n            output = model(X)\r\n\r\n            loss = loss_fn(Y, output)\r\n\r\n        grads = t.gradient(loss, model.trainable_weights)\r\n\r\n        optimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n\r\n        return loss\r\n    return apply_grad\r\n```\r\n\r\nand then for each model, I call this function like:\r\n```\r\nmodel1_apply_grads = get_apply_grad_fn()\r\nmodel2_apply_grads = get_apply_grad_fn()\r\n```\r\n\r\nwhich I can then call like so:\r\n```\r\nloss1 = model1_apply_grads(X1, Y1, model1, loss_fn1, optimizer1)\r\nloss2 = model2_apply_grads(X2, Y2, model2, loss_fn2, optimizer2)\r\n```\r\n\r\nI think this just reiterates some of the suggestions from above, but with explicit examples.", "Peter: Thanks for the example.\n\nJames: your code is broken; it creates a new Dense layer every time it's\ncalled, so it's not a thing you could ever use to train a model, etc.\n\nOn Wed, Oct 9, 2019 at 9:16 AM James McKeown <notifications@github.com>\nwrote:\n\n> A related minimal example:\n>\n> import tensorflow as tffrom tensorflow.keras.layers import Dense\n> @tf.functiondef model(inputs):\n>   outs = Dense(5)(inputs)\n>   return outs\n>\n> model(tf.constant([[1.,2.],[3.,4.]]))\n>\n> This works as expected without tf.function, but as written gives\n> ValueError: tf.function-decorated function tried to create variables on\n> non-first call.\n> This issue somehow seems related to #23873\n> <https://github.com/tensorflow/tensorflow/issues/23873>.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/27120?email_source=notifications&email_token=AAABHRNO47Q2LWXCOOE5STLQNX7VXA5CNFSM4HBFNUM2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEAYNL7Q#issuecomment-540071422>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRO6WF3MNX5NN2CJ7WTQNX7VXANCNFSM4HBFNUMQ>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp That makes perfect sense.  I guess I needed some wrapping too:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense\r\n\r\ndef create_model():\r\n  d = Dense(5)\r\n  @tf.function\r\n  def model(inputs):\r\n      outs = d(inputs)\r\n      return outs\r\n  return model\r\n\r\nmodel = create_model()\r\nmodel(tf.constant([[1.,2.],[3.,4.]]))\r\n```", "I have tried wrapping the functions as @Peter-Devine and it works but with a huge performance penalty. My training time increases by 5-6x if I wrap the functions.", "@ldm314 Yeah, my performance is also pretty slow, which does seem to negate some of the benefits of using TF over PT", "@Peter-Devine I am unable to find where the variable itself is being created. At the start of the 2nd epoch I would get this error every time. The slow performance came by calling the wrapped function on every batch. \r\n\r\nToday I tried using the wrapped function to create the train function on each epoch instead of each batch. It solved the issue without the performance problem.\r\n\r\n", "@alextp does this bug solved, or the issue still persist", "I'm using TF 2.1 now, still not fixed. I cannot use @tf.function-decorated train_step function with different optimizer(actually, with different hyper-parameters). One trivial solution is to halt and re-run train.py followed by loading weights when you change hyper-parameters. TF is so confusing :(", "@ldm314 It would be better to run the wrapper function only when necessary.\r\n\r\n```python\r\ndef wrapper(nn_model, loss_func, optimiser):\r\n    @tf.function\r\n    def train_one_batch(x_train, y_train, w_train):\r\n        with tf.GradientTape() as tape:\r\n            y_pred = nn_model(x_train)\r\n            loss = loss_func(y_true=y_train, y_pred=y_pred, sample_weight=w_train)\r\n            total_loss = loss + tf.math.add_n(nn_model.losses)\r\n        grads = tape.gradient(total_loss, nn_model.trainable_variables)\r\n        optimiser.apply_gradients(grads_and_vars=zip(grads, nn_model.trainable_variables))\r\n        return y_pred, total_loss\r\n    return train_one_batch\r\n\r\nfor x_train, y_train, w_train in training_dataset:\r\n    try:\r\n        y_pred, total_loss = train_one_batch(x_train, y_train, w_train)\r\n    except (UnboundLocalError, ValueError):\r\n        # UnboundLocalError: Raised when a reference is made to a local\r\n        #   variable in a function or method, but no value has been\r\n        #   bound to that variable.\r\n        # ValueError:\r\n        #   https://github.com/tensorflow/tensorflow/issues/27120\r\n        # Either case we need to define the train_one_batch function for a\r\n        #   new graph.\r\n        train_one_batch = wrapper(nn_model, loss_func, optimiser)\r\n        y_pred, total_loss = train_one_batch(x_train, y_train, w_train)\r\n```", "I use vanilla configuration:\r\n\r\n- MacOS 10.12\r\n- python 3.7\r\n- tensorflow 2.1.0 installed with pip\r\n\r\nIt seems that the minimal example is still lacking in the thread. Passing optimizers inside \r\n`@tf.function` decorator appears problematic as the following example shows:\r\n```python\r\nopt1 = tf.keras.optimizers.Adam(learning_rate = 1e-2)\r\nopt2 = tf.keras.optimizers.Adam(learning_rate = 1e-2) # could use 1e-3\r\n\r\n@tf.function\r\ndef train_step_with_opt(a, x, y, optimizer):\r\n    print('retracing')\r\n    with tf.GradientTape() as tape:\r\n        L = tf.reduce_sum(tf.square(a*x - y))\r\n\r\n    tr_weights = [a]\r\n    gradients = tape.gradient(L, tr_weights)\r\n    optimizer.apply_gradients(zip(gradients, tr_weights))\r\n\r\n    return a\r\n\r\na = tf.Variable(2.)\r\nx = tf.Variable([-1.,-1.,-1.], dtype = tf.float32)\r\ny = tf.Variable([2.,2.,2.], dtype = tf.float32)\r\n\r\ntrain_step_with_opt(a, x, y, opt1) # works, but retraced twice for a single initial call\r\ntrain_step_with_opt(a, x, y, opt2) # fails\r\n```\r\nThe state of an optimizer is a collection of tensors, so it should be possible to wrap functions as above with `tf.function` and have them being retraced only once on a call for \"similar\" optimizers (as above).\r\n\r\nAlso I am confused why the first function call is retraced twice (from `print('retracing')`).", "My call method in my custom layer is as follows\r\n\r\n\r\n```\r\n def call(self, y):\r\n            self.y=y\r\n           self.paddings = [[0,0],[0, 10-tf.shape(self.y)[0]]]\r\n            self.out = tf.pad(self.y,self.paddings, 'CONSTANT', constant_values=2)\r\n            self.x =tf.map_fn(lambda xi: tf.strings.format('{}', xi), self.out, dtype=tf.string)\r\n            # print(x)\r\n            self.b= tf.compat.v1.string_split(self.x)\r\n            self.b=tf.sparse.to_dense(self.b)\r\n            #print(b)\r\n            self.b= tf.compat.v1.strings.to_number(self.b,tf.int32)\r\n            self.S =  tf.Variable(lambda :tf.reshape((tf.gather((tf.reshape(self.kernels, [-1])),(self.b))), (400, \r\n                                      400)),trainable=True)\r\n            #self.S=tf.convert_to_tensor(self.S)\r\n            self._trainable_weights = [self.S]\r\n            self.y= tf.cast(self.y, tf.float64)\r\n            \r\n            \r\n            return K.dot(tf.identity(self.y),tf.identity(self.S))\r\n```\r\n\r\n\r\nThe code gives me the same error thats mentioned in the title of this thread.", "I know there's been a workaround suggested, but it didn't work, so does anyone have ideas for my situation?\r\n\r\nMy issue is that I need to create three different instances of the same class (I'm not using Keras) for a single training run. I tried to use a wrapper function like the following:\r\n```python\r\nclass MyModel(tf.Module):\r\n    def __init__(self, name, K, N, L, initial_weights=None):\r\n        super(MyModel, self).__init__(name=name)\r\n        self.name = name\r\n        self.type = 'basic'\r\n        with tf.name_scope(name):\r\n            self.K = tf.constant(K)\r\n            self.N = tf.constant(N)\r\n            self.L = tf.constant(L)\r\n            self.W = MyModel.get_initial_weights()(K, N, L, initial_weights)\r\n\r\n    @staticmethod\r\n    def get_initial_weights():\r\n        @tf.function\r\n        def get_initial_weights_inner(K, N, L, initial_weights):\r\n            if initial_weights is not None:\r\n                return initial_weights\r\n            else:\r\n                return tf.Variable(tf.random.uniform((K, N), minval=-L, maxval=L + 1, dtype=tf.int64), trainable=True)\r\n        return get_initial_weights_inner\r\n```\r\nThis didn't solve the problem\u2014now the error is occurring at `return tf.Variable(tf.random.uniform((K, N), minval=-L, maxval=L + 1, dtype=tf.int64), trainable=True)`. ", "> I know there's been a workaround suggested, but it didn't work, so does anyone have ideas for my situation?\r\n> \r\n> My issue is that I need to create three different instances of the same class (I'm not using Keras) for a single training run. I tried to use a wrapper function like the following:\r\n> \r\n> ```python\r\n> class MyModel(tf.Module):\r\n>     def __init__(self, name, K, N, L, initial_weights=None):\r\n>         super(MyModel, self).__init__(name=name)\r\n>         self.name = name\r\n>         self.type = 'basic'\r\n>         with tf.name_scope(name):\r\n>             self.K = tf.constant(K)\r\n>             self.N = tf.constant(N)\r\n>             self.L = tf.constant(L)\r\n>             self.W = MyModel.get_initial_weights()(K, N, L, initial_weights)\r\n> \r\n>     @staticmethod\r\n>     def get_initial_weights():\r\n>         @tf.function\r\n>         def get_initial_weights_inner(K, N, L, initial_weights):\r\n>             if initial_weights is not None:\r\n>                 return initial_weights\r\n>             else:\r\n>                 return tf.Variable(tf.random.uniform((K, N), minval=-L, maxval=L + 1, dtype=tf.int64), trainable=True)\r\n>         return get_initial_weights_inner\r\n> ```\r\n> \r\n> This didn't solve the problem\u2014now the error is occurring at `return tf.Variable(tf.random.uniform((K, N), minval=-L, maxval=L + 1, dtype=tf.int64), trainable=True)`.\r\n\r\nThe ``return`` statement the error occurs at will create a new ``tf.Variable``, and this is disallowed in a function decorated with ``tf.function`` in eager mode. You can read more about it [here](https://www.tensorflow.org/tutorials/customization/performance#variables). I don't think your function needs to be decorated with ``tf.function`` because it's not a too heavy computing operation to be converted to a graph. So you may remove the decorator to make it work.\r\n\r\n\r\n\r\n> It would be better to run the wrapper function only when necessary.\r\n> \r\n> ```python\r\n> def wrapper(nn_model, loss_func, optimiser):\r\n>     @tf.function\r\n>     def train_one_batch(x_train, y_train, w_train):\r\n>         with tf.GradientTape() as tape:\r\n>             y_pred = nn_model(x_train)\r\n>             loss = loss_func(y_true=y_train, y_pred=y_pred, sample_weight=w_train)\r\n>             total_loss = loss + tf.math.add_n(nn_model.losses)\r\n>         grads = tape.gradient(total_loss, nn_model.trainable_variables)\r\n>         optimiser.apply_gradients(grads_and_vars=zip(grads, nn_model.trainable_variables))\r\n>         return y_pred, total_loss\r\n>     return train_one_batch\r\n> \r\n> for x_train, y_train, w_train in training_dataset:\r\n>     try:\r\n>         y_pred, total_loss = train_one_batch(x_train, y_train, w_train)\r\n>     except (UnboundLocalError, ValueError):\r\n>         # UnboundLocalError: Raised when a reference is made to a local\r\n>         #   variable in a function or method, but no value has been\r\n>         #   bound to that variable.\r\n>         # ValueError:\r\n>         #   https://github.com/tensorflow/tensorflow/issues/27120\r\n>         # Either case we need to define the train_one_batch function for a\r\n>         #   new graph.\r\n>         train_one_batch = wrapper(nn_model, loss_func, optimiser)\r\n>         y_pred, total_loss = train_one_batch(x_train, y_train, w_train)\r\n> ```\r\n\r\nBeside the wrapper workaround approach for avoiding ``UnboundLocalError`` or ``ValueError`` exceptions, I also suggest a different approach, which is using explicitly the ``tf.function()`` instead of  ``@tf.function``. For example:\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ndef _train(model, x, y, optimizer):\r\n    \"\"\"A normal Python function which should be taken care of to make it convertible into\r\n    a graph.\r\n    Read more here: https://www.tensorflow.org/tutorials/customization/performance\r\n    \"\"\"\r\n    pass\r\ntrain = tf.function(_train) # should use a new name so `_train` can be reused\r\n...\r\n# when using, do a try catch:\r\ntry:\r\n   train(model, x, y, optimizer)\r\nexcept (UnboundLocalError, ValueError):\r\n   # recreates the decorated function\r\n   train = tf.function(_train)\r\n   # the old graph will be ignored and a new workable graph will be created\r\n   train(model, x, y, optimizer)\r\n```", "Wrapping @tf.function() within a function does not work as fast as it's outside of function.\r\n\r\nI'm using Bayesian-Opt right now, wrap it as a function is the only way to do it.\r\n\r\nIs there any other param tuning solution could be adopted both fast and sound?\r\n\r\n", "Here my ideas for various problems brought up in this thread, if folks are still blocked. The original bug still remains, but these workarounds may be valuable for the time being.\r\n\r\n---\r\n1) @ericpts: To train your model with both fast_optimizer and slow_optimizer:\r\n\r\n```\r\n@tf.function\r\ndef apply_gradients_fast(grads, vars):\r\n    grads = [grads]\r\n    fast_optimizer.apply_gradients(zip(grads, vars))\r\n\r\n@tf.function\r\ndef apply_gradients_slow(grads, vars):\r\n    grads = [grads]\r\n    slow_optimizer.apply_gradients(zip(grads, vars))\r\n\r\ndef apply_grads(use_fast, grads_per_model, vars):\r\n    for i in range(2):\r\n        if use_fast[i]:\r\n            apply_gradients_fast(grads_per_model[i], vars[i])\r\n        else:\r\n            apply_gradients_slow(grads_per_model[i], vars[i])\r\n```\r\n\r\nThis is equivalent to:\r\n```\r\n# not a tf.function\r\ndef apply_gradients_once(optimizer, grads, vars):\r\n  ...\r\n\r\napply_gradients_fast = tf.function(apply_gradients_once)\r\napply_gradients_slow = tf.function(apply_gradients_once)\r\n\r\ndef apply_grads(use_fast, grads_per_model, vars):\r\n    for i in range(2):\r\n        if use_fast[i]:\r\n            apply_gradients_fast(fast_optimizer, grads_per_model[i], vars[i])\r\n        else:\r\n            apply_gradients_slow(slow_optimizer, grads_per_model[i], vars[i])\r\n\r\n```\r\nThis would do a similar amount of tracing as decorating `apply_grads` with `tf.function` and passing in a Tensor of booleans as suggested by Alex and Allen:\r\n\r\n```\r\n@tf.function\r\ndef apply_grads(use_fast, grads_per_model, vars):\r\n...\r\n\r\napply_grads(tf.constant([False, True]), grads, vars) \r\napply_grads([True, False], grads, vars) #this works\r\n```\r\nThe suggestion to pass in Tensor arguments is documented here [1]: \"Caution: Passing python scalars or lists as arguments to tf.function will always build a new graph. To avoid this, pass numeric arguments as Tensors whenever possible.\"\r\n\r\n---\r\n2) @bionicles, @thisismygitrepo : Regarding changing the learning rate of your optimizer, it is unfortunate that you cannot instantiate an optimizer with a new learning rate and pass that into the same `tf.function`.  It may be a good idea instead to look at the learning rate scheduler in Keras [2] which would automatically tune the learning rate based on number of steps.\r\n\r\n@sondrewb: If you have a new model, I think it makes sense to recreate the graph traced since the model's architecture may be different.  When you encounter a new model, you can force retracing by creating a new tf.function\r\n\r\n```\r\n# not tf.function\r\ndef train_step(model, X, Y):\r\n...\r\n\r\nmodel_1= Model()\r\ntrain_1 = tf.function(train_step)\r\ntrain_1(model1, X, Y)\r\nmodel_2= Model()\r\ntrain_2 = tf.function(train_step)\r\ntrain_2(model2, X, Y)\r\n```\r\nas it is documented in https://www.tensorflow.org/guide/function#controlling_retracing. \r\n\r\n---\r\n3) @mckeown12 : Your example does a good job of reproducing this error. In this case, I think the error you encounter is intended behavior, as the Keras Dense layer creates variables after it is called.\r\n\r\n```\r\nd = Dense(5)\r\nprint(d.variables)\r\n> []\r\nd(tf.constant([[1.,2.],[3.,4.]]))\r\nprint(d.variables)\r\n> [<tf.Variable 'dense/kernel:0' shape=(2, 5) dtype=float32, numpy=...]\r\n```\r\n---\r\n4) Re using the wrapper function that @Peter-Devine suggested, the wrapper should work. I'm not sure why it is incurring a 5-6x performance penalty-- could you be retracing more than necessary @ldm314 ? (make sure you pass in Tensors as X and Y, see [3] for more tips ) If you use the wrapper correctly, it should only trigger tracing once for each model and that trace will be reused for all subsequent calls. \r\n\r\nThe following is the equivalent to the wrapper:\r\n```\r\n# not a tf.function\r\ndef apply_grad(X, Y, model, loss_fn, optimizer):\r\n    ...\r\n\r\nmodel1_apply_grads = tf.function(apply_grad)\r\nmodel2_apply_grads =tf.function(apply_grad)\r\n\r\nloss1 = model1_apply_grads(X1, Y1, model1, loss_fn1, optimizer1)\r\nloss2 = model2_apply_grads(X2, Y2, model2, loss_fn2, optimizer2)\r\n```\r\n\r\nAn alternative workaround is to define functions for each set of models, optimizers, and loss functions:\r\n\r\n```\r\n@tf.function\r\ndef apply_grad_1(X, Y):\r\n      with tf.GradientTape() as t:\r\n            output = model1(X)\r\n            loss = loss_fn1(Y, output)\r\n      grads = t.gradient(loss, model1.trainable_weights)\r\n      optimizer1.apply_gradients(zip(grads, model1.trainable_weights))\r\n      return loss\r\n  \r\n@tf.function\r\ndef apply_grad_2(X, Y):\r\n      with tf.GradientTape() as t:\r\n            output = model2(X)\r\n            loss = loss_fn2(Y, output)\r\n      grads = t.gradient(loss, model2.trainable_weights)\r\n      optimizer2.apply_gradients(zip(grads, model2.trainable_weights))\r\n      return loss\r\n\r\n```\r\n---\r\n\r\n5) @Flomastruk: It is true that the state of an optimizer is a collection of tensors; however, the state of `opt2` is not the same as the state of `opt1` and therefore would need a different set of tensors to track its state. Again, the workaround here is to define two separate `tf.function`-decorated train steps, one for each optimizer.\r\n\r\n'retracing' is printed twice, I believe, because \"under the hood\", tf.function attempts to convert your stateful function into a stateless function and if it detects that variables were created in tracing the graph, it attempts to recreate a graph without those variables. (I may be wrong on that one). \r\n\r\n---\r\n\r\n6) Re parameter tuning, if you are looking to change your model hyperparameters, I would create trace a new graph for each model you try. This sounds reasonable to me because you only have to pay the cost of tracing once for each set of hyperparameters. From [4]: \"Tracing costs some overhead. Although tracing small functions is quick, large models can take noticeable wall-clock time to trace. This investment is usually quickly paid back with a performance boost, but it's important to be aware that the first few epochs of any large model training can be slower due to tracing.\"\r\n\r\n---\r\nI hope this clears up some of the confusion in this thread! Hopefully in the future, it will be possible to pass in an optimizer or model without seeing this error :)\r\n\r\n[1] https://www.tensorflow.org/api_docs/python/tf/function\r\n[2] https://keras.io/api/optimizers/learning_rate_schedules/\r\n[3] https://www.tensorflow.org/guide/function#controlling_retracing\r\n[4] https://www.tensorflow.org/guide/intro_to_graphs#tracing_and_performance\r\n\r\n", "I'll have a quick look at the issue of reusing an optimizer - the error is surprising to me.", "I'm getting the same error on the last line generator.save(). From the mentioned workarounds I'm not sure how to apply to this, does anyone have a suggestion for this situation?\r\n\r\n```\r\ndef train(dataset, generator, discriminator, recognizer, composite_gan, checkpoint, checkpoint_prefix,\r\n          generator_optimizer, discriminator_optimizer, recognizer_optimizer, seed_labels, buffer_size, batch_size,\r\n          epochs, model_path, latent_dim, gen_path, loss_fn, disc_iters, random_words, bucket_size, char_vector):\r\n\r\n    batch_per_epoch = int(buffer_size / batch_size) + 1\r\n\r\n    print('training...')\r\n    for epoch_idx in range(epochs):\r\n        start = time.time()\r\n\r\n        for batch_idx in range(batch_per_epoch):\r\n            image_batch, label_batch = next(dataset)\r\n\r\n            train_step(epoch_idx, batch_idx, batch_per_epoch, image_batch, label_batch, discriminator, recognizer,\r\n                       composite_gan, generator_optimizer, discriminator_optimizer, recognizer_optimizer, batch_size,\r\n                       latent_dim, loss_fn, disc_iters, random_words, bucket_size)\r\n\r\n        # Produce images for the GIF as we go\r\n        generate_and_save_images(generator, epoch_idx + 1, seed_labels, gen_path, char_vector)\r\n\r\n        # Save the model every 5 epochs\r\n        if (epoch_idx + 1) % 5 == 0:\r\n            checkpoint.save(file_prefix=checkpoint_prefix)\r\n\r\n        print('Time for epoch {} is {} sec'.format(epoch_idx + 1, time.time() - start))\r\n\r\n    # save generator model\r\n    if not os.path.exists(model_path):\r\n        os.makedirs(model_path)\r\n\r\n    generator.save(model_path + 'generator_{}'.format(epochs), save_format='tf') \r\n```\r\nError: (left out the middle part)\r\n```\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 101, in <module>\r\n    main()\r\n  File \"main.py\", line 94, in main\r\n    latent_dim, gen_path, loss_fn, disc_iters, random_words, bucket_size, char_vec)\r\n  File \"/workspace/gan/src/bigacgan/data_utils.py\", line 145, in train\r\n    generator.save(model_path + 'generator_{}'.format(epochs), save_format='tf')\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", l\r\nine 1008, in save\r\n    signatures, options)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line\r\n 115, in save_model\r\n    signatures, options)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/sa\r\nve.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line \r\n886, in save\r\n    checkpoint_graph_view)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_seria\r\nlization.py\", line 74, in find_function_to_export\r\n    functions = saveable_view.list_functions(saveable_view.root)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line \r\n142, in list_functions\r\n    self._serialization_cache)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\"\r\n\r\n[...]\r\n\r\n    shape=variable_shape if variable_shape else None)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 258\r\n, in __call__\r\n    return cls._variable_v1_call(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 219\r\n, in _variable_v1_call\r\n    shape=shape)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 65,\r\n in getter\r\n    return captured_getter(captured_previous, **kwargs)\r\n  File \"/root/anaconda3/envs/env_gan/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", lin\r\ne 502, in invalid_creator_scope\r\n    \"tf.function-decorated function tried to create \"\r\nValueError: tf.function-decorated function tried to create variables on non-first call.\r\n```", "Problem solved for me if I set \"run_eagerly=True\" \r\nmodel.compile(..., run_eagerly=True)", "Hi @annaiart you need to check the definition of `generator`. It seems somewhere in it a `tf.Variable` is unconditionally created, which is not allowed by `tf.function` (and `.save` which uses the same mechanism as `tf.function` internally). Perhaps somewhere in your custom-defined Keras layer?", "Hi, for the following simple test example, in which I use conv1D op (I cannot use conv2D op for my project), I get the same error:\r\n\r\n`import tensorflow as tf`\r\n\r\n`input_shape = (1, 7, 1)`\r\n`x = tf.random.normal(input_shape)`\r\n\r\n`@tf.function`\r\n`def convol1d():`\r\n    `y=tf.keras.layers.Conv1D(1, 3,\r\n      input_shape=input_shape[1:],name=\"Conv1D\")(x)`\r\n       `return y`\r\n\r\n`data = convol1d()`\r\n`print(\"\\n\\n data is:\", data)`\r\n\r\n`tflite_model_name = 'convol1d'`\r\n`converter= tf.lite.TFLiteConverter.from_concrete_functions([convol1d.get_concrete_function()])`\r\n`converter.allow_custom_ops = True`\r\n`tflite_model = converter.convert()`\r\n`open(tflite_model_name + '.tflite', 'wb').write(tflite_model)`\r\n\r\nThe same error also appears when I try to use conv2D operator (by using another input x).", "You can't unconditionally create a Keras layer in `tf.function`, because the layer creates variables inside it. You have to either move the `y = tf.keras.layers.Conv1D(...)` line outside `tf.function`, or guard it by an `if`:\r\n```\r\ny = None\r\n@tf.function\r\ndef convol1d():\r\n  global y\r\n  if y is None:\r\n    y = tf.keras.layers.Conv1D(...)\r\n  ...\r\n```\r\n", "Thanks for your reply @wangpengmit: I guarded it by an if; however now I get this error:\r\n\r\n`ValueError: Failed to import metagraph, check error log for more info.`\r\n\r\nAt the end I would expect it instead:\r\n\r\n`Error: Didn't find custom operator for name 'Conv1D'.\r\nRegistration failed.`\r\n\r\nIf this latter error appeared, I would try to define a custom operator for conv1D op.", "That seems an unrelated bug. Please file a separate bug for it.", "I woud like to parametrize my custom training loop training step method with the model type:\r\n- `train_model` when running only the forward and backward on the `loss`\r\n- `eval_model` when computing several metrics in addition to running forward and backward on the loss.\r\n\r\nI face this error when I'm adding `model` on which the step should be performed in `_train_step`.\r\n\r\nIs it related to this issue? Why can't `tf.function` understand the branching that occurs and create two different graphs?\r\n\r\n```\r\n    @staticmethod\r\n    @tf.function\r\n    def _train_step(inputs, model, optimizer):\r\n        print(\"This function is tracing !\")\r\n        with tf.GradientTape() as tape:\r\n            results = model(inputs, training=True)\r\n        grads = tape.gradient(results[\"loss\"], model.trainable_weights)\r\n        optimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n        return results\r\n\r\n    @staticmethod\r\n    @tf.function\r\n    def _eval_step(inputs, model):\r\n        return model(inputs, training=False)\r\n\r\n    def batch_train(self, data, mode=ExperimentMode.TRAIN):\r\n        model = self.train_model if mode & ExperimentMode.TRAIN else self.eval_model\r\n        return self._train_step(self.select_data(data), model, self.optimizer)\r\n\r\n    def batch_eval(self, data):\r\n        return self._eval_step(self.select_data(data), self.eval_model)\r\n```\r\n\r\n**EDIT Note:** (@bhack ) : This code is actually run in a loop for multiple experiments (lr grid-search). The first experiment runs fine (with 2 printed \"tracing\" messages). It's on the second experiment that I get the `ValueError:  tf.function-decorated function tried to create variables on non-first call` (with 1 single \"tracing\" message printed).\r\n\r\n**EDIT 2:** (@bhack ) I tried calling `build()` before without success (\"tracing\" message printed twice and same issue raised on second experiment)", "Can you check https://github.com/tensorflow/tensorflow/issues/48851#issuecomment-830858393?", "This is a known issue. My guess is that changing model parameters causes it to rebuild internally - it's a bad interaction between tf.function and Keras. For now, the only workaround is to rebuild the tf.function before each experiment. For example, with something like this: `MyClass._train_step = tf.function(MyClass._train_step)`. You may actually want to make it a standalone function, because static methods might have caveats as well.", "@mdanatg A this ticket is 3 year old and we had many more or less partial examples do we have a minimal but compete standalone code to reproduce this?", "The repro in the original post is reasonably minimal and should be complete. Normally the triage team creates a runnable gist, but since this issue is so old that's probably missing. The error occurs in many instances, but the pattern is the following:\r\n\r\n```\r\n  class Foo:\r\n\r\n      def __init__(self):\r\n        self._flag_keyed_vars = {}\r\n\r\n      def __call__(self, var_creation_flag):\r\n        self.compute(var_creation_flag)\r\n\r\n      @tf.function\r\n      def compute(self, var_creation_flag):\r\n        if var_creation_flag not in self._flag_keyed_vars:\r\n          self._flag_keyed_vars[var_creation_flag] = tf.Variable(1.0)\r\n\r\n    foo = Foo()\r\n    foo(True)  # traced twice, with variable lifting\r\n    foo(True)  # not traced, reuses variables from first trace\r\n    foo(False)  # re-traced twice, variable lifting raises error; but we don't\r\n                      # need to raise, we can just lift like in the first trace.\r\n```", "@mdanatg Can we just `self._stateless_fn = self._defun_with_scope(variable_capturing_scope)`  in\r\nhttps://github.com/tensorflow/tensorflow/blob/3fd3ae1fbb10961dd1aa6805280674c781fd4609/tensorflow/python/eager/def_function.py#L762-L768\r\n\r\nOr this will have other side effects?", "Unsure, it likely would have side effects - that code is overdue for cleanup and difficult to predict. But I would suggest trying it out anyway, if anyone has the bandwidth - if it passes all the TF unit tests, then it stands a good chance of working.", "I am getting the error\r\n\r\n`ValueError: tf.function-decorated function tried to create variables on non-first call.`\r\n\r\nwhen running the following test with pytest:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef test_optimization():\r\n    find_min_parabola_adam().numpy() # == pytest.approx(2, 0.1)\r\n\r\n@tf.function\r\ndef find_min_parabola_adam():\r\n    var1 = tf.Variable(0.0)\r\n    loss = lambda: (var1-1.0)*(var1-3.0)\r\n    optimizer = tf.optimizers.Adam()\r\n    optimizer.minimize(loss, [var1])\r\n    return var1\r\n```\r\n\r\nNow I figured out by now that you can not run these *multiple* times, and that you need to be [careful when using multiple optimizers](https://www.tensorflow.org/guide/function#using_with_multiple_keras_optimizers) but it already errors out the first time I call it. Is this somehow related or should I create a new bug report?", "It is related. The tf.function guide has a bit of background: https://www.tensorflow.org/guide/function#creating_tfvariables\r\n\r\nThe key insight is that tf.function tries to catch cases when you write code that would create variables in subsequent calls. It actually traces the function twice, first time you call it.\r\n\r\nRight now, tf.function won't allow you to write functions which create variables, so the best option it to create the variable outside:\r\n\r\n```\r\nvar1 = tf.Variable(0.0)\r\n\r\n@tf.function\r\ndef find_min_parabola_adam():  # or better yet, pass var1 as argument\r\n    loss = lambda: (var1-1.0)*(var1-3.0)\r\n    optimizer = tf.optimizers.Adam()\r\n    optimizer.minimize(loss, [var1])\r\n```\r\n\r\nI should add that we're working on ways to let you write functions which create variables, so the workaround should hopefully not be needed for much longer.", "neither this:\r\n\r\n```python\r\nvar = tf.Variable(0.0)\r\ndef test_optimization():\r\n    assert find_min_parabola_adam() == pytest.approx(2, 0.1)\r\n\r\n@tf.function\r\ndef find_min_parabola_adam():\r\n    loss = lambda: (var-1.0)*(var-3.0)\r\n    optimizer = tf.optimizers.Adam()\r\n    # for _ in range(1000):\r\n    optimizer.minimize(loss, [var])\r\n    # return var\r\n```\r\n\r\nnor this:\r\n\r\n```python\r\ndef test_optimization():\r\n    var = tf.Variable(0.0)\r\n    assert find_min_parabola_adam(var) == pytest.approx(2, 0.1)\r\n\r\n@tf.function\r\ndef find_min_parabola_adam(var):\r\n    loss = lambda: (var-1.0)*(var-3.0)\r\n    optimizer = tf.optimizers.Adam()\r\n    # for _ in range(1000):\r\n    optimizer.minimize(loss, [var])\r\n    # return var\r\n```\r\n\r\ngets rid of this error", "Ah, I missed that you also had an optimizer in the code. Adam creates variables internally, so it has the same limitation. So you need to pull that out too. The code below works; I changed the function to use arguments, but closing over them should work too:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nvar1 = tf.Variable(0.0)\r\noptimizer = tf.optimizers.Adam()\r\n\r\n@tf.function\r\ndef find_min_parabola_adam(var1, optimizer):\r\n    loss = lambda: (var1-1.0)*(var1-3.0)\r\n    optimizer.minimize(loss, [var1])\r\n\r\nfind_min_parabola_adam(var1, optimizer)\r\nprint(var1)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27120\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27120\">No</a>\n", "It Is closed but the default flag is `false`", "Yes, we'll keep the bug open until we've had the chance to default it to True. The internal test results look promising btw.", "@mdanatg Good, let me know.", "@bhack did a few tests with the flag in #49310. Here's a use case that needs additional work:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nclass C:\r\n\r\n  def __init__(self):\r\n    self.v = None\r\n\r\n@tf.function\r\ndef f(o):\r\n  if o.v is None:\r\n    o.v = tf.Variable(1)\r\n  v.assign_add(1)\r\n  return v\r\n\r\no1 = C()\r\nprint(f(o1), id(o1.v))\r\n\r\no2 = C()\r\nprint(f(o2), id(o2.v))\r\n```\r\n\r\nA good thing here is that each object receives a different variable. The buggy bit is that if you run the test, you'll see that all references to `v` inside both traces reuse the first variable somehow. The second trace needs to point to the second variable instead.\r\n\r\nI suspect that means that each trace will potentially need its own stateful_fn, and that the lifting logic should move inside the concrete function, for things to work properly. I can't think of a reason why this wouldn't be doable, but would need a bit more refactoring.", "@mdanatg Is there an error in this test stub? What is `v.assign_add(1)`? Is it still `o.v`?", "If it was a typo I suppose the new failing test is something like:\r\n\r\n```python \r\n  def testMethodAllowDynamicVariable(self):\r\n\r\n    class C:\r\n      def __init__(self):\r\n        self.v = None\r\n\r\n    @def_function.function\r\n    def f(o):\r\n      if o.v is None:\r\n        o.v = variables.Variable(1)\r\n      o.v.assign_add(1)\r\n      return o.v\r\n    def_function.ALLOW_DYNAMIC_VARIABLE_CREATION = True\r\n    o1 = C()\r\n    f(o1)\r\n    id_o1 = id(o1.v)\r\n    o2 = C()\r\n    f(o2)\r\n    id_o2 = id(o2.v)\r\n    self.assertNotEqual(id_o1, id_o2)\r\n    self.assertEqual(o1.v, 2)\r\n    self.assertEqual(o2.v, 2)\r\n```\r\n", "What is the expected assert?", "Yes, we expect both variables to have the value 2, I think.\r\n\r\nAlso:\r\n```\r\nself.assertEqual(f(o2), 2)\r\nself.assertEqual(o2.v, 2)\r\nself.assertEqual(f(o2), 3)\r\nself.assertEqual(o2.v, 3)\r\nself.assertEqual(o1.v, 2)\r\n```", "Mhh.. This test is passing. What do you want to test?\r\n\r\n```python\r\n  def testMethodAllowDynamicVariable(self):\r\n\r\n    class C:\r\n      def __init__(self):\r\n        self.v = None\r\n\r\n    @def_function.function\r\n    def f(o):\r\n      if o.v is None:\r\n        o.v = variables.Variable(1)\r\n      o.v.assign_add(1)\r\n      return o.v\r\n    def_function.ALLOW_DYNAMIC_VARIABLE_CREATION = True\r\n    o1 = C()\r\n    f(o1)\r\n    o2 = C()\r\n    self.assertEqual(f(o2), 2)\r\n    self.assertEqual(o2.v, 2)\r\n    self.assertEqual(f(o2), 3)\r\n    self.assertEqual(o2.v, 3)\r\n    self.assertEqual(o1.v, 2)\r\n    self.assertNotEqual(id(o1.v), id(o2.v))\r\n```", "Ah, you're right. I didn't pay close enough attention. I think we're back in the green then, thanks for double checking! I'll continue my tests.", "More updates below. Things generally look pretty good, but there is a potentially blocking issue of performance and a correctness bug:\r\n\r\n1. Performance issue - with the flag on, all function invocations will call `self._stateful_fn`, which is likely to cause some performance degradation. We'd need to thoroughly investigate the impact of that. If we were to guarantee performance regressions don't happen, only the first trace should call `stateful_fn`, and subsequent invocation should go back to `stateless_fn`. In all, this would likely be less hairy if we moved the entire lifting logic inside ConcreteFunction.\r\n\r\n2. Corner case - see test below; this test should raise an error saying that you can't create `o1` in every call, but instead the error says something about a variable that doesn't exist. Conditionally creating `o1` (e.g. if it's a global initialized with `None`) works fine, though:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nclass C:\r\n\r\n  def __init__(self):\r\n    self.v = None\r\n\r\n@tf.function\r\ndef outer():\r\n\r\n  @tf.function\r\n  def f(o):\r\n    if o.v is None:\r\n      o.v = tf.Variable(1)\r\n    o.v.assign_add(1)\r\n    return o.v\r\n\r\n  o1 = C()\r\n  tf.print(f(o1), o1.v)\r\n\r\nouter()\r\n```", "For point 1. \r\nI'have replied in the PR https://github.com/tensorflow/tensorflow/pull/49310\r\n\r\nFor point 2. \r\nI suppose the error of this case formulation is not related to my flag but more in general on this kind on nesting. As, If we use `False` flag, we have exactly the same error so I think that it is a more \"general\" corner case not strictly connected to the `True` new behavior. \r\n\r\nWhat do you think?", "For 2, I think you're right, I turned the flag to False and saw the same error as well. It's a bug, but not a regression, so we're good!\r\n\r\nI'll see if we can assist with running some benchmarks internally as well; the more data we can gather, the better, so anything you can run would be useful.", "> I'll see if we can assist with running some benchmarks internally as well; the more data we can gather, the better, so anything you can run would be useful.\r\n\r\nIt seems we got a reply from the model garden team on their benchmarks, let me know.", "@mdanatg What do you think about this use case:\n\nhttps://discuss.tensorflow.org/t/how-to-implement-layerdrop-in-tensorflow-transformers/2396", "I'm not familiar with the exact algorithm - does it involve creating layers based on a random condition?", "> I'm not familiar with the exact algorithm - does it involve creating layers based on a random condition?\n\nYes, more or less, for a very minimal summary:\n\nhttps://paperswithcode.com/method/layerdrop", "Check also this comment in the RFC:\r\nhttps://github.com/tensorflow/community/pull/390#issuecomment-866520107\r\n\r\nwhen they talk about `tf.function`", "At a glance, I think I agree with the comment - the code could build all layers (without any dropout), then use control flow to skip dropped layers in the forward pass. That should result in zero gradients, but if it doesn't each variable update should be placed behind a conditional as well, so a more complicated optimization process.\r\n\r\nAnyhow, that means that we don't need dynamic variable creation, so the use case doesn't seem to apply here.", "@mdanatg Probably but the two topics are slightly different:\r\n\r\n- In the forum thread it was related specifically to layerdrop and with this formulation:\r\nhttps://github.com/huggingface/transformers/blob/master/src/transformers/models/bart/modeling_tf_bart.py#L754-L771\r\n\r\nIn graph mode we have:\r\n`ValueError: tf.function-decorated function tried to create variables on non-first call.` \r\n\r\nSo probably in this case do we need just a reformulation?\r\n\r\nInstead the comment in the RFC is more in general related to the continual learning domain, in that spacial case on TFLite/edge devices and so to dynamically change the graph.\r\n\r\n\r\n", "> So probably in this case do we need just a reformulation?\r\n\r\nIt would appear so.\r\n\r\n> Instead the comment in the RFC instead is more in general related to the continual learning domain, in that spacial case on TFLite/edge devices and so to dynamically change the graph.\r\n\r\nYes, that seems closer to the use case we're handling. Your PR is a step in that direction. There are other pieces in the puzzle as well. For example, the gradients machinery - that also assumes a static graph, so in order to support truly dynamic graphs, the gradients would also need to be made truly dynamic.", "> Yes, that seems closer to the use case we're handling. Your PR is a step in that direction. There are other pieces in the puzzle as well. For example, the gradients machinery - that also assumes a static graph, so in order to support truly dynamic graphs, the gradients would also need to be made truly dynamic.\r\n\r\nI think this really need a specific RFC and an internal approved plan.", "@mdanatg Do you think that It Is a topic that could be explored internally?", "Yes, it's being explored. There are no easy solutions, and it's possible that the best we can do for backwards compatibility is to improve the error message and the ways to debug it.", "> Yes, it's being explored. There are no easy solutions, and it's possible that the best we can do for backwards compatibility is to improve the error message and the ways to debug it.\n\nDynamically change the graph it will be interesting in the continual learning domain.\n\n ", "I am having the same issue. Can someone summarize the solution in simple terms ? I am new to tensorflow and i got the error:-\r\n\r\nFile \"train.py\", line 298, in <module>\r\n    _main_(args)\r\n  File \"train.py\", line 266, in _main_\r\n    train_model.fit_generator(\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1847, in fit_generator\r\n    return self.fit(\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1100, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 888, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2941, in __call__\r\n    filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3361, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3196, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 990, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 634, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 977, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\r\n        return step_function(self, iterator)\r\n    C:\\Users\\vigne\\yolo.py:53 call  *\r\n        batch_seen = tf.Variable(0.)\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:262 __call__  **\r\n        return cls._variable_v2_call(*args, **kwargs)\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:244 _variable_v2_call\r\n        return previous_getter(\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\r\n        return captured_getter(captured_previous, **kwargs)\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3332 creator\r\n        return next_creator(**kwargs)\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\r\n        return captured_getter(captured_previous, **kwargs)\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3332 creator\r\n        return next_creator(**kwargs)\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\r\n        return captured_getter(captured_previous, **kwargs)\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3332 creator\r\n        return next_creator(**kwargs)\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\r\n        return captured_getter(captured_previous, **kwargs)\r\n    C:\\Users\\vigne\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:730 invalid_creator_scope\r\n        raise ValueError(\r\n\r\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\r\n\r\n\r\n\r\nI also changed to tf.run_functions_eagerly(True) in def_function but it didnt solve the issue", "@vigkrish123  Can you check if your case is covered by this test https://github.com/tensorflow/tensorflow/pull/51538?\r\n", "> @vigkrish123 Can you check if your case is covered by this test #51538?\r\n\r\nI added the lines of code but after first Epoch, the error returned", "Do the recommendations in https://www.tensorflow.org/guide/function#creating_tfvariables help?", "> I added the lines of code but after first Epoch, the error returned\r\n\r\nI don't understand what you mean as that one is just an expecting failing test for a not implemented functionality. \r\nWhat i mean is:\r\n\r\nIs your use case the same as the expected failing test?", "> > I added the lines of code but after first Epoch, the error returned\r\n> \r\n> I don't understand what you mean as that one is just an expecting failing test for a not implemented functionality.\r\n> What i mean is:\r\n> \r\n> Is your use case the same as the expected failing test?\r\n\r\nAm not quite sure. The problem arises when the following code is reached:-\r\n\r\ntrain_model.fit_generator(\r\n        generator        = train_generator, \r\n        steps_per_epoch  = len(train_generator) * config['train']['train_times'], \r\n        epochs           = config['train']['nb_epochs'] + config['train']['warmup_epochs'], \r\n        verbose          = 2 if config['train']['debug'] else 1,\r\n        callbacks        = callbacks, \r\n        workers          = 4,\r\n        max_queue_size   = 8\r\n    )\r\n\r\nwhere train_generator = BatchGenerator(\r\n        instances           = train_ints, \r\n        anchors             = config['model']['anchors'],   \r\n        labels              = labels,        \r\n        downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\r\n        max_box_per_image   = max_box_per_image,\r\n        batch_size          = config['train']['batch_size'],\r\n        min_net_size        = config['model']['min_input_size'],\r\n        max_net_size        = config['model']['max_input_size'],   \r\n        shuffle             = True, \r\n        jitter              = 0.3, \r\n        norm                = normalize\r\n    )\r\nAm not sure whether its a bug or error from my side or something has to be changed in the default lines of code (def_function.py). ", "I don't see where you are using a `tf.function` here.", "> I don't see where you are using a `tf.function` here.\r\n\r\nProblem was when i called tf.Variable(0.). When I removed this and assigned it a normal value (batch_seen = 0), the code started proceeding further. Strange! Anyways thanks for the help :)", "Yes it is:\r\n```\r\nC:\\Users\\vigne\\yolo.py:53 call  *\r\n    batch_seen = tf.Variable(0.)\r\n```", "@ericpts Could you please have a look at this [gist](https://colab.research.google.com/gist/sushreebarsa/a0703e4f1b96b7b9ba2daf30f464ed4e/gist27120.ipynb#scrollTo=_dt8VD5u87fL)  for reference and let us know if it helps  ?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27120\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27120\">No</a>\n"]}, {"number": 27119, "title": "window + flat_map fails on dataset of tuples", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home edition\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu\r\n- TensorFlow version (use command below): b'v1.12.0-rc2-3-ga6d8ffae09' 1.12.0\r\n- Python version: 3.6.7\r\n- CUDA/cuDNN version: Cuda compilation tools, release 9.0, V9.0.176, CuDNN 7.4.1, I believe\r\n- GPU model and memory: NVIDIA GTX 1070, 8 GiB memory (maybe 6, as TF is a bit unclear on that point)\r\n\r\n**Describe the current behavior**\r\nOn a range dataset, window followed by flat_map works as expected, but on a dataset of tuples (originally encountered using a CSV dataset), flat_map fails, complaining that the input argument to the mapped function has multiple components.\r\n\r\n**Describe the expected behavior**\r\nI expected flat_map to treat the windows as datasets, allowing me to perform dataset operations such as `batch` on them.\r\n\r\n**Code to reproduce the issue**\r\n\r\n    #Simple window batch test\r\n    import tensorflow as tf\r\n    data = tf.data.Dataset.range(0,10)\r\n    data = data.map(lambda *x: (x[0],x[0]+1))\r\n    #Each entry is now a tuple of (n,n+1)\r\n    #Without the mapping to tuple, window+flat_map works.\r\n    data = data.window(3)\r\n    #Each entry is now a window dataset\r\n    #map fails, because the dataset is nested\r\n    #data.map(lambda x: print(x))\r\n    #flat_map fails because x is a tuple, not a dataset\r\n    data = data.flat_map(lambda x: x.batch(3))\r\n\r\n**Other info / logs**\r\n\r\n> Traceback (most recent call last):\r\n>   File \"window_batch_test.py\", line 14, in <module>\r\n>     data = data.flat_map(lambda x: x.batch(3))\r\n>   File \"C:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1070, in flat_map\r\n>     return FlatMapDataset(self, map_func)\r\n>   File \"C:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2677, in __init__\r\n>     experimental_nested_dataset_support=True)\r\n>   File \"C:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1860, in __init__\r\n>     self._function.add_to_graph(ops.get_default_graph())\r\n>   File \"C:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 479, in add_to_graph\r\n>     self._create_definition_if_needed()\r\n>   File \"C:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 335, in _create_definition_if_needed\r\n>     self._create_definition_if_needed_impl()\r\n>   File \"C:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 344, in _create_definition_if_needed_impl\r\n>     self._capture_by_value, self._caller_device)\r\n>   File \"C:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 864, in func_graph_from_py_func\r\n>     outputs = func(*func_graph.inputs)\r\n>   File \"C:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1794, in tf_data_structured_function_wrapper\r\n>     ret = func(*nested_args)\r\n> TypeError: <lambda>() takes 1 positional argument but 2 were given\r\n\r\nThe (regretably) deprecated `sliding_window_batch` seems to work, though. It is much more convenient for my purposes to just get the windows as batches.", "comments": ["This works as intended. If the input to `window` is a dataset of nested elements, then the output of `window` will be a dataset of nested datasets of (flat) elements.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.enable_v2_behavior()\r\n\r\ndata = tf.data.Dataset.range(0,10)\r\ndata = data.map(lambda *x: (x[0],x[0]+1))\r\ndata = data.window(3)\r\ndata = data.flat_map(lambda x, y: tf.data.Dataset.zip((x.batch(3), y.batch(3))))\r\n\r\nfor elem in data:\r\n  print(elem)\r\n```\r\n\r\nproduces\r\n\r\n```\r\n(<tf.Tensor: id=35, shape=(3,), dtype=int64, numpy=array([0, 1, 2])>, <tf.Tensor: id=36, shape=(3,), dtype=int64, numpy=array([1, 2, 3])>)\r\n(<tf.Tensor: id=39, shape=(3,), dtype=int64, numpy=array([3, 4, 5])>, <tf.Tensor: id=40, shape=(3,), dtype=int64, numpy=array([4, 5, 6])>)\r\n(<tf.Tensor: id=43, shape=(3,), dtype=int64, numpy=array([6, 7, 8])>, <tf.Tensor: id=44, shape=(3,), dtype=int64, numpy=array([7, 8, 9])>)\r\n(<tf.Tensor: id=47, shape=(1,), dtype=int64, numpy=array([9])>, <tf.Tensor: id=48, shape=(1,), dtype=int64, numpy=array([10])>)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27119\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27119\">No</a>\n", "Thank you for answer, and for providing what appears to be a way to solve the problem. I suppose that for a dataset with many columns the expression would be something like:\r\n\r\n    data.flat_map(lambda *x: tf.data.Dataset.zip(tuple(col.batch(batch_size) for col in x)))\r\n\r\nwhich worked on my CSV data. :-)\r\n\r\nWhat I don't get is that x cannot just be batched directly. x is a tuple, but was supposed to be a dataset. (flat_map doc says that it applies the function to every element (dataset), and then flattens the result (packing out the datasets).) It should at least be a custom tuple with dataset methods added, as far as I can tell.\r\n\r\nThe old sliding window batch works well. And, while perhaps being less flexible, it solves a common valid usecase that should not be made less available. The \"instructions for updating\" that show up in the terminal when I use sliding_window_batch says nothing about the trick you gave me here, and the recommended solution does not work.\r\n\r\nTo conclude, I think this issue should not be closed yet. But thank you again for providing a workaround.", "What about dict, e.g when the input to `window()` was already a dictionary? `flat_map` behaves unintuitively here and doesn't get the job done."]}, {"number": 27118, "title": "Inference vs training in tensorflow ", "body": "Hello,\r\nCould you please tell me how does Tensoflow differentiate the training step from the inference? ( in most examples I found, they use the same call for both steps )", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 27117, "title": "Upgrading mkl-dnn to 0.18 release version", "body": "", "comments": []}, {"number": 27116, "title": "Failed to load the native TensorFlow runtime", "body": "Exception has occurred: ImportError\r\nTraceback (most recent call last):   File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>     from tensorflow.python.pywrap_tensorflow_internal import *   File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>     _pywrap_tensorflow_internal = swig_import_helper()   File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)   File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module     return load_dynamic(name, filename, file)   File \"C:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic     return _load(spec) ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.   Failed to load the native TensorFlow runtime.  See https://www.tensorflow.org/install/errors  for some common reasons and solutions.  Include the entire stack trace above this error message when asking for help.\r\n  File \"D:\\Dropbox\\Ph.D\\AMIR Ph.D\\Python\\Projects\\Test_project\\Machine_learning\\Deep_learning\\TensorFlowDL\\First_example_TF.py\", line 1, in <module>\r\n    import tensorflow as ts\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27115, "title": "kk", "body": "issue  #26143", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27115) for more info**.\n\n<!-- need_author_consent -->", "This has _a lot_ of changed files. Can you rebase off of master so it only has a small change?", "Sure, I will resolve it till tomorrow ", "@alextp god knows whats going on whenever i am adding new pull request my previous commits are also highlighted, I am trying to rebase my branch  but nothing is happening.Can you suggest any method?", "Rebasing doesn't delete your old commits; rebase --squash does."]}, {"number": 27114, "title": "Unable to assign GPU using c_api", "body": "**System information**\r\nWindows 10\r\nSource (c_api)\r\nTensorFlow version: 1.13\r\nCUDA/cuDNN version:10, 7.4.2\r\nGPU model and memory: RTX Titan 24 G\r\n\r\nUsing the c_api I am unable to assign a graph to a specific GPU. Overall the objective is to have the same graph running inference individually on each GPU. I have moved to the c_api from building in c++ because SetDefaultDevice is broken in c++ since version 1.5.\r\n\r\nOne way to set the device is getting the hex string in python:\r\n\r\ngpu_options = tf.GPUOptions(allow_growth=True,visible_device_list='1')\r\nconfig = tf.ConfigProto(gpu_options=gpu_options)\r\nserialized = config.SerializeToString()\r\nprint(list(map(hex, serialized)))\r\n\r\nI can get the GPU:1 to work, or GPU:0, but only individually. If I try to construct both, I get this error: \r\n\r\nTensorFlow device (GPU:0) is being mapped to multiple CUDA devices (1 now, and 0 previously), which is not supported. This may be the result of providing different GPU configurations (ConfigProto.gpu_options, for example different visible_device_list) when creating multiple Sessions in the same process. This is not  currently supported, see https://github.com/tensorflow/tensorflow/issues/19083\r\n\r\nIs it possible to use multiple GPUs running the same graph using the c_api? If not, is there any possibility to get SetDefaultDevice working in c++?\r\n\r\n\r\n\r\n", "comments": ["@ttdd11 I think if you want \"the same graph\" to run on multiple GPUs you have the following options:\r\n \r\n 1. build the graph twice, once per GPU, and use a single session.run call to drive them\r\n 2. build the graph once, use two sessions, each on which can see a single gpu, and use session.run to drive them\r\n 3. build the graph as a function and call that function on each of the GPUs\r\n 4. use multiple tensorflow processes, one per GPU\r\n\r\nWhich of the approaches above did you try?\r\n\r\n@achandraa why is this comp:eager? I don't see anything eager-related here.\r\n\r\n", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I run into the same issue.\r\n1 : not possible if you plan to use each gpu at different times (or with different models) async\r\n2: does not work by design (visible gpu list will apply per process)\r\n3: is this possible with c_api ?\r\n4: This works (obviously) but complicates the application's architecture a lot (inter process communication, etc...)\r\n", "Yeah I recommend you architect your system to have one tf process per GPU\nand work the graphs / models / sessions / etc around that.\n\nOn Fri, May 31, 2019 at 7:03 AM KocsisV <notifications@github.com> wrote:\n\n> I run into the same issue.\n> 1 : not possible if you plan to use each gpu at different times (or with\n> different models) async\n> 2: does not work by design (visible gpu list will apply per process)\n> 3: is this possible with c_api ?\n> 4: This works (obviously) but complicates the application's architecture a\n> lot (inter process communication, etc...)\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/27114?email_source=notifications&email_token=AAABHRKF5DLMKNEYQVIBO2TPYEV4TA5CNFSM4HA5YEGKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWVJFZQ#issuecomment-497717990>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRPSEFJIRO66E4FLBXLPYEV4TANCNFSM4HA5YEGA>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 27113, "title": "Lite: Slice Op 4-D bottleneck removed", "body": "1:> Removed hard coding or bottleneck to 4-Dim\r\n2:> Add assumption, that begin size and input dim are equal", "comments": ["@liyunlu0618 : Gentle Reminder!", "If we relax this, we should also update optimized_ops.h. And the optimized path should avoid heap allocation.", "> If we relax this, we should also update optimized_ops.h. And the optimized path should avoid heap allocation.\r\n\r\n@jdduke : I have handled your comments, please help review, Thanks!", "@jdduke: Your comments and queries are addressed, please check, Thanks!", "@jdduke : Your comments are addressed now, please check, Thanks!", "@jdduke : The conflicts are resolved now, Thanks!", "Can one of the admins verify this patch?", "@ANSHUMAN87 Could you please resolve the conflicts? Thanks!", "Resolved!", "@ANSHUMAN87 Can you please check reviewer comments and keep us posted. Thanks!", "@jdduke : I have replied to your comments inline, please check and feedback, Thanks!", "@jdduke: I have replied to one of your comment with bench-marking report, please check, Thanks!", "Thanks for benchmarking!\r\n\r\nI appreciate all the work you've done on this PR, but I'm still struggling to see what improvement this is offering. It doesn't appear any faster, and handles the same 1D-4D cases as the current implementation. If you had a compelling model or use-case which required 5D, I would definitely consider landing this, but until then the benefit isn't as clear. Note that we *do* need a 5D strided_slice implementation, and have encountered a number of models which require that op be extended.", "> Thanks for benchmarking!\r\n> \r\n> I appreciate all the work you've done on this PR, but I'm still struggling to see what improvement this is offering. It doesn't appear any faster, and handles the same 1D-4D cases as the current implementation. If you had a compelling model or use-case which required 5D, I would definitely consider landing this, but until then the benefit isn't as clear. Note that we _do_ need a 5D strided_slice implementation, and have encountered a number of models which require that op be extended.\r\n\r\n@jdduke : Thanks for your response! I understand your point quite clearly. In fact this PR conceptualized from the need of STRIDED_SLICE(#26748) . Also this changes is not performance improvement, it is only for generalization to support N-dim. The benchmark i shared is to showcase, that there is no performance dip. Another point which i want to bring notice to you. Both this PR and #26748 are just first phase,  i have plan to remove complete dependency in 4-Dim for both SLICE & STRIDED_SLICE in following PRs(Please check my previous comments). But only if these PRs get merged, i can do that. So i urge you to reconsider both current PR & #26748. As the need for STRIDED_SLICE & SLICE for N-dim is quite evident. \r\n\r\nNOTE: This PR does not remove 4-dim dependency completely because of common data-structure limitation, which i will take care in my future PRs(applicable for STRIDED_SLICE#26748 also).", "Hey @ANSHUMAN87 , apologies again for the delayed response. We're working on a more comprehensive proposal for updating our ops to support 5D shapes in particular. Those appear to be the most common scenarios that aren't yet supported, and we'd rather address those first than handle the more general case (which may degrade performance). I'll let @thaink chime in on specific thoughts here, but I think we can extend our 4D support to 5D here without sacrificing performance.", "Hi @ANSHUMAN87,\r\nI don't think your PR introduce significant performance overhead. However, looks like you haven't removed the assumption of dims <= 4. In slice.cc, kMaxDim still being set to 4. \r\n\r\nBesides, the implementation looks more complex than it should. I think the implementation for reference and optimized ops could be the same, the reference ops could also use memcpy with cpy_len. \r\nMy proposal about 5D support is still under review, so I'll update about that when it get submitted.", "> Hi @ANSHUMAN87,\r\n> I don't think your PR introduce significant performance overhead. However, looks like you haven't removed the assumption of dims <= 4. In slice.cc, kMaxDim still being set to 4.\r\n> \r\n> Besides, the implementation looks more complex than it should. I think the implementation for reference and optimized ops could be the same, the reference ops could also use memcpy with cpy_len.\r\n> My proposal about 5D support is still under review, so I'll update about that when it get submitted.\r\n\r\n@thaink : Thanks for your valuable feedback! Just wanted to confirm whether should i wait for your changes or should handle your comments?", "@ANSHUMAN87, You can handle the comments now since this op is quite exceptional for my changes.", "> @ANSHUMAN87, You can handle the comments now since this op is quite exceptional for my changes.\r\n\r\n@thaink : Thanks for your valuable comments. I have handled all now. Please check. Thanks!", "With kMaxDim is still 4, generally the PR looks fine to me. However, I tried an approach similar to your lambda implementation recently and found out that it is about 4 times slower than the loop-based one. So let me measure the performance once before merging this PR.", "> With kMaxDim is still 4, generally the PR looks fine to me. However, I tried an approach similar to your lambda implementation recently and found out that it is about 4 times slower than the loop-based one. So let me measure the performance once before merging this PR.\r\n\r\n@thaink : I had shared one bench-marking result earlier. Hope it might help you!", "> > With kMaxDim is still 4, generally the PR looks fine to me. However, I tried an approach similar to your lambda implementation recently and found out that it is about 4 times slower than the loop-based one. So let me measure the performance once before merging this PR.\r\n> \r\n> @thaink : I had shared one bench-marking result earlier. Hope it might help you!\r\n\r\nThanks. I also get the same result. Can you sync this PR the latest master?", "@jdduke Since the kMaxdim is still 4, there should be no effect on delegates. I think it is fine to merge this PR, can you take a look?", "@ANSHUMAN87 Can you please check jdduke's comments and keep us posted. Thanks!", "@jdduke: Thanks for your comment! \r\n@gbaned :  I will handle this PR possibly by Saturday. Thanks!", "@jdduke : Your comment is handled now. Please check. Thanks!", "This is breaking a number of internal tests. At this point, I think it may not be worth the hassle as it's taken nearly a year to get to this point. Thanks for the contribution, we can revisit this PR when it becomes "]}, {"number": 27112, "title": "Cannot export Keras model TypeError: ('Not JSON Serializable:', b'\\n...')", "body": "Versions:\r\nMac OS 10.14.3\r\nTF 2.0.0-dev20190319\r\n\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python import tf2\r\nfrom tensorflow.keras.layers import Input\r\nfrom tensorflow.keras.models import Model\r\nprint(tf.__version__)\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport os\r\n# Goal: predict liquidlinePressure as a function of ambientTemp and current\r\ndf = pd.DataFrame([[250, 23.2, 8],\r\n                    [255, 22.5, 7.5],\r\n                    [256, 24.0, 8.5],\r\n                    [258, 24.0, 9],\r\n                    [260, 25.1, 8.5]], columns=['liquidLinePressure', 'ambientTemp', 'current'])\r\n#-----standardizing constants\r\nxmu = [26.0,6.0]\r\nxsigma = [5.0, 3.0]\r\nymu = [255.0]\r\nysigma = [41.0]\r\n#------------ prepare inputs and outputs\r\ndf = df.values\r\ninput_features=['ambientTemp','current']\r\noutput_features=['liquidLinePressure']\r\nX=df[:,1:]\r\nX = {input_features[i]:x.reshape(-1,1) for i, x in enumerate(X.T)}\r\ny=(df[:,0:1]-ymu)/ysigma #standardize y's for training, but standardize x's within the model\r\n\r\n#--------------using Kera's functional api for standardization of inputs\r\nambientTemp = Input(shape=(1,), dtype='float', name='ambientTemp')\r\nambientTemp_enc = ((ambientTemp-xmu[0])/xsigma[0])\r\ncurrent=Input(shape=(1,), dtype='float', name='current')\r\ncurrent_enc = ((current-xmu[1])/xsigma[1])\r\n\r\ninputs=[ambientTemp, current]\r\nstandardizedIns = [ambientTemp_enc, current_enc]\r\nstandardized_inputs = tf.keras.layers.concatenate(inputs)\r\n#--model layers\r\ndense1 = tf.keras.layers.Dense(16, activation='relu')(standardized_inputs)\r\ndense2 = tf.keras.layers.Dense(64, activation='relu')(dense1)\r\ndense3 = tf.keras.layers.Dense(64, activation='relu')(dense2)\r\nstandardized_outputs = tf.keras.layers.Dense(1, activation='linear')(dense3)\r\n\r\ntrain_model=Model(inputs=inputs, outputs=standardized_outputs)\r\ntrain_model.compile(optimizer='adam', loss='mse')\r\ntrain_model.fit(x=X, y=y, epochs=1, verbose=1, batch_size=64,\r\n shuffle=True);\r\ntrain_model.save_weights('trainweights.h5')\r\ntrain_model.save('train_model.h5')  #this works\r\ntrain_model.summary()\r\n\r\n#--- for tf serving, I would like to return unstandardized outputs\r\nliquidLinePressureMean = ((standardized_outputs*ysigma[0])+ymu[0])\r\noutputs=[liquidLinePressureMean]\r\n\r\nexport_model=Model(inputs=inputs, outputs=outputs, name='model_that_takes_care_of_standardization.h5')\r\nexport_model.build(input_shape=[(None,),(None,)]) #is this line necessary/correct?\r\nexport_model.summary()\r\n#traceback occurs below\r\nexport_model.save('my_model.h5') #this doesn't work\r\n```\r\n\r\nIt is curious that the preprocessing steps can serialize fine, but something goes wrong either with the definition/building of the `export_model`, or with the postprocessing steps...\r\n(I apologize in advance if this is user error and not a bug-- it seems related to issues [here] (https://github.com/tensorflow/tensorflow/issues/19303) and [here](https://github.com/keras-team/keras/issues/9342) both of which have seemingly hacky solutions.\r\n\r\n```python output\r\n\r\n2.0.0-dev20190319\r\n2019-03-25 10:43:07.165064: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n5/5 [==============================] - 0s 26ms/sample - loss: 10.0754\r\nModel: \"model\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\nambientTemp (InputLayer)        [(None, 1)]          0                                            \r\n__________________________________________________________________________________________________\r\ncurrent (InputLayer)            [(None, 1)]          0                                            \r\n__________________________________________________________________________________________________\r\nconcatenate (Concatenate)       (None, 2)            0           ambientTemp[0][0]                \r\n                                                                 current[0][0]                    \r\n__________________________________________________________________________________________________\r\ndense (Dense)                   (None, 16)           48          concatenate[0][0]                \r\n__________________________________________________________________________________________________\r\ndense_1 (Dense)                 (None, 64)           1088        dense[0][0]                      \r\n__________________________________________________________________________________________________\r\ndense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \r\n__________________________________________________________________________________________________\r\ndense_3 (Dense)                 (None, 1)            65          dense_2[0][0]                    \r\n==================================================================================================\r\nTotal params: 5,361\r\nTrainable params: 5,361\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\nModel: \"model_that_takes_care_of_standardization.h5\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\nambientTemp (InputLayer)        [(None, 1)]          0                                            \r\n__________________________________________________________________________________________________\r\ncurrent (InputLayer)            [(None, 1)]          0                                            \r\n__________________________________________________________________________________________________\r\nconcatenate (Concatenate)       (None, 2)            0           ambientTemp[0][0]                \r\n                                                                 current[0][0]                    \r\n__________________________________________________________________________________________________\r\ndense (Dense)                   (None, 16)           48          concatenate[0][0]                \r\n__________________________________________________________________________________________________\r\ndense_1 (Dense)                 (None, 64)           1088        dense[0][0]                      \r\n__________________________________________________________________________________________________\r\ndense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \r\n__________________________________________________________________________________________________\r\ndense_3 (Dense)                 (None, 1)            65          dense_2[0][0]                    \r\n__________________________________________________________________________________________________\r\nstrided_slice (TensorFlowOpLaye [None]               0           dense_3[0][0]                    \r\n__________________________________________________________________________________________________\r\nmul (TensorFlowOpLayer)         [None]               0           strided_slice[0][0]              \r\n__________________________________________________________________________________________________\r\nadd (TensorFlowOpLayer)         [None]               0           mul[0][0]                        \r\n==================================================================================================\r\nTotal params: 5,361\r\nTrainable params: 5,361\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\nTraceback (most recent call last):\r\n  File \"minimal_example.py\", line 65, in <module>\r\n    export_model.save('my_model.h5')\r\n  File \"/Users/jamesmckeown/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1319, in save\r\n    save_model(self, filepath, overwrite, include_optimizer)\r\n  File \"/Users/jamesmckeown/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 103, in save_model\r\n    default=serialization.get_json_type).encode('utf8')\r\n  File \"/Users/jamesmckeown/anaconda2/envs/py36/lib/python3.6/json/__init__.py\", line 238, in dumps\r\n    **kw).encode(obj)\r\n  File \"/Users/jamesmckeown/anaconda2/envs/py36/lib/python3.6/json/encoder.py\", line 199, in encode\r\n    chunks = self.iterencode(o, _one_shot=True)\r\n  File \"/Users/jamesmckeown/anaconda2/envs/py36/lib/python3.6/json/encoder.py\", line 257, in iterencode\r\n    return _iterencode(o, 0)\r\n  File \"/Users/jamesmckeown/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/serialization.py\", line 69, in get_json_type\r\n    raise TypeError('Not JSON Serializable:', obj)\r\nTypeError: ('Not JSON Serializable:', b'\\n\\rstrided_slice\\x12\\x0cStridedSlice\\x1a\\x0fdense_3/BiasAdd\\x1a\\x13strided_slice/begin\\x1a\\x11strided_slice/end\\x1a\\x15strided_slice/strides*\\x16\\n\\x10shrink_axis_mask\\x12\\x02\\x18\\x01*\\x10\\n\\nbegin_mask\\x12\\x02\\x18\\x00*\\x13\\n\\rellipsis_mask\\x12\\x02\\x18\\x00*\\x13\\n\\rnew_axis_mask\\x12\\x02\\x18\\x00*\\x0e\\n\\x08end_mask\\x12\\x02\\x18\\x00*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0b\\n\\x05Index\\x12\\x020\\x03')\r\n```\r\n\r\nIt is also curious to me that the constants used for unstandardizing the output do not show up as `Non-trainable params` of the second model.  Is this expected behavior?  ", "comments": ["Possibly related: https://github.com/keras-team/keras/issues/12473\r\n", "@mckeown12  Were you ever able to solve this problem? I'm having the same issue and not sure what is causing it. It only started after I started using tf-nightly.\r\n\r\nEdit: I think it's caused when using tensorflow ops (instead of a keras layer) with Keras Model API. I can avoid this error by wrapping operations in Lambda. For example:\r\n\r\nThis causes an error\r\n`embed_layer += get_position_encoding(timesteps, embed_size)`\r\n\r\nThis does not\r\n`embed_layer = tf.keras.layers.Lambda(lambda x: x + get_position_encoding(timesteps, embed_size))(embed_layer)`\r\n\r\nEdit2: The problem is that TensorFlowOpLayer has a property \"node_def\" of type *bytes* in its config instead of *str*, and it causes an error when saving model. The property usually has a value of something like `b'\\n\\rstrided_slice\\x12\\x0cStridedSlice\\x1a\\x0fdense_3/BiasAdd\\x1a\\x13strided_slice/begin\\x1a\\x11strided_slice/end\\x1a\\x15strided_slice/strides*\\x16\\n\\x10shrink_axis_mask\\x12\\x02\\x18\\x01*\\x10\\n\\nbegin_mask\\x12\\x02\\x18\\x00*\\x13\\n\\rellipsis_mask\\x12\\x02\\x18\\x00*\\x13\\n\\rnew_axis_mask\\x12\\x02\\x18\\x00*\\x0e\\n\\x08end_mask\\x12\\x02\\x18\\x00*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0b\\n\\x05Index\\x12\\x020\\x03`. ", "I ended up using `tf.saved_model.save(export_model, '/path/to/save/model')` for tf serving. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27112\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27112\">No</a>\n", "Just let us know if there is any resolution to this issue.", "Yes, @eralmansouri 's solution works for me to save to `.h5` as well.  Replacing the line\r\n\r\n`liquidLinePressureMean = ((standardized_outputs*ysigma[0])+ymu[0])`\r\n\r\nwith\r\n\r\n`liquidLinePressureMean = tf.keras.layers.Lambda(lambda x: (x*ysigma[0])+ymu[0])(standardized_outputs)`\r\n\r\nmakes my original example work as expected.", "@eralmansouri solution solved the problem in my case. I guess the problem comes from the tensorflow op in keras. I converted two of my tensorflow ops to keras layers and the problem no longer exists.\r\n\r\n`x = tf.image.resize(x, (IM_H, IM_W))`\r\n--> `x = tf.keras.layers.Lambda(lambda x: tf.image.resize(x, (IM_H, IM_W)))(x)`\r\nand\r\n`x = tf.math.divide(x, tf.reduce_max(x))`\r\n--> `x = tf.keras.layers.Lambda(lambda x: tf.math.divide(x, tf.reduce_max(x)))(x)`\r\n\r\nThe output of the network is still the same after the conversion.", "For anyone else having this problem, I had success modifying my code from:\r\n\r\n    concat = tf.concat([foo, bar], axis=3)\r\n\r\nTo instead use:\r\n\r\n    concat = tf.keras.layers.Concatenate(axis=3)([foo, bar])\r\n\r\n", "can confirm @krisives solution solved this issue :)", "> For anyone else having this problem, I had success modifying my code from:\r\n> \r\n> ```\r\n> concat = tf.concat([foo, bar], axis=3)\r\n> ```\r\n> \r\n> To instead use:\r\n> \r\n> ```\r\n> concat = tf.keras.layers.Concatenate(axis=3)([foo, bar])\r\n> ```\r\n\r\n@krisives Thank you, helped! (My issue was with using tf.reshape, and instead I used tf.keras.layers.Reshape)"]}, {"number": 27111, "title": "CPU version of Tensorflow training is very slow with PlotLossesCallback", "body": "I have the CPU version of tensorflow and have been training a 3 layered Simple Recurrent keras model. However, the model takes takes too long to complete the an epoch (in excess of 30 minutes). \r\nThis started when I added the `plot_losses = PlotLossesCallback()` so that I can get live progress plots of the progress on the losses and accuracies for each epoch. I'm not sure how to remediate the issue. Would installing cuDNN be helpful to fixing the issue or does it not work with the CPU version of tensorflow?\r\nOr is there another when this can be fixed?", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27111\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27111\">No</a>\n"]}, {"number": 27110, "title": "Lite: Range Op small refactor", "body": "The switch case is not required, as the dtype check is already done above.", "comments": ["unfortunately, this cl changes the existing behavior: capture unsupported data types.", "@renjie-liu: yes you are right, I did it intentionally, as the base code above it has already restricted the permitted datatypes. So I feel it's quite unnecessary. Please let me know your opinion, TIA!", "Right, the idea is to throw meaningful error rather than silently crash", "@renjie-liu : Based on your feedback, i have updated the changes, please have a look, and provide your valuable opinion, TIA!", "@renjie-liu : Your comment is handled now, please check, thanks!", "@renjie-liu : Gentle Reminder!", "@ANSHUMAN87 can you please address build failures"]}, {"number": 27109, "title": "Micro speech tutorial - wav_to_features script fails with \"ImportError: No module named enum\"", "body": "I'm following the instructions in the [micro_speech tutorial](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/micro_speech#creating-your-own-model)\r\n\r\nI'm on OSX 10.14.2\r\n\r\nWhen I get to the step to generate the test data files, and run the command:\r\n\r\n```bash\r\nbazel run tensorflow/examples/speech_commands:wav_to_features -- \\\r\n--input_wav=${HOME}/speech_commands_test_set_v0.02/yes/f2e59fea_nohash_1.wav \\\r\n--output_c_file=yes_features_data.cc \\\r\n--window_stride=20 --preprocess=average --quantize=1\r\n```\r\n\r\nI eventually get to an error \"ImportError: No module named enum\":\r\n\r\n> ERROR: /Users/danoved/Source/thesis/speech-rec/tensorflow/tensorflow/BUILD:713:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\n> Traceback (most recent call last):\r\n>   File \"/private/var/tmp/_bazel_danoved/be5220cf895eff30f56ec50496f58755/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n>     from tensorflow.python.tools.api.generator import doc_srcs\r\n>   File \"/private/var/tmp/_bazel_danoved/be5220cf895eff30f56ec50496f58755/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 63, in <module>\r\n>     from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n>   File \"/private/var/tmp/_bazel_danoved/be5220cf895eff30f56ec50496f58755/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py\", line 52, in <module>\r\n>     from tensorflow.python.framework.importer import import_graph_def\r\n>   File \"/private/var/tmp/_bazel_danoved/be5220cf895eff30f56ec50496f58755/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 28, in <module>\r\n>     from tensorflow.python.framework import function\r\n>   File \"/private/var/tmp/_bazel_danoved/be5220cf895eff30f56ec50496f58755/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/function.py\", line 37, in <module>\r\n>     from tensorflow.python.ops import resource_variable_ops\r\n>   File \"/private/var/tmp/_bazel_danoved/be5220cf895eff30f56ec50496f58755/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 41, in <module>\r\n>     from tensorflow.python.ops import variables\r\n>   File \"/private/var/tmp/_bazel_danoved/be5220cf895eff30f56ec50496f58755/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py\", line 20, in <module>\r\n>     import enum  # pylint: disable=g-bad-import-order\r\n> ImportError: No module named enum\r\n> Target //tensorflow/examples/speech_commands:wav_to_features failed to build\r\n> Use --verbose_failures to see the command lines of failed build steps.\r\n> INFO: Elapsed time: 3774.946s, Critical Path: 286.02s\r\n> INFO: 10376 processes: 10376 local.\r\n> FAILED: Build did NOT complete successfully\r\n> FAILED: Build did NOT complete successfully\r\n\r\n", "comments": ["It seems to me that you have not installed **enum** Module.\r\n\r\nYou can easily do that by ```pip install enum```", "> It seems to me that you have not installed **enum** Module.\r\n> \r\n> You can easily do that by `pip install enum`\r\n\r\nDid this help resolve your issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "```\r\nsudo pip install enum\r\nWARNING: The directory '/Users/my_user/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\nWARNING: The directory '/Users/my_user/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\nCollecting enum\r\n  Downloading https://files.pythonhosted.org/packages/02/a0/32e1d5a21b703f600183e205aafc6773577e16429af5ad3c3f9b956b07ca/enum-0.4.7.tar.gz\r\n    ERROR: Complete output from command python setup.py egg_info:\r\n    ERROR: /usr/local/lib/python3.6/site-packages/setuptools/version.py:1: UserWarning: Module enum was already imported from /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/enum.py, but /private/tmp/pip-install-_d714hex/enum is being added to sys.path\r\n      import pkg_resources\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/private/tmp/pip-install-_d714hex/enum/setup.py\", line 24, in <module>\r\n        version = main_module.__version__\r\n    AttributeError: module 'enum' has no attribute '__version__'\r\n    ----------------------------------------\r\nERROR: Command \"python setup.py egg_info\" failed with error code 1 in /private/tmp/pip-install-_d714hex/enum/\r\n```"]}, {"number": 27108, "title": "Fix errors of incorrect session for evaluation in the clusterspec propagation test.", "body": "For a `TensorFlowTestCase` instance, its `self.evalute(...)` uses the default session to fetch a tensor value.\r\nIn `testClusterSpecPropagationWorker1Placement` and `testMultipleLocalDevices`, the default session has no graph registered, which brings errors like the following:\r\n```bash\r\n======================================================================\r\nERROR: testClusterSpecPropagationWorker1Placement (__main__.SessionClusterSpecPropagationTest)\r\ntestClusterSpecPropagationWorker1Placement (__main__.SessionClusterSpecPropagationTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    yield\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    testMethod()\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    output = self.evaluate(const)\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    return sess.run(tensors)\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    run_metadata_ptr)\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    raise RuntimeError('The Session graph is empty.  Add operations to the '\r\nRuntimeError: The Session graph is empty.  Add operations to the graph before calling run().\r\n\r\n======================================================================\r\nERROR: testMultipleLocalDevices (__main__.SessionClusterSpecPropagationTest)\r\ntestMultipleLocalDevices (__main__.SessionClusterSpecPropagationTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    yield\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    testMethod()\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    output = self.evaluate(sum3)\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    return sess.run(tensors)\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    run_metadata_ptr)\r\n  File \"/data00/home/shishaochen/.cache/bazel/_bazel_shishaochen/66654af5b8967893709f1bb873fdbb49/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session\r\n    raise RuntimeError('The Session graph is empty.  Add operations to the '\r\nRuntimeError: The Session graph is empty.  Add operations to the graph before calling run().\r\n\r\n----------------------------------------------------------------------\r\n```\r\n**Thus, we'd better explicitly use the created GRPC session registered with the wanted graph to evaluate tensors.**", "comments": ["Close this as #24466 is merged."]}, {"number": 27106, "title": "TF Lite model parsing in Python", "body": "Could you please make it a little bit clear for me \r\n\r\nI am using pyhon generated code to read and get node attributes from the model graph.\r\n\r\nI generated it this way (output is `tflite/` folder with autogenerated *.py files):\r\n`flatc -python tensorflow/tensorflow/lite/schema/schema.fbs`\r\n\r\nThan I read the model: \r\n\r\n```\r\n    from tflite.Model import Model\r\n    def read_tflite_model(file):\r\n        buf = open(file, \"rb\").read()\r\n        buf = bytearray(buf)\r\n        model = Model.GetRootAsModel(buf, 0)\r\n        return model\r\n\r\n```\r\nGetting model parameters:\r\n\r\n```\r\n    def print_model_info(model):\r\n        version = model.Version()\r\n        print(\"Model version:\", version)\r\n        description = model.Description().decode('utf-8')\r\n        print(\"Description:\", description)\r\n        subgraph_len = model.SubgraphsLength()\r\n        print(\"Subgraph length:\", subgraph_len)\r\n\r\n```\r\nThan I realized that graph nodes could be interpreted as `Tensor` object or `Operator` object.\r\n\r\n`Tensor` object stores quantization params, shape, tensor type (I don't understand the meaning of it yet)\r\n\r\n`Operator` object has `BuiltinOptions` and `CustomOptions` methods that seems to me should give me access to node parameters (such as paddings, dilations and all layer specific info)\r\n\r\nI tried to iterate over them since there are Inputs and Outputs methods. But failed. I don't understand w\r\n\r\nThis is my scratch:\r\n```\r\ndef print_nodes_info(model):\r\n    # what does this 0 mean? should it always be zero?\r\n    subgraph = model.Subgraphs(0)\r\n    operators_len = subgraph.OperatorsLength()\r\n    print('Operators length:', operators_len)\r\n\r\n    from collections import deque\r\n    nodes = deque(subgraph.InputsAsNumpy())\r\n\r\n    STEP_N = 0\r\n    MAX_STEPS = operators_len\r\n    print(\"Nodes info:\")\r\n    while len(nodes) != 0 and STEP_N <= MAX_STEPS:\r\n        print(\"MAX_STEPS={} STEP_N={}\".format(MAX_STEPS, STEP_N))\r\n        print(\"-\" * 60)\r\n\r\n        node_id = nodes.pop()\r\n        print(\"Node id:\", node_id)\r\n\r\n        tensor = subgraph.Tensors(node_id)\r\n        print(\"Node name:\", tensor.Name().decode('utf-8'))\r\n        print(\"Node shape:\", tensor.ShapeAsNumpy())\r\n\r\n        # which type is it? what does it mean?\r\n        type_of_tensor = tensor.Type()\r\n        print(\"Tensor type:\", type_of_tensor)\r\n\r\n        quantization = tensor.Quantization()\r\n        min = quantization.MinAsNumpy()\r\n        max = quantization.MaxAsNumpy()\r\n        scale = quantization.ScaleAsNumpy()\r\n        zero_point = quantization.ZeroPointAsNumpy()\r\n        print(\"Quantization: ({}, {}), s={}, z={}\".format(min, max, scale, zero_point))\r\n\r\n        # I do not understand it again. what is j, that I set to 0 here?\r\n        operator = subgraph.Operators(0)\r\n        for i in operator.OutputsAsNumpy():\r\n            nodes.appendleft(i)\r\n\r\n        STEP_N += 1\r\n\r\n    print(\"-\"*60)\r\n\r\n```\r\n\r\nPlease help me to get access the node attributes.\r\nThank you in advance for your help.\r\n\r\n", "comments": ["@cumberb1tch This is a copy of #27105 . Please close this.", "Thanks @Ayush517 . \r\nI am closing this as it is a duplicate of #27105 "]}, {"number": 27105, "title": "TF Lite model parsing in Python", "body": "Could you please make it a little bit clear for me \r\n\r\nI am using pyhon generated code to read and get node attributes from the model graph.\r\n\r\nI generated it this way (output is `tflite/` folder with autogenerated *.py files):\r\n`flatc -python tensorflow/tensorflow/lite/schema/schema.fbs`\r\n\r\nThan I read the model: \r\n\r\n```\r\n    from tflite.Model import Model\r\n    def read_tflite_model(file):\r\n        buf = open(file, \"rb\").read()\r\n        buf = bytearray(buf)\r\n        model = Model.GetRootAsModel(buf, 0)\r\n        return model\r\n\r\n```\r\nGetting model parameters:\r\n\r\n```\r\n    def print_model_info(model):\r\n        version = model.Version()\r\n        print(\"Model version:\", version)\r\n        description = model.Description().decode('utf-8')\r\n        print(\"Description:\", description)\r\n        subgraph_len = model.SubgraphsLength()\r\n        print(\"Subgraph length:\", subgraph_len)\r\n\r\n```\r\nThan I realized that graph nodes could be interpreted as `Tensor` object or `Operator` object.\r\n\r\n`Tensor` object stores quantization params, shape, tensor type (I don't understand the meaning of it yet)\r\n\r\n`Operator` object has `BuiltinOptions` and `CustomOptions` methods that seems to me should give me access to node parameters (such as paddings, dilations and all layer specific info)\r\n\r\nI tried to iterate over them since there are Inputs and Outputs methods. But failed. I don't understand w\r\n\r\nThis is my scratch:\r\n```\r\ndef print_nodes_info(model):\r\n    # what does this 0 mean? should it always be zero?\r\n    subgraph = model.Subgraphs(0)\r\n    operators_len = subgraph.OperatorsLength()\r\n    print('Operators length:', operators_len)\r\n\r\n    from collections import deque\r\n    nodes = deque(subgraph.InputsAsNumpy())\r\n\r\n    STEP_N = 0\r\n    MAX_STEPS = operators_len\r\n    print(\"Nodes info:\")\r\n    while len(nodes) != 0 and STEP_N <= MAX_STEPS:\r\n        print(\"MAX_STEPS={} STEP_N={}\".format(MAX_STEPS, STEP_N))\r\n        print(\"-\" * 60)\r\n\r\n        node_id = nodes.pop()\r\n        print(\"Node id:\", node_id)\r\n\r\n        tensor = subgraph.Tensors(node_id)\r\n        print(\"Node name:\", tensor.Name().decode('utf-8'))\r\n        print(\"Node shape:\", tensor.ShapeAsNumpy())\r\n\r\n        # which type is it? what does it mean?\r\n        type_of_tensor = tensor.Type()\r\n        print(\"Tensor type:\", type_of_tensor)\r\n\r\n        quantization = tensor.Quantization()\r\n        min = quantization.MinAsNumpy()\r\n        max = quantization.MaxAsNumpy()\r\n        scale = quantization.ScaleAsNumpy()\r\n        zero_point = quantization.ZeroPointAsNumpy()\r\n        print(\"Quantization: ({}, {}), s={}, z={}\".format(min, max, scale, zero_point))\r\n\r\n        # I do not understand it again. what is j, that I set to 0 here?\r\n        operator = subgraph.Operators(0)\r\n        for i in operator.OutputsAsNumpy():\r\n            nodes.appendleft(i)\r\n\r\n        STEP_N += 1\r\n\r\n    print(\"-\"*60)\r\n\r\n```\r\n\r\nPlease help me to get access the node attributes.\r\nThank you in advance for your help.\r\n\r\n", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27104, "title": "Fix C2398 on windows", "body": "This seems to fix error C2398 while building with mkl-dnn on Windows.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27104) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 27103, "title": "Added 8-bit Quantization support for Range.", "body": "This is one of the ToDo items in the file.", "comments": ["@renjie-liu , thanks for the review, this implementation is taken from the below document,\r\nhttps://github.com/google/gemmlowp/blob/master/doc/quantization.md \r\nRefer to Equation (5) (innermost part where the matrix is added over). \r\n\r\nFor adding we just need the quantized value and offset it with the zero point, i have tried to do the same in the function QuantizedRange (range.cc file).\r\nstart_value = start_value - start->params.zero_point;\r\ndelta_value = delta_value - delta->params.zero_point;\r\n\r\nTo ensure the implmentation is ok i have tried to test with all the possible scenarios this operator was previously tested with and the results seems correct.\r\n\r\nCan you please recheck this and let me know your concerns.\r\n\r\nRegards\r\nAmit\r\n", "Hi Amit,\n\nmy concern is basically how you plan to Quantize Range op in the first\nplace. According to the documentation here\n<https://www.tensorflow.org/api_docs/python/tf/range>, all the values all\nscalars, which I'm not sure if we can quantize in that scenario.\n\nI wonder if you can provide any use case that quantized range is used?\n\nThanks a lot.\n\nOn Tue, Mar 26, 2019 at 9:30 AM Amit <notifications@github.com> wrote:\n\n> @renjie-liu <https://github.com/renjie-liu> , thanks for the review, this\n> implementation is taken from the below document,\n> https://github.com/google/gemmlowp/blob/master/doc/quantization.md\n> Refer to Equation (5) (innermost part where the matrix is added over).\n>\n> For adding we just need the quantized value and offset it with the zero\n> point, i have tried to do the same in the function QuantizedRange (range.cc\n> file).\n> start_value = start_value - start->params.zero_point;\n> delta_value = delta_value - delta->params.zero_point;\n>\n> To ensure the implmentation is ok i have tried to test with all the\n> possible scenarios this operator was previously tested with and the results\n> seems correct.\n>\n> Can you please recheck this and let me know your concerns.\n>\n> Regards\n> Amit\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/27103#issuecomment-476438191>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AikWmZn0V7HxdqkGpSyGyBjOj1GxyXEoks5vaXg2gaJpZM4cGexs>\n> .\n>\n\n\n-- \nRenjie Liu\n\nrenjieliu@google.com\n+1 (650) 253-4359\n", "@renjie-liu , thanks for the review, this was one of the TODOs in the file (range.cc , to quantize this operator), so i thought of implementing the same.\r\n\r\nAbout the scalar part, i am sorry for the confusion may be i was not very clear last time, this is part of the symmetric quantization i.e scalar values can be quantized assuming the range to the min and max of the data type, this is the same i tried to do even in the Test cases as well. \r\n\r\n  float kMin = std::numeric_limits<uint8_t>::min();\r\n  float kMax = std::numeric_limits<uint8_t>::max();\r\n\r\n  QuantizedRangeOpModel m({TensorType_UINT8, {}, kMin, kMax},\r\n                          {TensorType_UINT8, {}, kMin, kMax},\r\n                          {TensorType_UINT8, {}, kMin, kMax});\r\n\r\n\r\nHope this is ok for you. Let me know if you have any other concerns.\r\n\r\nRegards\r\nAmit\r\n", "I will defer to Suharsh to make the decision", "@amitsrivastava78 can you please resolve conflicts.", "Dear @suharshs , @jianlijianli and @renjie-liu , I think the above implementation might not be complete in all aspects, here is what i feel needs to be done : -\r\n\r\n1. All the input tensors(limit, delta and start) should be quantized with same min and max values. With min and max values  as start and limit values.\r\nWe can do the above in graph_transformations/quantize.cc file\r\n\r\n2. We should have restriction that input and output should be in same quantization range.\r\nWe can do it in /tools/optimize/quantize_model.cc\r\n\r\n3. And finally we can update the kernel part of the Range operator.\r\n\r\nKindly let me know your feedback, If you guys agree i will start the implementation. The quantization requirement of this operator is also from SSD models mentioned in #28438 \r\n\r\nRegards\r\nAmit\r\n\r\n", "Dear @suharshs , @jianlijianli and @renjie-liu , can you please check the above comment and point me to the right direction. Would love to work on this.\r\n\r\nRegards\r\nAmit", "Sorry for the delay here, i am discussing with some folks the correct general approach for operations like this. Will reply once i reach concensus. Thanks for your patience!", "> Sorry for the delay here, i am discussing with some folks the correct general approach for operations like this. Will reply once i reach concensus. Thanks for your patience!\r\n\r\n@suharshs thanks for the response i will wait for conclusion from your side , hope to hear from you soon.\r\n\r\nRegards\r\nAmit", "@suharshs , did you get a chance to discuss this, if so let me know the direction to proceed.\r\n\r\nRegards\r\nAmit", "Can one of the admins verify this patch?", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 27102, "title": "tf.py_function InternalError in distributed mode", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 16.04.6 LTS\r\n- TensorFlow installed from (source or binary):\r\npip\r\n- TensorFlow version (use command below):\r\n1.13.1\r\n- Python version:\r\n3.6.7\r\n\r\n**Describe the current behavior**\r\nI'm testing tensorflow distributed on the same machine. I opened two separate shells and created a cluster using:\r\n\r\n```python\r\nimport tensorflow as tf  \r\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\"]})\r\nserver = tf.train.Server(cluster, job_name=\"local\", task_index=0)\r\n```\r\n\r\non shell 0 and\r\n\r\n```python\r\nimport tensorflow as tf\r\ncluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\"]})\r\nserver = tf.train.Server(cluster, job_name=\"local\", task_index=1)\r\n```\r\n\r\non shell 1.\r\n\r\nOn shell 1 I ran:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef add(a, b):\r\n    return a + b\r\n\r\nNUM = 1000\r\nones = np.ones((NUM))\r\n\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n    va = tf.Variable(ones)\r\n    vb = tf.Variable(ones)\r\n    with tf.device(\"job:local/task:1\"):\r\n        inputs = [va, vb]\r\n        out = tf.py_function(add, inputs, tf.float64)\r\n\r\n    with tf.Session(\"grpc://localhost:2223\", graph=graph) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        print(sess.run([va, vb]))\r\n        print(sess.run([out]))\r\n```\r\n\r\nwhich returns the error:\r\n\r\n> InternalError (see above for traceback): expected the py_func to return a Tensor backed by memory in /job:local/replica:0/task:1/device:CPU:0, but is actually in /job:localhost/replica:0/task:0/device:CPU:0. This is a bug.\r\n\r\nwhile this does not happen if I replace tf.py_function in the code above with tf.py_func.\r\n\r\n**Describe the expected behavior**\r\n\r\nCode should run successfully like when using tf.py_func and should print the arrays:\r\n\r\n> [array([1., 1., 1., 1., ..., 1., 1., 1., 1.]), array([1., 1., 1., 1., ..., 1., 1., 1., 1.])]\r\n> [array([2., 2., 2., 2., ..., 2., 2., 2., 2.])]\r\n", "comments": ["I believe this has been fixed in nightly.\r\n\r\nCan you try?", "Hi @alextp,\r\n\r\nI confirm this issue has been fixed on 1.14.1-dev20190325. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27102\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27102\">No</a>\n"]}, {"number": 27101, "title": "Unable to convert custom trained model ( .pb file ) into tflite format", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution : Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below):1.12\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): NA\r\n- CUDA/cuDNN version: No gpu\r\n- GPU model and memory: No gpu\r\n\r\n\r\n**Describe the current behavior**\r\nI have the following script using which I was able to successfully convert [deeplabv3_mnv2_pascal_train.pb model ](https://drive.google.com/file/d/1xKI0SIrXB6Wl8SBuX-D1otI_8nuHjza1/view) into tflite format \r\n\r\nscript is as follows: \r\n\r\n> tflite_convert \\\r\n>   --output_file=test.lite \\\r\n>   --graph_def_file=deeplabv3_mnv2_pascal_tain.pb \\\r\n>   --input_arrays=ImageTensor \\\r\n>   --output_arrays=SemanticPredictions \\\r\n>   --input_shapes=1,513,513,3 \\\r\n>   --inference_input_type=QUANTIZED_UINT8 \\\r\n>   --inference_type=FLOAT \\\r\n>   --mean_values=128 \\\r\n>   --std_dev_values=128\r\n\r\nI obtained input_arrays, and output_arrays for deeplabv3_mnv2_pascal_train.pb using the following python script.\r\n\r\n> import tensorflow as tf\r\n> gf = tf.GraphDef()   \r\n> m_file = open('deeplabv3_mnv2_pascal_tain.pb','rb')\r\n> gf.ParseFromString(m_file.read())\r\n> \r\n> #We get the names of the nodes\r\n> for n in gf.node:\r\n>     print( n.name )\r\n> \r\n> #To get the tensor\r\n> tensor = n.op\r\n\r\nI am planning to apply the same steps above towards my custom trained model, and convert it into tflite format. My model is [here](https://drive.google.com/file/d/1YUoayPHOqnkd7PR0QVBS9Vzk15b6r4p3/view)\r\nI used the above python script to get the input_arrays, and output_arrays and then ran the following:\r\n\r\n> tflite_convert \\\r\n>   --output_file=test.lite \\\r\n>   --graph_def_file=my_graph.pb \\\r\n>   --input_arrays=Const \\\r\n>   --output_arrays=detection_masks \\\r\n>   --input_shapes=1,513,513,3 \\\r\n>   --inference_input_type=QUANTIZED_UINT8 \\\r\n>   --inference_type=FLOAT \\\r\n>   --mean_values=128 \\\r\n>   --std_dev_values=128\r\n> \r\n\r\nI am getting the following error :\r\n\r\n> 2019-03-25 12:54:10.156375: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n> Traceback (most recent call last):\r\n>   File \"/home/ajinkya/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 558, in set_shape\r\n>     unknown_shape)\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 1 and 4\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/home/ajinkya/.local/bin/tflite_convert\", line 11, in <module>\r\n>     sys.exit(main())\r\n>   File \"/home/ajinkya/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 412, in main\r\n>     app.run(main=run_main, argv=sys.argv[:1])\r\n>   File \"/home/ajinkya/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n>     _sys.exit(main(argv))\r\n>   File \"/home/ajinkya/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 408, in run_main\r\n>     _convert_model(tflite_flags)\r\n>   File \"/home/ajinkya/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 100, in _convert_model\r\n>     converter = _get_toco_converter(flags)\r\n>   File \"/home/ajinkya/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 87, in _get_toco_converter\r\n>     return converter_fn(**converter_kwargs)\r\n>   File \"/home/ajinkya/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/lite.py\", line 286, in from_frozen_graph\r\n>     _set_tensor_shapes(input_tensors, input_shapes)\r\n>   File \"/home/ajinkya/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/convert_saved_model.py\", line 205, in set_tensor_shapes\r\n>     tensor.set_shape(shape)\r\n>   File \"/home/ajinkya/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 561, in set_shape\r\n>     raise ValueError(str(e))\r\n> ValueError: Shapes must be equal rank, but are 1 and 4\r\n\r\nHow do I resolve this error?\r\n", "comments": ["> --input_shapes=1,513,513,3 \r\n\r\nIs this the correct shape for your graph? Are there any other inputs?", "Good catch I made that correction to --input_shapes=1,1568,1176,3. But now I get a new error : \r\n\r\n> ajinkya@ajinkya-H310M-S2:~/Documents/tensorflow$ bazel-bin/tensorflow/lite/toco/toco \\\r\n> >   --input_file=my_graph.pb \\\r\n> >   --output_file=test.tflite \\\r\n> >   --inference_input_type=QUANTIZED_UINT8  \\\r\n> >   --inference_type=FLOAT \\\r\n> >   --input_arrays=Shape  \\\r\n> >   --output_arrays=detection_masks  \\\r\n> >   --input_shapes=1,1568,1176,3 \\\r\n> >   --mean_values=128 \\\r\n> >   --std_dev_values=128\r\n> 2019-03-28 17:18:41.911148: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.916365: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.916436: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.916454: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.916463: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.916470: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.916478: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.916487: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.916496: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.916504: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.916512: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.916525: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.916534: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n> 2019-03-28 17:18:41.916555: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.916563: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.916569: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.916575: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.916617: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Round\r\n> 2019-03-28 17:18:41.916627: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Round\r\n> 2019-03-28 17:18:41.916641: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Round\r\n> 2019-03-28 17:18:41.916651: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Round\r\n> 2019-03-28 17:18:41.916827: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.916839: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.916847: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.916854: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.916862: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.916869: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.916882: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.916890: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.916897: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.916912: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.916923: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.916937: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.936856: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.936897: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.936906: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.936916: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.936923: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.936930: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.936938: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.936945: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.936967: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.936993: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.937016: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.937039: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.937051: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.937059: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937067: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.937073: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937081: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937090: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937098: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937105: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937118: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937128: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n> 2019-03-28 17:18:41.937149: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.937158: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937165: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937171: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937178: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.937186: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937192: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937198: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937205: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.937213: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937219: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937225: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937232: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.937239: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937245: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937251: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937319: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n> 2019-03-28 17:18:41.937384: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n> 2019-03-28 17:18:41.937493: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n> 2019-03-28 17:18:41.937615: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.937628: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937636: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937643: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.937652: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937659: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937672: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.937680: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.937688: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.937704: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.937714: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.937728: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.937748: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.937757: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937765: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.937772: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937793: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.937818: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.937831: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.937839: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937847: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937855: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937862: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937873: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937881: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n> 2019-03-28 17:18:41.937898: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.937906: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937912: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937917: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937926: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.937934: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.937940: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.937946: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.938026: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.938038: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.938046: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.938058: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.938067: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.938082: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.938127: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: CropAndResize\r\n> 2019-03-28 17:18:41.950637: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.950684: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.950711: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.950726: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.950735: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.950745: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.950755: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.950764: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.950777: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.950787: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n> 2019-03-28 17:18:41.950806: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.950816: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.950823: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.950829: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.950843: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.950853: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.950868: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.950878: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.950885: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.950897: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.950906: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.950923: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.951098: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.951109: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951117: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.951124: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951132: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.951139: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951147: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.951155: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951181: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.951209: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.951237: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.951263: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n> 2019-03-28 17:18:41.951277: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.951286: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951294: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.951302: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951311: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.951318: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951326: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n> 2019-03-28 17:18:41.951334: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951344: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951353: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951362: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951371: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951380: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951388: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951405: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951415: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n> 2019-03-28 17:18:41.951440: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.951450: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951457: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951464: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951472: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.951481: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951488: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951494: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951503: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.951511: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951518: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951525: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951533: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n> 2019-03-28 17:18:41.951541: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951548: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.951555: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.951627: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n> 2019-03-28 17:18:41.951702: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n> 2019-03-28 17:18:41.951840: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n> 2019-03-28 17:18:41.952194: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.952209: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.952217: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.952225: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.952235: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.952242: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.952250: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.952260: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.952267: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.952274: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n> 2019-03-28 17:18:41.952283: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n> 2019-03-28 17:18:41.952290: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n> 2019-03-28 17:18:41.952306: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.952313: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.952320: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.952328: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n> 2019-03-28 17:18:41.952336: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.952352: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.952363: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.952379: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.952390: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.952406: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.952417: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n> 2019-03-28 17:18:41.952432: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n> 2019-03-28 17:18:41.952498: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: CropAndResize\r\n> 2019-03-28 17:18:42.003142: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2032 operators, 3359 arrays (0 quantized)\r\n> 2019-03-28 17:18:42.068363: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1922 operators, 3171 arrays (0 quantized)\r\n> 2019-03-28 17:18:42.147043: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1922 operators, 3171 arrays (0 quantized)\r\n> 2019-03-28 17:18:42.195815: F tensorflow/lite/toco/graph_transformations/resolve_constant_slice.cc:59] Check failed: dim_size >= 1 (0 vs. 1)\r\n> Aborted (core dumped)\r\n> \r\n\r\nAny idea how to resolve this?For your reference I am attaching below script which I ran on the same graph where the problem is seen\r\n\r\n> \r\n> >>> m_file = open('my_graph.pb','rb')\r\n> >>> gf.ParseFromString(m_file.read())\r\n> 52727425\r\n> >>> for n in gf.node:\r\n> ...     print( n.name )\r\n> ... \r\n\r\nOutput of this script can be seen [here](https://docs.google.com/document/d/1SzMpfd20Zsh3od052FjtLtNKmVAgvbinGLSqpBKY9fU/edit?usp=sharing). Please note the graph is of image segmentation  ", "Can you try converting with TF op usage? See the instructions here: https://www.tensorflow.org/lite/guide/ops_select", "Is it possible to convert mask rcnn to tflite model? I didn't see anything regarding this on tensorflow documentation. there is this link where they used DeepLab (https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md). Should I use DeepLab rather than converting mask rcnn to tflite ?\r\n", "Mask RCNN requires control flow, which we're actively working to support in TensorFlow Lite as soon as possible. In the meantime, absolutely feel free to give DeepLab a try.", "Ill try this on deep lab and post my conclusions here", "I am using Tensoflow 2.0. \r\nWhen I use converter.allow_custom_ops = 1, the TensorArrayV3 errors goes away and the pb model is converted to tflite.\r\nBut I get this error when running interpreter:\r\nRuntimeError: Encountered unresolved custom op: TensorArrayV3.Node number 1 (TensorArrayV3) failed to prepare.\r\n\r\nI need to convert this model to a product quality tflite model to be used by interpreter. Any work arounds?", "> I am using Tensoflow 2.0.\r\n> When I use converter.allow_custom_ops = 1, the TensorArrayV3 errors goes away and the pb model is converted to tflite.\r\n> But I get this error when running interpreter:\r\n> RuntimeError: Encountered unresolved custom op: TensorArrayV3.Node number 1 (TensorArrayV3) failed to prepare.\r\n> \r\n> I need to convert this model to a product quality tflite model to be used by interpreter. Any work arounds?\r\n\r\ni am also getting the same error but on a different model, have you found any solution to this unresolved custom ops:, if yes can you share the solution?\r\nthank you.", "> > I am using Tensoflow 2.0.\r\n> > When I use converter.allow_custom_ops = 1, the TensorArrayV3 errors goes away and the pb model is converted to tflite.\r\n> > But I get this error when running interpreter:\r\n> > RuntimeError: Encountered unresolved custom op: TensorArrayV3.Node number 1 (TensorArrayV3) failed to prepare.\r\n> > I need to convert this model to a product quality tflite model to be used by interpreter. Any work arounds?\r\n> \r\n> i am also getting the same error but on a different model, have you found any solution to this unresolved custom ops:, if yes can you share the solution?\r\n> thank you.\r\n\r\ndo you solve this problems ?bro", "> I am using Tensoflow 2.0.\r\n> When I use converter.allow_custom_ops = 1, the TensorArrayV3 errors goes away and the pb model is converted to tflite.\r\n> But I get this error when running interpreter:\r\n> RuntimeError: Encountered unresolved custom op: TensorArrayV3.Node number 1 (TensorArrayV3) failed to prepare.\r\n> \r\n> I need to convert this model to a product quality tflite model to be used by interpreter. Any work arounds?\r\n\r\ndo you solve this problems ?\r\ncan you share the solution?bro", "> Mask RCNN requires control flow, which we're actively working to support in TensorFlow Lite as soon as possible. In the meantime, absolutely feel free to give DeepLab a try.\r\n\r\nI converted efficientdet to tflite. However, I got an error when I use the converted tflite model for inference. Does retinanet or efficientdet require control flow?\r\n\r\nMy tensorflow version is 1.15.0-rc0.\r\nMy code as follows.\r\n`\r\nfrom tensorflow import keras\r\nimport tensorflow as tf\r\nimport layers as layers_new\r\nimport initializers\r\nimport losses\r\nimport efficientnet\r\n\r\ncustom_objects = {\r\n'BatchNormalization': layers_new.BatchNormalization,\r\n'swish' : efficientnet.get_swish(backend=keras.backend,layers=keras.layers,models=keras.models,utils=keras.utils),\r\n'FixedDropout' : efficientnet.get_dropout(backend=keras.backend,layers=keras.layers,models=keras.models,utils=keras.utils),\r\n'wBiFPNAdd' : layers_new.wBiFPNAdd,\r\n'PriorProbability' : initializers.PriorProbability,\r\n'RegressBoxes' : layers_new.RegressBoxes,\r\n'FilterDetections' : layers_new.FilterDetections,\r\n'ClipBoxes' : layers_new.ClipBoxes,\r\n'_smooth_l1' : losses.smooth_l1(),\r\n'_focal' : losses.focal(),\r\n}\r\ninput_shapes = {'input_1':[None,512,512,3],'input_4':[None,49104,4]}\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file('E:/object_detection/Efficient-region-checkpoints/inference_checkpoints/inference_checkpoints_B0/freeze-backbone-false_1e-5/csv_05_0.3995_0.5901.h5',\r\ncustom_objects=custom_objects,\r\ninput_shapes=input_shapes,\r\n)\r\nconverter.allow_custom_ops=True\r\ntflite_model = converter.convert()\r\nopen(\"E:/object_detection/Efficient-region-checkpoints/tflites/inference_checkpoints_B0/freeze-backbone-false_1e-5/csv_05_0.3995_0.5901.tflite\", \"wb\").write(tflite_model)\r\ninterpreter = tf.lite.Interpreter(model_path=\"E:/object_detection/Efficient-region-checkpoints/tflites/inference_checkpoints_B0/freeze-backbone-false_1e-5/csv_05_0.3995_0.5901.tflite\")\r\ninterpreter.allocate_tensors()\r\n`\r\n\r\nThen I get the following error.\r\n\r\n`RuntimeError Traceback (most recent call last)\r\nin ()\r\n----> 1 interpreter.allocate_tensors()\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\lite\\python\\interpreter.py in allocate_tensors(self)\r\n242 def allocate_tensors(self):\r\n243 self._ensure_safe()\r\n--> 244 return self._interpreter.AllocateTensors()\r\n245\r\n246 def _safe_to_run(self):\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\lite\\python\\interpreter_wrapper\\tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)\r\n104\r\n105 def AllocateTensors(self):\r\n--> 106 return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\n107\r\n108 def Invoke(self):\r\n\r\nRuntimeError: Encountered unresolved custom op: Enter.Node number 8 (Enter) failed to prepare.`\r\n\r\nCould you help me?", "similar error here with tensorflow 2.1 ", "> similar error here with tensorflow 2.1\r\n@hope-yao Can you resolve this error?", "> > similar error here with tensorflow 2.1\r\n> > @hope-yao Can you resolve this error?\r\n\r\n@2696120622  check this out: https://github.com/onnx/onnx-tensorflow/issues/449#issuecomment-603563801\r\n\r\nsome operations are not implemented yet "]}, {"number": 27100, "title": "Segmentation Fault with TensorRT create interference graph ", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): bynary (tensorflow-gpu)\r\n- TensorFlow version (use command below): b'v1.13.1-0-g6612da8951' 1.13.1\r\n\r\n- Python version: Python 3.6.7\r\n- CUDA/cuDNN version: CUDA 10\r\n- GPU model and memory: NVIDIA 1060 GTX\r\n\r\n\r\n**Describe the current behavior**\r\ni'm trying to optimize a tensorflow model to tensort optimization. i'm using the example of object detection given by https://github.com/tensorflow/tensorrt/tree/master/tftrt/examples/object_detection. So the tensorflow model loads perfect but when I try to optimize it a segmentation fault raise.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\n`with tf.Graph().as_default() as tf_graph:\r\n            with tf.Session(config=tf_config) as tf_sess:\r\n                frozen_graph = trt.create_inference_graph(\r\n                    input_graph_def=frozen_graph,\r\n                    outputs=output_names,\r\n                    max_batch_size=max_batch_size,\r\n                    max_workspace_size_bytes=max_workspace_size_bytes,\r\n                    precision_mode=precision_mode,\r\n                    minimum_segment_size=minimum_segment_size,\r\n                    is_dynamic_op=True,\r\n                    maximum_cached_engines=maximum_cached_engines)`\r\n\r\nSo the segmentation fault occurs in trt create_create_interference_graph.\r\n**Other info / logs**\r\n\r\nThis is the log from python output\r\n\r\n> 2019-03-25 09:08:39.360172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n> 2019-03-25 09:08:39.360201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2019-03-25 09:08:39.360207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n> 2019-03-25 09:08:39.360210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n> 2019-03-25 09:08:39.360303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5171 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n> INFO:tensorflow:Running against TensorRT version 5.0.2\r\n> INFO:tensorflow:Running against TensorRT version 5.0.2\r\n> 2019-03-25 09:08:40.787773: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 1\r\n> 2019-03-25 09:08:40.788522: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n> 2019-03-25 09:08:40.790765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n> 2019-03-25 09:08:40.790785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2019-03-25 09:08:40.790790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n> 2019-03-25 09:08:40.790793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n> 2019-03-25 09:08:40.790903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5171 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n> 2019-03-25 09:08:42.079562: I tensorflow/contrib/tensorrt/segment/segment.cc:443] There are 2316 ops of 32 different types in the graph that are not converted to TensorRT: Fill, Switch, Range, TopKV2, ConcatV2, Identity, Squeeze, Transpose, Const, Unpack, ResizeBilinear, Reshape, Mul, Slice, Merge, Split, Where, ExpandDims, NonMaxSuppressionV3, GatherV2, Cast, Greater, Minimum, Sub, ZerosLike, Pack, Exp, Placeholder, Add, Shape, NoOp, StridedSlice, (For more information see https://docs.nvidia.com/deeplearning/dgx/integrate-tf-trt/index.html#support-ops).\r\n> 2019-03-25 09:08:42.206925: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:913] Number of TensorRT candidate segments: 185\r\n> 2019-03-25 09:08:47.654116: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:1015] TensorRT node TRTEngineOp_0 added for segment 0 consisting of 486 nodes succeeded.\r\n> Segmentation fault (core dumped)\r\n\r\nAnd this is the callstack from gdb .\r\n\r\n> > 2019-03-25 09:12:23.651268: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:1015] TensorRT node TRTEngineOp_0 added for segment 0 consisting of 486 nodes succeeded.\r\n> \r\n> Thread 1 \"python3\" received signal SIGSEGV, Segmentation fault.\r\n> 0x00007fff68d60261 in tensorflow::tensorrt::convert::GetDeviceAndAllocator(tensorflow::tensorrt::convert::ConversionParams const&, tensorflow::tensorrt::convert::EngineInfo const&) ()\r\n>    from /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tensorrt/_wrap_conversion.so\r\n> (gdb) bt\r\n> #0  0x00007fff68d60261 in tensorflow::tensorrt::convert::GetDeviceAndAllocator(tensorflow::tensorrt::convert::ConversionParams const&, tensorflow::tensorrt::convert::EngineInfo const&) ()\r\n>    from /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tensorrt/_wrap_conversion.so\r\n> #1  0x00007fff68d651aa in tensorflow::tensorrt::convert::ConvertAfterShapes(tensorflow::tensorrt::convert::ConversionParams&) ()\r\n>    from /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tensorrt/_wrap_conversion.so\r\n> #2  0x00007fff68d90f56 in tensorflow::tensorrt::convert::TRTOptimizationPass::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n>    from /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tensorrt/_wrap_conversion.so\r\n> #3  0x00007fffb549a8ee in tensorflow::grappler::MetaOptimizer::RunOptimizer(tensorflow::grappler::GraphOptimizer*, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*, tensorflow::grappler::MetaOptimizer::GraphOptimizationResult*) () from /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n> #4  0x00007fffb549b552 in tensorflow::grappler::MetaOptimizer::OptimizeGraph(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n>    from /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n> #5  0x00007fffb549c8a7 in tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n>    from /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n> #6  0x00007fffb028ab9c in TF_OptimizeGraph(GCluster, tensorflow::ConfigProto const&, tensorflow::MetaGraphDef const&, bool, std::string const&, TF_Status*) ()\r\n>    from /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n> #7  0x00007fffb0293157 in _wrap_TF_OptimizeGraph () from /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n> #8  0x0000000000502d6f in ?? ()\r\n> #9  0x0000000000506859 in _PyEval_EvalFrameDefault ()\r\n> #10 0x0000000000504c28 in ?? ()\r\n> #11 0x0000000000502540 in ?? ()\r\n> #12 0x0000000000502f3d in ?? ()\r\n> #13 0x0000000000507641 in _PyEval_EvalFrameDefault ()\r\n> #14 0x0000000000504c28 in ?? ()\r\n> #15 0x0000000000502540 in ?? ()\r\n> #16 0x0000000000502f3d in ?? ()\r\n> #17 0x0000000000507641 in _PyEval_EvalFrameDefault ()\r\n> #18 0x0000000000504c28 in ?? ()\r\n> #19 0x0000000000502540 in ?? ()\r\n> #20 0x0000000000502f3d in ?? ()\r\n> #21 0x0000000000507641 in _PyEval_EvalFrameDefault ()\r\n> #22 0x0000000000504c28 in ?? ()\r\n> #23 0x0000000000506393 in PyEval_EvalCode ()\r\n> #24 0x0000000000634d52 in ?? ()\r\n> #25 0x00000000004a38c5 in ?? ()\r\n> #26 0x00000000004a5cd5 in PyRun_InteractiveLoopFlags ()\r\n> #27 0x00000000006387b3 in PyRun_AnyFileExFlags ()\r\n> #28 0x000000000063915a in Py_Main ()\r\n> #29 0x00000000004a6f10 in main ()\r\n\r\n", "comments": ["@isra60 I was not able to reproduce. Could you add more description about how you setup the tensorflow/tensorrt repository locally? Thanks.", "@aaroey  I have  the same problem\u3002 have you solved it?", "Here is my informations.\r\n### System information\r\n\r\n   *  OS Platform and Distribution: Linux Ubuntu 16.04\r\n\r\n   * TensorFlow installed from source:git clone from github\r\n\r\n   * TensorFlow version : tensorflow 1.13.0rc0 \r\n\r\n   * Python version: Python 3.5.6\r\n\r\n   *  CUDA/cuDNN version: CUDA 10.0.130 cuDNN V7.3.1\r\n\r\n   * GPU model and memory: NVIDIA GTX  TITAN XP \r\n### TensorRt5.0.2\r\n", "@isra60 @huaifeng1993 could you try to use tf-nightly-gpu and see if it can reproduce?", "@aaroey I have similar issue and same stack with Tf2.1 but works with tf2.2 dev builds. Do you know of a change that might have gone in to address that?", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27100\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27100\">No</a>\n"]}, {"number": 27099, "title": "tf.feature_column.sequence_categorical", "body": "\r\nWhat is the difference between tf.feature_column.sequence_categorical... and tf.feature_column.categorical...\uff1f", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 27098, "title": "Update ImageClassifier.java", "body": "When switching from GPU mode to CPU mode, gpuDelegate is not released. If switching to GPU again, gpuDelegate will be regenerated. If you keep switching, the memory will explode.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27098) for more info**.\n\n<!-- need_sender_cla -->", "I signed it.", "> I signed it.\r\n\r\nThere is ```!``` missing in your reply.", "I signed it!", "@GuitarZhang  i cannot see the CLA , can you please check again", "> @GuitarZhang i cannot see the CLA , can you please check again\r\n\r\nThe user name I filled in was 258303742@qq.com(my email) or guitarzhang. Now I fill in the correct user name GuitarZhang, can you Please see again.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27098) for more info**.\n\n<!-- ok -->", "@GuitarZhang sorry for the delay , can you please resolve conflicts.", "Can one of the admins verify this patch?", "changes are pushed by this commit `343ba94` , closing this , thank you"]}, {"number": 27097, "title": "Additional testcases for embedding_lookup ops", "body": "", "comments": ["@miaout17 Could you please kindly review this PR..", "Can one of the admins verify this patch?", "Is this still desired? Is it worth rebasing?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!\r\n"]}, {"number": 27096, "title": "Div nan #27044", "body": "Tried again #27044 ", "comments": ["@shashvatshahi1998 please resolve conflicts "]}, {"number": 27095, "title": "Build Tensorflow r1.13 with verbs and gdr report rdma error", "body": "cmd : ` bazel build --config=opt --config=cuda --config=gdr --config=verbs --distdir=/home/bazel_package //tensorflow/tools/pip_package:build_pip_package`\r\nDue to network problems, I downloaded the dependencies in advance.\r\nAnd I have install  the SW stack (libibverbs, etc..)\r\n```\r\n\tsudo yum install jemalloc\r\n\tsudo yum install jemalloc-devel\r\n\tsudo yum install libibverbs\r\n\tsudo yum install libibverbs-devel\r\n```\r\n\r\nError info:\r\n```\r\nbazel-out/k8-opt/genfiles/tensorflow/core/protobuf/config.pb_text.cc:882:9: note: 'map_value' was declared here\r\n   int32 map_value;\r\n         ^\r\nERROR: /home/zgz/submit_code/tensorflow/tensorflow/contrib/verbs/BUILD:105:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma_mgr' failed (Exit 1)\r\nIn file included from tensorflow/contrib/verbs/rdma_mgr.cc:18:0:\r\n./tensorflow/contrib/verbs/rdma_mgr.h: In static member function 'static void tensorflow::RdmaMgr::RegMemVisitors()':\r\n./tensorflow/contrib/verbs/rdma_mgr.h:50:16: error: invalid use of member 'tensorflow::RdmaMgr::rdma_adapter_' in static member function\r\n   RdmaAdapter* rdma_adapter_;\r\n                ^\r\ntensorflow/contrib/verbs/rdma_mgr.cc:282:40: error: from this location\r\n     int32_t bus_id = TryToReadNumaNode(rdma_adapter_->context_->device) + 1;\r\n                                        ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 80.943s, Critical Path: 51.17s\r\nINFO: 2025 processes: 2025 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nplease tell me how to fix this.", "comments": ["Sorry that the verbs fix #24250 did not make into r1.13. Let us know if you meet any other problems with that fix.", "I only saw you discussing how to solve in  #24250 .\r\nI want to know what should I do? Can I change the code according to `https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/24250.patch` what you mentioned in #22455 . I hurry to compile tf1.13 with GDR and Verbs.", "Yes, could you try that? \r\n\r\n```\r\ncurl https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/24250.patch | git apply\r\n```", "OK, I try it Now.", "I fix the issue.\r\nI create file `24250.patch`, and paste the content from `https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/24250.patch`. Then, I exec `git apply 24250.patch`, but only modify  `rdma_mgr.cc` and `verbs_server_lib.cc` . Do I still need to manually modify other files that show in `24250.patch`?\r\n\r\ndiff info\r\n```\r\ndiff --git a/tensorflow/contrib/verbs/rdma_mgr.cc b/tensorflow/contrib/verbs/rdma_mgr.cc\r\nindex 2784bf1..2721585 100644\r\n--- a/tensorflow/contrib/verbs/rdma_mgr.cc\r\n+++ b/tensorflow/contrib/verbs/rdma_mgr.cc\r\n@@ -277,9 +277,16 @@ void RdmaMgr::InitAllocators() {\r\n   ProcessState::singleton()->AddCPUFreeVisitor(free_visitor);\r\n\r\n #if GOOGLE_CUDA\r\n+  GPUProcessState::singleton()->AddCUDAHostAllocVisitor(0, alloc_visitor);\r\n+  GPUProcessState::singleton()->AddCUDAHostFreeVisitor(0, free_visitor);\r\n+\r\n   if (IsGDRAvailable()) {\r\n     // Note we don't free allocated GPU memory so there is no free visitor\r\n-    int32_t bus_id = TryToReadNumaNode(rdma_adapter_->context_->device) + 1;\r\n+\r\n+    // TODO: This is to fix the 'invalid use of member in static member function bug'.\r\n+    //       Waiting for better implementation.\r\n+    //       int32_t bus_id = TryToReadNumaNode(rdma_adapter_->context_->device) + 1;\r\n+    int32_t bus_id = 0;\r\n\r\n     SubAllocator::Visitor cuda_alloc_visitor = [](void* ptr, int gpu_id,\r\n                                                   size_t num_bytes) {\r\n@@ -288,9 +295,6 @@ void RdmaMgr::InitAllocators() {\r\n     };\r\n     GPUProcessState::singleton()->AddGPUAllocVisitor(bus_id,\r\n                                                      cuda_alloc_visitor);\r\n-    GPUProcessState::singleton()->AddCUDAHostAllocVisitor(bus_id,\r\n-                                                          alloc_visitor);\r\n-    GPUProcessState::singleton()->AddCUDAHostFreeVisitor(bus_id, free_visitor);\r\n     LOG(INFO) << \"Instrumenting GPU allocator with bus_id \" << bus_id;\r\n   }\r\n #endif  // GOOGLE_CUDA\r\ndiff --git a/tensorflow/contrib/verbs/verbs_server_lib.cc b/tensorflow/contrib/verbs/verbs_server_lib.cc\r\nindex 5b72b16..19ef109 100644\r\n--- a/tensorflow/contrib/verbs/verbs_server_lib.cc\r\n+++ b/tensorflow/contrib/verbs/verbs_server_lib.cc\r\n@@ -33,6 +33,8 @@ RendezvousMgrInterface* NewRdmaRendezvousMgr(const WorkerEnv* env) {\r\n   return new RdmaRendezvousMgr(env);\r\n }\r\n\r\n+std::once_flag reg_mem_visitors_call;\r\n+\r\n }  // namespace\r\n\r\n VerbsServer::VerbsServer(const ServerDef& server_def, Env* env)\r\n@@ -76,10 +78,6 @@ Status VerbsServer::ChannelCacheFactory(const ServerDef& server_def,\r\n   return Status::OK();\r\n }\r\n\r\n-namespace {\r\n-std::once_flag reg_mem_visitors_call;\r\n-}  // namespace\r\n-\r\n Status VerbsServer::Init(ServiceInitFunction service_func,\r\n                          RendezvousMgrCreationFunction rendezvous_mgr_func) {\r\n   std::call_once(reg_mem_visitors_call, []() { RdmaMgr::RegMemVisitors(); });\r\n\r\n```", "I don\u2019t know. Did you get it working?", "Now I compile sucessfully. I find many diff in 24250.patch, but when I exec `24250.patch`, only modify `rdma_mgr.cc` and `verbs_server_lib.cc` . \r\n\r\nDue to network problem, my server can not exec `curl https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/24250.patch | git apply`. So I manually  create a file `24250.patch` .  Do I still need to manually modify other files that show in 24250.patch?\r\n\r\n\u73b0\u5728\u6211\u5df2\u7ecf\u7f16\u8bd1\u6210\u529f\u4e86\u3002\r\n\u7531\u4e8e\u7f51\u7edc\u95ee\u9898\uff0c\u6211\u7684\u670d\u52a1\u5668\u8282\u70b9\u65e0\u6cd5\u8bbf\u95ee`https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/24250.patch`, \u6240\u4ee5\u6211\u521b\u5efa\u6587\u4ef6`24250.patch`\u5e76\u62f7\u8d1d\u7f51\u7ad9\u4e0a\u5185\u5bb9\uff0c\u4e0a\u4f20\u5230\u670d\u52a1\u5668\u3002 \u5728\u670d\u52a1\u5668\u6267\u884c`git apply 24250.patch`\uff0c\u7136\u540e\u6267\u884c`git diff`\uff0c\u53d1\u73b0\u53ea\u4fee\u6539\u4e86 `rdma_mgr.cc` \u548c `verbs_server_lib.cc`\u3002\r\n\u4f46\u5728`https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/24250.patch`\u4e0a\u663e\u793a\u4fee\u6539\u4e86\u5f88\u591a\u6587\u4ef6\uff0c\u6211\u73b0\u5728\u662f\u5426\u9700\u8981\u5c06\u5176\u4ed6\u6587\u4ef6\u624b\u52a8\u4fee\u6539\uff1f", "If it\u2019s working it\u2019s working. \r\n\r\nThere\u2019re multiple commits in the PR for some reasons, and most of them cancel itself. What you are doing is correct."]}, {"number": 27094, "title": "Added 8-bit Quantization support for RELU_N1_TO_1.", "body": "Added the quantization support for the operator.", "comments": ["@suharshs , thanks for the review, i have updated the code as per your comments, kindly check and approve.\r\n\r\nRegards\r\nAmit", "@rthadur , resolved the merge conflicts\r\n@suharshs , sorry for the trouble i resolved the merge conflicts can you please approve again.\r\n\r\n\r\nRegards\r\nAmit", "@rthadur , can you please help to get this PR merged, this is already approved.\r\n\r\nRegards\r\nAmit", "> @rthadur , can you please help to get this PR merged, this is already approved.\r\n> \r\n> Regards\r\n> Amit\r\n\r\nsure , @suharshs can you please approve this internally ", "> > @rthadur , can you please help to get this PR merged, this is already approved.\r\n> > Regards\r\n> > Amit\r\n> \r\n> sure , @suharshs can you please approve this internally\r\n\r\n@suharshs , can you pls approve this internally as well.\r\n\r\nRegards\r\nAmit", "@suharshs , there was some merge conflict which i resolved, can you please approve it again. \r\n\r\nSorry for the trouble caused.\r\n\r\nRegards\r\nAmit"]}, {"number": 27092, "title": "Export experimental APIs", "body": "TFL_InterpreterOptionsAddBuiltinOp and TFL_InterpreterOptionsAddCustomOp are not exported.", "comments": ["After looking some header files, I guess the rule of indentation is:\r\n\r\n1. arguments should be kept in same line of function declaration if it is not over 80 column.\r\n2. If the location of arguments is over 80 column, alignment to begining paren `(` of function.\r\n3. If  it is still over 80 column, make 4 spaces indentation from begining of line.", "You can use `clang-tidy` to automatically format: https://www.tensorflow.org/community/contribute/code_style", "Thank you. I squashed commits."]}, {"number": 27091, "title": "Fix tf.train.AdamOptimizer bug when use with tf.keras.callbacks.ReduceLROnPlateau", "body": "fix #20999", "comments": ["still have problem"]}, {"number": 27090, "title": "InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'RoiPoolGrad' with these attrs.  Registered devices: [CPU], Registered kernels:", "body": "/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\nTraceback (most recent call last):\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1305, in _run_fn\r\n    self._extend_graph()\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1340, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'RoiPoolGrad' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  device='GPU'; T in [DT_FLOAT]\r\n\r\n\t [[Node: gradients/pool_5_grad/RoiPoolGrad = RoiPoolGrad[T=DT_FLOAT, pooled_height=7, pooled_width=7, spatial_scale=0.0625](conv5_3/Relu, roi-data/rois, pool_5:1, gradients/fc6/transpose_grad/transpose)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"./faster_rcnn/train_net.py\", line 109, in <module>\r\n    restore=bool(int(args.restore)))\r\n  File \"./faster_rcnn/../lib/fast_rcnn/train.py\", line 401, in train_net\r\n    sw.train_model(sess, max_iters, restore=restore)\r\n  File \"./faster_rcnn/../lib/fast_rcnn/train.py\", line 149, in train_model\r\n    sess.run(tf.global_variables_initializer())\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'RoiPoolGrad' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  device='GPU'; T in [DT_FLOAT]\r\n\r\n\t [[Node: gradients/pool_5_grad/RoiPoolGrad = RoiPoolGrad[T=DT_FLOAT, pooled_height=7, pooled_width=7, spatial_scale=0.0625](conv5_3/Relu, roi-data/rois, pool_5:1, gradients/fc6/transpose_grad/transpose)]]\r\n\r\nCaused by op 'gradients/pool_5_grad/RoiPoolGrad', defined at:\r\n  File \"./faster_rcnn/train_net.py\", line 109, in <module>\r\n    restore=bool(int(args.restore)))\r\n  File \"./faster_rcnn/../lib/fast_rcnn/train.py\", line 401, in train_net\r\n    sw.train_model(sess, max_iters, restore=restore)\r\n  File \"./faster_rcnn/../lib/fast_rcnn/train.py\", line 143, in train_model\r\n    grads, norm = tf.clip_by_global_norm(tf.gradients(loss, tvars), 10.0)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 532, in gradients\r\n    gate_gradients, aggregation_method, stop_gradients)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 701, in _GradientsHelper\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 396, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 701, in <lambda>\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"./faster_rcnn/../lib/roi_pooling_layer/roi_pooling_op_grad.py\", line 23, in _roi_pool_grad\r\n    data_grad = roi_pooling_op.roi_pool_grad(data, rois, argmax, grad, pooled_height, pooled_width, spatial_scale)\r\n  File \"<string>\", line 139, in roi_pool_grad\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\r\n    op_def=op_def)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\n...which was originally created as op 'pool_5', defined at:\r\n  File \"./faster_rcnn/train_net.py\", line 101, in <module>\r\n    network = get_network(args.network_name)\r\n  File \"./faster_rcnn/../lib/networks/factory.py\", line 29, in get_network\r\n    return VGGnet_train()\r\n  File \"./faster_rcnn/../lib/networks/VGGnet_train.py\", line 17, in __init__\r\n    self.setup()\r\n  File \"./faster_rcnn/../lib/networks/VGGnet_train.py\", line 84, in setup\r\n    .roi_pool(7, 7, 1.0/16, name='pool_5')\r\n  File \"./faster_rcnn/../lib/networks/network.py\", line 36, in layer_decorated\r\n    layer_output = op(self, layer_input, *args, **kwargs)\r\n  File \"./faster_rcnn/../lib/networks/network.py\", line 235, in roi_pool\r\n    name=name)[0]\r\n  File \"<string>\", line 57, in roi_pool\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\r\n    op_def=op_def)\r\n  File \"/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'RoiPoolGrad' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  device='GPU'; T in [DT_FLOAT]\r\n\r\n\t [[Node: gradients/pool_5_grad/RoiPoolGrad = RoiPoolGrad[T=DT_FLOAT, pooled_height=7, pooled_width=7, spatial_scale=0.0625](conv5_3/Relu, roi-data/rois, pool_5:1, gradients/fc6/transpose_grad/transpose)]]\r\n\r\nwhen i train the TFFRCNN ,there have a bug.\r\nwhat should i do now?\r\nthanks!\r\n", "comments": ["Please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md). Could you update them if they are relevant in your case, or leave them as N/A? Along with the template, please provide as many details as possible to find the root cause of the issue. It would be great if you can provide a small code to reproduce the error. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!"]}]