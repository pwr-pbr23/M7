[{"number": 36129, "title": "[TFLite int16] 16-bit reference kernel for DEPTHWISE_CONV_2D", "body": "This PR is one of steps to extend 8-bit quantization to support symmetric 16-bit activations.\r\n\r\nEach activation is of type int16 and symmetric around zero. The weight tensor precision remains at 8-bit signed values. The bias is set to int64 precision.\r\n\r\nIn this PR we introduce implementation and tests for DEPTHWISE_CONV_2D kernel reference function.\r\nThis is a follow-up of this PR: \r\nhttps://github.com/tensorflow/tensorflow/pull/35946\r\n\r\nThe specification of this operator:\r\nDEPTHWISE_CONV_2D \r\n\u202f Input 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f Input 1 (Weight): \r\n\u202f \u202f data_type \u202f: int8 \r\n\u202f \u202f range \u202f \u202f \u202f: [-127, 127] \r\n\u202f \u202f granularity: per-axis (dim = 3), zero_point=0 \r\n\u202f Input 2 (Bias): \r\n\u202f \u202f data_type \u202f: int64 \r\n\u202f \u202f range \u202f \u202f \u202f: [-(1<<39), (1<<39)-1] \r\n\u202f \u202f granularity: per-axis (dim = 3), zero_point=0 \r\n\u202f \u202f restriction: (scale, zero_point) = (input0_scale * input1_scale[...], 0) \r\n\u202f Output 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n \r\n", "comments": ["Hi @renjie-liu, thanks for the review! The merge with master I did on github went wrong and corrupted the file. I have corrected it.\r\nCould you please take another look ?\r\nThanks! ", "Hi @renjie-liu Thanks for the fast review! I corrected according to the comments.", "Hi @jdduke Could you please review this PR ? Thanks", "Hi @renjie-liu I added TODO comment as requested. This change has removed approval from this PR. Could you please re-approve this PR ? Thanks", "Hi @rthadur Could you please clarify what is going with this PR ? I see that it has been merged into mlt/master (commit mentioned above), but it is still open.", "@wwwind auto merge did not happen, but i see the changes are merged now, closing this PR. Thank you"]}, {"number": 36127, "title": "Make TensorFlow build with system packages", "body": "We want to control what versions of libraries are getting used on our cluster. TF using included and downloaded stuff is a misbehavor.\r\n\r\nIs it possible to get a list of dependencies and whether the system version is used/found?\r\n\r\nCan we interactively pass some arguments and have it use the system versions with TF showing if it does before running the build?\r\n\r\nExamples that I've seen are zlib and protobuf with the protoc.\r\n\r\nWe are using a Github release and running `./configure && bazel <...>` with lots of TF_NEED_* and *_PATH variables already set.", "comments": ["@Flamefire,\r\nGet all the Tensorflow dependencies list from [setup.py](https://github.com/tensorflow/tensorflow/blob/5d5db2835967694ce4af95ce9c32cf0298ecef6e/tensorflow/tools/pip_package/setup.py) file. You can control the dependencies from this py file. Thanks! \r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36127\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36127\">No</a>\n"]}, {"number": 36126, "title": "Tensorflow: Model.Fit Error - [[{{node IteratorGetNext}}]]", "body": "Hey Tensorflow-Team,\r\n\r\nthere is an error, that accurs when you try to follow the tutorial how to Load CSV data. [(Link)](https://www.tensorflow.org/tutorials/load_data/csv) When the model runs through all the epochs, each time there is this error-code: `BaseCollectiveExecutor::StartAbort Out of range: End of sequence [[{{node IteratorGetNext}}]]`. There are already some entries here on GitHub, but none of them gives a solution or a workaround. The people say that this is an issue with TF V2.0.0 and 2.1.0 . Is there a solution for this problem? I will leave my complete code here, it\u00b4s just 161 lines. \r\nMaybe I did a mistake. I also attached a screenshot from the error.\r\n\r\nThank you very much in advance! \r\n\r\nKind regards\r\nChristian Richter\r\n\r\nCode:\r\n```python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport functools\r\n\r\nimport tensorflow as tf\r\n\r\nimport xlrd\r\n\r\nimport pandas as pd\r\nimport csv\r\nimport numpy as np\r\nimport csv\r\n\r\ntf.compat.v1.enable_eager_execution()\r\n\r\ntrain_data_url = \"https://www.dropbox.com/s/mug8rjlniftu065/train_data_csv.csv?dl=0\"\r\n\r\ntest_data_url = \"https://www.dropbox.com/s/std8rt6lezl79ti/test_data_csv.csv?dl=0\"\r\n\r\ntrain_file_path = tf.keras.utils.get_file(\"train_data_csv.csv\", train_data_url)\r\ntest_file_path = tf.keras.utils.get_file(\"test_data_csv.csv\", test_data_url)\r\n\r\nnp.set_printoptions(precision = 3, suppress=True)\r\n\r\n#!head {train_file_path}\r\n\r\nLabel_Column = 'Besucher'\r\nLabels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100, 200, 300, 400, 500, 600, 700, 800, 900]\r\n\r\ntrain_dataset = tf.data.experimental.make_csv_dataset(\r\n    './Data/train_data_csv.csv',\r\n    batch_size = 52609,\r\n    select_columns = ['Datum','Uhrzeit','Wochentag','Wochenende','Ferien','Feiertag','Brueckentag','Schneechaos','Streik','Besucher'],\r\n    label_name = 'Besucher',\r\n    num_epochs = 1,\r\n    shuffle = False)\r\n\r\n\r\n\r\ntest_dataset = tf.data.experimental.make_csv_dataset(\r\n    './Data/alt_test_data_csv.csv',\r\n    batch_size = 1,\r\n    select_columns = ['Datum','Uhrzeit','Wochentag','Wochenende','Feiertag','Besucher'],\r\n    label_name = 'Besucher',\r\n    num_epochs = 1 ,\r\n    shuffle = False)\r\n\r\n\r\ndef show_batch(dataset):\r\n  for batch, label in dataset.take(1):\r\n    for key, value in batch.items():\r\n      print(\"{:20s}: {}\".format(key,value.numpy()))\r\n\r\n\r\n\r\n\r\nshow_batch(train_dataset)\r\n\r\ndef pack(features, label):\r\n    return tf.stack(list(features.values()), axis = -1), label\r\n\r\npacked_dataset1 = train_dataset.map(pack)\r\n#packed_dataset2 = test_dataset.map(pack)\r\n\r\nfor features, labels in packed_dataset1.take(1):\r\n    print(features.numpy())\r\n    print()\r\n    print(labels.numpy())\r\n\r\nexample_batch, labels_batch = next(iter(train_dataset))\r\n\r\n\r\nclass PackNumericFeatures(object):\r\n    def __init__(self, names):\r\n        self.names = names\r\n\r\n    def __call__(self, features, labels):\r\n\r\n        numeric_features = [features.pop(name) for name in self.names]\r\n        numeric_features = [tf. cast(feat, tf.float32) for feat in numeric_features]\r\n        numeric_features = tf.stack(numeric_features, axis = -1)\r\n        features['numeric'] = numeric_features\r\n\r\n        return features, labels\r\n\r\nNUMERIC_FEATURES = ['Datum','Uhrzeit','Wochentag','Wochenende','Ferien','Feiertag','Brueckentag','Schneechaos','Streik']\r\n\r\npacked_train_data = train_dataset.map(\r\n    PackNumericFeatures(NUMERIC_FEATURES)\r\n)\r\npacked_test_data = train_dataset.map(\r\n    PackNumericFeatures(NUMERIC_FEATURES)\r\n)\r\n\r\nshow_batch(packed_train_data)\r\n\r\nexample_batch, labels_batch = next(iter(packed_train_data))\r\n\r\n\r\ndesc = pd.read_csv(\"./Data/train_data_csv.csv\")[NUMERIC_FEATURES].describe()\r\ndesc\r\n\r\nMEAN = np.array(desc.T['mean'])\r\nSTD = np.array(desc.T['std'])\r\n\r\ndef normalize_numeric_data(data, mean, std):\r\n\r\n    return(data-mean)/std\r\n\r\nnormalizer = functools.partial(normalize_numeric_data, mean = MEAN, std = STD)\r\n\r\nnumeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\r\nnumeric_columns = [numeric_column]\r\nnumeric_column\r\n\r\nexample_batch['numeric']\r\n\r\nnumeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\r\nnumeric_layer(example_batch).numpy()\r\n\r\npreprocessing_layer = numeric_layer\r\n\r\nprint(preprocessing_layer(example_batch).numpy()[0])\r\n\r\nmodel = tf.keras.Sequential([\r\n    preprocessing_layer,\r\n    tf.keras.layers.Dense(128, activation='relu'),\r\n    tf.keras.layers.Dense(128, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid'),\r\n])\r\n\r\nmodel.compile(\r\n    loss='binary_crossentropy',\r\n    optimizer='adam',\r\n    metrics=['accuracy']\r\n)\r\n\r\ntrain_data = packed_train_data.shuffle(500)\r\ntest_data = packed_test_data\r\n\r\nmodel.fit(train_data, epochs = 20)\r\n\r\ntest_loss, test_accuracy = model.evaluate(test_data)\r\n\r\nprint('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))\r\n```\r\n\r\n<img width=\"1138\" alt=\"Bildschirmfoto 2020-01-22 um 11 49 44\" src=\"https://user-images.githubusercontent.com/60178097/72888143-4df51d00-3d0d-11ea-9c35-4246f5b36093.png\">\r\n\r\n", "comments": ["@christian-ri, I tried executing Load CSV data tutorial but it worked without error. \r\nCan you check once and let us confirm. Thanks! ", "I will tell you when I checked it. Thank you so far!", "@gadagashwini I get the same error for the code used in the tutorial. Do you have any suggestions? \r\n<img width=\"1351\" alt=\"Bildschirmfoto 2020-01-23 um 13 42 45\" src=\"https://user-images.githubusercontent.com/60178097/72985431-405f9600-3de6-11ea-8a36-8a6261baea14.png\">\r\n", "@gadagashwini Note that colab hides `stderr` from the C++ TensorFlow runtime by default so the error won't show up in the UI. However the error will still be thrown if executed as a normal Python script.\r\n\r\nCheckout [this colab notebook](https://colab.research.google.com/drive/1-M0IxI6klmtViFSTbPR2jDZP-xEv2Z-H) which reproduces the error using the following snippet:\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\ndataset = tfds.load(\"mnist\", split=\"train\")\r\nval_dataset = tfds.load(\"mnist\", split=\"test\")\r\n\r\ndef preprocessing(data):\r\n    return tf.cast(data[\"image\"], tf.float32), data[\"label\"]\r\n\r\ndataset = (\r\n    dataset.cache()\r\n    .shuffle(4 * 1024)\r\n    .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE,)\r\n    .batch(1024)\r\n    .prefetch(1)\r\n)\r\n\r\nval_dataset = (\r\n    val_dataset.cache()\r\n    .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE,)\r\n    .batch(1024)\r\n    .prefetch(1)\r\n)\r\n\r\nmodel = tf.keras.models.Sequential(\r\n    [\r\n        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\r\n        tf.keras.layers.Dense(64, activation=\"relu\"),\r\n        tf.keras.layers.Dense(10, activation=\"softmax\"),\r\n    ]\r\n)\r\n\r\nmodel.compile(\r\n    optimizer=\"adam\",\r\n    loss=\"sparse_categorical_crossentropy\",\r\n    metrics=[\"accuracy\", \"sparse_top_k_categorical_accuracy\"],\r\n)\r\n\r\nmodel.fit(dataset, epochs=5, validation_data=val_dataset)\r\n```", "@lgeiger Thank you for your answer! So does this mean, the error is actually no error and has nothing to do with the calculation?", "> So does this mean, the error is actually no error and has nothing to do with the calculation?\r\n\r\nI think the error still needs to be fixed, it is just not showing up in colab since it logs inside C++", "@omalleyt12 Any updates on this?  Is there more information we could provide?", "This issue doesn't show up in `tf-nightly==2.2.0.dev20200218` anymore. It would be nice if this could be backported, but at least v2.2 will include a fix for it.", "@lgeiger \r\nThank you very much for your efforts!\r\nIt would be great if the issue is solved in further versions. \r\nHope so.\r\n\r\nRegards", "Thanks for the issue! This is fixed in the latest tf-nightly. Unfortunately, we can't backport fixes of this nature to earlier versions", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36126\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36126\">No</a>\n"]}, {"number": 36125, "title": "Docstring link fix", "body": "Current https://groups.google.com/a/tensorflow.org/g/build/c/SsW98Eo7l3o link in `configure.py` `is_reduced_optimize_huge_functions_available` docstring is broken, https://groups.google.com/a/tensorflow.org/d/topic/build/SsW98Eo7l3o/discussion works better.\r\n\r\nOriginally added by https://github.com/tensorflow/tensorflow/commit/6d7c376df81efecef9ef69ff865b5ae02ad4ab59", "comments": ["Thanks for the fix. Both of these seem to be working for me with the newer Google Groups interface; is the old link broken in the old one?", "@angerson I can't find a way to switch between an older and newer Google Groups interface, don't know which one I have.\r\n\r\n![image](https://user-images.githubusercontent.com/140952/72924680-a3ebb400-3d51-11ea-8514-e33b4d0f3a72.png)\r\n\r\nOriginal link is simply giving an 404, so maybe the new interface is Google internal...\r\n![image](https://user-images.githubusercontent.com/140952/72924770-c7aefa00-3d51-11ea-9066-57e30b5e4bb6.png)\r\n", "Weird, I think you're right. I'm surprised that Groups added something backwards-incompatible like that."]}, {"number": 36124, "title": "TFLu: Updated CMSIS URL", "body": "Just updated the CMSIS URL", "comments": ["Changes have been submitted internally , waiting for auto merge to happen, thank you"]}, {"number": 36123, "title": "ERROR: intel-tensorflow has an invalid wheel", "body": "Are you maintaining intel-tensorflow?\r\n\r\nWith pip 20.0.1:\r\n```\r\n$ pip install intel-tensorflow\r\nCollecting intel-tensorflow\r\n  Downloading intel_tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (133.7 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133.7 MB 53.8 MB/s \r\nERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info\r\n```\r\nI guess the error is related to new pip.", "comments": ["/cc @chuanqi129", "We are not maintaining that wheel, I think this should be redirected to Intel.", "@djstrong ,\r\nCan you please check @mihaimaruseac  update on this and redirect to Intel?thanks!", "Unfortunately, I can't find contact information to Intel.", "yeah, this is a known issue with pip 20* versions and we will fix it in the next release. the install will work on versions 19 and before.", "Hi @djstrong, we have released intel-tensorflow 2.0.1 to fix the multiple .dist-info dirs in wheels, please have a try on it. Thanks.", "@penpornk ", "@Jianhui-Li Thank you!\r\n@chuanqi129 intel-tensorflow 2.0.1 seems to only be available on `pip3`. Do you plan on adding it to `pip`, or have you discontinued Python 2 support? Just for my information. Thank you!\r\n\r\n@djstrong I have verified that `pip3 install intel-tensorflow==2.0.1` works. Please let us know if this works for you. Thank you!", "Thanks @penpornk for your verification. Yes, we have discontinued Python 2 support.", "@djstrong Have your issue disappeared? If yes, could you close it?", "Yes, thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36123\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36123\">No</a>\n", "pip install pip==19 solves this problem\r\n"]}, {"number": 36122, "title": "Code will not compile Image classification", "body": "https://www.tensorflow.org/tutorials/images/classification\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThere's a bug in code\r\n\r\n`history = model.fit_generator(\r\n    train_data_gen,\r\n    steps_per_epoch=total_train // batch_size,\r\n    epochs=epochs,\r\n    validation_data=val_data_gen,\r\n    validation_steps=total_val // batch_size\r\n)`\r\n\r\nwhere\r\n`    steps_per_epoch=total_train // batch_size,\r\n`\r\nwill not compile because the , is behind the comment. The correct code should be\r\n`history = model.fit_generator(\r\n    train_data_gen,\r\n    steps_per_epoch=total_train, // batch_size\r\n    epochs=epochs,\r\n    validation_data=val_data_gen,\r\n    validation_steps=total_val // batch_size\r\n)`", "comments": ["@blyscuit `total_train // batch_size` is integer devision of `total_train` and `batch_size`.\r\nIn python 3, `a / b` is floating point devision and `a // b` is integer devision :) "]}, {"number": 36121, "title": "Installation broken - Tensorflow 2.1 Cuda 10.1 Ubuntu 18.04", "body": "Having followed the installation guide for GPU support multiple times, each time starting from a blank Ubuntu 18.04 LTS instance it breaks when installing cuda 10-1 after installing the driver and rebooting.\r\n\r\nSee guide for Ubuntu 18.04 + Cuda 10.1: https://www.tensorflow.org/install/gpu\r\nCuda 10.1 is the version with which Tensorflow 2.1 is compiled and therefore Cuda 10.1 needs to be installed.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS\r\n- TensorFlow installed from (source or binary): Tensorflow 2.1 binary\r\n- TensorFlow version: 2.1\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Tesla T4\r\n\r\nHaving restarted the machine and confirmed that the driver recognises the GPU:\r\nThe installation guide for GPU support breaks at this section:\r\n```\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n```\r\nWhich results in:\r\n```\r\nSome packages could not be installed. This may mean that you have\r\nrequested an impossible situation or if you are using the unstable\r\ndistribution that some required packages have not yet been created\r\nor been moved out of Incoming.\r\nThe following information may help to resolve the situation:\r\n\r\nThe following packages have unmet dependencies:\r\n cuda-10-1 : Depends: cuda-runtime-10-1 (>= 10.1.243) but it is not going to be installed\r\n             Depends: cuda-demo-suite-10-1 (>= 10.1.243) but it is not going to be installed\r\nE: Unable to correct problems, you have held broken packages.\r\n```\r\nHaving searched stackoverflow, github and the Tensorflow website, it seems that the dependencies list can not be installed. \r\n\r\nAgain, I have rerun this installation multiple times on a *blank* machine, without running *anything else* before trying to run this installation.\r\n", "comments": ["Can you try installing the 2 deps in `Depends:`?", "Yes tried that, but it gets stuck at installing cuda-**** something. Attempted to run this multiple times but for some reason it doesn't find one of the packages.\r\n\r\nNeed to try this again to see which specific package it wouldn't install..", "Report on installing dependencies:\r\n\r\n```\r\nSome packages could not be installed. This may mean that you have\r\nrequested an impossible situation or if you are using the unstable\r\ndistribution that some required packages have not yet been created\r\nor been moved out of Incoming.\r\nThe following information may help to resolve the situation:\r\n\r\nThe following packages have unmet dependencies:\r\n cuda-10-1 : Depends: cuda-runtime-10-1 (>= 10.1.243) but it is not going to be installed\r\n             Depends: cuda-demo-suite-10-1 (>= 10.1.243) but it is not going to be installed\r\nE: Unable to correct problems, you have held broken packages.\r\n```\r\n Installing cuda-runtime-10-1 results in:\r\n```\r\nsudo apt-get install cuda-runtime-10-1\r\n...\r\nThe following packages have unmet dependencies:\r\n cuda-runtime-10-1 : Depends: cuda-drivers (>= 418.87) but it is not going to be installed\r\nE: Unable to correct problems, you have held broken packages.\r\n```\r\n\r\nInstalling cuda-drivers results in:\r\n```\r\nsudo apt-get install cuda-drivers\r\n...\r\nThe following packages have unmet dependencies:\r\n cuda-drivers : Depends: libnvidia-fbc1-440 (>= 440.33.01) but it is not going to be installed\r\n                Depends: nvidia-compute-utils-440 (>= 440.33.01) but it is not going to be installed\r\n                Depends: nvidia-driver-440 (>= 440.33.01) but it is not going to be installed\r\n                Depends: xserver-xorg-video-nvidia-440 (>= 440.33.01) but it is not going to be installed\r\n```\r\n\r\nInstalling ```libnvidia-fbc1-440``` is successful and then also lets me install ```cuda-drivers```.\r\ncuda-drivers installation is successful and now it appears I can run this part from the guide without problems:\r\n```\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n```\r\n\r\nHowever, when testing to see if Tensorflow GPU works, this is the result:\r\n```\r\nPython 3.6.9 (default, Nov  7 2019, 10:44:02) \r\n[GCC 8.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2020-01-27 13:08:06.076513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-01-27 13:08:06.078594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n>>> tf.config.list_physical_devices('GPU')\r\n2020-01-27 13:08:13.950792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-01-27 13:08:13.952790: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\r\n2020-01-27 13:08:13.952841: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: adaptive-3\r\n2020-01-27 13:08:13.952857: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: adaptive-3\r\n2020-01-27 13:08:13.952948: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.33.1\r\n2020-01-27 13:08:13.952988: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.50.0\r\n2020-01-27 13:08:13.953003: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 430.50.0 does not match DSO version 440.33.1 -- cannot find working devices in this configuration\r\n[]\r\n```\r\n\r\nWhat installation steps for the cuda dependencies that work for Tensorflow 2.1 GPU on Linux Ubuntu?", "Update 2:\r\n\r\nWhen trying to reinstall ```sudo apt-get install --no-install-recommends nvidia-driver-418``` from the guide:\r\n```\r\nThe following packages have unmet dependencies:\r\n nvidia-driver-418 : Depends: nvidia-driver-430 but it is not going to be installed\r\nE: Unable to correct problems, you have held broken packages.\r\n```\r\n\r\nIt appears that Nvidia driver 418 depends on 430. When trying to install nvidia-driver 430 I ran into the same problem of many broken packages which would not be installed.\r\n\r\nAfter successfully installing nvidia-driver-430 by going down the rabit hole of broken packages and installing each individiually, nvidia-smi output:\r\n```\r\nnvidia-smi\r\nMon Jan 27 13:14:10 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\r\n| N/A   53C    P0    28W /  70W |      0MiB / 15109MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nAfter this testing Tensorflow 2.1 with list devices does seem to work:\r\n```\r\nPython 3.6.9 (default, Nov  7 2019, 10:44:02) \r\n[GCC 8.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2020-01-27 13:15:54.758171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-01-27 13:15:54.760036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n>>> tf.config.list_physical_devices('GPU')\r\n2020-01-27 13:16:08.210038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-01-27 13:16:08.908023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-27 13:16:08.908709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\r\ncoreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\r\n2020-01-27 13:16:08.908758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-01-27 13:16:08.908799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-01-27 13:16:08.911539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-01-27 13:16:08.912234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-01-27 13:16:08.914737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-01-27 13:16:08.916157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-01-27 13:16:08.916220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-01-27 13:16:08.916306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-27 13:16:08.916993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-27 13:16:08.917573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n```\r\n\r\nDoes Tensorflow 2.1 require nvidia-driver-430 instead of 418 and should the documentation be updated?", "2.1 uses CUDA 10.1", "Hi @mihaimaruseac \r\n\r\n10.1 is indeed the CUDA version that I am installing, because the current documentation does refer to that version for Tensorflow 2.1: https://www.tensorflow.org/install/gpu\r\n\r\nIt turns out the Nvidia *driver* needs to be 430 instead of 418 to make it work on Linux Ubuntu 18.04. \r\n\r\nI think the documentation needs to be updated to reflect the new driver version right?\r\nOr do you mean to say something else with your comment?", "You are right, I misunderstood.\r\n", "@igorhoogerwoord Thanks for sharing your findings.\r\nOn the TF website currently we say `CUDA 10.1 requires 418.x or higher.`\r\nhttps://www.tensorflow.org/install/gpu#software_requirements", "Is that helpful for people installing Tensorflow though?\r\nAs it appears Nvidia only makes 430 available for Ubuntu?\r\n\r\n-> The installation errors with the Nvidia cuda code took long to figure out because the driver version in the install script from the document says driver version 418 while this version can not actually be installed on Linux Ubuntu 18.04.", "Thanks. Can you send a PR for that page in the tensorflow/docs repo: https://github.com/tensorflow/docs/blob/master/site/en/install/gpu.md\r\n\r\nBut verifying will take longer", "Can someone else commit this?: https://github.com/tensorflow/docs/pull/1450", "--- **Possible solution here** differing from above driver problem ---\r\nA few comments from my side, as I've been struggling with a similar problem with a slightly different root cause: Couldn't install cuda-10-1, but nvidia-driver installation went well for me (TF-nightly (2.2), Ubuntu 18.04, GTX 1660Ti).\r\n\r\n0. Starting from a CLEAN MACHINE (delete your ./cache/pip/ if you have to).\r\n1. Created and activated conda environment with `python=3.6`\r\n2. `pip install tf-nightly` (installs 2.2.0 at this time of writing)\r\n3. Then followed the entire block in the [Tensorflow GPU manual](https://www.tensorflow.org/install/gpu) with no problems:\r\n```\r\n# Add NVIDIA package repositories\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.1.243-1_amd64.deb\r\nsudo dpkg -i cuda-repo-ubuntu1804_10.1.243-1_amd64.deb\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo apt-get update\r\nwget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\r\nsudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\r\nsudo apt-get update\r\n```\r\n4. Next block:\r\n```\r\n# Install NVIDIA driver\r\nsudo apt-get install --no-install-recommends nvidia-driver-418\r\n# Reboot. Check that GPUs are visible using the command: nvidia-smi\r\n```\r\nThis worked well for me as opposed to for @igorhoogerwoord as the 418 driver is automatically fetched as 430.50. For anyone who's interested: After a reboot, open the Ubuntu \"software update\" settings, go to the tab \"additional drivers\", and see whether the correct version is selected (430 should be selected). In a terminal, `nvidia-smi` should say:\r\n`| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |`\r\nThis is why I think the official instructions are okay here. Verification comes from this fact:\r\n```\r\n$ sudo apt-get install nvidia-driver-418\r\nnvidia-driver-418 is already the newest version (430.50-0ubuntu0.18.04.2).\r\n```\r\n5. But then, next step from the manual:\r\n```\r\n# Install development and runtime libraries (~4GB)\r\nsudo apt-get install --no-install-recommends cuda-10-1\r\ncuda-10-1 : Depends: cuda-runtime-10-1 (>= 10.1.243) but it is not going to be installed\r\n            Depends: cuda-demo-suite-10-1 (>= 10.1.243) but it is not going to be installed\r\nE: Unable to correct problems, you have held broken packages.\r\n```\r\nTrying to install the depends just lead to hair loss.\r\n\r\n6. Anyways, left it at that and continued with the rest of the manual:\r\n```\r\nsudo apt-get install --no-install-recommends libcudnn7=7.6.4.38-1+cuda10.1\r\nsudo apt-get install --no-install-recommends libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n\r\n# Install TensorRT. Requires that libcudnn7 is installed above.\r\nsudo apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1\r\nsudo apt-get install -y --no-install-recommends libnvinfer-dev=6.0.1-1+cuda10.1\r\nsudo apt-get install -y --no-install-recommends libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n```\r\nAll of these went well. Notice I did them all in clear separate steps.\r\n\r\n7. But how to install CUDA? After hours of cursing I decided to solve it dirtily:\r\n`conda install cudatoolkit=10.1.243`\r\nFollowing this, my tensorflow programs run just fine!\r\n\r\nNonetheless, the manual needs a major overhaul. It says \"The following NVIDIA\u00ae software must be installed on your system\" right before the Linux manual where everything is installed again. It just confuses the user where to start.\r\n\r\n**ADDENDUM**\r\nYou might notice that installing the packages in step 6 actually installs some CUDA 10.2 related things, particularly `libcublas`. You can check this by typing:\r\n```\r\ndpkg -l | grep libcublas\r\nlibcublas-dev       10.2.2.89-1       amd64    CUBLAS native dev links, headers\r\nlibcublas10         10.2.2.89-1       amd64    CUBLAS native runtime libraries\r\n```\r\nI had problems with this version mix before, so I decided to clean this up for once and for all:\r\n```\r\nsudo apt-get install libcublas-dev=10.2.1.243-1\r\nsudo apt-get install libcublas10=10.2.1.243-1\r\n```\r\nThe version numbers are a mess, 10.2.2 is CUDA 10.2 and 10.2.1 is CUDA 10.1.\r\nDowngrading libcublas will also trigger the cuda-license-10-2 package to become obsolete.", "Closing this issue since the associated PR has been merged. Feel free to reopen if necessary.\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36121\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36121\">No</a>\n", "\r\nIf anyone is still looking for a solution, try the following.\r\nNote: It was tried on Cuda 10.2, nvidia-450:\r\n\r\nAfter following the [installation guide for GPU](https://www.tensorflow.org/install/gpu#install_cuda_with_apt) till \"Install nvidia driver\"\r\n\r\n`\r\nsudo apt-get install nvidia-settings\r\n\r\nsudo apt-get install cuda-drivers-450\r\n\r\nsudo apt-get install cuda-runtime-10-2\r\n\r\nsudo apt-get install cuda-demo-suite-10-2\r\n\r\nsudo apt-get install  \\\r\n    cuda-10-2 \\\r\n    libcudnn7=7.6.5.32-1+cuda10.2  \\\r\n    libcudnn7-dev=7.6.5.32-1+cuda10.2\r\n\r\nexport PATH=/usr/local/cuda/bin:$PATH  \r\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\r\n\r\nsource ~/.bashrc\r\n`"]}, {"number": 36120, "title": "TFLite for Microcontrollers: Compilation issues for operators for bare metal", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Host: macOS 10.14.6, Target Tiva TM4C123\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.14 \r\n    - The pre-generated projects in the [porting guide of the TFLite micro readme](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/README.md) are based on 1.14, I tried to upgrade to a more recent version but somehow the micro interpreter fails to read the model correctly.\r\n    - When verifying the model and its inputs, `input->dims->size` contains a very large number which is incorrect.\r\n- Python version: 3.6.9 (Anaconda)\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 1.2.1\r\n- GCC/Compiler version (if compiling from source): TI ARM C/C++ Compiler                   v18.12.4.LTS\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n**Describe the problem**\r\nI am trying to port tflite for microcontrollers to a new target. As described in [this guide](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/README.md), I used an example project (the fully connected test project), which I managed to compile quickly without any issues. I am aware that I am not using a compiler for which there are any example projects but that has not been an issue so far. I have managed to initialize and run the model, up to the point where some TF operators are missing, such as `SUB`, or `CAST`. \r\n\r\nNow that I've added `lite/kernels/sub.cc` (there is no `sub.cc` in the folder `experimental/micro`) I need to include `lite/kernels/optimized/cpu_check.h` which depends on `lite/kernels/cpu_backend_context.h`, which in turn depends on `gemmlowp`. I haven't managed to compile `gemmlowp` because it depends on many OS dependent sources. However I read in the readme for TFLite for microcontrollers that there should be no such dependencies.\r\n\r\nIt seems to me that these operators have not yet been ported, and I am aware that this is in a highly experimental state and subject to radical changes. Can someone give me any hints on what I could do? Is there a way that could help me include these operators in the project by maybe stripping things from the \"normal\" tflite implementation? I don't think I need anything from `unistd.h` which `gemmlowp` depends on.\r\n\r\n**Any other info / logs**\r\nMy model is generated by [ml-agents](https://github.com/Unity-Technologies/ml-agents) which uses `tensorflow>=1.7,<2.1`, and stores the models as frozen graphs. This may cause limitations, if not issues.\r\n\r\nI am more than happy to provide anything that might provide any more necessary information\r\n", "comments": ["Hi @dav1d-wright ! We are checking to see if you still need help in this issue , Have you tried latest stable version TF 2.6  yet ? Many features have been added in latest versions.Please create a new issue if the issue is replicating in newer version. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36120\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36120\">No</a>\n"]}, {"number": 36119, "title": "null", "body": "null", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36119\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36119\">No</a>\n"]}, {"number": 36118, "title": "Riscv 32 mcu", "body": "Update for this pull request(reviewed by @nkreeger before):\r\nhttps://github.com/tensorflow/tensorflow/pull/33680  (Will close) \r\nhttps://github.com/tensorflow/tensorflow/pull/36095 (by @jpienaar before) \r\n\r\nrelated issues:\r\nhttps://github.com/tensorflow/tensorflow/issues/32041\r\nhttps://github.com/tensorflow/tensorflow/issues/33677\r\n\r\nIf possible, pls review as soon as possible, the tensorflow repo is very easy to get conflict because update so quickly.  Thanks,\r\n\r\nAbout the three patches for review:\r\n1) lite:micro:tools:make: Move the default target(all) up before any others.\r\n    \r\n The default Makefile target `all` is compiled if there's no command-line arguments.\r\n\r\n2) lite:micro:riscv32_mcu:Fix build failure of undefined references.\r\n    \r\n    Fix the ld error:\r\n    undefined references to `__wrap_puts` for build commands like `make -f tensorflow/lite/micro/tools/make/Makefile TARGET=riscv32_mcu hello_world_bin`\r\n    The related issue is tensorflow#32041\r\n\r\n    Refactoring, suggested by Nick Kreeger(nick.kreeger@gmail.com):\r\n    The targets/mcu_riscv_makefile.inc should only include the bare-bones parts for building for this platform.\r\n    So move platform specific items from targets/mcu_riscv_makefile.inc to the actual example folder.\r\n    Create a riscv32_mcu folder in each example directory. In those directories, create a new Makefile.inc that adds these rules moved out.    \r\n\r\n    The bug's original reasons:\r\n    The Makefile variables XXX_TEST_SRCS/XXX_SRCS in targets/mcu_riscv_makefile.inc are overridden by the the examples's respective makefile.inc (eg. hello_world/Makefile.inc), which leads to the   architecture special __wrap__funs are not included correctly.\r\n\r\n3) lite:micro:riscv32_mcu: Fix hidden symbol `__dso_handle' isn't defined.\r\n For arduino sketch in riscv_mcu examples, this patch fix by declare the global variable `void* __dso_handle;`.\r\n\r\n", "comments": []}, {"number": 36117, "title": "export CombinerPreprocessingLayer and Combiner", "body": "We will need to implement some custom preprocessing layers which should override the CombinerPreprocessingLayer.\r\nI export these two classes to override.\r\nOr any other suggestions for reusing the code in these two classes?", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36117) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36117) for more info**.\n\n<!-- ok -->", "@haifeng-jin Can you please resolve conflicts? Thanks!", "@gbaned Conflicts resolved. Thanks", "This will likely not pass tests since it requires proto definition. If you need, can you email me and Francois so we can do this for you?", "@tanzhenyu I need these mainly for implementing a preprocessing layer that encodes the categorical features into numerical features for structured data.\r\nHowever, I noticed there are some such preprocessing layers on the way in TF 2.2. If so, I don't need these classes now.\r\n\r\nI may need it in the future, we can discuss whether to do it with the team during my internship : )\r\n\r\nThank you!", "Haifeng, can you take a look at this?\r\nhttps://github.com/tensorflow/community/pull/188\r\n\r\nIt was reviewed and implemented, I haven't merged this into master yet.", "@haifeng-jin Could you please check the reviewer comments and keep us posted? Thanks!", "@gbaned As I discussed with @tanzhenyu, we will wait until the feature in tensorflow/community#188 is confirmed to see if we really my PR or not. \r\n\r\nIf we still need it, I will fix the tests.\r\nThis PR currently is not likely to pass the tests.\r\n\r\nThank you.", "Closing this PR per above discussion."]}, {"number": 36116, "title": "Multiple outputs from a keras model", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 1.15.0-rc1-11276-gc9f7f636eb 2.1.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): gcc-7\r\n- CUDA/cuDNN version: 10.1/7.6.3\r\n- GPU model and memory: GTX1080Ti 11GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI have a custom (keras) CNN model as well as a custom loss function.\r\n\r\nThe model has two inputs at one resolution and multiple (6) outputs at different resolutions (each output has a different resolution). \r\n\r\nThe dataset, from a TFRecord file, has the 2 image inputs and 1 ground truth image as an output.\r\n\r\nThe loss function expects to receive the single ground truth image as `y_true` and the 6 outputs in a list as `y_pred` and will then calculate the loss value based on this.\r\n\r\nWith this scenario, I get the following error\r\n```\r\nValueError: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 6 array(s), for inputs ['output_1', 'output_2', 'output_3', 'output_4', 'output_5', 'output_6'] but instead got the following list of 1 arrays: [<tf.Tensor 'args_5:0' shape=(None, 384, 768, 1) dtype=float32>]...\r\n```\r\n\r\nIf I modify my dataset loading code so that it resizes the ground truth image into a list of images with appropriate resolutions to match my networks output, I get the following error\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [270,480,1] != values[1].shape = [135,240,1]\r\n\t [[{{node packed}}]]\r\n```\r\n\r\n**Describe the expected behavior**\r\nI expect that TF/keras would allow at least one of these scenarios.\r\n\r\n\r\nIs there an accepted way to handle this sort of situation?", "comments": ["@Bidski \r\n\r\nCan you please provide colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!", "```import sys\r\nimport tensorflow as tf\r\n\r\n\r\n@tf.function\r\ndef parse_entry(entry):\r\n    feature_description = {\r\n        \"image_l\": tf.io.FixedLenFeature(shape=[], dtype=tf.string),\r\n        \"image_r\": tf.io.FixedLenFeature(shape=[], dtype=tf.string),\r\n        \"disparity_l\": tf.io.FixedLenSequenceFeature(shape=[], dtype=tf.float32, allow_missing=True),\r\n    }\r\n\r\n    example = tf.io.parse_single_example(entry, feature_description)\r\n\r\n    example[\"image_l\"] = tf.io.decode_image(example[\"image_l\"], channels=0, dtype=tf.dtypes.uint8)\r\n    example[\"image_r\"] = tf.io.decode_image(example[\"image_r\"], channels=0, dtype=tf.dtypes.uint8)\r\n    example[\"disparity_l\"] = tf.reshape(example[\"disparity_l\"], (540, 960, 1))\r\n\r\n    return (example[\"image_l\"], example[\"image_r\"]), example[\"disparity_l\"]\r\n\r\n\r\n@tf.function\r\ndef normalise(x, y):\r\n    img_l = tf.image.convert_image_dtype(x[0], dtype=tf.dtypes.float32, name=\"convert1\")\r\n    img_r = tf.image.convert_image_dtype(x[1], dtype=tf.dtypes.float32, name=\"convert2\")\r\n\r\n    return (img_l, img_r), y\r\n\r\n\r\n@tf.function\r\ndef fixup_shape(x, y):\r\n    x[0].set_shape([540, 960, 3])\r\n    x[1].set_shape([540, 960, 3])\r\n    y.set_shape([540, 960, 1])\r\n\r\n    return x, y\r\n\r\n\r\n@tf.function\r\ndef scale_output_resolution(x, y):\r\n    if False:\r\n        disparities = [\r\n            tf.image.resize(\r\n                y,\r\n                size=(tf.math.divide(540, tf.math.pow(2, n)), tf.math.divide(960, tf.math.pow(2, n))),\r\n                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR,\r\n            )\r\n            for n in range(1, 3)\r\n        ]\r\n    else:\r\n        if False:\r\n            disparities = [y for _ in range(1, 3)]\r\n        else:\r\n            disparities = y\r\n\r\n    return x, disparities\r\n\r\n\r\ndef create_dataset(path):\r\n    dataset = tf.data.TFRecordDataset(path)\r\n    dataset = dataset.map(parse_entry)\r\n    dataset = dataset.map(normalise)\r\n    dataset = dataset.map(fixup_shape)\r\n    dataset = dataset.map(scale_output_resolution)\r\n    dataset = dataset.batch(batch_size=1, drop_remainder=False)\r\n\r\n    return dataset\r\n\r\n\r\nclass TestModel(tf.keras.Model):\r\n    def __init__(self, **kwargs):\r\n        super(TestModel, self).__init__(**kwargs)\r\n\r\n        self.conv1 = tf.keras.layers.Conv2D(filters=2, kernel_size=(7, 7), strides=(2, 2), padding=\"same\", name=\"conv1\")\r\n        self.conv2 = tf.keras.layers.Conv2D(filters=1, kernel_size=(7, 7), strides=(2, 2), padding=\"same\", name=\"conv2\")\r\n\r\n    def call(self, inputs):\r\n        x = self.conv1(tf.concat(inputs, axis=-1, name=\"concat\"))\r\n        y = self.conv2(x)\r\n\r\n        return [x, y]\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.config.experimental_run_functions_eagerly(True)\r\n\r\n    train_dataset = create_dataset(sys.argv[1])\r\n    valid_dataset = create_dataset(sys.argv[2])\r\n\r\n    model = TestModel()\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.Adam(),\r\n        loss=tf.keras.losses.MeanAbsoluteError(),\r\n        metrics=[tf.keras.metrics.Accuracy],\r\n    )\r\n    model.fit(x=train_dataset, validation_data=valid_dataset, validation_steps=None, validation_freq=1, epochs=1)\r\n```\r\n\r\nThis code generates a slightly different error when resizing the ground truth images\r\n```\r\nValueError: Value [<tf.Tensor 'resize/Squeeze:0' shape=(270, 480, 1) dtype=float32>, <tf.Tensor 'resize_1/Squeeze:0' shape=(135, 240, 1) dtype=float32>] is not convertible to a tensor with dtype <dtype: 'float32'> and shape (2, None, None, 1).\r\n```\r\nbut otherwise this code behaves similarly to what I described above.\r\n\r\nPlay with the `if` statement conditions in the `scale_output_resolution` function see the different behaviours.\r\n\r\nRun the code as `python ./test.py ./train.tfrecord ./valid.tfrecord`.\r\n\r\nHere are some links to tfrecord files to test.\r\n[train.tfrecord](https://drive.google.com/open?id=1G3Ta5Ifm9tS3HXt6gGzHfwt06_Xm5hAg)\r\n[valid.tfrecord](https://drive.google.com/open?id=1oH5AGJPcqZLcI13FxAFWRSnJ0efecOJm)", "@Bidski \r\n\r\nI have tried on colab with TF version 2.1.0-rc2 and i am seeing different error message.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/c726a43c31ad0882f8c06d825e452ec0/untitled589.ipynb). Thanks!", "@ravikyram that looks to be the same error message that I reported originally?", "@Bidski \r\nI had a similar issue. I have two feature arrays as inputs to the network and an output vector.\r\nAfter calling:\r\n`for f0, f1 in train_ds.take(1):\r\n  print(f0.shape)\r\n  print(f1.shape)`\r\nI get output:\r\n`(16, 2, 1000, 3)\r\n(16, 9)`\r\n\r\nHowever, `model.fit` returns the same error", "I also have this issue when I call 'predict' of a model with multiple outputs.\r\n\r\nReproduction:\r\nThe following code works perfectly in **2.0**, while it gets the error 'ValueError: Error when checking model....' with tf **2.1**.\r\nhttps://colab.research.google.com/drive/1hMLd5-r82FrnFnBub-B-fVW78Px4KPX1\r\n\r\nAnyone can fix it?\r\nThanks.", "Same here: i extract losses from several layers, but loss function is the same for me. Compilation succeeds, but **.fit** fails:\r\n\r\n> ValueError: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 11 array(s), for inputs [...layer names deleted...] but instead got the following list of 1 arrays: [<tf.Tensor 'args_1:0' shape=(None, None) dtype=float64>]\r\n\r\np.s. **.predict** might be a different issue, it works fine for me.\r\n", "Here is reproducible example:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nnum_examples = 1000\r\ninput_shape = (10,)\r\nloss_dim = 3\r\nnum_losses = 2\r\n\r\nfeatures = np.random.random(size=[num_examples] + list(input_shape))\r\nlabels = np.random.random(size=[num_examples, num_losses, loss_dim])\r\n\r\ninputs = tf.keras.Input(shape=input_shape, name='features')\r\nl1 = tf.keras.layers.Dense(loss_dim, activation='relu', name='l1')(inputs)\r\nl2 = tf.keras.layers.Dense(loss_dim, activation='relu', name='l2')(l1)\r\nmodel = tf.keras.Model(inputs=inputs, outputs=[l1, l2])\r\n\r\ndef loss(y, y_hat):\r\n    return tf.abs(y - y_hat)\r\n\r\nmodel.compile(optimizer='adam', loss=[loss, loss], loss_weights=[0.2, 1.])\r\n\r\nmodel.fit(\r\n    features, \r\n    labels,\r\n    validation_split=0.2,\r\n    epochs=10,\r\n    batch_size=32\r\n)\r\n```\r\ni tried this shape too:\r\n`labels = np.random.random(size=[num_losses, num_examples, loss_dim])`\r\n\r\nif i convert labels into list, it works:\r\n\r\n```\r\nlabel_list = [l for l in labels.reshape(num_losses, num_examples, loss_dim)]\r\nmodel.fit(\r\n    features, \r\n    label_list,\r\n    validation_split=0.2,\r\n    epochs=10,\r\n    batch_size=32\r\n)\r\n```\r\n\r\nMain problem though for me is how to put this into a DataSet, which does not support anything besides tensors, i cannot use above solution for a DataSet, unless i missed some functionality.", "Is this https://github.com/keras-team/keras-preprocessing/issues/295 somehow related?", "@Strateus  I updated your code for multiple outputs. It works as expected. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/75728eb4b473e3b9fb75983b6e34cbfa/untitled984.ipynb).  Thanks!\r\n\r\n@Bidski Is this still an issue for you?  Also, please check [Functional API guide](https://www.tensorflow.org/guide/keras/functional) for detailed guide on multiple-inputs and multiple-outputs model. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36116\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36116\">No</a>\n"]}, {"number": 36115, "title": "Sampled Softmax for Tensorflow Keras", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nThis is a feature request for sampled softmax loss in Tensorflow-2 Keras. The sampled softmax loss is important when dealing with large number of target classes mainly in sequence to sequence models.\r\n\r\nSampled softmax is available in tensorflow via `tf.nn.sampled_softmax` but I couldn't find any resource that can help me to use it with tensorflow keras.\r\n\r\n_\r\n\r\n> **Note: If anyone have **implemented it**, **please** share the sample code on how you've achieved it. There are 10's of questions in StackOverflow regarding this without any answer. **\r\n\r\n_\r\n\r\n**Will this change the current api? How?**\r\nNo.\r\n**Who will benefit with this feature?**\r\nThis will benefit those who are dealing with large number of target classes to predict. In such cases softmax is not a ideal solution.", "comments": ["@fchollet Any progress on this? ", "Have you checked \r\n\r\nhttps://stackoverflow.com/q/56821654/9215780\r\n\r\nhttps://stackoverflow.com/q/47892380/9215780", "@innat Actually I tried them for seq2seq model, but they didn't work for me. I'll try them one more, since I don't see this coming anytime soon. But having it natively in Keras is not a bad idea, though.", "@user06039 \r\nPlease refer to below links for reference: \r\n[link](https://www.examplefiles.net/cs/1104466)\r\n[link](https://pretagteam.com/question/sampled-softmax-in-tensorflow-keras)\r\n\r\n\r\n\r\nPlease post this issue on keras-team/keras repo.\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 36114, "title": "Memory leak when use model.fit method with datagenerator", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nit's increasing ram when I use mode.fit() method\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): installed via pip\r\n- TensorFlow version (use command below): tensorflow-gpu 2.1.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GeForce GTX 1060 6GB\r\n\r\n**Describe the current behavior**\r\nRAM memory increases after I fit model. I cannot clear it with any garbage collector etc.\r\n**Describe the expected behavior**\r\nRAM shoud not increases at each epoch of training any model in that way.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nI'm using my own image generator with multioutput:\r\n\r\n**\r\nclass MultiOutputDataGenerator(tf.keras.preprocessing.image.ImageDataGenerator):\r\n\r\n    def flow(\r\n        self,\r\n        x,\r\n        y=None,\r\n        batch_size=32,\r\n        shuffle=True,\r\n        sample_weight=None,\r\n        seed=None,\r\n        save_to_dir=None,\r\n        save_prefix='',\r\n        save_format='png',\r\n        subset=None\r\n    ):\r\n\r\n        targets = None\r\n        target_lengths = {}\r\n        ordered_outputs = []\r\n        \r\n        for output, target in y.items():\r\n            \r\n            if targets is None:\r\n                \r\n                targets = target\r\n                \r\n            else:\r\n                \r\n                targets = np.concatenate((targets, target), axis=1)\r\n                \r\n            target_lengths[output] = target.shape[1]\r\n            ordered_outputs.append(output)\r\n        \r\n            gc.collect()\r\n\r\n        for flowx, flowy in super().flow(x, targets, batch_size=batch_size, shuffle=shuffle):\r\n            \r\n            target_dict = {}\r\n            i = 0\r\n            \r\n            for output in ordered_outputs:\r\n                \r\n                target_length = target_lengths[output]\r\n                target_dict[output] = flowy[:, i: i + target_length]\r\n                i += target_length\r\n                \r\n                gc.collect()\r\n\r\n            yield flowx, target_dict\r\n**\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@dishkakrauch,\r\nCould you post the complete code to reproduce the reported issue. Thanks!", "> @dishkakrauch,\r\n> Could you post the complete code to reproduce the reported issue. Thanks!\r\n\r\nSure! No problem.\r\nTraining data is images with one channel and size 64x64.\r\nThere are three targets for classification (168 classes, 11 classes and 7 classes).\r\nGitHub does not allow me to load csv.\r\nThis is it:\r\n\r\n```\r\nimport warnings\r\nwarnings.filterwarnings('ignore')\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\n#import tqdm\r\nimport gc\r\ngc.enable()\r\nimport os\r\nimport sys\r\nimport graphviz\r\nos.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\r\n\r\nimport tensorflow as tf\r\nimport sklearn\r\nfrom sklearn import *\r\n\r\nimport matplotlib.pylab as plt\r\nimport matplotlib.image as mpimg\r\nimport seaborn as sns\r\nimport cv2\r\nimport PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\r\n\r\nIMG_SIZE = 128\r\nN_CHANNELS = 1\r\n\r\nHEIGHT = 137\r\nWIDTH = 236\r\n\r\ndef resize(df, size, need_progress_bar=False):\r\n    resized = {}\r\n    if need_progress_bar:\r\n        for i in tqdm.tqdm_notebook(range(df.shape[0])):\r\n            image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\r\n            resized[df.index[i]] = image.reshape(-1)\r\n    else:\r\n        for i in range(df.shape[0]):\r\n            image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\r\n            resized[df.index[i]] = image.reshape(-1)\r\n    resized = pd.DataFrame(resized).T\r\n    return resized\r\n\r\ndef get_dummies(df):\r\n    cols = []\r\n    for col in df:\r\n        cols.append(pd.get_dummies(df[col].astype(str)))\r\n    return pd.concat(cols, axis=1)\r\n\r\nclass MultiOutputDataGenerator(tf.keras.preprocessing.image.ImageDataGenerator):\r\n\r\n    def flow(\r\n        self,\r\n        x,\r\n        y=None,\r\n        batch_size=32,\r\n        shuffle=True,\r\n        sample_weight=None,\r\n        seed=None,\r\n        save_to_dir=None,\r\n        save_prefix='',\r\n        save_format='png',\r\n        subset=None\r\n    ):\r\n\r\n        targets = None\r\n        target_lengths = {}\r\n        ordered_outputs = []\r\n        \r\n        for output, target in y.items():\r\n            \r\n            if targets is None:\r\n                \r\n                targets = target\r\n                \r\n            else:\r\n                \r\n                targets = np.concatenate((targets, target), axis=1)\r\n                \r\n            target_lengths[output] = target.shape[1]\r\n            ordered_outputs.append(output)\r\n        \r\n            gc.collect()\r\n\r\n        for flowx, flowy in super().flow(x, targets, batch_size=batch_size, shuffle=shuffle):\r\n            \r\n            target_dict = {}\r\n            i = 0\r\n            \r\n            for output in ordered_outputs:\r\n                \r\n                target_length = target_lengths[output]\r\n                target_dict[output] = flowy[:, i: i + target_length]\r\n                i += target_length\r\n                \r\n                gc.collect()\r\n\r\n            yield flowx, target_dict\r\n\r\ntrain_df = pd.read_csv(path + 'train.csv')\r\ndf_0 = pd.read_feather(path + train_image_data_0.fth')\r\n\r\nbatch_size = 256\r\n\r\ninputs = tf.keras.layers.Input(\r\n    shape=(IMG_SIZE, IMG_SIZE, 1)\r\n)\r\n\r\nmodel = tf.keras.layers.Conv2D(\r\n    filters=32,\r\n    kernel_size=(3, 3),\r\n    strides=(1, 1),\r\n    padding='SAME',\r\n    activation=tf.keras.activations.relu,\r\n    input_shape=(IMG_SIZE, IMG_SIZE, 1)\r\n)(inputs)\r\n\r\nmodel = tf.keras.layers.Conv2D(\r\n    filters=32,\r\n    kernel_size=(3, 3),\r\n    strides=(1, 1),\r\n    padding='SAME',\r\n    activation=tf.keras.activations.relu,\r\n    input_shape=(IMG_SIZE, IMG_SIZE, 1)\r\n)(model)\r\n\r\nmodel = tf.keras.layers.BatchNormalization(\r\n    momentum=.15\r\n)(model)\r\n\r\nmodel = tf.keras.layers.MaxPool2D(\r\n    pool_size=(2, 2),\r\n    strides=None\r\n)(model)\r\n\r\nmodel = tf.keras.layers.Dropout(\r\n    rate=.3\r\n)(model)\r\n\r\nmodel = tf.keras.layers.Conv2D(\r\n    filters=64,\r\n    kernel_size=(3, 3),\r\n    strides=(1, 1),\r\n    padding='SAME',\r\n    activation=tf.keras.activations.relu,\r\n    input_shape=(IMG_SIZE, IMG_SIZE, 1)\r\n)(model)\r\n\r\nmodel = tf.keras.layers.Conv2D(\r\n    filters=64,\r\n    kernel_size=(3, 3),\r\n    strides=(1, 1),\r\n    padding='SAME',\r\n    activation=tf.keras.activations.relu,\r\n    input_shape=(IMG_SIZE, IMG_SIZE, 1)\r\n)(model)\r\n\r\nmodel = tf.keras.layers.BatchNormalization(\r\n    momentum=.15\r\n)(model)\r\n\r\nmodel = tf.keras.layers.MaxPool2D(\r\n    pool_size=(2, 2),\r\n    strides=None\r\n)(model)\r\n\r\nmodel = tf.keras.layers.Dropout(\r\n    rate=.3\r\n)(model)\r\n\r\nmodel = tf.keras.layers.Conv2D(\r\n    filters=128,\r\n    kernel_size=(3, 3),\r\n    strides=(1, 1),\r\n    padding='SAME',\r\n    activation=tf.keras.activations.relu,\r\n    input_shape=(IMG_SIZE, IMG_SIZE, 1)\r\n)(model)\r\n\r\nmodel = tf.keras.layers.Conv2D(\r\n    filters=128,\r\n    kernel_size=(3, 3),\r\n    strides=(1, 1),\r\n    padding='SAME',\r\n    activation=tf.keras.activations.relu,\r\n    input_shape=(IMG_SIZE, IMG_SIZE, 1)\r\n)(model)\r\n\r\nmodel = tf.keras.layers.BatchNormalization(\r\n    momentum=.15\r\n)(model)\r\n\r\nmodel = tf.keras.layers.MaxPool2D(\r\n    pool_size=(2, 2),\r\n    strides=None\r\n)(model)\r\n\r\nmodel = tf.keras.layers.Dropout(\r\n    rate=.3\r\n)(model)\r\n\r\nmodel = tf.keras.layers.Flatten()(model)\r\n\r\n\r\nmodel = tf.keras.layers.Dense(\r\n    units=1024,\r\n    activation=tf.keras.activations.relu\r\n)(model)\r\n\r\nmodel = tf.keras.layers.Dropout(\r\n    rate=0.3\r\n)(model)\r\n\r\ndense = tf.keras.layers.Dense(\r\n    units=512,\r\n    activation = tf.keras.activations.relu\r\n)(model)\r\n\r\nhead_root = tf.keras.layers.Dense(\r\n    units=168,\r\n    activation=tf.keras.activations.softmax,\r\n    name='root'\r\n)(dense)\r\n\r\nhead_vowel = tf.keras.layers.Dense(\r\n    units=11,\r\n    activation=tf.keras.activations.softmax,\r\n    name='vowel'\r\n)(dense)\r\n\r\nhead_consonant = tf.keras.layers.Dense(\r\n    units=7,\r\n    activation=tf.keras.activations.softmax,\r\n    name='consonant'\r\n)(dense)\r\n\r\nmodel = tf.keras.Model(\r\n    inputs=inputs,\r\n    outputs=[head_root, head_vowel, head_consonant]\r\n)\r\n\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(),\r\n    loss=tf.keras.losses.categorical_crossentropy,\r\n    metrics=['accuracy']\r\n)\r\n\r\ntrain_df = train_df.drop(['grapheme'], axis=1, inplace=False)\r\n\r\ntrain_df[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']] = \\\r\ntrain_df[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].astype('uint8')\r\n\r\nX_train = pd.merge(\r\n    df_0,\r\n    train_df,\r\n    on='image_id'\r\n).drop(\r\n    labels=['image_id'],\r\n    axis=1\r\n)\r\n\r\nY_train_root = pd.get_dummies(X_train['grapheme_root']).values\r\nY_train_vowel = pd.get_dummies(X_train['vowel_diacritic']).values\r\nY_train_consonant = pd.get_dummies(X_train['consonant_diacritic']).values\r\n\r\nX_train = X_train.drop(\r\n    labels=['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'],\r\n    axis=1\r\n)\r\nX_train = resize(X_train, size=IMG_SIZE)/255\r\n\r\nX_train = X_train.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\r\n\r\nx_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = \\\r\nsklearn.model_selection.train_test_split(\r\n    X_train,\r\n    Y_train_root,\r\n    Y_train_vowel,\r\n    Y_train_consonant,\r\n    test_size=.08,\r\n    random_state=0\r\n)\r\n\r\ndel X_train\r\ndel Y_train_root\r\ndel Y_train_vowel\r\ndel Y_train_consonant\r\n\r\ngc.collect()\r\n\r\ndatagen = MultiOutputDataGenerator(\r\n    featurewise_center=False,  # set input mean to 0 over the dataset\r\n    samplewise_center=False,  # set each sample mean to 0\r\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\r\n    samplewise_std_normalization=False,  # divide each input by its std\r\n    zca_whitening=False,  # apply ZCA whitening\r\n    rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\r\n    zoom_range=.15, # Randomly zoom image \r\n    width_shift_range=.15,  # randomly shift images horizontally (fraction of total width)\r\n    height_shift_range=.15,  # randomly shift images vertically (fraction of total height)\r\n    horizontal_flip=False,  # randomly flip images\r\n    vertical_flip=False  # randomly flip images\r\n)\r\n\r\ndatagen.fit(x_train)\r\n\r\nfrom memory_profiler import profile\r\n\r\n%load_ext memory_profiler\r\n\r\ndef main():\r\n    \r\n    model.fit(\r\n        datagen.flow(\r\n            x_train,\r\n            {\r\n                'root': y_train_root,\r\n                'vowel': y_train_vowel,\r\n                'consonant': y_train_consonant\r\n            },\r\n            batch_size=batch\r\n\r\n\r\n_size\r\n        ),\r\n        epochs=1,\r\n        validation_data=(x_test, [y_test_root, y_test_vowel, y_test_consonant]),  \r\n        steps_per_epoch=x_train.shape[0] // batch_size\r\n    )\r\n    \r\n    gc.collect()\r\n\r\n# here is where profiler saying that fitiing model increases ram usage\r\n%memit main()\r\n```\r\n\r\n![Screenshot_1](https://user-images.githubusercontent.com/34490641/72932081-19ff1380-3d70-11ea-9c57-9e2bdb1b29c5.png)\r\n", "@gadagashwini any suggestions?", "@dishkakrauch, I tried replicating the issue on colab but getting different error. Please take a look at colab [gist](https://colab.research.google.com/gist/gadagashwini/ec233809cd9bc7d15a0d3f98b459e8c1/untitled22.ipynb) and provide more information to reproduce the issue. Thanks!", "> @dishkakrauch, I tried replicating the issue on colab but getting different error. Please take a look at colab [gist](https://colab.research.google.com/gist/gadagashwini/ec233809cd9bc7d15a0d3f98b459e8c1/untitled22.ipynb) and provide more information to reproduce the issue. Thanks!\r\n\r\nIt's cause you don't have data for training. How can I share it with you?", "@dishkakrauch, Can you provide data as zip file here. Thanks ", "> @dishkakrauch, Can you provide data as zip file here. Thanks\r\n\r\nIt's more than limit 10MB. Can I share google drive link here?\r\nhttps://drive.google.com/file/d/1ggk622mLwkpWHS04Q8lq1ITIKZwSPOPh/view?usp=sharing", "@gadagashwini got any updates?", "@dishkakrauch, Sorry for delayed response. I tried replicating the issue with your dataset but received different error, can you take a look at [gist](https://colab.research.google.com/gist/gadagashwini/8eb404091c851c12b97ce27b674b8e65/untitled22.ipynb#scrollTo=kvvxvhrGpw9V) and make changes in gist. Thanks! ", "> @dishkakrauch, Sorry for delayed response. I tried replicating the issue with your dataset but received different error, can you take a look at [gist](https://colab.research.google.com/gist/gadagashwini/8eb404091c851c12b97ce27b674b8e65/untitled22.ipynb#scrollTo=kvvxvhrGpw9V) and make changes in gist. Thanks!\r\n\r\nI'm really surprised that it's a big problem to load file and try to repeat all the following steps to my erorr. Can't you load file with feather-format package insted pandas?\r\n\r\n```\r\npip install feather-format\r\nimport feather\r\ndf_0 = feather.read_dataframe(path)\r\n```", "Solved by:\r\nimport tensorflow as tf\r\ntf.keras.backend.clear_session()\r\nThanks to @taborda11 "]}, {"number": 36113, "title": "[Intel Mkl] Updating MKL implementation of Eager API.", "body": "Changes in Eager API broke the MKL builds (See below). This fixes the problem.\r\n\r\n```[0m\u001b[91mERROR: /tensorflow/tensorflow/core/common_runtime/eager/BUILD:352:1: C++ compilation of rule '//tensorflow/core/common_runtime/eager:mkl_eager_op_rewrite' failed (Exit 1)\r\n\u001b[0m\u001b[91mtensorflow/core/common_runtime/eager/mkl_eager_op_rewrite.cc: In static member function 'static tensorflow::Status tensorflow::MklEagerOpRewrite::SetupNewOp(tensorflow::EagerOperation*, std::string, std::unique_ptr<tensorflow::EagerOperation>*)':\r\ntensorflow/core/common_runtime/eager/mkl_eager_op_rewrite.cc:119:45: error: cannot convert 'tensorflow::EagerContext' to 'tensorflow::EagerContext*' in initialization\r\n   EagerContext* ctx = orig_op->EagerContext();\r\n                                             ^\r\ntensorflow/core/common_runtime/eager/mkl_eager_op_rewrite.cc:121:70: error: no matching function for call to 'tensorflow::EagerOperation::EagerOperation(tensorflow::EagerContext*&, const char*, bool&, const AttrTypeMap*&)'\r\n                                                    is_function, types));\r\n                                                                      ^\r\nIn file included from ./tensorflow/core/common_runtime/eager/eager_op_rewrite_registry.h:21:0,\r\n                 from tensorflow/core/common_runtime/eager/mkl_eager_op_rewrite.cc:18:\r\n./tensorflow/core/common_runtime/eager/eager_operation.h:31:12: note: candidate: tensorflow::EagerOperation::EagerOperation(tensorflow::EagerContext*)\r\n   explicit EagerOperation(tensorflow::EagerContext* ctx) : ctx_(*ctx) {}\r\n            ^~~~~~~~~~~~~~\r\n./tensorflow/core/common_runtime/eager/eager_operation.h:31:12: note:   candidate expects 1 argument, 4 provided\r\n./tensorflow/core/common_runtime/eager/eager_operation.h:29:7: note: candidate: tensorflow::EagerOperation::EagerOperation(const tensorflow::EagerOperation&)\r\n class EagerOperation {\r\n       ^~~~~~~~~~~~~~\r\n./tensorflow/core/common_runtime/eager/eager_operation.h:29:7: note:   candidate expects 1 argument, 4 provided```", "comments": ["@guizili0 Here is the PR for the Eager API fix.", "@jaingaurav This code only gets called with --config=mkl.", "@gunan: Do we have an internal test target that tests --config=mkl? It would have helped avoid this failure.", "@jaingaurav Thanks for the feedback. "]}, {"number": 36112, "title": "Minor fixes to StructuredTensor", "body": "This removes duplicate checks in the StructuredTensor constructor and corrects the format of string representation.", "comments": []}, {"number": 36111, "title": "cudart64_101.dll not found, but I have CUDA installed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (10.0.18362 Build 18362)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7.6 (from windows store)\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10 and 10.1, but I also tried with just 10.1 and just 10.2\r\n- GPU model and memory: NVIDIA GeForce GTX 1060 OC with 6GB GDDR5\r\n\r\n\r\n\r\n**Describe the problem**\r\nI'm getting the error Could not load dynamic library \"'cudart64_101.dll'; dlerror: cudart64_101.dll\r\n not found\", even though cuda is installed and the file exists on my computer\r\n![Annotation 2020-01-21 162719](https://user-images.githubusercontent.com/31412003/72844651-f7cf9d80-3c6a-11ea-8133-ffec9d410cca.png)\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nimport tensorflow as tf\r\nimport pathlib\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nimport numpy as np\r\nnp.set_printoptions(precision=4)\r\n\r\nI get these from [https://www.tensorflow.org/guide/data](https://www.tensorflow.org/guide/data)\r\n\r\n**Any other info / logs**\r\n2020-01-21 16:18:17.197417: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-01-21 16:18:17.197832: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.", "comments": ["@frogtd129,\r\nYou may need to find which directory these dlls are in, and then update your PATH to include that directory. Thanks", "I added the directory to path and still get the same warning.", "I'm having the same problem. According to the [docs](https://www.tensorflow.org/install/gpu):  \r\n\r\n> The following NVIDIA\u00ae software must be installed on your system:\r\n> \r\n> NVIDIA\u00ae GPU drivers \u2014CUDA 10.1 requires 418.x or higher.\r\n> CUDA\u00ae Toolkit \u2014TensorFlow supports CUDA 10.1 (TensorFlow >= 2.1.0)\r\n> CUPTI ships with the CUDA Toolkit.\r\n> cuDNN SDK (>= 7.6)\r\n> (Optional) TensorRT 6.0 to improve latency and throughput for inference on some models.\r\n> \r\n\r\n\r\n I tried with CUDA 10.2 and the right cuDNN according to their website (\r\n\"Download cuDNN v7.6.5 (November 18th, 2019), for CUDA 10.2\") and it worked, but then it stopped working and I don't know what I did. The GPU driver's version is higher than 418.x.\r\n\r\nNow I'm using CUDA 10.1, cuDNN v7.6.5 and I'm getting the same error as OP.  \r\ntensorflow 2.1.0  \r\npython 3.7.6  \r\n", "Using miniconda worked:  \r\n```\r\nconda create --name .conda_venv\r\nconda activate .conda_venv\r\nconda install tensorflow-gpu\r\n```", "The Conda install works great for me with TF2.1 and VSCode Win 10", "Directory : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin\\ \r\n\r\nDownload Link : https://www.dll-files.com/download/1d7955354884a9058e89bb8ea34415c9/cudart64_101.dll.html?c=N09pWDBSTVYxRE1rM2hpNjVUa2doQT09", "I got the same problem as you,you can use tensoflow2.0.0+CUDA10 instead to solve this problem.", "You're supposed to use CUDA 10.1 with TensorFlow 2.1.0\r\n\r\nHave a look here : https://www.tensorflow.org/install/gpu\r\n\r\n> Software requirements\r\n> \r\n> The following NVIDIA\u00ae software must be installed on your system:\r\n> \r\n>     NVIDIA\u00ae GPU drivers \u2014CUDA 10.1 requires 418.x or higher.\r\n>     CUDA\u00ae Toolkit \u2014TensorFlow supports CUDA 10.1 (TensorFlow >= 2.1.0)\r\n>     CUPTI ships with the CUDA Toolkit.\r\n>     cuDNN SDK (>= 7.6)\r\n>     (Optional) TensorRT 6.0 to improve latency and throughput for inference on some models\r\n\r\nI got the same problem some time ago when I installed TensorFlow GPU with CUDA 10.2.\r\nWhen I checked the v10.2 folder for the file cudart64_101.dll I found ...10**2**.dll\r\nThat's when I should have suspected I messed up the installation... but instead I tried a BAD IDEA first:\r\nI copied it and renamed it to ...101.dll- surprisingly enough it appeared to work and was a fun way to benchmark CPU vs GPU with different code variations but that's just asking for problems. So DON'T do that. \r\nAlso, as a rule of thumb I do not suggest to manually add DLL files. Ever ! \r\nWhen something doesn't work as you expect you'll be wondering if it's you or the installation and you'll waste much more valuable time then.\r\n\r\n**What you should do is** :\r\n(Take a break) \r\nUninstall TF.\r\nUninstall CUDA 10.2 and Nvidia's Nsight.\r\nInstall CUDA 10.1 and continue from there.\r\n\r\nBTW, this guide is great - **Just read ahead before you do anything** :\r\nhttps://towardsdatascience.com/installing-tensorflow-with-cuda-cudnn-and-gpu-support-on-windows-10-60693e46e781\r\n\r\n\r\n\r\n", "I was running TF2.0 with CUDA 10.0 fine. I updated to TF2.1 and started having this error. I reinstalled CUDA to version 10.1 following this guide: https://www.tensorflow.org/install/gpu?hl=en. The error still persisted so eventually I tried it out of my conda environment and it worked.", "FWIW, for me just copy-and-paste the *101.dll's into the 10.2/bin folder worked fine. ", "I haven't managed to get tf to work with GPU since 1.14, for this reason. I'm on Win10, and using Anaconda environments. Was hoping that the recently released tf 2.1 conda package would solve the issue, but unfortunately it still persists.\r\n\r\nSo right now I have two environments, one (tf 1.14) where things work fine, and the other (tf 2.1) where tf can't find the dll.\r\n\r\nFor tf 1.14 the DLL is at: C:\\Users\\Daniel\\Miniconda3\\envs\\tf\\Library\\bin\\cudart64_100.dll - this directory is on the PATH and tf finds it and is happy.\r\n\r\nFor tf 2.1 the DLL is at C:\\Users\\Daniel\\Miniconda3\\envs\\tf2\\Library\\bin\\cudart64_101.dll - tf doesn't find this, even though the directory is on the PATH.\r\n\r\nThere's obviously a CUDA version difference, but AFAIK that's how it's supposed to be. The 2.1 env was just created today with conda create -n tf2 tensorflow-gpu, which seems to have pulled in the right dependencies as far as I can tell.\r\n\r\nAre there perhaps any recent changes to dso_loader that could affect the file search behaviour? Noting that when using Anaconda/Miniconda the CUDA path is arbitrary since it contains the env name (as opposed to the regular CUDA installation in C:\\Program Files\\...)", "I have it working with both the copy trick and Anaconda with an Nvidia 2070 max Q", "@daniahl \r\nI don't use Anaconda but I suggest you revisit my comment above. Besides the versions and stuff listed there, there's a link to a guide which describes how to install (with obsolete versions, so use the ones I mentioned) but more important **how to check that every component works**.\r\nI hope it would help you narrow down your search.\r\n\r\nGood luck !\r\n\r\nP.S.\r\nSeems like you're nearly there. A PATH issue may very well be the cause.\r\nPerhaps you could remove the old versions from the path and see what happens.", "Thing is, with Anaconda you're not supposed to need to install the CUDA toolkit separately; the toolkit and CuDNN come as conda packages. This is why I am curious as to whether tf now has trouble with that kind of setup. I could try by installing CUDA and CuDNN the \"normal\" way. If that solves it, however, there might be a bug somewhere, cause this shouldn't be needed.\r\n", "> PATH\r\n\r\n@gadagashwini, yes indeed, it seems like an obvious decision, but after changing the PATH environment variable in \"System properties/Advanced/Environment Variables\" Win10, \"tflite_convert\" tool stops raise an error about dynamic library cudart64_101.dll.\r\nNow it looks like this:\r\n```\r\n$ tflite_convert.exe\r\n2020-02-24 23:18:51.593706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n```", "Creating environment with Conda, activating environment, upgrading pip, upgrading tensorflow 1.15 to 2.1 with pip, then install tensorflow-gpu with Conda and Nvidia 10.1 runtime worked for me.\r\n\r\nTensorflow 2.1.0\r\nWindows 10 1909.\r\nConda 4.8.1\r\npip 20.0.2 from C:\\tools\\Anaconda3\\envs\\(my env)\\lib\\site-packages\\pip (python 3.7)\r\ncudatoolkit               10.1.243\r\ncudnn                     7.6.5\r\n```\r\n>>> import tensorflow\r\n2020-03-01 10:18:52.598939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n```\r\n\r\nDLL under\r\n```\r\nC:\\tools\\Anaconda3\\envs\\(my env)\\Library\\bin\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/7253192/75628399-90303a80-5ba6-11ea-80e8-299f18cdafc0.png)\r\n\r\nPath entries - I replaced my created environment name with (my env)\r\n\r\n```\r\nC:\\cuda\\bin;\r\nC:\\tools\\Anaconda3\\envs\\(my env);\r\nC:\\tools\\Anaconda3\\envs\\(my env)\\Library\\mingw-w64\\bin;\r\n\r\nC:\\tools\\Anaconda3\\envs\\(my env)\\Library\\usr\\bin;\r\nC:\\tools\\Anaconda3\\envs\\(my env)\\Library\\bin;\r\nC:\\tools\\Anaconda3\\envs\\(my env)\\Scripts;\r\nC:\\tools\\Anaconda3\\envs\\(my env)\\bin;\r\nC:\\tools\\Anaconda3\\condabin;\r\n\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin;\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\libnvvp;\r\nC:\\Program Files\\NVIDIA Corporation\\NvStreamSrv;\r\nC:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2019.5.0;\r\nC:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;\r\nC:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;\r\n\r\nC:\\tools\\Anaconda3;\r\nC:\\tools\\Anaconda3\\Library\\mingw-w64\\bin;\r\nC:\\tools\\Anaconda3\\Library\\usr\\bin;\r\nC:\\tools\\Anaconda3\\Library\\bin;\r\nC:\\tools\\Anaconda3\\Scripts;\r\nC:\\Python38\\Scripts;\r\nC:\\Python38;\r\n```\r\n\r\n\r\nThere might be a bump in the version from 10.1 to 10.2 required here.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cudart_stub.cc\r\n\r\nSeems to be hard-coded to 10.1?\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/stream_executor/cuda", "> \r\n> \r\n> Directory : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin\\\r\n> \r\n> Download Link : https://www.dll-files.com/download/1d7955354884a9058e89bb8ea34415c9/cudart64_101.dll.html?c=N09pWDBSTVYxRE1rM2hpNjVUa2doQT09\r\n\r\nThanks so much @jalpeshpanchal99, this sorted it for me!", "Combinations of CUDA {10.2, 10.1U2, 10.1} + Python {3.8, 3.7.7} from store +pip didn't work for me. adding \\bin to CUDNN_PATH, copying files around, didn't work either. I suspect binary incompatibility or permission issues rather than file actually missing.  \r\n\r\nUninstalling Python and replacing with Anaconda then `conda install tensorflow` solved it for me.", "I have similar issue with CUDA 10.2.89, because it installs `cudart64_102.dll` but tensorflow 2.2.0rc1 requires `cudart64_101.dll`. The usual renaming of a copy of dll helped.\r\n\r\n![\u0410\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u044f 2020-03-21 172112](https://user-images.githubusercontent.com/4838367/77229778-69a76300-6b98-11ea-89c3-81c48171b7a3.png)\r\n\r\nPS: if you use Windows do not forget to restart the PC after CUDA installation, because system environment variables are updated", "Still no luck here. At first I thought TF2 might have issues with the anaconda paths to the dll files, but after having installed CUDA directly from NVIDIA to the default path, TF still complains that it can't find the DLL.\r\nPytorch finds the file and GPU works, so I really don't know why TF doesn't.", "@joao-carvalheira : Simple and efficient!\r\n> ```\r\n> conda create --name .conda_venv\r\n> conda activate .conda_venv\r\n> conda install tensorflow-gpu\r\n> ```\r\n", "Hello I would recommend adding specific 3.7 version of python as it is proven to be working nicely with TF2.\n\nconda create -n tf2env python=3.7\n\nand do not forget to get latest conda version at your base env\n\nconda update -n base -c defaults conda\n\nAll the best !\n\n________________________________\nDe : Jean-Michel Lekston <notifications@github.com>\nEnvoy\u00e9 : dimanche 22 mars 2020 07:00\n\u00c0 : tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc : Pierre-Emmanuel FEGA <zepef@hotmail.com>; Comment <comment@noreply.github.com>\nObjet : Re: [tensorflow/tensorflow] cudart64_101.dll not found, but I have CUDA installed (#36111)\n\n\n@joao-carvalheira<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fjoao-carvalheira&data=02%7C01%7C%7Ce204868de3934109ee0308d7ce695030%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637204824015577990&sdata=nMlD3Zrf1e8UVXvi9g81%2FUJ9mpYfQV5B9%2FcTAHQe%2F%2Fs%3D&reserved=0> : Simple and efficient!\n\nconda create --name .conda_venv\nconda activate .conda_venv\nconda install tensorflow-gpu\n\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F36111%23issuecomment-602204942&data=02%7C01%7C%7Ce204868de3934109ee0308d7ce695030%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637204824015577990&sdata=fGQBbU%2FIChALmMtjynX8K3XgfVxRSeCFnPtui7bkh1Y%3D&reserved=0>, or unsubscribe<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAAFKP5JF4DQS5ZV6KPPKIJLRIYKWBANCNFSM4KJ2YMJQ&data=02%7C01%7C%7Ce204868de3934109ee0308d7ce695030%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637204824015587983&sdata=%2Ffe8QcK1DaMOmfZ%2BmL9e8cH1dB4OLX2998wyYTy%2FvfI%3D&reserved=0>.\n", "I copied\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin\\cudart64_102.dll\r\ninto cudart64_101.dll\r\nSo I have both (that actually the same file with different names).\r\n\r\nIt solved my problem.", "> Also, as a rule of thumb I do not suggest to manually add DLL files. Ever !\r\n\r\nHey GuyGoldener, I was having the same problems the others were having and I resorted to downloading the 101.dll separately and manually adding it to the /bin folder. While I see that it's wrong, uninstalling CUDA 10.2 is easier said than done. I wanted to know if in this case an uninstall of CUDA 10.2 and fresh install of CUDA 10.1 is necessary in your opinion, considering the time it takes to freshly install CUDA again and the risks associated with uninstalling CUDA 10.2", "> I have similar issue with CUDA 10.2.89, because it installs `cudart64_102.dll` but tensorflow 2.2.0rc1 requires `cudart64_101.dll`. The usual renaming of a copy of dll helped.\r\n> \r\n> ![\u0410\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u044f 2020-03-21 172112](https://user-images.githubusercontent.com/4838367/77229778-69a76300-6b98-11ea-89c3-81c48171b7a3.png)\r\n> \r\n> PS: if you use Windows do not forget to restart the PC after CUDA installation, because system environment variables are updated\r\n\r\nNo need to restart PC. Just re-launch cmd.exe or PowerShell will apply the new Env Variables.", "![Screenshot (57)](https://user-images.githubusercontent.com/43216487/78386904-0daef680-75fc-11ea-8542-567368c436a4.png)\r\nI had the same problem but I just copied \"cudart64_102\" with the name as \"cudart_101.dll\" and it worked.", "I had a similar problem. I added the installation Cuda Toolkit 10.1 bin directory to the PATH variable, but the tensorflow environment did not seem to recognize it and complained about not finding cudart64_101.dll. It turned out, that I did not restart PyCharm.\r\nAfter closing and starting PyCharm, all the dlls were correctly recognized.", "> Directory : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin\\\r\n> \r\n> Download Link : https://www.dll-files.com/download/1d7955354884a9058e89bb8ea34415c9/cudart64_101.dll.html?c=N09pWDBSTVYxRE1rM2hpNjVUa2doQT09\r\n\r\nthat worked for me ", "I have the same issue as @daniahl . Anaconda has put the `cudart64_101.dll` into my-env\\Library\\bin, but tensorflow does not find it there. Or does not look there.\r\n\r\nI don't want to install a global CUDA setup, what if my games fail, or it gets updated by geforce experience, or my tf 1.14 conda starts failing. It should work with the dll that is just *right there*.", "Maybe a fix without dealing with mismatching dlls.\r\nWorks with Tf-GPU 2.1, installed as described below.\r\n\r\nI had the same error after installing with \u201cthe award winning new approach\u201d: conda create \u2014name tf_gpu tensorflow-gpu.\r\nI downgraded cudatookit using \r\n\r\nConda install cudatoolkit==10.0.130\r\n\r\nin anaconda prompt. No path adjustments needed. This cudatoolkit version seems to have xx_100.dll instead and loads fine when tensorflow is imported.\r\n", "I had this exact issue. On Windows 10, installed CUDA 10.1, python 3.7, tensorflow 2.1, PATH variable set correctly, but was still seeing this error.\r\n\r\nThe problem turned out to be that the version of python I had installed was the one from the Microsoft Store and _not_ the one from python.org. As it turns out, apps installed from the Microsoft Store are sandboxed. Windows restricts where they can load DLLs from pretty severely. Among [the restrictions](https://docs.microsoft.com/en-us/windows/win32/dlls/dynamic-link-library-search-order): Windows does not search the directories in the `PATH` env var for the DLLs. So app store python will never be able to find CUDA DLLs this way.\r\n\r\nLong story short: be sure to install your python from python.org. Took me waaay too much spelunking of the tensorflow code for loading DLLs to figure this out.", "@smreichling I was not aware of this. Thank you very much for the detailed analysis!\r\nWe should definitely document this in our installation documentation.\r\n@lamberta where does this information best fit in our documents?", "@smreichling \r\n> The problem turned out to be that the version of python I had installed was the one from the Microsoft Store and not the one from python.org. As it turns out, apps installed from the Microsoft Store are sandboxed. Windows restricts where they can load DLLs from pretty severely. Among the restrictions: Windows does not search the directories in the PATH env var for the DLLs. So app store python will never be able to find CUDA DLLs this way.\r\n\r\nIs there a way to test this from command line? \r\nFor example in a powershell or Conda CMD?\r\n\r\nI have no idea which version was installed, since it was a while ago.", "> Maybe a fix without dealing with mismatching dlls.\r\n> Works with Tf-GPU 2.1, installed as described below.\r\n> \r\n> I had the same error after installing with \u201cthe award winning new approach\u201d: conda create \u2014name tf_gpu tensorflow-gpu.\r\n> I downgraded cudatookit using\r\n> \r\n> Conda install cudatoolkit==10.0.130\r\n> \r\n> in anaconda prompt. No path adjustments needed. This cudatoolkit version seems to have xx_100.dll instead and loads fine when tensorflow is imported.\r\n\r\nNo this didn't solve anything for me either :(\r\n\r\nFirst it warned (as it should):\r\n\r\n```\r\nThe following packages will be DOWNGRADED:\r\n\r\n  cudatoolkit                           10.1.243-h74a9793_0 --> 10.0.130-0\r\n  cudnn                                    7.6.5-cuda10.1_0 --> 7.6.5-cuda10.0_0\r\n  tensorflow                       2.1.0-gpu_py37h7db9008_0 --> 2.0.0-gpu_py37h57d29ca_0\r\n  tensorflow-base                  2.1.0-gpu_py37h55f5790_0 --> 2.0.0-gpu_py37h390e234_0\r\n  tensorflow-estima~                     2.1.0-pyhd54b08b_0 --> 2.0.0-pyh2649769_0\r\n  tensorflow-gpu                           2.1.0-h0d30ee6_0 --> 2.0.0-h0d30ee6_0\r\n```\r\n\r\nwhich is something I don't want, I want tf 2.1.0, but for the sake of testing I did anyway.\r\n\r\nRunning it gave me the same error:\r\n\r\n```\r\n(D:\\Data\\Python-envs\\tf-2-gpu) C:\\Users\\Me>python\r\nPython 3.7.7 (default, Apr 15 2020, 05:09:04) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2020-04-23 16:44:29.635410: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found\r\n```\r\n\r\nBut in `D:\\Data\\Python-envs\\tf-2-gpu\\Library\\bin` I do have a `cudart64_100.dll` file.\r\n\r\nAfaik I'm not using the windows story python, since I never go there, and I just installed anaconda (miniconda) a while ago.", "> where does this information best fit in our documents?\r\n\r\nHmm. Well, if it is in fact an issue with the Windows Store python, there's two candidate locations (or both!):\r\n\r\n- The WIndows section of the GPU setup guide: https://www.tensorflow.org/install/gpu#windows_setup\r\n- The WIndows-specific setup instructions in the pip install guide: https://www.tensorflow.org/install/pip?lang=python3#windows\r\n\r\nThese docs live over here: https://github.com/tensorflow/docs/tree/master/site/en/install\r\n\r\nMicrosoft provides two guides:\r\n- [Get started using Python on Windows for beginners](https://docs.microsoft.com/en-us/windows/python/beginners) (Windows Store)\r\n- [Get started using Python on Windows for scripting and automation](https://docs.microsoft.com/en-us/windows/python/scripting)\r\n  * \"For some advanced scenarios (like needing to access/modify Python's installed files, make copies of binaries, or use Python DLLs directly) ...\"\r\n\r\nSo maybe we can point off to the latter guide and include that blurb for some context.\r\n", "I'm thinking we should include the blurb in both locations on the website, both on the GPU setup guide and on the pip install one", "The copy trick that is suggested multiple times in this issue seems like a bit of a hack to me. I ran into the same issue just now, and (1) installing CUDA 10.1 toolkit - on top of 10.2 - and (2) adding \r\n```\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\bin\r\n```\r\nto the path does the same trick.\r\n\r\nDifferent versions of CUDA happily coexist with each other so installing both 10.1 and 10.2 is very possible. To me, this seems more Windows-style than manually copying a .dll. On this note, the CUDA toolkit creates environment variables called `CUDA_PATH`, `CUDA_PATH_V10_1`. `CUDA_PATH_V10_2`, ... . Perhaps it could be possible for Tensorflow to check for these variables and include the libraries found there; this would resolve the need to add the toolkit to the path, and would allow for an appropriate warning of the form `TensorFlow was compiled against CUDA XX.YY; however this CUDA version could not be found on your system.`\r\n\r\nEdit: Fixed typo where I repeated  `CUDA_PATH_V10_1` twice instead of  `CUDA_PATH_V10_1`. `CUDA_PATH_V10_2`.", "@chsigg @yifeif ", "I had a similar issue and found out the issue was using Python 3.8. I downgraded to Python 3.7 and it started working.\r\nBefore that I tried reinstalling drivers, making sure all files existed, using conda vs venv, tf 2.1 vs tf 2.2, reinstalling tf, and explicitly installing tensorflow-gpu.", "You can try this manually loading the dll if PATH fails even after adding: https://github.com/tensorflow/tensorflow/issues/30748#issuecomment-647106802", "> I had this exact issue. On Windows 10, installed CUDA 10.1, python 3.7, tensorflow 2.1, PATH variable set correctly, but was still seeing this error.\r\n> \r\n> The problem turned out to be that the version of python I had installed was the one from the Microsoft Store and _not_ the one from python.org. As it turns out, apps installed from the Microsoft Store are sandboxed. Windows restricts where they can load DLLs from pretty severely. Among [the restrictions](https://docs.microsoft.com/en-us/windows/win32/dlls/dynamic-link-library-search-order): Windows does not search the directories in the `PATH` env var for the DLLs. So app store python will never be able to find CUDA DLLs this way.\r\n> \r\n> Long story short: be sure to install your python from python.org. Took me waaay too much spelunking of the tensorflow code for loading DLLs to figure this out.\r\n\r\nThis was my issue.  I spent 4 hours trying various things till this was exactly the problem.  Please update the documentation ASAP!", "> I had this exact issue. On Windows 10, installed CUDA 10.1, python 3.7, tensorflow 2.1, PATH variable set correctly, but was still seeing this error.\r\n> \r\n> The problem turned out to be that the version of python I had installed was the one from the Microsoft Store and _not_ the one from python.org. As it turns out, apps installed from the Microsoft Store are sandboxed. Windows restricts where they can load DLLs from pretty severely. Among [the restrictions](https://docs.microsoft.com/en-us/windows/win32/dlls/dynamic-link-library-search-order): Windows does not search the directories in the `PATH` env var for the DLLs. So app store python will never be able to find CUDA DLLs this way.\r\n> \r\n> Long story short: be sure to install your python from python.org. Took me waaay too much spelunking of the tensorflow code for loading DLLs to figure this out.\r\n\r\nit worked for me when use gpu and tensorflow on window . thank", "> I had this exact issue. On Windows 10, installed CUDA 10.1, python 3.7, tensorflow 2.1, PATH variable set correctly, but was still seeing this error.\r\n> \r\n> The problem turned out to be that the version of python I had installed was the one from the Microsoft Store and _not_ the one from python.org. As it turns out, apps installed from the Microsoft Store are sandboxed. Windows restricts where they can load DLLs from pretty severely. Among [the restrictions](https://docs.microsoft.com/en-us/windows/win32/dlls/dynamic-link-library-search-order): Windows does not search the directories in the `PATH` env var for the DLLs. So app store python will never be able to find CUDA DLLs this way.\r\n> \r\n> Long story short: be sure to install your python from python.org. Took me waaay too much spelunking of the tensorflow code for loading DLLs to figure this out.\r\n\r\nThanks @smreichling ! This issue took me 6 hours. I had the same issue: installed Python from Microsoft Store, reinstalled cuda, cuDNN, tensorflow for 4 times, verified the path and rebooted for many many times..... until I found this solution.... Installing Python from Python.org is the solution for those struggling with the Python from MS Store. Remember to install Python 64-bit version from Python.org. The download button on Python.org homepage will download the 32-bit version by default which will not let you install tensorflow using pip.", "Almost all comments are misleading. Why you push the idea of copying files from conda 10.2 to 10.1. He clearly said that he tried with conda 10.1. Also, suggesting installing tf with conda isn't correct too: why we should be forced to use it? It should work simply by installing cuda+cudnn from official site and defining env variables accordingly + installing tf with pip. This shouldn't be a problem.\r\n\r\nAlso, what about this situation> I had Python 3.5 and tf 2.2 that worked just fine with cuda 10.1. I have created with conda a new environment with Python 3.8 and tf 2.2. Guess what? It does not detect cudart64_101.dll. So there are clearly problems here\r\n\r\nP.S. for someone, installing this can help> https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads\r\n\r\nP.S.2. I have managed to get it to work, by setting this entries in the PATH variable and putting them first in the list and restarting the PC>\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\bin\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\extras\\CUPTI\\lib64\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\include\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\lib\\x64\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\libnvvp\r\n\r\nI think that i didn't worked because initially C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\lib\\x64 was missing, but i am not sure. Hope this will help someone\r\n", "This page actually worked for me:\r\nhttps://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html , section 3.3. I copied the files to cuda v.10.2. ", "> > I had this exact issue. On Windows 10, installed CUDA 10.1, python 3.7, tensorflow 2.1, PATH variable set correctly, but was still seeing this error.\r\n> > The problem turned out to be that the version of python I had installed was the one from the Microsoft Store and _not_ the one from python.org. As it turns out, apps installed from the Microsoft Store are sandboxed. Windows restricts where they can load DLLs from pretty severely. Among [the restrictions](https://docs.microsoft.com/en-us/windows/win32/dlls/dynamic-link-library-search-order): Windows does not search the directories in the `PATH` env var for the DLLs. So app store python will never be able to find CUDA DLLs this way.\r\n> > Long story short: be sure to install your python from python.org. Took me waaay too much spelunking of the tensorflow code for loading DLLs to figure this out.\r\n> \r\n> Thanks @smreichling ! This issue took me 6 hours. I had the same issue: installed Python from Microsoft Store, reinstalled cuda, cuDNN, tensorflow for 4 times, verified the path and rebooted for many many times..... until I found this solution.... Installing Python from Python.org is the solution for those struggling with the Python from MS Store. Remember to install Python 64-bit version from Python.org. The download button on Python.org homepage will download the 32-bit version by default which will not let you install tensorflow using pip.\r\n\r\nWorked!!!!\r\nI tried every solution in comments. spent 6 hours too. and it's because I installed python from Microsoft store.", "> Directory : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin\\\r\n> \r\n> Download Link : https://www.dll-files.com/download/1d7955354884a9058e89bb8ea34415c9/cudart64_101.dll.html?c=N09pWDBSTVYxRE1rM2hpNjVUa2doQT09\r\n\r\nFirst of all, I had the same problem as \"cudart64_101.dll not found\". \r\nFinally, get it to work by installing CUDA10.1 + cuDNN7.6.5 for CUDA10.1 with **pip install tensorflow** on windows 10. \r\nHere is the list of Not working methods\r\n1) copy or rename or download external cudart64_101.dll and put them into CUDA folder\r\nThis never worked since 'cudnn64_7.dll' and 'cusparse64_10.dll' is also missing and never a good idea unless you know the details of the lib files well.\r\n2) Install Python from python.org, not from Microsoft store or use python 3.7 etc....\r\nwell in fact even though Python form python.org alone did not help. the default installation path is weird enough, install in C:Python38 otherwise cause permission problem. After all, I used Python 3.8 and works fine. I even tried in **venv** isolate tf in a specific folder and still works.\r\n\r\nin summary: The best way is to install proper libs, you do not have to uninstall CUDA11.0, it can co-exist. if you install CUDA 10.1 later, the System CUDA_PATH will be CUDA10.1. you can check it by **nvcc --version**. To check TensorFlow version\r\nI used **python -c 'import tensorflow as tf; print(tf.__version__)'** and it nicely reported version 2.3.0\r\n\r\n#cudatest.py file\r\nimport tensorflow as tf \r\ntf.config.list_physical_devices('GPU')\r\n\r\nalso reported followings\r\n$ python cudatest.py\r\n2020-07-31 11:52:36.145220: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-07-31 11:52:37.418972: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-07-31 11:52:38.406721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1650 Ti computeCapability: 7.5\r\ncoreClock: 1.485GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 178.84GiB/s\r\n2020-07-31 11:52:38.406762: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-07-31 11:52:38.410134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-07-31 11:52:38.412850: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-07-31 11:52:38.413875: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-07-31 11:52:38.417343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-07-31 11:52:38.419256: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-07-31 11:52:38.425368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-07-31 11:52:38.425437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n\r\nHope this one helps and\r\nWhat else do you guys think that I have to check or test in Windows 10 laptop?\r\n\r\n", "I'm pretty sure the issue had do with the sandboxed nature of the python from the microsoft store, not anything to do with tensorflow. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36111\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36111\">No</a>\n", "> \r\n> \r\n> I had a similar issue and found out the issue was using Python 3.8. I downgraded to Python 3.7 and it started working.\r\n> Before that I tried reinstalling drivers, making sure all files existed, using conda vs venv, tf 2.1 vs tf 2.2, reinstalling tf, and explicitly installing tensorflow-gpu.\r\n\r\nThank was what worked for me. My problem was the new 3.8 version.  It worked when I changed to 3.7. Thank you!", "First, check tensorflow **compatibility** with CUDA/cuDNN/Python from **[here](https://www.tensorflow.org/install/source#gpu)**\r\nFor me these worked fine:\r\n\r\n- CUDA 10.0\r\n- cuDNN 7.6\r\n- Tensorflow-gpu 2.0.0\r\n\r\nYou might want to use newer versions. If so, just check compatibility", "I tried with a 3.7.* version of python instead of 3.8.* and it works for me", "updating to the latest tf worked for me `pip install tf-nightly-gpu`", "I have the same problem and the solution is:\r\n\r\n1) Uninstall all drivers that says \"nvidia\" from Uninstall programs (ALL, Cuda and gpu driver)\r\n2) Install last nvidia drivers for your GPU https://uk.download.nvidia.com/GFE/GFEClient/3.21.0.36/GeForce_Experience_v3.21.0.36.exe\r\n3) Install cuda 11.2 https://developer.download.nvidia.com/compute/cuda/11.2.1/local_installers/cuda_11.2.1_461.09_win10.exe\r\n2) Install Anaconda https://repo.anaconda.com/archive/Anaconda3-2020.11-Windows-x86_64.exe\r\n3) conda create -n cudaenv python=3.6\r\n4) conda activate cudaenv\r\n5) pip install tensorflow python-dotenv\r\n6) Create a.py with this: import tensorflow as tf\r\n7) run it: python a.py \r\nOutput:\r\nxxx: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll", "It seems Python installed from Microsoft Store, for some reason, is not able to search for dll's through environment variables (Security Policies). One easy and temporary fix is , before this line of code\r\n```python\r\nimport tensorflow as tf\r\n````\r\n\r\nAdd the following code:\r\n\r\n```python\r\nimport os\r\nos.add_dll_directory(r\"<your_path_to_NVIDIA_toolsets>\\CUDA\\<your_cuda_version\\DEV\\bin\")\r\n````\r\n\r\nThis way, tensorflow loader will be able to load \"cudart64_101.dll\"\r\n\r\nEDIT: Inside \"<your_path_to_NVIDIA_toolsets>\\CUDA\\<your_cuda_version\\DEV\\bin\" you should be able to find \"cudart64_101.dll\" or the specific library (cudart64_1xx.dll) your specific version of tensorflow is asking for."]}, {"number": 36110, "title": "[ROCm][XLA] Adding address space cast in ir_emitter", "body": "This is a follow-up to #35881 \r\n\r\n----------\r\n\r\nBackground: Kernel variables in Nvdia/OpenCL side are represented as address space 0, whereas in AMDGPU side is represented as address space 5.\r\n\r\nThis PR replaced `CreateBitCast()` to `CreatePointerBitCastOrAddrSpaceCast()`, aiming to fix AMDGPU address space. Without this change, the generated llvm IR will have a mismatch in address space, causing widespread failures in unit tests. E,g:\r\n\r\n> Invalid bitcast\r\n   %add.typed = bitcast float addrspace(5)* %add.raw to float*\r\n\r\n@whchung @cheshire ", "comments": []}, {"number": 36109, "title": "TFTRT not converting dilated convolutions", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10, 7\r\n- TensorRT: 5\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n1.15.0\r\n\r\n**Describe the current behavior**\r\nTFTRT skips dilated convolutions and gives leaves this in the output. Other convolutions work fine.\r\n\r\nThis is what it looks like in Tensorboard: \r\n![dilated_convolution](https://user-images.githubusercontent.com/16327442/72840584-da172e00-3c94-11ea-9068-4c6c93b80c18.png)\r\n\r\nIt appears that there are some BatchToSpaceND and SpaceToBatchND operations. Perhaps these are not supported?\r\n\r\n**Describe the expected behavior**\r\n\r\nBased on the PR that was merged into Tensorflow in January last year (TFTRT: Support Dilated Convolutions #24674) I would expect that converting a convolution with dilations would be supported. Instead it's not... I tried dilation rates of 2, 8, 16...\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\n\r\nimport tensorflow as tf\r\n\r\ninp = tf.keras.layers.Input(input=(400, 400, 3))\r\nx = tf.keras.layers.Conv2D(8, kernel_size=(3,3), strides=(1,1), dilation_rate=(16,16))(inp)\r\nmodel = tf.keras.models.Model(inp, x) \r\n\r\nsess = tf.keras.backend.get_session()\r\n\r\noutput_nodes = [n.name[:-2] for n in model.outputs]\r\n\r\ngraph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), output_nodes)\r\n\r\nconverter = trt.TrtGraphConverter(input_graph_def=graph_def,\r\n                                              nodes_blacklist=model.outputs,\r\n                                              precision_mode=\"FP32\",\r\n                                              max_batch_size=1,\r\n                                              minimum_segment_size=1,\r\n                                              max_workspace_size_bytes=(2048>>20),\r\n                                              use_calibration=True)\r\ncalib_graph = converter.convert()\r\n\r\nwith tf.gfile.GFile(\"model.trt.pbtxt\", \"w\") as f:\r\n        f.write(str(calib_graph))\r\n```\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Any updates?", "First of all, I wonder why  your test case doesn't work straightforwardly for me. I got this error:\r\nValueError: ('Unrecognized keyword arguments:', ['input'])\r\nI have to modify \"input=\" to  \"shape=\" to make it works. Why the program works on your end?\r\n\r\nThe test works for me and I see TRTEngineOp with convolution in the result.\r\nSee the attachments. The .txt file is a pbtxt file, have to rename it to please github.\r\n \r\n![trt_github_issue_36109](https://user-images.githubusercontent.com/35820639/73485523-16632200-4358-11ea-99f8-2d2cbb814a0a.png)\r\n\r\n[trt_github_issue_36109_pbtxt.txt](https://github.com/tensorflow/tensorflow/files/4135989/trt_github_issue_36109_pbtxt.txt)\r\n\r\n\r\n\r\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36109\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36109\">No</a>\n"]}, {"number": 36108, "title": "Pin ipykernel==5.1.1 in Dockerfiles", "body": "The latest ipykernel has a bug, see https://github.com/ipython/ipykernel/issues/422.\nThis change pins ipykernel in the Jupyter Dockerfiles to avoid the error\nwhen executing notebooks, e.g. this raises the error:\n\n```\ngit clone http://github.com/tensorflow/docs /tmp/docs\ncd /tmp/docs\ndocker run -it --rm -v $PWD:/tmp -w /tmp tensorflow/tensorflow:latest-py3-jupyter \\\n  jupyter nbconvert --to notebook --execute ./site/en/tutorials/quickstart/beginner.ipynb\n```\n\nIt goes away with this change:\n\n```\ndocker build . -f ./dockerfiles/cpu-jupyter.Dockerfile -t test-jupyter \\\n    --build-arg USE_PYTHON_3_NOT_2=1\ngit clone http://github.com/tensorflow/docs /tmp/docs\ncd /tmp/docs\ndocker run -it --rm -v $PWD:/tmp -w /tmp test-jupyter \\\n  jupyter nbconvert --to notebook --execute ./site/en/tutorials/quickstart/beginner.ipynb\n```", "comments": []}, {"number": 36107, "title": "Tensorflow install breaks curl on Ubuntu", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: 1.15\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: Virtualenv/pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: NVidia 640\r\n\r\n**Describe the problem**\r\n\r\nRasa install of Tensorflow 1.15 causes a Ubuntu dependency error which prevents \"curl\" from installing, which silently breaks the iDrive backup system.\r\n\r\nThe underlying problem seems to be that Tensorflow tries to build a modified \"curl\" with support for some Google remote file system. See this Tensorflow mod to Curl:\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/bb890ea5fa4c8a2100a295e93c5bf37b3c88b55a\r\n\r\nThat would be fine if the modified \"curl\" was private to the Tensorflow environment, but somehow the nonstandard version of \"curl\" or \"libcurl\" got installed in the Ubuntu system. This broke the Ubuntu package dependency system, and now a standard \"curl\" cannot be installed. This, in turn, broke things which depend on \"curl\" being present, such as iDrive backups. \r\n\r\nDetails here: https://ubuntuforums.org/showthread.php?t=2435412\r\n\r\nAlso see: https://github.com/RasaHQ/rasa/issues/5104", "comments": ["What do you mean by \"rasa install\"?\r\nStandard tensorflow pip package installations should have no interactions with curl/libcurl.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36107\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36107\">No</a>\n", "Closing because this is an unsupported installation method/environment for TF.\r\nThis is likely due to the installer/environment."]}, {"number": 36106, "title": "[ROCm] add ROCm support for XLA RCCL thunk", "body": "", "comments": ["gentle ping", "gentle ping"]}, {"number": 36105, "title": "how to install openpose library for python in windows 10 ?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["![Screenshot (175)](https://user-images.githubusercontent.com/56798346/72825545-3da55980-3c9d-11ea-935a-2335a795d24d.png)\r\n", "@NIravMeghani, Looks like issue is not related to Tensorflow, can you post this issue in relevant location. Thanks!", "yeap\r\nhow can i transfer this to other topic ?\r\n"]}, {"number": 36104, "title": "undef TranslateName for c file_system as well", "body": "This PR applies PR #35947 to C verson of the file_system, to undef TranslateName.\r\n\r\nTranslateName under Windows are defined as `TranslateNameA` or `TranslateNameW` and it might be enabled depending on Visual Studio's configurations. It would be safe to undef TranslateName when possible.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 36103, "title": "Fix: Can't set None on TextVectorization layer's split parameter problem", "body": "resolves: #36071 ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36103) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36103) for more info**.\n\n<!-- ok -->", "Can someone review this PR, please?", "@tanzhenyu Thanks for the approval. I actually forgot to put `self` argument in the test. I have pushed one more commit. Can you review it again, please?", "@rushabh-v can you please fix build failures ?", "I'm sorry for those silly mistakes. I have fixed it", "Can you review it once again, please? @tanzhenyu ", "@rushabh-v can you please fix build failures ?\r\n\r\n", ">@rushabh-v can you please fix build failures ?\r\n\r\nFixed it. used dtype wrongly before.", "Can you review it, please? @tanzhenyu ", "> Can you review it, please? @tanzhenyu\r\n\r\nLet me know after all runs are passed then I will approve it.", "I didn't know that I can run the checks before it's reviewed. Can you please tell me how to run the checks. Or you mean I should check locally? the checks says `Waiting for status to be reported`", "@rthadur the added test is passing and other tests are also passing. But three CI checks are failing. I looked at the logs but couldn't figure out why they are failing. Can you take a look, please?", "@tanzhenyu gentle ping to assist with build failures. Thank you", "```\r\n2. do_pylint: Python 3 pylint\r\n  FAIL\r\n```\r\n\r\nDownloading the log and looking at the start gives the pylint issues\r\n\r\n```\r\nFAIL: Found 1 non-whitelisted pylint errors:\r\ntensorflow/python/keras/layers/preprocessing/text_vectorization_test.py:1121: [C0326(bad-whitespace), ] No space allowed before bracket\r\n```", "Okay, I have removed that extra blank space before the bracket, it should be fine now..", "```\r\n\"tensorflow/python/keras/layers/preprocessing/text_vectorization_test.py\", line 1124, in test_split_equals_zero_on_adapt\r\n    predictions = model.predict(predict_data)\r\n  File \"tensorflow/python/keras/engine/training_v1.py\", line 969, in predict\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"tensorflow/python/keras/engine/training_arrays.py\", line 707, in predict\r\n    x, check_steps=True, steps_name='steps', steps=steps)\r\n  File \"tensorflow/python/keras/engine/training_v1.py\", line 2311, in _standardize_user_data\r\n    batch_size=batch_size)\r\n  File \"tensorflow/python/keras/engine/training_v1.py\", line 2338, in _standardize_tensors\r\n    exception_prefix='input')\r\n  File \"tensorflow/python/keras/engine/training_utils.py\", line 527, in standardize_input_data\r\n    standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)\r\n  File \"tensorflow/python/keras/engine/training_utils.py\", line 527, in <listcomp>\r\n    standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)\r\n  File \"tensorflow/python/keras/engine/training_utils.py\", line 452, in standardize_single_array\r\n    if (x.shape is not None and len(x.shape) == 1 and\r\nAttributeError: 'str' object has no attribute 'shape'\r\n```\r\n\r\n@rushabh-v can you please check above error ?", "@rushabh-v Can you please check @rthadur comments and resolve conflicts?. Thanks!", "@rushabh-v Any update on this PR? Please. Thanks!", "@rushabh-v Any update on this PR? and please resolve conflicts Thanks!", "@rushabh-v can you please check below errors\r\n\r\n`File \"/testing/parameterized.py\", line 284, in bound_param_test\r\n   return test_method(self, *testcase_params)\r\n File \"/tensorflow/python/keras/keras_parameterized.py\", line 388, in decorated\r\n   _v1_session_test(f, self, config, *args, **kwargs)\r\n File \"/tensorflow/python/keras/keras_parameterized.py\", line 405, in _v1_session_test\r\n   f(test_or_class, *args, **kwargs)\r\n File \"/tensorflow/python/keras/layers/preprocessing/text_vectorization_test.py\", line 1214, in test_split_equals_zero_on_adapt\r\n   predictions = model.predict(predict_data)\r\n File \"/tensorflow/python/keras/engine/training_v1.py\", line 988, in predict\r\n   use_multiprocessing=use_multiprocessing)\r\n File \"/tensorflow/python/keras/engine/training_arrays.py\", line 707, in predict\r\n   x, check_steps=True, steps_name='steps', steps=steps)\r\n File \"/tensorflow/python/keras/engine/training_v1.py\", line 2330, in _standardize_user_data\r\n   batch_size=batch_size)\r\n File \"/tensorflow/python/keras/engine/training_v1.py\", line 2357, in _standardize_tensors\r\n   exception_prefix='input')\r\n File \"/tensorflow/python/keras/engine/training_utils.py\", line 527, in standardize_input_data\r\n   standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)\r\n File \"/tensorflow/python/keras/engine/training_utils.py\", line 527, in <listcomp>\r\n   standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)\r\n File \"/tensorflow/python/keras/engine/training_utils.py\", line 452, in standardize_single_array\r\n   if (x.shape is not None and len(x.shape) == 1 and\r\nAttributeError: 'str' object has no attribute 'shape'\r\n`", "hey @rthadur ! \r\n\r\nI apologize to you and @mihaimaruseac  for not replying to your comments. Actually I mistakenly unsubscribed from the notification of this PR. And just saw those comments today.\r\n\r\nBut I see that the errors are solved with the last commit of @mihaimaruseac ", "@rushabh-v we still see same error , can you please check again.", "It seems it's an internal error only, so probably will need manual import. Don't know if I can do this this week, but I'll add it on my plate.", "Yes, the traceback says: `AssertionError: Exception of type <class 'tensorflow.python.framework.errors_impl.UnimplementedError'>: Cast int32 to string is not supported [Op:Cast]`", "@mihaimaruseac  Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "This looks pretty stale--this fix would no longer apply at head. And the underlying issue this fixes looks already closed.\r\n\r\nI think we can probably just close this @gbaned ", "@mattdangerw  Thanks for the confirmation. Closing this PR. Thanks!"]}, {"number": 36102, "title": "CONV_2d convert to DEPTHWISE_CONV when input depth=1", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n**Describe the current behavior**\r\nCONV_2d convert to DEPTHWISE_CONV when input depth=1\r\n\r\n**Describe the expected behavior**\r\nCONV_2d should be CONV_2d\r\n\r\n**Code to reproduce the issue**\r\nif input depth=1 for CON_2D layer, TFLite converter will convert it to DEPTHWISE_CONV.\r\nAlthough it's computationally identical, it can cause confusion and potentially bug...\r\n\r\nTo replicate the problem:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\ndef gen_calibration_dataset():\r\n    for _ in range(10):\r\n        yield [np.random.rand(1,28,28,1).astype(np.float32)]\r\n\r\ndef get_keras_model_conv():\r\n\r\n    input_0 = tf.keras.layers.Input(shape=[28, 28, 1])\r\n\r\n    conv_0 = tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3),\r\n                                    activation=tf.nn.relu)(input_0)\r\n    conv_1 = tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3),\r\n                                    activation=tf.nn.relu)(conv_0)\r\n\r\n    model = tf.keras.models.Model(inputs=[input_0], outputs=[conv_1])\r\n\r\n    model.summary()\r\n\r\n    return model\r\n\r\ndef gen_model():\r\n\r\n    keras_model = get_keras_model_conv()\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\r\n    tflite_quant_model = converter.convert()\r\n    open('conv.tflite', 'wb').write(tflite_quant_model)\r\n\r\ngen_model()\r\n```\r\nkeras model summary gives:\r\n```\r\nModel: \"model\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         [(None, 28, 28, 1)]       0         \r\n_________________________________________________________________\r\nconv2d (Conv2D)              (None, 26, 26, 12)        120       \r\n_________________________________________________________________\r\nconv2d_1 (Conv2D)            (None, 24, 24, 12)        1308      \r\n=================================================================\r\n\r\n```\r\n\r\nBut,\r\ninspect the model with [netron](https://github.com/lutzroeder/netron) or `bazel run //tensorflow/lite/tools:visualize conv.tflite conv.html` shows as below:\r\n\r\n![image](https://user-images.githubusercontent.com/55463253/72816765-9276af00-3c60-11ea-8daf-fc42ced34568.png)\r\n\r\n![image](https://user-images.githubusercontent.com/55463253/72816851-b2a66e00-3c60-11ea-9b7d-14ac076b5de4.png)\r\n\r\n\r\n**Other info / logs**\r\nN/A\r\n", "comments": ["Hi, tensorflowers, is this a bug or expected? Any suggestions?", "@psunn I ran comparison between your `tensorlfow model` and `tf_lite_model` and the max difference is very low. `Max absolute difference: 2.0861626e-07` is what I got from the code. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/fc3386eb9e40c05c9fe7b5f1ee190cf0/untitled778.ipynb). Thanks!\r\n\r\nPlease close this issue if it was resolved for you. Thanks!", "Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36102\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36102\">No</a>\n", "@jvishnuvardhan I met the same problem ,my tf is 1.15", "@sunzhe09 Can you please create a new issue as it is  better to track and the original issue was with `TF2.1`. Please share a standalone code when you create a new issue. Thanks!", "@jvishnuvardhan ok\r\n"]}, {"number": 36101, "title": "[TFLite int16] 16-bit version of MUL reference kernel operator", "body": "This PR is one of steps to extend 8-bit quantization to support symmetric 16-bit activations.\r\n\r\nEach activation is of type int16 and symmetric around zero. The weight tensor precision remains at 8-bit signed values. The bias is set to int64 precision.\r\n\r\nIn this PR we introduce implementation and tests for MUL kernel reference function.\r\nThe specification of this operator:\r\n\r\nMUL \r\n\u202f Input 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f Input 1: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f Output 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n 32767]\r\n\u202f \u202f granularity: per-tensor, zero_point=0\r\n", "comments": ["My understanding is the kernel implementation needs to reflect the\nquantization schema. +Suharsh Sivakumar <suharshs@google.com> may help\nanswer that.\n\nThanks!\n\nOn Wed, Jan 22, 2020 at 6:18 PM Elena Zhelezina <notifications@github.com>\nwrote:\n\n> *@wwwind* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/lite/kernels/mul.cc\n> <https://github.com/tensorflow/tensorflow/pull/36101#discussion_r369474903>\n> :\n>\n> > @@ -183,6 +184,22 @@ TfLiteStatus EvalQuantized(TfLiteContext* context, TfLiteNode* node,\n>            TF_LITE_MUL(optimized_integer_ops, Mul, int8_t);\n>          }\n>        }\n> +    } else if (input1->type == kTfLiteInt16) {\n> +      // We have this check, because in case of int16\n> +      // input1_val*input2_val can overflow int32:\n> +      // see MulElementwise -\n> +      // tensorflow/lite/kernels/internal/reference/integer_ops/mul.h in case of\n> +      // 16-bit this function is used in symmetric quantization, so offset\n> +      // should be zero.\n> +      TF_LITE_ENSURE_EQ(context, op_params.input1_offset, 0.0);\n>\n> Hi @renjie-liu <https://github.com/renjie-liu>,\n> Thank you for the review.\n>\n> We introduce this kernel for the quantization scheme: activations in\n> 16-bit and weights in 8-bit. The range of 16-bit is quite large and it is\n> sufficient, if we do only symmetric quantization. That's why we consider\n> only symmetric quantization for 16-bit reference kernels.\n> Should operator specifications reflect this case ? Should we have a\n> special \"restricted_value\" property for 16-bit that shows that zero point\n> is zero in this case ?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/36101?email_source=notifications&email_token=AIURNGLW6AOEKBO2PZVBUZLQ7AMRHA5CNFSM4KJVCHJKYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCSTNG3Y#discussion_r369474903>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIURNGI4AHIUBWOQD7LM5ETQ7AMRHANCNFSM4KJVCHJA>\n> .\n>\n\n\n-- \nRenjie Liu\n\nrenjieliu@google.com\n+1 (650) 253-4359\n", "@suharshs Hi Suharsh, Sorry to bother, but could you please take a look at this PR? Thanks", "@suharshs Sorry to bother, but could you please re-approve this PR ? We had to push a small fix for CheckLint error, which has invalidated the approval. Thanks! ", "@rthadur This PR has been approved, but it still has the label \"stat: awaiting response\". What does this mean ? Could this PR be merged ? Thanks"]}, {"number": 36100, "title": "Fixed typo in TFlite export exception.", "body": "Changed the exception statement in tensorflow/lite/toco/tflite/export.cc:\r\n\"Placeholder \", input_array, \" should be specied by input_arrays.\"\r\nto:\r\n\"Placeholder \", input_array, \" should be specified by input_arrays.\"", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36100) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36100) for more info**.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36100) for more info**.\n\n<!-- ok -->", "We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.If possible include more such changes and include in this PR.\r\nCC @mihaimaruseac @chanshah", "I completely understand, excuse me being a douchebag. It was my first ever pull  request, and I shall  from now on try commit relevant content.\r\nThank you for your commitment so far :)"]}, {"number": 36099, "title": "Update the documentation link to the TFLITE conversion commands ", "body": "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/toco\r\n\r\nTflite converter is missing the usage documentation exmaple links :\r\n[link 1](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/cmdline_reference.md)\r\n[link 2](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/cmdline_examples.md)\r\n\r\nthe flags are needed to run such command : \r\n\r\n```\r\nbazel run --config=opt tensorflow/lite/toco:toco -- \\\r\n--input_file=$OUTPUT_DIR/tflite_graph.pb \\\r\n--output_file=$OUTPUT_DIR/detect.tflite \\\r\n--input_shapes=1,300,300,3 \\\r\n--input_arrays=normalized_input_image_tensor \\\r\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\r\n--inference_type=FLOAT \\\r\n--allow_custom_ops\r\n```\r\n\r\nPlease update the links or some one points me at the file that contains these flags to investigate more other possibilities and methods.\r\n\r\n\r\n", "comments": ["Thanks for the report. Meanwhile you may refer those links from the website.\r\nSee https://www.tensorflow.org/lite/convert\r\nFor GitHub the location has changed https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/toco/g3doc", "Hi. Would like to contribute. How can i get write access right? Thanks", "Thanks. Please submit a pull request to the repo and someone will review. See the TF contributor guide for instructions: https://www.tensorflow.org/community/contribute"]}]