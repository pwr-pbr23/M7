[{"number": 29419, "title": "tf.gather_nd replacement", "body": "Hi,\r\n\r\nI am doing a project but their tensorflow, but the hardware does not support tf.gather_nd. I am asking if possible that use tf.gather, tf.slice or tf.strided_slice to rewrite a function of tf.gather_nd?\r\n\r\nThanks,\r\nPeter ", "comments": ["@gbc8181 Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "> @gbc8181 Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n> \r\n> Make sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n> \r\n> We ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\nHi,\r\n\r\nI checked with the administer. The Tensor-flow is 1.08. Since they have very special hardware thus they cannot support tf.gather_nd. Now the method is can we use tf.gather to realize the function of tf.gather_nd. \r\n\r\nThanks", "This is not Bug/Performance issue or Build/Installation. Please post this kind of support questions at [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks! "]}, {"number": 29418, "title": "Add notes for newly versioned .so files", "body": "This adds a missing set of release notes describing changes to our .so libraries.", "comments": ["@rajatmonga Could you double-check these new notes before they're merged, please?", "@gunan or @martinwicke could confirm too -- any one of the three of them would work."]}, {"number": 29417, "title": "Release Notes for 2.0 Beta", "body": "", "comments": []}, {"number": 29416, "title": "[TF 2.0 API Docs] Added Returns and Raises sections to tf.image.convert_image_dtype", "body": "Added missing documentation sections. #29406", "comments": ["Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 29415, "title": "Cleaning up this file, so that only kathy's changes are in.", "body": " Cleaning up this file, so that only kathy's changes are in.", "comments": []}, {"number": 29414, "title": "Update version numbers for TensorFlow 1.14.0-rc1", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 1 -> 1\nMinor: 14 -> 14\nPatch: 0 -> 0\n\nNo lingering old version strings \"1.14.0-rc0\" found in source directory \n\"tensorflow/\". Good.\nWARNING: Below are potentially instances of lingering old version string \n\"1.14.0rc0\" in source directory \"tensorflow/\" that are not updated by this \nscript. Please check them manually!\ntensorflow/tools/pip_package/setup.py:63:1.14.0rc0\n```", "comments": ["@mihaimaruseac That extra lingering string is an install reference to `tensorflow_estimator`. Does that need to be updated now, later, or at all?", "It doesn't need to be updated."]}, {"number": 29413, "title": "tf.keras throws AlreadyExistsError for LSTM training whereas keras stand-alone throws no error.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.13.1 (keras version 2.2.4)\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None (CPU Training)\r\n\r\n**Describe the current behavior**\r\nWhen using tf.keras models and layers to build a simple LSTM and train on the Penn Treebank Dataset a long list of errors are thrown of the form:\r\n\r\nW tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n\r\nHowever, when just importing keras and building the same LSTM, no errors occur. \r\n\r\n**Describe the expected behavior**\r\nIt would be expected that both keras's should be operational. I am also not mixing and matching keras and tf.keras layers.\r\n\r\n**Code to reproduce the issue**\r\nAttached is a test case that reproduces the problem. It is required that the Penn Treebank Dataset is downloaded/available (Directions in source). Code was modified from:\r\n\r\nhttps://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_lstm.py\r\n\r\nRun option 1 to use keras with no errors and use option 2 to run with tf.keras and see all the errors.\r\n\r\n**Other info / logs**\r\n\r\n2019-06-04 15:27:39.644788: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.647428: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.664264: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.666201: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.671178: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.676772: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.680910: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.685541: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.689694: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.693689: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.702369: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.703234: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.713664: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.725751: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.727035: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.731410: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.734116: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.745524: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.749895: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.750059: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.754578: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.757058: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.764737: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.769848: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.779327: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.779501: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.787285: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-04 15:27:39.793182: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/\r\nEnter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\nTraceback (most recent call last):\r\n  File \"keras_lstm_issueFile.py\", line 152, in <module>\r\n    validation_steps=len(valid_data)//(batch_size*num_steps))\r\n  File \"/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1426, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n  File \"/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 191, in model_iteration\r\n    batch_outs = batch_function(*batch_data)\r\n  File \"/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1191, in train_on_batch\r\n    outputs = self._fit_function(ins)  # pylint: disable=not-callable\r\n  File \"/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3076, in __call__\r\n    run_metadata=self.run_metadata)\r\n  File \"/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\r\n    run_metadata_ptr)\r\n  File \"/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.AlreadyExistsError: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19Tem\r\nporaryVariableOp6TmpVarE\r\n         [[{{node training/Adam/gradients/lstm/while/ReadVariableOp/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var}}]]\r\n\r\n[keras_lstm_issueFile.zip](https://github.com/tensorflow/tensorflow/files/3254289/keras_lstm_issueFile.zip)\r\n\r\n", "comments": ["@yakaboskic I tried reproducing the issue of option 1 and option 2 separately but I am not able to reproduce the it, Could you please provide minimal code snippet to reproduce issue. Thanks!", "I have the same issue, but also complicated/long code - thus no minimal example.\r\nWhen learning with a lear-rate of 0 the error vanishes, but the network is not learning ;)\r\nA bit of googling hinted at some weights degenerating and yielding similar errors.\r\n\r\nAlso the net trained ~1.8 Epochs yesterday (around 800 iterations) and then encountered this error. When fiddling with the learning-rate i can make it crash after 1 iteration (with a lr of 1) or not at all (with a lr of 0).\r\n\r\nHope this information help a bit.\r\n\r\nSystem is debian stretch with python 3.5.3 (GCC 6.3.0) and a GTX1080 for training. Also current tensorflow from pip.", "reverted back to 1.12. That version works without problems.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "@Drezil Thanks a lot! It works! :)\r\nI tried in 1.14.0 and 1.13.1, error occurs. \r\nbut with 1.12.0, it's perfect!", "Is this issue still present in TF 2.0 in graph mode (with tf.function decorator?)", "@gavinlive, \r\nCan you please post a new issue by providing the information asked by the template?\r\nThe reason for this is we can focus on your specific configuration and problem since the root cause can be unrelated even though the error messages are similar. Thanks!"]}, {"number": 29412, "title": "Updated maximum layer", "body": "Added an example and `Raises` as well as updated docstring and Arguments. This will take care of this issue https://github.com/tensorflow/tensorflow/issues/29297", "comments": ["Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 29411, "title": "Avoid allocating reserve_space_3 multiple times (it was already handled by reserve_space_allocator).", "body": "", "comments": []}, {"number": 29410, "title": "patched r1.14 with s3 fixes", "body": "", "comments": ["@rahul003 May I ask, why close this PR? And another PR #24054 is also closed."]}, {"number": 29409, "title": "Add missing cuBLAS header dependencies.", "body": "PiperOrigin-RevId: 250103546\r\n\r\nThis change from master is required to build r1.14 against CUDA 10.1 (at least on Red Hat).", "comments": ["I think @rmlarsen is a better reviewer for this.", "Note that this is just a cherry-pick of [5c64152b](https://github.com/tensorflow/tensorflow/commit/5c64152b43b596b3738d59170e40156168763e59) from master.", "Sorry. I didn't notice that this is for r1.14 branch. This should go to @bananabowl then."]}, {"number": 29408, "title": "[TF 2.0 API Docs] tf.keras.backend.maximum", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/backend/maximum\r\n\r\n## Description of the issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe description is not clear enough.\r\n\r\n### Correct links\r\n\r\nThe links are okay.\r\n\r\n### Parameters defined\r\n\r\nThe parameters are defined.\r\n\r\n### Returns defined\r\n\r\nThe return values are defined.\r\n\r\n### Raises listed and defined\r\n\r\nErrors are not defined or listed.\r\n\r\n### Usage example\r\n\r\nThere is no usage example.\r\n\r\n### Request visuals, if applicable\r\n\r\nThere are no visuals.\r\n\r\n### Submit a pull request?\r\n\r\nNo.\r\n", "comments": ["Hi @KengoWada could you please fill out the form you submitted above by replacing the non-bold text with you text?", "Sorry about that. I have updated the form. Thank you.", "I just created a pull-request [here](https://github.com/tensorflow/tensorflow/pull/29435).", "@KengoWada,\r\nClosing this issue since the associated PR has been merged. Feel free to reopen if the problem still persists. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29408\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29408\">No</a>\n"]}, {"number": 29407, "title": "[TF 2.0 API Docs] tf.data.experimental.scan", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/scan\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\nNo\r\nIt's  hard for a person to tell what is  raising the error \r\n\r\n\r\n### Usage example\r\n\r\nNo. usage example,it might be hard for someone to know under what context to use it \r\n\r\n### Request visuals, if applicable\r\nNo\r\n\r\n\r\n", "comments": ["Please refer to the updated [page](https://www.tensorflow.org/api_docs) and let us know.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 29406, "title": "[TF 2.0 API Docs] tf.data.experimental.make_saveable_from_iterator", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/make_saveable_from_iterator\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Returns defined\r\n\r\nThe returns section is missing.\r\n\r\n### Raises listed and defined\r\n\r\nRaises are neither listed nor defined.", "comments": ["Issue can be closed", "Closing the issue since its been merged. Thanks!"]}, {"number": 29405, "title": "[INTEL MKL] MKL ML cleanup - MklSoftmaxOp ", "body": "MKL ML is not supported anymore.\r\nClean up related code with MklSoftmaxOp.", "comments": []}, {"number": 29404, "title": "Final cherrypick for fixing the windows cpu/gpu builds.", "body": "PiperOrigin-RevId: 251441123", "comments": []}, {"number": 29403, "title": "tf 2 memory leak of Flatten and BatchNormalization layer", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10 x64\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n- Python version: 3.6.6\r\n\r\n\r\n**Describe the current behavior**\r\nmemory leak when model has Flatten or BN layer.\r\nmemory usage keep increasing and never down after gc collection.\r\n\r\n**Describe the expected behavior**\r\nmodels created will be collected by gc, and memory usage go down to initial level\r\n\r\n**Code to reproduce the issue**\r\n```python\r\n\r\nfrom time import sleep\r\n\r\nimport os\r\nimport time\r\nimport gc\r\nimport numpy as np\r\nimport tensorflow.keras as k\r\nimport tensorflow as tf\r\n\r\nif __name__ == '__main__':\r\n\t\"\"\"\r\n\tthe Flatten and BN layer will cause memory leak, and performance problem\r\n\tmemory usage keep increasing during the iteration, and never down after gc:\r\n\t\tFlatten + BN : mem 1.3GB, time 105s\r\n\t\tFlatten only: mem 1.3GB, time 105s\r\n\t\tBN only: mem 760MB, time 45s\r\n\t\tno Flatten or BN: mem 490M, time 21s\r\n\t\"\"\"\r\n\tmodel_file = 'l:/m'\r\n\tfor i in range(100):\r\n\t\tif os.path.exists(model_file):\r\n\t\t\tmodel = k.models.load_model(model_file)\r\n\t\telse:\r\n\t\t\tmodel = k.models.Sequential([\r\n\t\t\t\tk.layers.Flatten(input_shape=(10,)), # this layer will cause HUGE memory leak and performance problem\r\n\t\t\t\tk.layers.Dense(100),\r\n\t\t\t\tk.layers.ELU(),\r\n\t\t\t\tk.layers.Dense(500),\r\n\t\t\t\tk.layers.BatchNormalization(), # this layer will cause memory leak\r\n\t\t\t\tk.layers.ELU(),\r\n\t\t\t\tk.layers.Dense(2, activation=tf.nn.softmax),\r\n\t\t\t])\r\n\t\t\tmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\r\n\t\t\tmodel.fit(np.ndarray((5000, 10), dtype=float), np.array([0, 1] * 2500), epochs=1, verbose=1)\r\n\t\t\tmodel.save(model_file)\r\n\t\t\r\n\t\tx = np.ndarray((1, 10), dtype=float)\r\n\t\tx.fill(1)\r\n\t\tprint(i, model.predict(x))\r\n\t\r\n\tos.remove(model_file)\r\n\tgc.collect()\r\n\tsleep(100000)\r\n\r\n\r\n```\r\n", "comments": ["Will it be possible to provide the full code snippet that can replicate the issue. It will be really helpful to proceed further. Thanks!", "> Will it be possible to provide the full code snippet that can replicate the issue. It will be really helpful to proceed further. Thanks!\r\n\r\nI've updated the code snippet.", "Please see https://github.com/tensorflow/tensorflow/issues/28844 for a detailed explanation of what's going on. (Feel free to re-open if upgrading to `tf-nightly-2.0-preview` and adding `tf.keras.backend.clear_session()` doesn't resolve the issue.)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29403\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29403\">No</a>\n"]}, {"number": 29402, "title": "[TF 2.0 API Docs] tf.io.decode_base64", "body": "\r\n## Existing Url with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_base64\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\nThe link to the python script where the function is define is inactive\r\nWrong: python/ops/gen_string_ops.py\r\nCorrect (The file is not mentioned in the repo)\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_columErrors are not defined\r\n\r\n### Usage example\r\n\r\nNo usage example provided\r\nUse case: (The documentation does not define how to use, when to use the symbol)\r\n", "comments": ["@Emanuz We are checking to see if you still need help on this issue. Could you please have a look on the [link1](https://www.tensorflow.org/api_docs/python/tf/io/decode_base64) , [link2](https://stackoverflow.com/questions/48910253/why-would-tensorflow-decode-base64-fail-due-to-invalid-character-but-base64-b64?rq=1) and let us know if it helps? Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 29401, "title": "[TF 2.0 API Docs] tf.io.decode_json_example", "body": "**Existing URLs containing the issue:**\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_json_example\r\n\r\n### Description of issue (what needs changing):\r\n**Correct Links**\r\nThe link to the python script where the function is defined is inactive. \r\nWrong: python/ops/gen_parsing_ops.py.\r\nCorrect: (The file mentioned here is not in the repo)\r\n\r\n**Usage Example**\r\nNo usage example is provided.\r\nUse Cases: The documentation does not define when to use and when not to use the symbol.\r\n\r\n**Raises Listed and Defined**\r\nErrors are not defined.", "comments": ["I think this was resolved with the update docs. https://www.tensorflow.org/api_docs/python/tf/io/decode_json_example\r\n\r\nIn the update docs, the links are active and working. Also, provided an example.\r\n\r\nI am closing this issue as this was resolved. Thanks!"]}, {"number": 29400, "title": "https://www.tensorflow.org/versions/api_docs/python/tf link does not exist", "body": "## URL(s) with the issue: \r\nhttps://www.tensorflow.org/versions\r\n\r\n## Description of issue (what needs changing): \r\n\r\n### Clear Description \r\n\r\nWhen someone is in [this page](https://www.tensorflow.org/versions) , clicking on the bullet point `r1.13 (stable)` redirects to a `404 not found page`.\r\n\r\n### Correct links\r\n\r\nThe bullet point targets [here](https://www.tensorflow.org/versions/api_docs/python/tf) while it should target [here](https://www.tensorflow.org/api_docs/python/tf). \r\n\r\n\r\n### Submit a pull request?\r\n\r\nI tried to fix it but I cannot find where this link ref is stated. If someone could point me in the right direction I could fix it, otherwise someone else could do it.\r\n", "comments": ["Thanks. That link should point here: https://www.tensorflow.org/api_docs/python/tf\r\n\r\nBut it's losing the left nav---just like when you select it API from the dropdown and select 1.13\r\n\r\n", "Looks fixed now so the issue can be closed I guess.", "Working on it :)\r\nFixing leftnav issue now", "Oh okay. The error does not exist for me anymore so I thought someone has fixed it already.", "Closing this issue since its resolved. Thanks!"]}, {"number": 29399, "title": "Allow calling tf.config APIs after initialization", "body": "If the API call does not modify the existing values, we allow the call\r\nto be made.\r\n\r\nPiperOrigin-RevId: 251378501", "comments": []}, {"number": 29398, "title": "Remove incorrect extra `)` in tf_upgrade_v2 documentation", "body": "While testing tf_upgrade_v2 noticed there is\r\none extra `)` in tf_upgrade_v2 documentation:\r\n```\r\n  File \"<unknown>\", line 7\r\n    tf.argmax([[1, 3, 2]], dimension=0))\r\n                                       ^\r\nSyntaxError: invalid syntax\r\n```\r\n\r\nThis fix fixes the issue.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 29397, "title": "tf.config cherry-picks", "body": "", "comments": []}, {"number": 29396, "title": "[tf2.0] decode numpy array with bytes format stored in tensor", "body": "I can not found any documentation about this. \r\n\r\nI saved some numpy arrays into tfrecord, it stored as bytes (using np.array().to_bytes() method)\r\n\r\nWhen read it back, there were no way to decode that bytes back to numpy.\r\n\r\nAnyone knows how to solve it?", "comments": ["@jinfagang tensor.numpy() --> gives numpy array of the given tensor in TF2.0.\r\n```python\r\na=tf.constant([1,2,3,4,5])\r\na # <tf.Tensor: id=32, shape=(5,), dtype=int32, numpy=array([1, 2, 3, 4, 5], dtype=int32)>\r\na.numpy() # array([1, 2, 3, 4, 5], dtype=int32)\r\n```\r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "I think it was resolved. I am closing the issue. But, please let me know if I'm mistaken. Thanks!"]}, {"number": 29395, "title": "[ROCm] Update eigen_contraction_kernel subroutine to make it device compatible", "body": "This PR addresses ROCm specific compilation issues. Below is the summary of the PR changes.\r\n\r\n-----\r\n\r\nFirst of all, `UseCustomContractionKernels()` should be declared with `EIGEN_DEVICE_FUNC` and `EIGEN_DONT_INLINE` as well to be consistent with the signature from `packLhs()` or `packRhs()`, `invoke()`.\r\n\r\nSecondly, `std::call_once()` is not available in gpu device code, and this function should not be invoked in device as well. If it does happen, take the short cut and return.\r\n\r\n-----\r\nThe change has been thoroughly tested under different compilation targets in develop-upstream branch.\r\n\r\n@tatianashp @whchung @chsigg ", "comments": ["Looking at the test results, Linux GPU has a large number of failures on `Broken by missing target @mkl_dnn//:mkldnn_single_threaded`. I do realize that this change might be related because `eigen_contraction_kernel_with_mkl` is the only target build with `mkldnn_single_threaded`.  However, I'm not able to view the corresponding build log online or reproduce locally. \r\n\r\nAn alternative of fixing this for the rocm target is to remove the defined macros in this target to make the chunk of code not build for rocm, i.e. `\"//tensorflow:using_rocm_hipcc\": [],` @chsigg Let me know if you prefer this alternative fix.", "posting here for reference, the error(s) we see in the `--config=rocm` build without this fix\r\n\r\n```\r\n[[32mINFO: ^[[0mFrom Compiling tensorflow/core/kernels/conv_2d_gpu_uint64.cu.cc [for host]:                                                                                                                                                                      \r\nclang-9: warning: /usr/bin/gcc: 'linker' input unused [-Wunused-command-line-argument]                                                                                                                                                                            \r\nclang-9: warning: /usr/bin/gcc: 'linker' input unused [-Wunused-command-line-argument]                                                                                                                                                                            \r\nIn file included from tensorflow/core/kernels/conv_2d_gpu_uint64.cu.cc:25:                                                                                                                                                                                        \r\nIn file included from ./tensorflow/core/kernels/conv_2d.h:22:                                                                                                                                                                                                     \r\nIn file included from ./tensorflow/core/kernels/eigen_spatial_convolutions.h:26:                                                                                                                                                                                  \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:860:1: error:  'Eigen::internal::UseCustomContractionKernels':  no overloaded function has restriction specifiers that are compatible with the ambient context 'packLhs'                                     \r\nREGISTER_TENSOR_CONTRACTION_KERNEL_WITH_FALLBACK(float, float, float);                                                                                                                                                                                            \r\n^                                                                                                                                                                                                                                                                 \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:605:38: note: expanded from macro 'REGISTER_TENSOR_CONTRACTION_KERNEL_WITH_FALLBACK'                                                                                                                         \r\n      if (UseCustomContractionKernels()) {                                     \\                                                                                                                                                                                  \r\n                                     ^                                                                                                                                                                                                                            \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:860:1: error:  'Eigen::internal::UseCustomContractionKernels':  no overloaded function has restriction specifiers that are compatible with the ambient context 'packLhs'                                     \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:605:38: note: expanded from macro 'REGISTER_TENSOR_CONTRACTION_KERNEL_WITH_FALLBACK'                                                                                                                         \r\n      if (UseCustomContractionKernels()) {                                     \\                                                                                                                                                                                  \r\n                                     ^                                                                                                                                                                                                                            \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:860:1: error:  'Eigen::internal::UseCustomContractionKernels':  no overloaded function has restriction specifiers that are compatible with the ambient context 'packRhs'                                     \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:624:38: note: expanded from macro 'REGISTER_TENSOR_CONTRACTION_KERNEL_WITH_FALLBACK'                                                                                                                         \r\n      if (UseCustomContractionKernels()) {                                     \\                                                                                                                                                                                  \r\n                                     ^                                                                                                                                                                                                                            \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:860:1: error:  'Eigen::internal::UseCustomContractionKernels':  no overloaded function has restriction specifiers that are compatible with the ambient context 'packRhs'                                     \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:624:38: note: expanded from macro 'REGISTER_TENSOR_CONTRACTION_KERNEL_WITH_FALLBACK'                                                                                                                         \r\n      if (UseCustomContractionKernels()) {                                     \\                                                                                                                                                                                  \r\n                                     ^                                                                                                                                                                                                                            \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:860:1: error:  'Eigen::internal::UseCustomContractionKernels':  no overloaded function has restriction specifiers that are compatible with the ambient context 'invoke'                                      \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:644:38: note: expanded from macro 'REGISTER_TENSOR_CONTRACTION_KERNEL_WITH_FALLBACK'                                                                                                                         \r\n      if (UseCustomContractionKernels()) {                                     \\                                                                                                                                                                                  \r\n                                     ^                                                                                                                                                                                                                            \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:860:1: error:  'Eigen::internal::UseCustomContractionKernels':  no overloaded function has restriction specifiers that are compatible with the ambient context 'invoke'                                      \r\n./tensorflow/core/kernels/eigen_contraction_kernel.h:644:38: note: expanded from macro 'REGISTER_TENSOR_CONTRACTION_KERNEL_WITH_FALLBACK'                                                                                                                         \r\n      if (UseCustomContractionKernels()) {                                     \\                                                                                                                                                                                  \r\n                                     ^                                                                                                                                                                                                                            \r\n6 errors generated.                                                                                                                                                                                                                                               \r\n                                                                                                                                          \r\n```\r\n\r\nOne curious aspect of these errors, is that the they do not cause the build to terminate, and the build actually finishes with a non-error exit status! That was the reason we failed to spot it before.  \r\n\r\nHave you (TF developers) seen this with errors (in Eigen headers) before, where in the errors do not lead to a build failure? just curious.\r\n\r\n"]}, {"number": 29394, "title": "Add get_ prefix to parallelism_threads APIs", "body": "PiperOrigin-RevId: 251391606", "comments": ["@bananabowl: Could we do https://github.com/tensorflow/tensorflow/pull/29397 instead? It has a few other documentation and behavior subtleties I'd like to include with the release.", "> @bananabowl: Could we do #29397 instead? It has a few other documentation and behavior subtleties I'd like to include with the release.\r\n\r\nSure thing!"]}, {"number": 29393, "title": "[2.0alpha0 AutoGraph] tf.function does not automatically transform nested class methods", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0alpha0\r\n- Python version: 3.6.5\r\n\r\n**Describe the current behavior**\r\nWhen we define multiple methods for a class and only decorate one of them with `@tf.function`, the nested methods are not automatically transformed and some errors raise.\r\n\r\n**Describe the expected behavior**\r\nWe only need decorate the outermost method.\r\n\r\n**Code to reproduce the issue**\r\n<pre>\r\n# -*- coding: utf-8 -*-\r\n# @Author  : Lin Lan (ryan.linlan@gmail.com)\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\n\r\n\r\nclass Foo(tf.keras.Model):\r\n    def __init__(self):\r\n        super(Foo, self).__init__()\r\n        self.dense = tf.keras.layers.Dense(20)\r\n        self.embeddings = tf.Variable(tf.random.normal((100, 5)), dtype=tf.float32)\r\n\r\n    @tf.function\r\n    def call(self, inputs):\r\n        embeddings = tf.nn.embedding_lookup(\r\n            self.embeddings, inputs)\r\n        return self._inner(embeddings)\r\n\r\n    # @tf.function\r\n    def _inner(self, embeddings):\r\n        batch = tf.shape(embeddings)[0]\r\n        ta = tf.TensorArray(tf.float32, size=batch)\r\n        for i in tf.range(batch):\r\n            this = self.dense(embeddings[i][tf.newaxis, :])\r\n            ta = ta.write(i, this)\r\n        return ta.stack()\r\n\r\n\r\nfoo = Foo()\r\nres = foo([0, 2, 4, 6, 8])\r\n</pre>\r\n\r\n**Other info / logs**\r\n`TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.`\r\n\r\nAlso decorating the method `_inner` eliminate the error.\r\n\r\n", "comments": ["It took me a lot of time to find this bug (or intended behavior?) from my original code. It would be better to add a warning in the doc of `tf.function`.\r\n\r\nThis [section](https://www.tensorflow.org/alpha/guide/effective_tf2#refactor_your_code_into_smaller_functions) is confusing given this issue. Also the third paragraph of this [section](https://www.tensorflow.org/alpha/guide/autograph#the_tffunction_decorator).", "Have tried with TF version 2.0.0-alpha on Colab and was able to reproduce the issue as mentioned in the description.", "You shouldn't need to decorate self._inner. @mdanatg why isn't it being caught here?", "This is a bug. We'll have it fixed in the nightly soon.", "Hi @mdanatg Any updates regarding to this issue?", "Yep! It will likely be fixed today, or sometime next week at the latest.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29393\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29393\">No</a>\n"]}, {"number": 29392, "title": "Error while importing tensorflow", "body": "- OS Platform and Distribution : CentOS Linux release 7.5.1804\r\n- TensorFlow installed from (source or binary): pip\r\n- Python version: 3.7.2\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n\r\nI get the following error when I try to import tensorflow:\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/users/pjh/Python-3.7.3/Lib/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/users/pjh/Python-3.7.3/Lib/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/users/pjh/Python-3.7.3/Lib/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/users/pjh/Python-3.7.3/Lib/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\n-----------------------------------------------\r\n\r\nI am not the root user in the server.\r\nI installed python in my directory by downloading 'https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz'. Next I downloaded tensorflow by 'python3 -m pip install tensorflow --user' (python3 command is linked to the one installed in my directory). Then I executed 'python3' and tried to import tensorflow.\r\n\r\nThank you so much.", "comments": ["This is a duplicate of https://github.com/tensorflow/tensorflow/issues/26826\r\nEither use python 3.6, or you'll need to build TensorFlow from source to use it with python 3.7 and CentOS.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 29391, "title": "Dropout in GRU/LSTM in Tensorflow 2.0 doesn't reset dropout masks on call", "body": "**System information**\r\n\r\n_Tensorflow_\r\nGIT VERSION: `v1.12.1-3283-geff4ae822a`\r\nVERSION: `2.0.0-dev20190604`\r\n\r\nColab environment\r\n\r\n**Describe the current behavior**\r\n\r\nIn RNNs, the dropout masks should be reset after every call. However, in training mode (where the dropouts are activated) GRU and LSTM implementation in tensorflow 2.0 seems to be re-using the same dropout masks, leading to deterministic behavior.\r\n\r\nSimple RNN seems to be doing the right thing, re-sampling dropout masks after each call.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe expected behaviour should be the same as SimpleRNN (re-sample dropout masks on each call).\r\n\r\n**Code to reproduce the issue**\r\n\r\nThe following code produces the correct behaviour in tensorflow 1.13.1:\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function\r\n\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n\r\nimport numpy as np\r\n\r\ntf.enable_eager_execution()\r\nprint(tf.__version__)\r\ndata = np.random.normal(0, 1, (1, 10, 2)).astype(np.float32)\r\nrnn = tf.keras.layers.GRU(units=10, dropout=0.5, recurrent_dropout=0.5)\r\nprint(set([rnn(data, training=True).numpy()[0, 0] for _ in range(5)]))\r\n```\r\n\r\noutput\r\n```\r\n1.13.1\r\n{0.09432551, -0.07633728, 0.03358479, 0.010588642, 0.0}\r\n```\r\n\r\nbut in tensorflow 2.0 it doesn't\r\n```\r\nfrom __future__ import absolute_import, division, print_function\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nprint(tf.version.GIT_VERSION, tf.version.VERSION)\r\ndata = np.random.normal(0, 1, (1, 10, 2)).astype(np.float32)\r\nrnn = tf.keras.layers.GRU(units=10, dropout=0.5, recurrent_dropout=0.5)\r\nprint(set([rnn(data, training=True).numpy()[0, 0] for _ in range(5)]))\r\n```\r\noutput\r\n```\r\nv1.12.1-3283-geff4ae822a 2.0.0-dev20190604\r\n{-0.14212656}\r\n```\r\n\r\nA quick fix is to call `reset_dropout_mask()` and `reset_recurrent_dropout_mask()` between calls however this looks like a breaking change.\r\n\r\n```\r\ndef fixed_rnn():\r\n  rnn.cell.reset_dropout_mask()\r\n  rnn.cell.reset_recurrent_dropout_mask()\r\n  return rnn(data, training=True).numpy()[0, 0]\r\n\r\nprint(set([fixed_rnn() for _ in range(5)]))\r\n```\r\noutput\r\n```\r\n{-0.004232532, 1.1669009, -0.009177759, 3.0901778, 4.5860972}\r\n```", "comments": ["Have tried on Colab with TF CPU versions 1.13.1 and 2.0.0-dev20190604 and was able to reproduce the issue.", "Thanks for reporting the issue. There was a similar issue, and has been recently fixed in 180f28a26660ca2e1ba27477f4f9592db5f9c4e8. Can u try with the latest nightly again?", "https://github.com/tensorflow/tensorflow/issues/29187", "For version `v1.12.1-3447-g5a0f1bbfb7 2.0.0-dev20190606`  the issue seems resolved. ", "Thanks for verifying this, closing bug now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29391\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29391\">No</a>\n", "@sbagroy986, the CPU and GPU implementation is covered under same code path, which means they should all be covered by the change. Can u report a issue with details if you feel this hasn't be fixed? Also, please make sure you install the latest pip package, which should include the fix."]}, {"number": 29390, "title": "Enable GPU support for Object Detection Sample Android Tflite App ", "body": " The [official documentation](https://www.tensorflow.org/lite/performance/gpu#supported_models_and_ops) suggests `mobile_ssd_v2_float_coco.tflite` model for enabling GPU delegate, but after analyzing the Model with [Netron,](https://electronjs.org/apps/netron) ( visualization tool to help identify how the output tensors differ.)\r\n`mobile_ssd_v2_float_coco.tflite`\r\nOUTPUT:\r\nraw_outputs/box_encodings\r\nid: raw_outputs/box_encodings\r\ntype: float32[1,2034,4]\r\nraw_outputs/class_predictions\r\nid: raw_outputs/class_predictions\r\ntype: float32[1,2034,91]\r\n\r\nWhereas the default model `detect.tflite` used in the demo has 4 different parameters.\r\nOUTPUT: \r\nTFLite_Detection_PostProcess\r\nid: TFLite_Detection_PostProcess\r\ntype: float32\r\nTFLite_Detection_PostProcess:1\r\nid: TFLite_Detection_PostProcess:1\r\ntype: float32\r\nTFLite_Detection_PostProcess:2\r\nid: TFLite_Detection_PostProcess:2\r\ntype: float32\r\nTFLite_Detection_PostProcess:3\r\nid: TFLite_Detection_PostProcess:3\r\ntype: float32\r\nie for **Location, Classes, Scores, Number and detections**\r\n\r\n**How can we use `mobile_ssd_v2_float_coco.tflite`or any model to get enable GPU with Object Detection, Please suggest?** ", "comments": ["Please help us to get information like what platform you are using. Also include the TensorFlow version and other relevant information. If you are unclear. please use the [Template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}]