[{"number": 38326, "title": "systemlibs: unbundle astunparse and small syslibs updates", "body": "A series of small changes needed for systemlibs for TF-2.2, there are also a few bigger changes needed but will be done in separate PRs.\r\n\r\nBundled GRPC was updated and needs some minor new rules to build against the system version of grpc\r\n\r\nThe bundled protobuf rules needed some minor updates to work with bazel --incompatible_no_support_tools_in_action_inputs.\r\n\r\nastunparse is unbundled like all other python packages\r\n\r\n@angerson ", "comments": []}, {"number": 38325, "title": "Bazel Build Tensorflow CPU-only", "body": "**System information**\r\n- Windows 10\r\n- TensorFlow Build from source\r\n- TensorFlow version 1.x (trying)\r\n- Python version: 3.6\r\n- Installed using chocoletey powershell\r\n- Bazel version : 3.0\r\n\r\nERROR: Config value opt is not defined in any .rc file\r\n\r\n`bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nmight be helpful, I received error when I was executing tensorflow 1.x version\r\n`bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n\r\n[bazel build tensorflow cpu-only.txt](https://github.com/tensorflow/tensorflow/files/4446724/bazel.build.tensorflow.cpu-only.txt)\r\n\r\n", "comments": ["You should use `-c=opt`", "> You should use `-c=opt`\r\n\r\n```\r\nPS C:\\tensorflow> bazel build -c=opt //tensorflow/tools/pip_package:build_pip_package\r\nERROR: Invalid options syntax: -c=opt\r\nPS C:\\tensorflow> bazel build --c=opt //tensorflow/tools/pip_package:build_pip_package\r\nERROR: Unrecognized option: --c=opt\r\n```", "Sorry, was on the phone and didn't type properly, didn't check log.\r\n\r\nFirst thing, the attached log you provided shows a totally different error. Seems to be an error from running `python configure.py`?\r\n\r\nIf you haven't successfully run `python configure.py` then the configuration option might not exist.\r\n\r\nFurthermore, it might be possible you have a corrupted bazel cache/checkout. Can you try `bazel clean --expunge` and cloning again the repository? Note that we only support 1.15 (`r1.15` branch), 2.0, 2.1, 2.2 and master at this point, assuming you already use the corresponding Bazel version.\r\n\r\nFinally, sorry again for my quick message. The config is indeed `--config=opt`, I confused it with a different issue\r\n\r\nPS: Please don't attach logs and/or images of errors. It's better to post the error message using ` ``` ` markdown so that it can be searched in the future and tooling can act on it.\r\n\r\nPS2: If the [build from source on Windows guide](https://www.tensorflow.org/install/source_windows) is wrong, please tell us which steps didn't work, assuming you follow them in sequence", "> Sorry, was on the phone and didn't type properly, didn't check log.\r\n> \r\n> First thing, the attached log you provided shows a totally different error. Seems to be an error from running `python configure.py`?\r\n> \r\n> If you haven't successfully run `python configure.py` then the configuration option might not exist.\r\n> \r\n> Furthermore, it might be possible you have a corrupted bazel cache/checkout. Can you try `bazel clean --expunge` and cloning again the repository? Note that we only support 1.15 (`r1.15` branch), 2.0, 2.1, 2.2 and master at this point, assuming you already use the corresponding Bazel version.\r\n> \r\n> Finally, sorry again for my quick message. The config is indeed `--config=opt`, I confused it with a different issue\r\n> \r\n> PS: Please don't attach logs and/or images of errors. It's better to post the error message using `` ``` `` markdown so that it can be searched in the future and tooling can act on it.\r\n> \r\n> PS2: If the [build from source on Windows guide](https://www.tensorflow.org/install/source_windows) is wrong, please tell us which steps didn't work, assuming you follow them in sequence\r\n\r\n I use `bazel clean --expunge` as you instructed but this what show up:\r\n\r\n```\r\nPS C:\\tensorflow> bazel clean --expunge\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Reading rc options for 'clean' from c:\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nERROR: Unrecognized option: --experimental_repo_remote_exec\r\n```\r\n\r\nI am using tensorflow-master though I directly download it then extract unlike what the instruction stated\r\n\r\nquestion: is it necessary to `python ./configure.py` even though I will use CPU?\r\n\r\nwhen I run `bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package`\r\nstill showing this ....\r\n\r\n```\r\nPS C:\\tensorflow> bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nERROR: Unrecognized option: --experimental_repo_remote_exec\r\n```", "You definitely need to run the `configure.py` command. It sets up several variables in `bazelrc` and also checks that you have the corresponding Bazel version installed.\r\n\r\nGiven the error messages about the unrecognized options, it is very likely that you are using a different bazel version than the one we support (2.0.0)\r\n\r\nI would recommend running `python ./configure.py` once, seeing the errors it gives. If it tells you to install a bazel version, please do. If it succeeds, then `bazel clean --expunge` to clean old bad state, then run again the configure command and then you should be able to build the pip package.", "> You definitely need to run the `configure.py` command. It sets up several variables in `bazelrc` and also checks that you have the corresponding Bazel version installed.\r\n> \r\n> Given the error messages about the unrecognized options, it is very likely that you are using a different bazel version than the one we support (2.0.0)\r\n> \r\n> I would recommend running `python ./configure.py` once, seeing the errors it gives. If it tells you to install a bazel version, please do. If it succeeds, then `bazel clean --expunge` to clean old bad state, then run again the configure command and then you should be able to build the pip package.\r\n\r\nYes, I already manage to run it properly the error is about bazel version please update the tested build configuration. Now I have new problem from building,\r\n`bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package`\r\n`bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nhere is the error both of them failed to build.\r\n\r\n```\r\nINFO: From Compiling external/com_google_protobuf/src/google/protobuf/stubs/common.cc:\r\nexternal/com_google_protobuf/src/google/protobuf/stubs/common.cc(42): warning C4005: 'WIN32_LEAN_AND_MEAN': macro redefinition\r\nexternal/com_google_protobuf/src/google/protobuf/stubs/common.cc(42): note: command-line arguments:  see previous definition of 'WIN32_LEAN_AND_MEAN'\r\nINFO: From Compiling tensorflow/core/profiler/internal/traceme_recorder.cc:\r\ntensorflow/core/profiler/internal/traceme_recorder.cc(26): warning C4273: 'tensorflow::profiler::internal::g_trace_level': inconsistent dll linkage\r\n.\\tensorflow/core/profiler/internal/traceme_recorder.h(36): note: see previous definition of 'g_trace_level'\r\nERROR: C:/tensorflow/tensorflow/core/lib/random/BUILD:28:1: C++ compilation of rule '//tensorflow/core/lib/random:philox' failed (Exit 2)\r\nc:\\users\\acer\\_bazel_acer\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1028): warning C4346: 'Eigen::internal::StridedLinearBufferCopy<Scalar,IndexType>::Kind': dependent name is not a type\r\nc:\\users\\acer\\_bazel_acer\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1028): note: prefix with 'typename' to indicate a type\r\nc:\\users\\acer\\_bazel_acer\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1134): note: see reference to class template instantiation 'Eigen::internal::StridedLinearBufferCopy<Scalar,IndexType>' being compiled\r\nc:\\users\\acer\\_bazel_acer\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1028): error C2061: syntax error: identifier 'Kind'\r\nc:\\users\\acer\\_bazel_acer\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1037): warning C4346: 'Eigen::internal::StridedLinearBufferCopy<Scalar,IndexType>::Kind': dependent name is not a type\r\nc:\\users\\acer\\_bazel_acer\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1037): note: prefix with 'typename' to indicate a type\r\nc:\\users\\acer\\_bazel_acer\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1037): error C2061: syntax error: identifier 'Kind'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 2534.618s, Critical Path: 44.44s\r\nINFO: 344 processes: 344 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nis it realted to `python ./configure.py` at c++ compilation?\r\n```\r\n  Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n```", "What is the version of your compiler? Which compiler are you using? These were fields in the issue template but I don't see them in the issue opening.\r\n\r\nYou are using Bazel 2.0.0 and building on master, right?\r\n\r\nPlease use ` ``` ` before and after long code blocks instead of just 1 backtick. The formatting is more readable that way", "version 14\r\nand yes, I'm using 2.0.0 building on master", "this is what i get when i directly use VS2019 developer command prompt\r\n\r\n```WARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nFATAL: Command line too long (34754 > 32768):  -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=c:\\\\users\\\\acer\\\\_bazel_acer\\\\xv6zejqw --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED -Xverify:none -Djava.util.logging.config.file=c:\\\\users\\\\acer\\\\_bazel_acer\\\\xv6zejqw\\\\javalog.properties -Dcom.google.devtools.build.lib.util.LogHandlerQuerier.class=com.google.devtools.build.lib.util.SimpleLogHandler$HandlerQuerier -XX:-MaxFDLimit -Djava.library.path=C:\\\\Users\\\\Acer\\\\_bazel_Acer\\\\install\\\\c642351a638f19fdbbfb423e673c68ca\\\\embedded_tools\\\\jdk\\\\bin;C:\\\\Users\\\\Acer\\\\_bazel_Acer\\\\install\\\\c642351a638f19fdbbfb423e673c68ca\\\\embedded_tools\\\\jdk\\\\bin\\\\server;C:\\\\Users\\\\Acer\\\\_bazel_Acer\\\\install\\\\c642351a638f19fdbbfb423e673c68ca -Dfile.encoding=ISO-8859-1 -Dbazel.windows_unix_root=C:\\msys64\\usr\\bin\\bash.exe -jar C:\\\\Users\\\\Acer\\\\_bazel_Acer\\\\install\\\\c642351a638f19fdbbfb423e673c68ca\\\\A-server.jar --batch --connect_timeout_secs=30 --output_user_root=c:\\users\\acer\\_bazel_acer --install_base=c:\\users\\acer\\_bazel_acer\\install\\c642351a638f19fdbbfb423e673c68ca --install_md5=c642351a638f19fdbbfb423e673c68ca --output_base=c:\\users\\acer\\_bazel_acer\\xv6zejqw --workspace_directory=c:\\tensorflow \"--default_system_javabase=C:/Program Files/Android/Jdk/microsoft_dist_openjdk_1.8.0.25\" --deep_execroot --expand_configs_in_place --idle_server_tasks --noexperimental_oom_more_eagerly --experimental_oom_more_eagerly_threshold=100 --write_command_log --nowatchfs --nofatal_event_bus_exceptions --client_debug=false --host_jvm_args=-Dbazel.windows_unix_root=C:\\msys64\\usr\\bin\\bash.exe --product_name=Bazel --noincompatible_enable_execution_transition --option_sources=batch: version --startup_time=508 --command_wait_time=0 --extract_data_time=0 --restart_reason=new_options --binary_path=C:\\ProgramData\\chocolatey\\lib\\bazel\\bazel.exe --rc_source=client --default_override=0:common=--isatty=1 --default_override=0:common=--terminal_columns=80 \"--default_override=0:build=--python_path=C:/Program Files (x86)/Microsoft Visual Studio/Shared/Python36_86/python.exe\" --rc_source=c:\\tensorflow\\.bazelrc --rc_source=c:\\tensorflow\\.tf_configure.bazelrc --rc_source=nul --default_override=1:build:ios_armv7=--config=ios --default_override=1:build:ios_armv7=--cpu=ios_armv7 --default_override=1:build:rbe=--action_env=BAZEL_DO_NOT_DETECT_CPP_TOOLCHAIN=1 --default_override=1:build:rbe=--google_default_credentials --default_override=1:build:rbe=--bes_backend=buildeventservice.googleapis.com --default_override=1:build:rbe=--bes_results_url=https://source.cloud.google.com/results/invocations --default_override=1:build:rbe=--bes_timeout=600s --default_override=1:build:rbe=--define=EXECUTOR=remote --default_override=1:build:rbe=--distinct_host_configuration=false --default_override=1:build:rbe=--flaky_test_attempts=3 --default_override=1:build:rbe=--jobs=200 --default_override=1:build:rbe=--remote_executor=grpcs://remotebuildexecution.googleapis.com --default_override=1:build:rbe=--remote_timeout=3600 --default_override=1:build:rbe=--spawn_strategy=remote,worker,standalone,local --default_override=1:build:rbe=--remote_download_toplevel --default_override=1:build:rbe_cpu_linux=--config=rbe_linux --default_override=1:build:rbe_cpu_linux=--crosstool_top=//third_party/toolchains/preconfig/ubuntu16.04/gcc7_manylinux2010:toolchain --default_override=1:build:rbe_cpu_linux=--extra_toolchains=//third_party/toolchains/preconfig/ubuntu16.04/gcc7_manylinux2010:cc-toolchain-k8 --default_override=1:build:rbe_cpu_linux=--extra_execution_platforms=@org_tensorflow//third_party/toolchains:rbe_ubuntu16.04-manylinux2010 --default_override=1:build:rbe_cpu_linux=--host_platform=@org_tensorflow//third_party/toolchains:rbe_ubuntu16.04-manylinux2010 --default_override=1:build:rbe_cpu_linux=--platforms=@org_tensorflow//third_party/toolchains:rbe_ubuntu16.04-manylinux2010 --default_override=1:build:android=--crosstool_top=//external:android/crosstool --default_override=1:build:android=--host_crosstool_top=@bazel_tools//tools/cpp:toolchain --default_override=1:build:ios_arm64=--config=ios --default_override=1:build:ios_arm64=--cpu=ios_arm64 --default_override=1:build:android_arm=--config=android --default_override=1:build:android_arm=--cpu=armeabi-v7a --default_override=1:build:android_arm=--fat_apk_cpu=armeabi-v7a --default_override=1:build:avx_linux=--copt=-mavx --default_override=1:build:android_arm64=--config=android --default_override=1:build:android_arm64=--cpu=arm64-v8a --default_override=1:build:android_arm64=--fat_apk_cpu=arm64-v8a --default_override=1:build=--apple_platform_type=macos --default_override=1:build=--define --default_override=1:build=framework_shared_object=true --default_override=1:build=--define --default_override=1:build=open_source_build=true --default_override=1:build=--java_toolchain=//third_party/toolchains/java:tf_java_toolchain --default_override=1:build=--host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --default_override=1:build=--define=use_fast_cpp_protos=true --default_override=1:build=--define=allow_oversize_protos=true --default_override=1:build=--spawn_strategy=standalone --default_override=1:build=-c --default_override=1:build=opt --default_override=1:build=--announce_rc --default_override=1:build=--define=grpc_no_ares=true --default_override=1:build=--noincompatible_remove_legacy_whole_archive --default_override=1:build=--noincompatible_prohibit_aapt1 --default_override=1:build=--enable_platform_specific_config --default_override=1:build=--config=v2 --default_override=2:build=--action_env \"--default_override=2:build=PYTHON_BIN_PATH=C:/Program Files (x86)/Microsoft Visual Studio/Shared/Python36_86/python.exe\" --default_override=2:build=--action_env \"--default_override=2:build=PYTHON_LIB_PATH=C:/Program Files (x86)/Microsoft Visual Studio/Shared/Python36_86/lib/site-packages\" \"--default_override=2:build=--python_path=C:/Program Files (x86)/Microsoft Visual Studio/Shared/Python36_86/python.exe\" --default_override=2:build=--config=xla --default_override=2:build=--action_env --default_override=2:build=TF_CONFIGURE_IOS=0 --default_override=1:build:rbe_linux_py2=--config=rbe_linux --default_override=1:build:rbe_linux_py2=--repo_env=PYTHON_BIN_PATH=/usr/bin/python2 --default_override=1:build:rbe_linux_py2=--python_path=/usr/bin/python2 --default_override=1:build:rbe_linux_py2=--repo_env=TF_PYTHON_CONFIG_REPO=@org_tensorflow//third_party/toolchains/preconfig/ubuntu16.04/py --default_override=1:build:linux=--copt=-w --default_override=1:build:linux=--define=PREFIX=/usr --default_override=1:build:linux=--define=LIBDIR=$(PREFIX)/lib --default_override=1:build:linux=--define=INCLUDEDIR=$(PREFIX)/include --default_override=1:build:linux=--cxxopt=-std=c++14 --default_override=1:build:linux=--host_cxxopt=-std=c++14 --default_override=1:build:linux=--config=dynamic_kernels --default_override=1:test:rbe_linux_cuda_base=--test_env=LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64 --default_override=1:build:avx2_linux=--copt=-mavx2 --default_override=1:build:android_x86=--config=android --default_override=1:build:android_x86=--cpu=x86 --default_override=1:build:android_x86=--fat_apk_cpu=x86 --default_override=1:build:dbg=--config=opt --default_override=1:build:dbg=-c --default_override=1:build:dbg=dbg --default_override=1:build:dbg=--cxxopt --default_override=1:build:dbg=-DTF_LITE_DISABLE_X86_NEON --default_override=1:build:android_x86_64=--config=android --default_override=1:build:android_x86_64=--cpu=x86_64 --default_override=1:build:android_x86_64=--fat_apk_cpu=x86_64 --default_override=1:build:rbe_win_py38=--config=rbe --default_override=1:build:rbe_win_py38=--repo_env=PYTHON_BIN_PATH=C:\\Python38\\python.exe --default_override=1:build:rbe_win_py38=--repo_env=PYTHON_LIB_PATH=C:\\Python38\\lib\\site-packages --default_override=1:build:rbe_win_py38=--repo_env=TF_PYTHON_CONFIG_REPO=@org_tensorflow//third_party/toolchains/preconfig/win_1803/py38 --default_override=1:build:rbe_win_py38=--python_path=C:\\Python38\\python.exe --default_override=1:build:ios=--apple_platform_type=ios --default_override=1:build:ios=--apple_bitcode=embedded --default_override=1:build:ios=--copt=-fembed-bitcode --default_override=1:build:ios=--copt=-Wno-c++11-narrowing --default_override=1:build:ios_i386=--config=ios --default_override=1:build:ios_i386=--cpu=ios_i386 --default_override=1:build:windows=--copt=/w --default_override=1:build:windows=--copt=/D_USE_MATH_DEFINES --default_override=1:build:windows=--host_copt=/D_USE_MATH_DEFINES --default_override=1:build:windows=--cxxopt=/std:c++14 --default_override=1:build:windows=--host_cxxopt=/std:c++14 --default_override=1:build:windows=--config=monolithic --default_override=1:build:windows=--copt=-DWIN32_LEAN_AND_MEAN --default_override=1:build:windows=--host_copt=-DWIN32_LEAN_AND_MEAN --default_override=1:build:windows=--copt=-DNOGDI --default_override=1:build:windows=--host_copt=-DNOGDI --default_override=1:build:windows=--linkopt=/DEBUG --default_override=1:build:windows=--host_linkopt=/DEBUG --default_override=1:build:windows=--linkopt=/OPT:REF --default_override=1:build:windows=--host_linkopt=/OPT:REF --default_override=1:build:windows=--linkopt=/OPT:ICF --default_override=1:build:windows=--host_linkopt=/OPT:ICF --default_override=1:build:windows=--experimental_strict_action_env=true --default_override=1:build:windows=--verbose_failures --default_override=1:build:windows=--distinct_host_configuration=false --default_override=1:build:ios_x86_64=--config=ios --default_override=1:build:ios_x86_64=--cpu=ios_x86_64 --default_override=1:common=--experimental_repo_remote_exec --default_override=1:build:sycl=--crosstool_top=@local_config_sycl//crosstool:toolchain --default_override=1:build:sycl=--define=using_sycl=true --default_override=1:build:sycl=--action_env --default_override=1:build:sycl=TF_NEED_OPENCL_SYCL=1 --default_override=1:build:ios_fat=--config=ios --default_override=1:build:ios_fat=--ios_multi_cpus=armv7,arm64,i386,x86_64 --default_override=1:build:monolithic=--define --default_override=1:build:monolithic=framework_shared_object=false --default_override=1:test=--define --default_override=1:test=open_source_build=true --default_override=1:test=--config=v2 --default_override=2:test=--flaky_test_attempts=3 --default_override=2:test=--test_size_filters=small,medium --default_override=1:build:mkl=--define=build_with_mkl=true --default_override=1:build:mkl=--define=enable_mkl=true --default_override=1:build:mkl=--define=tensorflow_mkldnn_contraction_kernel=0 --default_override=1:build:mkl=--define=build_with_mkl_dnn_v1_only=true --default_override=1:build:mkl=-c --default_override=1:build:mkl=opt --default_override=1:build:rbe_win_py37=--config=rbe --default_override=1:build:rbe_win_py37=--repo_env=TF_PYTHON_CONFIG_REPO=@windows_py37_config_python --default_override=1:build:rbe_win_py37=--python_path=C:\\Python37\\python.exe --default_override=1:build:using_cuda=--define=using_cuda=true --default_override=1:build:using_cuda=--action_env --default_override=1:build:using_cuda=TF_NEED_CUDA=1 --default_override=1:build:using_cuda=--crosstool_top=@local_config_cuda//crosstool:toolchain --default_override=1:build:ngraph=--define=with_ngraph_support=true --default_override=1:test:rbe=--test_env=USER=anon --default_override=1:build:cuda=--config=using_cuda --default_override=1:build:cuda=--define=using_cuda_nvcc=true --default_override=1:build:native_arch_linux=--copt=-march=native --default_override=1:build:numa=--define=with_numa_support=true --default_override=1:build:cuda_clang=--config=using_cuda --default_override=1:build:cuda_clang=--define=using_cuda_clang=true --default_override=1:build:cuda_clang=--define=using_clang=true --default_override=1:build:cuda_clang=--action_env --default_override=1:build:cuda_clang=TF_CUDA_CLANG=1 --default_override=1:build:tensorrt=--action_env --default_override=1:build:tensorrt=TF_NEED_TENSORRT=1 --default_override=1:build:rocm=--crosstool_top=@local_config_rocm//crosstool:toolchain --default_override=1:build:rocm=--define=using_rocm=true --default_override=1:build:rocm=--define=using_rocm_hipcc=true --default_override=1:build:rocm=--action_env --default_override=1:build:rocm=TF_NEED_ROCM=1 --default_override=1:build:sycl_nodouble=--config=sycl --default_override=1:build:sycl_nodouble=--cxxopt --default_override=1:build:sycl_nodouble=-DTENSORFLOW_SYCL_NO_DOUBLE --default_override=1:build:sycl_nodouble=--config=sycl --default_override=1:build:sycl_nodouble=--config=sycl --default_override=1:build:v1=--define=tf_api_version=1 --default_override=1:build:v1=--action_env=TF2_BEHAVIOR=0 --default_override=1:build:sycl_asan=--copt --default_override=1:build:sycl_asan=-fno-omit-frame-pointer --default_override=1:build:sycl_asan=--copt --default_override=1:build:sycl_asan=-fsanitize-coverage=3 --default_override=1:build:sycl_asan=--copt --default_override=1:build:sycl_asan=-DGPR_NO_DIRECT_SYSCALLS --default_override=1:build:sycl_asan=--linkopt --default_override=1:build:sycl_asan=-fPIC --default_override=1:build:sycl_asan=--linkopt --default_override=1:build:sycl_asan=-fsanitize=address --default_override=1:build:sycl_trisycl=--define=using_trisycl=true --default_override=1:build:noaws=--define=no_aws_support=true --default_override=1:build:rbe_linux_cuda_nvcc=--config=rbe_linux_cuda_base --default_override=1:build:rbe_linux_cuda_nvcc=--crosstool_top=@ubuntu16.04-py3-gcc7_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_cuda//crosstool:toolchain --default_override=1:build:rbe_linux_cuda_nvcc=--extra_toolchains=@ubuntu16.04-py3-gcc7_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_cuda//crosstool:toolchain-linux-x86_64 --default_override=1:build:rbe_linux_cuda_nvcc=--extra_execution_platforms=@ubuntu16.04-py3-gcc7_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_platform//:platform --default_override=1:build:rbe_linux_cuda_nvcc=--host_platform=@ubuntu16.04-py3-gcc7_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_platform//:platform --default_override=1:build:rbe_linux_cuda_nvcc=--platforms=@ubuntu16.04-py3-gcc7_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_platform//:platform --default_override=1:build:rbe_linux_cuda_nvcc=--repo_env=TF_CUDA_CONFIG_REPO=@ubuntu16.04-py3-gcc7_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_cuda --default_override=1:build:rbe_linux_cuda_nvcc=--repo_env=TF_TENSORRT_CONFIG_REPO=@ubuntu16.04-py3-gcc7_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_tensorrt --default_override=1:build:rbe_linux_cuda_nvcc=--repo_env=TF_NCCL_CONFIG_REPO=@ubuntu16.04-py3-gcc7_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_nccl --default_override=1:build:rbe_linux_cuda_nvcc=--define=using_cuda_nvcc=true --default_override=1:build:nogcp=--define=no_gcp_support=true --default_override=1:build:nohdfs=--define=no_hdfs_support=true --default_override=1:build:nonccl=--define=no_nccl_support=true --default_override=1:build:dynamic_kernels=--define=dynamic_loaded_kernels=true --default_override=1:build:dynamic_kernels=--copt=-DAUTOLOAD_DYNAMIC_KERNELS --default_override=1:build:c++17=--cxxopt=-std=c++1z --default_override=1:build:c++17=--cxxopt=-stdlib=libc++ --default_override=1:build:c++1z=--config=c++17 --default_override=1:build:macos=--copt=-w --default_override=1:build:macos=--define=PREFIX=/usr --default_override=1:build:macos=--define=LIBDIR=$(PREFIX)/lib --default_override=1:build:macos=--define=INCLUDEDIR=$(PREFIX)/include --default_override=1:build:macos=--cxxopt=-std=c++14 --default_override=1:build:macos=--host_cxxopt=-std=c++14 --default_override=1:build:short_logs=--output_filter=DONT_MATCH_ANYTHING --default_override=1:common:tensorflow_testing_rbe_linux=--remote_instance_name=projects/tensorflow-testing/instances/default_instance --default_override=1:build:avx_win=--copt=/arch=AVX --default_override=1:build:avx2_win=--copt=/arch=AVX2 --default_override=1:build:rbe_linux=--config=rbe --default_override=1:build:rbe_linux=--action_env=PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/go/bin --default_override=1:build:rbe_linux=--host_javabase=@bazel_toolchains//configs/ubuntu16_04_clang/1.1:jdk8 --default_override=1:build:rbe_linux=--javabase=@bazel_toolchains//configs/ubuntu16_04_clang/1.1:jdk8 --default_override=1:build:rbe_linux=--host_java_toolchain=@bazel_tools//tools/jdk:toolchain_hostjdk8 --default_override=1:build:rbe_linux=--java_toolchain=@bazel_tools//tools/jdk:toolchain_hostjdk8 --default_override=1:build:rbe_linux=--config=xla --default_override=1:build:rbe_linux=--config=avx_linux --default_override=1:build:rbe_linux=--config=short_logs --default_override=1:build:rbe_linux=--linkopt=-lrt --default_override=1:build:rbe_linux=--linkopt=-lm --default_override=1:build:v2=--define=tf_api_version=2 --default_override=1:build:v2=--action_env=TF2_BEHAVIOR=1 --default_override=1:build:xla=--action_env=TF_ENABLE_XLA=1 --default_override=1:build:xla=--define=with_xla_support=true --default_override=1:build:rbe_linux_cuda_base=--config=rbe_linux --default_override=1:build:rbe_linux_cuda_base=--repo_env=TF_NEED_TENSORRT=1 --default_override=1:build:rbe_linux_cuda_base=--repo_env=TF_CUDA_VERSION=10 --default_override=1:build:rbe_linux_cuda_base=--repo_env=TF_CUDNN_VERSION=7 --default_override=1:build:rbe_linux_cuda_base=--repo_env=REMOTE_GPU_TESTING=1 --default_override=1:build:rbe_linux_cuda_base=--repo_env=TF_NEED_CUDA=1 --default_override=1:test:rbe_linux_cuda_nvcc=--config=rbe_linux_cuda_base --default_override=1:build:rbe_linux_py3=--config=rbe_linux --default_override=1:build:rbe_linux_py3=--python_path=/usr/bin/python3 --default_override=1:build:rbe_linux_py3=--repo_env=TF_PYTHON_CONFIG_REPO=@ubuntu16.04-manylinux2010-py3_config_python --default_override=1:build:rbe_linux_cuda_clang=--config=rbe_linux_cuda_base --default_override=1:build:rbe_linux_cuda_clang=--crosstool_top=@ubuntu16.04-py3-clang_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_cuda//crosstool:toolchain --default_override=1:build:rbe_linux_cuda_clang=--extra_toolchains=@ubuntu16.04-py3-clang_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_cuda//crosstool:toolchain-linux-x86_64 --default_override=1:build:rbe_linux_cuda_clang=--extra_execution_platforms=@ubuntu16.04-py3-clang_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_platform//:platform --default_override=1:build:rbe_linux_cuda_clang=--host_platform=@ubuntu16.04-py3-clang_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_platform//:platform --default_override=1:build:rbe_linux_cuda_clang=--platforms=@ubuntu16.04-py3-clang_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_platform//:platform --default_override=1:build:rbe_linux_cuda_clang=--repo_env=TF_CUDA_CONFIG_REPO=@ubuntu16.04-py3-clang_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_cuda --default_override=1:build:rbe_linux_cuda_clang=--repo_env=TF_TENSORRT_CONFIG_REPO=@ubuntu16.04-py3-clang_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_tensorrt --default_override=1:build:rbe_linux_cuda_clang=--repo_env=TF_NCCL_CONFIG_REPO=@ubuntu16.04-py3-clang_manylinux2010-cuda10.1-cudnn7-tensorrt6.0_config_nccl --default_override=1:build:rbe_linux_cuda_clang=--define=using_cuda_clang=true --default_override=1:test:rbe_linux_cuda_clang=--config=rbe_linux_cuda_base --default_override=1:common:rbe_gpu_linux=--config=rbe_linux_cuda_nvcc --default_override=1:build:rbe_win=--config=rbe --default_override=1:build:rbe_win=--crosstool_top=@org_tensorflow//third_party/toolchains/preconfig/win/bazel_211:toolchain --default_override=1:build:rbe_win=--extra_toolchains=@org_tensorflow//third_party/toolchains/preconfig/win/bazel_211:cc-toolchain-x64_windows --default_override=1:build:rbe_win=--host_javabase=@org_tensorflow//third_party/toolchains/preconfig/win:windows_jdk8 --default_override=1:build:rbe_win=--javabase=@org_tensorflow//third_party/toolchains/preconfig/win:windows_jdk8 --default_override=1:build:rbe_win=--extra_execution_platforms=@org_tensorflow//third_party/toolchains/preconfig/win:rbe_windows_ltsc2019 --default_override=1:build:rbe_win=--host_platform=@org_tensorflow//third_party/toolchains/preconfig/win:rbe_windows_ltsc2019 --default_override=1:build:rbe_win=--platforms=@org_tensorflow//third_party/toolchains/preconfig/win:rbe_windows_ltsc2019 --default_override=1:build:rbe_win=--shell_executable=C:\\tools\\msys64\\usr\\bin\\bash.exe --default_override=1:build:rbe_win=--define=override_eigen_strong_inline=true --default_override=1:build:rbe_win=--jobs=500 --default_override=1:build:tensorflow_testing_rbe=--project_id=tensorflow-testing --default_override=1:build:tensorflow_testing_rbe_linux=--config=tensorflow_testing_rbe --default_override=1:build:tensorflow_testing_rbe_linux=--config=rbe --default_override=1:build:tensorflow_testing_rbe_linux=--config=rbe_linux --default_override=1:common:tensorflow_testing_rbe_win=--remote_instance_name=projects/tensorflow-testing/instances/windows --default_override=1:build:tensorflow_testing_rbe_win=--config=tensorflow_testing_rbe --default_override=2:build:opt=--copt=/arch:AVX --default_override=2:build:opt=--define --default_override=2:build:opt=with_default_optimizations=true --default_override=2:test:v1=--test_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu,-oss_serial --default_override=2:test:v1=--build_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu --default_override=2:test:v2=--test_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu,-oss_serial,-v1only --default_override=2:test:v2=--build_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu,-v1only --client_env=ALLUSERSPROFILE=C:\\ProgramData --client_env=APPDATA=C:\\Users\\Acer\\AppData\\Roaming \"--client_env=bazel_vc=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\" \"--client_env=bazel_vs=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\" --client_env=bazel_winsdk_full_version=10.0.18362.1 --client_env=ChocolateyInstall=C:\\ProgramData\\chocolatey --client_env=ChocolateyLastPathUpdate=132307587054369432 --client_env=CommandPromptType=Native \"--client_env=CommonProgramFiles=C:\\Program Files\\Common Files\" \"--client_env=CommonProgramW6432=C:\\Program Files\\Common Files\" --client_env=COMPUTERNAME=LAPTOP-AZANES --client_env=ComSpec=C:\\WINDOWS\\system32\\cmd.exe --client_env=CUDA_PATH=C:\\tensorflow1\\models\\research\\slim \"--client_env=CUDA_PATH_V10_2=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\" --client_env=CUDA_PATH_V9_0=C:\\tensorflow1\\models\\research\\slim \"--client_env=DevEnvDir=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\\\\" --client_env=DriverData=C:\\Windows\\System32\\Drivers\\DriverData \"--client_env=ExtensionSdkDir=C:\\Program Files (x86)\\Microsoft SDKs\\Windows Kits\\10\\ExtensionSDKs\" --client_env=Framework40Version=v4.0 --client_env=FrameworkDir=C:\\WINDOWS\\Microsoft.NET\\Framework\\ --client_env=FrameworkDIR32=C:\\WINDOWS\\Microsoft.NET\\Framework\\ --client_env=FrameworkVersion=v4.0.30319 --client_env=FrameworkVersion32=v4.0.30319 \"--client_env=FSHARPINSTALLDIR=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\\\\" --client_env=HOMEDRIVE=C: --client_env=HOMEPATH=\\Users\\Acer \"--client_env=INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\" \"--client_env=JAVA_HOME=C:\\Program Files\\Android\\Jdk\\microsoft_dist_openjdk_1.8.0.25\" \"--client_env=LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\ATLMFC\\lib\\x86;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\lib\\x86;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x86;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x86;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x86;\" \"--client_env=LIBPATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\ATLMFC\\lib\\x86;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\lib\\x86;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\lib\\x86\\store\\references;C:\\Program Files (x86)\\Windows Kits\\10\\UnionMetadata\\10.0.18362.0;C:\\Program Files (x86)\\Windows Kits\\10\\References\\10.0.18362.0;C:\\WINDOWS\\Microsoft.NET\\Framework\\v4.0.30319;\" --client_env=LOCALAPPDATA=C:\\Users\\Acer\\AppData\\Local --client_env=LOGONSERVER=\\\\LAPTOP-AZANES \"--client_env=NETFXSDKDir=C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\\\\" --client_env=NUMBER_OF_PROCESSORS=4 \"--client_env=NVCUDASAMPLES10_2_ROOT=C:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v10.2\" --client_env=NVCUDASAMPLES9_0_ROOT=C:\\tensorflow1\\models\\research\\slim --client_env=NVCUDASAMPLES_ROOT=C:\\tensorflow1\\models\\research\\slim \"--client_env=NVTOOLSEXT_PATH=C:\\Program Files\\NVIDIA Corporation\\NvToolsExt\\\\\" --client_env=OneDrive=C:\\Users\\Acer\\OneDrive --client_env=OS=Windows_NT \"--client_env=PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\bin\\HostX86\\x86;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x86;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\\\MSBuild\\Current\\Bin;C:\\WINDOWS\\Microsoft.NET\\Framework\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_86\\Scripts\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_86\\;C:\\tensorflow1\\models\\research\\slim\\bin;C:\\tensorflow1\\models\\research\\slim\\libnvvp;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\libnvvp;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\ProgramData\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Intel\\iCLS Client\\;C:\\Program Files\\Intel\\iCLS Client\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Git\\cmd;C:\\Program Files\\dotnet\\;C:\\Program Files\\Microsoft SQL Server\\130\\Tools\\Binn\\;C:\\Gradle\\gradle-6.1.1\\bin;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files (x86)\\AOMEI Backupper;C:\\Emgu\\emgu 3.2\\bin\\x64;C:\\Program Files\\MATLAB\\R2017a\\runtime\\win64;C:\\Program Files\\MATLAB\\R2017a\\bin;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2019.5.0\\;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\Program Files\\Calibre2\\;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\bazel3.0.exe;C:\\ProgramData\\chocolatey\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\Scripts;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python38\\Scripts\\;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python38\\;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python38-32\\Scripts\\;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python38-32\\;\\\"C:\\Users\\Acer\\AppData\\Local\\Microsoft\\WindowsApps; flutter\\bin'\\\";C:\\Program Files\\CMake\\bin;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python-3.6.10\\setup;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\;C:\\msys64\\usr\\bin;C:\\msys64\\usr\\bin\\bash.exe;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\bazel.exe;C:\\Program Files\\Git;C:\\msys64\\usr\\bin\\bash.sha256;C:\\msys64\\usr\\bin\\bash.sh;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\" --client_env=PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW --client_env=PROCESSOR_ARCHITECTURE=AMD64 \"--client_env=PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 78 Stepping 3, GenuineIntel\" --client_env=PROCESSOR_LEVEL=6 --client_env=PROCESSOR_REVISION=4e03 --client_env=ProgramData=C:\\ProgramData \"--client_env=ProgramFiles=C:\\Program Files\" \"--client_env=ProgramW6432=C:\\Program Files\" --client_env=PROMPT=$P$G \"--client_env=PSModulePath=C:\\Program Files\\WindowsPowerShell\\Modules;C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\Modules\" \"--client_env=PT7HOME=C:\\Program Files\\Cisco Packet Tracer 7.3.0\" --client_env=PUBLIC=C:\\Users\\Public --client_env=QT_DEVICE_PIXEL_RATIO=auto --client_env=SYSTEMDRIVE=C: --client_env=SYSTEMROOT=C:\\WINDOWS --client_env=TEMP=C:\\Users\\Acer\\AppData\\Local\\Temp --client_env=TMP=C:\\Users\\Acer\\AppData\\Local\\Temp --client_env=UCRTVersion=10.0.18362.0 \"--client_env=UniversalCRTSdkDir=C:\\Program Files (x86)\\Windows Kits\\10\\\\\" --client_env=USERDOMAIN=LAPTOP-AZANES --client_env=USERDOMAIN_ROAMINGPROFILE=LAPTOP-AZANES --client_env=USERNAME=Acer --client_env=USERPROFILE=C:\\Users\\Acer \"--client_env=VCIDEInstallDir=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\\\\" \"--client_env=VCINSTALLDIR=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\\\\" \"--client_env=VCToolsInstallDir=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.24.28314\\\\\" \"--client_env=VCToolsRedistDir=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Redist\\MSVC\\14.24.28127\\\\\" --client_env=VCToolsVersion=14.24.28314 --client_env=VisualStudioVersion=16.0 \"--client_env=VS140COMNTOOLS=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools\\\\\" \"--client_env=VS160COMNTOOLS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\\\\" --client_env=VSCMD_ARG_app_plat=Desktop --client_env=VSCMD_ARG_HOST_ARCH=x86 --client_env=VSCMD_ARG_TGT_ARCH=x86 --client_env=VSCMD_VER=16.4.5 \"--client_env=VSINSTALLDIR=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\\\\" --client_env=windir=C:\\WINDOWS \"--client_env=WindowsLibPath=C:\\Program Files (x86)\\Windows Kits\\10\\UnionMetadata\\10.0.18362.0;C:\\Program Files (x86)\\Windows Kits\\10\\References\\10.0.18362.0\" \"--client_env=WindowsSdkBinPath=C:\\Program Files (x86)\\Windows Kits\\10\\bin\\\\\" \"--client_env=WindowsSdkDir=C:\\Program Files (x86)\\Windows Kits\\10\\\\\" --client_env=WindowsSDKLibVersion=10.0.18362.0\\ \"--client_env=WindowsSdkVerBinPath=C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\\\\" --client_env=WindowsSDKVersion=10.0.18362.0\\ \"--client_env=WindowsSDK_ExecutablePath_x64=C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\\\\" \"--client_env=WindowsSDK_ExecutablePath_x86=C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\\\\" --client_env=__DOTNET_ADD_32BIT=1 --client_env=__DOTNET_PREFERRED_BITNESS=32 \"--client_env=__VSCMD_PREINIT_PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_86\\Scripts\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_86\\;C:\\tensorflow1\\models\\research\\slim\\bin;C:\\tensorflow1\\models\\research\\slim\\libnvvp;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\libnvvp;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\ProgramData\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Intel\\iCLS Client\\;C:\\Program Files\\Intel\\iCLS Client\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Git\\cmd;C:\\Program Files\\dotnet\\;C:\\Program Files\\Microsoft SQL Server\\130\\Tools\\Binn\\;C:\\Gradle\\gradle-6.1.1\\bin;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files (x86)\\AOMEI Backupper;C:\\Emgu\\emgu 3.2\\bin\\x64;C:\\Program Files\\MATLAB\\R2017a\\runtime\\win64;C:\\Program Files\\MATLAB\\R2017a\\bin;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2019.5.0\\;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\Program Files\\Calibre2\\;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\bazel3.0.exe;C:\\ProgramData\\chocolatey\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\Scripts;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python38\\Scripts\\;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python38\\;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python38-32\\Scripts\\;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python38-32\\;\\\"C:\\Users\\Acer\\AppData\\Local\\Microsoft\\WindowsApps; flutter\\bin'\\\";C:\\Program Files\\CMake\\bin;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python-3.6.10\\setup;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\;C:\\msys64\\usr\\bin;C:\\msys64\\usr\\bin\\bash.exe;C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\bazel.exe;C:\\Program Files\\Git;C:\\msys64\\usr\\bin\\bash.sha256;C:\\msys64\\usr\\bin\\bash.sh;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\" --client_env=BAZEL_SH=C:\\msys64\\usr\\bin\\bash.exe --client_cwd=c:\\tensorflow\r\nTraceback (most recent call last):\r\n  File \"./configure.py\", line 1553, in <module>\r\n    main()\r\n  File \"./configure.py\", line 1370, in main\r\n    _TF_MAX_BAZEL_VERSION)\r\n  File \"./configure.py\", line 485, in check_bazel_version\r\n    ['bazel', '--batch', '--bazelrc=/dev/null', 'version'])\r\n  File \"./configure.py\", line 161, in run_shell\r\n    output = subprocess.check_output(cmd, stderr=stderr)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_86\\lib\\subprocess.py\", line 356, in check_output\r\n    **kwargs).stdout\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_86\\lib\\subprocess.py\", line 438, in run\r\n    output=stdout, stderr=stderr)\r\nsubprocess.CalledProcessError: Command '['bazel', '--batch', '--bazelrc=/dev/null', 'version']' returned non-zero exit status 37.```\r\n", "That is not a TF issue, it's caused by Windows restrictions. You can try moving the code to a shorter path, for example.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38325\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38325\">No</a>\n"]}, {"number": 38324, "title": "Performance issue with cross compiled benchmark_model and label_img", "body": "**System information** \r\n- OS Platform and Distribution \r\n**Host** : Linux  4.15.0-96-generic #97-Ubuntu SMP Wed Apr 1 03:25:46 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n**Target**: Linux ubuntu 5.3.0-1019-raspberry4 #21-Ubuntu SMP Mon Feb 17 14:05:03 UTC 2020 aarch64 aarch64 aarch64 GNU/Linux\r\n\r\n- Mobile device : Raspberry Pi 4\r\nThe performance issue happens on mobile device:   Raspberry Pi 4\r\n\r\n- TensorFlow installed from: source, commit 9d2bdd0b244c759ca54c6f10f58c069ec2200452\r\nfollow the instructions in https://www.tensorflow.org/lite/guide/build_arm64 \r\n\r\n- GCC/Compiler version \r\n**Host**: gcc version 7.5.0 (Ubuntu/Linaro 7.5.0-3ubuntu1~18.04) Target: aarch64-linux-gnu\r\n**Target:** gcc version 9.2.1 20191008 (Ubuntu 9.2.1-9ubuntu2) \r\n\r\n**Describe the current behavior**\r\n\r\nWhen I run the benchmark_model or label_img applications,the inference time is longer in cross compiled application than native compile applications.\r\n\r\nSurprisingly, the time is greater in float point models. In quantized models there is not much difference.\r\n\r\nCompiler issue ??\r\n\r\nBenchmark | model | Native compiled | Cross compiled\r\n-- | -- | -- | --\r\nbenchmark_model | mobilenet v1 | 161564 | 195817\r\nbenchmark_model | mobilenet v1 quant | 95125.1 | 99856.7\r\nlabel_img | mobilenet v1 | 72.938 ms | 217.212 ms\r\nlabel_img | mobilenet v1 quant | 30.668 ms | 31.723 ms\r\n\r\n\r\n\r\n\r\n", "comments": ["Using the docker devel image I get the same results as cross compiling in Host", "Do you have the same issue whent built with ./tensorflow/lite/tools/make/build_rpi_lib.sh as guided at https://www.tensorflow.org/lite/guide/build_rpi?", "Terry,\r\ndo you have any idea on this issue?", "@hajuho Raspbian is a 32 bit platform.  https://www.tensorflow.org/lite/guide/build_rpi is a recipe to build over armv7/6 32 bit platform. I am using using Ubuntu 64 bits over armv8-a (aarch64) platform, Raspberry Pi 4. So, I am using https://www.tensorflow.org/lite/guide/build_arm64 recipe.\r\n\r\nI am using the same recipe (https://www.tensorflow.org/lite/guide/build_arm64) to build natively in RP4 and cross compile in a x86_64 Host.\r\n\r\n\r\n", "This is interesting.\r\n@jlz3008 which OS are you using for RPI4? I wonder which toolchain was used for native build.", "@terryheo . The OS in RPI4 is a ubuntu 64 bits. Please, see the first comment.\r\nI find that Tensorflow lite in 64 bits OS (ubuntu) have better preformance that 32 bits OS (raspbian)\r\n", "Did you use images from https://ubuntu.com/download/raspberry-pi ?", "Yes. @terryheo  Exactly ubuntu-19.10.1-preinstalled-server-arm64+raspi3.img.xz\r\nBut the problem is not in the target OS. The problem is that generated code from crosscompile has worse performance than native compile. So, I guess the problem is in crosscompile flags or generated code, not in target OS or target native toolchain.", "Thanks for the confirmation. I'll check what caused the difference. ", "@jlz3008 Could you please let us know if you still need help on this issue ?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38323, "title": "[r2.2:CherryPick] Create optimizer weights when loading model from HDF5", "body": null, "comments": ["For tracking purposes:\r\nPiperOrigin-RevId: 305295553\r\nChange-Id: Ib903c75791c330f68939054426616354d2c25983"]}, {"number": 38322, "title": "[INTEL MKL] Fixing build issue in two unit tests", "body": "This PR fixes a build issue caused by this commit https://github.com/tensorflow/tensorflow/commit/6c7129eae0250648d766b8601c793dbd464cbb17", "comments": ["@gbaned is there anything blocking this from being merged?"]}, {"number": 38321, "title": "Lambda layer as loss_function - Invalid Argument Error", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: AWS SageMaker with Tensorflow 2.1.0 and Python 3.6\r\n- TensorFlow version: 2.1.0\r\n- Python version: - Python 3.6\r\n- CUDA/cuDNN version: - GPU model and memory: Tesla K80\r\n\r\n**Describe the current behavior**\r\nI am trying to use Lambda layer as the last layer and to use its output for loss function. The below code is a dummy demo that I expected that the model should be compiled normally. However, it raises the InvalidArgumentError for loss.  The code is below or available at the following gist: https://gist.github.com/quocdat32461997/10358455066ccc76817b54d20613c1dd\r\n\r\n**Standalone code to reproduce the issue** \r\ndef loss_fn(args):\r\n        return K.constant(1, dtype = 'float32')\r\n\r\ninputs = Input(shape = (784,))\r\ndense1 = Dense(512, activation = 'relu')(inputs)\r\ndense2 = Dense(128, activation = 'relu')(dense1)\r\ndense3 = Dense(32, activation = 'relu')(dense2)\r\n\r\nclassification_output = Dense(10, activation = 'softmax')(dense3)\r\n\r\noutputs = Lambda(loss_fn, name = 'loss', output_shape = (1,))(classification_output)\r\nmodel = Model(inputs = inputs, outputs = outputs)\r\n\r\nmodel.compile(tensorflow.keras.optimizers.Adam(learning_rate = 0.01), loss = lambda y_true, y_pred: y_pred)\r\n\r\n**Other info / logs** \r\nTraceback (most recent call last):\r\n  File \"demo.py\", line 21, in <module>\r\n    model.compile(tensorflow.keras.optimizers.Adam(learning_rate = 0.01), loss = lambda y_true, y_pred: y_pred)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 446, in compile\r\n    self._compile_weights_loss_and_weighted_metrics()\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1592, in _compile_weights_loss_and_weighted_metrics\r\n    self.total_loss = self._prepare_total_loss(masks)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1652, in _prepare_total_loss\r\n    per_sample_losses = loss_fn.call(y_true, y_pred)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py\", line 220, in call\r\n    y_pred, y_true)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/ops/losses/util.py\", line 79, in squeeze_or_expand_dimensions\r\n    is_last_dim_1 = math_ops.equal(1, array_ops.shape(y_pred)[-1])\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\", line 898, in _slice_helper\r\n    name=name)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\", line 1064, in strided_slice\r\n    shrink_axis_mask=shrink_axis_mask)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 9535, in strided_slice\r\n    shrink_axis_mask=shrink_axis_mask, name=name)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\r\n    attrs=attr_protos, op_def=op_def)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 595, in _create_op_internal\r\n    compute_device)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1786, in __init__\r\n    control_input_ops)\r\n  File \"/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1622, in _create_c_op\r\n    raise ValueError(str(e))\r\nValueError: slice index -1 of dimension 0 out of bounds. for 'loss_1/loss_loss/strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <-1>, input[2] = <0>, input[3] = <1>.\r\n", "comments": ["Can you please try with latest TF version (`!pip install tensorflow==2.2-rc2`). I am not seeing any issue with latest TF version. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/ec32c11c11745f22176da26546118955/untitled21.ipynb). Thanks!", "It solves the problem. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38321\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38321\">No</a>\n"]}, {"number": 38320, "title": "TFLite Conversion: ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development. ", "body": "Hi I am trying to convert savemodel to tflite but get the below error info:\r\n\r\nValueError: This converter can only   convert a single ConcreteFunction. Converting multiple functions is under   development.\r\n\r\nHow to solve this problem? thanks.\r\n\r\n", "comments": ["@noticebo,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and the TensorFlow version you are using.\r\n\r\nAlso, could you please check [this comment](https://github.com/tensorflow/tensorflow/issues/34350#issuecomment-555304243) from a similar issue and let us know if it helps? Thanks!", "Hi. the TensorFlow version is: 2.2.0rc2.\r\nmodel: mobilenetedgetpu model https://storage.cloud.google.com/mobilenet_edgetpu/checkpoints/mobilenet_edgetpu_224_0.75.tgz\r\n\r\ncode:\r\nimport tensorflow as tf\r\n\r\nsaved_model_dir='./savemodel'\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.experimental_new_converter = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\nconverter.target_spec.supported_types = [tf.compat.v1.lite.constants.FLOAT]\r\n\r\ntflite_quant_model = converter.convert() ", "@noticebo I tried loading the saved_model and encountered errors. Can you please share the complete model contents. Please check the [gist](https://colab.research.google.com/gist/jvishnuvardhan/66290010d8ef03314cc4f9db762439e2/untitled75.ipynb) for errors. thanks!", "@jvishnuvardhan  hi did you transform checkpoint to savemodel? \r\n\r\nreference code from Internet:\r\n\r\nimport tensorflow as tf\r\nimport sys\r\n \r\ntrained_checkpoint_prefix = sys.argv[1]\r\nexport_dir = sys.argv[2]\r\ngraph = tf.Graph()\r\nconfig=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\r\nwith tf.compat.v1.Session(graph=graph, config=config) as sess:\r\n    # Restore from checkpoint\r\n    loader = tf.compat.v1.train.import_meta_graph(trained_checkpoint_prefix + '.meta')\r\n    loader.restore(sess, trained_checkpoint_prefix)\r\n \r\n    # Export checkpoint to SavedModel\r\n    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)\r\n    builder.add_meta_graph_and_variables(sess, [tf.saved_model.TRAINING, tf.saved_model.SERVING], strip_default_attrs=True)\r\n    builder.save()\r\n\r\noriginal link\uff1ahttps://blog.csdn.net/zmlovelx/java/article/details/100511406\r\n", "@noticebo @jvishnuvardhan  were you able to solve this issue ? \r\n\r\nI used the script provided above to convert ckpt to .pb model , however I still get the same error. \r\n\r\nAlso my `KeysView(_SignatureMap({}))` is empty when I try \r\n```\r\nsaved_model_obj = tf.saved_model.load(export_dir=saved_model_dir)\r\nprint(saved_model_obj.signatures.keys())\r\n```", "@miaout17  @jvishnuvardhan  \r\nany update on this ?  ", "Having same issue, any fixes?", "I met the same issue.\r\nSince the quantization in TF1.x is limited, \r\nCould I save saved_model with TF1.x and convert to TFlite with TF2.x?\r\nThanks for any comments!", "Could you please refer to this issu #34350, and similar issues and confirm this can be closed,#38320, [link](https://stackoverflow.com/questions/59032729/error-trying-to-conver-tf-model-into-tflite-model)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38320\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38320\">No</a>\n"]}, {"number": 38319, "title": "Keras model compiled with custom loss raises \"object has no attribute '__name__'\" error.", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device:\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: 10.1, 7.6\r\n- GPU model and memory: RTX 2080 Ti\r\n\r\n**Describe the current behavior**\r\nWhen trying to train a keras model compiled with a custom loss wrapped in a functools.partial, `model.fit` raises the following exception (full traceback is below):\r\n\r\n```\r\n/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:261 _get_loss_object\r\n        loss_name = loss.__name__\r\n\r\n    AttributeError: 'functools.partial' object has no attribute '__name__'\r\n```\r\n\r\nIf, on the other hand, the loss is passed as lambda, the function executes as expected.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n```\r\nfrom tensorflow import keras\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.datasets import mnist\r\nfrom functools import partial\r\n\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train = x_train[...,None] / 255 - 1\r\nx_test = x_test[...,None] / 255 - 1\r\ny_train = keras.utils.to_categorical(y_train)\r\ny_test = keras.utils.to_categorical(y_test)\r\nmodel = keras.models.Sequential(\r\n  [\r\n    keras.layers.Conv2D(6, (3,3), activation='relu'),\r\n    keras.layers.AveragePooling2D(),\r\n    keras.layers.Conv2D(16, (3,3), activation='relu'),\r\n    keras.layers.AveragePooling2D(),\r\n    keras.layers.Flatten(),\r\n    keras.layers.Dense(units=120, activation='relu'),\r\n    keras.layers.Dense(units=84, activation='relu'),\r\n    keras.layers.Dense(units=10, activation='softmax')\r\n  ]\r\n)\r\n\r\ndef dummy_loss(y,y2,a):\r\n  return y+y2\r\n\r\nmodel.compile(\r\n  loss=partial(dummy_loss, a=2),\r\n  #loss=lambda v1, v2 : dummy_loss(v1,v2,4),\r\n  optimizer=keras.optimizers.Adam(), metrics={'output_1':'accuracy'})\r\nmodel.train_on_batch(x_train[:2,...], y_train[:2,...]) # error here\r\n```\r\n\r\n**Other info / logs** \r\n\r\nThe error seems to come from [this line](https://github.com/tensorflow/tensorflow/blob/33c47b42e04d11622a01ea279ad26e7c3c02a687/tensorflow/python/keras/engine/compile_utils.py#L261), which assumes the existence of an attribute `__name__` on any object passed by the user. The example with lambda works because lambdas have a default `__name__` value `<lambda>`, while `partial`s (and generic callables) do not.\r\n\r\nFull traceback of the exception:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1285, in train_on_batch\r\n    logs = train_function(iterator)\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 627, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 506, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2446, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 441, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 968, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nAttributeError: in user code:\r\n\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:505 train_function  *\r\n        outputs = self.distribute_strategy.run(\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:467 train_step  **\r\n        y, y_pred, sample_weight, regularization_losses=self.losses)\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:187 __call__\r\n        self._build(y_pred)\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:140 _build\r\n        self._losses = nest.map_structure(self._get_loss_object, self._losses)\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/util/nest.py:617 map_structure\r\n        structure[0], [func(*x) for x in entries],\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/util/nest.py:617 <listcomp>\r\n        structure[0], [func(*x) for x in entries],\r\n    /home/slr/anaconda3/envs/tf_rc/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:261 _get_loss_object\r\n        loss_name = loss.__name__\r\n\r\n    AttributeError: 'functools.partial' object has no attribute '__name__'\r\n```", "comments": ["@GPhilo, I think you want to use custom loss with additional attribute. To define such type of loss you have to define loss function like this.\r\n```\r\ndef dummy_loss(a=2):\r\n    def lossFunction(y,y2):    \r\n        return y+y2\r\n    return lossFunction\r\n```\r\nLink of full code is [here](https://gist.github.com/khimraj/d4eced88749f5a51b67130e29ca37ecd).", "@khimraj Thanks for the fast reply.\r\nHow is this different from using a `partial` or a functor object?", "Was able to replicate the issue with Tf 2.2.rc2.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/5e7b66ff475cc270ecacb0b73c79c3e3/untitled496.ipynb). Thanks!", "@GPhilo I have updated custom_loss function. After updating the custom_loss, code runs without any issue. Can you please check and let us know whether it resolved for you or not. [Here](https://colab.research.google.com/gist/jvishnuvardhan/790cd2b42ff6c2b2d9bc5c3ff4b52752/untitled68.ipynb) is the gist for you. Thanks!", "@jvishnuvardhan The rewritten custom_loss indeed works, however according to the documentation of [`tf.keras.Model.compile`](https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=nightly#compile) (both nightly and stable versions), `loss` should accept \"any callable with the signature loss = fn(y_true, y_pred)\". The line linked in the issue's \"other info\" section above effectively goes against the documentation, restricting valid values of the `loss` parameter to objects with a `__name__` attribute.", "Hi, I am also facing a similar issue, below is my code \r\n\r\ncode to reproduce the issue\r\n\r\n\r\n    import numpy as np\r\n    import matplotlib.pyplot as plt\r\n    import tensorflow.keras.backend as K\r\n    import tensorflow as tf\r\n    from sklearn import metrics as skm\r\n    import json\r\n    from utils.training import focal_loss\r\n\r\n    class FocalLoss(object):\r\n        def __init__(self, num_class, num_sub_catg_class, batch_size, input_shape, lambda_conf=100.0, lambda_offsets=1.0, class_weights=1.0):\r\n            self.batch_size = batch_size\r\n            self.num_class = num_class\r\n            self.num_sub_catg_class = num_sub_catg_class\r\n            self.lambda_conf = lambda_conf\r\n            self.lambda_offsets = lambda_offsets\r\n            self.class_weights = class_weights\r\n            self.num_rows, self.num_cols = input_shape[:2]\r\n\r\n        def __call__(self, y_true, y_pred, sample_weight=None):\r\n            \r\n            num_rows, num_cols = self.num_rows, self.num_cols\r\n            self.class_mask_tensor, self.class_sub_catg_mask_tensor = 1.0, 1.0\r\n            if sample_weight is not None:\r\n                print(\"Sample weight provided\")\r\n                sample_weight = K.cast(sample_weight, K.floatx())\r\n                self.class_mask_tensor = sample_weight[:, :num_rows*num_cols]\r\n                self.class_sub_catg_mask_tensor = sample_weight[:, num_rows*num_cols:2*num_rows*num_cols]\r\n\r\n            class_y_true = y_true[:, :, :, :self.num_class]\r\n            sub_catg_class_y_true = y_true[:, :, :, self.num_class:self.num_class+self.num_sub_catg_class]\r\n\r\n            class_y_pred = y_pred[:, :, :, :self.num_class]\r\n            sub_catg_class_y_pred = y_pred[:, :, :, self.num_class:self.num_class+self.num_sub_catg_class]\r\n\r\n            class_y_true = tf.reshape(class_y_true, tf.stack([self.batch_size, num_rows*num_cols, self.num_class]))\r\n            class_y_pred = tf.reshape(class_y_pred, tf.stack([self.batch_size, num_rows*num_cols, self.num_class]))\r\n            class_loss = focal_loss(class_y_true, class_y_pred, mask=self.class_mask_tensor)\r\n\r\n            sub_catg_class_y_true = tf.reshape(sub_catg_class_y_true, tf.stack([self.batch_size, num_rows*num_cols, self.num_sub_catg_class]))\r\n            sub_catg_class_y_pred = tf.reshape(sub_catg_class_y_pred, tf.stack([self.batch_size, num_rows*num_cols, self.num_sub_catg_class]))\r\n            sub_catg_class_loss = focal_loss(sub_catg_class_y_true, sub_catg_class_y_pred, mask=self.class_sub_catg_mask_tensor)\r\n\r\n            class_loss = tf.reduce_mean(input_tensor=tf.squeeze(class_loss))\r\n            sub_catg_class_loss = tf.reduce_mean(input_tensor=tf.squeeze(sub_catg_class_loss))\r\n            total_loss = class_loss+sub_catg_class_loss\r\n            \r\n            return total_loss\r\n\r\n\r\nmy error:\r\n```\r\n/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:266 _get_loss_object\r\n        loss_name = loss.__name__\r\n\r\n    AttributeError: 'FocalLoss' object has no attribute '__name__'\r\n```\r\n\r\nThe reason I am writing a custom a class is that I would like to assign sample weights.\r\n\r\n\r\nMy solution - adding and setting reduction, and name parameter worked. Inherit tf.keras.losses.Loss class.\r\n\r\n\r\n\r\n```\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow.keras.backend as K\r\nimport tensorflow as tf\r\nfrom sklearn import metrics as skm\r\nimport json\r\nfrom utils.training import focal_loss\r\n\r\nclass FocalLoss(tf.keras.losses.Loss):\r\n\r\n    def __init__(self, num_class, num_sub_catg_class, global_batch_size, input_shape, reduction=tf.keras.losses.Reduction.AUTO, lambda_conf=100.0, lambda_offsets=1.0, class_weights=1.0, name='focal_loss'):\r\n        self.global_batch_size = global_batch_size\r\n        self.num_class = num_class\r\n        self.num_sub_catg_class = num_sub_catg_class\r\n        self.lambda_conf = lambda_conf\r\n        self.lambda_offsets = lambda_offsets\r\n        self.class_weights = class_weights\r\n        self.num_rows, self.num_cols = input_shape[:2]\r\n        self.name = name\r\n        self.reduction = reduction\r\n\r\n    def __call__(self, y_true, y_pred, sample_weight=None):\r\n        \r\n        num_rows, num_cols = self.num_rows, self.num_cols\r\n        self.class_mask_tensor, self.class_sub_catg_mask_tensor = 1.0, 1.0\r\n        if sample_weight is not None:\r\n            print(\"Sample weight provided\")\r\n            sample_weight = K.cast(sample_weight, K.floatx())\r\n            self.class_mask_tensor = sample_weight[:, :num_rows*num_cols]\r\n            self.class_sub_catg_mask_tensor = sample_weight[:, num_rows*num_cols:2*num_rows*num_cols]\r\n\r\n        class_y_true = y_true[:, :, :, :self.num_class]\r\n        sub_catg_class_y_true = y_true[:, :, :, self.num_class:self.num_class+self.num_sub_catg_class]\r\n\r\n        class_y_pred = y_pred[:, :, :, :self.num_class]\r\n        sub_catg_class_y_pred = y_pred[:, :, :, self.num_class:self.num_class+self.num_sub_catg_class]\r\n\r\n        class_y_true = tf.reshape(class_y_true, tf.stack([self.global_batch_size, num_rows*num_cols, self.num_class]))\r\n        class_y_pred = tf.reshape(class_y_pred, tf.stack([self.global_batch_size, num_rows*num_cols, self.num_class]))\r\n        class_loss = focal_loss(class_y_true, class_y_pred, mask=self.class_mask_tensor)\r\n\r\n        sub_catg_class_y_true = tf.reshape(sub_catg_class_y_true, tf.stack([self.global_batch_size, num_rows*num_cols, self.num_sub_catg_class]))\r\n        sub_catg_class_y_pred = tf.reshape(sub_catg_class_y_pred, tf.stack([self.global_batch_size, num_rows*num_cols, self.num_sub_catg_class]))\r\n        sub_catg_class_loss = focal_loss(sub_catg_class_y_true, sub_catg_class_y_pred, mask=self.class_sub_catg_mask_tensor)\r\n\r\n        mean_class_loss = tf.nn.compute_average_loss(tf.squeeze(class_loss), global_batch_size=self.global_batch_size)\r\n        mean_sub_catg_class_loss = tf.nn.compute_average_loss(tf.squeeze(sub_catg_class_loss), global_batch_size=self.global_batch_size)\r\n\r\n        total_loss = mean_class_loss+mean_sub_catg_class_loss\r\n        return total_loss\r\n```", "I can also reproduce this issue even when using a custom loss class that inherits from tf.Module.\r\n\r\nThe [documentation on custom losses](https://keras.io/api/losses/) state the following:\r\n\r\n> Any callable with the signature loss_fn(y_true, y_pred) that returns an array of losses (one of sample in the input batch) can be passed to compile() as a loss\r\n\r\nSo perhaps it should be updated instead?", "Got hte same error", "@GPhilo Looks like this was resolved. I have check with `tf-nightly` and I cannot reproduce the issue. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/a501e181c0dfea612d22b8ba71f0ed4d/untitled496.ipynb).\r\n\r\nCan you verify once and close the issue if this was resolved for you. Thanks!", "@AlexandreBourrieau Can you please open a new issue with a simple standalone code to reproduce the issue? Thanks!", "As mentionned by @madan-ram, I use the solution he say : \"My solution - adding and setting reduction, and name parameter worked. Inherit tf.keras.losses.Loss class.\" It works for me now.", "@jvishnuvardhan Thanks, I believe this has indeed been fixed, I'll close this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38319\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38319\">No</a>\n"]}, {"number": 38318, "title": "New project inquiries", "body": "Hello :) \r\n\r\nI am totally new at programming, and wanted some advice. \r\nI want to create a program using the google maps api. \r\n\r\nIs Python the adequate programming language to use? \r\n\r\nThanks in advance for your answer :) ", "comments": ["Hey inoxstasy, you are currently posting on a platform that is solely for issues related to the TensorFlow application and not at all meant for general programming questions like this. Try posting your question on https://www.reddit.com/r/learnprogramming/ or https://stackoverflow.com/. Good luck with your project.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nHence moving this to closed status."]}, {"number": 38317, "title": "Loss not changing for an adversarial example", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI am trying to port some of the examples from [this NIPS tutorial](https://adversarial-ml-tutorial.org/introduction/) to TensorFlow 2.x. I have been able to port some of them (from chapter 1). However, when creating the perturbation vector, the loss wouldn't change and I unable to figure out why. \r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nColab Notebook: https://colab.research.google.com/drive/14WEpzKW7IHV4M08QXoTLEUX4qzfSnTB-\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Changing the optimizer did the work. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38317\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38317\">No</a>\n"]}, {"number": 38316, "title": "ABSL clock.h undeclared identifier when building from source", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 2.x\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: chocolatey\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): LLVM\r\n- CUDA/cuDNN version: 10, 7\r\n- GPU model and memory: Quadro M5000M, 8192MB\r\n\r\n\r\n\r\n**Describe the problem**\r\nUnable to build because of an undeclared identifier in clock.h file from absl. This appears to be an issue with the dependencies for tensorflow.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nWhen running the configure script, errors appeared for versions of Bazel < 2.0.0 and also > 2.0.0. Hence Bazel 2.0.0 was installed. The configuration step contains the following output:\r\n\r\n```\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nYou have bazel 2.0.0 installed.\r\nPlease specify the location of python. [Default is C:\\Python36\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Python36\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Python36\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.0 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0/include\r\nFound cuDNN 7 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 5.2\r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]: /arch:AVX2\r\n\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y\r\nEigen strong inline overridden.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\n```\r\n\r\nSubsequently, build of the C++ API was attempted with `bazel build --config=opt --config=cuda //tensorflow:libtensorflow_cc.so`. However, this yielded the following error:\r\n\r\n```\r\n.\\tensorflow/core/platform/env.h(368): warning: overloaded virtual function \"tensorflow::Env::RegisterFileSystem\" is only partially overridden in class \"tensorflow::EnvWrapper\"\r\n\r\nexternal/com_google_absl\\absl/types/optional.h(428): warning: expression has no effect\r\n          detected during instantiation of \"const T &absl::lts_2020_02_25::optional<T>::operator*() const & [with T=stream_executor::dnn::AlgorithmDesc]\"\r\n.\\tensorflow/stream_executor/dnn.h(804): here\r\n\r\nexternal/com_google_absl\\absl/types/optional.h(428): warning: expression has no effect\r\n          detected during instantiation of \"const T &absl::lts_2020_02_25::optional<T>::operator*() const & [with T=size_t]\"\r\n.\\tensorflow/stream_executor/dnn.h(858): here\r\n\r\nexternal/com_google_absl\\absl/time/clock.h(70): error C2065: 'Duration': undeclared identifier\r\nexternal/com_google_absl\\absl/time/clock.h(70): error C2146: syntax error: missing ')' before identifier 'duration'\r\nexternal/com_google_absl\\absl/time/clock.h(70): error C2143: syntax error: missing ';' before '{'\r\nexternal/com_google_absl\\absl/time/clock.h(70): error C2447: '{': missing function header (old-style formal list?)\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nINFO: Elapsed time: 1231.090s, Critical Path: 124.55s\r\nINFO: 1539 processes: 1539 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nSome suggestions from other posts have been to change the version of Bazel. However, based on the error messages received, it appears that only Bazel 2.0.0 is suitable. Are there any suggestions on how to address this issue?\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Did not resolve this issue fully. I reverted to a previously tested build process, using TF 1.13.0 and building with Bazel 0.19.2. This build worked for me.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38316\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38316\">No</a>\n", "same problem \r\nbuild tf2.3.0 in windows10", "> same problem\r\n> build tf2.3.0 in windows10\r\n\r\n@KangolHsu \r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!\r\n"]}, {"number": 38315, "title": "install_tensorflow() error: Collecting package metadata (current_repodata.json): ...working... failed", "body": "**System information**\r\n- Windows 10 Pro:\r\n- TensorFlow installed from (source or binary): use install_tensorflow() in r\r\n- TensorFlow version:\r\n- Python version: Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]:: Anaconda\r\n- Installed using virtualenv? pip? conda?: in r version 3.6.0 \r\n- GPU model and memory: \r\nIntel(R) HD Graphics 620, \r\ntotal available graphics memory: 8259 MB\r\n\r\n\r\n\r\n**Describe the problem**\r\nno able to successfully install tensorflow in r. Have tried various ways, it always shows error as below. We will have training tomorrow. 15 out 18 are not able to install and have the similar errors as me. Thanks for your help!\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n![Untitled](https://user-images.githubusercontent.com/46570223/78681144-f7ca5b80-78b1-11ea-8596-5598b13086b0.png)\r\n\r\n\r\n", "comments": ["@HongHe0123, Follow the steps mentioned [here](https://tensorflow.rstudio.com/installation/). Thanks!", "The company blocked the website. Now the problem is solved. Thanks!", "Closing as resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38315\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38315\">No</a>\n"]}, {"number": 38314, "title": "Cherry-picks to fix TF serving", "body": "Since TF serving didn't cut their `r2.2` branch at the same time as TF's `r2.2` branch, we need a few cherrypicks to make sure both compile.\r\n\r\n1. Prefixing TensorFlow thread annotation macros with TF_.\r\nPiperOrigin-RevId: 299110761\r\nChange-Id: I66ecaa9d01dc441f091888bef3f24d220e9180c5\r\n\r\n1. Add aggregated cost dimensions to the CostGraph, typically used for load-balancing decisions.\r\nPiperOrigin-RevId: 299182048\r\nChange-Id: Ie9336b3f04c0bca21bcd6488da8d4be1889a451b", "comments": ["It was still WIP, sorry for this. I'll open a new PR with additional work", "I do prefer one PR per cherry-pick anyway, and that was already quite large\nto review.\n\nOn Tue, Apr 7, 2020 at 8:21 AM Mihai Maruseac <notifications@github.com>\nwrote:\n\n> It was still WIP, sorry for this. I'll open a new PR with additional work\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/38314#issuecomment-610450093>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRKVGJRUCQGPYFWVG2DRLNAHTANCNFSM4MDEGEUA>\n> .\n>\n\n\n-- \n - Alex\n", "I have same preferences. However, to test serving we needed a commit that included all the changes that needed to cherry-pick, before we land them (so we can remove those that are not actually needed)"]}, {"number": 38313, "title": "Keras mismatches outputs and targets", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\n\r\n- We build a keras model with outputs like `task_a_logits`, `task_a_probs`, `task_b_logits`, `task_b_probs`\r\n- We compile our model by passing a `loss` dict like `{\"task_a_logits\": ..., \"task_b_logits\": ...}` (Note that no loss is applied on the probabilities). All losses are applied on the logits.\r\n- We build a dataset that yields tuples like `(x, {\"task_a_logits\": ..., \"task_b_logits\": ...}`\r\n- To `keras.fit()`, we pass a dataset that yields targets for each task, also in a dict.\r\n\r\nThis works without eager execution, but using TF 2.0's defaults, keras gets confused because there are less targets and losses than outputs. [This patch](https://gist.github.com/georgwiese/57568ac518813b9d9f0e6785d8f707fa) fixes the issue.\r\n\r\nWith the original code and the example above, `loss_fns` and `targets` have two elements and `outs` have four. They get zipped together and then shapes mismatch: `logits and labels must be broadcastable: logits_size=[18,4] labels_size=[18,3]`\r\n\r\n**Describe the expected behavior**\r\n\r\nKeras matches outputs and targets correctly.\r\n\r\n**Standalone code to reproduce the issue** \r\nI provided a patch that points to the bug in the Keras source code.\r\n", "comments": ["@georgwiese \r\ncould you please provide with simple[complete] standalone code for us to replicate the issue", "@georgwiese\r\ncould you please update on the above comment", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38313\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38313\">No</a>\n"]}, {"number": 38312, "title": "Cannot convert lstm with \"stateful=True\" to tflite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Window 7\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (or github SHA if from source):2.2.0-rc0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\nmodel= tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Input(shape=(None, 32), batch_size=1,name='input'))\r\nmodel.add(tf.keras.layers.LSTM(256, return_sequences=True, stateful=True))\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['acc'])\r\nprint(model.input)\r\nprint(model_ctor.summary())\r\nprint(tf.__version__)\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\n```\r\n\r\n\r\n**Copy and paste the output here.\r\n\r\n```\r\nTensor(\"input_12:0\", shape=(1, None, 32), dtype=float32)\r\nModel: \"sequential_12\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nlstm_15 (LSTM)               (1, None, 256)            295936    \r\n=================================================================\r\nTotal params: 295,936\r\nTrainable params: 295,936\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nNone\r\n2.2.0-rc0\r\n\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    496         results = c_api.TF_GraphImportGraphDefWithResults(\r\n--> 497             graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\n    498         results = c_api_util.ScopedTFImportGraphDefResults(results)\r\n\r\nInvalidArgumentError: Input 0 of node sequential_13/lstm_16/AssignVariableOp was passed float from sequential_13/lstm_16/23648:0 incompatible with expected resource.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-26-c3e3cbbc4fe1> in <module>\r\n     10 converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,                                    tf.lite.OpsSet.SELECT_TF_OPS]\r\n     11 converter.experimental_new_converter = True\r\n---> 12 tflite_model = converter.convert()\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self)\r\n    462     frozen_func, graph_def = (\r\n    463         _convert_to_constants.convert_variables_to_constants_v2_as_graph(\r\n--> 464             self._funcs[0], lower_control_flow=False))\r\n    465     input_tensors = [\r\n    466         tensor for tensor in frozen_func.inputs\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\convert_to_constants.py in convert_variables_to_constants_v2_as_graph(func, lower_control_flow, aggressive_inlining)\r\n    705   graph_def, converted_inputs = _convert_variables_to_constants_v2_impl(\r\n    706       func, lower_control_flow, aggressive_inlining)\r\n--> 707   frozen_func = _construct_concrete_function(func, graph_def, converted_inputs)\r\n    708   return frozen_func, graph_def\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\convert_to_constants.py in _construct_concrete_function(func, output_graph_def, converted_input_indices)\r\n    404   new_func = wrap_function.function_from_graph_def(output_graph_def,\r\n    405                                                    new_input_names,\r\n--> 406                                                    new_output_names)\r\n    407 \r\n    408   # Manually propagate shape for input tensors where the shape is not correctly\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in function_from_graph_def(graph_def, inputs, outputs)\r\n    631     importer.import_graph_def(graph_def, name=\"\")\r\n    632 \r\n--> 633   wrapped_import = wrap_function(_imports_graph_def, [])\r\n    634   import_graph = wrapped_import.graph\r\n    635   return wrapped_import.prune(\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in wrap_function(fn, signature, name)\r\n    609           signature=signature,\r\n    610           add_control_dependencies=False,\r\n--> 611           collections={}),\r\n    612       variable_holder=holder,\r\n    613       signature=signature)\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    979         _, original_func = tf_decorator.unwrap(python_func)\r\n    980 \r\n--> 981       func_outputs = python_func(*func_args, **func_kwargs)\r\n    982 \r\n    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in __call__(self, *args, **kwargs)\r\n     84 \r\n     85   def __call__(self, *args, **kwargs):\r\n---> 86     return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)\r\n     87 \r\n     88   def call_with_variable_creator_scope(self, fn):\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in wrapped(*args, **kwargs)\r\n     90     def wrapped(*args, **kwargs):\r\n     91       with variable_scope.variable_creator_scope(self.variable_creator_scope):\r\n---> 92         return fn(*args, **kwargs)\r\n     93 \r\n     94     return wrapped\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in _imports_graph_def()\r\n    629 \r\n    630   def _imports_graph_def():\r\n--> 631     importer.import_graph_def(graph_def, name=\"\")\r\n    632 \r\n    633   wrapped_import = wrap_function(_imports_graph_def, [])\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py in new_func(*args, **kwargs)\r\n    505                 'in a future version' if date is None else ('after %s' % date),\r\n    506                 instructions)\r\n--> 507       return func(*args, **kwargs)\r\n    508 \r\n    509     doc = _add_deprecated_arg_notice_to_docstring(\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py in import_graph_def(***failed resolving arguments***)\r\n    403       return_elements=return_elements,\r\n    404       name=name,\r\n--> 405       producer_op_list=producer_op_list)\r\n    406 \r\n    407 \r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    499       except errors.InvalidArgumentError as e:\r\n    500         # Convert to ValueError for backwards compatibility.\r\n--> 501         raise ValueError(str(e))\r\n    502 \r\n    503     # Create _DefinedFunctions for any imported functions.\r\n\r\nValueError: Input 0 of node sequential_13/lstm_16/AssignVariableOp was passed float from sequential_13/lstm_16/23648:0 incompatible with expected resource.\r\n\r\n\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\n\r\nWhen I try to convert a lstm model with \"stateful=False\", it can convert success.But when I change stateful to True, it convert fail. I need lstm with stateful. How can I do?\r\n\r\n\r\n", "comments": ["I have tried on colab with TF version 2.2-rc0, 2.2-rc2 and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/494fcc18b48251ccacee56d75ab7f3f6/untitled20.ipynb). Thanks!", "We are tracking this bug with #37659. Thanks!", "@renjie-liu and @ashwinmurthy can offer further guidance.", "We are in the process of releasing support for Keras LSTM to TFlite conversion. Could you install the latest TF nightly and try the following?\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"keras_lstm\")\r\ntflite_model = converter.convert()\r\n\r\nThis assumes you have  a saved model corresponding to the TF Keras LSTM model via something like:\r\nmodel.save(\"keras_lstm\", save_format='tf', signatures=concrete_func)\r\n\r\nCould you try that and let us know if that works? We will be happy to help", "Also, please ensure TF v2 behavior is enabled:\r\n\r\nimport tensorflow.compat.v2 as tf\r\ntf.enable_v2_behavior()", "> \r\n> \r\n> We are in the process of releasing support for Keras LSTM to TFlite conversion. Could you install the latest TF nightly and try the following?\r\n> \r\n> converter = tf.lite.TFLiteConverter.from_saved_model(\"keras_lstm\")\r\n> tflite_model = converter.convert()\r\n> \r\n> This assumes you have a saved model corresponding to the TF Keras LSTM model via something like:\r\n> model.save(\"keras_lstm\", save_format='tf', signatures=concrete_func)\r\n> \r\n> Could you try that and let us know if that works? We will be happy to help\r\n\r\nHow to install the latest TF nightly?", "pip install tf-nightly", "> \r\n> \r\n> We are in the process of releasing support for Keras LSTM to TFlite conversion. Could you install the latest TF nightly and try the following?\r\n> \r\n> converter = tf.lite.TFLiteConverter.from_saved_model(\"keras_lstm\")\r\n> tflite_model = converter.convert()\r\n> \r\n> This assumes you have a saved model corresponding to the TF Keras LSTM model via something like:\r\n> model.save(\"keras_lstm\", save_format='tf', signatures=concrete_func)\r\n> \r\n> Could you try that and let us know if that works? We will be happy to help\r\n\r\n\r\n\r\nIt don't work either\r\n\r\n```\r\nimport tensorflow.compat.v2 as tf\r\ntf.enable_v2_behavior()\r\n\r\nmodel = tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Input(shape=(None, 32), batch_size=1,name='input'))\r\nmodel.add(tf.keras.layers.LSTM(256, return_sequences=True, stateful=True))\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['acc'])\r\nprint(model.input)\r\nprint(model.summary())\r\nmodel.save(\"D:\\keras_lstm\", save_format='tf')\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"D:\\keras_lstm\")\r\nprint(tf.__version__)\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\n```\r\n\r\n**Output:**\r\n\r\n```\r\nTensor(\"input_4:0\", shape=(1, None, 32), dtype=float32)\r\nModel: \"sequential_4\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nlstm_4 (LSTM)                (1, None, 256)            295936    \r\n=================================================================\r\nTotal params: 295,936\r\nTrainable params: 295,936\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nNone\r\nINFO:tensorflow:Assets written to: D:\\\u8bed\u97f3\u8bc6\u522b\\\u5ff5\u4f5b\u8ba1\u6570\\pb\\keras_lstm\\assets\r\n2.2.0-dev20200409\r\n\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    496         results = c_api.TF_GraphImportGraphDefWithResults(\r\n--> 497             graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\n    498         results = c_api_util.ScopedTFImportGraphDefResults(results)\r\n\r\nInvalidArgumentError: Input 0 of node sequential_4/lstm_4/AssignVariableOp was passed float from sequential_4/lstm_4/Read/ReadVariableOp/resource:0 incompatible with expected resource.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-6-b26f2fd1836d> in <module>\r\n     16                                        tf.lite.OpsSet.SELECT_TF_OPS]\r\n     17 converter.experimental_new_converter = True\r\n---> 18 tflite_model = converter.convert()\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self)\r\n    597     frozen_func, graph_def = (\r\n    598         _convert_to_constants.convert_variables_to_constants_v2_as_graph(\r\n--> 599             self._funcs[0], lower_control_flow=False))\r\n    600     self._graph_def = graph_def\r\n    601     input_tensors = [\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\convert_to_constants.py in convert_variables_to_constants_v2_as_graph(func, lower_control_flow, aggressive_inlining)\r\n    705   graph_def, converted_inputs = _convert_variables_to_constants_v2_impl(\r\n    706       func, lower_control_flow, aggressive_inlining)\r\n--> 707   frozen_func = _construct_concrete_function(func, graph_def, converted_inputs)\r\n    708   return frozen_func, graph_def\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\convert_to_constants.py in _construct_concrete_function(func, output_graph_def, converted_input_indices)\r\n    404   new_func = wrap_function.function_from_graph_def(output_graph_def,\r\n    405                                                    new_input_names,\r\n--> 406                                                    new_output_names)\r\n    407 \r\n    408   # Manually propagate shape for input tensors where the shape is not correctly\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in function_from_graph_def(graph_def, inputs, outputs)\r\n    631     importer.import_graph_def(graph_def, name=\"\")\r\n    632 \r\n--> 633   wrapped_import = wrap_function(_imports_graph_def, [])\r\n    634   import_graph = wrapped_import.graph\r\n    635   return wrapped_import.prune(\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in wrap_function(fn, signature, name)\r\n    609           signature=signature,\r\n    610           add_control_dependencies=False,\r\n--> 611           collections={}),\r\n    612       variable_holder=holder,\r\n    613       signature=signature)\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    979         _, original_func = tf_decorator.unwrap(python_func)\r\n    980 \r\n--> 981       func_outputs = python_func(*func_args, **func_kwargs)\r\n    982 \r\n    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in __call__(self, *args, **kwargs)\r\n     84 \r\n     85   def __call__(self, *args, **kwargs):\r\n---> 86     return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)\r\n     87 \r\n     88   def call_with_variable_creator_scope(self, fn):\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in wrapped(*args, **kwargs)\r\n     90     def wrapped(*args, **kwargs):\r\n     91       with variable_scope.variable_creator_scope(self.variable_creator_scope):\r\n---> 92         return fn(*args, **kwargs)\r\n     93 \r\n     94     return wrapped\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in _imports_graph_def()\r\n    629 \r\n    630   def _imports_graph_def():\r\n--> 631     importer.import_graph_def(graph_def, name=\"\")\r\n    632 \r\n    633   wrapped_import = wrap_function(_imports_graph_def, [])\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py in new_func(*args, **kwargs)\r\n    505                 'in a future version' if date is None else ('after %s' % date),\r\n    506                 instructions)\r\n--> 507       return func(*args, **kwargs)\r\n    508 \r\n    509     doc = _add_deprecated_arg_notice_to_docstring(\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py in import_graph_def(***failed resolving arguments***)\r\n    403       return_elements=return_elements,\r\n    404       name=name,\r\n--> 405       producer_op_list=producer_op_list)\r\n    406 \r\n    407 \r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    499       except errors.InvalidArgumentError as e:\r\n    500         # Convert to ValueError for backwards compatibility.\r\n--> 501         raise ValueError(str(e))\r\n    502 \r\n    503     # Create _DefinedFunctions for any imported functions.\r\n\r\nValueError: Input 0 of node sequential_4/lstm_4/AssignVariableOp was passed float from sequential_4/lstm_4/Read/ReadVariableOp/resource:0 incompatible with expected resource.\r\n\r\n```", "We still dont have support from from_keras_model, you need to use the from_saved_model API", "Looking at the output you shared, the \r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"D:\\keras_lstm\")\r\n\r\nseems to be successful. Since we print the tf version corresponding to:\r\nprint(tf.__version__)\r\n\r\nCan you remove below:\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\nand just verify the output of the converted tflite model from from_saved_model call?\r\n", "> \r\n> \r\n> Looking at the output you shared, the\r\n> converter = tf.lite.TFLiteConverter.from_saved_model(\"D:\\keras_lstm\")\r\n> \r\n> seems to be successful. Since we print the tf version corresponding to:\r\n> print(tf.**version**)\r\n> \r\n> Can you remove below:\r\n> converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n> \r\n> and just verify the output of the converted tflite model from from_saved_model call?\r\n\r\nI'm sorry I made a mistake.\r\nBut it also don't work.\r\n```\r\nimport tensorflow.compat.v2 as tf\r\ntf.enable_v2_behavior()\r\n\r\nmodel = tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Input(shape=(None, 32), batch_size=1,name='input'))\r\nmodel.add(tf.keras.layers.LSTM(256, return_sequences=True, stateful=True))\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['acc'])\r\nprint(model.input)\r\nprint(model.summary())\r\nmodel.save(\"D:\\keras_lstm\", save_format='tf')\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"D:\\keras_lstm\")\r\nprint(tf.__version__)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\n```\r\n\r\n```\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:993: UserWarning: The internal states of stateful RNN layers are not included in `layer.weights`. Please use `layer.states()` if you want to retrieve the internal states of the layer.\r\n  'The internal states of stateful RNN layers are not included in '\r\n\r\nTensor(\"input:0\", shape=(1, None, 32), dtype=float32)\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nlstm (LSTM)                  (1, None, 256)            295936    \r\n=================================================================\r\nTotal params: 295,936\r\nTrainable params: 295,936\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nNone\r\nINFO:tensorflow:Assets written to: D:\\keras_lstm\\assets\r\n2.2.0-dev20200409\r\n\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    496         results = c_api.TF_GraphImportGraphDefWithResults(\r\n--> 497             graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\n    498         results = c_api_util.ScopedTFImportGraphDefResults(results)\r\n\r\nInvalidArgumentError: Input 0 of node StatefulPartitionedCall/sequential/lstm/AssignVariableOp was passed float from Func/StatefulPartitionedCall/input/_2:0 incompatible with expected resource.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-1-d97b2d5a9af7> in <module>\r\n     15                                        tf.lite.OpsSet.SELECT_TF_OPS]\r\n     16 converter.experimental_new_converter = True\r\n---> 17 tflite_model = converter.convert()\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self)\r\n    597     frozen_func, graph_def = (\r\n    598         _convert_to_constants.convert_variables_to_constants_v2_as_graph(\r\n--> 599             self._funcs[0], lower_control_flow=False))\r\n    600     self._graph_def = graph_def\r\n    601     input_tensors = [\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\convert_to_constants.py in convert_variables_to_constants_v2_as_graph(func, lower_control_flow, aggressive_inlining)\r\n    705   graph_def, converted_inputs = _convert_variables_to_constants_v2_impl(\r\n    706       func, lower_control_flow, aggressive_inlining)\r\n--> 707   frozen_func = _construct_concrete_function(func, graph_def, converted_inputs)\r\n    708   return frozen_func, graph_def\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\convert_to_constants.py in _construct_concrete_function(func, output_graph_def, converted_input_indices)\r\n    404   new_func = wrap_function.function_from_graph_def(output_graph_def,\r\n    405                                                    new_input_names,\r\n--> 406                                                    new_output_names)\r\n    407 \r\n    408   # Manually propagate shape for input tensors where the shape is not correctly\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in function_from_graph_def(graph_def, inputs, outputs)\r\n    631     importer.import_graph_def(graph_def, name=\"\")\r\n    632 \r\n--> 633   wrapped_import = wrap_function(_imports_graph_def, [])\r\n    634   import_graph = wrapped_import.graph\r\n    635   return wrapped_import.prune(\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in wrap_function(fn, signature, name)\r\n    609           signature=signature,\r\n    610           add_control_dependencies=False,\r\n--> 611           collections={}),\r\n    612       variable_holder=holder,\r\n    613       signature=signature)\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    979         _, original_func = tf_decorator.unwrap(python_func)\r\n    980 \r\n--> 981       func_outputs = python_func(*func_args, **func_kwargs)\r\n    982 \r\n    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in __call__(self, *args, **kwargs)\r\n     84 \r\n     85   def __call__(self, *args, **kwargs):\r\n---> 86     return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)\r\n     87 \r\n     88   def call_with_variable_creator_scope(self, fn):\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in wrapped(*args, **kwargs)\r\n     90     def wrapped(*args, **kwargs):\r\n     91       with variable_scope.variable_creator_scope(self.variable_creator_scope):\r\n---> 92         return fn(*args, **kwargs)\r\n     93 \r\n     94     return wrapped\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py in _imports_graph_def()\r\n    629 \r\n    630   def _imports_graph_def():\r\n--> 631     importer.import_graph_def(graph_def, name=\"\")\r\n    632 \r\n    633   wrapped_import = wrap_function(_imports_graph_def, [])\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py in new_func(*args, **kwargs)\r\n    505                 'in a future version' if date is None else ('after %s' % date),\r\n    506                 instructions)\r\n--> 507       return func(*args, **kwargs)\r\n    508 \r\n    509     doc = _add_deprecated_arg_notice_to_docstring(\r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py in import_graph_def(***failed resolving arguments***)\r\n    403       return_elements=return_elements,\r\n    404       name=name,\r\n--> 405       producer_op_list=producer_op_list)\r\n    406 \r\n    407 \r\n\r\nc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    499       except errors.InvalidArgumentError as e:\r\n    500         # Convert to ValueError for backwards compatibility.\r\n--> 501         raise ValueError(str(e))\r\n    502 \r\n    503     # Create _DefinedFunctions for any imported functions.\r\n\r\nValueError: Input 0 of node StatefulPartitionedCall/sequential/lstm/AssignVariableOp was passed float from Func/StatefulPartitionedCall/input/_2:0 incompatible with expected resource.\r\n\r\n\r\n```", "We confirmed that there is an issue with using the stateful keras layer. We are investigating the fix.\r\n\r\nCan you try this without stateful? So, in TFLite the LSTM is always stateful by default", "Please see this colab:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/Keras_LSTM_fusion_Codelab.ipynb", "@zrct0 - curious if you were able to try the stateless version and convert it?", "> @zrct0 - curious if you were able to try the stateless version and convert it?\r\n\r\nI've tried stateless  and convert succeed. But there is a big decrease in accuracy.", "@zrct0 wonder the accuracy drop on the tf side or tflite side?\r\n\r\nthanks", "> @zrct0 wonder the accuracy drop on the tf side or tflite side?\r\n> \r\n> thanks\r\ntf side.\r\nThe results of TF side and tflite side are the same.\r\nIt just not very well when it's stateless ", "I use stateful RNN to process real-time speech recognition. I can't find an alternative\r\nSo I hope Tensorflow can fix the bug", "@zrct0 Thanks for letting us know. We are looking into fixing the stateful conversion as well. But there is a workaround here, you can still use stateless Keras RNN layer and create a stateful layer on top by  managing the state in your python program (not as part of TF). This should still be equivalent to a stateful keras. As a side, we are looking into the accuracy issues between stateful vs stateless", "@zrct0 how much is the accuracy drop when you moved to stateless?", "I have the same issue with TrtGraphConverterV2 and autoregressive transformer decoder. All operations with weights inside tf.while_loop throw errors like:\r\n```\r\nInput 20 of node StatefulPartitionedCall/decoder_1/while was passed resource from Func/StatefulPartitionedCall/input/_203:0 incompatible with expected float.\r\n```\r\n", "> @zrct0 how much is the accuracy drop when you moved to stateless?\r\n\r\nThe decrease in accuracy is in actual use, not in the test set, so I can't quantify the decrease.", "Support for stateful LSTM would be greatly apreciated..", "> @zrct0 Thanks for letting us know. We are looking into fixing the stateful conversion as well. But there is a workaround here, you can still use stateless Keras RNN layer and create a stateful layer on top by managing the state in your python program (not as part of TF). This should still be equivalent to a stateful keras. As a side, we are looking into the accuracy issues between stateful vs stateless\r\n\r\n@ashwinmurthy I'm also getting this bug. Can you please give a small example for this workaround? Thx", "> > @zrct0 Thanks for letting us know. We are looking into fixing the stateful conversion as well. But there is a workaround here, you can still use stateless Keras RNN layer and create a stateful layer on top by managing the state in your python program (not as part of TF). This should still be equivalent to a stateful keras. As a side, we are looking into the accuracy issues between stateful vs stateless\r\n> \r\n> @ashwinmurthy I'm also getting this bug. Can you please give a small example for this workaround? Thx\r\n\r\nThis is what I managed to come up with. Haven't setup training yet. But I imagine it will be painful with keep tracked of all the states. Looking forward to an update on this.\r\n\r\n````\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import LSTM, Dense, Flatten, TimeDistributed\r\nfrom tensorflow.keras import Input, Model\r\nfrom tensorflow.keras.optimizers import Adam\r\nimport numpy as np\r\n\r\ninput = Input(batch_shape=(1, 1, 3, 3))\r\nhidden_state = Input(batch_shape=(1, 8))\r\ncell_state = Input(batch_shape=(1, 8))\r\nx = TimeDistributed(Flatten())(input)\r\nx, new_hidden_state, new_cell_state = LSTM(units=8, return_state=True)(x, initial_state=[hidden_state, cell_state])\r\noutput = Dense(4)(x)\r\nmodel = Model(inputs=[input, hidden_state, cell_state], outputs=[output, new_hidden_state, new_cell_state])\r\nmodel.compile(loss='mse', optimizer=Adam(lr=0.01))\r\n\r\nob = np.random.random((1, 1, 3, 3))\r\nhidden_state = np.random.random((1, 8))\r\noutput, new_hidden_state, new_cell_state = model.predict([ob, hidden_state, cell_state])\r\nprint(model.predict([ob, new_hidden_state, new_cell_state]))\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n````", "also, how do you insert code into a comment? The \"insert code\" button didn't work for me.", "I have tried on colab with TF version 2.5 and getting different error ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/dc7b4f5e68bf0ba39faef815f76b6fa9/untitled306.ipynb)..Thanks!", "Please use the saved model converter in the tf-nightly with the following flag:\r\n\r\n`converter.experimental_enable_resource_variables = True`.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38312\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38312\">No</a>\n"]}, {"number": 38311, "title": "Loading a quantized TFlite model fails when allocating tensors", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **2.2.0-dev20200407**\r\n- Python version: **3.6** / **3.8**\r\n- Bazel version (if compiling from source): **N/A**\r\n- GCC/Compiler version (if compiling from source): **N/A**\r\n- CUDA/cuDNN version: **N/A**\r\n- GPU model and memory: **N/A**\r\n\r\n**Describe the current behavior**\r\nLoading a `tf.keras` model to tflite causes an error when trying to allocate the tensors for inference. The error is:\r\n`RuntimeError: tensorflow/lite/kernels/conv.cc:337 bias->type != kTfLiteInt32 (9 != 2)Node number 1 (CONV_2D) failed to prepare.`\r\n\r\n**Describe the expected behavior**\r\nThe exported model should load without error. Inference with the same model in tensorflow is working.\r\n\r\n**Standalone code to reproduce the issue** \r\nColab gist reproducing the error can be found [here](https://colab.research.google.com/gist/moberweger/d75235cd637c0689e0984cfb3a388144/untitled0.ipynb) Slight modifications to the network structure (ie removing random layers) make the error go, but without any understandable scheme. \r\n\r\n**Other info / logs** \r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n\r\n<ipython-input-2-6b478363f7a3> in <module>()\r\n     68     interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\r\n     69     input_details = interpreter.get_input_details()\r\n---> 70     interpreter.allocate_tensors()\r\n     71     print(\"DONE\")\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py in allocate_tensors(self)\r\n    241   def allocate_tensors(self):\r\n    242     self._ensure_safe()\r\n--> 243     return self._interpreter.AllocateTensors()\r\n    244 \r\n    245   def _safe_to_run(self):\r\n\r\nRuntimeError: tensorflow/lite/kernels/conv.cc:337 bias->type != kTfLiteInt32 (9 != 2)Node number 1 (CONV_2D) failed to prepare.\r\n```\r\n", "comments": ["@moberweger,\r\nI am unable to open the Colab link you have provided as I do not have access to it.\r\n\r\nPlease go to File -> Save a copy as a GitHub Gist and share the link of the new gist created with us. Thanks!", "@amahendrakar Thanks for the notice. I updated the original issue with the new [link](https://colab.research.google.com/gist/moberweger/d75235cd637c0689e0984cfb3a388144/untitled0.ipynb)", "Was able to reproduce the issue with [TF-nightly](https://colab.research.google.com/gist/amahendrakar/594b38f7a23dc304debc2868a32b9d0a/38311-tf-nightly.ipynb) i.e. v2.2.0.dev20200410.\r\n\r\nOn running the above code with [TF v2.2.0rc2](https://colab.research.google.com/gist/amahendrakar/1353339ab5e6940f70a9697f418d614d/38311-2-2.ipynb#scrollTo=BfzADgjtSfGs), facing an error stating `AttributeError: 'TFLiteConverterV2' object has no attribute 'experimental_new_quantizer'`\r\n\r\nPlease find the attached gist. Thanks!", "Hello, and thank you so much for your time! Unfortunately, we are running into the exact same issue. Has there been a workaround/fix yet? ", "I have tried in colab with TF nightly version(`2.4.0-dev20200807`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/d9b9320804eb12c0e7ba55f9a1775e42/untitled229.ipynb).Thanks!", "Facing the same issue in both TF 2.3.0 and TF nightly version(tf-nightly-2.4.0.dev20200922) for my model involving Conv1D layers. Are Conv layers not yet supported for tflite or is it something else?\r\n\r\nIs there a way to resolve this or do we need to wait till the next tf stable release (TF 2.4.0).\r\nPlease help.", "@moberweger Looks like there was some in compatible `dtype` issue. The following is the error .\r\n\r\n`RuntimeError: tensorflow/lite/kernels/conv.cc:350 bias->type != kTfLiteInt32 (INT8 != INT32)Node number 1 (CONV_2D) failed to prepare.`\r\n\r\nWhen I remove `BatchNorm` layer, it worked without any error.  I remember there was some issue related to `BatchNorm` but it was long time back. Need to check that. Thanks!", "@tromedlov22 Please share a simple standalone code to reproduce the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38311\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38311\">No</a>\n"]}, {"number": 38310, "title": "google colab  can not install TFX (taxi_pipeline_interactive.ipynb)", "body": "1.!pip install \"tfx>=0.21.1,<0.22\" \"tensorflow>=2.1,<2.2\" \"tensorboard>=2.1,<2.2\"\r\nInstall successfully\r\n2.Restart run time\r\ncontinuously shown busy\r\nPlease help me solved this problems \r\n", "comments": ["@pradeepmishra11, Please provide the colab gist or Provide the exact sequence of commands / steps that you executed before running into the problem. Thanks", "1,# TODO(ccy): remove \"pyzmq==17.0.0\" pin after bug in Colab is fixed.\r\n!pip install -q \"tfx>=0.21.1,<0.22\" \"tensorflow>=2.1,<2.2\" \"tensorboard>=2.1,<2.2\" \"pyzmq==17.0.0\"\r\n2.2.Restart run time\r\ncontinuously shown busy\r\n3.import os\r\nimport pprint\r\nimport tempfile\r\nimport urllib\r\n\r\nimport absl\r\nimport tensorflow as tf\r\nimport tensorflow_model_analysis as tfma\r\ntf.get_logger().propagate = False\r\npp = pprint.PrettyPrinter()\r\n\r\nimport tfx\r\nfrom tfx.components import CsvExampleGen\r\nfrom tfx.components import Evaluator\r\nfrom tfx.components import ExampleValidator\r\nfrom tfx.components import Pusher\r\nfrom tfx.components import ResolverNode\r\nfrom tfx.components import SchemaGen\r\nfrom tfx.components import StatisticsGen\r\nfrom tfx.components import Trainer\r\nfrom tfx.components import Transform\r\nfrom tfx.dsl.experimental import latest_blessed_model_resolver\r\nfrom tfx.orchestration import metadata\r\nfrom tfx.orchestration import pipeline\r\nfrom tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\r\nfrom tfx.proto import pusher_pb2\r\nfrom tfx.proto import trainer_pb2\r\nfrom tfx.proto.evaluator_pb2 import SingleSlicingSpec\r\nfrom tfx.utils.dsl_utils import external_input\r\nfrom tfx.types import Channel\r\nfrom tfx.types.standard_artifacts import Model\r\nfrom tfx.types.standard_artifacts import ModelBlessing\r\n\r\n%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip", "@pradeepmishra11 , This issue is not related to Tensorflow. Can you raise this issue in TFX repository. Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@pradeepmishra11 ,\r\nas updated above please create this issue in tfx", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38310\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38310\">No</a>\n"]}, {"number": 38309, "title": "tf.saved_model.save()/load() Issue", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n-  CNN model is build under subclass \r\n- OS Platform and Distribution: Win10/Anaconda/Python3.7/Tensorflow 2.1.0\r\n- TensorFlow installed from (source or binary): pip install\r\n- Python version: - 3.7\r\n- CUDA/cuDNN version: Run under CPU mode\r\n\r\n**Describe the current behavior**\r\n1. When finish 1 epoch of training for model, use **tf.saved_model.save(model, save_model_dir)**  to save the whole model to the folder\r\n2. Try to load the pb file generated by the system called **saved_model.pb** by command:\r\n    model = tf.saved_model.load(save_model_dir)\r\n3. Try to predict the result by using command:\r\n    model(inputs)\r\n4. The system return following error:\r\nTypeError: '_UserObject' object is not callable\r\n5. From the API document, the example is clearly use the function as I mentioned I think\r\n\r\nWhat's the error then?\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nfrom __future__ import absolute_import, division, print_function\r\nimport tensorflow as tf\r\nimport math\r\n\r\n# User defined packages\r\nfrom configuration import IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS, \\\r\n    EPOCHS, BATCH_SIZE, save_model_dir, save_every_n_epoch\r\nfrom prepare_data import generate_datasets, load_and_preprocess_image\r\nfrom models import mobilenet_v1, mobilenet_v2, mobilenet_v3_large, mobilenet_v3_small, \\\r\n    efficientnet, resnext, inception_v4, inception_resnet_v1, inception_resnet_v2, \\\r\n    se_resnet, squeezenet, densenet, shufflenet_v2, resnet\r\nfrom models.model_selection import get_model\r\nfrom frozen_pb import get_frozen_model\r\n\r\n\r\ndef print_model_summary(network):\r\n    network.build(input_shape=(None, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\r\n    network.summary()\r\n\r\n\r\ndef process_features(features, data_augmentation):\r\n    image_raw = features['image_raw'].numpy()\r\n    image_tensor_list = []\r\n    for image in image_raw:\r\n        image_tensor = load_and_preprocess_image(image, data_augmentation=data_augmentation)\r\n        image_tensor_list.append(image_tensor)\r\n    images = tf.stack(image_tensor_list, axis=0)\r\n    labels = features['label'].numpy()\r\n\r\n    return images, labels\r\n\r\n\r\nif __name__ == '__main__':\r\n    # GPU settings\r\n    gpus = tf.config.list_physical_devices(\"GPU\")\r\n    if gpus:\r\n        for gpu in gpus:\r\n            tf.config.experimental.set_memory_growth(gpu, True)\r\n\r\n    # get the dataset\r\n    train_dataset, valid_dataset, test_dataset, train_count, valid_count, test_count = generate_datasets()\r\n\r\n    # create model\r\n    model = get_model()\r\n    print_model_summary(network=model)\r\n\r\n    # define loss and optimizer\r\n    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\r\n    # Tried RMSprop for optimizer, the result is not so good, finetune the optimizer to Adam or Momentum\r\n    #optimizer = tf.keras.optimizers.RMSprop(learning_rate = GLOBAL_LEARNING_RATE,\r\n    #                                        momentum = MOMENTUM,\r\n    #                                        name = 'rms_optimizer')\r\n    \r\n    optimizer = tf.keras.optimizers.Adam(lr = 0.0001, decay = 0.4)\r\n\r\n    train_loss = tf.keras.metrics.Mean(name='train_loss')\r\n    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\r\n\r\n    valid_loss = tf.keras.metrics.Mean(name='valid_loss')\r\n    valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\r\n\r\n    # @tf.function\r\n    def train_step(image_batch, label_batch):\r\n        with tf.GradientTape() as tape:\r\n            predictions = model(image_batch, training=True)\r\n            loss = loss_object(y_true=label_batch, y_pred=predictions)\r\n        gradients = tape.gradient(loss, model.trainable_variables)\r\n        optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\r\n\r\n        train_loss.update_state(values=loss)\r\n        train_accuracy.update_state(y_true=label_batch, y_pred=predictions)\r\n        \r\n        return predictions, tf.math.argmax(predictions, axis =1).numpy()\r\n\r\n    # @tf.function\r\n    def valid_step(image_batch, label_batch):\r\n        predictions = model(image_batch, training=True)\r\n        v_loss = loss_object(label_batch, predictions)\r\n\r\n        valid_loss.update_state(values=v_loss)\r\n        valid_accuracy.update_state(y_true=label_batch, y_pred=predictions)\r\n        \r\n        return tf.math.argmax(predictions, axis =1).numpy()\r\n\r\n    # start training\r\n    for epoch in range(EPOCHS):\r\n        step = 0\r\n        for features in train_dataset:\r\n            step += 1\r\n            images, labels = process_features(features, data_augmentation=False)\r\n            predictions, predict_labels = train_step(images, labels)\r\n            print(\"Epoch: {}/{}, step: {}/{}, loss: {:.5f}, accuracy: {:.5f}\".format(epoch,\r\n                                                                                     EPOCHS,\r\n                                                                                     step,\r\n                                                                                     math.ceil(train_count / BATCH_SIZE),\r\n                                                                                     train_loss.result().numpy(),\r\n                                                                                     train_accuracy.result().numpy()),\r\n                  predictions,\r\n                  predict_labels,\r\n                  labels)\r\n\r\n        for features in valid_dataset:\r\n            valid_images, valid_labels = process_features(features, data_augmentation=False)\r\n            valid_step(valid_images, valid_labels)\r\n\r\n        print(\"Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, \"\r\n              \"valid loss: {:.5f}, valid accuracy: {:.5f}\".format(epoch,\r\n                                                                  EPOCHS,\r\n                                                                  train_loss.result().numpy(),\r\n                                                                  train_accuracy.result().numpy(),\r\n                                                                  valid_loss.result().numpy(),\r\n                                                                  valid_accuracy.result().numpy()))\r\n        train_loss.reset_states()\r\n        train_accuracy.reset_states()\r\n        valid_loss.reset_states()\r\n        valid_accuracy.reset_states()\r\n\r\n        if epoch % save_every_n_epoch == 0:\r\n            tf.saved_model.save(model, save_model_dir)\r\n            \r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["By the way, I've seen the response for previous similar bug.\r\n\r\nIt is suggested to use tf.keras.models.save_model to save the model, while I tried this function and the result became to be another failure:\r\n**input shape is not defined, must use model._set_input(inputs) to manually setup the shape**\r\n\r\nHere comes the question:\r\nIs it means I must use model.compile and model.fit together with it?", "@rogeryuchao, I am not able to figure out how you are defining model. But still I suggest to use `model.predict(inputs)` instead of `model(inputs)` to predict the result from loaded model.", "@khimraj Hi, \r\n\r\nI also tried model.predict actually, but still do not work.\r\nplease check the following information for the model building class\r\n\r\n`import tensorflow as tf\r\nfrom models.inception_modules import Stem, ReductionA, BasicConv2D, Conv2DLinear\r\nfrom configuration import NUM_CLASSES, DROPOUT_RATIO, L1_REGULIZER, L2_REGULIZER\r\n\r\n\r\nclass InceptionResNetA(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super(InceptionResNetA, self).__init__()\r\n        self.b1_conv = BasicConv2D(filters=32,\r\n                                   kernel_size=(1, 1),\r\n                                   strides=1,\r\n                                   padding=\"same\")\r\n        self.b2_conv1 = BasicConv2D(filters=32,\r\n                                    kernel_size=(1, 1),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b2_conv2 = BasicConv2D(filters=32,\r\n                                    kernel_size=(3, 3),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b3_conv1 = BasicConv2D(filters=32,\r\n                                    kernel_size=(1, 1),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b3_conv2 = BasicConv2D(filters=48,\r\n                                    kernel_size=(3, 3),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b3_conv3 = BasicConv2D(filters=64,\r\n                                    kernel_size=(3, 3),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.conv = Conv2DLinear(filters=384,\r\n                                 kernel_size=(1, 1),\r\n                                 strides=1,\r\n                                 padding=\"same\")\r\n\r\n    def call(self, inputs, training=None, **kwargs):\r\n        b1 = self.b1_conv(inputs, training=training)\r\n        b2 = self.b2_conv1(inputs, training=training)\r\n        b2 = self.b2_conv2(b2, training=training)\r\n        b3 = self.b3_conv1(inputs, training=training)\r\n        b3 = self.b3_conv2(b3, training=training)\r\n        b3 = self.b3_conv3(b3, training=training)\r\n\r\n        x = tf.concat(values=[b1, b2, b3], axis=-1)\r\n        x = self.conv(x, training=training)\r\n\r\n        output = tf.keras.layers.add([x, inputs])\r\n        return tf.nn.relu(output)\r\n\r\n\r\nclass InceptionResNetB(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super(InceptionResNetB, self).__init__()\r\n        self.b1_conv = BasicConv2D(filters=192,\r\n                                   kernel_size=(1, 1),\r\n                                   strides=1,\r\n                                   padding=\"same\")\r\n        self.b2_conv1 = BasicConv2D(filters=128,\r\n                                    kernel_size=(1, 1),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b2_conv2 = BasicConv2D(filters=160,\r\n                                    kernel_size=(1, 7),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b2_conv3 = BasicConv2D(filters=192,\r\n                                    kernel_size=(7, 1),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.conv = Conv2DLinear(filters=1152,\r\n                                 kernel_size=(1, 1),\r\n                                 strides=1,\r\n                                 padding=\"same\")\r\n\r\n    def call(self, inputs, training=None, **kwargs):\r\n        b1 = self.b1_conv(inputs, training=training)\r\n        b2 = self.b2_conv1(inputs, training=training)\r\n        b2 = self.b2_conv2(b2, training=training)\r\n        b2 = self.b2_conv3(b2, training=training)\r\n\r\n        x = tf.concat(values=[b1, b2], axis=-1)\r\n        x = self.conv(x, training=training)\r\n\r\n        output = tf.keras.layers.add([x, inputs])\r\n\r\n        return tf.nn.relu(output)\r\n\r\n\r\nclass InceptionResNetC(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super(InceptionResNetC, self).__init__()\r\n        self.b1_conv = BasicConv2D(filters=192,\r\n                                   kernel_size=(1, 1),\r\n                                   strides=1,\r\n                                   padding=\"same\")\r\n        self.b2_conv1 = BasicConv2D(filters=192,\r\n                                    kernel_size=(1, 1),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b2_conv2 = BasicConv2D(filters=224,\r\n                                    kernel_size=(1, 3),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b2_conv3 = BasicConv2D(filters=256,\r\n                                    kernel_size=(3, 1),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.conv = Conv2DLinear(filters=2144,\r\n                                 kernel_size=(1, 1),\r\n                                 strides=1,\r\n                                 padding=\"same\")\r\n\r\n    def call(self, inputs, training=None, **kwargs):\r\n        b1 = self.b1_conv(inputs, training=training)\r\n        b2 = self.b2_conv1(inputs, training=training)\r\n        b2 = self.b2_conv2(b2, training=training)\r\n        b2 = self.b2_conv3(b2, training=training)\r\n\r\n        x = tf.concat(values=[b1, b2], axis=-1)\r\n        x = self.conv(x, training=training)\r\n\r\n        output = tf.keras.layers.add([x, inputs])\r\n\r\n        return tf.nn.relu(output)\r\n\r\n\r\nclass ReductionB(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super(ReductionB, self).__init__()\r\n        self.b1_maxpool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\r\n                                                    strides=2,\r\n                                                    padding=\"valid\")\r\n        self.b2_conv1 = BasicConv2D(filters=256,\r\n                                    kernel_size=(1, 1),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b2_conv2 = BasicConv2D(filters=384,\r\n                                    kernel_size=(3, 3),\r\n                                    strides=2,\r\n                                    padding=\"valid\")\r\n        self.b3_conv1 = BasicConv2D(filters=256,\r\n                                    kernel_size=(1, 1),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b3_conv2 = BasicConv2D(filters=288,\r\n                                    kernel_size=(3, 3),\r\n                                    strides=2,\r\n                                    padding=\"valid\")\r\n        self.b4_conv1 = BasicConv2D(filters=256,\r\n                                    kernel_size=(1, 1),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b4_conv2 = BasicConv2D(filters=288,\r\n                                    kernel_size=(3, 3),\r\n                                    strides=1,\r\n                                    padding=\"same\")\r\n        self.b4_conv3 = BasicConv2D(filters=320,\r\n                                    kernel_size=(3, 3),\r\n                                    strides=2,\r\n                                    padding=\"valid\")\r\n\r\n    def call(self, inputs, training=None, **kwargs):\r\n        b1 = self.b1_maxpool(inputs)\r\n\r\n        b2 = self.b2_conv1(inputs, training=training)\r\n        b2 = self.b2_conv2(b2, training=training)\r\n\r\n        b3 = self.b3_conv1(inputs, training=training)\r\n        b3 = self.b3_conv2(b3, training=training)\r\n\r\n        b4 = self.b4_conv1(inputs, training=training)\r\n        b4 = self.b4_conv2(b4, training=training)\r\n        b4 = self.b4_conv3(b4, training=training)\r\n\r\n        return tf.concat(values=[b1, b2, b3, b4], axis=-1)\r\n\r\n\r\ndef build_inception_resnet_a(n):\r\n    block = tf.keras.Sequential()\r\n    for _ in range(n):\r\n        block.add(InceptionResNetA())\r\n    return block\r\n\r\n\r\ndef build_inception_resnet_b(n):\r\n    block = tf.keras.Sequential()\r\n    for _ in range(n):\r\n        block.add(InceptionResNetB())\r\n    return block\r\n\r\n\r\ndef build_inception_resnet_c(n):\r\n    block = tf.keras.Sequential()\r\n    for _ in range(n):\r\n        block.add(InceptionResNetC())\r\n    return block\r\n\r\n\r\nclass InceptionResNetV2(tf.keras.Model):\r\n    def __init__(self):\r\n        super(InceptionResNetV2, self).__init__()\r\n        self.stem = Stem()\r\n        self.inception_resnet_a = build_inception_resnet_a(5)\r\n        self.reduction_a = ReductionA(k=256, l=256, m=384, n=384)\r\n        self.inception_resnet_b = build_inception_resnet_b(10)\r\n        self.reduction_b = ReductionB()\r\n        self.inception_resnet_c = build_inception_resnet_c(5)\r\n        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(8, 8))\r\n        self.dropout = tf.keras.layers.Dropout(rate=DROPOUT_RATIO)\r\n        self.flat = tf.keras.layers.Flatten()\r\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\r\n                                        activation=tf.keras.activations.softmax,\r\n                                        kernel_regularizer=tf.keras.regularizers.l1(L1_REGULIZER),\r\n                                        activity_regularizer=tf.keras.regularizers.l2(L2_REGULIZER))\r\n\r\n    def call(self, inputs, training=None, mask=None):\r\n        x = self.stem(inputs, training=training)\r\n        x = self.inception_resnet_a(x, training=training)\r\n        x = self.reduction_a(x, training=training)\r\n        x = self.inception_resnet_b(x, training=training)\r\n        x = self.reduction_b(x, training=training)\r\n        x = self.inception_resnet_c(x, training=training)\r\n        x = self.avgpool(x)\r\n        x = self.dropout(x, training=training)\r\n        x = self.flat(x)\r\n        x = self.fc(x)\r\n\r\n        return x`\r\n\r\n", "@rogeryuchao\r\ni have tried to replicate the issue shared and face indentation errors the code is too big to fix indentation for entire code, can you please share colab gist for us to analyse the issue if possible or share complete correct indented code", "@rogeryuchao\r\nplease update as per above comment", "@Saduf2019 \r\nSorry for the late reply. Because of the china policy, unfortunately I cannot launch colab for sharing the code, while I think you can clone the repo and all the project framework are in it, thank you.\r\n    git@github.com:rogeryuchao/general_cnn.git", "@rogeryuchao\r\nplease provide us with minimal reproducible code, for us to help you.", "\r\n[general_cnn-master.zip](https://github.com/tensorflow/tensorflow/files/4510732/general_cnn-master.zip)\r\n", "@rogeryuchao \r\ncan you please share the steps as the repository is huge and which files are to be used to replicate the issue", "@Saduf2019\r\nI cannot provide the image I use to you, because it is huge files. But I can let you know the steps:\r\n1. Put the `class_name[folder_name]/image_files.jpgs` into original_data_set folder\r\n2. In shell, Run `split_dataset.py`\r\n3. In shell, Run `to_tfrecord.py`\r\n4. Change the train.py (Now I use `model.save_weight[line 202]` function instead of `tf.save_model/tf.keras.models.save_model[line 204]` function), you can swap them\r\n5. In configuration.py, change `THRESHOLD` function to 0.0\r\n6. In configuration.py, if you think the saving timing is too late, you can adjust `save_every_n_epoch`\r\n6. In shell, Run `train.py 1 ABCD`\r\n7. Wait for the model to finish epochs and save model, the model will be saved under `saved_model` folder, but it will fail anyway(Even if I define the shape of input in line 203)\r\n8. If defined the shape of input, the model will be saved, but cannot be used, try `evaluate.py 1 ABCD` to load the model, eventually it does not work", "@rogeryuchao Please provide a minimal example for us to reproduce this issue as I cannot reproduce this issue. If you can provide reproduce code with dataset, we can progress further with this discussion. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38309\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38309\">No</a>\n"]}, {"number": 38308, "title": "Tensorflow 2.1.0 build issue ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution : Linux , RHEL6\r\n- TensorFlow installed from (source or binary):  Source\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.1\r\n- Bazel version (if compiling from source): 0.28.1\r\n- GCC/Compiler version (if compiling from source): 6.3.0\r\n\r\n**Describe the problem**\r\n\r\n/tensorflow/tensorflow/compiler/tf2xla/cc/BUILD:8:1: Linking of rule '//tensorflow/compiler/tf2xla/cc:ops/xla_ops_gen_cc' failed (Exit 1) bazel-out/host/bin/external/com_google_absl/absl/time/_objs/time/clock.o:clock.cc:function absl::GetCurrentTimeNanosSlowPath(): error: undefined reference to 'clock_gettime'\r\nbazel-out/host/bin/tensorflow/core/platform/_objs/env_time_impl/env_time.o:env_time.cc:function tensorflow::(anonymous namespace)::PosixEnvTime::NowNanos() const: error: undefined reference to 'clock_gettime'\r\nbazel-out/host/bin/external/com_google_absl/absl/base/_objs/base/sysinfo.o:sysinfo.cc:function absl::base_internal::ReadMonotonicClockNanos(): error: undefined reference to 'clock_gettime'\r\ncollect2: error: ld returned 1 exit status Target //tensorflow:libtensorflow_cc.so failed to build\r\nINFO: Elapsed time: 5992.496s, Critical Path: 85.82s\r\nINFO: 3149 processes: 3149 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\nbazel build --linkopt='-lrt' --verbose_failures --config=monolithic -c opt //tensorflow:libtensorflow_cc.so\r\n", "comments": ["@npandey2385 \r\n\r\nCan you downgrade bazel version to 0.27.1 and check. Please, find the [tested build configurations](https://www.tensorflow.org/install/source#cpu) from here.Also, refer #35623 and see if it helps you. Thanks!", "I was able to build it with bazel 0.28.1 after apllying these two changes.\r\n\r\n1- https://github.com/Flamefire/tensorflow/commit/1751e3c8de7a3e2a69dd22a6062aec7d2c7709ef\r\n2-\r\nAdd -lrt as red line as follows:\r\n\r\n\r\n        \"//conditions:default\": [\r\n            \"-z defs\",\r\n            \"-s\",\r\n            \"-Wl,--version-script\",  #  This line must be directly followed by LINKER_VERSION_SCRIPT\r\n            LINKER_VERSION_SCRIPT,\r\n        ],\r\nto\r\n        \"//conditions:default\": [\r\n            \"-lrt\",\r\n            \"-z defs\",\r\n            \"-s\",\r\n            \"-Wl,--version-script\",  #  This line must be directly followed by LINKER_VERSION_SCRIPT\r\n            LINKER_VERSION_SCRIPT,\r\n        ],\r\nin tensorflow/java/BUILD.\r\n", "@npandey2385 \r\n\r\nGlad to know it worked.Please close this thread if the issue was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38308\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38308\">No</a>\n"]}, {"number": 38307, "title": "Waymo dataset:  module 'tensorflow' has no attribute 'enable_eager_execution'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I am replicating the waymo dataset tutorial code for understanding and learning \r\n- Using Notebook of Google COLAB (as New user to Google Colab)\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below):  2.1.0 (as installed by default in Google Colab)\r\n\r\n**This is the line of code: (sharing since it is available for public view as well by google in it's tutorial)**\r\n\r\n!pip3 install waymo-open-dataset\r\nimport os\r\nimport tensorflow as tf\r\nimport math\r\nimport numpy as np\r\nimport itertools\r\n\r\ntf.enable_eager_execution()\r\n\r\nfrom waymo_open_dataset.utils import range_image_utils\r\nfrom waymo_open_dataset.utils import transform_utils\r\nfrom waymo_open_dataset.utils import frame_utils\r\nfrom waymo_open_dataset import dataset_pb2 as open_dataset\r\n\r\n**Describe the current behavior**\r\n**Error I get upon executing the above lines of code**\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-8-8d310d062fcf> in <module>()\r\n      6 import itertools\r\n      7 \r\n----> 8 tf.enable_eager_execution()\r\n      9 \r\n     10 from waymo_open_dataset.utils import range_image_utils\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'\r\n", "comments": ["@Viki250893,\r\nThe line `tf.enable_eager_execution()` is used only in TensorFlow 1.x to enable eager execution.\r\n \r\nFrom TensorFlow 2.x eager mode is enabled by default so you can comment out that line. Thanks!", "Thank you, but upon commenting the line.\r\n\r\n!pip3 install waymo-open-dataset\r\nimport os\r\nimport tensorflow as tf\r\nimport math\r\nimport numpy as np\r\nimport itertools\r\n\r\n**#tf.enable_eager_execution()**\r\n\r\nfrom waymo_open_dataset.utils import range_image_utils\r\nfrom waymo_open_dataset.utils import transform_utils\r\nfrom waymo_open_dataset.utils import frame_utils\r\nfrom waymo_open_dataset import dataset_pb2 as open_dataset\r\n\r\n**I get the following error**\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-3-4a0693fecef3> in <module>()\r\n      8 #tf.enable_eager_execution()\r\n      9 \r\n---> 10 from waymo_open_dataset.utils import range_image_utils\r\n     11 from waymo_open_dataset.utils import transform_utils\r\n     12 from waymo_open_dataset.utils import frame_utils\r\n\r\n/usr/local/lib/python3.6/dist-packages/waymo_open_dataset/utils/range_image_utils.py in <module>()\r\n     57                           value,\r\n     58                           shape,\r\n---> 59                           pool_method=tf.unsorted_segment_max):\r\n     60   \"\"\"Similar as tf.scatter_nd but allows custom pool method.\r\n     61 \r\n\r\nAttributeError: module 'tensorflow' has no attribute 'unsorted_segment_max'", "@Viki250893,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here.\r\n\r\nAlso, please add ``` (i.e. three backticks) before and after your code to preserve the indentation and formatting. Thanks!", "You can also provide the link to the tutorial you are following.", "https://colab.research.google.com/drive/1DMt8gRU19fT5uPWBOdfRi5RsuXyRqeMO#scrollTo=Ipl_UEDWgLrB", "@Viki250893,\r\nI am unable to open the link you have provided as I do not have access to it.\r\n\r\nPlease go to File -> Save a copy as a GitHub Gist and share the link of the new gist created with us. Thanks!", "https://colab.research.google.com/gist/Viki250893/40008cf236a25736d1cdefc7e0e403ea/untitled1.ipynb\r\n\r\nI hope this link has the access.", "@amahendrakar Can you please reply with possible solution. Thank you. ", "No update from the team. So closing the issue and reporting again. ", "@Viki250893,\r\nCould you please check if the tutorial you are following is intended to use with TF 1.x?\r\n\r\nI was able to reproduce the issue with TF 2.x, however I'm able to run the code without any issues with TF 1.15.2. Please find the gist [here](https://colab.research.google.com/gist/amahendrakar/f532cd92dba6789a6f5e11df73c85f60/38307.ipynb). Thanks!", "Thank you for the reply.  I have  a check and update you.\n", "WAYMO/Author whoever it is, has updated the tutorial script with\r\n**Updated script has tensorflow.compat version1.**\r\n``` \r\nimport tensorflow.compat.v1 as tf  \r\n```\r\n\r\n**but, when I reported it, (Previously it was )**\r\n```\r\nimport tensorflow as tf\r\n```\r\nhttps://colab.research.google.com/gist/Viki250893/40008cf236a25736d1cdefc7e0e403ea/untitled1.ipynb#scrollTo=3etKdSB4gIeR\r\n\r\nI'm not sure what's happening. \r\n\r\nI would like to understand the difference of it being compatible with updated \"compat.v1\". This is on importing the library, not the eager enabler.\r\n\r\n\r\nRight now, it's working fine. \r\nMaybe you can share some clarity and may close the issue.\r\n\r\nThank you", "@Viki250893,\r\nFor information regarding compatibility modules please check [this](https://www.tensorflow.org/guide/upgrade#compatibility_modules) TensorFlow guide. [This guide](https://www.tensorflow.org/guide/migrate) to migrate TF 1.x code to TF 2.x would also be helpful.\r\n\r\nPlease feel free to close the issue if resolved. Thanks!", "Thank you very much!!! @amahendrakar "]}, {"number": 38306, "title": "Build manylinux whl from source", "body": "**System information**\r\n- OS Platform and Distribution:\r\ncentos\r\n- TensorFlow installed from (source or binary):\r\nsource\r\n- TensorFlow version:\r\n1.15.0\r\n- Python version:\r\n3.6\r\n- Bazel version (if compiling from source):\r\n0.26\r\n- GCC/Compiler version (if compiling from source):\r\n7.4\r\n- CUDA/cuDNN version:\r\n10.0\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nIs it possible to build a manylinux package from source using some extra flags? I'm in a environment where it is much easier to build in one enviroment and test in another. It would be really nice if I can build a manylinux pip whl from source.\r\n", "comments": ["Our build scripts are [in the repo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build/release).\r\n\r\nBy default, compiling the pip package should build the manylinux pip.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38306\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38306\">No</a>\n", "> By default, compiling the pip package should build the manylinux pip.\r\n\r\n@mihaimaruseac Do you mean, compiling from within one of the tensorflow devel docker images?\r\n"]}, {"number": 38305, "title": "tf.lookup.StaticHashTable: Cannot convert a Tensor of dtype resource to a NumPy array", "body": "**System information** \r\n\r\n- Have I written custom code:  Yes\r\n- OS Platform and Distribution: macOS 10.14.6\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):  v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nI have some input that I need to translate,\r\n```\r\n\"Dog\" -> 0\r\n\"Cat\" -> 1\r\n...\r\n```\r\nand then embed.\r\n\r\nI tried to use the `tf.lookup.StaticHashTable` for this, but it works when the input is a `tf.Variable`, not when using `tf.keras.layers.Input`, see the following output: \r\n\r\n```\r\nIn [6]:\r\ninputs1 = tf.Variable([[3]], dtype=tf.int64)\r\ntranslate_and_embed(inputs1)\r\nOut[6]:\r\n<tf.Tensor: shape=(1, 1, 10), dtype=float32, numpy=\r\narray([[[ 0.01451602,  0.04537327, -0.00232627,  0.00584463,\r\n         -0.04128218, -0.03868868,  0.04147324, -0.02444596,\r\n          0.03310961,  0.01144157]]], dtype=float32)>\r\nIn [7]:\r\ninputs2 = tf.keras.layers.Input(shape=(1,), dtype=tf.int64)\r\ntranslate_and_embed(inputs2)\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-10-b2c4cfd055e5> in <module>()\r\n      1 inputs2 = tf.keras.layers.Input(shape=(1,), dtype=tf.int64)\r\n----> 2 translate_and_embed(inputs2)\r\n\r\n<ipython-input-8-340bf85dfb2f> in translate_and_embed(inputs)\r\n     21         output_dim=10,\r\n     22     )\r\n---> 23     return embedder(translated)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    718     # framework.\r\n    719     if build_graph and base_layer_utils.needs_keras_history(inputs):\r\n--> 720       base_layer_utils.create_keras_history(inputs)\r\n    721 \r\n    722     # Clear eager losses on top level model call.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in create_keras_history(tensors)\r\n    185     keras_tensors: The Tensors found that came from a Keras Layer.\r\n    186   \"\"\"\r\n--> 187   _, created_layers = _create_keras_history_helper(tensors, set(), [])\r\n    188   return created_layers\r\n    189 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    245           else:\r\n    246             with ops.init_scope():\r\n--> 247               constants[i] = backend.function([], op_input)([])\r\n    248       processed_ops, created_layers = _create_keras_history_helper(\r\n    249           layer_inputs, processed_ops, created_layers)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in __call__(self, inputs)\r\n   3733     return nest.pack_sequence_as(\r\n   3734         self._outputs_structure,\r\n-> 3735         [x._numpy() for x in outputs],  # pylint: disable=protected-access\r\n   3736         expand_composites=True)\r\n   3737 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in <listcomp>(.0)\r\n   3733     return nest.pack_sequence_as(\r\n   3734         self._outputs_structure,\r\n-> 3735         [x._numpy() for x in outputs],  # pylint: disable=protected-access\r\n   3736         expand_composites=True)\r\n   3737 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in _numpy(self)\r\n    908       return self._numpy_internal()\r\n    909     except core._NotOkStatusException as e:\r\n--> 910       six.raise_from(core._status_to_exception(e.code, e.message), None)\r\n    911 \r\n    912   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.\r\n```\r\n\r\n**Describe the expected behavior**\r\nI expect the second function call to return a symbolic tensor.\r\n\r\n**Standalone code to reproduce the issue** \r\n- https://colab.research.google.com/gist/jeanmn/6d2821feaf4828f43524ada267db266f/tf-lookup-statichhashtable-cannot-convert-a-tensor-of-dtype-resource-to-a-numpy-array.ipynb\r\n- https://gist.github.com/jeanmn/6d2821feaf4828f43524ada267db266f\r\n\r\n**Other info / logs**\r\n- Similar issue? https://github.com/tensorflow/tensorflow/issues/37441\r\n- Related? #37844 \r\n", "comments": ["@jeanmn \r\nplease refer to below issues and let us know if it helps:\r\n#37844 #32999 #[link](https://stackoverflow.com/questions/59962509/valueerror-cannot-convert-a-tensor-of-dtype-resource-to-a-numpy-array)", "> @jeanmn\r\n> please refer to below issues and let us know if it helps:\r\n> #37844 #32999 #[link](https://stackoverflow.com/questions/59962509/valueerror-cannot-convert-a-tensor-of-dtype-resource-to-a-numpy-array)\r\n\r\n- #37844\r\nThis is the same issue that I was referring to. That issue seems to be related to TFlite conversion? My issue is happening without any TFlite conversion, which leads me to believe that there is some issue with the StaticHashMap itself.\r\n[The suggested example](https://github.com/tensorflow/tensorflow/issues/37844#issuecomment-605336360) from @abattery looked promising, \r\nbut as far as I can see `tf.initializers.tables_initializer`  raises an\r\n```\r\nAttributeError: module 'tensorflow_core.python.keras.api._v2.keras.initializers' has no attribute 'tables_initializer'\r\n```\r\nfor tensorflow 2.1.0 (and later?). \r\n\r\n- #32999\r\nThis issue also seems to describe problems that happen during TFlite conversion. I'm not sure how it helps my case.\r\n\r\n- [stackoverflow link](https://stackoverflow.com/questions/59962509/valueerror-cannot-convert-a-tensor-of-dtype-resource-to-a-numpy-array)\r\nThis is the other issue that I was referring to in my issue description. #37441\r\nIt is also unresolved, and appears similar to mine.\r\n\r\nPlease direct me to the correct answer suggestion if I have missed it.\r\n\r\nHere is the function from my gist that I am trying to run, (the one that fails when feeding an Input layer):\r\n```\r\nimport tensorflow as tf\r\n\r\ndef translate_and_embed(inputs):\r\n    keys = [0,1,2,3]\r\n    values = [0,10,20,30]\r\n\r\n    initializer = tf.lookup.KeyValueTensorInitializer(\r\n        keys=keys,\r\n        values=values,\r\n        key_dtype=tf.int64,\r\n        value_dtype=tf.int64,\r\n    )\r\n    table = tf.lookup.StaticHashTable(\r\n        initializer,\r\n        default_value=-1,\r\n    )\r\n    translated = table.lookup(inputs)\r\n\r\n    embedder = tf.keras.layers.Embedding(\r\n        input_dim=max(values)+1,\r\n        output_dim=10,\r\n    )\r\n    return embedder(translated)\r\n```", "i am able to replicate this, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/295838ac302571e25c0d1c8c4a9c476d/38305.ipynb)", "@jeanmn I guess `lookup` method in `tf.lookup.StaticHashTable1 is looking for a Eager Tensor where as you provided a Symbolic Tensor. Please check the source [here](https://www.tensorflow.org/api_docs/python/tf/lookup/StaticHashTable#lookup). Thanks!\r\n", "Currently, Tensorflow Lite does not support Keras layer + hash table use cases yet. I am working on enabling this path. Will notify the updates in the thread later.", "@jvishnuvardhan \r\nThis is my use case: I am trying to construct and save a model architecture where the first layer should be a lookup operation. If I am forced to use an EagerTensor, does this mean that what I am trying to achieve with the StaticHashTable is impossible?\r\n\r\nIn [the link to the documentation you sent me](https://www.tensorflow.org/api_docs/python/tf/lookup/StaticHashTable#lookup) I don't see any indication that the lookup operation is supposed to **not** handle symbolic tensors:\r\n> [keys: Keys to look up. May be either a SparseTensor or dense Tensor.](https://www.tensorflow.org/api_docs/python/tf/lookup/StaticHashTable#lookup)\r\n\r\nWhat am I missing?\r\n\r\n@abattery \r\nAre you saying that your work will possibly fix my issue also? Note that I am not working with Tensorflow Lite here.", "`InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.`\r\n\r\n@jeanmn Yes, this error is related to the same problem I mentioned in the above comment.", "You  may want to label the issue with `TF 2.2` because this error also shows up with the TensorFlow version `2.2.0rc3`", "Same issue here, when I try build Keras model based on my graph:\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras.layers import  Input\r\nfrom tensorflow.keras import Model\r\nimport numpy as np\r\ntf.keras.backend.clear_session()\r\n\r\nin3 = tf.keras.Input(shape=(1,), name=\"in3\", dtype=tf.string)\r\nkeys_tensor = tf.constant([\"A\", \"B\"])\r\nvals_tensor = tf.constant([9, 10])\r\ntable = tf.lookup.StaticHashTable(\r\n    tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor)\r\n    , -1)\r\nout = table.lookup(in3)\r\nmodel = Model(inputs=[in3], outputs=out)\r\nmodel.summary()\r\n```\r\nIt looks that the problem is with the Tensor: \r\n`Tensor(\"None_Lookup/LookupTableFindV2/table_handle:0\", shape=(), dtype=resource)`\r\nas it can't be simply converted to `numpy` \r\n", "The following sample code worked in tensorflow 2.1 & 2.2 - \r\n\r\nMain point is to extend keras layer object & use lookup operation inside that.\r\nHere's the sample code - https://gist.github.com/jithinjees/a99e57af3812be2c84bdc2ef84ad0de6 \r\nIn the link above i have listed lookup using 2 different classes, 1 is file based lookup & other one is an in-memory list based lookup.\r\nFor the file based lookup the input file used is a text file which contains one word per line\r\n\r\nHere's a gist of that code - \r\n\r\n```python\r\nclass VocabLookup(tf.keras.layers.Layer):\r\n    def __init__(self,vocab_path):\r\n        super(VocabLookup, self).__init__(trainable=False,dtype=tf.int64)\r\n        self.vocab_path = vocab_path\r\n    def build(self,input_shape):\r\n        table_init = tf.lookup.TextFileInitializer(self.vocab_path,tf.string,tf.lookup.TextFileIndex.WHOLE_LINE,\r\n                              tf.int64,tf.lookup.TextFileIndex.LINE_NUMBER)\r\n        self.table = tf.lookup.StaticHashTable(table_init,-1)\r\n        self.built=True\r\n        \r\n    def call(self, input_text):\r\n        splitted_text = tf.strings.split(input_text).to_tensor()\r\n        word_ids = self.table.lookup(splitted_text)\r\n        return word_ids\r\n    \r\n    def get_config(self):\r\n        config = super(VocabLookup, self).get_config()\r\n        config.update({'vocab_path': self.vocab_path})\r\n        return config \r\ninput_text = tf.keras.Input(shape=(),dtype=tf.string,name='input_text')\r\nlookup_out = VocabLookup(vocab_path=vocab_path)(input_text)\r\nmodel_lookup = tf.keras.Model(inputs={'input_text':input_text},outputs=lookup_out)\r\n\r\n```\r\n\r\nHope this helps", "I had the same issue when i use TF2.0.0, here is my sample code. Although I made it worked in layer object, but I still want it simply used in keras API.\r\n```python\r\nkeys_tensor = tf.constant(range(27), tf.int64)\r\nvals_tensor = tf.constant([0]*11+[1]*9+[2]*6+[3], tf.int64)\r\ntable = tf.lookup.StaticHashTable(\r\n    tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), -1)\r\n\r\ninputs = layers.Input(shape=(4))\r\ninputs1 = layers.Input(shape=(4))\r\nx = layers.Dense(4)(inputs)\r\nmodel = keras.Model([inputs,inputs1], x)\r\n\r\nkey = tf.argmax(inputs1, axis=1)\r\nmatches = table.lookup((key))\r\nmatches = tf.one_hot(matches, depth=4)\r\nloss = K.categorical_crossentropy(matches, inputs1)\r\n\r\nmodel.add_loss(loss)\r\nmodel.compile(optimizer=keras.optimizers.Adam(1e-3))\r\n\r\nx_train = tf.ones(shape=[2,4])\r\ny_train = tf.constant([[0,0,0,1],[0,0,1,0]])\r\nmodel.fit([x_train, y_train])\r\n```", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210525, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/7f227fa8ae315a91e96a09ee83ce3a2e/untitled7.ipynb). Thanks!", "@jithinjees were you able to use this to serve the model?", "@wangruinju yes, not exactly the same one, but another model using the same approach of creating a tf.lookup.StaticHashTable", "Hi @jeanmn! I was able to resolve this issue by disabling eager execution . Attaching [Gist ](https://colab.research.google.com/gist/mohantym/ba9425657d843665f7952c873e981565/tf-lookup-statichhashtable-cannot-convert-a-tensor-of-dtype-resource-to-a-numpy-array.ipynb#scrollTo=nhOuA0OCOk14)for reference. Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38305\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38305\">No</a>\n"]}, {"number": 38304, "title": "revert the gitignore due to build failure", "body": "Hi, the .gitignore cannot resolve ```/tensorflow/lite/**/[ios|objc|swift]*/BUILD``` this code but ignore all BUILD file in /tensorflow/lite/**, and it will lead to build failure when I push the code to my repo and pull it again to build.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38304) for more info**.\n\n<!-- need_sender_cla -->", "@ahuizxc Thank you for your contribution. Can you please sign CLA? Thanks!", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38304) for more info**.\n\n<!-- ok -->", "This should be against master", "Oh, it already exists in master."]}, {"number": 38302, "title": "How to get libhexagon_interface.so for non Android OS (e.g. arm linux)?", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source): 2.2-rc2\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Qualcomm 845 SOC\r\n\r\n**Describe the problem**\r\nTry to get hexagon delegate working on qualcomm 845 soc with arm linux environment. The official supported hexagon delegate only works on Android and the provided libhexagon_interface.so links to Android libraries like liblog.so etc. Could you provide a libhexagon_interface.so that supports pure arm linux? Or could you provide documentation how to build libhexagon_interface.so if I have hexagon sdk from qualcomm downloaded?\r\n\r\nThanks!\r\n\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": ["Hi @cjluo-nuro, \r\n\r\nCan you provide what toolchain do you need for building the delegate, so we make sure the provided libhexagon_interface.so is the same.\r\na bazel command for building the delegate.\r\n\r\nLong term, we are working with QC to make sure we can put the code, currently we can't because of licensing.\r\n\r\nThanks", "Hi, Karim, I use clang-8 with ubuntu arm environment (GCC 7.3) to build the delegate. ubuntu arm does not have android libraries. For example, the available libraries the delegate binary linked to are:\r\n\r\n 0x0000000000000001 (NEEDED)             Shared library: [libpthread.so.0]\r\n 0x0000000000000001 (NEEDED)             Shared library: [libm.so.6]\r\n 0x0000000000000001 (NEEDED)             Shared library: [libdl.so.2]\r\n 0x0000000000000001 (NEEDED)             Shared library: [librt.so.1]\r\n 0x0000000000000001 (NEEDED)             Shared library: [libstdc++.so.6]\r\n 0x0000000000000001 (NEEDED)             Shared library: [libgcc_s.so.1]\r\n 0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]\r\n 0x0000000000000001 (NEEDED)             Shared library: [ld-linux-aarch64.so.1]\r\n", "Friendly ping @karimnosseir ?", "@cjluo-nuro \r\nSorry for the delay, was trying to find a way for testing (wasn't successful yet).\r\nDo you mind reaching privately with details on the hardware used, if you don't mind i want to send you a version to try.\r\n\r\nThanks\r\n\r\nEDIT: Wasn't successful to find a device to test on it.", "Thanks @karimnosseir. Is this your LDAP?", "Yes", "Thanks just shoot you an email", "Received the lib from @karimnosseir and it works on my dev board."]}, {"number": 38301, "title": "refactoring: early return 'if else' -> 'if'", "body": "For early return, I think 'only if' syntax is better than 'if elif' syntax.", "comments": []}, {"number": 38300, "title": "Master build failed with user local specific GCC", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Both `CentsOS 7.3` and `Ubuntu 18.04` \r\n- TensorFlow installed from (source or binary): build from source\r\n- TensorFlow version: master (f32548266f25890fc654342296dc112f26ad9bf6)\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): GCC 6.3\r\n\r\n\r\n**Describe the problem**\r\n\r\n**After the upgrade of protobuf, we can't use the user local GCC to build TF master branch**\r\nI have already set the `env` for specified GCC as below\r\n```\r\nexport PATH=\"/home/chuanqiw/lib/gcc-build-6.3.0/bin:$PATH\"\r\nexport LD_LIBRARY_PATH=\"/home/chuanqiw/lib/gcc-build-6.3.0/lib64:$LD_LIBRARY_PATH\"\r\n```\r\nBuild command I used:\r\n`bazel build --config=mkl --define=build_with_mkl_dnn_v1_only=true --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512pf --copt=-mavx512cd --copt=-mavx512bw --copt=-mavx512dq --copt=-DENABLE_INTEL_MKL_BFLOAT16 -c opt //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n**Any other info / logs**\r\n```\r\nERROR: /home/chuanqiw/tensorflow/gitlab/private-tensorflow/tensorflow/core/data/service/BUILD:308:1: Action tensorflow/core/data/service/worker.grpc.pb.h failed (Exit 1)\r\nbazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)\r\nbazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)\r\nbazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)\r\nbazel-out/host/bin/external/com_google_protobuf/protoc: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by bazel-out/host/bin/external/com_google_protobuf/protoc)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/chuanqiw/tensorflow/gitlab/private-tensorflow/tensorflow/lite/toco/python/BUILD:77:1 Action tensorflow/core/data/service/worker.grpc.pb.h failed (Exit 1)\r\nINFO: Elapsed time: 996.555s, Critical Path: 102.83s\r\nINFO: 8409 processes: 8409 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "comments": ["Hi @gadagashwini, it isn't a MKL specific issue, this failure also appeared in Eigen build. Sorry for the misleading. \r\nYou also can reproduce it with below build command\r\n`bazel build --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512pf --copt=-mavx512cd --copt=-mavx512bw --copt=-mavx512dq -c opt //tensorflow/tools/pip_package:build_pip_package`", "Hi @angerson and @gadagashwini , may I know the status of this issue?", "@chuanqi129  i also meet this error, have you resolved it?", "Hi @gyshi , can't resolve it, just upgrade the system native GCC version", "Hi @gadagashwini this is not only a centos issue, but also for ubuntu. I know maybe the centos has low priority", "> Hi @gyshi , can't resolve it, just upgrade the system native GCC version\r\n\r\nthx, i will try it", "@gyshi you can also try this instruction: https://gist.github.com/jakublipinski/40ba68994fe0092600a05b0060e7d445", "@chuanqi129 \r\nAs we have the latest stable version 2.6.0, Can you try building TF 2.6.0 and let us know if this is still an issue.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38300\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38300\">No</a>\n"]}, {"number": 38299, "title": "refactoring: 'if' syntax deduplication", "body": "I changed the existing code with the phrase if else to one line.\r\nThank you for creating a great project.", "comments": []}, {"number": 38298, "title": "ERROR: Did not get operators, tensors, or buffers in subgraph 0.", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- Tensorflow version (commit SHA if source): 2.01\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Android\r\n\r\n**Describe the problem**\r\nWhile loading the interpreter from to read the detect.tflite file i'm getting the following error. The link to the model file is https://drive.google.com/open?id=1xxMLG1JLB_6ssCJ8xMOhtJGZo1P_dewc\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nThe detect.tflite file and the respective frozen graph is hereby i'm attaching. \r\nAlso, the code to read the same is as follows:\r\n\r\n#include <math.h>\r\n#include <stdio.h>\r\n\r\n#include <algorithm>\r\n#include <chrono>\r\n#include <fstream>\r\n#include <memory>\r\n#include <string>\r\n#include <vector>\r\n\r\n//#include <gflags/gflags.h>\r\n#include <glog/logging.h>\r\n#include <tensorflow/lite/delegates/gpu/gl_delegate.h>\r\n#include <tensorflow/lite/kernels/register.h>\r\n#include <tensorflow/lite/model.h>\r\n#include <opencv2/core.hpp>\r\n#include <opencv2/imgcodecs.hpp>\r\n#include <opencv2/imgproc.hpp>\r\n\r\n//#include \"test_video.hpp\"\r\n//#include \"video_encoder.hpp\"\r\n#include \"config_parser.h\"\r\n#include \"lane_detection.h\"\r\n\r\n#define IMAGE_MEAN 128.0f\r\n#define IMAGE_STD 128.0f\r\n\r\ntemplate <typename T>\r\nT* TensorData(TfLiteTensor* tensor, int batch_index);\r\n\r\ntemplate <>\r\nfloat* TensorData(TfLiteTensor* tensor, int batch_index) {\r\n  int nelems = 1;\r\n  for (int i = 1; i < tensor->dims->size; i++)\r\n    nelems *= tensor->dims->data[i];\r\n  switch (tensor->type) {\r\n    case kTfLiteFloat32:\r\n      return tensor->data.f + nelems * batch_index;\r\n    default:\r\n      LOG(FATAL) << \"Should not reach here!\";\r\n  }\r\n  return nullptr;\r\n}\r\n\r\ntemplate <>\r\nuint8_t* TensorData(TfLiteTensor* tensor, int batch_index) {\r\n  int nelems = 1;\r\n  for (int i = 1; i < tensor->dims->size; i++)\r\n    nelems *= tensor->dims->data[i];\r\n  switch (tensor->type) {\r\n    case kTfLiteUInt8:\r\n      return tensor->data.uint8 + nelems * batch_index;\r\n    default:\r\n      LOG(FATAL) << \"Should not reach here!\";\r\n  }\r\n  return nullptr;\r\n}\r\n\r\nbool LaneDetection::init(const ConfigParser& config, bool is_quantized) {\r\n  using config_content = std::map<std::string, std::string>;\r\n  config_content config_section;\r\n\r\n  LOGI(\"LaneDetect: reading config\");\r\n  std::cout << \"LaneDetect: reading config\" << std::endl;\r\n  try {\r\n    config_section = config[\"LaneNet\"];\r\n  } catch (const std::out_of_range& e) {\r\n    LOGE(e.what());\r\n    LOGE(\r\n        \"Can not get LaneNet section content in config file, please \"\r\n        \"check again\");\r\n    _m_successfully_initialized = false;\r\n    return false;\r\n  }\r\n\r\n  if (config_section.find(\"dbscan_neighbor_radius\") == config_section.end()) {\r\n    LOGE(\"Can not find \\\"dbscan_neighbor_radius\\\" field in config section\");\r\n    _m_successfully_initialized = false;\r\n    return false;\r\n  } else {\r\n    _m_dbscan_eps = std::stof(config_section[\"dbscan_neighbor_radius\"]);\r\n  }\r\n\r\n  if (config_section.find(\"dbscan_core_object_min_pts\") ==\r\n      config_section.end()) {\r\n    LOGE(\r\n        \"Can not find \\\"dbscan_core_object_min_pts\\\" field in config \"\r\n        \"section\");\r\n    _m_successfully_initialized = false;\r\n    return false;\r\n  } else {\r\n    _m_dbscan_min_pts =\r\n        std::atoi(config_section[\"dbscan_core_object_min_pts\"].c_str());\r\n  }\r\n\r\n  if (config_section.find(\"pix_embedding_feature_dims\") ==\r\n      config_section.end()) {\r\n    LOGE(\r\n        \"Can not find \\\"pix_embedding_feature_dims\\\" field in config \"\r\n        \"section\");\r\n    _m_successfully_initialized = false;\r\n    return false;\r\n  } else {\r\n    _m_lanenet_pix_embedding_feature_dims =\r\n        std::atoi(config_section[\"pix_embedding_feature_dims\"].c_str());\r\n  }\r\n\r\n  if (config_section.find(\"model_file_path\") == config_section.end()) {\r\n    LOGE(\"Can not find \\\"model_file_path\\\" field in config section\");\r\n    _m_successfully_initialized = false;\r\n    return false;\r\n  } else {\r\n    _m_lanenet_model_file_path = config_section[\"model_file_path\"];\r\n  }\r\n\r\n  LOGI(\"LaneDetect: read config file\");\r\n  std::cout << \"LaneDetect: read config file\" << std::endl;\r\n\r\n  ///////////////////////////////\r\n  model_ = tflite::FlatBufferModel::BuildFromFile(\r\n      _m_lanenet_model_file_path.c_str());\r\n  if (!model_) {\r\n    LOGI(\"LaneDetect: Failed to load model: %s\",\r\n         _m_lanenet_model_file_path.c_str());\r\n    std::cout << \"LaneDetect: Failed to load model: \"\r\n              << _m_lanenet_model_file_path << std::endl;\r\n    return false;\r\n  }\r\n\r\n  // Create interpreter.\r\n  tflite::ops::builtin::BuiltinOpResolver resolver;\r\n  tflite::InterpreterBuilder(*model_, resolver)(&interpreter_);\r\n  if (!interpreter_) {\r\n    LOGI(\"LaneDetect: Failed to create interpreter!\");\r\n    std::cout << \"LaneDetect: Failed to create interpreter!\" << std::endl;\r\n    return false;\r\n  }\r\n  /* if (interpreter_->AllocateTensors() != kTfLiteOk)\r\n  {\r\n      LOG(ERROR) << \"Failed to allocate tensors!\";\r\n      return false;\r\n  } */\r\n  interpreter_->SetNumThreads(1);\r\n\r\n  const TfLiteGpuDelegateOptions options = {\r\n      .metadata = NULL,\r\n      .compile_options =\r\n          {\r\n              .precision_loss_allowed = 1,  // FP16\r\n              .preferred_gl_object_type = TFLITE_GL_OBJECT_TYPE_FASTEST,\r\n              .dynamic_batch_enabled = 0,  // Not fully functional yet\r\n          },\r\n  };\r\n  auto* delegate = TfLiteGpuDelegateCreate(&options);\r\n  if (interpreter_->ModifyGraphWithDelegate(delegate) != kTfLiteOk) {\r\n    interpreter_->UseNNAPI(true);\r\n    LOGI(\"LaneDetect: gpu delegate failed ! adding nnAPI support\");\r\n    std::cout << \"LaneDetect: gpu delegate failed ! adding nnAPI support\"\r\n              << std::endl;\r\n  }\r\n\r\n  // Find input tensors.\r\n  if (interpreter_->inputs().size() != 1) {\r\n    LOGI(\"LaneDetect: Graph needs to have 1 and only 1 input!\");\r\n    std::cout << \"LaneDetect: Graph needs to have 1 and only 1 input!\"\r\n              << std::endl;\r\n    return false;\r\n  }\r\n  input_tensor_ = interpreter_->tensor(interpreter_->inputs()[0]);\r\n  if (is_quantized) {\r\n    if (input_tensor_->type != kTfLiteUInt8) {\r\n      LOGI(\"LaneDetect: Quantized graph's input should be kTfLiteUInt8!\");\r\n      std::cout << \"LaneDetect: Quantized graph's input should be kTfLiteUInt8!\"\r\n                << std::endl;\r\n      return false;\r\n    }\r\n  } else {\r\n    if (input_tensor_->type != kTfLiteFloat32) {\r\n      LOGI(\"LaneDetect: Quantized graph's input should be kTfLiteFloat32!\");\r\n      std::cout\r\n          << \"LaneDetect: Quantized graph's input should be kTfLiteFloat32!\"\r\n          << std::endl;\r\n      return false;\r\n    }\r\n  }\r\n\r\n  // Find output tensors.\r\n  if (interpreter_->outputs().size() != 2) {\r\n    LOGI(\r\n        \"LaneDetect: Graph needs to have 2 and only 2 outputs! It has %d \"\r\n        \"outputs though!!!\",\r\n        interpreter_->outputs().size());\r\n    std::cout << \"LaneDetect: Graph needs to have 2 and only 2 outputs! It has \"\r\n              << interpreter_->outputs().size() << \" outputs though!!!\"\r\n              << std::endl;\r\n    return false;\r\n  }\r\n  output_binary_mask_ = interpreter_->tensor(interpreter_->outputs()[0]);\r\n  output_instance_mask_ = interpreter_->tensor(interpreter_->outputs()[1]);\r\n\r\n  _m_input_node_size_host.width = width();\r\n  _m_input_node_size_host.height = height();\r\n\r\n  return true;\r\n}\r\n\r\nvoid LaneDetection::preprocess(const cv::Mat& input_image,\r\n                               cv::Mat& output_image) {\r\n  if (input_image.type() != CV_32FC3) {\r\n    input_image.convertTo(output_image, CV_32FC3);\r\n  } else {\r\n    input_image.copyTo(output_image);\r\n  }\r\n  // BGR2RGB\r\n  cv::cvtColor(output_image, output_image, cv::COLOR_BGR2RGB);\r\n\r\n  LOGI(\"LaneDetect: output image size : %d x %d  check size : %d x %d\",\r\n       output_image.size().width, output_image.size().height,\r\n       _m_input_node_size_host.width, _m_input_node_size_host.height);\r\n\r\n  // resizing to the input size of the model\r\n  if (output_image.size() != _m_input_node_size_host) {\r\n    cv::resize(output_image, output_image, _m_input_node_size_host);\r\n  }\r\n\r\n  // // making mean 0 and range 2\r\n  // cv::divide(output_image, cv::Scalar(127.5, 127.5, 127.5), output_image);\r\n  // cv::subtract(output_image, cv::Scalar(1.0, 1.0, 1.0), output_image);\r\n  return;\r\n}\r\n\r\nvoid LaneDetection::FeedInMat(const cv::Mat& mat, int batch_index) {\r\n  switch (input_tensor_->type) {\r\n    case kTfLiteFloat32: {\r\n      float* dst = TensorData<float>(input_tensor_, batch_index);\r\n      const int row_elems = width() * input_channels();\r\n      for (int row = 0; row < height(); row++) {\r\n        const uchar* row_ptr = mat.ptr(row);\r\n        for (int i = 0; i < row_elems; i++) {\r\n          dst[i] = (row_ptr[i] - IMAGE_MEAN) / IMAGE_STD;\r\n        }\r\n        dst += row_elems;\r\n      }\r\n    } break;\r\n    case kTfLiteUInt8: {\r\n      uint8_t* dst = TensorData<uint8_t>(input_tensor_, batch_index);\r\n      const int row_elems = width() * input_channels();\r\n      for (int row = 0; row < height(); row++) {\r\n        memcpy(dst, mat.ptr(row), row_elems);\r\n        dst += row_elems;\r\n      }\r\n    } break;\r\n    default:\r\n      LOG(FATAL) << \"Should not reach here!\";\r\n  }\r\n}\r\n\r\nvoid LaneDetection::detect(cv::Mat& image,\r\n                           cv::Mat& binary_seg_result,\r\n                           cv::Mat& instance_seg_result) {\r\n  // preprocess\r\n  cv::Mat input_image_copy;\r\n  preprocess(image, input_image_copy);\r\n\r\n  FeedInMat(input_image_copy, 0);\r\n  if (interpreter_->Invoke() != kTfLiteOk) {\r\n    LOGI(\"LaneDetect: Unable to invoke TfLite\");\r\n    return;\r\n  }\r\n  std::cout << \"Lane detection ran successfully\" << std::endl;\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["any solution?", "@shauryad15 This is a micro related issue,Please post this in [micro repository](https://github.com/tensorflow/tflite-micro/issues)  we will get you the right help..Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38298\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38298\">No</a>\n"]}, {"number": 38297, "title": "Cant install tensorflow", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):Pip\r\n- TensorFlow version:2.1.0\r\n- Python version:3.7\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI cant install tensorflow. It says that an error occured and tensorflow isn't found. \r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npython pip install tensorflow\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@generationzcode \r\n\r\nCan you please go through instructions mentioned in [Tensorflow website](https://www.tensorflow.org/install/pip). You can install by `pip install tensorflow`. If you are still facing any issue please, share error log. Thanks!", "I did that. I've done it like 5 or six times... I tried installing it from the URL for the wheel. It didn't work either", "Ok\r\nI'll share the error statement", "`ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n`", "@generationzcode \r\n\r\nCan you please go through the [link](https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip) and see if it helps you. Thanks!", "I've been struggling with this for a few weeks. Thanks @ravikyram  for your help. I figured it out. Anyone else looking at this issue, the answer is installing a 64 bit version of python. :)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38297\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38297\">No</a>\n"]}, {"number": 38296, "title": "tf.keras custom layer does not use \"compute_output_shape\"", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): \r\n- Python version: v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: `Driver Version: 440.33.01    CUDA Version: 10.2`\r\n- GPU model and memory: GTX 1080 Ti 11162MiB ram\r\n\r\n**Describe the current behavior**\r\n\r\nWhen implementing a custom layer where the output shape is not computable directly from the code within the `call` method, the `compute_output_shape` function is _not_ used to determine the output shape.\r\n\r\nThis causes issues when passing to a layer which must know some of the shape, e.g. a `Conv*D` layer which needs to know the number of channels ahead of time.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe `compute_output_shape` function _is_ used to determine the output shape.\r\n\r\n**Standalone code to reproduce the issue** \r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\nclass Spectrogram(tf.keras.layers.Layer):\r\n    def __init__(self, num_freqs, max_freq, **kwargs):\r\n        super(Spectrogram, self).__init__(**kwargs)\r\n\r\n        self.num_freqs = num_freqs\r\n        self.max_freq = max_freq\r\n\r\n        self.input_spec = [\r\n            tf.keras.layers.InputSpec(ndim=2), tf.keras.layers.InputSpec(ndim=2)\r\n        ]\r\n\r\n    def call(self, x_fs):\r\n        x, fs = x_fs\r\n        nfft = tf.cast(\r\n            fs[0,0] * (self.num_freqs - 1) / self.max_freq,\r\n            tf.int32\r\n        )\r\n        y = tf.signal.stft(x, nfft, 256, nfft, pad_end=True)\r\n        y = tf.sqrt(tf.abs(y))[:, :, :self.num_freqs]\r\n        return y\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return (input_shape[0], None, self.num_freqs)\r\n\r\n\r\nsignal = tf.keras.layers.Input(shape=(None,))\r\nfs = tf.keras.layers.Input(shape=(1,))\r\nx = Spectrogram(257, 10_000)([signal, fs])\r\ny = tf.keras.layers.Conv1D(16, 3)(x)\r\n\r\ntf.keras.models.Model([signal, fs], [y]).summary()\r\n```\r\n\r\n**Logs**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"chorus/repro.py\", line 32, in <module>\r\n    y = tf.keras.layers.Conv1D(16, 3)(x)\r\n  File \"/home/kevin/.pyenv/versions/chorus/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 897, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/home/kevin/.pyenv/versions/chorus/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 2416, in _maybe_build\r\n    self.build(input_shapes)  # pylint:disable=not-callable\r\n  File \"/home/kevin/.pyenv/versions/chorus/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 153, in build\r\n    input_channel = self._get_input_channel(input_shape)\r\n  File \"/home/kevin/.pyenv/versions/chorus/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 293, in _get_input_channel\r\n    raise ValueError('The channel dimension of the inputs '\r\nValueError: The channel dimension of the inputs should be defined. Found `None`.\r\n```\r\n\r\n**Other info**\r\n\r\nThis was originally opened in #19961 but was unfortunately closed as \"not a bug\", but I'm pretty sure this is not expected behavior according to the [keras docs](https://keras.io/layers/writing-your-own-keras-layers/).", "comments": ["Was able to reproduce the issue with [TF v2.2.0rc2](https://colab.research.google.com/gist/amahendrakar/ed24e7ab568037a258a2d8bdc1dad4ef/38296.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/2560e0070f5e2390f3a088d578106ac9/38296-tf-nightly.ipynb). Please find the attached gist. Thanks!", "This is a difference between tf.keras and the older OSS keras releases.\r\n\r\nAs an immediate stop-gap you should be able to manually set the output shape on the tensor and be okay, e.g.\r\n```\r\n        y = tf.sqrt(tf.abs(y))[:, :, :self.num_freqs]\r\n        y.set_shape(self.compute_output_shape(x.shape))\r\n        return y\r\n```\r\n\r\nCurrently tf.keras uses compute_output_shape to set the output shape *only* when layers are dynamic and can only be run eagerly.\r\n\r\nIn the medium-term we need to figure out whether it makes sense for Keras to automatically set the output shape to the result of compute_output_shape whenever compute_output_shape is implemented, rather than just for dynamic layers.\r\n", "@kbrose \r\n\r\nwas this resolved by following @tomerk  suggestion? Please close the issue if it was resolved already. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> In the medium-term we need to figure out whether it makes sense for Keras to automatically set the output shape to the result of compute_output_shape whenever compute_output_shape is implemented, rather than just for dynamic layers.\r\n\r\nThis sounds to me like we shouldn't be closing the issue whether or not the stop gap works. What do you think @ravikyram ?", "@kbrose as mentioned by @tomerk in the above comment, Keras computes the output shape of only dynamic layers, and you can use set_shape in scenarios where you want to control the output shape. \r\nThe [keras docs ](https://keras.io/guides/making_new_layers_and_models_via_subclassing/) you referenced above also been updated. \r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38296\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38296\">No</a>\n"]}]