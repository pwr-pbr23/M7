[{"number": 40214, "title": "Fix floating point exception with tf.unravel_index", "body": "This PR tries to address the issue raised in #40204 where\r\n`tf.unravel_index` caused floating point exception when any one\r\nelement is 0 in `dims`.\r\n\r\nThe issue is that `indices` in `tf.unravel_index` should make sure\r\nit is not out of boundary compared to `dims`.\r\n\r\nThis PR fixes the issue by adding a check before hand, though Eigen.\r\n\r\nThis PR fixes #40204.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @ezhulenev for the review. The PR has been updated. Please take a look."]}, {"number": 40213, "title": "\"tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\" on aarch64", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below):1.15.0\r\n- Python version:2.7\r\n- Bazel version (if compiling from source):0.26.0\r\n- GCC/Compiler version (if compiling from source):7.4.0\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory:no\r\n\r\n**Describe the current behavior**\r\n\r\nI used [tensorflow/benchmark](https://github.com/tensorflow/benchmarks) to train resnet50 by [tf_cnn_benchmarks.py](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py) on my aarch64 platform.\r\ncommand line:\r\npython tf_cnn_benchmarks.py --device=cpu --data_format=NHWC --optimizer=sgd --distortions=false --variable_update=replicated --data_dir=/opt/imagenet/tf_train --data_name=imagenet --model=resnet50 --batch_size=32 --train_dir=/opt/data/resnet50_ckpt/cpu_v1/  --num_epochs=10--save_model_steps=20\r\n\r\n\r\n**Describe the expected behavior**\r\nAfter training thousands batchs raise \"tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\"\r\n\r\n> INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Retval[0] does not have value\r\nI0605 18:58:49.349148 281473050139600 coordinator.py:224] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Retval[0] does not have value\r\nTraceback (most recent call last):\r\n  File \"tf_cnn_benchmarks.py\", line 73, in <module>\r\n    app.run(main)  # Raises error on invalid flags, unlike tf.app.run()\r\n  File \"/root/.env/tf2.0.0/lib/python2.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/root/.env/tf2.0.0/lib/python2.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"tf_cnn_benchmarks.py\", line 68, in main\r\n    bench.run()\r\n  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1880, in run\r\n    return self._benchmark_train()\r\n  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 2085, in _benchmark_train\r\n    return self._benchmark_graph(result_to_benchmark, eval_build_results)\r\n  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 2294, in _benchmark_graph\r\n    is_chief, summary_writer, profiler)\r\n  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 2430, in benchmark_with_session\r\n    collective_graph_key=collective_graph_key)\r\n  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 869, in benchmark_one_step\r\n    results = sess.run(fetches, options=run_options, run_metadata=run_metadata)\r\n  File \"/root/.env/tf2.0.0/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"/root/.env/tf2.0.0/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/root/.env/tf2.0.0/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/root/.env/tf2.0.0/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\r\n\r\n", "comments": ["@Danliran \r\n\r\nRequest you share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "> @Danliran\r\n> \r\n> Request you share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!\r\n\r\n@ravikyram thanks for response. tf_cnn_benchmarks.py\r\n https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \r\nhere is command to training resnet50 from tensorflow/benchmarks guideline. \r\npython tf_cnn_benchmarks.py --device=cpu --data_format=NHWC --optimizer=sgd --distortions=false --variable_update=replicated --data_dir=/opt/imagenet/tf_train --data_name=imagenet --model=resnet50 --batch_size=32 --train_dir=/opt/data/resnet50_ckpt/cpu_v1/ --num_epochs=10--save_model_steps=20", "@ravikyram @gowthamkpr strace log about training, hope it can help you.\r\n\r\n> openat(AT_FDCWD, \"tf_cnn_benchmarks.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=2476, ...}) = 0\r\nread(3, \"# Copyright 2017 The TensorFlow \"..., 4096) = 2476\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"app.run(main)  # Raises error on\"..., 68app.run(main)  # Raises error on invalid flags, unlike tf.app.run()\r\n) = 68\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/root/.env/tf1.15/lib/py\"..., 85  File \"/root/.env/tf1.15/lib/python2.7/site-packages/absl/app.py\", line 299, in run\r\n) = 85\r\nopenat(AT_FDCWD, \"/root/.env/tf1.15/lib/python2.7/site-packages/absl/app.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=14864, ...}) = 0\r\nread(3, \"# Copyright 2017 The Abseil Auth\"..., 4096) = 4096\r\nread(3, \"ilar to HelpfullFlag, but genera\"..., 4096) = 4096\r\nread(3, \"\\n        logging.error(traceback\"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"_run_main(main, args)\\n\", 22_run_main(main, args)\r\n) = 22\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/root/.env/tf1.15/lib/py\"..., 91  File \"/root/.env/tf1.15/lib/python2.7/site-packages/absl/app.py\", line 250, in _run_main\r\n) = 91\r\nopenat(AT_FDCWD, \"/root/.env/tf1.15/lib/python2.7/site-packages/absl/app.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=14864, ...}) = 0\r\nread(3, \"# Copyright 2017 The Abseil Auth\"..., 4096) = 4096\r\nread(3, \"ilar to HelpfullFlag, but genera\"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"sys.exit(main(argv))\\n\", 21sys.exit(main(argv))\r\n)  = 21\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"tf_cnn_benchmarks.py\\\", l\"..., 48  File \"tf_cnn_benchmarks.py\", line 68, in main\r\n) = 48\r\nopenat(AT_FDCWD, \"tf_cnn_benchmarks.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=2476, ...}) = 0\r\nread(3, \"# Copyright 2017 The TensorFlow \"..., 4096) = 2476\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"bench.run()\\n\", 12bench.run()\r\n)           = 12\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/home/tf/benchma\"..., 99  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1880, in run\r\n) = 99\r\nopenat(AT_FDCWD, \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=164060, ...}) = 0\r\nread(3, \"# Copyright 2017 The TensorFlow \"..., 4096) = 4096\r\nread(3, \"\\n#   the forward-only option, wh\"..., 4096) = 4096\r\nread(3, \"            'The autotune thresh\"..., 4096) = 4096\r\nread(3, \"                'the number of s\"..., 4096) = 4096\r\nread(3, \"ed, after the graph has been par\"..., 4096) = 4096\r\nread(3, \" maximum number of GPU Ops that \"..., 4096) = 4096\r\nread(3, \"or the MultiDeviceIterator that \"..., 4096) = 4096\r\nread(3, \"INE_integer('kmp_settings', 1,\\n \"..., 4096) = 4096\r\nread(3, \"            'collective_all_redu\"..., 4096) = 4096\r\nread(3, \"s.')\\nflags.DEFINE_integer('save_\"..., 4096) = 4096\r\nread(3, \"pointNotFoundException(Exception\"..., 4096) = 4096\r\nread(3, \"params.eval_during_training_at_s\"..., 4096) = 4096\r\nread(3, \"filename, ''\\n      as_text = fil\"..., 4096) = 4096\r\nread(3, \"\\n                         (name,\"..., 4096) = 4096\r\nread(3, \"loat(piece))\\n      except ValueE\"..., 4096) = 4096\r\nread(3, \"tf.train.RMSPropOptimizer(\\n     \"..., 4096) = 4096\r\nread(3, \"rning_rate_decay_factor)):\\n     \"..., 4096) = 4096\r\nread(3, \"d not self.params.datasets_use_p\"..., 4096) = 4096\r\nread(3, \".sync_queue_devices = [self.para\"..., 4096) = 4096\r\nread(3, \"eter_server'):\\n      raise Value\"..., 4096) = 4096\r\nread(3, \"onstants.BenchmarkMode.TRAIN_AND\"..., 4096) = 4096\r\nread(3, \"d batches per prepocessing group\"..., 4096) = 4096\r\nread(3, \"ame: %s' % self.params.job_name)\"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"return self._benchmark_train()\\n\", 31return self._benchmark_train()\r\n) = 31\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/home/tf/benchma\"..., 112  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 2085, in _benchmark_train\r\n) = 112\r\nopenat(AT_FDCWD, \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=164060, ...}) = 0\r\nread(3, \"# Copyright 2017 The TensorFlow \"..., 4096) = 4096\r\nread(3, \"\\n#   the forward-only option, wh\"..., 4096) = 4096\r\nread(3, \"            'The autotune thresh\"..., 4096) = 4096\r\nread(3, \"                'the number of s\"..., 4096) = 4096\r\nread(3, \"ed, after the graph has been par\"..., 4096) = 4096\r\nread(3, \" maximum number of GPU Ops that \"..., 4096) = 4096\r\nread(3, \"or the MultiDeviceIterator that \"..., 4096) = 4096\r\nread(3, \"INE_integer('kmp_settings', 1,\\n \"..., 4096) = 4096\r\nread(3, \"            'collective_all_redu\"..., 4096) = 4096\r\nread(3, \"s.')\\nflags.DEFINE_integer('save_\"..., 4096) = 4096\r\nread(3, \"pointNotFoundException(Exception\"..., 4096) = 4096\r\nread(3, \"params.eval_during_training_at_s\"..., 4096) = 4096\r\nread(3, \"filename, ''\\n      as_text = fil\"..., 4096) = 4096\r\nread(3, \"\\n                         (name,\"..., 4096) = 4096\r\nread(3, \"loat(piece))\\n      except ValueE\"..., 4096) = 4096\r\nread(3, \"tf.train.RMSPropOptimizer(\\n     \"..., 4096) = 4096\r\nread(3, \"rning_rate_decay_factor)):\\n     \"..., 4096) = 4096\r\nread(3, \"d not self.params.datasets_use_p\"..., 4096) = 4096\r\nread(3, \".sync_queue_devices = [self.para\"..., 4096) = 4096\r\nread(3, \"eter_server'):\\n      raise Value\"..., 4096) = 4096\r\nread(3, \"onstants.BenchmarkMode.TRAIN_AND\"..., 4096) = 4096\r\nread(3, \"d batches per prepocessing group\"..., 4096) = 4096\r\nread(3, \"ame: %s' % self.params.job_name)\"..., 4096) = 4096\r\nread(3, \"not None:\\n        # We might rei\"..., 4096) = 4096\r\nread(3, \"f.batch_size)\\n      mlperf.logge\"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"return self._benchmark_graph(res\"..., 70return self._benchmark_graph(result_to_benchmark, eval_build_results)\r\n) = 70\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/home/tf/benchma\"..., 112  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 2294, in _benchmark_graph\r\n) = 112\r\nopenat(AT_FDCWD, \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=164060, ...}) = 0\r\nread(3, \"# Copyright 2017 The TensorFlow \"..., 4096) = 4096\r\nread(3, \"\\n#   the forward-only option, wh\"..., 4096) = 4096\r\nread(3, \"            'The autotune thresh\"..., 4096) = 4096\r\nread(3, \"                'the number of s\"..., 4096) = 4096\r\nread(3, \"ed, after the graph has been par\"..., 4096) = 4096\r\nread(3, \" maximum number of GPU Ops that \"..., 4096) = 4096\r\nread(3, \"or the MultiDeviceIterator that \"..., 4096) = 4096\r\nread(3, \"INE_integer('kmp_settings', 1,\\n \"..., 4096) = 4096\r\nread(3, \"            'collective_all_redu\"..., 4096) = 4096\r\nread(3, \"s.')\\nflags.DEFINE_integer('save_\"..., 4096) = 4096\r\nread(3, \"pointNotFoundException(Exception\"..., 4096) = 4096\r\nread(3, \"params.eval_during_training_at_s\"..., 4096) = 4096\r\nread(3, \"filename, ''\\n      as_text = fil\"..., 4096) = 4096\r\nread(3, \"\\n                         (name,\"..., 4096) = 4096\r\nread(3, \"loat(piece))\\n      except ValueE\"..., 4096) = 4096\r\nread(3, \"tf.train.RMSPropOptimizer(\\n     \"..., 4096) = 4096\r\nread(3, \"rning_rate_decay_factor)):\\n     \"..., 4096) = 4096\r\nread(3, \"d not self.params.datasets_use_p\"..., 4096) = 4096\r\nread(3, \".sync_queue_devices = [self.para\"..., 4096) = 4096\r\nread(3, \"eter_server'):\\n      raise Value\"..., 4096) = 4096\r\nread(3, \"onstants.BenchmarkMode.TRAIN_AND\"..., 4096) = 4096\r\nread(3, \"d batches per prepocessing group\"..., 4096) = 4096\r\nread(3, \"ame: %s' % self.params.job_name)\"..., 4096) = 4096\r\nread(3, \"not None:\\n        # We might rei\"..., 4096) = 4096\r\nread(3, \"f.batch_size)\\n      mlperf.logge\"..., 4096) = 4096\r\nread(3, \"ributed_collective) and\\n        \"..., 4096) = 4096\r\nread(3, \".broadcast_global_variables(0)\\n \"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"is_chief, summary_writer, profil\"..., 36is_chief, summary_writer, profiler)\r\n) = 36\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/home/tf/benchma\"..., 118  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 2430, in benchmark_with_session\r\n) = 118\r\nopenat(AT_FDCWD, \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=164060, ...}) = 0\r\nread(3, \"# Copyright 2017 The TensorFlow \"..., 4096) = 4096\r\nread(3, \"\\n#   the forward-only option, wh\"..., 4096) = 4096\r\nread(3, \"            'The autotune thresh\"..., 4096) = 4096\r\nread(3, \"                'the number of s\"..., 4096) = 4096\r\nread(3, \"ed, after the graph has been par\"..., 4096) = 4096\r\nread(3, \" maximum number of GPU Ops that \"..., 4096) = 4096\r\nread(3, \"or the MultiDeviceIterator that \"..., 4096) = 4096\r\nread(3, \"INE_integer('kmp_settings', 1,\\n \"..., 4096) = 4096\r\nread(3, \"            'collective_all_redu\"..., 4096) = 4096\r\nread(3, \"s.')\\nflags.DEFINE_integer('save_\"..., 4096) = 4096\r\nread(3, \"pointNotFoundException(Exception\"..., 4096) = 4096\r\nread(3, \"params.eval_during_training_at_s\"..., 4096) = 4096\r\nread(3, \"filename, ''\\n      as_text = fil\"..., 4096) = 4096\r\nread(3, \"\\n                         (name,\"..., 4096) = 4096\r\nread(3, \"loat(piece))\\n      except ValueE\"..., 4096) = 4096\r\nread(3, \"tf.train.RMSPropOptimizer(\\n     \"..., 4096) = 4096\r\nread(3, \"rning_rate_decay_factor)):\\n     \"..., 4096) = 4096\r\nread(3, \"d not self.params.datasets_use_p\"..., 4096) = 4096\r\nread(3, \".sync_queue_devices = [self.para\"..., 4096) = 4096\r\nread(3, \"eter_server'):\\n      raise Value\"..., 4096) = 4096\r\nread(3, \"onstants.BenchmarkMode.TRAIN_AND\"..., 4096) = 4096\r\nread(3, \"d batches per prepocessing group\"..., 4096) = 4096\r\nread(3, \"ame: %s' % self.params.job_name)\"..., 4096) = 4096\r\nread(3, \"not None:\\n        # We might rei\"..., 4096) = 4096\r\nread(3, \"f.batch_size)\\n      mlperf.logge\"..., 4096) = 4096\r\nread(3, \"ributed_collective) and\\n        \"..., 4096) = 4096\r\nread(3, \".broadcast_global_variables(0)\\n \"..., 4096) = 4096\r\nread(3, \"      named tensors/ops list, fe\"..., 4096) = 4096\r\nread(3, \"fo.execution_barrier:\\n          \"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"collective_graph_key=collective_\"..., 43collective_graph_key=collective_graph_key)\r\n) = 43\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/home/tf/benchma\"..., 113  File \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 869, in benchmark_one_step\r\n) = 113\r\nopenat(AT_FDCWD, \"/home/tf/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=164060, ...}) = 0\r\nread(3, \"# Copyright 2017 The TensorFlow \"..., 4096) = 4096\r\nread(3, \"\\n#   the forward-only option, wh\"..., 4096) = 4096\r\nread(3, \"            'The autotune thresh\"..., 4096) = 4096\r\nread(3, \"                'the number of s\"..., 4096) = 4096\r\nread(3, \"ed, after the graph has been par\"..., 4096) = 4096\r\nread(3, \" maximum number of GPU Ops that \"..., 4096) = 4096\r\nread(3, \"or the MultiDeviceIterator that \"..., 4096) = 4096\r\nread(3, \"INE_integer('kmp_settings', 1,\\n \"..., 4096) = 4096\r\nread(3, \"            'collective_all_redu\"..., 4096) = 4096\r\nread(3, \"s.')\\nflags.DEFINE_integer('save_\"..., 4096) = 4096\r\nread(3, \"pointNotFoundException(Exception\"..., 4096) = 4096\r\nread(3, \"params.eval_during_training_at_s\"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"results = sess.run(fetches, opti\"..., 76results = sess.run(fetches, options=run_options, run_metadata=run_metadata)\r\n) = 76\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/root/.env/tf1.15/lib/py\"..., 114  File \"/root/.env/tf1.15/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\r\n) = 114\r\nopenat(AT_FDCWD, \"/root/.env/tf1.15/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=69365, ...}) = 0\r\nread(3, \"# Copyright 2015 The TensorFlow \"..., 4096) = 4096\r\nread(3, \"d to feed a run, `feed_fn2` to s\"..., 4096) = 4096\r\nread(3, \", tensor_type):\\n      raise Valu\"..., 4096) = 4096\r\nread(3, \": Callable as returned by a fetc\"..., 4096) = 4096\r\nread(3, \"ass.\\n    \\\"\\\"\\\"\\n    values = _get_a\"..., 4096) = 4096\r\nread(3, \"\\n    i = 0\\n    j = 0\\n    for is_\"..., 4096) = 4096\r\nread(3, \"dles = []\\n\\n    if config is None\"..., 4096) = 4096\r\nread(3, \"\\n\\n  @property\\n  def sess_str(sel\"..., 4096) = 4096\r\nread(3, \"he value of tensors in the graph\"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"run_metadata_ptr)\\n\", 18run_metadata_ptr)\r\n)     = 18\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/root/.env/tf1.15/lib/py\"..., 116  File \"/root/.env/tf1.15/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n) = 116\r\nopenat(AT_FDCWD, \"/root/.env/tf1.15/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=69365, ...}) = 0\r\nread(3, \"# Copyright 2015 The TensorFlow \"..., 4096) = 4096\r\nread(3, \"d to feed a run, `feed_fn2` to s\"..., 4096) = 4096\r\nread(3, \", tensor_type):\\n      raise Valu\"..., 4096) = 4096\r\nread(3, \": Callable as returned by a fetc\"..., 4096) = 4096\r\nread(3, \"ass.\\n    \\\"\\\"\\\"\\n    values = _get_a\"..., 4096) = 4096\r\nread(3, \"\\n    i = 0\\n    j = 0\\n    for is_\"..., 4096) = 4096\r\nread(3, \"dles = []\\n\\n    if config is None\"..., 4096) = 4096\r\nread(3, \"\\n\\n  @property\\n  def sess_str(sel\"..., 4096) = 4096\r\nread(3, \"he value of tensors in the graph\"..., 4096) = 4096\r\nread(3, \"tionary\\n        whose values are\"..., 4096) = 4096\r\nread(3, \"d Session.')\\n    if self.graph.v\"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"feed_dict_tensor, options, run_m\"..., 41feed_dict_tensor, options, run_metadata)\r\n) = 41\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/root/.env/tf1.15/lib/py\"..., 119  File \"/root/.env/tf1.15/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n) = 119\r\nopenat(AT_FDCWD, \"/root/.env/tf1.15/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=69365, ...}) = 0\r\nread(3, \"# Copyright 2015 The TensorFlow \"..., 4096) = 4096\r\nread(3, \"d to feed a run, `feed_fn2` to s\"..., 4096) = 4096\r\nread(3, \", tensor_type):\\n      raise Valu\"..., 4096) = 4096\r\nread(3, \": Callable as returned by a fetc\"..., 4096) = 4096\r\nread(3, \"ass.\\n    \\\"\\\"\\\"\\n    values = _get_a\"..., 4096) = 4096\r\nread(3, \"\\n    i = 0\\n    j = 0\\n    for is_\"..., 4096) = 4096\r\nread(3, \"dles = []\\n\\n    if config is None\"..., 4096) = 4096\r\nread(3, \"\\n\\n  @property\\n  def sess_str(sel\"..., 4096) = 4096\r\nread(3, \"he value of tensors in the graph\"..., 4096) = 4096\r\nread(3, \"tionary\\n        whose values are\"..., 4096) = 4096\r\nread(3, \"d Session.')\\n    if self.graph.v\"..., 4096) = 4096\r\nread(3, \"d_list)` arguments whose types\\n \"..., 4096) = 4096\r\nread(3, \"session.TF_DeleteBuffer(run_meta\"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"run_metadata)\\n\", 14run_metadata)\r\n)         = 14\r\nclose(3)                                = 0\r\nwrite(2, \"  File \\\"/root/.env/tf1.15/lib/py\"..., 120  File \"/root/.env/tf1.15/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n) = 120\r\nopenat(AT_FDCWD, \"/root/.env/tf1.15/lib/python2.7/site-packages/tensorflow_core/python/client/session.py\", O_RDONLY) = 3\r\nfstat(3, {st_mode=S_IFREG|0644, st_size=69365, ...}) = 0\r\nread(3, \"# Copyright 2015 The TensorFlow \"..., 4096) = 4096\r\nread(3, \"d to feed a run, `feed_fn2` to s\"..., 4096) = 4096\r\nread(3, \", tensor_type):\\n      raise Valu\"..., 4096) = 4096\r\nread(3, \": Callable as returned by a fetc\"..., 4096) = 4096\r\nread(3, \"ass.\\n    \\\"\\\"\\\"\\n    values = _get_a\"..., 4096) = 4096\r\nread(3, \"\\n    i = 0\\n    j = 0\\n    for is_\"..., 4096) = 4096\r\nread(3, \"dles = []\\n\\n    if config is None\"..., 4096) = 4096\r\nread(3, \"\\n\\n  @property\\n  def sess_str(sel\"..., 4096) = 4096\r\nread(3, \"he value of tensors in the graph\"..., 4096) = 4096\r\nread(3, \"tionary\\n        whose values are\"..., 4096) = 4096\r\nread(3, \"d Session.')\\n    if self.graph.v\"..., 4096) = 4096\r\nread(3, \"d_list)` arguments whose types\\n \"..., 4096) = 4096\r\nread(3, \"session.TF_DeleteBuffer(run_meta\"..., 4096) = 4096\r\nread(3, \"ssage, self._graph)\\n      if 'on\"..., 4096) = 4096\r\nwrite(2, \"    \", 4    )                     = 4\r\nwrite(2, \"raise type(e)(node_def, op, mess\"..., 37raise type(e)(node_def, op, message)\r\n) = 37\r\nclose(3)                                = 0\r\nwrite(2, \"tensorflow.python.framework.erro\"..., 39tensorflow.python.framework.errors_impl) = 39\r\nwrite(2, \".\", 1.)                        = 1\r\nwrite(2, \"InvalidArgumentError\", 20InvalidArgumentError)    = 20\r\nwrite(2, \": \", 2: )                       = 2\r\nwrite(2, \"Retval[0] does not have value\", 29Retval[0] does not have value) = 29\r\nwrite(2, \"\\n\", 1\r\n)                       = 1\r\nunlinkat(AT_FDCWD, \"/tmp/tmp5HeJNi.py\", 0) = 0\r\nunlinkat(AT_FDCWD, \"/tmp/tmpuWUoTb.py\", 0) = 0\r\nunlinkat(AT_FDCWD, \"/tmp/tmpRaOsTY.py\", 0) = 0\r\nunlinkat(AT_FDCWD, \"/tmp/tmpt0VBwu.py\", 0) = 0\r\nunlinkat(AT_FDCWD, \"/tmp/tmpZMqsKy.py\", 0) = 0\r\nunlinkat(AT_FDCWD, \"/tmp/tmpl2wn88.py\", 0) = 0\r\nunlinkat(AT_FDCWD, \"/tmp/tmpcDvUvG.py\", 0) = 0\r\nunlinkat(AT_FDCWD, \"/tmp/tmpgPPLwh.py\", 0) = 0\r\nrt_sigaction(SIGINT, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, {sa_handler=0xaaaada8a4260, sa_mask=[], sa_flags=0}, 8) = 0\r\nmunmap(0xfffd94779000, 262144)          = 0\r\nmunmap(0xfffd8d1bc000, 262144)          = 0\r\nmunmap(0xfffd8d33b000, 262144)          = 0\r\nmunmap(0xfffd946f9000, 262144)          = 0\r\nmunmap(0xfffdac6f9000, 262144)          = 0\r\nmunmap(0xfffd8d2bb000, 262144)          = 0\r\nmunmap(0xffff77141000, 262144)          = 0\r\nmunmap(0xfffd8cefc000, 262144)          = 0\r\nmunmap(0xfffda4339000, 262144)          = 0\r\nclose(11)                               = 0\r\nfutex(0xffff8071a674, FUTEX_WAKE_PRIVATE, 2147483647) = 0\r\nfstat(0, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...}) = 0\r\nfstat(0, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...}) = 0\r\nfstat(0, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...}) = 0\r\nexit_group(1)                           = ?\r\n+++ exited with 1 +++\r\n", "@Danliran Please post this issue in [tensorflow/benchmarks](https://github.com/tensorflow/benchmarks/issues) as the issue is related to benchmarks. Thanks!", "@gowthamkpr do you have any idear about this issue.  post it in tensorflow/benchmarks https://github.com/tensorflow/benchmarks/issues/479", "@Danliran Sorry for pointing you out to multiple repos. But as mentioned in [comment](https://github.com/tensorflow/benchmarks/issues/479#issuecomment-640967838) please try to post it [here](https://github.com/tensorflow/models/issues) as well as they would be able to help you. I will keep this issue open here. Thanks!", "@gowthamkpr That`s all right, If this issue reproduce  in [TensorFlow Official Models ](https://github.com/tensorflow/models/tree/master/official), I will post it to tensorflow/models.", "Sure. Thanks! I will close this issue here then.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40213\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40213\">No</a>\n"]}, {"number": 40212, "title": "[TF 2.3.0] [Intel MKL]  Make bf16 default with mkl + non AVX512 system error handling", "body": "1. Make bf16 default with mkl build\r\n2. Log appropriate message to user with legacy systems without AVX512 such as AVX and AVX2 (example broadwell) and fall back to eigen kernels when available.", "comments": ["@penpornk Oops you were quick to review before me asking. :) Sorry, I did not like the stray word in the a new line when all can be contained in a single line. Changed it. Can you please re review and approve. Thank you for your patience! \ud83d\udc4d ", "@nammbash No problem! Done. :)"]}, {"number": 40211, "title": "[TF 2.3.0] [Intel MKL] remove duplicate registration for softmax bf16 op", "body": "Removing the duplicate registration of the softmax kernel from mkl_tmp_bf16_op.cc.\r\n\r\nGoogle added the op registration here already\r\nhttps://github.com/tensorflow/tensorflow/commit/cbac31d59ded64caa23a00481bb33d1104ab8822#diff-d960722b1c03feab5e375c2bfe409747R85", "comments": []}, {"number": 40210, "title": "correct summing total blocks in EfficientNet", "body": "The number of total blocks incorrect, as it is not updated for the depth_coefficient. As an effect, it will  make drop_rate much higher than expected. In the case of larger base models (for example B3), choosing drop_connect_rate to be large (for example 0.8) will result in dropout rate for some layers becoming larger than 1. ", "comments": ["Thanks for reporting the issue and sending the PR.\r\n\r\nI found the link of the original implementation from the https://arxiv.org/abs/1905.11946, and corresponding code is at https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/efficientnet_model.py#L693.\r\n\r\n```\r\ndrop_rate = 1.0 - survival_prob\r\nsurvival_prob = 1.0 - drop_rate * float(idx) / len(self._blocks)\r\n```\r\n\r\nself._blocks is the list that contains all the blocks, the block is created by rounded value of \"repeat\".  The existing Keras implementation is incorrect since adding unrounded value together could be larger than the total number of blocks.\r\n", "Since this change will cause potential change to the saved weights. Could you check if the existing h5 weights need any update with the default parameter? ", "I think if the weights are pre-trained using this implementation, then it has to be updated except for B0 where depth scaling is 1.  \r\n\r\nThe difference here is equivalent to changing `drop_connect_rate` value. Varying drop_connect_rate does have effect on training result (although it would probably not visibly alter the performance of the model). However, using the given pre-trained weights, varying drop_connect_rate gives exactly the same model (stochastically checked by randomly printing out weights of several layers, and by comparing the outputs for predicting a small dataset). That means the change in drop_connect_rate cannot be accounted for without updating the weight files.\r\n\r\nI tried to make a more explicit comparison between the existing and corrected code, but building TF from source is too much pain - is there any better way to test?", "Yea, I think that is aligning with my expectation as well, we will have to update the weights. We need to check with @fchollet about how weights are created and uploaded to Keras side. There is also a checksum in the source code, which I think need to be updated within the PR as well.", "@yixingfu discovered that the keras-application weights are exactly same as the one from the checkpoint in https://github.com/tensorflow/tpu/tree/30b0889ee1933c3dbe90f1c46461a1a89370a5ba/models/official/efficientnet, which means the weights doesn't need to be updated in this PR. Approving this PR."]}, {"number": 40209, "title": " (error pr)", "body": "error, please delete this pr if possible", "comments": []}, {"number": 40208, "title": "MKL does not work with tensorflow 2.2.0", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0\r\n- Python version: N/A\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): devtoolset-7 on centos 7\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nWe have built tensorflow 2.2.0 framework and jni targets from source with `--config=mkl`. When we run models, logs show that MKL is not enabled even though there are few symbols of mkl.\r\n[tensorflow log](https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/core/platform/cpu_feature_guard.cc#L143)\r\n\r\n```\r\nnm -D libtensorflow_framework.so | grep -i mkl | wc -l\r\n     173\r\n\r\n```\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nBAZEL_LINKLIBS=-l%:libstdc++.a bazel build -c opt --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-O3 \\\r\n      --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector \\\r\n      --copt=-msse4.2 --copt=-mavx \\\r\n      --config=mkl \\\r\n      --linkopt -ldl \\\r\n      --copt=-march=x86-64 \\\r\n      --config=v2 \\\r\n      //tensorflow/tools/lib_package:libtensorflow_jni \\\r\n      //tensorflow/tools/lib_package:libtensorflow \\\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nWe were using Docker to compile and build the targets.\r\nWe used the same commands without `--config=v2` to successfully build tensorflow 1.15 with MKL enabled. It has 15718 mkl related symbols.", "comments": ["@ashahab @preethivenkatesh @penpornk The fix from https://github.com/tensorflow/tensorflow/issues/36717#issuecomment-602733323 doesnt seem to work and we are still facing the same issue as 1.15\r\n\r\nWould you be able to provide some help ?", "Sorry to hear that! I've assigned this issue to the @TensorFlow-MKL team (@ashahba is from the team).", "@penpornk and  @pavanky  Thanks for reporting the issue, sorry for the delay. I will have someone look at it and get back to you ASAP.", "@penpornk  @pavanky @agramesh1 I will check this issue as soon.", "@agramesh1 @NeoZhangJianyu Thank you very much!", "@pavanky I can reproduce and verified your docker build instructions to display the same number of mkl symbols. however, regarding the warning message not displaying Intel MKLDNN support, we have found this issue in tf2.1(now appearing in tf2.2 as well), which appeared to be cosmetic and didn't impact the performance. We are already started investigating this issue last week and will try to provide a fix to the messaging ASAP. Alternatively, you can check if MKLDNN is enabled by running this command \r\n```\r\npython -c 'from tensorflow.python import _pywrap_util_port;    print(\"MKL enabled :\", _pywrap_util_port.IsMklEnabled())'\r\n```\r\nI verified the mkl symbols and the warning message in the baremetal build as well, which matches the behavior as that of the docker build (175 MKL symbols, and no Intel MKLDNN warning)", "> however, regarding the warning message not displaying Intel MKLDNN support, we have found this issue in tf2.1(now appearing in tf2.2 as well), which appeared to be cosmetic and didn't impact the performance. We are already started investigating this issue last week and will try to provide a fix to the messaging ASAP.\r\n\r\nThe issue is because `-DINTEL_MKL` did not get passed to `cpu_feature_guard.cc`. (To pass `-DINTEL_MKL` configuration, the BUILD file needs to add `copts = tf_copts()` for the target `//tensorflow/core/platform:cpu_feature_guard`.) \r\n\r\nSince both vanilla TF and TF-MKL uses MKL-DNN at the time, I removed the `INTEL_MKL` guard and made both display the same message (saying MKL-DNN is used) in:  https://github.com/tensorflow/tensorflow/commit/95f92b6d33b7b405c5c327a68c216a5a5b5d9f93. Unfortunately, this fix was after the TF 2.2.0 branch cut, so the message is still wrong in 2.2.0.", "@penpornk @preethivenkatesh Let me do this change to the PR associated with the cpu_feature_gaurd here https://github.com/tensorflow/tensorflow/pull/40330#discussion_r439675263", "@nammbash Sounds great! (Although it sounds like we could use one string for both again. See [here](https://github.com/tensorflow/tensorflow/pull/40330#discussion_r439659273).)", "@preethivenkatesh we dont have a wheel ready with MKL right now, just the java jar file. Is there a way to test it from Java ?\r\n", "unfortunately we don't have the `IsMklEnabled()` support for java due to limited usage. Is it possible to run java jar file on a sample workload? setting mkldnn verbose path variable might be helpful, using `export MKLDNN_VERBOSE=1` before running a sample workload produces verbose MKLDNN logs if mkl is enabled", "> Since both vanilla TF and TF-MKL uses MKL-DNN at the time, I removed the INTEL_MKL guard and made both display the same message (saying MKL-DNN is used) in: 95f92b6. Unfortunately, this fix was after the TF 2.2.0 branch cut, so the message is still wrong in 2.2.0.\r\n\r\n@preethivenkatesh @penpornk considering this comment, will we notice any difference in TF vs TF-MKL with this environment variable set ?", "yes, @pavanky you will still continue to see differences in the speed, the MKL op that is primarily upstreamed into the vanilla TF is for MatMul, but the MKLDNN-TF has a lot more set of ops supported that are not upstreamed yet. ", "@preethivenkatesh @penpornk  We have run some workload tests and seen the difference. Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40208\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40208\">No</a>\n"]}, {"number": 40207, "title": "Model training ending after around 50 steps.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version:1.14.0 (cpu version)\r\n- Python version:3.7.7\r\n- Installed using virtualenv? pip? conda?:conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\n\r\n**Describe the problem**\r\nIm training a model using the ssd_inception_v2_coco mode.  I execute the command:  python model_main.py --alsologtostderr --model_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config\r\nand it trains for about 50 steps before it runs through a couple hundred lines of tracebacks and a couple numpy type errors.  It does save the data so if I run the command again it continues from where it left off.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npython model_main.py --alsologtostderr --model_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n>python model_main.py --alsologtostderr --model_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nC:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nWARNING:tensorflow:\r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Documents\\TensorFlow\\models\\research\\slim\\nets\\inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Documents\\TensorFlow\\models\\research\\slim\\nets\\mobilenet\\mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\r\n\r\nWARNING:tensorflow:From model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\config_util.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nW0605 16:20:32.751548 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\config_util.py:96: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\model_lib.py:597: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nW0605 16:20:32.762156 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\model_lib.py:597: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\r\nW0605 16:20:32.763155 21396 model_lib.py:598] Forced number of epochs for all eval validations to be 1.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\config_util.py:482: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\r\n\r\nW0605 16:20:32.782005 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\config_util.py:482: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\r\n\r\nINFO:tensorflow:Maybe overwriting train_steps: None\r\nI0605 16:20:32.783971 21396 config_util.py:482] Maybe overwriting train_steps: None\r\nINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\r\nI0605 16:20:32.793966 21396 config_util.py:482] Maybe overwriting sample_1_of_n_eval_examples: 1\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\nI0605 16:20:32.795971 21396 config_util.py:482] Maybe overwriting use_bfloat16: False\r\nINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\r\nI0605 16:20:32.807742 21396 config_util.py:482] Maybe overwriting eval_num_epochs: 1\r\nINFO:tensorflow:Maybe overwriting load_pretrained: True\r\nI0605 16:20:32.817380 21396 config_util.py:482] Maybe overwriting load_pretrained: True\r\nINFO:tensorflow:Ignoring config override key: load_pretrained\r\nI0605 16:20:32.819402 21396 config_util.py:492] Ignoring config override key: load_pretrained\r\nWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\nW0605 16:20:32.827637 21396 model_lib.py:614] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\nINFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\r\nI0605 16:20:32.829394 21396 model_lib.py:649] create_estimator_and_inputs: use_tpu False, export_to_tpu False\r\nINFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EA704252C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\nI0605 16:20:32.841974 21396 estimator.py:209] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EA704252C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\nWARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001EA70433168>) includes params argument, but params are not passed to Estimator.\r\nW0605 16:20:32.848480 21396 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001EA70433168>) includes params argument, but params are not passed to Estimator.\r\nINFO:tensorflow:Not using Distribute Coordinator.\r\nI0605 16:20:32.854470 21396 estimator_training.py:186] Not using Distribute Coordinator.\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nI0605 16:20:32.859618 21396 training.py:612] Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\nI0605 16:20:32.861163 21396 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nW0605 16:20:32.887774 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\data_decoders\\tf_example_decoder.py:170: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\r\n\r\nW0605 16:20:32.902736 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\data_decoders\\tf_example_decoder.py:170: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\data_decoders\\tf_example_decoder.py:185: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\r\n\r\nW0605 16:20:32.903731 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\data_decoders\\tf_example_decoder.py:185: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:61: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\r\n\r\nW0605 16:20:32.941629 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:61: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\r\n\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\nW0605 16:20:32.946616 21396 dataset_builder.py:66] num_readers has been reduced to 1 to match input file shards.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.experimental.parallel_interleave(...)`.\r\nW0605 16:20:32.953633 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.experimental.parallel_interleave(...)`.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\ops\\interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nW0605 16:20:32.957589 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\ops\\interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:149: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nW0605 16:20:32.990371 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:149: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\ops.py:472: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\r\n\r\nW0605 16:20:33.112078 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\ops.py:472: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\ops.py:472: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0605 16:20:33.115038 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\ops.py:472: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\ops.py:474: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW0605 16:20:33.126492 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\ops.py:474: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\inputs.py:320: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0605 16:20:33.167061 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\inputs.py:320: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\preprocessor.py:512: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\r\n\r\nW0605 16:20:33.171998 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\preprocessor.py:512: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nW0605 16:20:33.220893 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the `axis` argument instead\r\nW0605 16:20:33.224887 21396 deprecation.py:506] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the `axis` argument instead\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\preprocessor.py:2421: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\r\n\r\nW0605 16:20:33.810291 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\preprocessor.py:2421: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:152: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.batch(..., drop_remainder=True)`.\r\nW0605 16:20:34.148696 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:152: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.batch(..., drop_remainder=True)`.\r\nINFO:tensorflow:Calling model_fn.\r\nI0605 16:20:34.162653 21396 estimator.py:1145] Calling model_fn.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nW0605 16:20:34.387717 21396 deprecation.py:506] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:20:37.683687 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:20:37.718561 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:20:37.755499 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:20:37.789371 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:20:37.824299 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:20:37.861396 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\variables_helper.py:134: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\r\n\r\nW0605 16:20:37.901255 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\variables_helper.py:134: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\model_lib.py:332: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\r\n\r\nW0605 16:20:37.925952 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\model_lib.py:332: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\meta_architectures\\ssd_meta_arch.py:1028: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nW0605 16:20:40.277952 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\meta_architectures\\ssd_meta_arch.py:1028: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\losses.py:174: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\r\n\r\nW0605 16:20:40.291881 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\losses.py:174: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\losses.py:180: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\r\n\r\nW0605 16:20:40.293919 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\core\\losses.py:180: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\model_lib.py:356: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nW0605 16:20:40.543186 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\model_lib.py:356: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\learning_schedules.py:54: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\r\n\r\nW0605 16:20:40.545150 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\learning_schedules.py:54: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\optimizer_builder.py:44: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\r\n\r\nW0605 16:20:40.563030 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\builders\\optimizer_builder.py:44: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nW0605 16:20:42.401734 21396 deprecation.py:506] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nINFO:tensorflow:Done calling model_fn.\r\nI0605 16:20:48.850543 21396 estimator.py:1147] Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nI0605 16:20:48.853538 21396 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\nI0605 16:20:52.710421 21396 monitored_session.py:240] Graph was finalized.\r\n2020-06-05 16:20:52.713721: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nW0605 16:20:52.743332 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nINFO:tensorflow:Restoring parameters from training/model.ckpt-1242\r\nI0605 16:20:52.765274 21396 saver.py:1280] Restoring parameters from training/model.ckpt-1242\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file utilities to get mtimes.\r\nW0605 16:20:54.521835 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file utilities to get mtimes.\r\nINFO:tensorflow:Running local_init_op.\r\nI0605 16:20:55.466892 21396 session_manager.py:500] Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nI0605 16:20:55.871834 21396 session_manager.py:502] Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 1242 into training/model.ckpt.\r\nI0605 16:21:05.430812 21396 basic_session_run_hooks.py:606] Saving checkpoints for 1242 into training/model.ckpt.\r\nINFO:tensorflow:loss = 4.2586923, step = 1243\r\nI0605 16:21:24.690247 21396 basic_session_run_hooks.py:262] loss = 4.2586923, step = 1243\r\nINFO:tensorflow:Saving checkpoints for 1304 into training/model.ckpt.\r\nI0605 16:31:09.404349 21396 basic_session_run_hooks.py:606] Saving checkpoints for 1304 into training/model.ckpt.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to delete files with this prefix.\r\nW0605 16:31:09.901591 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to delete files with this prefix.\r\nINFO:tensorflow:Calling model_fn.\r\nI0605 16:31:12.018701 21396 estimator.py:1145] Calling model_fn.\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:31:15.044162 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:31:15.074082 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:31:15.102516 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:31:15.129999 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:31:15.158922 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0605 16:31:15.185850 21396 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\eval_util.py:785: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0605 16:31:15.971594 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\eval_util.py:785: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ntf.py_func is deprecated in TF V2. Instead, there are two\r\n    options available in V2.\r\n    - tf.py_function takes a python function which manipulates tf eager\r\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\r\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\r\n    means `tf.py_function`s can use accelerators such as GPUs as well as\r\n    being differentiable using a gradient tape.\r\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\r\n    (it is not differentiable, and manipulates numpy arrays). It drops the\r\n    stateful argument making all functions stateful.\r\n\r\nW0605 16:31:16.161088 21396 deprecation.py:323] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ntf.py_func is deprecated in TF V2. Instead, there are two\r\n    options available in V2.\r\n    - tf.py_function takes a python function which manipulates tf eager\r\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\r\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\r\n    means `tf.py_function`s can use accelerators such as GPUs as well as\r\n    being differentiable using a gradient tape.\r\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\r\n    (it is not differentiable, and manipulates numpy arrays). It drops the\r\n    stateful argument making all functions stateful.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\visualization_utils.py:924: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\r\n\r\nW0605 16:31:16.337792 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\utils\\visualization_utils.py:924: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\model_lib.py:456: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\r\n\r\nW0605 16:31:16.428550 21396 deprecation_wrapper.py:119] From C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\model_lib.py:456: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\r\n\r\nINFO:tensorflow:Done calling model_fn.\r\nI0605 16:31:16.751320 21396 estimator.py:1147] Done calling model_fn.\r\nINFO:tensorflow:Starting evaluation at 2020-06-05T16:31:16Z\r\nI0605 16:31:16.775298 21396 evaluation.py:255] Starting evaluation at 2020-06-05T16:31:16Z\r\nINFO:tensorflow:Graph was finalized.\r\nI0605 16:31:17.219084 21396 monitored_session.py:240] Graph was finalized.\r\nINFO:tensorflow:Restoring parameters from training/model.ckpt-1304\r\nI0605 16:31:17.229057 21396 saver.py:1280] Restoring parameters from training/model.ckpt-1304\r\nINFO:tensorflow:Running local_init_op.\r\nI0605 16:31:17.974575 21396 session_manager.py:500] Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nI0605 16:31:18.098278 21396 session_manager.py:502] Done running local_init_op.\r\ncreating index...\r\nindex created!\r\nINFO:tensorflow:Loading and preparing annotation results...\r\nI0605 16:31:23.954166 13852 coco_tools.py:109] Loading and preparing annotation results...\r\nINFO:tensorflow:DONE (t=0.00s)\r\nI0605 16:31:23.962145 13852 coco_tools.py:131] DONE (t=0.00s)\r\ncreating index...\r\nindex created!\r\n2020-06-05 16:31:23.992431: W tensorflow/core/framework/op_kernel.cc:1490] Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\core\\function_base.py\", line 117, in linspace\r\n    num = operator.index(num)\r\n\r\nTypeError: 'numpy.float64' object cannot be interpreted as an integer\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 209, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_evaluation.py\", line 358, in first_value_func\r\n    self._metrics = self.evaluate()\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_evaluation.py\", line 209, in evaluate\r\n    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_tools.py\", line 170, in __init__\r\n    iouType=iou_type)\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 76, in __init__\r\n    self.params = Params(iouType=iouType) # parameters\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 527, in __init__\r\n    self.setDetParams()\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 507, in setDetParams\r\n    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\r\n\r\n  File \"<__array_function__ internals>\", line 6, in linspace\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\core\\function_base.py\", line 121, in linspace\r\n    .format(type(num)))\r\n\r\nTypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1356, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1341, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1429, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\", line 272, in _evaluate_once\r\n    session.run(eval_ops, feed_dict)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 754, in run\r\n    run_metadata=run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1252, in run\r\n    run_metadata=run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1353, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\six.py\", line 703, in reraise\r\n    raise value\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1338, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1411, in run\r\n    run_metadata=run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1169, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 950, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1173, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1350, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1370, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\r\n         [[node IteratorGetNext (defined at model_main.py:105) ]]\r\n\r\nOriginal stack trace for 'IteratorGetNext':\r\n  File \"model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 613, in run\r\n    return self.run_local()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 714, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 367, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1158, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1192, in _train_model_default\r\n    saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1484, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 754, in run\r\n    run_metadata=run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1252, in run\r\n    run_metadata=run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1338, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1419, in run\r\n    run_metadata=run_metadata))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 594, in after_run\r\n    if self._save(run_context.session, global_step):\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 619, in _save\r\n    if l.after_save(session, step):\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 519, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 539, in _evaluate\r\n    self._evaluator.evaluate_and_export())\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 920, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 477, in evaluate\r\n    name=name)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 519, in _actual_eval\r\n    return _evaluate()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 501, in _evaluate\r\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1501, in _evaluate_build_graph\r\n    self._call_model_fn_eval(input_fn, self.config))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1534, in _call_model_fn_eval\r\n    input_fn, ModeKeys.EVAL)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1022, in _get_features_and_labels_from_input_fn\r\n    self._call_input_fn(input_fn, mode))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py\", line 65, in parse_input_fn_result\r\n    result = iterator.get_next()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\r\n    output_shapes=self._structure._flat_shapes, name=name)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1973, in iterator_get_next\r\n    output_shapes=output_shapes, name=name)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1356, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1341, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1429, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\core\\function_base.py\", line 117, in linspace\r\n    num = operator.index(num)\r\n\r\nTypeError: 'numpy.float64' object cannot be interpreted as an integer\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 209, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_evaluation.py\", line 358, in first_value_func\r\n    self._metrics = self.evaluate()\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_evaluation.py\", line 209, in evaluate\r\n    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_tools.py\", line 170, in __init__\r\n    iouType=iou_type)\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 76, in __init__\r\n    self.params = Params(iouType=iouType) # parameters\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 527, in __init__\r\n    self.setDetParams()\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 507, in setDetParams\r\n    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\r\n\r\n  File \"<__array_function__ internals>\", line 6, in linspace\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\core\\function_base.py\", line 121, in linspace\r\n    .format(type(num)))\r\n\r\nTypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\n\r\n\r\n         [[{{node PyFunc_3}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 613, in run\r\n    return self.run_local()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 714, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 367, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1158, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1192, in _train_model_default\r\n    saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1484, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 754, in run\r\n    run_metadata=run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1252, in run\r\n    run_metadata=run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1353, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\six.py\", line 703, in reraise\r\n    raise value\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1338, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1419, in run\r\n    run_metadata=run_metadata))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 594, in after_run\r\n    if self._save(run_context.session, global_step):\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 619, in _save\r\n    if l.after_save(session, step):\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 519, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 539, in _evaluate\r\n    self._evaluator.evaluate_and_export())\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 920, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 477, in evaluate\r\n    name=name)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 519, in _actual_eval\r\n    return _evaluate()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 508, in _evaluate\r\n    output_dir=self.eval_dir(name))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1609, in _evaluate_run\r\n    config=self._session_config)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\", line 272, in _evaluate_once\r\n    session.run(eval_ops, feed_dict)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 854, in __exit__\r\n    self._close_internal(exception_type)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 887, in _close_internal\r\n    h.end(self._coordinated_creator.tf_sess)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 951, in end\r\n    self._final_ops, feed_dict=self._final_ops_feed_dict)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 950, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1173, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1350, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1370, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\core\\function_base.py\", line 117, in linspace\r\n    num = operator.index(num)\r\n\r\nTypeError: 'numpy.float64' object cannot be interpreted as an integer\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 209, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_evaluation.py\", line 358, in first_value_func\r\n    self._metrics = self.evaluate()\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_evaluation.py\", line 209, in evaluate\r\n    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_tools.py\", line 170, in __init__\r\n    iouType=iou_type)\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 76, in __init__\r\n    self.params = Params(iouType=iouType) # parameters\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 527, in __init__\r\n    self.setDetParams()\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 507, in setDetParams\r\n    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\r\n\r\n  File \"<__array_function__ internals>\", line 6, in linspace\r\n\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\core\\function_base.py\", line 121, in linspace\r\n    .format(type(num)))\r\n\r\nTypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\n\r\n\r\n         [[node PyFunc_3 (defined at C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_evaluation.py:368) ]]\r\n\r\nOriginal stack trace for 'PyFunc_3':\r\n  File \"model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 613, in run\r\n    return self.run_local()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 714, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 367, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1158, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1192, in _train_model_default\r\n    saving_listeners)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1484, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 754, in run\r\n    run_metadata=run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1252, in run\r\n    run_metadata=run_metadata)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1338, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1419, in run\r\n    run_metadata=run_metadata))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 594, in after_run\r\n    if self._save(run_context.session, global_step):\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 619, in _save\r\n    if l.after_save(session, step):\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 519, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 539, in _evaluate\r\n    self._evaluator.evaluate_and_export())\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 920, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 477, in evaluate\r\n    name=name)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 519, in _actual_eval\r\n    return _evaluate()\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 501, in _evaluate\r\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1501, in _evaluate_build_graph\r\n    self._call_model_fn_eval(input_fn, self.config))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1537, in _call_model_fn_eval\r\n    features, labels, ModeKeys.EVAL, config)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1146, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\model_lib.py\", line 454, in model_fn\r\n    eval_config, list(category_index.values()), eval_dict)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\eval_util.py\", line 916, in get_eval_metric_ops_for_evaluators\r\n    eval_dict))\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\object_detection\\metrics\\coco_evaluation.py\", line 368, in get_estimator_eval_metric_ops\r\n    first_value_op = tf.py_func(first_value_func, [], tf.float32)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 480, in py_func\r\n    return py_func_common(func, inp, Tout, stateful, name=name)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 462, in py_func_common\r\n    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 285, in _internal_py_func\r\n    input=inp, token=token, Tout=Tout, name=name)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_script_ops.py\", line 161, in py_func\r\n    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\gomezn\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()", "comments": ["@Natiel4  \r\nPlease share simple standalone code for us to replicate this issue faced, or if possible share a colab gist with the error to analyse.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40207\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40207\">No</a>\n"]}, {"number": 40206, "title": "Delete Dockerfile.custom_op", "body": "/cc @yifeif ", "comments": ["@rthadur  Can you invoke kokoro?", "@bhack changes have been merged internally , waiting for auto-merge to happen.", "@rthadur Is  `MacOS Python2 and CC`  broken?"]}, {"number": 40205, "title": "Unit test //tensorflow/python:session_clusterspec_prop_test fails because eager execution is incompatible with tf.placeholder()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v2.2.0-0-g2b96f3662b 2.2.0\r\n- Python version: 3.8.2\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-10ubuntu2) 9.3.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nThe test case `//tensorflow/python:session_clusterspec_prop_test` fails with the following log (Partial log, see [test.log](https://github.com/tensorflow/tensorflow/files/4738058/test.log) for the full log):\r\n```\r\n[ RUN      ] SessionClusterSpecPropagationTest.testClusterSpecPropagationIsolation\r\n2020-06-03 11:07:09.469162: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:46629}\r\n2020-06-03 11:07:09.470895: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:46629\r\n[  FAILED  ] SessionClusterSpecPropagationTest.testClusterSpecPropagationIsolation\r\n\r\n======================================================================\r\nERROR: testClusterSpecPropagationIsolation (__main__.SessionClusterSpecPropagationTest)\r\ntestClusterSpecPropagationIsolation (__main__.SessionClusterSpecPropagationTest)\r\nTest that two sessions using ClusterSpec propagation are isolated.\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session_clusterspec_prop_test.py\", line 416, in testClusterSpecPropagationIsolation\r\n    init_value = array_ops.placeholder(dtypes.int32, shape=[])\r\n  File \"/home/sidong/.cache/bazel/_bazel_sidong/9ef871a29c692fc6a18121463529e145/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/ops/array_ops.py\", line 3023, in placeholder\r\n    raise RuntimeError(\"tf.placeholder() is not compatible with \"\r\nRuntimeError: tf.placeholder() is not compatible with eager execution.\r\n``` \r\n\r\n**Describe the expected behavior**\r\nThe test case should pass.\r\n\r\n**Standalone code to reproduce the issue**\r\n`bazel --host_jvm_args=\"-Xms1024m\" --host_jvm_args=\"-Xmx2048m\" test --host_javabase=\"@local_jdk//:jdk\" -k --build_tests_only --test_output=errors -- //tensorflow/python:session_clusterspec_prop_test`\r\n\r\n**Other info / logs** \r\nAs the error message suggested, the error is caused by eager-execution. It seems to me that in this test case, eager execution should be disabled (as it is enabled by default in Tensorflow 2.x). Modifying the test file as following will knock down the error, and the test will pass.\r\n```\r\ndiff --git a/tensorflow/python/client/session_clusterspec_prop_test.py b/tensorflow/python/client/session_clusterspec_prop_test.py\r\nindex f33b9129b8..7b0344d73e 100644\r\n--- a/tensorflow/python/client/session_clusterspec_prop_test.py\r\n+++ b/tensorflow/python/client/session_clusterspec_prop_test.py\r\n@@ -563,4 +563,5 @@ class SessionClusterSpecPropagationTest(test_util.TensorFlowTestCase):\r\n \r\n \r\n if __name__ == '__main__':\r\n+  ops.disable_eager_execution()\r\n   googletest.main()\r\n```\r\nPlease let me know if I should PR this fix, or if there is another way of disabling eager execution (or maybe do not use `tf.placeholder()`?). Thanks.\r\n\r\nSidong", "comments": ["Thanks for reporting!\r\n\r\nAs documented [here](https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder) the placeholder is not compatible with eager execution so this test is not enabled in the TF2 release. We do not test it with explicitly disabling eager in TF2, but will keep having this case covered in the TF1 testing.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40205\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40205\">No</a>\n", "Good to know that, thank you for confirming this, I will neglect this failure in the test results for 2.x version."]}, {"number": 40204, "title": "Floating point exception while executing tf.unravel_index function", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nWhen passing 0 in argument `dims` in `tf.unravel_index` function, a floating point exception occurs because of divide by zero in  `mod_op` function at tensorflow/core/kernels/unravel_index_op.cc:29. \r\n\r\n\r\n**Describe the expected behavior**\r\nNo crash in the c++ level. I would expect an exception in python saying that `dims` argument should not be 0.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n`python -c \"import tensorflow as tf; tf.unravel_index(indices=[2, 5, 7], dims=[3, 0])\"`\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Added a PR #40214 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40204\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40204\">No</a>\n"]}, {"number": 40202, "title": "\"Inconsistent CUDA toolkit path: /usr vs /usr/lib\" when running ./configure", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v2.2.0 (2b96f3662bd776e277f86997659e61046b56c315)\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: No\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): 8.3.0\r\n- CUDA/cuDNN version: 10.1/7.6.5\r\n- GPU model and memory: GeForce GTX 1070 and 8192 MB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI receive the error \"Inconsistent CUDA toolkit path: /usr vs /usr/lib\" when running `./configure`. I believe I should not receive the error.\r\n\r\n**Any other info / logs**\r\n\r\nConsole output:\r\n\r\n```\r\n~/tensorflow % ./configure\r\nYou have bazel 2.0.0 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/lib/python3.7/dist-packages\r\n  /usr/lib/python3.7/dist-packages\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.7/dist-packages]\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nInconsistent CUDA toolkit path: /usr vs /usr/libAsking for detailed CUDA configuration... ^C\r\n```\r\n\r\nAt the time of writing, the error comes from [`third_party/gpus/find_cuda_config.py:292`](https://github.com/tensorflow/tensorflow/blob/255f590ab64e637f49288883013d35efa0633b35/third_party/gpus/find_cuda_config.py#L292). The error occurs because, on my system, `cuda_binary_dir` evaluates to `/usr/bin`, while `nvvm_library_dir` evaluates to `/usr/lib/nvidia-cuda-toolkit/libdevice`. Although I'm using Debian 10, which isn't officially supported, this error can also occur in Ubuntu 20.04 if the user installed `nvcc` via the [`nvidia-cuda-toolkit`](https://packages.ubuntu.com/focal/amd64/nvidia-cuda-toolkit/filelist) package, which installs `nvcc` in two locations:\r\n\r\n* `/usr/bin/nvcc`\r\n* `/usr/lib/nvidia-cuda-toolkit/bin/nvcc`\r\n\r\n~~The solution I tentatively suggest is to remove the consistency check from `find_cuda_config.py` because it's merely a heuristic. As a result, the check might cause `./configure` to proceed when it should exit early, or to exit early when it should proceed.~~\r\n\r\n---\r\n**Edit:** As pointed out by @tensorfoo and @ambertide, removing the consistency check doesn't work. A more reliable workaround is to install the cuda toolkit using Nvidia's .run file installer.", "comments": ["For whoever might have had the same problem: I was able to compile TensorFlow by uninstalling the `nvidia-cuda-toolkit` package in my package manager and installing CUDA using Nvidia's .run file installer. It may have also been possible to use their .deb package, but it required me to downgrade my graphics card driver. AFAIK, there's no practical reason for Nvidia's package to require a downgrade; it's just slightly ham-fisted dependency management on Nvidia's part.\r\n\r\nAlthough I was able to work around my issue, I don't consider it properly solved because, seeing as Ubuntu is officially supported by TensorFlow, one would expect it to work with the CUDA drivers available directly from Ubuntu's software repository.", "@chsigg FYI", "Hi Christian, thanks for reporting this issue. \r\n\r\nThere is a TODO on line [third_party/gpus/find_cuda_config.py:286](https://github.com/tensorflow/tensorflow/blob/255f590ab64e637f49288883013d35efa0633b35/third_party/gpus/find_cuda_config.py#L286) that this needs some work. \r\n\r\nWe now do pass in both `cuda_binary_dir` and `nvvm_library_dir` directories, so I think what would need to happen is to replace each use of `cuda_toolkit_path` with one of the two and then remove `cuda_toolkit_path`. \r\n\r\nAs it stands now, we probably require that `cuda_toolkit_path` contains both nvvm libs and binaries.\r\n\r\nDoes this make sense, and would you be able and willing to write a PR to fix this?", "@chsigg Thanks for getting back to me. What you said makes sense. Unfortunately I don't have time to raise a PR right now. I hope that I can in a few weekends from now, unless someone else would like to work on it sooner.", "ran into this trying to build 1.15, tried the solution of removing the check suggested, gets through configure, but the build fails early with a `ERROR: An error occurred during the fetch of repository 'local_config_cuda':\r\n   Traceback (most recent call last):`\r\n", "Honestly, this just points on the direction of the unnecessarily hard procedure to install, build or do anything with Tensorflow, or anything ML oriented in general. I have also run into this issue while trying to build 1.14 with 10.1/7.6.5, the path that brought me here was one of frustration, two times I had to reinstall the Nvidia drivers, my resolution fell to 1024 at one point, another time my apt completely broke, twice, who knows maybe I am just frustrated and unable to perform basic tasks, but it seems to me that this entire process is a tad bit harder than it should be. ", "@ambertide I started working on this issue over the weekend. I don't think it's completely TensorFlow's fault. The `nvidia-cuda-toolkit` package strangely spreads its libraries and executables throughout the file system. Part of the CUDA toolkit gets put into `/usr/lib/cuda`, part of it goes into `/usr/lib/nvidia-cuda-toolkit`, and some other bits go into `/usr/bin`. And there's also a few files which are wrappers which run executables in other directories. They could have been symlinks, but instead they're wrappers. I think Nvidia's .run file installer puts files in more sensible locations. TensorFlow works better with it, anyway.\r\n\r\nThat said, TensorFlow can circumvent all the Nvidia driver madness by just doing what PyTorch does and bundling the drivers with the Python module.", "> @ambertide I started working on this issue over the weekend. I don't think it's completely TensorFlow's fault. The `nvidia-cuda-toolkit` package strangely spreads its libraries and executables throughout the file system. Part of the CUDA toolkit gets put into `/usr/lib/cuda`, part of it goes into `/usr/lib/nvidia-cuda-toolkit`, and some other bits go into `/usr/bin`. And there's also a few files which are wrappers which run executables in other directories. They could have been symlinks, but instead they're wrappers. I think Nvidia's .run file installer puts files in more sensible locations. TensorFlow works better with it, anyway.\r\n> \r\n> That said, TensorFlow can circumvent all the Nvidia driver madness by just doing what PyTorch does and bundling the drivers with the Python module.\r\n\r\nYeah, I guess I was being a bit unfair, also to add for people who may stumble upon this in the future, sadly removing the consistency check for 1.14 does not resolve the problem. It continues to say 'cuda.h' was not found.\r\n", "Just encountered what seems to be the same problem on Ubuntu 20.04 with cuda 10.1 and nvidia driver 440.1 while trying to compile Tensorflow 1.14.0.\r\nMy error message is `Inconsistent CUDA toolkit path: /usr/lib/nvidia-cuda-toolkit vs /usr/lib/cudaAsking for detailed CUDA configuration...` \r\n\r\nIs there any update/workaround for this issue?", "Would it be possible for you to install NVIDIA's CUDA Toolkit in a single directory from NVIDIA\u2019s .run package with\r\n\r\n```\r\n$ wget https://developer.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.105_418.39_linux.run\r\n$ sudo sh cuda_10.1.105_418.39_linux.run --silent --toolkit --toolkitpath=/usr/local/cuda\r\n```", "Thank you for the reply. Unfortunately I'm not an admin on the machine, so I was hoping in some workaround from the TF side. In the meantime I'll try to contact an admin.", "If you aren't su, you can install the toolkit into a different folder, where you have write permission.", "Hi @DoxasticFox !\r\nWe are checking to see whether you still need help in this issue . Have you tried above [suggestion](https://github.com/tensorflow/tensorflow/issues/40202#issuecomment-663435110) yet? Thanks!", "@mohantym I just gave up.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40202\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40202\">No</a>\n"]}, {"number": 40201, "title": "TF-TRT reduction op converter tests", "body": "This PR adds unit test for the reduce op converters. Tagging @bixia1 for review. ", "comments": ["@tfeher  Can you please resolve conflicts? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Sorry for the delay.  I will update the PR soon. This, and many of the TF-TRT PRs that I have opened, are part of a large series of PRs that update / improve all the TF-TRT op converter tests. I will work on this as soon as some open issues are fixed in other related PRs.", "@tfeher  Can you please check @bixia1's comments and keep us posted ? Thanks!"]}, {"number": 40200, "title": "Quantization of LeNET model using MNIST dataset breaks during model freeze", "body": "I'm trying to train Lenet-net using the MNIST dataset from [here](http://yann.lecun.com/exdb/mnist/ ) and to quantize its float model. My steps are the following:\r\n\r\nFirstly, I have applied MNIST dataset to train the classifier which works fines. \r\n\r\n```\r\npython3 train_image_classifier.py --dataset_dir=tmp/mnist --dataset_name=mnist --train_dir=train/mnist --model_name=lenet --clone_on_cpu=true --max_number_of_steps=50000 --quantize_delay=40000\r\n```\r\n\r\nSecondly, I have exported the trained model to the pb format and it works well.\r\n\r\n```\r\npython3 export_inference_graph.py --dataset_dir=tmp/mnist --dataset_name=mnist --train_dir=train/mnist --model_name=lenet --checkpoint=train/mnist/model.ckpt-50000 --quantize --output_file=mnist.pb \r\n```\r\n\r\nFinally, I try to freeze graph using \r\n```\r\nfreeze_graph --input_graph=mnist.pb --input_checkpoint=train/mnist/model.ckpt-50000 --output_graph=mnist_frozen.pb --input_binary=true --output_node_names=Predictions/Reshape_1 \r\n``` \r\n\r\nbut the following error occurred\r\n\r\n```\r\nInvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nAssign requires shapes of both tensors to match. lhs shape= [5,5,3,32] rhs shape= [5,5,1,32] \r\n```\r\n\r\nPlease can you advise how to freeze it correctly?\r\n\r\n\r\nBTW, I have tried other models like CIFAR10 and all process works fine.\r\n", "comments": ["@peter197321,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "**Tools version:**\r\nPython= 3.7.7, TensorFlow=1.15.3, Numpy=1.16.4, contextlib2=0.6.0, pillow=7.1.2\r\n\r\n**Sources:**\r\n**```\r\nhttps://github.com/tensorflow/models/blob/master/research/slim/train_image_classifier.py\r\nhttps://github.com/tensorflow/models/blob/master/research/slim/export_inference_graph.py\r\n```**\r\n\r\n\r\nfreeze_graph and tflite_convert tools taken from Anaconda3 environment\r\n", "I guess I encounter an error in script [export_inference_graph.py](https://github.com/tensorflow/models/blob/57e075203f8fba8d85e6b74f17f63d0a07da233a/research/slim/export_inference_graph.py#L133) where image-grayscale and model are needed so I've changed hard-coded the number of channels to `1 ` for my case.\r\n\r\nOn another hand, I used to add explicit control switch `--use_grayscale` for a newer version from the master branch\r\n\r\nNow it seems it's working."]}, {"number": 40199, "title": "Rolled RNN cannot be converted to INT8", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS\r\n- TensorFlow installed from (source or binary): tf-nightly\r\n- TensorFlow version (use command below): 2.2.0.dev20200508 (also happens with 2.3.0.dev20200605)\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nWhen converting a rolled RNN model to INT8, the conversion fails with the following error:\r\n\r\n```\r\nTypeError: pybind11::init(): factory function returned nullptr\r\nDuring handling of the above exception, another exception occurred:\r\n...\r\nValueError: Failed to parse the model: pybind11::init(): factory function returned nullptr.\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe conversion should be successful.\r\n\r\n**Standalone code to reproduce the issue**\r\nPlease find the gist [here](https://colab.research.google.com/gist/MatteoArm/02a4f032cab5b58a414d741b78107de1/untitled0.ipynb)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nMy traceback:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 51, in __init__\r\n    _calibration_wrapper.CalibrationWrapper(model_content))\r\nTypeError: pybind11::init(): factory function returned nullptr\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"rnn_rolled_issue.py\", line 83, in <module>\r\n    tflite_model_INT8 = converter.convert()\r\n  File \"/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 639, in convert\r\n    output_tensors)\r\n  File \"/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 505, in convert\r\n    constants.FLOAT, True)\r\n  File \"/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 337, in _calibrate_quantize_model\r\n    calibrate_quantize = _calibrator.Calibrator(result)\r\n  File \"/opt/anaconda/3/envs/P3.7.4_TF2.2.0.dev20200508/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 53, in __init__\r\n    raise ValueError(\"Failed to parse the model: %s.\" % e)\r\nValueError: Failed to parse the model: pybind11::init(): factory function returned nullptr.\r\n```\r\n", "comments": ["@MatteoArm  \r\nPlease refer to these links and let us know if it helps.\r\n[link]((https://github.com/NVIDIA/TensorRT/issues/308))\r\n[link1](https://github.com/traveller59/torch2trt/issues/1#issuecomment-492603147)", "@Saduf2019 Thanks for the suggestion, but this seems to be a different issue.\r\nIt looks like the problem here originates in the python bindings for the CalibrationWrapper, or in the CalibrationWrapper class itself.", "Renjie, can you take a look.\r\n\r\nThanks", "looks like the problem is related to pybind?", "Hi YC, do you have any idea about this?\r\n\r\nThanks!", "Was able to replicate the issue with TF 2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/571b08d82ee6459c4e6716035fbbf197/untitled325.ipynb) ..Thanks!", "Hi @MatteoArm ! This issue is not replicating in Latest version (TF 2.7) now. Attaching [Gist](https://colab.sandbox.google.com/gist/mohantym/d4d87d7c6172789be22fd0b19a977918/untitled325.ipynb#scrollTo=effYrDkvO4qA) for reference .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40199\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40199\">No</a>\n"]}, {"number": 40198, "title": "Change snappy_buffers_test record size for s390x", "body": "On s390x the record size for snappy_buffers_test should be 620 bytes.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40198) for more info**.\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40198) for more info**.\n\n<!-- ok -->", "Given that the implementation of io::SnappyOutputBuffer is not being changed, I don't see why COMPRESSED_RECORD_SIZE needs updating.  The compression algorithm should presumably be architecture agnostic.  My guess is that there is an underlying issue that needs to be resolved.", "@cdavoudian Can you please resolve conflicts? Thanks!", "Resolved conflicts, still waiting for review & merge. Thanks!", "@gharibian Can you please review this PR ? Thanks!", "@saxenasaurabh Can you please review this PR ? Thanks!", "I don't think we have enough information to move forward with this PR. There is no indication of why the value should be changed nor is there a test to show what this issue fixes. @cdavoudian, could you please address the previous comments from @gharibian?", "@cdavoudian  Any update on this PR? Please. Thanks!", "@gbaned I am following his up on behalf of @cdavoudian who is no longer involved in this project. Unlike x86, on s390x (big-endian) architecture, snappy compresses the record size to 620 bytes.  This problem was also encounterd in TF v2.0.0.  Reading the testcase comments it appears that snappy can compress this to different sizes based on the implementation.", "@jaingaurav Can you please take a look on above comments from @rposts. Thanks!", "@rposts: Thanks for the context. Is there any way of validating this new value either by including some header from snappy? Otherwise, is there any test case that can be constructed to fail without this change? At very least please include a link to the documentation in the code, pointing to the different size.", "@rposts  Can you please check @jaingaurav's comments and keep us posted ? Thanks!", "@gbaned @jaingaurav Apologies for the delay - I will be looking at it shortly. Thx.", "@gbaned @jaingaurav - I ran the testcase on x86 and s390x and enclosing my results here.  As you can see, snappy compresses to different sizes on these 2 platforms: The call is made in [port.cc](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/platform/default/port.cc#L310):\r\n\r\nOn x86:\r\n```\r\n(gdb) p input\r\n$7 = 0x5555556c6ce0 \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce vehicula tincidunt libero sit amet ultrices. Vestibulum non felis augue. Duis vitae augue id lectus lacinia congue et ut purus. Donec auctor, nisl at dapibus volutpat, diam ante lacinia dolor, veldignissim lacus nisi sed purus. Duis fringilla nunc ac lacus sagittis efficitur. Praesent tincidunt egestas eros, eu vehicula urna ultrices et. Aliquam erat volutpat. Maecenas vehicula risus consequat risus dictum, luctus tincidunt nibh imperdiet. Aenean bibendum ac erat cursus scelerisque. Cras lacinia in enim dapibus iaculis. Nunc porta felis lectus, ac tincidunt massa pharetra quis. Fusce feugiat dolor vel ligula rutrum egestas. Donec vulputate quam eros, et commodo purus lobortis sed.Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce vehicula tincidunt libero sit amet ultrices. Vestibulum non felis augue. Duis vitae augue id lectus lacinia congue et ut purus. Donec auctor, nisl at dapibus volutpat, diam ante lacinia dolor, veldignissim lacus nisi sed purus. Duis fringilla nunc ac lacus sagittis efficitur. Praesent tincidunt egestas eros, eu vehicula urna ultrices et. Aliquam erat volutpat. Maecenas vehicula risus consequat risus dictum, luctus tincidunt nibh imperdiet. Aenean bibendum ac erat cursus scelerisque. Cras lacinia in enim dapibus iaculis. Nunc porta felis lectus, ac tincidunt massa pharetra quis. Fusce feugiat dolor vel ligula rutrum egestas. Donec vulputate quam eros, et commodo purus lobortis sed.\", 'x' <repeats 8496 times>, \" '\"\r\n(gdb) p length\r\n$8 = 752\r\n(gdb) l\r\n303\r\n304     std::size_t MallocExtension_GetAllocatedSize(const void* p) { return 0; }\r\n305\r\n306     bool Snappy_Compress(const char* input, size_t length, string* output) {\r\n307     #ifdef TF_USE_SNAPPY\r\n308       output->resize(snappy::MaxCompressedLength(length));\r\n309       size_t outlen;\r\n310       snappy::RawCompress(input, length, &(*output)[0], &outlen);\r\n311       output->resize(outlen);\r\n312       return true;\r\n(gdb) p length\r\n$9 = 752\r\n(gdb) p outlen\r\n$10 = 623\r\n(gdb) n\r\n310       snappy::RawCompress(input, length, &(*output)[0], &outlen);\r\n(gdb) n\r\n311       output->resize(outlen);\r\n(gdb) p outlen\r\n$11 = 619\r\n```\r\n\r\nOn s390x:\r\n```\r\n(gdb) p input\r\n$16 = 0x2aa001208d0 \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce vehicula tincidunt libero sit amet ultrices. Vestibulum non felis augue. Duis vitae augue id lectus lacinia congue et ut purus. Donec auctor, nisl at dapibus volutpat, diam ante lacinia dolor, veldignissim lacus nisi sed purus. Duis fringilla nunc ac lacus sagittis efficitur. Praesent tincidunt egestas eros, eu vehicula urna ultrices et. Aliquam erat volutpat. Maecenas vehicula risus consequat risus dictum, luctus tincidunt nibh imperdiet. Aenean bibendum ac erat cursus scelerisque. Cras lacinia in enim dapibus iaculis. Nunc porta felis lectus, ac tincidunt massa pharetra quis. Fusce feugiat dolor vel ligula rutrum egestas. Donec vulputate quam eros, et commodo purus lobortis sed.\", 'x' <repeats 9248 times>\r\n(gdb) p length\r\n$17 = 752\r\n(gdb) p outlen\r\n$18 = 2929168547440\r\n(gdb) n\r\n310       snappy::RawCompress(input, length, &(*output)[0], &outlen);\r\n(gdb)\r\n311       output->resize(outlen);\r\n(gdb) p outlen\r\n$19 = 620\r\n```\r\nUnfortunately I could not find any headers to prove unless digging deep into snappy code it but I think these results show snappy differences across x86/s390x.  Would this suffice?\r\n\r\nThanks.", "@jaingaurav Can you please take a look on above comments from @rposts. Thanks!", "@jaingaurav Any update on this PR? Please. Thanks!", "@rohan100jain Can you please take a look on this PR ? Thanks!", "We relaxed this in 47388e6e562b3589950ec2ae4a5a5e9a5563b916. `snappy_test` no longer checks for the exact size in the error message."]}, {"number": 40197, "title": "Add llvm support for s390x, fix xla and aot issue", "body": "Fixes issue #39912 . \r\n\r\nCurrently, 'systemz' or 's390x' was not included in the llvm build target list. It will throw an warning saying \"'z14' is not a recognized processor for this target (ignoring processor)\" then fail the endianness-check when using xla compiling.\r\n\r\nThis patch adds llvm support for s390x machine, fixing xla (including aot compile) features. It fixes 8 failed test cases and 1 failed-to-build test case on s390x. It is also has been tested to have no effect on x86 machines.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40197) for more info**.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40197) for more info**.\n\n<!-- ok -->", "Hi @joker-eph , would you mind taking a look into my PR? It has been awaiting review for a while, thank you.", "Sorry for the delay: I am auto-subscribed to PR touching tensorflow/compiler but I am mostly looking into MLIR-related work", "Thanks a lot for the approval, appreciate it.", "@sanjoy who's the best point of contact for adding this to tfcompile here?", "There seems to be a new conflict here (removing alias), I will double-check and push again soon.", "@sanjoy Any update on this PR? Please. Thanks!", "> @sanjoy Any update on this PR? Please. Thanks!\r\n\r\nThe PR LGTM, but I want to not merge it as-is (since I need to make some internal changes).  How do I do that?  If I approve it, it will get auto-merged right?", "Hi @sanjoy ,\r\nthanks for the comment. I notice that `@llvm-project//llvm:SystemZCodeGen` is already guarded in `tensorflow/compiler/xla/service/cpu/BUILD`, so I add a similar guard to it in `tensorflow/compiler/aot/BUILD`(They seem to be the only 2 places that this dependency is used). I use the `//tensorflow:linux_s390x` macro to guard for s390x machine, and I leave the `if_llvm_aarch64_available` part \"as is\" because you mention it needs to be fixed in the future. Please let me know if I missed anything or if you prefer I use another macro, thanks.", "Thank you @sanjoy for the feedback, I have wrote a macro `if_llvm_s390x_available` and use it exactly the same as `if_llvm_aarch64_available`. Please let me know if there's anything wrong with it.", "Thank you for the approval @sanjoy , I'm so sorry that I made a typo in my last commit, I think that could be the reason causing the CI tests failed. I have fixed it now, could you please re-approve it to see if the CI could pass this time?\r\n", "Hmm, it seems that it is still failing, I will look into this tomorrow, thank you @sanjoy .", "I think the duplicate dependency was the cause of the failure, it was actually a collision but was not detected by git. It is fixed now and should be able to pass the CI test (I successfully built it on my side).", "CI build has passed but sanity check failed. It suggested me to do the following change:\r\n```diff\r\ndiff --git a/tensorflow/compiler/aot/BUILD b/tensorflow/compiler/aot/BUILD\r\nindex 33d0adc96d..33edb527f4 100644\r\n--- a/tensorflow/compiler/aot/BUILD\r\n+++ b/tensorflow/compiler/aot/BUILD\r\n@@ -36,8 +36,9 @@ cc_library(\r\n         \"flags.h\",\r\n         \"quantize.h\",\r\n     ],\r\n-    defines = if_llvm_aarch64_available([\"TF_LLVM_AARCH64_AVAILABLE=1\"])\r\n-              + if_llvm_s390x_available([\"TF_LLVM_S390X_AVAILABLE=1\"]),\r\n+    defines = if_llvm_aarch64_available([\"TF_LLVM_AARCH64_AVAILABLE=1\"]) + if_llvm_s390x_available([\r\n+        \"TF_LLVM_S390X_AVAILABLE=1\",\r\n+    ]),\r\n     visibility = [\"//tensorflow/python:__pkg__\"],\r\n     deps = [\r\n         \":aot_only_var_handle_op\",\r\n```\r\n\r\nHowever, this does not really look neat to me, and I am not familiar with the preferred style here either. Do I need to make this change or if you could suggest a better style to pass sanity check here? Thanks.", "> However, this does not really look neat to me, and I am not familiar with the preferred style here either. Do I need to make this change or if you could suggest a better style to pass sanity check here?\r\n\r\nI would suggest making the change, I don't think fighting the build-file formatter is a good use of our time.", "@Sidong-Wei Can you please check @sanjoy's comments and address Ubuntu Sanity errors? Thanks!", "Sure @gbaned , I have pushed the change according to the sanity check suggestion. I just wanted to check if there's any better idea than its suggestion, it should be good now.", "Hi, it seems to me that all checks have passed, just wondering is there anything else I need to do before the PR is merged?"]}, {"number": 40196, "title": "2.3 Nightly build produces error when initializing system in TF documentation's Colab tutorial", "body": "**System information**\r\n- Have I written custom code: NO\r\n- TensorFlow installed from: pip (tf-nightly)\r\n- TensorFlow version: 2.3.0-dev20200605\r\n\r\n**Describe the current behavior**\r\nTPU won't initialize in colab using the nightly build.\r\n\r\n**Describe the expected behavior**\r\nRun the https://www.tensorflow.org/guide/tpu notebook successfully, as one would if using TF 2.2.\r\n\r\n**Standalone code to reproduce the issue**\r\n1. Load https://www.tensorflow.org/guide/tpu in colab.\r\n2. Run `!pip install tf-nightly` in a new cell before running anything else.\r\n3. Run the TPU initialization section of the notebook.\r\n4. Observe the following error:\r\n\r\n```InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}\r\n```\r\n\r\n\r\n", "comments": ["@jasonbrancazio \r\n\r\nI have tried in  colab with TF nightly version (`2.3.0-dev20200605`) .Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/0dcb9b852c34d150ef74573641eeef22/untitled54.ipynb).Is this expected behavior?.Thanks!", "@ravikyram Yes, the InvalidArgumentError is the same error I experienced.", "That indicates a version mismatch between your colab client and TPU worker. Is your TPU worker also nightly?", "@rxsang I don't see how to determine without modifying the steps indicated above whether the TPU worker is using a nightly version of tf. Would you mind posting how to determine this? \r\n\r\nI did see your trick here, which seems to be related to provisioning a worker at a certain version level rather than inspecting its properties: https://github.com/tensorflow/tensorflow/issues/34346#issuecomment-598399912\r\n\r\nRegardless, I just retried the steps outlined in my bug report. I no longer see the error I reported.  \r\n\r\nPerhaps the default versions in colab notebooks are no longer mismatched.", "@jasonbrancazio Looks like this was already resolved. I cannot reproduce the error with `tf-nightly`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/f3e731ccbb301541790371112502f50c/tpu.ipynb).\r\n\r\nI am closing this issue as this was already resolved. Please feel free to reopen if I am mistaken. Thanks!"]}, {"number": 40194, "title": "How to feed multi tf.data.Dataset objects into a multi-input/output model in tensorflow", "body": "I how to deal with multi input/output when the input is numpy arrays. However, my inputs are all tf.data.datasets objects. And I would like to feed the latter into a multi-input/output in tensorflow keras 2.1. \r\n\r\n    def prepare_dataset(...):\r\n        X_train = tf.data.Dataset.from_tensor_slices(final_df_QS_normalized_train_val)\r\n        X_train = X_train.window(train_window_length, shift=1, drop_remainder=True)\r\n        X_train = X_train.flat_map(lambda window : window.batch(train_window_length))\r\n        X_train = X_train.shuffle(100, seed=42)\r\n        X_train = X_train.batch(batch_size)\r\n\r\n        y_train = tf.data.Dataset.from_tensor_slices(final_df_DQ_normalized_train_val)\r\n        y_train = y_train.window(train_window_length, shift=1, drop_remainder=True)\r\n        y_train = y_train.flat_map(lambda window : window.batch(train_window_length))\r\n        y_train = y_train.shuffle(100, seed=42)\r\n        y_train = y_train.batch(batch_size)\r\n\r\n        sample_weights_train = tf.data.Dataset.from_tensor_slices(sample_weights_df_train_val)\r\n        sample_weights_train = sample_weights_train.window(train_window_length, shift=1, drop_remainder=True)\r\n        sample_weights_train = sample_weights_train.flat_map(lambda window : window.batch(train_window_length))\r\n        sample_weights_train = sample_weights_train.shuffle(100, seed=42)\r\n        sample_weights_train = sample_weights_train.batch(batch_size)\r\n        ..... # the same is applied to the validation data part....\r\n        return X_train, y_train, sample_weights_train\r\n\r\nThen I have a method that creates a model and return the input/output as follows:\r\n\r\n    def build_uncomplied_model(hparams, CASE_UPC_CD):\r\n        inputs = tf.keras.Input(shape=(None, 1), name=CASE_UPC_CD + \"_input\")\r\n        x = inputs\r\n\r\n        if hparams['model_uncertainty']:\r\n                x = layers.Bidirectional(layers.LSTM(hparams[\"cell_size_1\"], return_sequences=True, \r\n                                                    dropout=hparams['dropout']), merge_mode=hparams['merge_mode'])(x, training=True)\r\n        else:\r\n                x = layers.Bidirectional(layers.LSTM(hparams[\"cell_size_1\"], return_sequences=True, \r\n                                                    dropout=hparams['dropout']))(x)\r\n\r\n        outputs = layers.TimeDistributed(layers.Dense(1), name=CASE_UPC_CD + \"_output\")(x)\r\n\r\n        return inputs, outputs\r\n\r\nThen inside a for loop, I created a multiple of this model. All inputs/outputs are stored in a list to be used later in model creation. \r\n\r\n    c = 0\r\n    for CASE_UPC_CD in tqdm(final_df_QS_normalized_train.columns.values):\r\n        c += 1\r\n        logdir = os.path.join(ROOT_DIR, \"logs_SeparateLSTMs\", time_now, CASE_UPC_CD)\r\n\r\n        X_train, y_train, sample_weights_train, X_valid, y_valid, sample_weights_valid = \\\r\n                                                       prepare_dataset(final_df_QS_normalized_train[CASE_UPC_CD], \r\n                                                       final_df_DQ_normalized_train[CASE_UPC_CD], \r\n                                                       final_df_QS_normalized_valid[CASE_UPC_CD], \r\n                                                       final_df_DQ_normalized_valid[CASE_UPC_CD], \r\n                                                       sample_weights_df_train[CASE_UPC_CD], \r\n                                                       sample_weights_df_valid[CASE_UPC_CD], hparams)\r\n\r\n        train_input[CASE_UPC_CD + \"_input\"] = X_train\r\n        train_output[CASE_UPC_CD + \"_output\"] = y_train\r\n\r\n        valid_input[CASE_UPC_CD + \"_input\"] = X_valid\r\n        valid_output[CASE_UPC_CD + \"_output\"] = y_valid\r\n\r\n        inputs, outputs = build_uncomplied_model(hparams, CASE_UPC_CD)\r\n\r\n        inputs_all.append(inputs)\r\n        outputs_all.append(outputs)\r\n\r\n        if c == 10:\r\n            break\r\n\r\n    train_dataset = tf.data.Dataset.from_tensor_slices((train_input, train_output))\r\n    valid_dataset = tf.data.Dataset.from_tensor_slices((valid_input, valid_output))\r\n\r\nThis last line is throwing an error:\r\n\r\n    ValueError: Unbatching a dataset is only supported for rank >= 1\r\n\r\nHow to solve this issue? Any help is much appreciated\r\n", "comments": ["@IscaAy \r\nI ran the code shared, please find the gist of the same [here](https://colab.sandbox.google.com/gist/Saduf2019/f13d15dca62cf3cceee53485bc3c61d7/untitled208.ipynb). please provide complete stand alone code such that we can replicate the issue faced or if possible share a colab gist.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40192, "title": "'Function could not be transformed and will be executed as-is' while training RNN with Embedding in Keras", "body": "I got the attached error saying that I should report to \"AutoGraph team\".\r\n\r\nI was training a following toy-model:\r\n\r\n```\r\nmodel = keras.Sequential()\r\n\r\nmodel.add(keras.layers.Embedding(vocab_size, 2, input_length = max_len))\r\nmodel.add(keras.layers.Flatten())             \r\nmodel.add(keras.layers.Dense(1, activation = 'sigmoid'))\r\n```\r\n\r\nwith `tf.keras`, tensorflow version == '2.0.0'.\r\n\r\nOperating system = Win10\r\nPython = 3.6\r\n\r\n```\r\nTrain on 14 samples\r\nEpoch 1/300\r\nWARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001F5E571F620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001F5E571F620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nEpoch 2/300\r\nEpoch 3/300\r\nEpoch 4/300\r\nEpoch 5/300\r\nEpoch 6/300\r\nEpoch 7/300\r\nEpoch 8/300\r\nEpoch 9/300\r\nEpoch 10/300\r\nEpoch 11/300\r\nEpoch 12/300\r\nEpoch 13/300\r\nEpoch 14/300\r\nEpoch 15/300\r\nEpoch 16/300\r\nEpoch 17/300\r\nEpoch 18/300\r\nEpoch 19/300\r\nEpoch 20/300\r\nEpoch 21/300\r\nEpoch 22/300\r\nEpoch 23/300\r\nEpoch 24/300\r\nEpoch 25/300\r\nEpoch 26/300\r\nEpoch 27/300\r\nEpoch 28/300\r\nEpoch 29/300\r\nEpoch 30/300\r\nEpoch 31/300\r\nEpoch 32/300\r\nEpoch 33/300\r\nEpoch 34/300\r\nEpoch 35/300\r\nEpoch 36/300\r\nEpoch 37/300\r\nEpoch 38/300\r\nEpoch 39/300\r\nEpoch 40/300\r\nEpoch 41/300\r\nEpoch 42/300\r\nEpoch 43/300\r\nEpoch 44/300\r\nEpoch 45/300\r\nEpoch 46/300\r\nEpoch 47/300\r\nEpoch 48/300\r\nEpoch 49/300\r\nEpoch 50/300\r\nEpoch 51/300\r\nEpoch 52/300\r\nEpoch 53/300\r\nEpoch 54/300\r\nEpoch 55/300\r\nEpoch 56/300\r\nEpoch 57/300\r\nEpoch 58/300\r\nEpoch 59/300\r\nEpoch 60/300\r\nEpoch 61/300\r\nEpoch 62/300\r\nEpoch 63/300\r\nEpoch 64/300\r\nEpoch 65/300\r\nEpoch 66/300\r\nEpoch 67/300\r\nEpoch 68/300\r\nEpoch 69/300\r\nEpoch 70/300\r\nEpoch 71/300\r\nEpoch 72/300\r\nEpoch 73/300\r\nEpoch 74/300\r\nEpoch 75/300\r\nEpoch 76/300\r\nEpoch 77/300\r\nEpoch 78/300\r\nEpoch 79/300\r\nEpoch 80/300\r\nEpoch 81/300\r\nEpoch 82/300\r\nEpoch 83/300\r\nEpoch 84/300\r\nEpoch 85/300\r\nEpoch 86/300\r\nEpoch 87/300\r\nEpoch 88/300\r\nEpoch 89/300\r\nEpoch 90/300\r\nEpoch 91/300\r\nEpoch 92/300\r\nEpoch 93/300\r\nEpoch 94/300\r\nEpoch 95/300\r\nEpoch 96/300\r\nEpoch 97/300\r\nEpoch 98/300\r\nEpoch 99/300\r\nEpoch 100/300\r\nEpoch 101/300\r\nEpoch 102/300\r\nEpoch 103/300\r\nEpoch 104/300\r\nEpoch 105/300\r\nEpoch 106/300\r\nEpoch 107/300\r\nEpoch 108/300\r\nEpoch 109/300\r\nEpoch 110/300\r\nEpoch 111/300\r\nEpoch 112/300\r\nEpoch 113/300\r\nEpoch 114/300\r\nEpoch 115/300\r\nEpoch 116/300\r\nEpoch 117/300\r\nEpoch 118/300\r\nEpoch 119/300\r\nEpoch 120/300\r\nEpoch 121/300\r\nEpoch 122/300\r\nEpoch 123/300\r\nEpoch 124/300\r\nEpoch 125/300\r\nEpoch 126/300\r\nEpoch 127/300\r\nEpoch 128/300\r\nEpoch 129/300\r\nEpoch 130/300\r\nEpoch 131/300\r\nEpoch 132/300\r\nEpoch 133/300\r\nEpoch 134/300\r\nEpoch 135/300\r\nEpoch 136/300\r\nEpoch 137/300\r\nEpoch 138/300\r\nEpoch 139/300\r\nEpoch 140/300\r\nEpoch 141/300\r\nEpoch 142/300\r\nEpoch 143/300\r\nEpoch 144/300\r\nEpoch 145/300\r\nEpoch 146/300\r\nEpoch 147/300\r\nEpoch 148/300\r\nEpoch 149/300\r\nEpoch 150/300\r\nEpoch 151/300\r\nEpoch 152/300\r\nEpoch 153/300\r\nEpoch 154/300\r\nEpoch 155/300\r\nEpoch 156/300\r\nEpoch 157/300\r\nEpoch 158/300\r\nEpoch 159/300\r\nEpoch 160/300\r\nEpoch 161/300\r\nEpoch 162/300\r\nEpoch 163/300\r\nEpoch 164/300\r\nEpoch 165/300\r\nEpoch 166/300\r\nEpoch 167/300\r\nEpoch 168/300\r\nEpoch 169/300\r\nEpoch 170/300\r\nEpoch 171/300\r\nEpoch 172/300\r\nEpoch 173/300\r\nEpoch 174/300\r\nEpoch 175/300\r\nEpoch 176/300\r\nEpoch 177/300\r\nEpoch 178/300\r\nEpoch 179/300\r\nEpoch 180/300\r\nEpoch 181/300\r\nEpoch 182/300\r\nEpoch 183/300\r\nEpoch 184/300\r\nEpoch 185/300\r\nEpoch 186/300\r\nEpoch 187/300\r\nEpoch 188/300\r\nEpoch 189/300\r\nEpoch 190/300\r\nEpoch 191/300\r\nEpoch 192/300\r\nEpoch 193/300\r\nEpoch 194/300\r\nEpoch 195/300\r\nEpoch 196/300\r\nEpoch 197/300\r\nEpoch 198/300\r\nEpoch 199/300\r\nEpoch 200/300\r\nEpoch 201/300\r\nEpoch 202/300\r\nEpoch 203/300\r\nEpoch 204/300\r\nEpoch 205/300\r\nEpoch 206/300\r\nEpoch 207/300\r\nEpoch 208/300\r\nEpoch 209/300\r\nEpoch 210/300\r\nEpoch 211/300\r\nEpoch 212/300\r\nEpoch 213/300\r\nEpoch 214/300\r\nEpoch 215/300\r\nEpoch 216/300\r\nEpoch 217/300\r\nEpoch 218/300\r\nEpoch 219/300\r\nEpoch 220/300\r\nEpoch 221/300\r\nEpoch 222/300\r\nEpoch 223/300\r\nEpoch 224/300\r\nEpoch 225/300\r\nEpoch 226/300\r\nEpoch 227/300\r\nEpoch 228/300\r\nEpoch 229/300\r\nEpoch 230/300\r\nEpoch 231/300\r\nEpoch 232/300\r\nEpoch 233/300\r\nEpoch 234/300\r\nEpoch 235/300\r\nEpoch 236/300\r\nEpoch 237/300\r\nEpoch 238/300\r\nEpoch 239/300\r\nEpoch 240/300\r\nEpoch 241/300\r\nEpoch 242/300\r\nEpoch 243/300\r\nEpoch 244/300\r\nEpoch 245/300\r\nEpoch 246/300\r\nEpoch 247/300\r\nEpoch 248/300\r\nEpoch 249/300\r\nEpoch 250/300\r\nEpoch 251/300\r\nEpoch 252/300\r\nEpoch 253/300\r\nEpoch 254/300\r\nEpoch 255/300\r\nEpoch 256/300\r\nEpoch 257/300\r\nEpoch 258/300\r\nEpoch 259/300\r\nEpoch 260/300\r\nEpoch 261/300\r\nEpoch 262/300\r\nEpoch 263/300\r\nEpoch 264/300\r\nEpoch 265/300\r\nEpoch 266/300\r\nEpoch 267/300\r\nEpoch 268/300\r\nEpoch 269/300\r\nEpoch 270/300\r\nEpoch 271/300\r\nEpoch 272/300\r\nEpoch 273/300\r\nEpoch 274/300\r\nEpoch 275/300\r\nEpoch 276/300\r\nEpoch 277/300\r\nEpoch 278/300\r\nEpoch 279/300\r\nEpoch 280/300\r\nEpoch 281/300\r\nEpoch 282/300\r\nEpoch 283/300\r\nEpoch 284/300\r\nEpoch 285/300\r\nEpoch 286/300\r\nEpoch 287/300\r\nEpoch 288/300\r\nEpoch 289/300\r\nEpoch 290/300\r\nEpoch 291/300\r\nEpoch 292/300\r\nEpoch 293/300\r\nEpoch 294/300\r\nEpoch 295/300\r\nEpoch 296/300\r\nEpoch 297/300\r\nEpoch 298/300\r\nEpoch 299/300\r\nEpoch 300/300\r\n\r\n<tensorflow.python.keras.callbacks.History at 0x1f5ebf5b320>\r\n```", "comments": ["@AlxndrMlk,\r\nWhile running the code I'm facing an error stating `NameError: name 'vocab_size' is not defined`.\r\nCould you please provide the complete code to reproduce the issue reported here.\r\n\r\nAlso, as per [#38691](https://github.com/tensorflow/tensorflow/issues/38691), the issue seems to be fixed in  TF-nightly. Could you please upgrade to the latest TF-nightly and let us know if it works. Thanks!", "Sure, @amahendrakar, pasting the full code below. Thanks!\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow.keras as keras\r\n\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\n\r\nimport matplotlib.pyplot as plt\r\nplt.style.use('fivethirtyeight')\r\n\r\n# Define docs\r\ndocs = [\r\n    'Amazing!',\r\n    'Well done!',\r\n    'Great job!',\r\n    'Good job',\r\n    'Nicely done!',\r\n    'Amazing job!',\r\n    'Not bad!',\r\n    'Very poor.',\r\n    'Not well',\r\n    'Not very well written',\r\n    'Purely bad',\r\n    'It\\'s not good.',\r\n    'Very badly done',\r\n    'Very bad'\r\n]\r\n    \r\n# Define labels\r\nlabels = np.array([1] * 7 + [0] * 7)\r\n\r\n# Tokenize the docs\r\nvocab_size = 50\r\n\r\ntokenizer = keras.preprocessing.text.Tokenizer(vocab_size, oov_token = '<UNK>')\r\ntokenizer.fit_on_texts(docs)\r\n\r\nseqs = tokenizer.texts_to_sequences(docs)\r\n\r\n# Pad sequences\r\nmax_len = max([len(x) for x in seqs]) + 2\r\n\r\npadded_seqs = pad_sequences(seqs, \r\n                            maxlen  = max_len, \r\n                            padding = 'post')\r\n\r\nmodel = keras.Sequential()\r\n\r\nmodel.add(keras.layers.Embedding(vocab_size, 32, input_length = max_len))\r\nmodel.add(keras.layers.Flatten())              # We need to flatten the array before the dense layer\r\nmodel.add(keras.layers.Dense(32))\r\nmodel.add(keras.layers.Dropout(.2))\r\nmodel.add(keras.layers.Dense(32))\r\nmodel.add(keras.layers.Dropout(.2))\r\nmodel.add(keras.layers.Dense(1, activation = 'sigmoid'))\r\n\r\n# Compile the model\r\nmodel.compile(optimizer = 'adam', \r\n              loss      = 'binary_crossentropy', \r\n              metrics   = ['accuracy'])\r\n\r\n# Fit the model\r\nmodel.fit(padded_seqs, labels, epochs = 150, verbose = 10)\r\n\r\n# Note that after all the model fits the data and loss goes down as expected:\r\n# plt.plot(model.history.history['accuracy'])\r\nplt.plot(model.history.history['loss'])\r\n```\r\n", "When it comes to installing the latest nightly, I'll be able to do this later this week.", "> When it comes to installing the latest nightly, I'll be able to do this later this week.\r\n\r\n@AlxndrMlk,\r\nAny updates regarding this issue? Thanks!", "@amahendrakar - sorry for the delayed response. Not so far, unfortunately. \r\n\r\nI was not able to successfully install and run tf > 2.0 on my machine. I need more time to investigate this issue. I'll try to find a while during the weekend to check it.", "> I was not able to successfully install and run tf > 2.0 on my machine. I need more time to investigate this issue. I'll try to find a while during the weekend to check it.\r\n\r\n@AlxndrMlk,\r\nDid you get a chance to look into this over the weekend? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 40191, "title": "Convert IndexedSlices to Tensors for backward ConcreteFunction calls.", "body": "Fixes #36236.\r\n\r\nTL;DR: When a `tf.function` is used in a computation graph, during backward pass all inputs must be Tensors. If they are IndexedSlices (which can happen when for example `tf.gather` is used), an exception is raised.\r\n\r\nThe fix automatically converts IndexedSlices to Tensors during a backward pass on a ConcreteFunction.\r\n\r\nThe conversion is currently silent, i.e., no warning is produced. I could imagine a warning being emitted.", "comments": []}, {"number": 40190, "title": "Add INT16 support in modify_model_interface", "body": " * Added support for 16bit quantized models in modify_model_interface.cc\r\n * Added extra arguments for inputing 16bit quantized models in modify_model_interface_main.cc\r\n * Modified 2 of the unit tests to be parametrized and covered 16bit models in modify_model_interface_test.cc", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40190) for more info**.\n\n<!-- need_sender_cla -->", "Related to #36632", "@TamasArm Thank you for your contribution. Can you please sign CLA? Thanks!", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40190) for more info**.\n\n<!-- ok -->", "@TamasArm Can you please resolve conflicts? Thanks!", "Is there anything else I can do to help move this forward?", "Gentle ping: @MeghnaNatraj @renjie-liu ", "@TamasArm could you merge the latest changes? There is just one merge conflict. \r\nOtherwise this looks good to me as well!\r\n\r\n@jianlijianli Can you take a final look at this before we merge these changes?", "Bear with me, I am trying to fix the issues with extra commits on my log after a failed rebase, sorry about that!", "Fixed now, it's free to review again!", "@akarmi Yes, we should be making the changes in the python equivalent code as well. \r\n\r\n@TamasArm If you're not familiar with this, let us know and I can make this change later.\r\n\r\nIf you're interested to try: We have a python wrapper that internally invokes the c++ library `modify_model_interface.cc` which you have updated. The workflow is: User runs [modify_model_interface.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/optimize/python/modify_model_interface.py) --> [modify_model_interface_lib.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/optimize/python/modify_model_interface_lib.py) --> [pybind (python to c++ connection) file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/optimize/python/modify_model_interface.cc) which ultimately invokes `modify_model_interface.cc` \r\n\r\nTo support your changes in python, you need to update [modify_model_interface_constants.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/optimize/python/modify_model_interface_constants.py) to add INT16 and a test to create an INT16 quantized model and validate this in [modify_model_interface_lib_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/optimize/python/modify_model_interface_lib_test.py)\r\n\r\nIf this is confusing, do let us know and we can update it on our end :)\r\n\r\n", "@MeghnaNatraj Thank you for the explanation! It seems clear to me, I'll get started on it right away, I'll try to be done with it by Monday night. Should I do it in a seperate PR?", "@TamasArm Yes, let us add this change in a separate PR. I'll go ahead and work on merging this change.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40190) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 40189, "title": "Install Tensorflow CPU package for CPU images", "body": "/cc @yifeif @seanpmorgan", "comments": ["@yifeif As a side note why we don't have the custom_ops release push for TF 2.2.0 at https://hub.docker.com/r/tensorflow/tensorflow/tags?page=1&name=custom? \r\nThe last release is still 2.1.0.", "> @yifeif As a side note why we don't have the custom_ops release push for TF 2.2.0 at https://hub.docker.com/r/tensorflow/tensorflow/tags?page=1&name=custom?\r\n> The last release is still 2.1.0.\r\n\r\nThanks @bhack. I'm on it.", "It is strange seems that kokoro is not triggered.", "@gbaned why you removed ready to pull label?", "Is the CI still generally broken on MacOS and Windows? It was broken on Friday but as I see it is not a required step in the pipeline to merge the PR.", "> Is the CI still generally broken on MacOS and Windows? It was broken on Friday but as I see it is not a required step in the pipeline to merge the PR.\r\n\r\n@bhack Thanks for the confirmation, we will process the PR. ", "> > @yifeif As a side note why we don't have the custom_ops release push for TF 2.2.0 at https://hub.docker.com/r/tensorflow/tensorflow/tags?page=1&name=custom?\r\n> > The last release is still 2.1.0.\r\n> \r\n> Thanks @bhack. I'm on it.\r\n\r\nThanks for the help @yifeif! Please let us know when a 2.2 image is available. Preferably with `tensorflow-cpu` in the CPU container to save space (per this PR).", "@gbaned Are you sure the `ready to pull` is enough to trigger kokoro in cases like this one?  I cannot view the kokoro logic or queue but it is seems to me that you we are in one of the cases that you need to force the label. ", "@seanpmorgan @bhack I've pushed the 2.2 images. Let me know if you guys run into any issue."]}, {"number": 40188, "title": "No documentatio non how to manipulate a python.data.ops.dataset_oops.BatchDataset", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://keras.io/api/preprocessing/image/\r\n\r\n## Description of issue (what needs changing):\r\nthe documentation says that the object returned from the tf.keras.preprocessing.image_dataset_from_directory function is a tf.data.Dataset object.  However, there is no documentation on how to manipulate it or get details how to use it. I\r\n### Clear description\r\nI have a large dataset and i am trying to split it into testing and training, however while i can \"complete a validation split in the  function (as documented) this is no documentation on how I can address the training or validation subsets.  Should i convert the objects to np array or can it be manipulated within TF and if so how?\r\n\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n    wk_dir,\r\n    labels=\"inferred\",\r\n    label_mode=\"int\",\r\n    class_names=None,\r\n    color_mode=\"grayscale\",\r\n    batch_size=batches,\r\n    image_size=image_dim,\r\n    shuffle=True,\r\n    seed=1968,\r\n    validation_split=0.2,\r\n    subset=\"training\",\r\n    interpolation=\"bilinear\",\r\n    follow_links=False,\r\n)\r\n\r\n### Returns defined\r\n\r\nFound 127842 files belonging to 3 classes.\r\nUsing 102274 files for training.\r\n\r\nprint(type(train_ds))\r\n<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\r\n\r\nwhat are the attributes which can be used to , get details and possible split this object type?\r\nAttributeError: 'BatchDataset' object has no attribute 'eval'\r\n\r\n### Raises listed and defined\r\n\r\n\r\n\r\n\r\n", "comments": ["I think the function returns an instance of `tf.data.BatchDataset`, you can read the documents of `tf.data` API here [tf.data](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch).", "@Cillinc \r\nPlease update as per above comment", "thanks - i am reading the documentation and struggling to get things to work.  if it is a tf.datch.BatchDataset then i will continue to work with the documentation.  one would assume that one of the most common things people did once they imported files into a TF was to split them into training and validation....but this is not clear in the documentation as to how to do it.  I have set the , validation_split=0.2,\r\n    subset=\"validation\", \r\nand that works, but i do not see how to address the subsets and `AttributeError: 'BatchDataset' object has no attribute 'subset'`\r\nso working ahead and trying everything i can find......", "Try making two sets one for training and one for validation. (I include my setup in COLAB).\r\n\r\nBy the way do you have any idea how to extract class_names and labels that are derived from the sub-directories? I need that to decode the outcome when I test an image. I have no idea how to get that working, yet.\r\n\r\n I am new in CNN so I cannot explain most of the issues. Got this together by trial and error.\r\n\r\n<pre>\r\nimport numpy as np\r\nimport IPython.display as display \r\nfrom PIL import Image\r\nimport matplotlib.pyplot as plt\r\nimport os\r\nimport IPython.display as display\r\nimport glob\r\n\r\n!pip install tf-nightly --quiet\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras import preprocessing\r\nimport time\r\n\r\nimage_size = (331,331)\r\nbatch_size = 32\r\ntrain_ds=` tf.keras.preprocessing.image_dataset_from_directory(\r\n    \"/content/drive/My Drive/AR\",\r\n    labels=\"inferred\",\r\n    label_mode=\"categorical\",\r\n    class_names=None,\r\n    batch_size=batch_size,\r\n    image_size=image_size,\r\n    color_mode =  \"rgb\",\r\n    shuffle=True,\r\n    seed=142,\r\n    validation_split=0.2,\r\n    subset= \"training\",\r\n    interpolation=\"bilinear\",\r\n    follow_links=False,\r\n)\r\n\r\nvalidation_ds= tf.keras.preprocessing.image_dataset_from_directory(\r\n    \"/content/drive/My Drive/AR\",\r\n    labels=\"inferred\",\r\n    label_mode=\"categorical\",\r\n    batch_size=batch_size,\r\n    image_size=image_size,\r\n     color_mode =  \"rgb\",\r\n    shuffle=True,\r\n    seed=142,\r\n    validation_split=0.2,\r\n    subset= \"validation\",\r\n    interpolation=\"bilinear\",\r\n    follow_links=False,\r\n    )\r\n</pre>\r\nThat results in:\r\n<pre>Found 34 files belonging to 3 classes.\r\nUsing 28 files for training.\r\nFound 34 files belonging to 3 classes.\r\nUsing 6 files for validation.\r\n</pre>\r\n\r\nThose two sets can then be entered in your convnet. Below what I use.\r\n<pre>\r\n#Note: num_classes must be similar to the train_ds dataset 3 in this particular case.\r\n\r\ndata_augmentation = keras.Sequential([\r\n  layers.experimental.preprocessing.RandomFlip('horizontal'),\r\n  layers.experimental.preprocessing.RandomRotation(0.1),\r\n])\r\n\r\ntrain_ds = train_ds.prefetch(buffer_size=32)\r\nvalidation_ds = validation_ds.prefetch(buffer_size=32)\r\nmodel = tf.keras.applications.InceptionResNetV2(input_shape=(331,331, 3), include_top=False, weights='imagenet')\r\n\r\ndef make_model(input_shape, num_classes):\r\n  inputs = keras.Input(shape=input_shape)\r\n  # Image augmentation block\r\n  x = data_augmentation(inputs)\r\n\r\n  # Entry block\r\n  x = layers.experimental.preprocessing.Rescaling(1./255)(x)\r\n  x = model(x)\r\n\r\n  previous_block_activation = x  # Set aside residual\r\n\r\n  x = layers.GlobalAveragePooling2D()(x)\r\n  if num_classes == 2:\r\n    activation = 'sigmoid'\r\n    units = 1\r\n  else:\r\n    activation = 'softmax'\r\n    units = num_classes\r\n  \r\n  x = layers.Dropout(0.5)(x)\r\n  outputs = layers.Dense(units, activation=activation)(x)\r\n  return keras.Model(inputs, outputs)\r\n\r\nmodel = make_model(input_shape=image_size + (3,), num_classes=3)\r\nkeras.utils.plot_model(model, show_shapes=True)\r\n</pre>\r\n\r\nNow that is my model. Below code for training en storing the best model on your googleDrive for later tests.\r\n\r\n<pre>\r\nepochs = 10\r\n#model = make_model(input_shape=image_size + (3,), num_classes=3)\r\nfile_path = \"/content/drive/My Drive/TrainedNetwork/.\"\r\n\r\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"/content/drive/My Drive/TrainedNetwork/model-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5\", verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \r\n\r\n#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\r\nmodel.compile(optimizer=keras.optimizers.Adam(1e-3),\r\n              loss='categorical_crossentropy',\r\n              metrics=['accuracy'])\r\nmodel.fit(train_ds, epochs=epochs, validation_data=validation_ds, callbacks=[checkpoint], verbose=2)\r\n</pre>", "thanks in my case I was not worried about what values were given to the class names - just that there was 3 classes which the model could work with.  SO i used each of the subdirectories as their own classes and it is working for me.  \r\n\r\nnow my only problem is that the image files are all B&W and the distinguishing attributes to tell one class from another is not enough for the model i have.  So might have to rethink things and put 3 filters into a RGB type image and try again......but this is the fun of things - and also a great way to learn.", "@Cillinc \r\nAs you have a solution, should we move this issue to closed status", "thanks for thew suport!!!!!"]}, {"number": 40187, "title": "When using batch normalization layer in distributed training, saved model couldn't be used to predict or serve in tfserving", "body": "**System information**\r\n- Have I written custom code: YES\r\n- OS Platform and Distribution: WIN 10\r\n- TensorFlow installed from: pip\r\n- TensorFlow version: 2.2.0\r\n- Python version:3.7.7\r\n- CPU ONLY\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using batch normalization layer (eithor `SyncBatchNormalization` or `BatchNormalization`)  in `MultiWorkerMirroredStrategy` distributed training, training process works well, and model could be saved as well.\r\n\r\nBut when I tried to load the model (`keras.models.load_model`) to predict, it would raise error. And when I tried to use `saved_model_cli run` or `tfserving` for predicting, it will hang and get no response.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nNote that I don't know how to use `MultiWorkerMirroredStrategy` in `colab`, so I just give the reproduce steps here, and it's very easy.\r\n\r\n1. Training Code (worker.py)\r\n\r\n```python\r\nimport os\r\nimport json\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom absl import app, flags\r\nimport numpy as np\r\n\r\nFLAGS = flags.FLAGS\r\nflags.DEFINE_string(\"logs\", \"logs\", \"logs dir\")\r\nflags.DEFINE_integer(\"index\", 0, \"worker index\")\r\n\r\n\r\nclass ThreeLayerMLP(keras.Model):\r\n    def __init__(self, name=None):\r\n        super().__init__(name=name)\r\n        self.dense_1 = layers.Dense(32, activation='relu', name='dense_1')\r\n        self.bn = layers.experimental.SyncBatchNormalization()\r\n        self.dense_2 = layers.Dense(16, activation='relu', name='dense_2')\r\n        self.pred_layer = layers.Dense(\r\n            1,\r\n            activation='sigmoid',\r\n            name='predictions',\r\n        )\r\n\r\n    def call(self, inputs, training=None):\r\n        print(inputs.shape)\r\n        x = self.dense_1(inputs)\r\n        x = self.bn(x)\r\n        x = self.dense_2(x)\r\n        return self.pred_layer(x)\r\n\r\n\r\ndef prepare_data():\r\n    np.random.seed(0)\r\n    x_train, y_train = (\r\n        np.random.random((6000, 32)),\r\n        np.random.randint(2, size=(6000, 1)),\r\n    )\r\n\r\n    x_val, y_val = (\r\n        np.random.random((1000, 32)),\r\n        np.random.randint(2, size=(1000, 1)),\r\n    )\r\n\r\n    return ((x_train, y_train), (x_val, y_val))\r\n\r\n\r\ndef main(argv):\r\n    del argv  # Unused args\r\n    tf_config = {\r\n        \"cluster\": {\r\n            \"worker\": [\"localhost:12345\", \"localhost:12346\"],\r\n        },\r\n        \"task\": {\r\n            \"index\": FLAGS.index,\r\n            \"type\": \"worker\"\r\n        }\r\n    }\r\n    os.environ[\"TF_CONFIG\"] = json.dumps(tf_config)\r\n    print(json.loads(os.environ[\"TF_CONFIG\"]))\r\n\r\n    # distributed strategy\r\n    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n    BATCH_SIZE_PER_REPLICA = 64\r\n    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n    print('Number of devices: %d' % strategy.num_replicas_in_sync)\r\n\r\n    with strategy.scope():\r\n        model = ThreeLayerMLP(name='3_layer_mlp')\r\n        model.compile(\r\n            loss=tf.keras.losses.BinaryCrossentropy(),\r\n            optimizer=keras.optimizers.RMSprop(),\r\n            metrics=[\"AUC\"],\r\n        )\r\n\r\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(\r\n        log_dir=FLAGS.logs,\r\n        histogram_freq=1,\r\n        update_freq='batch',\r\n    )\r\n\r\n    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n        filepath=os.path.join(FLAGS.logs, \"checkpoints\", \"ckpt\"), )\r\n\r\n    ((x_train, y_train), (x_val, y_val)) = prepare_data()\r\n\r\n    model.fit(\r\n        x_train,\r\n        y_train,\r\n        epochs=1,\r\n        batch_size=BATCH_SIZE,\r\n        validation_data=(x_val, y_val),\r\n        callbacks=[tensorboard_callback, checkpoint_callback],\r\n    )\r\n\r\n    model_dir = os.path.join(FLAGS.logs, \"models\", str(FLAGS.index))\r\n    model.save(model_dir)\r\n\r\n\r\nif __name__ == '__main__':\r\n    app.run(main)\r\n```\r\n\r\n2. Distributed training: open 2 terminal with tensorflow 2.2.0 installed, and execute the command below:\r\n\r\n```shell\r\npython worker.py --index=0\r\npython worker.py --index=1\r\n```\r\n\r\n3. Model load and predict code:\r\n\r\n```python\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\n\r\ndef main():\r\n    model = keras.models.load_model('logs/models/0')\r\n    model.summary()\r\n    x_test, y_test = prepare_test_data()\r\n    print(model.predict(x_test))\r\n\r\ndef prepare_test_data():\r\n    x_test, y_test = (\r\n        np.random.random((10, 32)),\r\n        np.random.randint(2, size=(10, 1)),\r\n    )\r\n\r\n    return x_test, y_test\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nexecute the code above and will raise error:\r\n\r\n```shell\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 3_layer_mlp/StatefulPartitionedCall/StatefulPartitionedCall/sync_batch_normalization/Cast/allreduce/CollectiveReduce: {{node 3_layer_mlp/StatefulPartitionedCall/StatefulPartitionedCall/sync_batch_normalization/Cast/allreduce/CollectiveReduce}} was explicitly assigned to /job:worker/replica:0/task:0/device:CPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\r\n         [[3_layer_mlp/StatefulPartitionedCall/StatefulPartitionedCall/sync_batch_normalization/Cast/allreduce/CollectiveReduce]] [Op:__inference_predict_function_1439]\r\n```\r\n\r\n4. saved_model_cli:\r\n\r\n```shell\r\nsaved_model_cli run --dir logs/models/0 --tag_set serve --signature_def serving_default --input_expr \"input_1=np.random.random((1,32))\"\r\n```\r\n\r\nafter execute the command above, the process will hang and get no response. The same behavior occur when sending http predict request to tfserving.\r\n\r\nIf I remove the `batchnormalization` layer, erverything will back to normal.", "comments": ["It seems that this problem has gone in the latest nightly version(20200827).\r\n\r\nThanks for your good work, I'll close this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40187\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40187\">No</a>\n"]}, {"number": 40186, "title": "Importing tensorflow using python -c causes segmentation fault on interpreter exit", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.8.0b4\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: Quadro P2000\r\n\r\n**Describe the current behavior**:\r\nRunning  `python -c \"import tensorflow\"` results in a segmentation fault:\r\n\r\n`[1]    25266 segmentation fault (core dumped)  python -c \"import tensorflow\"`\r\n\r\n**Describe the expected behavior**\r\nNo segmentation fault happens, the program just exits.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nRun `python -c \"import tensorflow\"` using python 3.8.\r\n\r\nI found the issue because I was running tensorflow in a subprocess like this:\r\n\r\n```python\r\nimport subprocess\r\n\r\n\r\ndef call_subprocess_command(*command):\r\n    with subprocess.Popen(args=command, text=True, shell=False,\r\n                          stdout=subprocess.PIPE, stderr=subprocess.STDOUT) as process:\r\n        assert process.stdout is not None\r\n        for line in iter(process.stdout.readline, \"\"):\r\n            line = line.strip()\r\n            print(\"(subprocess)\", line)\r\n\r\n    if process.returncode != 0:\r\n        raise RuntimeError(f\"{command} failed with exit code {process.returncode}\")\r\n\r\n\r\ncall_subprocess_command(\"python\", \"-X\", \"faulthandler\", \"-c\", \"import tensorflow;print(tensorflow.__version__)\")\r\n```\r\n\r\nThis prints the version, thus indicating that the segmentation fault happens when the interpreter exits.\r\n```\r\n(subprocess) 2.2.0\r\n(subprocess) Fatal Python error: Segmentation fault\r\n(subprocess) \r\n(subprocess) Current thread 0x00007fe3c40f0080 (most recent call first):\r\nTraceback (most recent call last):\r\n  File \"/home/veith/.config/JetBrains/PyCharm2020.1/scratches/scratch.py\", line 16, in <module>\r\n    call_subprocess_command(\"python\", \"-X\", \"faulthandler\", \"-c\", \"import tensorflow;print(tensorflow.__version__)\")\r\n  File \"/home/veith/.config/JetBrains/PyCharm2020.1/scratches/scratch.py\", line 13, in call_subprocess_command\r\n    raise RuntimeError(f\"{command} failed with exit code {process.returncode}\")\r\nRuntimeError: ('python', '-X', 'faulthandler', '-c', 'import tensorflow;print(tensorflow.__version__)') failed with exit code -11\r\n\r\nProcess finished with exit code 1\r\n```\r\n", "comments": ["@RunOrVeith,\r\nCould you update to the stable version of TensorFlow 2.2 and let us know if you are facing the same issue. Thanks!", "@RunOrVeith,\r\nI was able to run the command `python -c \"import tensorflow\"` without any issues. \r\n\r\n![Screenshot 2020-06-05 at 8 33 08 PM](https://user-images.githubusercontent.com/57165142/83892321-2195e680-a76c-11ea-879a-653e970beb24.png)\r\n\r\nCould you please check if you are facing the same issue in a virtual environment. Thanks!", "I assume you meant \"upgrade to a stable version of python\", and it does ondeed only seem to be a problem in python 3.8.0b4.\r\nI get the expected output using python 3.8.3, so maybe this is also a big that has since been fixed inside the python interpreter.", "> I assume you meant \"upgrade to a stable version of python\"\r\n\r\n@RunOrVeith,\r\nYou have mentioned in the issue template that you are using TensorFlow release candidate v2.2 rc4 (released on Apr 30, 2020). Hence, I suggest you to check with the stable version TensorFlow v2.2 (released on May 7, 2020). \r\n\r\n\r\n\r\n\r\n>I get the expected output using python 3.8.3, so maybe this is also a big that has since been fixed inside the python interpreter.\r\n\r\nIs this still an issue? Please feel free to close the issue if resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 40185, "title": "[RNN] dynamic input shape support", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.4\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): tf-nightly (2.3.0.dev20200604)\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nhttps://colab.research.google.com/drive/1BtT2DkitM6PQKxOAsd-S0IU2Fwh2Reo1?usp=sharing\r\n```\r\n\r\n**Failure details**\r\nI was heard about the support for unknown dimensions in TF Lite (https://github.com/tensorflow/tensorflow/issues/29590#issuecomment-580951882), then I tried to convert my model mainly followed by the instructions (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/Keras_LSTM_fusion_Codelab.ipynb), but with replacing specific dimensions in TensorSpec() to None, the model exported to SavedModel format successfully. However, the conversion of TF Lite converter didn't work fine (errors shown in Colab).\r\n\r\nBefore this, I've also tried fixed size in TenserSpec(), then called resize_tensor_input() & allocate_tensors() on the TF Lite interpreter's side, but it didn't work either :(\r\n\r\nAre there any proper ways for model in TF Lite to accept variable shape data?", "comments": ["@superlyy \r\nI ran the code shared, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/02e436b2bcecb88fb846e2859b8a988d/untitled217.ipynb) , please let us know if this confirms the issue.", "@Saduf2019 \r\nI ran this code successfully before, but I think it doesn't mention about variable size input tensor any.", "Hello @superlyy i dont know your use case, i was having this same issue with images, but later i realize that i will not work with image tensor but with byte strings tensor, maybe you can update your approach to work that way. i have an implementation here https://github.com/ElPapi42/deep-deblurring-model/blob/tflite/deblurrer/model/wrapper.py, check the decorator, maybe can be helpful for you.", "@superlyy\r\nPlease update as per above comment.", "Hey guys, @ElPapi42, thanks for the suggestions again. I try with a [subclassed Model](https://colab.research.google.com/drive/11OeYjwm4CUfL9wSnbAtQaMSyXqQOGlNK?usp=sharing), but it still doesn't work well with LSTM. Btw, the model is actually made for MIR-related task, the inputs are time-series of preprocessed features.", "Hello again! i don't have a solution, but I noticed you don't initialize the model weights before saving to disk, can you try to forward pass a batch of sample data through the architecture before doing ```tf.saved_model.save()```?", "Absolutely. Before saving model, I forward a random data to model by using fit() [in here](https://colab.research.google.com/drive/11OeYjwm4CUfL9wSnbAtQaMSyXqQOGlNK#scrollTo=-FJBTa9cN88y). But it shows another error in convert.convert():\r\n`None is only supported in the 1st dimension. Tensor 'args_0' has invalid shape '[None, None, 256]'.`\r\nI'm wondering if TF Lite can not only support the dynamic shape in batch size, but also the other dimensions?", "I decide to write another bare minimum example, and I can confirm this only happens with LSTM layer, when changed to GRU everything works:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import LSTM, Bidirectional, GRU\r\n\r\nclass SubClassedModel(tf.keras.Model):\r\n    def __init__(self):\r\n        super(SubClassedModel, self).__init__()\r\n        self.model = Bidirectional(GRU(4, time_major=True, return_sequences=True), name='BILSTM_OUTPUT')\r\n\r\n    @tf.function(input_signature=[tf.TensorSpec(shape=[None, None, 256], dtype=tf.float32)])\r\n    def call(self, inputs):\r\n        return self.model(inputs)\r\n\r\ndef convert(model):\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model) \r\n    return converter.convert()\r\n\r\nmodel = SubClassedModel()\r\ntest_input = tf.random.uniform(shape=[2, 2, 256], dtype=tf.float32)\r\nwith tf.device('/cpu:0'):\r\n    test_output = model(test_input)\r\n\r\ntflite = convert(model)\r\n```\r\nDont know the reason for this error, but surely must be inspected @Saduf2019 ", "@superlyy @ElPapi42 \r\nPlease share a colab gist of the error faced for us to analyse", "@Saduf2019 https://colab.research.google.com/drive/1sPKS9ZhRmCVV9JB9KmY0ywH7ZxWHFKxQ?usp=sharing\r\n\r\nIf you change the LSTM layer to a GRU, everything works on 2.3.0-dev20200609. On 2.2.0 both are broken with dynamic input shapes.", "I am able to replicate this issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/8ebae339287d4e6eaa45de1f1947b0ed/untitled227.ipynb)", "@ElPapi42 @superlyy Looks like this was resolved in recent `tf-nightly`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/3658c3ba00ffa7a6f09f23b0007c88ef/untitled227.ipynb). thanks!\r\n\r\nPlease close the issue if this was resolved for you. thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40185\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40185\">No</a>\n"]}, {"number": 40184, "title": "TF-TRT Improve test coverage of pool op converters", "body": "- Add dynamic shape and explicit batch tests for 3D pool ops.\r\n- Extend the test to cover 2D pool ops\r\n", "comments": ["@tfeher Can you please check @bixia1's comments and keep us posted. Thanks!"]}, {"number": 40182, "title": "ImportError: cannot import name 'function_pb2'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CENTOS 7.8\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source(Master)\r\n- TensorFlow version: 2.2\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): Build label: 3.0.0\r\n- GCC/Compiler version (if compiling from source): gcc version 7.3.1 20180303 (Red Hat 7.3.1-5) (GCC) \r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: NVIDIA (TESLA M60)\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nhittiing the following error after succesful bazel build.\r\nINFO: 0 processes.\r\nINFO: Build completed successfully\r\n./bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag /tmp/tensorflow_pkg\r\n\r\npip install /tmp/tensorflow_pkg/tensorflow-2.2.0-cp36-cp36m-linux_x86_64.whl \r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\nImportError: No module named eager\r\n\r\n\r\n import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/nobackup/tensorflow/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/nobackup/tensorflow/tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"/nobackup/tensorflow/tensorflow/python/eager/context.py\", line 32, in <module>\r\n    from tensorflow.core.framework import function_pb2\r\nImportError: cannot import name 'function_pb2'\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\nImportError: No module named eager\r\n", "comments": ["got the same here after a successful build on:\r\n\r\n`import tensorflow as tf`\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/begood/Documents/tensorflow/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/home/begood/Documents/tensorflow/tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"/home/begood/Documents/tensorflow/tensorflow/python/eager/context.py\", line 32, in <module>\r\n    from tensorflow.core.framework import function_pb2\r\nImportError: cannot import name 'function_pb2' from 'tensorflow.core.framework' (unknown location)\r\n\r\npython 3.8\r\ntf: 2.2 - build with cuda\r\ngcc: 8\r\nbazel: 3.0.0", "I got the same problem related to 'function_pb2' after compiling TensorFlow. It is likely because I was still at the TensorFlow source folder, so that python was searching that folder instead of loading the installed package I guess? When I change to another directory (e.g., $HOME), I can successfully import the installed TF without error. ", "@sangmeshcp Is this still an issue? If yes, does the suggestion posted by @youngtf work for your case?", "> I got the same problem related to 'function_pb2' after compiling TensorFlow. It is likely because I was still at the TensorFlow source folder, so that python was searching that folder instead of loading the installed package I guess? When I change to another directory (e.g., $HOME), I can successfully import the installed TF without error.\r\n\r\nThis worked for me. Thanks!", "> directory\r\n\r\nHello,\r\ncan you explain what do you mean by \"When I change to another directory (e.g., $HOME)\" \r\nThanks", "> > directory\r\n> \r\n> Hello,\r\n> can you explain what do you mean by \"When I change to another directory (e.g., $HOME)\"\r\n> Thanks\r\n\r\n@AhmedEwis \r\n\r\nE.g. `cd ~`. \r\nOr you may find more detail at https://www.techrepublic.com/article/linux-directory-navigation-tips-and-tricks/.\r\nI hope it helps.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> I got the same problem related to 'function_pb2' after compiling TensorFlow. It is likely because I was still at the TensorFlow source folder, so that python was searching that folder instead of loading the installed package I guess? When I change to another directory (e.g., $HOME), I can successfully import the installed TF without error.\r\n\r\nThanks, even with Jupyter worked. I change the directory to the tensorflow installation directory and ran the python 3 from there and it started working :)", "Closing this issue since setting tensorflow installation directory correctly solves the problem and lack of response from the issue author.\r\nFeel free to reopen if required. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40182\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40182\">No</a>\n", "i'm not getting hhow to resolve it\r\n", "@dileepdanger,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "@dileepdanger \r\ntype `cd ~`"]}, {"number": 40181, "title": "tf.StridedSlice op doc fix", "body": "", "comments": ["I think that the source of truth at the moment is `tensorflow/core/api_def/base_api/api_def_StridedSlice.pbtxt` (we actually have a tool to generate the ODS from the proto registration)", "api_def_StridedSlice.pbtxt updated"]}]