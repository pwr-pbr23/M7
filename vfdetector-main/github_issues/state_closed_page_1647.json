[{"number": 3498, "title": "'tensorflow.contrib.learn' has no attribute 'infer_real_valued_columns_from_input'", "body": "## Environment info: \n\nOperating System:\nUbuntu 16.04 , Python3.5.2, tensorflow version '0.9.0'\n## I try to run boston_house_prices data but it failed with no attribute 'infer_real_valued_columns_from_input' in tensorflow.contrib.learn. I wrote this script according to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/boston.py\n\nimport pandas as pd\nimport numpy as np\nimport random\nfrom sklearn import cross_validation, metrics, preprocessing\nimport tensorflow as tf\nfrom tensorflow.contrib import learn\n\ndf = pd.read_csv('boston_house_prices.csv')\ndf.fillna(-99999, inplace = True)\n\nX = np.array(df.drop(['MEDV'], 1))\nX = preprocessing.StandardScaler().fit_transform(X)\ny = np.array(df['MEDV'], dtype = int)\n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.2, random_state = 42)\nrandom.seed(42)\n\nfeature_columns = learn.infer_real_valued_columns_from_input(X_train)\nregressor = learn.DNNRegressor(feature_columns=feature_columns, hidden_units = [10, 10])\n\nregressor.fit(X_train, y_train, steps = 5000, batch_size =1)\nscore = metrics.mean_squared_error(regressor.predict(X_test), y_test)\nprint(\"Accuracy %f\" % score)\n## Logs or other output that would be helpful:\n\nTraceback (most recent call last):\n  File \"2DNN.py\", line 26, in <module>\n    feature_columns = learn.infer_real_valued_columns_from_input(X_train)\nAttributeError: module 'tensorflow.contrib.learn' has no attribute 'infer_real_valued_columns_from_input'\n", "comments": ["It looks as if you are using the example script from HEAD but the r0.9 version of tensorflow.contrib.learn. Would you try again with matching versions and see if that works?\n\n(In general [stack overflow](https://stackoverflow.com/questions/tagged/tensorflow) is a better venue for this kind of question.)\n", "Thanks.  michaelisard. I will try stack overflow.\n"]}, {"number": 3497, "title": "Calculate dependencies for makefile", "body": "This change updates the makefile so that changes in headers are spotted and the right files are rebuilt. This also breaks down the different iOS architectures' objects into subfolders, so that incremental builds are possible.\n", "comments": []}, {"number": 3496, "title": " android studio api19:   System.loadLibrary(\"tensorflow_demo\"); <----what can i do \u3160\u3160", "body": " android studio api19:  \nTensorflowClassifier.java: \nstatic {\n    System.loadLibrary(\"tensorflow_demo\");\n  }\n<----this is problem\nplz help\u3160\u3160 i am korean \u3160\u3160\nCouldn't load tensorFlow_demo from loader dalvik.system.PathClassLoader[DexPathList[[zip file \"/data/app/org.tensorflow.demo-2.apk\"],nativeLibraryDirectories=[/data/app-lib/org.tensorflow.demo-2, /vendor/lib, /system/lib]]]: findLibrary returned null\n\nwhat should i do?\u3160\u3160 plz\n## error log\n\n07-25 14:15:28.049 3164-3164/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: main\n                                                                   Process: org.tensorflow.demo, PID: 3164\n                                                                   java.lang.UnsatisfiedLinkError: Couldn't load tensorFlow_demo from loader dalvik.system.PathClassLoader[DexPathList[[zip file \"/data/app/org.tensorflow.demo-2.apk\"],nativeLibraryDirectories=[/data/app-lib/org.tensorflow.demo-2, /vendor/lib, /system/lib]]]: findLibrary returned null\n                                                                       at java.lang.Runtime.loadLibrary(Runtime.java:358)\n                                                                       at java.lang.System.loadLibrary(System.java:526)\n                                                                       at org.tensorflow.demo.TensorflowClassifier.<clinit>(TensorflowClassifier.java:46)\n                                                                       at org.tensorflow.demo.TensorflowImageListener.<init>(TensorflowImageListener.java:54)\n                                                                       at org.tensorflow.demo.CameraConnectionFragment.<init>(CameraConnectionFragment.java:240)\n                                                                       at org.tensorflow.demo.CameraConnectionFragment.newInstance(CameraConnectionFragment.java:170)\n                                                                       at org.tensorflow.demo.CameraActivity.onCreate(CameraActivity.java:30)\n                                                                       at android.app.Activity.performCreate(Activity.java:5231)\n                                                                       at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1087)\n                                                                       at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2159)\n                                                                       at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2245)\n                                                                       at android.app.ActivityThread.access$800(ActivityThread.java:135)\n                                                                       at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1196)\n                                                                       at android.os.Handler.dispatchMessage(Handler.java:102)\n                                                                       at android.os.Looper.loop(Looper.java:136)\n                                                                       at android.app.ActivityThread.main(ActivityThread.java:5017)\n                                                                       at java.lang.reflect.Method.invokeNative(Native Method)\n                                                                       at java.lang.reflect.Method.invoke(Method.java:515)\n                                                                       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:779)\n                                                                       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:595)\n                                                                       at dalvik.system.NativeStart.main(Native Method)\n## .\n", "comments": ["I'm no expert but I beleive API 19 would of been used on a older version of Android SDK this is what my workspace file looked like.\n\n> android_sdk_repository(\n>     name = \"androidsdk\",\n>     api_level = 24,\n>     build_tools_version = \"24.0.0\",\n>     path = \"YOURPATH\")\n> \n> android_ndk_repository(\n>     name=\"androidndk\",\n>     path=\"YOURPATH/android-ndk-r12b\",\n>     api_level=21)\n\nMaybe try that?  If you could also mention what Operating System and what versions of the Android SDK & NDK you are trying to use and copy and paste what your WORKSPACE file looks like compared to what I pasted I imagine that could be helpful.\n", "@kimhyungjoo Please see https://github.com/tensorflow/tensorflow/issues/3444, which contains instructions for building the native libs while using Android studio.\n", "Since there's not been an update for a while, closing this issue. Please reopen if you're still having problems.\n"]}, {"number": 3495, "title": "Show the collection that a variable belongs to in TensorBoard", "body": "This is specially useful when using functions like `tf.contrib.layers.fully_connected` that generate the weight and bias variables on their own. With this you could simply inspect in TensorBoard and get that information right away, no need to look in the docs or ask.\n", "comments": ["I can work on this\n", "@dsmilkov @jameswex Can either of you give some guidance on how shkr could approach working on this?\n", "Is this for viewing variables in TensorBoard in the Events tab, or in the Graph tab? I'd like to understand a specific example of what this ask is for. Thanks.\n", "@jameswex The request would be for the Graph tab.\nWhen trying to implement regularization using `tf.contrib.layers.fully_connected`, it accepts some parameters that handle regularization for weights and biases, but the Tensors needed for regularization end up in the `REGULARIZATION_LOSSES` collection, however its hard to know unless you ask. It would be nice if you could see the collection(s) that a Tensor belongs e.g. REGULARIZATION_LOSSES in the TensorBoard Graph viewer.\n\nIf it helps, here is the code I use to get those regularization terms\n\n```\ntf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n```\n", "I'm sorry I'm still not quite following the issue and proposed solution. Can you provide a screenshot of the confusion caused by how the variables are displayed in the graph in your use case?\n", "My understanding is that @cgarciae is requesting to add a collections field in the node for each variable either present in the red outlined box or the top right box for the selected variable. Currently the collections that a tensor belongs cannot be seen on tensorboard. Please point out if I am missing any section where it is present.\n\n![screen shot 2016-09-04 at 11 25 45 am](https://cloud.githubusercontent.com/assets/5184832/18233055/6115d206-7292-11e6-8406-520f099d8038.png)\n](url)\n\n@cgarciae @jameswex if that is the correct formulation of the feature request, then I can move ahead. Please confirm.\n", "Exactly what @shkr said!\n", "That explanation helps. Sounds like you would want to add the collections a variable belongs to as an entry in the attr map in the NodeDef for a variable node so that that information is saved for every node in the graph definition proto. Then the graph visualizer can use that information to add a collections list to the tf_node_info info card for any selected variable.\n", "Thanks @jameswex those directions are helpful\n", "Update : As described in PR #4433 @mrry has suggested a different approach by using the MetaGraphDef. I will submit a PR which follows the recommendation.\n", "Please feel free to submit PRs to our new repository at https://github.com/tensorflow/tensorboard! In the meantime, I'm closing this due to inactivity."]}, {"number": 3494, "title": "Tensorflow Import on OSX 10.11.5 fails ", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: 10.11.5\nPython Version: 2.7.12 (installed from homebrew)\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n /usr/local/cuda/lib/libcuda.dylib\n /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a\n/usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib\n/usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib\n/usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a\n/usr/local/cuda/lib/libcudnn.5.dylib\n/usr/local/cuda/lib/libcudnn.dylib -> libcudnn.5.dylib\n/usr/local/cuda/lib/libcudnn_static.a\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   I tried both install from source using the OSX guide. \n   And, the nightly binary with GPU support. 0.90\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.dylib locally\n   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.dylib locally\n   I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.dylib locally\n   fish: 'python -c \"import tensorflow\"' terminated by signal SIGSEGV (Address boundary error)\n\nPython quits \n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n   5161e4c51b994b3feb93cdb851479c29a3450f31\n2. The output of `bazel version`\n   Build label: 0.3.0-homebrew\n   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\n   Build time: Tue Jul 12 11:11:47 2016 (1468321907)\n   Build timestamp: 1468321907\n   Build timestamp as int: 1468321907\n### Steps to reproduce\n1. Install tensorflow from source or nightly using pip install\n2. python -c \"import tensorflow\"\n### What have you tried?\n1. import numpy, import scipy etc looking at previous errors. \n2. dtruss output attached for import tensorflow\n### Logs or other output that would be helpful\n\n(If logs are large, please upload \n[dtruss_python_tensorflow.txt](https://github.com/tensorflow/tensorflow/files/382028/dtruss_python_tensorflow.txt)\nas attachment).\n", "comments": ["Can you try re-installing CUDA with \"brew cask install cuda\"?\n", "Hi @michaelisard  I tried that, but same result. did a bazel clean, and complete rebuild. \n", "@martinwicke is this behavior you recognize?\n", "I'm seeing the same issue with Python 3.\n", "Same issue here on 10.12 with Python 3.5.2:\n\n```\n>>> import tensorflow\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.dylib locally\nProcess 62685 stopped\n* thread #1: tid = 0x8c054, 0x00007fffb77c3bf2 libsystem_c.dylib`strlen + 18, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)\n    frame #0: 0x00007fffb77c3bf2 libsystem_c.dylib`strlen + 18\nlibsystem_c.dylib`strlen:\n->  0x7fffb77c3bf2 <+18>: pcmpeqb (%rdi), %xmm0\n    0x7fffb77c3bf6 <+22>: pmovmskb %xmm0, %esi\n    0x7fffb77c3bfa <+26>: andq   $0xf, %rcx\n    0x7fffb77c3bfe <+30>: orq    $-0x1, %rax\n\n```\n", "The question is, why does this work on our test machines? @yifeif any idea?\n\nCan you try in a virtualenv? It often provides useful isolation. That said, this seems pervasive.\n", "Above result is in virtualenv.\n", "@alexcolburn 's solution [here](https://github.com/tensorflow/tensorflow/issues/2940) solves this for me\n", "Thank you @jramapuram. The solution works! \n", "BTW, the problem that @alexcolburn solution fixes was is a crash in cuda_diagnostics code which gets triggered when the library can't find cuda dyld. The code tries to print some strings obtained `CFStringGetCStringPtr` which can return null, which shouldn't be printed. I fixed one such condition in #3448 but there were other improper uses in that file I didn't touch. The way to tell if that's the issue is to see if there's `Diagnostician` in stack trace. IE, to look at MacOS crash logs for (Application->Utilities->Console, under User Diagnostic Reports for Python) and see if there's something like  this in the stack trace\n\n```\nProcess:               Python [2127]\nPath:                  /System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python\nIdentifier:            Python\nVersion:               2.7.10 (2.7.10)\nCode Type:             X86-64 (Native)\nParent Process:        Python [2113]\nResponsible:           Python [2127]\nUser ID:               501\n\nPlugIn Path:             /Users/USER/*/_pywrap_tensorflow.so\n\n....\n\n-> \n    __TEXT                 0000000101b33000-0000000101b34000 [    4K] r-x/rwx SM=COW  /System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python\n\nThread 0 Crashed:: Dispatch queue: com.apple.main-thread\n0   libsystem_c.dylib               0x00007fff9d00c152 strlen + 18\n1   _pywrap_tensorflow.so           0x00000001067cea2c perftools::gputools::cuda::Diagnostician::FindKernelDriverVersion() + 204\n2   _pywrap_tensorflow.so           0x00000001067ce220 perftools::gputools::cuda::Diagnostician::LogDriverVersionInformation() + 512\n3   _pywrap_tensorflow.so           0x00000001067cdf8f perftools::gputools::cuda::Diagnostician::LogDiagnosticInformation() + 671\n4   _pywrap_tensorflow.so           0x00000001067ded69 perftools::gputools::cuda::CUDADriver::Init() + 569\n5   _pywrap_tensorflow.so           0x00000001067f556f perftools::gputools::cuda::CudaPlatform::VisibleDeviceCount() const + 15\n6   _pywrap_tensorflow.so           0x00000001065841f5 \n```\n", "I'll close this as duplicate of #2940.\n"]}, {"number": 3493, "title": "Building issues", "body": "ERROR: /home/wenjian/pkgs/tensorflow/tensorflow/core/kernels/BUILD:1517:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:spacetobatch_op_gpu':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/spacetobatch_op_gpu.cu.cc':\n  '/usr/local/cuda-8.0/include/cuda_runtime.h'\n  '/usr/local/cuda-8.0/include/host_config.h'\n  '/usr/local/cuda-8.0/include/builtin_types.h'\n  '/usr/local/cuda-8.0/include/device_types.h'\n  '/usr/local/cuda-8.0/include/host_defines.h'\n  '/usr/local/cuda-8.0/include/driver_types.h'\n  '/usr/local/cuda-8.0/include/surface_types.h'\n  '/usr/local/cuda-8.0/include/texture_types.h'\n  '/usr/local/cuda-8.0/include/vector_types.h'\n  '/usr/local/cuda-8.0/include/library_types.h'\n  '/usr/local/cuda-8.0/include/channel_descriptor.h'\n  '/usr/local/cuda-8.0/include/cuda_runtime_api.h'\n  '/usr/local/cuda-8.0/include/cuda_device_runtime_api.h'\n  '/usr/local/cuda-8.0/include/driver_functions.h'\n  '/usr/local/cuda-8.0/include/vector_functions.h'\n  '/usr/local/cuda-8.0/include/vector_functions.hpp'\n  '/usr/local/cuda-8.0/include/common_functions.h'\n  '/usr/local/cuda-8.0/include/math_functions.h'\n  '/usr/local/cuda-8.0/include/math_functions.hpp'\n  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.h'\n  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.hpp'\n  '/usr/local/cuda-8.0/include/cuda_surface_types.h'\n  '/usr/local/cuda-8.0/include/cuda_texture_types.h'\n  '/usr/local/cuda-8.0/include/device_functions.h'\n  '/usr/local/cuda-8.0/include/device_functions.hpp'\n  '/usr/local/cuda-8.0/include/device_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/device_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/device_double_functions.h'\n  '/usr/local/cuda-8.0/include/device_double_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_35_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_20_intrinsics.h'\n  '/usr/local/cuda-8.0/include/sm_20_intrinsics.hpp'\n  '/usr/local/cuda-8.0/include/sm_30_intrinsics.h'\n  '/usr/local/cuda-8.0/include/sm_30_intrinsics.hpp'\n  '/usr/local/cuda-8.0/include/sm_32_intrinsics.h'\n  '/usr/local/cuda-8.0/include/sm_32_intrinsics.hpp'\n  '/usr/local/cuda-8.0/include/sm_35_intrinsics.h'\n  '/usr/local/cuda-8.0/include/surface_functions.h'\n  '/usr/local/cuda-8.0/include/texture_fetch_functions.h'\n  '/usr/local/cuda-8.0/include/texture_indirect_functions.h'\n  '/usr/local/cuda-8.0/include/surface_indirect_functions.h'\n  '/usr/local/cuda-8.0/include/device_launch_parameters.h'\n  '/usr/local/cuda-8.0/include/cuda_fp16.h'\n  '/usr/local/cuda-8.0/include/math_constants.h'\n  '/usr/local/cuda-8.0/include/curand_kernel.h'\n  '/usr/local/cuda-8.0/include/curand.h'\n  '/usr/local/cuda-8.0/include/curand_discrete.h'\n  '/usr/local/cuda-8.0/include/curand_precalc.h'\n  '/usr/local/cuda-8.0/include/curand_mrg32k3a.h'\n  '/usr/local/cuda-8.0/include/curand_mtgp32_kernel.h'\n  '/usr/local/cuda-8.0/include/cuda.h'\n  '/usr/local/cuda-8.0/include/curand_mtgp32.h'\n  '/usr/local/cuda-8.0/include/curand_philox4x32_x.h'\n  '/usr/local/cuda-8.0/include/curand_globals.h'\n  '/usr/local/cuda-8.0/include/curand_uniform.h'\n  '/usr/local/cuda-8.0/include/curand_normal.h'\n  '/usr/local/cuda-8.0/include/curand_normal_static.h'\n  '/usr/local/cuda-8.0/include/curand_lognormal.h'\n  '/usr/local/cuda-8.0/include/curand_poisson.h'\n  '/usr/local/cuda-8.0/include/curand_discrete2.h'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 261.225s, Critical Path: 89.69s\n", "comments": ["I believe the solution is to add `cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include\"` in `third_party/gpus/crosstool/CROSSTOOL` as mentioned #3431. Also note that `/usr/local/cuda/include` did not work for me even though its a symlink to `/usr/local/cuda-8.0`.\n", "So can the problem generally be resolved by following symlinks when you give the cuda directory?\n\nIn that case, should we do that in the configure script, or at least warn the user if they give us a symlink?\n", "Automatically closing due to lack of recent activity. Please reopen when new information becomes available.\n"]}, {"number": 3492, "title": "Dilated Convolution, Dilated Pooling and 2D/3D Sliding Window CNNs", "body": "Could you please implement 2D/3D dilated convolution and 2D/3D dilated pooling in tensorflow?\n\nPlease see http://arxiv.org/pdf/1511.07122.pdf for a reference on dilated convolution.\n\nDilated max-pooling is simply regular max-pooling but the pixels/voxels you use in each \"application\" of the max-pooling operation are exactly the same pixels/voxels you would select with dilated convolution.\n\nDilated convolution/pooling are useful for connectomics and 3D shape datasets (3D deep learning).\n", "comments": ["It looks like tensorflow already supports 2D dilated convolution.\n\n`tf.nn.atrous_conv2d(value, filters, rate, padding, name=None)`\n\nhttps://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#atrous_conv2d\n", "(1) We do not have immediate plans to add support for 3D atrous/dilated convolution in TF. For the 2-D case we already have `tf.nn.atrous_conv2d(value, filters, rate, padding, name=None)`.\n\n(2) You can adapt the existing [tf.nn.atrous_conv2d](https://github.com/tensorflow/tensorflow/blob/73ced9d797056c7e67a06ed2098dd809d85ec44a/tensorflow/python/ops/nn_ops.py) implementation to perform 2D atrous/dilated pooling by replacing the call to `conv2d` with a call to `avg_pool` or `max_pool`.\n\nAn alternative to achieve a similar effect (i.e., pooling over a larger area) is to just use standard pooling with enlarged kernel size:\n\n```\n ksize_eff = ksize + (ksize - 1) * (rate - 1)\n```\n\nNote that average or max pooling act on each channel separately, which means that they are fast even for large kernel size. They also have no learned parameters, which means that there is no risk for over-fitting. These factors combined imply that kernel upsampling is less appealing for pooling than it is for convolution.\n", "On connectomics datasets, the 3D images included are very high resolution. 3D neural nets trained on such datasets have lots and lots of parameters. For this reason, 3D dilated convolution and 3D dilated pooling are very useful in speeding up the learning process and enabling the training of very deep nets (cover larger area but less computation/less parameters to train). Most deep learning frameworks including TensorFlow are optimized to run 2D deep nets fast, not 3D deep nets.\n", "In addition, support for 2D/3D sliding window CNNs (specifically, dense training using output patches) would be appreciated.\n\nFor references on 2D/3D sliding window CNNs, see:\n- http://znn-release.readthedocs.io/en/latest/\n- http://people.idsia.ch/~juergen/nips2012.pdf\n", "(Edited title and added 'Enhancement' label per convention.)\n", "Marking 'contributions welcome' since this would be great to add, but isn't currently being worked on.\n", "Any word on the progress of this? I'm looking for 3D support\n", "This is being implemented --- hopefully will be available soon.\n", "+1 for 3D dilated convolutions.\n\nTorch implements this with nn.VolumetricDilatedConvolution:\nhttps://github.com/torch/nn/blob/master/doc/convolution.md#nn.VolumetricDilatedConvolution\n", "This is implemented in master --- see tf.nn.convolution and tf.nn.pool.\n", "Is there any timeline for implementing tf.nn.pool with \"SAME\" padding with dilation_rate > 1? It looks like tf.nn.atrous_conv2d works with SAME padding, but the tf.nn.pool function doesn't have it. Here is a relevant location in the codebase: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_ops.py#L741\r\n\r\nNote that I only need this for 2 dimensions, just as atrous_conv2d", "Any word on if dilated convolutions have been implemented in the convolutional transpose layers? Or a timeline on when it can be?", "I believe a portion of this request is implemented in `tensorflow/models/slim/.../resnet_utils.py` in the function [conv2d_same](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_utils.py#L77). I explained in more detail at https://github.com/tensorflow/tensorflow/issues/4742#issuecomment-285931111.", "Looks like a good chunk of this is done.  Further requests should probably be filed as further issues."]}, {"number": 3491, "title": "Unified file system support implementation for C++/Python", "body": "Currently the C++ code has file system interface and provides POSIX and GCS implementation. However, part of the Python code also using another file system abstraction (tensorflow/python/summary/impl/gcs.py). This is annoying and tedious to supporting new type of file systems. So what is the consideration here and whether this is plan to make the Python code depending on C++ IO abstraction only.\n", "comments": ["@rohan100jain can you comment on this?\n", "I'm actively working on this right now. The idea is what you suggested - exposing a python file interface that wraps the internal C++ file system interface so that all new file systems can just be directly implemented on top of C++ and is available automatically. \n", "@rohan100jain when will this feature be released? may be the interace can be released first?\nwe want to add our dfs support based on this and don't wish to do in the current GCS way which hacks the python layer.\n", "I think you can probably get started right now implementing the file_system.h API -- there is a private internal library in python that currently already binds to the C++ implementation, but we have not yet exposed it until we can completely replace all of the existing uses.  By the time you probably get all of the C++ components done, I'm optimistic that the python support will be there too.\n\nWhich DFS are you working on, and where were you planning on hosting the code, btw?  Alternative implementations of the file_system implementations should be a matter of building and linking a shared library, but we haven't yet tried this ourselves (currently we host and support all of the file system implementations, but we probably won't do this for all filesystems).\n", "@vrv It's a DFS we developed and mainly used internally: https://github.com/XiaoMi/galaxy-fds-sdk-cpp. And we host it in our internal branch since the audience is quite limited right now, so it's not a problem now. We already implemented the file_system based on 0.9 and the basic train/export/serving flow can work, however many python code are broken.\n\nAs you mentioned, hosting can be an issue when the DFS can't be accepted and integrated to the trunk code tree. What about supporting dynamic loading of the file system plugin, just like adding customized op? I can work on it if contribution welcome.\n\nI just found the recently release internal python interface file_io.py as you mentioned, a great progress, expecting it goes public.\n", "@vrv By the way, I noticed two facts:\n1. file_io.py only support read_file_to_string for reading, will it be problematic for large files?\n2. the GCS implemented recently added read ahead buffer. In fact we also support this improvement for our DFS implementation. I wondering will the sequential access pattern guaranteed by the upper level? Or else the performance can be very bad when the caching/buffering failed. If not, may be exposing a config parameter for NewRandomAccessFile to allow flexible caching a better solution?\n", "Just checked code, the plugin mechanism is already implemented but not documented: ./tensorflow/python/framework/test_file_system.cc\n", "file_io.py is now live and gfile redirects to it now. This should unify the python and C++ implementations. Let me know if there are further feature requests.\n\n@llhe \n1. vrv@ just added support for read(n). This mirrors what we used to have and should help out with large files\n2. We have a BufferedInputStream that does buffering on top of the RandomAccessFile. The python read(n), tell(), seek() functions are using it now as well. Its not perfect read ahead (in which we should perhaps read the next chunk of the buffer via a second thread etc.) but it should help out a bit with performance. Please feel free to open more feature requests if needed.\n\nThe plugin mechanism for file systems isn't documented but there is a separate issue tracking that (https://github.com/tensorflow/tensorflow/issues/4120)\n\nClosing this bug now.\n"]}, {"number": 3490, "title": "R0.9", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "The link changes are actually backports, but those are fixes only for 0.9. \n\nCan you add a commit reverting  tensorflow/g3doc/tutorials/wide/index.md and  tensorflow/g3doc/tutorials/wide-n-deep/index.md? \n", "I'm pretty sure this is an accident -- something about github's instructions end up making users try to push branches back to master.\n"]}, {"number": 3489, "title": "Timeline only produced for the last invocation on Session.run", "body": "Hi!\n\nFirst of all, thanks for the great profiling/timeline feature! I think it can be really amazing to debug model performance.\n\nI do have a question though: is it possible to create a timeline for _multiple_ invocations of `Session.run`?\n\nIn all the examples that I saw, timeline creation looks something along the lines of this:\n\n```\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\nrun_metadata = tf.RunMetadata()\n\nsess.run(result, options=run_options, run_metadata=run_metadata)\n\ntl = timeline.Timeline(run_metadata.step_stats)\nctf = tl.generate_chrome_trace_format()\n```\n\nThis is all good and well, but this generates the trace only for _one_ invocation of Session.run. If it is invoked multiple times (for example in batch training), the `step_stats` in the run_metadata are always overwritten by the last run.\n\nIs there a way to aggregate the timing data to create a timeline that spans over multiple invocations?\n\nI would need this to debug performance decay over long periods.\n", "comments": ["Perhaps this is more appropriate for over on stackoverflow, since I'm not sure there's a bug here. But let's discuss anyways. I'm working on performance analysis tools for TF, so I'm interested in your view.\n\nOne question is what do you want the behavior to be? If you literally just want a concatenation, one way of doing this is to record both traces and generate a new protobuf with both of their elements. The structure of the RunMetadata protobuf isn't that bad:\n[top level](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L224) \n[most everything else](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/step_stats.proto#L29)\n\nIt sounds like you want something more intelligent, though. If you're trying to do something like a moving average, you'll need to muck with actual data, and that raises more questions. For instance, how would heterogeneous tensor shapes get handled? (i.e., what if a tensor has different dimensions between two run steps?)\n", "I started out with the assumption that running the same operation on data of the same shape should take approximately the same amount of time. I have found this to not be true, if you are interested you can take a look at my [StackExchange Thread](http://superuser.com/questions/1086626/machine-performance-drops-over-time-until-reboot). There have also been other [reports](https://github.com/tensorflow/models/issues/170) of slowdowns that might, or might not be related.\n\nMy primary goal is to get rid of those slowdowns. If that happens by some magic commit and the problem goes away, that would be very dandy. I'm not very hopeful this will happen though, so I am ready and willing to dig down and debug the issue.\n\nI was hoping that the Timeline thing would be able to help me. I created this issue because I was not sure (and it's not documented anywhere) of what the purpose of the TimeLine object is, and whether it's supposed to be used in only one invocation of Session.run() or multiple ones. Judging from your comment, it's supposed to cover only one invocaton?\n\n> If you literally just want a concatenation, one way of doing this is to record both traces and generate a new protobuf with both of their elements\n\nIs there a somewhat sane python snippet that can do that? If not, I'd prefer not to dig into Protobuf affairs.\n\n> It sounds like you want something more intelligent, though\n\nNot really. The only thing that interests me is why some batches take significantly longer to compute than other batches, and I was hoping that a simple concatenation of the timeline could yield some insight.\n", "My requirement for an accumulated timeline has dropped (libtcmalloc magic has fixed my slowdown problem), and people seem rather uninterested in the feature, so I would suggest to close the issue.\n"]}, {"number": 3488, "title": "minor typo fix", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n"]}, {"number": 3487, "title": "seq2seq multidimensional regression", "body": "Hi, I am facing an issue while trying to train an RNN to do a multidimensional regression.  \n\n**The Tensorflow loss function built for RNNs seems to address the cases where we directly want to train labels or words embeddings, so I tried to compute the loss myself for a regression and it failed or seems not done for that.** \n\nThe question is also more detailed with my actual code and Tensorflow Graph on [StackOverflow](http://stackoverflow.com/questions/38549040/tensorflow-seq2seq-multidimensional-regression).\n_This seems more like a missing feature, so this is why I ask the question here too._ \n\nWhat would be a nice workaround? There **should** be one.\n\nIf there is already code for that, I would really like to see it, because what I want to do seems undocumented yet and I would like to do it, I am probably not alone. In the end, I would like to predict the N next coeficients of some [STFT](https://www.youtube.com/watch?v=TZzS52OplYs&index=5&list=PLlp-GWNOd6m6gSz0wIcpvl4ixSlS-HEmr), but for now I focus on making the regression model with simple sinusoidal data. \n\nMany thanks!!!\n", "comments": ["@lukaszkaiser: can you take a look?  Thanks.\n", "@guillaume-chevalier Are you sure about using `tf.nn.softmax_cross_entropy_with_logits` ? MSE is usually more suited for regression problems.\n", "This is a general request for information, not a bug or concrete feature request, so indeed - Stack Overflow is a better place for that. I'll answer there, closing this issue.\n", "Many thanks for the help, using an MSE fixed the problem. \n"]}, {"number": 3486, "title": "import tensorflow as tf error", "body": "### Environment info\n\nOperating System: OS X EI Capitan Version 10.11.1\n### Steps to reproduce\n1. run `import tensorflow as tf'\n### Logs or other output that would be helpful\n\n```\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 16, in <module>\n    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 16, in <module>\n    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py\", line 16, in <module>\n    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\", line 22, in <module>\n    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tB/\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01\\x62\\x06proto3')\nTypeError: __init__() got an unexpected keyword argument 'syntax'\n```\n\nPlease advice. Thank you.\n", "comments": ["Please provide the steps you have used to install TensorFlow.  The official instructions for Mac should work without issues.  Could you re-install?\n", "Same issue here after following the standard installation instructions. I then found that I had a conflicting protobuf library. Removing the conflicting library and installing >protobuf3.0 fixed it. \n", "@datomnurdin, did @hybridteory's suggestion solve your problem?\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 3485, "title": "Branch 128270792", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Martin, do you think we can merge this anyway and try to fix the kmeans test independently? \n", "One more try. I'll contact owners to help if this one fails.\n"]}, {"number": 3484, "title": "Enhance doc of model_dir in estimators", "body": "cc: @martinwicke @ilblackdragon \n", "comments": ["Jenkins, test this please\n", "Thank you!\n"]}, {"number": 3483, "title": "Slicing error: Using a `tf.Tensor` as a Python `bool` is not allowed", "body": "### Environment info\n\nOperating System:\nMacOSX, Python3, tensorflow version '0.9.0'\n### Steps to reproduce\n1. I am trying to slice a tensor (I want to remove boundaries for purpose of error evaluation)\n\n```\n# vector_loss  = tf.Variable(...)\npad = 8\nwidth = tf.shape(vector_loss,)[2]\nvector_loss = vector_loss[:,:,pad:width-pad, :]\n```\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n```\nTraceback (most recent call last):\n  File \"./footprint_poisson.py\", line 445, in <module>\n    epochs=50)\n  File \"./footprint_poisson.py\", line 263, in fit\n    tot_loss = self._create_loss()\n  File \"./footprint_poisson.py\", line 220, in _create_loss\n    poisson_loss_ = poisson_loss(self.vars.y, self.vars.y_predicted, pad = 8)\n  File \"./footprint_poisson.py\", line 28, in poisson_loss\n    vector_loss = vector_loss[:,:,pad:width-pad, :]\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 176, in _SliceHelper\n    if s.stop is not None and s.stop < 0:\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 515, in __bool__\n    raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\nTypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor.\n```\n", "comments": ["Quick things to check:\n\n1) Do you mean `tf.shape(vector_loss,)` or, without the comma?\n2) Make sure the shape of `vector_loss` is fully defined.  I think you need `width` to be a constant.\n", "ranges cannot be specified with tensors, they have to be values.... so you must do\n\n```\npad = 8\nwidth = tf.shape(vector_loss,)[2]\nstart, end = pad, (width - pad ).eval()\nvector_loss = vector_loss[:,:,start:end, :]\n```\n\nSoon, we will release negative index support which will not ease the restriction that the end range cannot be a tensor, but it will allow\n\n`vector_loss[:,:,pad:-pad,:]\n`\n", "Looks like shape of `vector_loss` was not fully defined. Can ranges be specified with `tensorflow.python.framework.tensor_shape.Dimension`?\n", "The change that I was describing will be sync'd soon (it's internal). For now try,\n\n``` python\nshape = tf.shape(vector_loss)\nstart = tf.pack([0,0,pad,0])\nsize = tf.pack([shape[0],shape[1],shape[2]-pad,shape[3]])\nvector_loss = vector_loss.slice(start,size)\n```\n", "This is now done and including as of 57197386a469e00693540481de08a9b1770c7bb4\n"]}, {"number": 3482, "title": "Update Docker Image", "body": "Hey All,\n\nThere are a variety of issues I'm running into with the docker image, just basic stuff.\n1.  sudo apt-get update\n2.  Python3 support\n3.  Nano is not installed (vim is the worst)\n   3a.  I want this so I can easily edit the notebook config for setting passwords.\n4.  The jupyter notebook needs to be updated to the latest\n5.  Pip updates\n6.  Maybe ship with Anaconda as well.\n\nIts just a variety of things that aren't working quite well.  I'm trying to put together a Jupyter Notebook our machine learning meetup group can use and share, and its just a pain in the neck. \n\nI tried to do just a fresh setup from a fresh linux vm, but I was having issues getting Jupyter to actually recognize the TensorFlow install; so now I'm trying the docker image again.  The biggest issue with the docker image in its current state is that after a while the auto-save starts breaking, json formats for posting to save break and then it messes up the encoding of the notebook, which then becomes more or less un-recoverable (without extensive effort).\n\nI beleive (not sure) that updating everything in the supported image would fix at least some of these issues.\n", "comments": ["I think vim is more popular than nano...\nI'm mostly bothered by the fact that tensorflow is an old version and not \"the latest\". It runs 0.7.0. How could that be?\n", "On Docker Hub you can pick which version they have different tags in the tach section, there is 0.9 and even nightlys. The other stuff your best bet is to create our own image based off they one they have. The current image installs the latest pip and jupyter when you run it, if you want to update you can either create bash into the container and update or rerun the container.\n"]}, {"number": 3481, "title": "Failed to do 8-bit quantization following the tutorial: Op type not registered 'Dequantize'", "body": "hello, I'm learning to do 8-bit quantization following the [How-to-tutorial](https://www.tensorflow.org/versions/master/how_tos/quantization/index.html) step-by-step, after I managed to output the `quantized_graph.pb`, then I was trying to test it, just like the tutorial:\n\n```\n>> bazel build tensorflow/examples/label_image:label_image\n>> bazel-bin/tensorflow/examples/label_image/label_image \\\n--input_graph=/tmp/quantized_graph.pb \\\n--input_width=299 \\\n--input_height=299 \\\n--mean_value=128 \\\n--std_value=128 \\\n--input_layer_name=\"Mul:0\" \\\n--output_layer_name=\"softmax:0\"\n```\n\n( a not-so-important change is, in fact, I found the script above didn't work, so I changed some parameter names as below: )\n\n```\n>> bazel-bin/tensorflow/examples/label_image/label_image \n--graph=/tmp/imagenet/quantized_graph.pb \\\n--input_width=299 \\\n--input_height=299 \\\n--input_mean=128 \\\n--input_std=128 \\\n--input_layer=\"Mul:0\"\\\n--output_layer=\"softmax:0\"\n```\n\nHowever, I got the error:\n\n```\nE tensorflow/examples/label_image/main.cc:281] Not found: Op type not registered 'Dequantize'\n```\n\nDo anyone know how to fix this? thanks a lot in advance :)\n", "comments": []}, {"number": 3480, "title": "Errors loading inception v3 in iOS example", "body": "### Environment info\n\nOperating System: Mac OS X / iOS\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`) : fc9162975e52978d3af38549b570cc3cc5f0ab66\n2. The output of `bazel version`: Build label: 0.3.0-homebrew\n### Steps to reproduce\n1. Download the .pb file from  https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip\n2. Insert the .pb file in the data folder of the `camera` iOS project\n3. Launch the project from Xcode, console outputs following errors:\n\n`Running model failed:Invalid argument: Session was not created with a graph before Run()!`\n\n`Running model failed:Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs\n     [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]`\n### What have you tried?\n1. ran the following script referenced in #2883:\n\n`bazel build tensorflow/python/tools:strip_unused && \\\nbazel-bin/tensorflow/python/tools/strip_unused \\\n--input_graph=your_retrained_graph.pb \\\n--output_graph=stripped_graph.pb \\\n--input_node_names=Mul \\\n--output_node_names=final_result \\\n--input_binary=true`\n\nHowever, I receive the following error:\n\n`/tensorflow/bazel-bin/tensorflow/python/tools/strip_unused.runfiles/org_tensorflow/tensorflow/python/framework/graph_util.py\", line 156, in extract_sub_graph\n    assert d in name_to_node_map, \"%s is not in graph\" % d\nAssertionError: final_result is not in graph`\n", "comments": ["Hi Piso. Use `pool_3` as the `input_graph` instead of `final_result`. \n\nI also have been trying to get the iOS sample to work with Inception v3 but I'm getting the sample prediction no matter the image captured by the camera. So if you manage to get it running may you please help me with my issue #3446. Thanks\n", "Here is the full code you need to use\n `bazel-bin/tensorflow/python/tools/strip_unused --input_graph= your_retrained_graph.pb --output_graph=stripped_graph.pb --input_node_names=Mul --output_node_names=pool_3 --input_binary=true`\n", "@piso try running this from the root of your tensorflow repo: \n\n```\nbazel build tensorflow/python/tools:strip_unused && \\\nbazel-bin/tensorflow/python/tools/strip_unused \\\n--input_graph=tensorflow/contrib/ios_examples/camera/data/tensorflow_inception_graph.pb \\\n--output_graph=tensorflow/contrib/ios_examples/camera/data/tensorflow_inception_graph_stripped.pb \\\n--input_node_names=Mul \\\n--output_node_names=softmax \\\n--input_binary=true\n```\n\nThen change the name of the graph being loaded in `CameraExampleViewController.mm`\nSpecifically, change this line:\n\n```\ntensorflow::Status load_status =\n      LoadModel(@\"tensorflow_inception_graph\", @\"pb\", &tf_session);\n```\n\nto\n\n```\ntensorflow::Status load_status =\n      LoadModel(@\"tensorflow_inception_graph_stripped\", @\"pb\", &tf_session);\n```\n", "@Tugees @shrutisharmavsco and @Piso \n1. Are you able to run bazel-bin/tensorflow/python/tools/strip_unused on TensorFlow 0.10.0rc? (I just created an issue https://github.com/tensorflow/tensorflow/issues/3962)\n2. Are you able to run the stripped Inception V3 model on iOS device without crashing?\n\nThanks,\nJeff\n", "@jeffxtang \n1. I haven't tried to run strip_unused script on TensorFlow 0.10.0rc\n2. I was able to run stripped Inception V3 model on iOS without crashing but I didn't try it in the camera example, only in the simple example where it tags only an image at a time\n", "Thanks @shrutisharmavsco - I used the same command you posted (actually I tried both `--output_node_names=softmax` and `--output_node_names=pool_3` and then used the stripped model in the tf_ios simple example (with changes to `std::string input_layer` and `std::string output_layer` as well as changes to `const int wanted_width` etc as specified by @petewarden on https://github.com/tensorflow/tensorflow/issues/2883, but the app simply crashed on my iPhone 6 device - similar screenshot to https://github.com/tensorflow/tensorflow/issues/2927\n\nSo @shrutisharmavsco you can run the stripped V3 model on actual iOS device with recognition result generated? Anything you did differently from what I did above? Thanks!\n", "@jeffxtang that all sounds like the right steps to me. I don't think I did anything differently. I was running it on an iPhone 5C. I do get memory warnings generated but the app does not crash - it still generates the tags. I haven't quantized the model yet, though.\n", "Thanks @shrutisharmavsco for the info. When you have the chance can you try quantizing the model and see if the memory warnings will disappear running on your iPhone 5C or if you'll hit problem similar to https://github.com/tensorflow/tensorflow/issues/3619?\n", "@jeffxtang running the quantized model made the memory warnings disappear on the iPhone 5C\n", "@shrutisharmavsco cool. I'm able to run the quantized model on my iPhone 6 too without memory warnings or other problems.\n", "@jeffxtang  are you noticing a speed decrease running the quantized model vs the non-quantized one?\n", "No @shrutisharmavsco the performance seems to be the same to me. You can check out my recently released iOS app which uses a quantized model for comparison: https://itunes.apple.com/us/app/dog-breeds-recognition-powered/id1150923794?mt=8\n", "For those of you who may be interested, I just posted a blog documenting the whole process of using a retrained inception v3 model for my app above at http://jeffxtang.github.io\n", "I've got a tutorial explaining how to get this running up at https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/ now, so I'm going to close this bug. Please open new bugs if there are issues with the process. Thanks @jeffxtang for your work on this too!\n", "Great tutorial @petewarden! I noticed you use `optimize_for_inference` instead of `strip_unused` and also `convert_graphdef_memmapped_format` - is this the recommended way now? Since TensorFlow 0.10.0? Thanks!\n", "Yes, those are the recommended approaches. I'm working on a general description of the process, I'll email you a draft.\n"]}, {"number": 3479, "title": "Build error with CUDA", "body": "I'm able to build tensorflow trainer example successfully with\n\n`bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`\n\nBut I get the following build error when trying to build the tensorflow pip package:\n\n`bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`\n\n```\nERROR: /home/charlesq/projects/tensorflow/tensorflow/core/kernels/BUILD:1646:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:scatter_op_gpu':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/scatter_op_gpu.cu.cc':\n  '/usr/local/cuda-8.0/include/cuda_runtime.h'\n  '/usr/local/cuda-8.0/include/host_config.h'\n  '/usr/local/cuda-8.0/include/builtin_types.h'\n  '/usr/local/cuda-8.0/include/device_types.h'\n  '/usr/local/cuda-8.0/include/host_defines.h'\n  '/usr/local/cuda-8.0/include/driver_types.h'\n  '/usr/local/cuda-8.0/include/surface_types.h'\n  '/usr/local/cuda-8.0/include/texture_types.h'\n  '/usr/local/cuda-8.0/include/vector_types.h'\n  '/usr/local/cuda-8.0/include/library_types.h'\n  '/usr/local/cuda-8.0/include/channel_descriptor.h'\n  '/usr/local/cuda-8.0/include/cuda_runtime_api.h'\n  '/usr/local/cuda-8.0/include/cuda_device_runtime_api.h'\n  '/usr/local/cuda-8.0/include/driver_functions.h'\n  '/usr/local/cuda-8.0/include/vector_functions.h'\n  '/usr/local/cuda-8.0/include/vector_functions.hpp'\n  '/usr/local/cuda-8.0/include/common_functions.h'\n  '/usr/local/cuda-8.0/include/math_functions.h'\n  '/usr/local/cuda-8.0/include/math_functions.hpp'\n  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.h'\n  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.hpp'\n  '/usr/local/cuda-8.0/include/cuda_surface_types.h'\n  '/usr/local/cuda-8.0/include/cuda_texture_types.h'\n  '/usr/local/cuda-8.0/include/device_functions.h'\n  '/usr/local/cuda-8.0/include/device_functions.hpp'\n  '/usr/local/cuda-8.0/include/device_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/device_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/device_double_functions.h'\n  '/usr/local/cuda-8.0/include/device_double_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_35_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_20_intrinsics.h'\n  '/usr/local/cuda-8.0/include/sm_20_intrinsics.hpp'\n  '/usr/local/cuda-8.0/include/sm_30_intrinsics.h'\n  '/usr/local/cuda-8.0/include/sm_30_intrinsics.hpp'\n  '/usr/local/cuda-8.0/include/sm_32_intrinsics.h'\n  '/usr/local/cuda-8.0/include/sm_32_intrinsics.hpp'\n  '/usr/local/cuda-8.0/include/sm_35_intrinsics.h'\n  '/usr/local/cuda-8.0/include/surface_functions.h'\n  '/usr/local/cuda-8.0/include/texture_fetch_functions.h'\n  '/usr/local/cuda-8.0/include/texture_indirect_functions.h'\n  '/usr/local/cuda-8.0/include/surface_indirect_functions.h'\n  '/usr/local/cuda-8.0/include/device_launch_parameters.h'\n  '/usr/local/cuda-8.0/include/cuda_fp16.h'\n  '/usr/local/cuda-8.0/include/math_constants.h'\n  '/usr/local/cuda-8.0/include/curand_kernel.h'\n  '/usr/local/cuda-8.0/include/curand.h'\n  '/usr/local/cuda-8.0/include/curand_discrete.h'\n  '/usr/local/cuda-8.0/include/curand_precalc.h'\n  '/usr/local/cuda-8.0/include/curand_mrg32k3a.h'\n  '/usr/local/cuda-8.0/include/curand_mtgp32_kernel.h'\n  '/usr/local/cuda-8.0/include/cuda.h'\n  '/usr/local/cuda-8.0/include/curand_mtgp32.h'\n  '/usr/local/cuda-8.0/include/curand_philox4x32_x.h'\n  '/usr/local/cuda-8.0/include/curand_globals.h'\n  '/usr/local/cuda-8.0/include/curand_uniform.h'\n  '/usr/local/cuda-8.0/include/curand_normal.h'\n  '/usr/local/cuda-8.0/include/curand_normal_static.h'\n  '/usr/local/cuda-8.0/include/curand_lognormal.h'\n  '/usr/local/cuda-8.0/include/curand_poisson.h'\n  '/usr/local/cuda-8.0/include/curand_discrete2.h'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 6000.817s, Critical Path: 170.00s\n```\n\nOperating system: Linux Mint Rosa 17.3 (Ubuntu 14.04.3 Trusty)\n\nCuda version 8.0. Compute capability 6.1 (GTX 1080 GPU)\n\nPath of cuda libs is /usr/local/cuda. The folder /usr/local/cuda/lib does not exist, however there is lib64/\n\n```\n $ ls /usr/local/cuda/lib64/libcud*\n/usr/local/cuda/lib64/libcudadevrt.a    /usr/local/cuda/lib64/libcudart.so.8.0.27  /usr/local/cuda/lib64/libcudnn.so.5\n/usr/local/cuda/lib64/libcudart.so      /usr/local/cuda/lib64/libcudart_static.a   /usr/local/cuda/lib64/libcudnn.so.5.0.5\n/usr/local/cuda/lib64/libcudart.so.8.0  /usr/local/cuda/lib64/libcudnn.so          /usr/local/cuda/lib64/libcudnn_static.a\n\n$ git rev-parse HEAD\n36d056acd92ca2f7e97fec82fd09f36c42c05338\n\n$ bazel version\n.......\nBuild label: 0.2.1\nBuild target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Mar 31 19:30:01 2016 (1459452601)\nBuild timestamp: 1459452601\nBuild timestamp as int: 1459452601\n```\n", "comments": ["+1 same error\n", "add\ncxx_builtin_include_directory: \"/usr/local/cuda-8.0/include\"\nto \nthird_party/gpus/crosstool/CROSSTOOL\n\nas suggested in https://github.com/tensorflow/tensorflow/issues/3431 fixed the issue for me. Give that a shot.\n", "Adding the line `cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include\"` works, but not `cxx_builtin_include_directory: \"/usr/local/cuda/include\"`. I checked that on my laptop, `/usr/local/cuda` is symlinked to `/usr/local/cuda-8.0`.\n", "thanks, this works for me\n", "I don't it is correct to close it down, as adding explicit flags to a file should not be a permanent solution.\n", "what does \n\"\nadd\ncxx_builtin_include_directory: \"/usr/local/cuda-8.0/include\"\nto \nthird_party/gpus/crosstool/CROSSTOOL\"\n\nmeans? I am not sure where cxx_builtin and how to add this.\n", "@sungjin712 \r\nopen `third_party/gpus/crosstool/CROSSTOOL` from the root dir and add this line `cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include\"` next to other `cxx_builtin_include_directory: \"xx\"` lines."]}, {"number": 3478, "title": "How to restore a distributed model and continue to train it with more workers?", "body": "### Environment info\n\nRunning distributed tensorflow on kubernetes.\n\nInstalled version of CUDA and cuDNN:  No\n### Steps to reproduce\n1. Train a model with 3 workers\n2. restore the model with 4 workers\n### Logs or other output that would be helpful\n\n```\ntensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [4] rhs shape= [3]\n     [[Node: save/Assign_103 = Assign[T=DT_INT64, _class=[\"loc:@local_steps\"], use_locking=true, validate_shape=true, _device=\"/job:ps/replica:0/task:0/cpu:0\"](local_steps, save/restore_slice_103)]]\n     [[Node: save/restore_all/NoOp_S6 = _Recv[client_terminated=false, recv_device=\"/job:worker/replica:0/task:0/cpu:0\", send_device=\"/job:ps/replica:0/task:0/cpu:0\", send_device_incarnation=6655275555388235088, tensor_name=\"edge_9844_save/restore_all/NoOp\", tensor_type=DT_FLOAT, _device=\"/job:worker/replica:0/task:0/cpu:0\"]()]]\n```\n\nIt seems that we need to have the same number of workers to restore a model. Is it possible to increase the number of workers without retraining the model from beginning?\n", "comments": ["I think in the presence of `local_steps`, re-storing into a different number of PS's is a known issue. @jmchen-g will know more.\n", "I assume this has been fixed in the meanwhile. Please open a new if you are still experiencing issues."]}, {"number": 3476, "title": "How to initialize LSTMStateTuple ?", "body": "In ptb_word_lm.py tutorial. When I set tf.nn.rnn_cell.BasicLSTMCell to  `state_is_tuple=True`, it fail initialise the state at the begining of each epoch. What is the way to initialise a `LSTMStateTuple` ?\n\nI did use cell.zero_state to get the varible for the initial state, which works fine. However, when I want to get initial values of the initial state using `initial_state.eval()`, I got an error saying that AttributeError: `LSTMStateTuple` object has no attribute 'eval'.\n\nPlease see a simplified version of my code below (this code works well when `state_is_tuple=False`)\n\n```\n    state = lstm.initial_state.eval()\n    for step, (x, y) in enumerate(reader.ptb_iterator(train_data,\n                                                    batch_size, num_steps)):\n        feed_dict = {\n            input_data: x, targets: y,\n            lstm.initial_state: state\n        }\n        _cost, state, _ = sess.run(\n            [cost, lstm.final_state, train_op],\n            feed_dict=feed_dict\n        )\n```\n\nThe main reason for feeding this initial_state into feed_dict is to propagate the cell's state to the next iteration.\n\nMany Thank\n", "comments": ["A) use the zero_state function on the cell object\n\nB) for an rnn, all time steps share weights.  We use one matrix to keep all gate weights.  Split by column into 4 parts to get the 4 gate weight matrices.\n\nC) StackOverflow is a better place to ask.\n", "@ebrevdo Thank you. But I still can't initialize state from `LSTMStateTuple`.\n\nWhen `state_is_tuple = False`, I can get new state values by `new_state_val = state.eval()`, and then feed `new_state_val` into `feed_dict`.\n\nHowever, when `state_is_tuple=True`, I can't initialize the state values as `LSTMStateTuple` does not have `eval()`. So I instead do the following:\n\n```\nnew_state = state\nnew_state[0].assign(state[0].eval())\nnew_state[1].assign(state[1].eval())\n```\n\nI got an error saying --> AttributeError: 'Tensor' object has no attribute 'assign'\n\nCould you please advise how to get the initial state from the LSTM cell when `state_tuple=True`?\n\nMany thanks : D\n", "Usually states are fed to tf.nn.rnn via initial_state parameter.  you can use cell.zero_state method to get an all zeros initial state.  Alternatively, you do not have to pass one and cell.zero_state will be called for you.  You do not need to store an initial state to a Variable in most cases.\n", "@ebrevdo Perharps, I didn't describe my problem clearly. I did use `cell.zero_state` to get the varible for the initial state, which works fine. However, when I want to get initial values of the initial state using `initial_state.eval()`, I got an error saying that `AttributeError: 'LSTMStateTuple' object has no attribute 'eval'`.\n\nPlease see a simplified version of my code below (this code works well when `state_is_tuple=False`)\n\n```\n        state = lstm.initial_state.eval()\n        for step, (x, y) in enumerate(reader.ptb_iterator(train_data,\n                                                        batch_size, num_steps)):\n            feed_dict = {\n                input_data: x, targets: y,\n                lstm.initial_state: state\n            }\n            _cost, state, _ = sess.run(\n                [cost, lstm.final_state, train_op],\n                feed_dict=feed_dict\n            )\n```\n\nThe main reason for feeding this initial_state into `feed_dict` is to propagate the cell's state to the next iteration.\n\nMany Thank\n", "LSTMStateTuple is just a tuple.  You can create it with two placeholders and when you run session, pass values for those placeholders with the feed_dict param.  To evaluate an LSTMStateTuple, simply call session.run(lstm_state_tuple).\n", "Thanks, it is solved.\n\nhttps://github.com/zsdonghao/TuneLayer/blob/master/tutorial_ptb_lstm_state_is_tuple.py\nhttps://github.com/zsdonghao/TuneLayer/blob/master/tutorial_ptb_lstm.py\n", "It seems I'm late to the party but can someone explain why the state is a tuple and not just a single value? thanks.\r\n\r\nis it the case that since the \"output\" of previous cell is fed in automatically to the next iteration, hence we have a cell state as-well-as an initial \"output\" state?", "LSTMTuple consists of cell state, and output.", "It seems that this issue was resolved a long time ago. But I stuck on this problem not so long ago and didn't figure out good solution from upward thread. \r\n\r\nSo I decided to share solution I found. Possibly it would be useful for somebody.\r\n\r\nAfter creating cell (e.g. with MultiRNNCell) we can receive zero_state of it cell. Hence we can initialise Tensor with such shape and feed value into it. After that we only need to pass it into RNN directly.\r\nCode example:\r\n\r\n`\r\nCode example:  \r\n\r\n    init_state = cell.zero_state(batch_size[0], tf.float32)\r\n\r\n    init_state = tf.identity(init_state, 'init_state') #Actually it works without this line. But it can be useful \r\n\r\n    _lstm_state_ = tf.contrib.rnn.LSTMStateTuple(init_state[0, 0, :, :], init_state[0,1,:,:])\r\n\r\n    preds, final_state = tf.nn.dynamic_rnn(cell, x, initial_state=(_lstm_state_,), parallel_iterations=1)\r\n`\r\n\r\nImo, this solution much scalable (e.g. for adding more layers) than creating placeholder for each LSTM layer parameter.\r\n\r\n", "Another solution:\r\n\r\n\tinitial_state_c = tf.placeholder(dtype=m_dtype, shape=[None, cell_size], name=\"initial_state_c\")\r\n\tinitial_state_h = tf.placeholder(dtype=m_dtype, shape=[None, cell_size], name=\"initial_state_h\")\r\n\r\n\tinitial_state = tf.nn.rnn_cell.LSTMStateTuple(initial_state_c, initial_state_h)\r\n\r\n\tcell = tf.nn.rnn_cell.LSTMCell(cell_size, use_peepholes=use_peepholes, initializer=kernel_initializer)\r\n\tLSTM_cell = cell\r\n\toutput, new_state = tf.nn.dynamic_rnn(cell, inputs, dtype=m_dtype, sequence_length=length, initial_state=initial_state)\r\n\r\n\tnew_state_temp = LSTM_cell.zero_state(batch_size=34, dtype=m_dtype)\r\n\tnew_state_ = sess.run(new_state_temp)\r\n\r\n\tfeed_dict = {inputs_ph: train_x[:, i*time_steps: (i + 1) * time_steps, :], labels_ph: train_y[:, i*time_steps: (i + 1) * time_steps, :], phase_train: True, initial_state_c: new_state_.c, initial_state_h: new_state_.h}\r\n\t_, summary_t, new_state_ = sess.run([train_step, summary_train, new_state], feed_dict=feed_dict)"]}, {"number": 3475, "title": "Device placement error while using multi gpus on single machine by distributed version", "body": " I follow [Distributed TensorFlow](https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html#distributed-tensorflow) to try the distributed version of tensorflow, my code is [here](https://github.com/guolinke/temp/blob/master/mnist_expert_dist.py).\n\nI try to run it on mulit machines with mutil gpus, and every worker will start multi instances of tensorflow.\n\nTo simplify problem, i only run it on single machine with multi-gpu(8*k40m), and only start one ps and one worker. Following is my scripts:\n\n```\npython ./mnist_expert_dist.py --ps_hosts=localhost:12222 --worker_hosts=localhost:12223 --job_name=ps --task_index=0 --gpu_index=0 --iteration_count=5000 --verbose=true\n\npython ./mnist_expert_dist.py --ps_hosts=localhost:12222 --worker_hosts=localhost:12223 --job_name=worker --task_index=0 --gpu_index=1 --iteration_count=5000 --verbose=true\n```\n\nFollowing is my error messages:\n\n```\nTraceback (most recent call last):\n  File \"./mnist_expert_dist.py\", line 187, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./mnist_expert_dist.py\", line 184, in main\n    run_training(cluster, server)\n  File \"./mnist_expert_dist.py\", line 121, in run_training\n    sess = sv.prepare_or_wait_for_session(server.target)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 684, in prepare_or_wait_for_session\n    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 170, in prepare_session\n    max_wait_secs=max_wait_secs, config=config)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 209, in recover_session\n    sess.run([self._local_init_op])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 372, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 636, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 708, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 728, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/Const': Could not satisfy explicit device specification '/job:worker/task:0/device:GPU:1' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices:\nIdentity: CPU\nConst: CPU\n         [[Node: save/Const = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values: model>, _device=\"/job:worker/task:0/device:GPU:1\"]()]]\nCaused by op u'save/Const', defined at:\n  File \"./mnist_expert_dist.py\", line 187, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./mnist_expert_dist.py\", line 184, in main\n    run_training(cluster, server)\n  File \"./mnist_expert_dist.py\", line 113, in run_training\n    init_op=init_op)#,\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 300, in __init__\n    self._init_saver(saver=saver)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 429, in _init_saver\n    saver = saver_mod.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 845, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 504, in build\n    filename_tensor = constant_op.constant(\"model\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py\", line 166, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2260, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1230, in __init__\n    self._traceback = _extract_stack()\n```\n\nI use nvidia-smi to see the status of gpu, it seems ps will take all gpus, and worker cannot access any gpus.\nHow can I solve this problem?\nCan i start the ps only with one gpu? or only use cpu?\n\nThanks.\n", "comments": ["I believe this is a debugging issue, for which StackOverflow is a more suitable venue.\n\n(After debugging, if an underlying bug with TF has surfaced, please feel free to re-open.)\n", "@concretevitamin I don't think it is a debugging issue. I can successfully run this script if only start one instance per worker (same as [Distributed TensorFlow](https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html#distributed-tensorflow) ).  \n\nMy issue is when I try to start multi instance per worker, It will have error that \"no supported kernel for GPU devices is available.\"\n\nI wonder why it cannot start multi instance per worker? (I don't find any tutorials about this)\nIs TF only support single instance per worker?\n\nThanks\n", "@mrry: can you take a look?  Thanks!\n", "The error message suggests that you're assigning a GPU device to one of the nodes in the `tf.train.Saver`, but it doesn't have a GPU implementation. The standard solution to this is to enable `allow_soft_placement=True` in your session `ConfigProto`.\n\nLooking at your stack trace, it seems like you aren't passing this to `sv.prepare_or_wait_for_session()`:\n\n```\n  File \"./mnist_expert_dist.py\", line 121, in run_training\n    sess = sv.prepare_or_wait_for_session(server.target)\n```\n\n...but in your GitHub repository, you do [appear to pass it](https://github.com/guolinke/temp/blob/5585113151169974e6d511a135c22972e6140205/mnist_expert_dist.py#L113) (and configure it correctly):\n\n``` python\n  sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True,\n                           device_filters=[\"/job:ps\", \"/job:worker/task:%d\" % FLAGS.task_index])\n  # ...\n  sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)\n```\n\nDo you still get the same error with the latest version of your code?\n", "Also note that the way you are assigning GPUs to local processes will probably result in inefficient resource utilization. By default every TF process will get access to all 8 of your GPUs (and potentially try to allocate all of the memory on all of them, leading to OOM errors). You should use the `CUDA_VISIBLE_DEVICES` environment variable to restrict each process to a different GPU, which will then be known as `\"/gpu:0\"` in its respective process.\n", "@mrry \nI can run it after added `allow_soft_placement=True`. Thanks very much.\nAnd thanks for your advise, it helps a lot.\n"]}, {"number": 3474, "title": "Cannot import name 'pywrap_tensorflow'", "body": "Hi, I have tried almost every methods in Stackoverflow and here, but am still struggling with the problem. Please help me to solve it.\n### Environment info\n\nOperating System: **Ubuntu 16.04 64bit (GTX 1070)** \n\nInstalled version of CUDA and cuDNN: **CUDA 8.0 RC & cuDNN 5.0**\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\ndongyoung@dkpc:~$ ls /usr/local/cuda/lib64/libcud*\n/usr/local/cuda/lib64/libcudadevrt.a    /usr/local/cuda/lib64/libcudart.so.8.0.27  /usr/local/cuda/lib64/libcudnn.so.5\n/usr/local/cuda/lib64/libcudart.so      /usr/local/cuda/lib64/libcudart_static.a   /usr/local/cuda/lib64/libcudnn.so.5.0.5\n/usr/local/cuda/lib64/libcudart.so.8.0  /usr/local/cuda/lib64/libcudnn.so          /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`) \n   Sorry, but I don't know how to do this. I just downloaded the tensorflow-master.zip file from Github\n2. The output of `bazel version`\n   **[bazel release 0.3.0]**\n### Steps to reproduce\n1. In my home directory, type 'ipython3', then change directory to tensorflow that I installed which is ~/tensorflow\n2. then type 'import tensorflow as tf'\n3. It shows ImportError: cannot import name 'pywrap_tensorflow'\n### Logs or other output that would be helpful\n\n![screenshot from 2016-07-23 12-18-14](https://cloud.githubusercontent.com/assets/673965/17075477/8e5fbdf6-50cf-11e6-8e7e-0ede795a251b.png)\n\n(If logs are large, please upload as attachment).\n\nOne more question is that how can I make a path 'tensorflow' to use globally?\n\nThank you :)\n", "comments": ["Is the ~/tensorflow also the src directory? That ususlly works bad for me. \n", "Thank you so much hholst80! It helped :+1: \n"]}, {"number": 3473, "title": "Incompatibility with Python modules that mutually import each other", "body": "I came across the following issue. It probably isn't very urgent.\n### Environment info\n\nI can produce the following error on:\n1. Operating System: OS X El Capitan, 10.11.3 (15D21)\n2. Ubuntu 14.04 (the default Ubuntu AMI on EC2)\n\nI am using the CPU version of TensorFlow, installed from\n\n```\n# Ubuntu/Linux 64-bit, CPU only, Python 2.7\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl\n```\n\n```\n> python -c \"import tensorflow; print(tensorflow.__version__)\"\n0.9.0\n```\n### Steps to reproduce\n1. Create `file1.py` with contents:\n   \n   ``` python\n   import file2 # Can also reproduce the error with a single file by having file1 import itself\n   import tensorflow as tf # The order of these two imports doesn't matter\n   sess = tf.Session() # Removing the assignment fixes the problem\n   ```\n2. Create `file2.py` with contents\n   \n   ``` python\n   import file1\n   ```\n3. Then run\n   \n   ```\n   > python file1.py\n   Exception AttributeError: \"'NoneType' object has no attribute 'raise_exception_on_not_ok_status'\" in <bound method Session.__del__ of <tensorflow.python.client.session.Session object at 0x1172b7cd0>> ignored\n   ```\n", "comments": ["Let's see...who's our Python / framework wizard?  Assigning to @mrry to take a look for now :)\n", "This seems like an unusual thing to do. \n\nIt sounds like this issue is related to [this question on Stack Overflow](http://stackoverflow.com/q/25649676), and it's a Python problem rather than a TensorFlow one. Notably the behavior of setting modules to `None` on exit was removed in Python 3.4, so if you want to write code this way you could consider upgrading :).\n\nAlternatively, ensuring that you guard any session creation (or other TensorFlow code) under `if __name__ == '__main__':` should work too.\n", "Thanks for looking into it! The Stack Overflow post was pretty useful. Using `if __name__ == '__main__':` definitely works.\n", "I'm having the same problem but I don't quite understand where\nif **name** == '**main**':\nShould go exactly.\nI'm a little new to python\nWhat happens to all the\nnone's \nin the problem file?\n", "Do you have Python modules that mutually import each other? I solved this problem by rearranging things to get rid of all occurrences of that.\n", "I'm deploying Tensorflow so there are lots of modules doing lots of things.\nI'm new to all of this so when you say,\n[I solved this problem by rearranging things to get rid of all occurrences of \"that\".]\nIs \"that\" keeping modules from importing each other?\nWhere does \"if name == 'main':\" fit in to all this?\nMaybe I should drill some basic Python programming, but when I do it feels like I'm not learning how to do anything and nothing is retained. Sorry this is unfocused. Seems futile.\n", "Yeah, \"that\" means \"keeping modules from importing each other\". In the code example in the original post, I think that replacing `file1.py` with the code below addresses the issue. I'm not sure how to deal with this in general however.\n\n``` python\nimport file2 # Can also reproduce the error with a single file by having file1 import itself\nimport tensorflow as tf # The order of these two imports doesn't matter\n\nif __name__ == \"__main__\":\n  sess = tf.Session() # Removing the assignment fixes the problem\n```\n", "I think that the guarding is also important, i.e. the code should be like this:\r\n\r\n```\r\nif __name__ == \"__main__\":\r\n  with tf.Session() as sess:\r\n    # do sth with sess\r\n  # now sess will be cleaned up, even if there was an exception\r\n```"]}, {"number": 3472, "title": "Zero value warning message in quantized convolution op is wrong?", "body": "This warning message [in this quantized ops code snippet](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/quantization/kernels/quantized_conv_ops.cc#L201-L206) is output when `input_offset < 0`:\n\n> Zero is not representable in the quantized range used by the input. This means QuantizedConv2d has to fall back to a slow implementation, since the border of zero values can't be represented easily. You should try to construct graphs that avoid this situation.\n\nIs that really what's going on there? What does that have to do with `input_offset < 0`? Secondly, there is a code comment about gemmlowp needing support for a specific code path (perhaps it's the `input_offset < 0` path?). What's going on here? \n\nAdding @petewarden as he's probably the most familiar with this code.\n", "comments": ["The snippet is no longer a valid link. Please ask on stackoverflow if you need more info."]}, {"number": 3471, "title": "C++ api runs much slower than Python API (compile flags)", "body": "My graph run in Python only takes 6 seconds for one batch, but when I run the identical batch on the same graph (graph_freeze) in the C++ Api, the time is 80 seconds. I'm guessing this 13x slowdown is probably from using the wrong C flags during compilation. This is all running on CPU only. \n\nI'm loading the graphs using the same way as in the label_images example. \n\nI took a look at: https://github.com/tensorflow/tensorflow/issues/2721, and added the -mavx C flag, which increased it by about double, but still 13x slower than the python.\n\nThe graph is a mostly a large multi layered regular RNN but with some feedforward as well. \n\nAny ideas on how to get it to the same speed as python? Is there somewhere I can see what flags tensorflow installed from source is compiled with?\n### Environment info\n\nOperating System: Linux ubuntu 64 bit 14.04\n\nInstalled version of CUDA and cuDNN:  None (CPU Only)\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   Linux 64 Bit CPU Python 3.5\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.9.0\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### Steps to reproduce\n1. Create graph in python\n2. freeze_graph.py\n3. Load graph in C++\n### What have you tried?\n1. adding -mavx C flag\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["Did you use the `-c opt` flag?  I.e.\n\n`bazel -c opt --copt=-mavx build <...>`\n", "Ah amazing, I got the run times from 2minutes -> 4.5 seconds. However, note that you must pass the flags after the build keyword:\n\n`bazel build -c opt --copt=-mavx <...>`\n\nMaybe this should be added to documentation somewhere?\n", "Right. \"-c opt\" means optimized build.\n\nOn Friday, July 22, 2016, Lingliang Zhang notifications@github.com wrote:\n\n> Closed #3471 https://github.com/tensorflow/tensorflow/issues/3471.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3471#event-732392733,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAkLHqaVmdOMiWjVmjEpiJU7PqDgFTKqks5qYVRLgaJpZM4JTLKK\n> .\n", "@lingz I am trying to run the exported .pb file in C++ and getting errors. \r\nThe .pb file works in python but not c++.\r\nI am feeding it as `cv::Mat`\r\n```\r\ncv::Mat frameC;\r\nstatic TF_Operation *placeholder = TF_GraphOperationByName(graph, \"batch:0\");\r\nstatic TF_Operation *output_op = TF_GraphOperationByName(graph, \"probability/class_idx\");\r\n\r\nfor (;;)\r\n    {\r\n        if (!capture.read(frameC))\r\n        {\r\n            std::cerr << \"Failed to grab frame\" << std::endl;\r\n            continue;\r\n        }\r\n        cv::resize(frameC, dest, cv::Size(inputWidth, inputHeight));\r\n        \r\n        TF_Tensor *tensor = TF_NewTensor(TF_FLOAT, dims, 4, dest, size, &deallocator, nullptr);\r\n        csession.SetInputs({{placeholder, tensor}});\r\n        std::chrono::steady_clock::time_point beginRun = std::chrono::steady_clock::now();\r\n        csession.Run(s);\r\n\r\n    }\r\n```\r\nCan you point me to a how you ran it in C++ ? \r\nThank you\r\n", "I have an independant project using Makefile and tensorflow shared object file instead of bazel to build. What's the g++ equalivalent of `-c opt` here?", "In my case, adding optimization options (all available for cpu) during **bazel** build works with me. \r\n`bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 //tensorflow:libtensorflow_cc.so`"]}, {"number": 3470, "title": "TensorFlow r0.9rc0 and r0.10rc0 cluster memory leak and core dump", "body": "### Environment info\n\nOperating System: \n\n```\n$ uname -svm\nLinux #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64\n$ lsb_release -a\nDistributor ID: Ubuntu\nDescription:    Ubuntu 16.04.1 LTS\nRelease:        16.04\nCodename:       xenial\n```\n\nInstalled version of CUDA and cuDNN: \n\n```\n$ find /usr/lib -name libcud\\*\n/usr/lib/i386-linux-gnu/libcuda.so.1\n/usr/lib/i386-linux-gnu/libcuda.so.361.42\n/usr/lib/i386-linux-gnu/libcuda.so\n/usr/lib/x86_64-linux-gnu/libcudnn_static.a\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v5.a\n/usr/lib/x86_64-linux-gnu/libcuda.so.1\n/usr/lib/x86_64-linux-gnu/libcudart.so.7.5.18\n/usr/lib/x86_64-linux-gnu/libcudnn.so\n/usr/lib/x86_64-linux-gnu/libcuda.so.361.42\n/usr/lib/x86_64-linux-gnu/libcudnn.so.5.0.5\n/usr/lib/x86_64-linux-gnu/libcudart.so\n/usr/lib/x86_64-linux-gnu/libcudart.so.7.5\n/usr/lib/x86_64-linux-gnu/libcudadevrt.a\n/usr/lib/x86_64-linux-gnu/libcudnn.so.5\n/usr/lib/x86_64-linux-gnu/stubs/libcuda.so\n/usr/lib/x86_64-linux-gnu/libcuda.so\n/usr/lib/x86_64-linux-gnu/libcudart_static.a\n```\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nBuilt from source:\n\n```\n* No Google Cloud Platform support\n* GPU support\n* CUDA Compute Capability: 3.0, 3.5 and 5.2\n\nprintf '\\n\\nY\\n\\n\\n/usr\\n\\n\\n3.0,3.5,5.2\\n' | ./configure\n```\n\n```\ntensorflow-0.9.0rc0-py3-none-any.whl\n```\n\n```\n0.9.0rc0\n```\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n\n```\n$ git rev-parse HEAD\n2f5ca43750dcd052843fd02a841bf041c3958670\n```\n\n```\n$ bazel version\n...............\nBuild label: 0.2.2\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Apr 21 13:01:41 2016 (1461243701)\nBuild timestamp: 1461243701\nBuild timestamp as int: 1461243701\n```\n### Steps to reproduce\n1. I'll provide a gist with an example and update.\n### What have you tried?\n1. Tried disabling summary and checkpoint restart.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\nOn 16 worker processes the memory consumption on the (single) PS process grows with >1MB/s. The worker processes also grows in memory size but not as much. My workers are only executing a sequence of \"sess.run(..)\" commands in the loop so I don't think its even possible to add stuff to the graph. We'll try to prove me wrong in the gist if I can get a usable repro.\n### Update (TensorFlow r0.10 and debugging)\n\nI just checked with the latest version of TensorFlow (r0.10) and it seems to leaks memory in the same way. Disclaimer: I used the TensorFlow package from TensorFlow.org but I have cuDNN 5 installed right now.\n\nThe TensorFlow package I used (in a Python 3.5 conda environment called `tf-r0.10`):\n\n```\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp35-cp35m-linux_x86_64.whl\n$ pip install --upgrade $TF_BINARY_URL\n```\n1. I tried adding a `sess.graph.finalize()` and I got no exceptions, thus I make the assumption that the code does not create any new nodes in each iteration.\n2. If I use the tmalloc from Ubuntu 16.04 (`libtcmalloc-minimal4`) the memory leak just got worse, but I did not get any output that I could try and examine why?\n\n```\npre_window: source activate tf-r0.10 && export CUDA_VISIBLE_DEVICES='' LD_PRELOAD=/usr/lib/libtcmalloc_minimal_debug.so.4 HEAPPROFILE=/tmp/heapprofile HEAPCHECK=1\n```\n\nI can still reproduce the core dump with the `for _ in range(100)` change:\n\n```\nterminate called after throwing an instance of 'std::system_error'\n  what():  Resource temporarily unavailable\nAborted (core dumped)\n```\n", "comments": ["Please do attach the repro snippet, the relevant logs, and please do perform debugging on your end first.  \n", "https://gist.github.com/hholst80/84fb412660b0e2de03e47daec186d094\n\nYou will need a `.tmuxinator.yml` (and tmuxinator) to launch it and an Anaconda environment called `tf-r0.9` with TensorFlow r0.9:\n\n```\nname: cluster\n\n# Runs before everything. Use it to start daemons etc.\npre: rm -rf log\n\n# Runs in each window and pane before window/pane specific commands. Useful for setting up interpreter versions.\npre_window: source activate tf-r0.9 && export CUDA_VISIBLE_DEVICES=''\n\n# Specifies (by name or index) which window will be selected on project startup. If not set, the first window is used.\nstartup_window: ps\n\n# Arrange panes in one of the five preset layouts:\n# even-horizontal, even-vertical, main-horizontal, main-vertical, or tiled.\n\n# If you have installed a GPU-compatible version of TensorFlow, the `ps` will also\n# try to allocate GPU memory although it is not helpful. This could potentially\n# crash the worker on the same machine as it has little to no GPU memory to\n# allocate. To avoid this, you can prepend the previous command to start `ps`\n# with: `CUDA_VISIBLE_DEVICES=''`\n\nwindows:\n  - ps:\n      layout: even-vertical\n      panes:\n              - python cluster.py --job_name=ps --task_index=0\n              - sleep 5 && tensorboard --logdir log\n  - worker0-3:\n      layout: tiled\n      panes:\n              - python cluster.py --job_name=worker --task_index=0\n              - python cluster.py --job_name=worker --task_index=1\n              - python cluster.py --job_name=worker --task_index=2\n              - python cluster.py --job_name=worker --task_index=3\n  - worker4-7:\n      layout: tiled\n      panes:\n              - python cluster.py --job_name=worker --task_index=4\n              - python cluster.py --job_name=worker --task_index=5\n              - python cluster.py --job_name=worker --task_index=6\n              - python cluster.py --job_name=worker --task_index=7\n  - worker8-11:\n      layout: tiled\n      panes:\n              - python cluster.py --job_name=worker --task_index=8\n              - python cluster.py --job_name=worker --task_index=9\n              - python cluster.py --job_name=worker --task_index=10\n              - python cluster.py --job_name=worker --task_index=11\n  - worker12-15:\n      layout: tiled\n      panes:\n              - python cluster.py --job_name=worker --task_index=12\n              - python cluster.py --job_name=worker --task_index=13\n              - python cluster.py --job_name=worker --task_index=14\n              - python cluster.py --job_name=worker --task_index=15\n```\n\nI can also reproduce a core dump (fail on `wait()`) using the same source by changing Agent.act line\n\n```\nself._network.copyin(self._sess)\n```\n\ninto\n\n```\nfor _ in range(100):\n  self._network.copyin(self._sess)\n```\n", "mrry@ could you take a look at this or reassign?\n", "Can you try the steps in [this documentation](http://stackoverflow.com/documentation/tensorflow/3883/how-to-debug-a-memory-leak-in-tensorflow#t=201607261538595171712) to narrow down the cause of the memory leak?\n", "I updated the issue.\n", "@mrry What are the next steps here?\n", "Without a heap profile or a simple repro, there's not much more I can do.\n\n@hholst80 I'm not familiar with tmuxinator, so I'm not sure if it is causing problems with producing a heap profile. Could you perhaps slim down the example so that you can create two processes from the command line, with no external dependencies?\n", "Run this in a script:\n\n``` .bash\nsource activate tensorflow # <--- adapt this to source TensorFlow 0.9 or 0.10 environment; remove if not using Anaconda.\nexport CUDA_VISIBLE_DEVICES='' # <--- the repro is for CPU\npython cluster.py --job_name=ps --task_index=0 &\nfor INDEX in `seq 0 15` # <--- tune this parameter to your liking. My repro is for 16 processes.\ndo\n    python cluster.py --job_name=worker --task_index=$INDEX &\ndone\n```\n", "Thanks for those repro instructions! I've got it running locally and am seeing the leak in the parameter server. I'll keep this issue posted with updates....\n", "An update: I was able to reproduce the memory leak with r0.10, and it seems to be due to an RPC stub object not being deleted correctly. This logic was changed just after r0.10 was branched, and it appears that the nightly code no longer has the same leak.\n\nHowever, there's a second issue, which is related to the core dump you were seeing:\n\n> ```\n> terminate called after throwing an instance of 'std::system_error'\n>   what():  Resource temporarily unavailable\n> Aborted (core dumped)\n> ```\n\nThis is being caused by a **thread leak**\\* in the distributed runtime. When I reproduced this and inspected a core dump, I found over 2000 threads blocked on a notification at the same point in the code, which is related to cleaning up after running a step. It appears that in some fraction of steps, at least one of the responses to these messages was being lost (or the request never made it to the remote server), which would leak a thread waiting on the response.\n\nI have a workaround in preparation, and I'll send a PR soon.\n\n[\\* **EDIT:** see next message for a better explanation.]\n", "An alternative and more plausible hypothesis for the \"thread leak\" I mentioned above: backpressure on the cleanup task would prevent these from completing in a timely manner. However, since the master doesn't block on the completion of that task before returning, a single client thread would be free to send more run requests, creating further cleanup tasks without bound. Since the worker service was only allowing a single cleanup task to complete at once, and the parameter server would be receiving cleanup tasks from all of the workers, this would create an unbounded number of threads in each master, eventually causing some of them to fail upon creating another thread.\n\nThere's a fix in PR #3757, which is under review now. I tested it locally, and it's been running for hours now on my local machine without failure. Can you try it and confirm that it works?\n\nThanks for persevering with this long-running issue!\n", "It seems by my rudimentary analysis to have improved the performance as well. Thank you very much @mrry for your work on this issue!\n", "You're welcome, and I'm glad to hear it!\n"]}, {"number": 3469, "title": "Raspberry Pi Bazel Build \"Define appropriate PLATFORM macro\" error", "body": "When building TensorFlow on Raspberry Pi with Bazel, the pre-compiler end up throwing this error:\n\n```\nDefine the appropriate PLATFORM_<foo> macro for this platform\n```\n\nFrom what I've been able to gather, here's the cause of the issue:\n1. Because Raspberry Pi uses an ARM CPU, the `IS_MOBILE_PLATFORM` macro is defined [in `tensorflow/core/platform/platform.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/platform.h#L45)\n2. Later, when trying to compile [png.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/png.h#L23-L26), [gif.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/gif.h), or [jpeg.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/jpeg.h), the if/else statements fall through, leaving with the default option to throw an error.\n### Environment info\n\nOperating System: Raspbian GNU/Linux, version 8.0\n\nInstalled version of CUDA and cuDNN: N/A\n\nInstalled from source.\n1. The commit hash : e95f4e760c6b6713b6b686ebeff9a1586a5831dd\n2. The output of `bazel version` : \n\n```\nBuild label: 0.2.1-2016-06-13 (@447f7f3)\nBuild target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Mon Jun 13 19:05:24 2016 (1465844724)\nBuild timestamp: 1465844724\nBuild timestamp as int: 1465844724\n```\n### Steps to reproduce\n1. Build TensorFlow from source on Raspberry Pi [as described in this guide](https://github.com/samjabrahams/tensorflow-on-raspberry-pi/blob/master/GUIDE.md) _without_ deleting [this line from `tensorflow/core/platform/platform.h`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/platform.h#L45), which defines `IS_MOBILE_PLATFORM` when compiling on ARM devices.\n### What have you tried?\n1. Deleted the line mentioned above, which fixes the problem for local builds\n### Logs or other output that would be helpful\n\n[define_macro_error.txt](https://github.com/tensorflow/tensorflow/files/378789/define_macro_error.txt)\n", "comments": ["According to [this post on StackExchange](http://raspberrypi.stackexchange.com/questions/754/how-can-i-detect-that-im-compiling-for-raspberry-pi), it looks like there's no reliable, automatic way to detect if building for Raspberry Pi. \n\nWould it be possible to add in a `#if  !defined(PLATFORM_RASPBERRY_PI)` line in [`platform.h`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/platform.h#L45) and define the macro manually in Bazel with `--copt=\"-D PLATFORM_RASPBERRY_PI\"`?\n", "@petewarden any thoughts?\n", "No update on this one I'm afraid. I've been focused on the makefile approach to building for the Pi, and I'm not familiar enough with Bazel to suggest the right way to handle this.\n", "Closing this -- we only support Makefile builds right now.", "Ok, no worries- I'll keep maintaining my repo for those who want a Python interface on their Raspberry Pi.", "Long build process on the Raspberry Pi.\r\n\r\n>When you wake up the next morning and it's finished compiling\r\n\r\nAt this stage."]}, {"number": 3468, "title": "Remove confusing section", "body": "Removing the --rm is simpler. If users want to use a named container, they can, but it's not essential.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}]