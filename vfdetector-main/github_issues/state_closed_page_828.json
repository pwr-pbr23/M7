[{"number": 28690, "title": "tf.lite.TFLiteConverter.from_frozen_graph error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (or github SHA if from source):1.13.1\r\n\r\n\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\n\r\n```\r\n\r\n\r\n", "comments": ["Could you provide your pb file and the tflite conversion command you used. Will be helpful for finding out the issue. Because, all the operators that you have mentioned are supported operators by TFLite.", "I have download the model from the link as i mentioned below :+1: \r\n[http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz](url)\r\n\r\nthe conversion program written in python which is shown below:\r\n\r\n\r\nimport tensorflow as tf\r\n\r\ngraph_def_file=\"./frozen_inference_graph.pb\"\r\ninput_arrays=[\"image_tensor\"]\r\noutput_arrays=[\"detection_boxes\",\"detection_scores\",\"num_detections\",\"detection_classes\"]\r\ninput_tensor={\"image_tensor\":[1,300,300,3]}\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays,input_tensor)\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\nopen(\"detect.tflite\", \"wb\").write(tflite_model)", "Follow the steps in this repository\r\n[https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md](\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md)", "If i am using that model whose link given below:\r\n[http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz](url)\r\nwhich is also a SSD mobilenetV1 model , It get successfully converted into tflite.So what is issue with the above first mentioned model which is also a SSD mobilenet model.", "@harsh020goyal \r\n\r\nhi ,\r\n\r\nas of now object detection model just supports **ssd mobilenet** versions using\r\n script [running_on_mobile_tensorflowlite](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md) to tflite version. This script allows \"add_postprocessing_op\" parameter which resolve your problem which mentioned in issue.\r\n\r\n`Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\n`\r\n\r\nHope this resolve your issue.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "@Dayananda-V @harsh020goyal \r\n ``TFLite_Detection_PostProcess`` appears because when you frozen your graph, you use ``export_tflite_ssd_graph.py.py`` instead of ``export_inference_graph.py``, so that your input arrays become **normalized_input_image_tensor**, and your output arrays become **'TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'**.\r\n\r\nThen to convert to tflite format, you can use either **bazel** or **tf.lite.TFLiteConverter**.\r\nFor the last method, the code snippet is like this:\r\n``converter = tf.lite.TFLiteConverter.from_frozen_graph('your_graph.pb',input_shapes = {'normalized_input_image_tensor':(1,300,300, input_arrays = ['normalized_input_image_tensor'],output_arrays = ['TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'])\r\nconverter.allow_custom_ops=True tflite_model = converter.convert() tf_model_files = 'new.tflite' open(tf_model_files,\"wb\").write(tflite_model)``\r\n\r\n\r\n", "@chenyuZha : Thanks for the solution. If anyone is looking for how to get the value of `input_shapes`, `input_arrays` and `output_arrays` then kindly upload your tflite graph to the [this](https://lutzroeder.github.io/netron/) link and you will find all parameters value."]}, {"number": 28689, "title": "Various build fixes for FreeBSD", "body": "This PR incorporates changes from https://github.com/freedomtan/tensorflow/commit/ffd86f605bfdbe6f209c1fa707089d6010f0b719, https://github.com/tensorflow/tensorflow/pull/25471 and my own.\r\n\r\nThis is not ready to be merged yet, as there is a problematic change in last commit. In third_party/hwloc/BUILD.bazel file we only need to have `_INCLUDE_PRIVATE_HWLOC_AUTOIGEN_CONFIG_H_LINUX_SUBS` items in `_INCLUDE_PRIVATE_HWLOC_AUTOIGEN_CONFIG_H_COMMON_SUBS` when we are building on Linux. I wasn't able to express that in Bazel, though. Nested `select`s, as well as `if`s in `BUILD` files are prohibited. How do I go about this change?\r\n\r\nFixes https://github.com/tensorflow/tensorflow/issues/28113\r\nObsoletes https://github.com/tensorflow/tensorflow/pull/25471", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28689) for more info**.\n\n<!-- need_sender_cla -->", "Signed CLA.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28689) for more info**.\n\n<!-- ok -->", "@arrowd please let us know if this is still WIP ?", "> \r\n> \r\n> @arrowd please let us know if this is still WIP ?\r\n\r\nYes, I still need help with including `_INCLUDE_PRIVATE_HWLOC_AUTOIGEN_CONFIG_H_LINUX_SUBS` into\r\n\r\n```\r\ntemplate_rule(\r\nname = \"include_private_hwloc_autogen__config_h\",\r\n...\r\n```\r\n\r\nin `third_party/hwloc/BUILD.bazel`\r\n", "Let's just omit that `hwloc` change from the PR for now and get this merged?", "> Let's just omit that `hwloc` change from the PR for now and get this merged?\r\n\r\ncan you please push changes again after removing '`hwloc`'", "Ping. Can we get this in?", "Another bump.", "I take it, this didn't make it into `beta1` release?", "Unfortunately did not. But it will be definitely in 2.0 release candidates, and any other release we do."]}, {"number": 28688, "title": "Why is the model file named as *00000-of-00001", "body": "My variables model files is named as *00000-of-00002 or *00001-of-00002. My questions are:\r\n1. What's the difference between them?\r\n2. Why is the model file named as this pattern?\r\nThanks!", "comments": ["@zqp2009happy  It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n"]}, {"number": 28687, "title": "Using td.cond during training leads to reduced throughput", "body": "In the process of using the resnet50 for imagenet training, we used LARS to update the learning rate and calculate LR at each step of the training. The throughput of the training is about 5500. For this we intend to optimize and calculate the LR operation every few steps to improve throughput. In the original code, we perform compute_lr calculation every step.\r\nI modified the code as shown below\uff1a\r\ngg is a tensor used to observe which step of training;\r\n2 is a constant, indicating that lr is calculated every 2 steps.\r\n\r\nThe code:\r\n\r\ndef compute_lr()\r\ncoumpte_lr\r\n...\r\nstored_lr\r\n...\r\nreturn lr\r\ndef get_larsvalue()\r\nget_stored_lr\r\n...\r\nreturn lr\r\n\r\ntf.cond(tf.cast(tf.equal(tf.mod(gg,2),0),tf.bool),lambda:self.compute_lr(),lambda: self.get_larsvalue())\r\n\r\nBut after I modified the code, the throughput dropped. After analysis, I think it is because tf.cond is not a lazy operation, it will execute both branches, which is obviously not what I want. I don't know how to code to complete my thoughts now, ask you to help. Thanks", "comments": ["@melo19890618 It looks, This question is better asked on [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there. Let us know. Thanks! ", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28686, "title": "BUGFIX:", "body": "Fixed the bug of the kernel not fully processing all the items when the batch * height * width > number of threads spawned by adding a layer of for-loop\r\n\r\n**two spaces for minor performance increase:**\r\n1. instead of taking `hue_delta` as a global memory, take in the value inside `hue_delta` in order to eliminate unnecessary global memory read\r\n2. make the copying performed in this conditional: `if (!AdjustHue && !AdjustSaturation && !AdjustV)` access global memory with coalesced accesses", "comments": ["@chsigg \r\na small bugfix of `adjust_hsv_nhwc` kernel ( more details in the commit note )\r\n", "@tensorflow-bot\r\nrun test again", "@chsigg \r\nTwo Windows Bazel builds failed. Could you help me out?\r\n\r\nThe error output is:\r\n```\r\nERROR: T:/src/github/tensorflow/tensorflow/lite/python/interpreter_wrapper/BUILD:59:1: Linking of rule '//tensorflow/lite/python/interpreter_wrapper:_tensorflow_wrap_interpreter_wrapper.so' failed (Exit 1000): link.exe failed: error executing command\r\n```"]}, {"number": 28685, "title": "The cycle detection algorithm in the variable creation has bad performance", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Don\u2019t know\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): Not used\r\n- GCC/Compiler version (if compiling from source): Not used\r\n- CUDA/cuDNN version: Not related\r\n- GPU model and memory: Not related\r\n\r\n**Describe the current behavior**\r\n\r\nMaybe related: #17439.\r\n\r\nI noticed some slow variable creations. It happens when the initial value is a tensor with complex dependencies.  After some digging, I found that it may be caused by the algorithm used in the cycle detection code:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/d1022145203c1edb81a39010da3f61207533091d/tensorflow/python/ops/variables.py#L2505-L2517\r\n\r\n**Describe the expected behavior**\r\n\r\nCreating a variable should be completed within acceptable time.\r\n\r\n**Code to reproduce the issue**\r\n\r\n\r\nYou can reproduce the problem using the following code:\r\n\r\n```python\r\nimport time\r\n\r\nimport tensorflow as tf\r\n\r\n\r\ndef _build_tensor(depth):\r\n    fibonacci = [tf.zeros(shape=()), tf.ones(shape=())]\r\n\r\n    for _ in range(depth):\r\n        fibonacci.append(fibonacci[-2] + fibonacci[-1])\r\n\r\n    return fibonacci[-1]\r\n\r\n\r\ndef main():\r\n    for depth in range(15, 25):\r\n        with tf.Graph().as_default():\r\n            tensor = _build_tensor(depth)\r\n\r\n            start_time = time.perf_counter()\r\n            tf.Variable(initial_value=tensor)\r\n            end_time = time.perf_counter()\r\n\r\n            print('Depth = {}, Time = {}'.format(depth, end_time - start_time))\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n**Other info / logs**\r\n\r\nHere is my output from running the code:\r\n\r\n```\r\nDepth = 15, Time = 0.008952808999310946\r\nDepth = 16, Time = 0.014324793000014324\r\nDepth = 17, Time = 0.019670226999551232\r\nDepth = 18, Time = 0.03077544999996462\r\nDepth = 19, Time = 0.04785999100022309\r\nDepth = 20, Time = 0.07621835800000554\r\nDepth = 21, Time = 0.12341592400025547\r\nDepth = 22, Time = 0.19620911800029717\r\nDepth = 23, Time = 0.31814610099991114\r\nDepth = 24, Time = 0.5071976489998633\r\n```\r\n\r\nNotice the time used for creating a variable grows exponentially.\r\n\r\n----\r\n\r\nThe cycle detection algorithm could be optimized to have a linear time complexity. Also, the algorithm should avoid stack overflow if the initial value has a long dependency chain.", "comments": ["@EFanZh  It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n", "@muddham I have updated my issue, please check.", "@EFanZh Able to reproduce the issue with the provided code.\r\nDepth = 15, Time = 0.014409996000040337\r\nDepth = 16, Time = 0.018489084000066214\r\nDepth = 17, Time = 0.02723818900005881\r\nDepth = 18, Time = 0.048183349999931124\r\nDepth = 19, Time = 0.07164499200007413\r\nDepth = 20, Time = 0.11124446999997417\r\nDepth = 21, Time = 0.17927562900001703\r\nDepth = 22, Time = 0.2863872639999272\r\nDepth = 23, Time = 0.4592743739999605\r\nDepth = 24, Time = 0.7376542980000522", "Thanks a lot for reporting this @EFanZh! The fix is on the way.\r\n\r\nI'm curious, what was the use-case which triggered this regression for you? In my experience complex initializers are not that common.", "@superbobry I was creating a variable to store the the result of a complex computation. The problem is that I need to store the computation result multiples, so I think I could utilize the initializer of the variable to to it, by which, I mean setting the initial value of that variable to the computation result and use the initializer as the storing operation, then my program gets stuck.\r\n\r\nCurrently, as a workaround, I am using an zero value as the initial value of the variable, and created another assignment operation to store the computation result. But this method has two extra operations created: a `tf.zeros` and a `tf.assign`. It is not as clean as using the computation result as the initial value.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28685\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28685\">No</a>\n", "@superbobry I see the updated implementation is using recursion, which I think may cause stack overflow if the dependency chain becomes too long. Is it possible to implement cycle detection using a stack and loop to avoid stack overflow?\r\n\r\nAlso, the usage of `self.cached_session()` in `testCycleDetectionIsLinear` seems unnecessary. Because new graphs are created and used inside the loop, `with self.cached_session()` has no effect.", "Recursion is indeed bounded in Python, but the default limit (1000 on Linux) seems reasonable for most (if not all) initializer graphs. Recursion in Python is also slower than iteration, but again, I'm not convinced it is worth optimizing in that particular case.\r\n\r\nThanks for spotting redundant `self.cached_session()`!"]}, {"number": 28684, "title": "Error using tensorflow module, even appearing in the list shown by pip list", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version:\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: pip\r\n- GPU model and memory: MX920\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI can't use tensorflow module, even appearing in the list shown by pip list\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI executed the 3 first commands: \r\n_python3 --version\r\npip3 --version\r\nvirtualenv --version_\r\n\r\nBut, the answer I get from the 1st command was: \"python3\" is not recognized as a intern or extern command, operational program or a batch file\r\n\r\nThen I just keep with the installation, because the virtualenv and the pip3 were updated, and after that, I tried to do the command:\r\n_virtualenv --system-site-packages -p python3 ./venv_\r\nBut the answer I get was:\r\n_The path python3 (from --python=python3) does not exist_\r\n\r\nso, I couldn't create the virtual environment.\r\nAfter that, I wrote the command:\r\n_pip3 install --user --upgrade tensorflow_\r\n\r\nAnd the command:\r\n_pip list_\r\n\r\nIn the answer of the last one, the list showed that the tensorflow was installed, but when I tried to run an example provided by the TensorFlow site, PyCharm couldn't find the module, and now I don't know what to do.\r\nAlso, when I write the command: \r\n_python -c \"import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"_\r\n\r\nI get this answer:\r\n_2019-05-13 21:40:50.182555: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\ntf.Tensor(1277.5322, shape=(), dtype=float32)_\r\n", "comments": ["@wagnerDestro Please follow the instructions in this [link](https://www.tensorflow.org/install/pip) to install tensorflow. Thanks!", "@gadagashwini I followed the steps in the tensorflow guide. I even reinstalled Python 3 to make sure, but the error persists.", "@wagnerDestro Can you recheck and confirm that your cpu supports AVX2? ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28683, "title": "Enable opening TF source tree with Visual Studio Code", "body": "When one attempts to open up the TensorFlow source code tree in Visual Studio Code with the `vscode-bazel` plugin, the IDE responds with this error:\r\n![Screen Shot 2019-05-13 at 5 19 53 PM](https://user-images.githubusercontent.com/12436991/57662341-f611ee00-75a3-11e9-9546-9864e73e48c6.png)\r\n\r\nThis PR adds a small edit to one of the `BUILD` files that makes this error go away. After this change, Visual Studio Code is able to process the build files and display a list of Bazel build targets.", "comments": []}, {"number": 28682, "title": "Add tensorflow/addons to v2 converter warning", "body": "Adding tensorflow/addons into the contrib converter warnings.", "comments": []}, {"number": 28681, "title": "Keras model to tensorflow trainable pb file and checkpoint", "body": "I tried to convert keras h5 model into pb and checkpoint files.\r\n```python\r\nfrom keras import backend as K\r\nfrom keras.models import load_model\r\nimport tensorflow as tf\r\n\r\nmodel = load_model('model/my_model.h5')\r\n\r\nK.set_learning_phase(0) #0 : test, 1 : train\r\n\r\nsess = K.get_session()\r\n\r\nsaver = tf.train.Saver()\r\nsaver.save(sess, 'keras/keras.ckpt')\r\n\r\nsess.graph.as_default()\r\ngraph = sess.graph\r\n\r\nwith open('keras/keras.pb', 'wb') as f:\r\n    f.write(graph.as_graph_def().SerializeToString())\r\n```\r\n\r\nI succeeded in bringing this pb and checkpoint to tensorflow and running the graph, obtaining an inference.\r\nBut the problem is, I have no idea how to train this thing.\r\nUsually, tensorflow models have a training operation, and we just have to sess.run that operation, but I'm assuming keras is working in a different way somehow.\r\nIs it possible to train keras models when they are converted to tensorflow models?", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 28680, "title": "[TF 2.0 API Docs] tf  - typo, extra symbols in pip install doc copy code", "body": "\r\n## Existing URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf\r\n\r\n## Description of issue (what needs changing):\r\n\r\nCopyable code block has extra characters `\",` at the end:\r\n\r\n```pip install tensorflow==2.0.0-alpha0\",```\r\n\r\n### Clear description\r\n\r\nCopyable code block should be changed to the following to make copying easier.\r\n\r\n```pip install tensorflow==2.0.0-alpha0```\r\n\r\n### Correct links\r\n\r\nThis is the overview for the TF 2.0 API, but I couldn't find the docstring in the referred source: https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/__init__.py\r\n\r\n### Submit a pull request?\r\n\r\nWould love to, but couldn't find in source where this was a docstring or being generated :(\r\n", "comments": ["@ghchinoy Looks like this is fixed. \r\nCan you please let us know if you are happy to close if no issue persists. Thanks!"]}, {"number": 28679, "title": "Batch matrix-matrix product slower than Pytorch", "body": "I'm doing a batch matrix multiplication using matmul but it seems to be slower than using [bmm](https://pytorch.org/docs/stable/torch.html#torch.bmm) function from Pytorch. Specifically,\r\n\r\n```\r\nsentence = tf.constant(tf.random.normal([10240, 32, 3]))\r\nw = tf.constant(tf.random.normal([10240, 3, 1]))\r\n\r\n%timeit tf.matmul(sentence, w)\r\n725 \u00b5s \u00b1 9.57 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\r\n```\r\n\r\ncompared to \r\n\r\n```\r\nsentence = torch.randn(10240, 32, 3).to(device)\r\nw = torch.randn(10240, 3, 1).to(device)\r\n\r\n%timeit torch.bmm(sentence, w)\r\n78.5 \u00b5s \u00b1 14 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n```\r\n\r\nIs there anyway to speed up the batch matrix-matrix product computation?\r\n\r\nAlso, normal matrix multiplication seems to be slightly slower than Pytorch\r\n\r\n```\r\nsentence = tf.constant(tf.random.normal([10240, 32]))\r\nw = tf.constant(tf.random.normal([32, 1]))\r\n\r\n%timeit tf.matmul(sentence, w)\r\n42.6 \u00b5s \u00b1 807 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n\r\n```\r\n\r\ncompared to\r\n\r\n```\r\nsentence = torch.randn(10240, 32).to(device)\r\nw = torch.randn(32, 1).to(device)\r\n\r\n%timeit torch.mm(sentence, w)\r\n19.2 \u00b5s \u00b1 1.38 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n```\r\nbut I guess that's between the acceptable limits.\r\n\r\nTested with eager mode both on 1.13 and 2.0-alpha.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): Both 1.13 and 2.0-alpha\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0/CuDNN 7.3.1\r\n- GPU model and memory: NVidia Titan V\r\n\r\n", "comments": ["When a statement `torch.bmm` returns, it does not mean the computation has finished. The computation on GPU tensors is asynchronous. \r\nSo you cannot use %timeit to time it.\r\n\r\nAlso, most cuda functions are slower in the first few iterations, which are often excluded from timing.", "@lioutasb Please provide simple reproducible code to investigate it further.", "@lioutasb Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28678, "title": "atch matrix-matrix product", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["duplicate #28676"]}, {"number": 28677, "title": "atch matrix-matrix product", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["duplicate #28676"]}, {"number": 28676, "title": "atch matrix-matrix product", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 28675, "title": "Build TF without AVX from docker devel-gpu-py3 failed", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): -\r\n- TensorFlow version: -\r\n- Python version: 3.5\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 0.21.0\r\n- GCC/Compiler version (if compiling from source): same as docker image `devel-gpu-py3`\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: 1080Ti\r\n\r\n\r\n\r\n**Describe the problem**\r\nI have old processors (2 x Xeon X5660) and GTX 1080 Ti and I want to play with TF, but installation tensorflow on my test Ubuntu 16.04 failed because my processors dont have AVX instructions.\r\nI need a custiom build tensorflow for python 3.5, GPU and no AVX.\r\nTherefore, I try to build tensorflow it myself.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```bash\r\n# get image from hub\r\ndocker pull tensorflow/tensorflow:devel-gpu-py3\r\n\r\n# run image\r\ndocker run --runtime=nvidia -it  -v ~/projects/tf:/my-devel tensorflow/tensorflow:devel-gpu-py3 bash\r\n\r\n# downgrade bazel (because tf 0.13.1 need bazel 0.21, not 0.24.1 as in docker image)\r\nrm -rf /usr/local/bin/bazel\r\nwget -O /bazel/installer.sh \"https://github.com/bazelbuild/bazel/releases/download/0.21.0/bazel-0.21.0-installer-linux-x86_64.sh\"\r\nchmod +x /bazel/installer.sh\r\n/bazel/installer.sh\r\n\r\n\r\ncd /tensorflow_src\r\ngit checkout v1.13.1\r\n\r\n# create venv (I thought it would help to get around the error but did not help.)\r\nvirtualenv --python=/usr/local/bin/python venv\r\nsource venv/bin/activate\r\n\r\n# install deps\r\npip --no-cache-dir install Pillow h5py keras_applications keras_preprocessing matplotlib mock numpy scipy sklearn pandas portpicker\r\n\r\nexport TF_ENABLE_XLA=1\r\nexport CC_OPT_FLAGS=\"-march=native -mno-avx\"\r\n\r\n\r\n./configure\r\n\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nAfter run last command I get:\r\n```\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (364 packages loaded, 23677 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/double_conversion/BUILD.bazel:12:1: C++ compilation of rule '@double_conversion//:double-conversion' failed (Exit 127)\r\n/usr/bin/env: 'python': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 76.013s, Critical Path: 0.10s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nBut:\r\n```\r\n(venv) root@6dae59a3faf7:/tensorflow_src# /usr/bin/env 'python'\r\nPython 3.5.2 (default, Nov 12 2018, 13:43:14) \r\n[GCC 5.4.0 20160609] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> \r\n```\r\n\r\n\r\nWhy bazel or TF not found python? In configuration path to python is valid and it seems to be ok.\r\n\r\nIts issue looks like very old issues with error message \"/usr/bin/env: 'python': No such file or directory\", but they not receive answers.", "comments": ["Maybe there is some simple way to build tensorflow without AVX, but with GPU (1080 Ti) and py35 support?", "Found solution: https://github.com/tensorflow/tensorflow/issues/10289#issuecomment-492102920\r\nBuilded wheel: https://github.com/yaroslavvb/tensorflow-community-wheels/issues/109"]}, {"number": 28674, "title": "tflite - Fixing GL Delegate build so that the .so generated can be linked in Android CMake and used in the NDK", "body": "When evaluating the GL delegate, I found that there was a linking error in the bazel file because the name of the .so was not set.  This fixes that issue so that once this built, this .so can be dropped in with libtensorflow.so and we can do GL inference through C++.\r\n\r\nApologies for sitting on this PR, but it got sidelined until now. ", "comments": ["@infil00p \r\n\r\nHi Joe.  Thanks for the PR.  The android_x86 things are probably not gonna help for the GPU delegate, because the emulators don't support OpenGL ES 3.1 compute shaders.  It's not gonna work.  Delegating the decision to @jdduke \r\n\r\nI'm not sure about the linkopts you added in the 2nd file.  The indentation is a bit off, and I can't tell because I'm not using CMake etc.  Also delegating the decision to @jdduke ", "What's causing MacOS Contrib to fail? Any idea? "]}, {"number": 28672, "title": "[ROCm] Fix for the broken `--config=rocm` build", "body": "This PR contains fixes for two separate issues, both of which broke the `--config=rocm` build (in different ways)\r\n\r\nsee individual commit comments for details.\r\n\r\n---------------------\r\n\r\n@tatianashp , @whchung, just FYI\r\n\r\nPlease approve and merge. The changes here are trivial and only applicable for the --config=rocm build.\r\n\r\nthanks", "comments": []}, {"number": 28671, "title": "Exception when import: DLL load failed (Windows 10, Tensorflow 1.12.0, python 3.6.7)", "body": "I have installed Python 3.6.7 on my Windows 10 machine. Afterwards I downloaded with the tensorflow module: pip install https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.12.0-cp36-cp36m-win_amd64.whl\r\n\r\nOn the computer is Visual Studio 2019 installed with additional MSVC v141 (VS 2017) and MSVC v140 (VS 2015).\r\n\r\nWhen I run import tensorflow as tf in python, I get the following error:\r\n\r\n```\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\nWhat I tried so far:\r\n\r\n- checked if I am able to import dependencies (absl-py-0.7.1 astor-0.7.1. ...):\r\nevery module gets loaded except tensorflow_estimator and tensorflow\r\n\r\n- reinstalled visual studio, python, tensorflow and tried multiple versions\r\n\r\nDoes anyone have another idea?\r\n", "comments": ["Did you try to follow instruction listed in [TensorFlow website](https://www.tensorflow.org/install/source_windows). You can also have a look on this [issue](https://github.com/tensorflow/tensorflow/issues/19584) and let us know if that helps. Thanks! ", "Thank you, the reason was that my CPU has no AVX support. Now it works.", "That's great the issue is resolved. Thanks!", "Are you satisfied with the resolution of your issue?<br> [Yes](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28671)<br> [No](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28671)\r\n"]}, {"number": 28670, "title": "[ROCm] Adding ROCm support for the \"matmul\" op", "body": "This PR adds ROCm support for the \"matmul\" op.\r\n\r\nThis is a trivial change...please review and merge.\r\n\r\nThanks\r\n\r\ndeven\r\n\r\n-----------------------\r\n\r\n@tatianashp , @whchung just FYI", "comments": ["@deven-amd could you help resolved conflicts?", "working on it ... `--config=rocm` build is broken again on the tip :(", "pushed out a rebase to resolve the merge conflict.\r\n\r\nI see that all the CI builds are failing, bu there seem to be no links present which would allow me to look at the failure logs...don't know what is going on"]}, {"number": 28669, "title": "AttributeError: '_OptionsDataset' object has no attribute 'output_shapes'", "body": "Downloading / extracting dataset imdb_reviews (?? GiB) to /home/lucifer/tensorflow_datasets/imdb_reviews/subwords8k/0.0.1...\r\nDl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\r\nDl Size...:   0%|          | 0/80 [00:01<?, ? MiB/s]\r\nDl Completed...:   0%|          | 0/1 [00:41<?, ? url/s]MiB]\r\nDl Size...:   1%|\u258f         | 1/80 [00:41<54:16, 41.23s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [01:52<?, ? url/s]/ MiB]\r\nDl Size...:   2%|\u258e         | 2/80 [01:52<1:05:24, 50.31s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [02:12<?, ? url/s]MiB]  \r\nDl Size...:   4%|\u258d         | 3/80 [02:12<52:38, 41.02s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [02:55<?, ? url/s]MiB]\r\nDl Size...:   5%|\u258c         | 4/80 [02:55<52:45, 41.65s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [03:01<?, ? url/s]MiB]\r\nDl Size...:   6%|\u258b         | 5/80 [03:01<38:43, 30.98s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [03:34<?, ? url/s]MiB]\r\nDl Size...:   8%|\u258a         | 6/80 [03:34<39:07, 31.72s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [03:39<?, ? url/s]MiB]\r\nDl Size...:   9%|\u2589         | 7/80 [03:39<28:48, 23.68s/ MiB]\r\n\r\n...........\r\n\r\nDl Size...:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 79/80 [38:44<00:42, 42.73s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [40:17<?, ? url/s] MiB]\r\nDl Size...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 80/80 [40:17<00:00, 57.89s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [40:54<?, ? url/s]     \r\nDl Size...: 81 MiB [40:54, 51.50s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [42:18<?, ? url/s]\r\nDl Size...: 82 MiB [42:18, 61.31s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [42:50<?, ? url/s]\r\nDl Size...: 83 MiB [42:50, 52.68s/ MiB]\r\nDl Completed...:   0%|          | 0/1 [43:56<?, ? url/s]\r\n\r\n........\r\n\r\nDl Size...: 154 MiB [1:22:41, 80.27s/ MiB]\r\nDl Completed...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [1:23:56<00:00, 4554.05s/ url]\r\nDl Size...: 155 MiB [1:23:56, 78.58s/ MiB]\r\nDl Completed...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [1:24:53<00:00, 4554.05s/ url]\r\nDl Completed...: 2 url [1:25:03, 3352.75s/ url]                     \r\nDl Size...: 156 MiB [1:25:03, 72.26s/ MiB]\r\n\r\n25000 examples [00:28, 863.60 examples/s] \r\nShuffling...:   0%|          | 0/10 [00:00<?, ? shard/s]WARNING: Logging before flag parsing goes to stderr.\r\nW0513 21:39:05.540721 140294086346560 deprecation.py:323] From /home/lucifer/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:249: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse eager execution and: \r\n`tf.data.TFRecordDataset(path)`\r\n\r\nReading...: 0 examples [00:00, ? examples/s]\r\nReading...: 2500 examples [00:00, 230117.41 examples/s]\r\nWriting...:   0%|          | 0/2500 [00:00<?, ? examples/s]\r\nWriting...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:00<00:00, 172112.14 examples/s]\r\nReading...: 0 examples [00:00, ? examples/s]\r\nReading...: 2500 examples [00:00, 198575.13 examples/s]\r\nWriting...:   0%|          | 0/2500 [00:00<?, ? examples/s]\r\nWriting...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:00<00:00, 191566.22 examples/s]\r\nReading...: 0 examples [00:00, ? examples/s]\r\nReading...: 2500 examples [00:00, 203007.82 examples/s]\r\nWriting...:   0%|          | 0/2500 [00:00<?, ? examples/s]\r\n\r\n........\r\n\r\n17342 examples [00:02, 5761.24 examples/s]\r\n17994 examples [00:03, 5968.74 examples/s]\r\n18644 examples [00:03, 6116.94 examples/s]\r\n19303 examples [00:03, 6249.34 examples/s]\r\n19966 examples [00:03, 6358.77 examples/s]\r\n20624 examples [00:03, 6421.09 examples/s]\r\n21278 examples [00:03, 6428.01 examples/s]\r\n21935 examples [00:03, 6468.08 examples/s]\r\n22588 examples [00:03, 6486.41 examples/s]\r\n23241 examples [00:03, 6458.44 examples/s]\r\n23890 examples [00:03, 6432.71 examples/s]\r\n24551 examples [00:04, 6482.91 examples/s]\r\n25000 examples [00:04, 5994.04 examples/s]\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-4-31d575d3ee06> in <module>\r\n      1 dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\r\n----> 2                           as_supervised=True)\r\n      3 train_dataset, test_dataset = dataset['train'], dataset['test']\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51     _check_required(fn, kwargs)\r\n---> 52     return fn(*args, **kwargs)\r\n     53 \r\n     54   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/registered.py in load(name, split, data_dir, batch_size, download, as_supervised, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs)\r\n    251   if download:\r\n    252     download_and_prepare_kwargs = download_and_prepare_kwargs or {}\r\n--> 253     dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n    254 \r\n    255   if as_dataset_kwargs is None:\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     51     _check_required(fn, kwargs)\r\n---> 52     return fn(*args, **kwargs)\r\n     53 \r\n     54   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py in download_and_prepare(self, download_dir, download_config)\r\n    234         else:  # Mode is forced or stats do not exists yet\r\n    235           logging.info(\"Computing statistics.\")\r\n--> 236           self.info.compute_dynamic_properties()\r\n    237         # Set checksums of downloaded (or cached) files, and size:\r\n    238         self.info.download_checksums = dl_manager.recorded_download_checksums\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_info.py in compute_dynamic_properties(self)\r\n    243 \r\n    244   def compute_dynamic_properties(self):\r\n--> 245     self._compute_dynamic_properties(self._builder)\r\n    246     self._fully_initialized = True\r\n    247 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_info.py in _compute_dynamic_properties(self, builder)\r\n    256         # Fill DatasetFeatureStatistics.\r\n    257         dataset_feature_statistics, schema = get_dataset_feature_statistics(\r\n--> 258             builder, split_name)\r\n    259 \r\n    260         # Add the statistics to this split.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_info.py in get_dataset_feature_statistics(builder, split)\r\n    488   # Start here, we've processed all examples.\r\n    489 \r\n--> 490   output_shapes_dict = dataset.output_shapes\r\n    491   output_types_dict = dataset.output_types\r\n    492 \r\n\r\nAttributeError: '_OptionsDataset' object has no attribute 'output_shapes'", "comments": ["Tutorials in TF2.0 Alpha\r\nlinux ubuntu 18.04\r\nGTX780\r\ntensorflow2.0  alpha0 gpu version\r\n\r\nwhen i run \"Text classification with an RNN\",  the error comes as follows:", "@lucifer2288 I tried reproducing the issue through colab link of Text classification with an RNN but the code executed without any error. Can you try once again and let us know if that still gives error. Thanks!", "> @lucifer2288 I tried reproducing the issue through colab link of Text classification with an RNN but the code executed without any error. Can you try once again and let us know if that still gives error. Thanks!\r\n\r\nthank you very much,  i solved this problem by update tensorflow-datasets from v1.0.1 to v1.0.2,  case closed, ", "> @lucifer2288 I tried reproducing the issue through colab link of Text classification with an RNN but the code executed without any error. Can you try once again and let us know if that still gives error. Thanks!\r\n\r\nThank you dude", "I just try the \"text_classification.ipynb\" in the colab. The issue still exists.\r\n(tensorflow-datasets version: 1.3.2)", "The attribute `output_shapes` was deprecated, you can access the output shapes via `tf.compat.v1.data.get_output_shapes()`.", "The docs need updating with recommended solution:\r\nhttps://www.tensorflow.org/tutorials/keras/text_classification\r\n\r\nStill has\r\n```\r\ntrain_batches = (\r\n    train_data\r\n    .shuffle(BUFFER_SIZE)\r\n    .padded_batch(32, train_data.output_shapes))\r\n\r\ntest_batches = (\r\n    test_data\r\n    .padded_batch(32, train_data.output_shapes))\r\n```\r\n"]}, {"number": 28668, "title": "tf.keras.models.load_model fails on Sequential model", "body": "**System information**\r\n- TensorFlow installed from: `pip`\r\n- TensorFlow version: `tf-nightly-2.0-preview-2.0.0.dev20190513`\r\n- Python version: 3.6.7\r\n\r\n**Describe the current behavior**\r\n\r\nAttempting `tf.keras.models.load_model` on a `Sequential` model throws\r\n\r\n```sh\r\nValueError: You are trying to load a weight file containing 2 layers into a model with 0 layers.\r\n```\r\n\r\nMight be caused by a `layers`/`_layers` mismatch as mentioned [here](https://github.com/keras-team/keras/issues/10417#issuecomment-418511814). Not sure if this is the problem but [`_clone_sequential_model`](https://github.com/tensorflow/tensorflow/blob/2c2d508aa2947ede05cfa195139b176d6cdc9056/tensorflow/python/keras/models.py#L218) uses `model._layers` whereas [`save_model_to_hdf5`](https://github.com/tensorflow/tensorflow/blob/30f682e776fbcff8d2da3c3cc0e8d12e1b3dde12/tensorflow/python/keras/saving/hdf5_format.py#L104) accesses `model.layers`.\r\n\r\n**Minimal example**\r\n\r\n```py\r\nimport tensorflow as tf\r\n\r\nmodel = tf.keras.Sequential(\r\n    [tf.keras.Input(3), tf.keras.layers.Dense(3), tf.keras.layers.Dense(1)]\r\n)\r\nmodel.compile(loss=\"mse\", optimizer=\"adam\")\r\nmodel.fit(tf.constant([[1, 2, 3], [4, 5, 6]]), tf.constant([1, 2]))\r\nmodel.save(\"model.h5\")\r\nrestored_model = tf.keras.models.load_model(\"model.h5\")\r\n```", "comments": ["Tried running your snippet and was able to reproduce the error on mentioned TensorFlow version (2.0.0-dev20190513).", "I'm seeing the same error with the stable `tensorflow==1.14.0`. This seems relatively high priority since I'm currently unable to save any tf.keras models.\r\n\r\n```python\r\nimport tempfile\r\n\r\nimport tensorflow as tf\r\n\r\n\r\ngpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\r\nsession = tf.compat.v1.Session(\r\n    config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\r\ntf.keras.backend.set_session(session)\r\n\r\n\r\ndef main():\r\n    batch_size = 3\r\n\r\n    image_shape = (32, 32, 3)\r\n    inputs = tf.random.uniform((batch_size, *image_shape))\r\n\r\n    model = tf.keras.Sequential((\r\n        tf.keras.layers.Conv2D(\r\n            filters=16,\r\n            kernel_size=3,\r\n            strides=2,\r\n            padding='SAME',\r\n            activation='linear'),\r\n    ))\r\n\r\n    _ = model(inputs)\r\n\r\n    with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\r\n        tf.keras.models.save_model(model, fd.name, overwrite=True)\r\n        model2 = tf.keras.models.load_model(fd.name, compile=False)\r\n\r\n    print(model2.summary())\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nResults in:\r\n```\r\nValueError: You are trying to load a weight file containing 1 layers into a model with 0 layers.\r\n```", "Probably a duplicate of #26809.", "@foxik I'm pretty sure mine is not related to having an input layer.", "@hartikainen Your example might not be, but the original Minimal example in the issue is related -- if the `Input` is removed and `input_shape` set for the first `Dense` layer, the model does load.\r\n\r\nSo I believe the originally reported problem in this issue is a duplicate of #26809. \r\n\r\nYour example is slightly different -- your model does not specify input shape in any way, so it is constructed during the first call of the model. Such models however do not save the input shapes to h5 (and from h5 are similar to how a Sequential model is saved when the InputLayer is left out), so when you try to load the weights, the same code path triggers an error. If you\r\n- add `input_shape=image_shape` parameter to the Conv2D, the model can be loaded;\r\n- or if you load the model without loading weights, run it once, and only then load the weights, it can be loaded:\r\n```python\r\n# Instead of the original\r\nmodel2 = tf.keras.models.load_model(fd.name, compile=False)\r\n# this works; the JSON is also stored in h5 file, but it cannot be easily accessed, so I take it directly from the original model\r\nmodel2 = tf.keras.models.model_from_json(model.to_json())\r\nmodel2(inputs)\r\nmodel2.load_weights(fd.name)\r\n```", "Thanks @foxik, that was useful. One thing I'm still wondering is, is this expected behavior or a bug? I'd expect `Sequential` model like the one in my above example to be saveable/loadable the same way as a model built with explicit input shapes. Or is there something that makes loading them more difficult?", "The case in which an `Input` or `InputLayer` is an explicit part of model specification (like in the Minimal example of this issue description) it is definitely a bug (because the Input layer with information about input sizes is not saved).\r\n\r\nYour case where the model dimensions is defined by first usage is semantically a bit different -- but personally I believe it is also a bug.", "This is fixed in latest TF 2.0 nightly build '2.0.0-dev20190718'\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28668\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28668\">No</a>\n", "@ymodak is the example I posted above also supposed to work with `tf-nightly-gpu-2.0-preview==2.0.0-dev20190718`? I'm still seeing the same issue (with a slightly modified script):\r\n```python\r\nimport tempfile\r\n\r\nimport tensorflow as tf\r\n\r\n\r\ndef main():\r\n    batch_size = 3\r\n\r\n    image_shape = (32, 32, 3)\r\n    inputs = tf.random.uniform((batch_size, *image_shape))\r\n\r\n    model = tf.keras.Sequential((\r\n        tf.keras.layers.Conv2D(\r\n            filters=16,\r\n            kernel_size=3,\r\n            strides=2,\r\n            padding='SAME',\r\n            activation='linear'),\r\n    ))\r\n\r\n    _ = model(inputs)\r\n\r\n    with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\r\n        tf.keras.models.save_model(model, fd.name, overwrite=True)\r\n        model2 = tf.keras.models.load_model(fd.name, compile=False)\r\n\r\n    print(model2.summary())\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nI get:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/kristian/conda/envs/softlearning-2/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/kristian/conda/envs/softlearning-2/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/kristian/github/hartikainen/softlearning-2/tests/test_sequential_serialize.py\", line 31, in <module>\r\n    main()\r\n  File \"/home/kristian/github/hartikainen/softlearning-2/tests/test_sequential_serialize.py\", line 25, in main\r\n    model2 = tf.keras.models.load_model(fd.name, compile=False)\r\n  File \"/home/kristian/conda/envs/softlearning-2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 138, in load_model\r\n    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\r\n  File \"/home/kristian/conda/envs/softlearning-2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 165, in load_model_from_hdf5\r\n    load_weights_from_hdf5_group(f['model_weights'], model.layers)\r\n  File \"/home/kristian/conda/envs/softlearning-2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 671, in load_weights_from_hdf5_group\r\n    ' layers.')\r\nValueError: You are trying to load a weight file containing 1 layers into a model with 0 layers.\r\nException ignored in: <function _TensorCacheDeleter.__del__ at 0x7f9fabdde158>\r\nTraceback (most recent call last):\r\n  File \"/home/kristian/conda/envs/softlearning-2/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\", line 316, in __del__\r\nTypeError: argument of type 'NoneType' is not iterable\r\n```", "@hartikainen Thanks for testing against TF 2.0  Can you please post a new issue for the same? Its better to track this separately. Thanks!", "I still have this issue with the following versions :\r\n\r\n```\r\nfrom tensorflow import keras\r\nkeras.__version__\r\nOut[27]: \r\n'2.2.4-tf'\r\nimport tensorflow\r\ntensorflow.__version__\r\nOut[29]: \r\n'2.0.0-beta1'\r\n```\r\n\r\nMWE:\r\n\r\n```\r\nfrom tensorflow.python.keras.layers import Conv2D, GlobalAveragePooling2D, Input\r\nfrom tensorflow.python.keras.models import Sequential, load_model\r\n\r\nmodel = Sequential([\r\n    Input((224, 224, 3)),\r\n    Conv2D(10, (3, 3)),\r\n    GlobalAveragePooling2D(),\r\n])\r\nmodel.summary()\r\n\r\nmodel.save('test.hdf5')\r\n\r\nmodel_2 = load_model('test.hdf5')\r\n```", "Same issue. Highly frustrating that I cannot load models trained prior to `keras@2.3.x` into the `tf.keras` ecosystem. This is a blocking error for many developers wishing to transition from traditional `keras` to `tf.keras` and in turn `tensorflow@2.x.x`.\r\n\r\n@hartikainen did @foxik 's answer solve your issue? Unless I'm missing a step, that did not solve my issue. ", "@ghunkins, no my case hasn't been resolved yet. My specific issue is tracked at https://github.com/tensorflow/tensorflow/issues/30892, but I don't know if there's been any work towards fixing that.", "I've the same problem here.  My model was created, trained and saved using tf.keras and I'm *not* able to tf.keras.models.load_model it.  I saved the model using HDF5 entire model option as explained in this link: https://www.tensorflow.org/tutorials/keras/save_and_load ; the load_model function fails with a weird error:\r\n\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n\r\n(...)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in from_config(cls, config, custom_objects)\r\n   1150       assert layer_name in created_layers\r\n   1151       layer = created_layers[layer_name]\r\n-> 1152       layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\r\n   1153       output_tensors.append(nest.flatten(layer_output_tensors)[tensor_index])\r\n   1154 \r\n\r\nIndexError: list index out of range\r\n", "@andmax Please create a new issue as your error is different so that others with similar error will get benefited. ping me once you create. We will resolve. Thanks!", "Hi @jvishnuvardhan  I've already created an issue:\r\nhttps://github.com/tensorflow/tensorflow/issues/33357\r\nAnd it seems it will be fixed on next release TF 1.15rc/2.0.\r\nThanks!", "hi, guys, I m getting a similar error  \r\n\r\nnp.set_printoptions(suppress=True)\r\nmodel = tensorflow.keras.models.load_model('keras_model.h5')\r\n\r\nValueError: ('Unrecognized keyword arguments:', dict_keys(['input_dtype']))\r\n\r\nplease tell me how to solve it.\r\nmany thanks in advance! ", "@uchihatashi Can you please create a new issue with details and a standalone code to reproduce your error. Thanks!", "@jvishnuvardhan hey thanks a lot for the response and I found my error as I was having a problem with the version of TensorFlow and Keras.  "]}, {"number": 28667, "title": "Can't Run code on ubuntu 18.04 ", "body": "I tried to run the code in my ubuntu system but couldn't run the code\r\ncan u suggest a way to run the code without gpu support and it would be great if u say with few proper steps", "comments": ["@hariteja97  It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n"]}, {"number": 28666, "title": "I can not import tf successfully although it doesn't output any error", "body": "<em> </em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10 64bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: 1.8.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.16.1\r\n- GCC/Compiler version (if compiling from source): gcc 6.3\r\n- CUDA/cuDNN version: CUDA_9.0; cuDNN_7.1\r\n- GPU model and memory: GTX 1080ti\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI follow the guide : https://www.pugetsystems.com/labs/hpc/The-Best-Way-to-Install-TensorFlow-with-GPU-Support-on-Windows-10-Without-Installing-CUDA-1187/\r\nbut when I used cmd or spyder to write&run tensorflow with 'import tensorflow as tf', the console will run a moment and output none\r\n\r\n\r\n**Any other info / logs**\r\n\r\n![spyder](https://user-images.githubusercontent.com/49911630/57619542-1d2ae880-75c1-11e9-97b8-c417790f4afb.png)\r\n", "comments": ["@WY19940327 I tried reproducing the issue  but the code executed and also displayed the result. Can you try once again and let us know if that still gives no output. Also follow the instructions in this [link](https://www.tensorflow.org/install/pip) to install Tensorflow. Thanks!", "Thank U! I will try to reinstall tf follow your link and give you res", "@gadagashwini I reinstall tf-gpu follow your link, but the system output same things\r\n\r\n![image](https://user-images.githubusercontent.com/49911630/57771285-411b3500-774d-11e9-8bfe-c1aa005d4ee3.png)\r\n\r\n![image](https://user-images.githubusercontent.com/49911630/57771321-598b4f80-774d-11e9-8f88-a3dfccb165fe.png)\r\n\r\n![image](https://user-images.githubusercontent.com/49911630/57771406-96efdd00-774d-11e9-9cc5-8187f1890b3d.png)\r\n", "@WY19940327 Just to clarify, Did you install tensorflow inside the conda environment or outside? ", "@gadagashwini  I installed tensorflow by 'conda -c anaconda tensorflow-gpu==1.8.0' before you gave me the guide link which used the pip. maybe some thing wrong in my processing", "@WY19940327 To verify, Please let us know if you are still stuck?  Thanks!  ", "@gadagashwini yes. it made me crazy. no matter I used conda or pip tf follow your guide, I always got same problem with the 'import tf'", "@gadagashwini  sorry, I found my gtx 1080ti is used cuda10.0, not cuda9.0. I try to change my cuda version", "@gadagashwini god like! I just remove the env which installed by conda and use virtualenv, then everything has been OK. Anyway, thanks your help.\r\n\r\n![image](https://user-images.githubusercontent.com/49911630/57962284-033a2e80-7950-11e9-82a2-1decc6dff4eb.png)\r\n", "@WY19940327 Glad it resolved. Will close this. Thanks!"]}, {"number": 28665, "title": "Added TC for UINT8 type conversions.", "body": "", "comments": ["@talumbau , thaks for spending time on my PR, i have updated the code as per your suggestion, kindly check and approve.\r\n\r\nRegards\r\nAmit", "@talumbau thanks for approving the PR.\r\n\r\n@gbaned , can you please help to get this merged.\r\n\r\nRegards\r\nAmit", "@gbaned , can pls help to get this merged.\r\n\r\nRegards\r\nAmit", "Hi Amit,\r\n\r\nUnfortunately, I gave you a bad suggestion that is blocking merging this PR. In showing explicitly the behavior of negative floats casts to uint8, my intention was to show that we reproduce numpy behavior. However, the cast of a float to an integral type where the truncated value is not representable in the destination type is undefined behavior in C++. This is my fault for specifically requesting such changes in your PR. Please revert your tests to the version prior (where you do not explicitly cast a negative float to uint8), and I will approve. Thanks very much and sorry for the hassle! ", "@talumbau , thanks for spending time on the PR , i have reverted the changes, kindly check and approve.\r\nAlso there are 2 more important PRs of mine, under your name would be great if you can spend some time on that and provide feedback.\r\n\r\nRegards\r\nAmit", "This is unable to merge due to new conflicts in the file. Please rebase and fix merge conflicts.", "@talumbau , i checked there is no merge conflict coming for me, can you please double check.\r\n\r\nRegards\r\nAmit", "Can one of the admins verify this patch?", "I'm not sure why you say there is no merge conflict. If you look at master right now, there exists a test called `CastFloatToUInt8`:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/cast_test.cc#L94\r\n\r\nthis conflicts with the test of the same name in your PR. I believe what happened is that this test came in to existence after you initially created the pull request. I think you should update your branch to master and see if the CL still makes sense or if test coverage has already been added via another mechanism. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 28664, "title": "tensorflow-gpu import error", "body": "Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\shoba\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\nPlease help. I see that you asked to submit new ticket since its different for each system spec. \r\nkindly help what should i do to resolve this issue. i have installed python 3.6.8. cuda 9.0\r\n\r\nthanks\r\nshobana", "comments": ["OS Platform and Distribution - windows 10 64 bit\r\nTensorFlow installed from - pip install tensorflow-gpu\r\nTensorFlow version - 1.13.1\r\nBazel version - not sure\r\nCUDA/cuDNN version - cuda - 9.0 and cudnn - v7.5.0.56\r\nGPU model and memory - Intel(R) HD Graphics 630\r\ntotal graphics memory - 4154 MB\r\n", "Although I think unrelated but the CUDA version should be 10.0 and cuDNN version should be 7.4 ( corresponding to CUDA 10.0 ). Use anaconda to install tensorflow-gpu after installing CUDA and cuDNN. Its easier that way.", "ok will try it and let you know. thanks ", "@Shobana16 Please let us know if you have tried installing using conda.", "@Shobana16 Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28663, "title": "meta_optimizer.cc layout failed on frozen_graph", "body": "TF 2.0 preview gpu\r\nPython 3.6.3\r\n\r\nImporting a frozen graph def leads to an error: `... meta_optimizer.cc:486] layout failed: Invalid argument: Invalid graph: Frame ids for node ...`\r\n\r\n**What I did**\r\nCheckpoint: http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\r\n\r\nRun in `research/slim/` found here: https://github.com/tensorflow/models/tree/master/research/slim\r\n1. GraphDef:\r\n```python export_inference_graph.py --model_name=inception_v3 --output_file=MODELS/inception_v3_inf_graph.pb```\r\n2. Obtain a copy of: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py and place it in `research/slim`\r\n3. Create Frozen Graph:\r\n```python freeze_graph.py --input_graph=MODELS/inception_v3_inf_graph.pb --input_checkpoint=MODELS/inception_v3.ckpt --input_binary=true --output_graph=MODELS/frozen_inception_v3.pb --output_node_names=InceptionV3/Predictions/Reshape```\r\n4. Pack into `tar.gz`.\r\n\r\nI then imported the frozen graph with\r\n```python\r\nimport tensorflow as tf\r\nimport tarfile\r\nimport os\r\n\r\nfrom tensorflow.core.framework import graph_pb2\r\nfrom tensorflow.python.framework import importer\r\n\r\nINCEPTION_V3_FILE_NAME = 'frozen_inception_v3.tar.gz'\r\nINCEPTION_V3_FROZEN_GRAPH = 'frozen_inception_v3.pb'\r\n# Shape[None x 299 x 299 x 3]\r\nINCEPTION_V3_INPUT = 'input:0'\r\n# Shape[None x 1 x 1 x 2048]\r\nINCEPTION_V3_OUTPUT = 'InceptionV3/Logits/AvgPool_1a_8x8/AvgPool:0'\r\n\r\n\r\ndef graph_def_from_tarball(filename, tar_filename):\r\n    with tarfile.open(tar_filename, 'r:gz') as tar:\r\n        proto_str = tar.extractfile(filename).read()\r\n    return graph_pb2.GraphDef.FromString(proto_str)\r\n\r\n\r\ngraph_def = graph_def_from_tarball(\r\n    INCEPTION_V3_FROZEN_GRAPH,\r\n    INCEPTION_V3_FILE_NAME\r\n)\r\n\r\n\r\n@tf.function\r\ndef run_classifier(images):\r\n\r\n    def classifier_fn(images):\r\n        input_map = {INCEPTION_V3_INPUT: images}\r\n        output_tensor = [INCEPTION_V3_OUTPUT]\r\n        classifier_outputs = importer.import_graph_def(\r\n            graph_def,\r\n            input_map,\r\n            output_tensor,\r\n            'InceptionV3'\r\n        )\r\n        return classifier_outputs[0]\r\n\r\n    logits = tf.map_fn(\r\n        fn=classifier_fn,\r\n        elems=tf.expand_dims(images, 0),\r\n        parallel_iterations=1,\r\n        back_prop=False,\r\n        swap_memory=True,\r\n        dtype=tf.float32,\r\n        name='RunClassifier')\r\n\r\n    logits = tf.concat(tf.unstack(logits), 0)\r\n    return logits\r\n\r\n\r\nimages = tf.random.normal([1, 299, 299, 3])\r\n\r\nr = run_classifier(images)\r\nprint(r)\r\n\r\n```\r\n\r\nError message (the node it errors on varies):\r\n```\r\nE tensorflow/core/grappler/optimizers/meta_optimizer.cc:486] layout failed: Invalid argument: Invalid graph: Frame ids for node RunClassifier/while/body/_1/InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/BatchNorm/moving_mean does not match frame ids for it's fanout RunClassifier/while/body/_1/InceptionV3/InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/BatchNorm/FusedBatchNorm/Mul2\r\n```\r\nSometimes it is:\r\n```\r\nE tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] layout failed: Invalid argument: Invalid graph: Frame ids for node RunClassifier/while/body/_1/InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta does not match frame ids for it's fanout RunClassifier/while/body/_1/InceptionV3/InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/BatchNorm/FusedBatchNorm/Offset\r\n```\r\n\r\n**What I expect**\r\nNo error or some better description of what went wrong.\r\nNote: The imported graph def works, it just throws this error and it is unclear to me if it does the right thing considering the error message.", "comments": ["This example was extracted from a large codebase and tested on my machine!\r\n\r\nThis extracted example also causes the following problem: https://github.com/tensorflow/tensorflow/issues/27141\r\nWhen I run this code within a large code base (cannot share) I do not get the aforementioned CUDNN error but I get the `layout failed` one.\r\n\r\nEdit: I did some more testing and there seems to be some kind of race condition. When adding e.g. `tf.config.gpu.set_per_process_memory_growth()` after the `imports` I sometimes don't get the CUDNN error anymore.", "I'm not familiar with the grappler code, so I'm unassigning myself.", "any updates on this issue? I'm trying to convert my model to tensorrt and faced a similar issue. The error log looks like this:\r\n\r\n` layout failed: Invalid argument: Invalid graph: Frame ids for node StatefulPartitionedCall/while/body/_378/while/transformer_decoder/transformer_decoder_layer/multi_head_attention_12/dense_73/BiasAdd/ReadVariableOp does not match frame ids for it's fanout StatefulPartitionedCall/while/body/_378/while/Identity_2`", "Hi,\r\n\r\nTagging @bixia1 for better visibility. cc: @DEKHTIARJonathan \r\nRequesting Tensorflow team to please help on following issue.\r\nWhen we try converting tensorflow model to TRT getting following error messages (related to frame ids):\r\n```\r\nDuring conversion:\r\nlayout failed: Invalid argument: Invalid graph: Frame ids for node StatefulPartitionedCall/while/body/_378/while/transformer_decoder/transformer_decoder_layer_2/multi_head_attention_17/dense_100/BiasAdd/ReadVariableOp does not match frame ids for it's fanout StatefulPartitionedCall/while/body/_378/while/Identity_4\r\n```\r\n```\r\nDuring execution:\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{node Func/StatefulPartitionedCall/while/body/_378/output_control_node/_1118}} has inputs from different frames. The input {{node StatefulPartitionedCall/while/body/_378/while/transformer_decoder/transformer_decoder_layer_2/sequential_14/dense_101/Tensordot/ReadVariableOp}} is in frame 'StatefulPartitionedCall/while'. The input {{node StatefulPartitionedCall/while/body/_378/while/y_net/embedding/embedding_lookup}} is in frame ''. [Op:__inference_signature_wrapper_89313]\r\n```\r\nSteps to reproduce:\r\n- Download [runnables.zip](https://drive.google.com/file/d/1ZEAymONsLzl96Ee5yLYnYCK00sgZ_nR7/view?usp=sharing) \r\n- Run \"python jdw_convert_to_trt.py [model-path-./jdw_model] [output-model-path]\"\r\n\r\nFor your reference, error logs:\r\n[execution_log.txt](https://github.com/tensorflow/tensorflow/files/6734803/execution_log.txt)\r\n[conversion_log.txt](https://github.com/tensorflow/tensorflow/files/6734804/conversion_log.txt)\r\nOriginal post : [What is \u201cframe ids\u201d in tf-trt conversion](https://forums.developer.nvidia.com/t/what-is-frame-ids-in-tf-trt-conversion/173743)\r\n\r\n\r\nThank you.", "@sleighsoft \r\nIt looks like you are using an older Version of Tensorflow 2.0. Many bugs have been fixed in the latest version. Can you please execute your code using Latest stable Version(2.5) and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28663\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28663\">No</a>\n"]}, {"number": 28662, "title": "Unable to use custom problem for visualizing attention", "body": "I am trying to run the code in the TransformerVisualization.ipynb notebook to visualize the attention on a user defined problem, however I am unable to do so. When running the following code\r\n\r\n```\r\nusr_dir.import_usr_dir('./transformer')\r\nvisualizer = visualization.AttentionVisualizer(hparams_set, model_name, data_dir, problem_name, beam_size=1)\r\n```\r\n\r\nI get the following error\r\n\r\n```\r\nINFO:tensorflow:Importing user module transformer from path /content/Deep-Learning\r\n---------------------------------------------------------------------------\r\nLookupError                               Traceback (most recent call last)\r\n<ipython-input-20-fd5211124aa0> in <module>()\r\n      1 usr_dir.import_usr_dir('./transformer')\r\n----> 2 visualizer = visualization.AttentionVisualizer(hparams_set, model_name, data_dir, problem_name, beam_size=1)\r\n\r\n4 frames\r\n/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/registry.py in problem(name)\r\n    256                   ] + all_problem_names\r\n    257     error_msg = \"\\n  * \".join(error_lines)\r\n--> 258     raise LookupError(error_msg)\r\n    259   return _PROBLEMS[base_name](was_reversed=was_reversed, was_copy=was_copy)\r\n    260 \r\n\r\nLookupError: code_transformer not in the set of supported problems:\r\n  * algorithmic_addition_binary40\r\n  * algorithmic_addition_decimal40\r\n  * algorithmic_cipher_shift200\r\n  * algorithmic_cipher_shift5\r\n  * algorithmic_cipher_vigenere200\r\n  * algorithmic_cipher_vigenere5\r\n  * algorithmic_identity_binary40\r\n  * algorithmic_identity_decimal40\r\n  * algorithmic_multiplication_binary40\r\n  * algorithmic_multiplication_decimal40\r\n  * algorithmic_reverse_binary40\r\n  * algorithmic_reverse_binary40_test\r\n  * algorithmic_reverse_decimal40\r\n  * algorithmic_reverse_nlplike32k\r\n  * algorithmic_reverse_nlplike8k\r\n  * algorithmic_shift_decimal40\r\n  * algorithmic_sort_problem\r\n  * audio_timit_characters_tune\r\n  * audio_timit_tokens8k_test\r\n  * audio_timit_tokens8k_tune\r\n  * babi_qa_concat_all_tasks_10k\r\n  * babi_qa_concat_all_tasks_1k\r\n  * babi_qa_concat_task10_10k\r\n  * babi_qa_concat_task10_1k\r\n  * babi_qa_concat_task11_10k\r\n  * babi_qa_concat_task11_1k\r\n  * babi_qa_concat_task12_10k\r\n  * babi_qa_concat_task12_1k\r\n  * babi_qa_concat_task13_10k\r\n  * babi_qa_concat_task13_1k\r\n  * babi_qa_concat_task14_10k\r\n  * babi_qa_concat_task14_1k\r\n  * babi_qa_concat_task15_10k\r\n  * babi_qa_concat_task15_1k\r\n  * babi_qa_concat_task16_10k\r\n  * babi_qa_concat_task16_1k\r\n  * babi_qa_concat_task17_10k\r\n  * babi_qa_concat_task17_1k\r\n  * babi_qa_concat_task18_10k\r\n  * babi_qa_concat_task18_1k\r\n  * babi_qa_concat_task19_10k\r\n  * babi_qa_concat_task19_1k\r\n  * babi_qa_concat_task1_10k\r\n  * babi_qa_concat_task1_1k\r\n  * babi_qa_concat_task20_10k\r\n  * babi_qa_concat_task20_1k\r\n  * babi_qa_concat_task2_10k\r\n  * babi_qa_concat_task2_1k\r\n  * babi_qa_concat_task3_10k\r\n  * babi_qa_concat_task3_1k\r\n  * babi_qa_concat_task4_10k\r\n  * babi_qa_concat_task4_1k\r\n  * babi_qa_concat_task5_10k\r\n  * babi_qa_concat_task5_1k\r\n  * babi_qa_concat_task6_10k\r\n  * babi_qa_concat_task6_1k\r\n  * babi_qa_concat_task7_10k\r\n  * babi_qa_concat_task7_1k\r\n  * babi_qa_concat_task8_10k\r\n  * babi_qa_concat_task8_1k\r\n  * babi_qa_concat_task9_10k\r\n  * babi_qa_concat_task9_1k\r\n  * cola\r\n  * cola_characters\r\n  * common_voice\r\n  * common_voice_clean\r\n  * common_voice_noisy\r\n  * common_voice_train_full_test_clean\r\n  * genomics_expression_cage10\r\n  * genomics_expression_gm12878\r\n  * genomics_expression_l262k\r\n  * github_function_docstring\r\n  * gym_air_raid-v0_random\r\n  * gym_air_raid-v4_random\r\n  * gym_air_raid_deterministic-v0_random\r\n  * gym_air_raid_deterministic-v4_random\r\n  * gym_air_raid_no_frameskip-v0_random\r\n  * gym_air_raid_no_frameskip-v4_random\r\n  * gym_alien-v0_random\r\n  * gym_alien-v4_random\r\n  * gym_alien_deterministic-v0_random\r\n  * gym_alien_deterministic-v4_random\r\n  * gym_alien_no_frameskip-v0_random\r\n  * gym_alien_no_frameskip-v4_random\r\n  * gym_amidar-v0_random\r\n  * gym_amidar-v4_random\r\n  * gym_amidar_deterministic-v0_random\r\n  * gym_amidar_deterministic-v4_random\r\n  * gym_amidar_no_frameskip-v0_random\r\n  * gym_amidar_no_frameskip-v4_random\r\n  * gym_assault-v0_random\r\n  * gym_assault-v4_random\r\n  * gym_assault_deterministic-v0_random\r\n  * gym_assault_deterministic-v4_random\r\n  * gym_assault_no_frameskip-v0_random\r\n  * gym_assault_no_frameskip-v4_random\r\n  * gym_asterix-v0_random\r\n  * gym_asterix-v4_random\r\n  * gym_asterix_deterministic-v0_random\r\n  * gym_asterix_deterministic-v4_random\r\n  * gym_asterix_no_frameskip-v0_random\r\n  * gym_asterix_no_frameskip-v4_random\r\n  * gym_asteroids-v0_random\r\n  * gym_asteroids-v4_random\r\n  * gym_asteroids_deterministic-v0_random\r\n  * gym_asteroids_deterministic-v4_random\r\n  * gym_asteroids_no_frameskip-v0_random\r\n  * gym_asteroids_no_frameskip-v4_random\r\n  * gym_atlantis-v0_random\r\n  * gym_atlantis-v4_random\r\n  * gym_atlantis_deterministic-v0_random\r\n  * gym_atlantis_deterministic-v4_random\r\n  * gym_atlantis_no_frameskip-v0_random\r\n  * gym_atlantis_no_frameskip-v4_random\r\n  * gym_bank_heist-v0_random\r\n  * gym_bank_heist-v4_random\r\n  * gym_bank_heist_deterministic-v0_random\r\n  * gym_bank_heist_deterministic-v4_random\r\n  * gym_bank_heist_no_frameskip-v0_random\r\n  * gym_bank_heist_no_frameskip-v4_random\r\n  * gym_battle_zone-v0_random\r\n  * gym_battle_zone-v4_random\r\n  * gym_battle_zone_deterministic-v0_random\r\n  * gym_battle_zone_deterministic-v4_random\r\n  * gym_battle_zone_no_frameskip-v0_random\r\n  * gym_battle_zone_no_frameskip-v4_random\r\n  * gym_beam_rider-v0_random\r\n  * gym_beam_rider-v4_random\r\n  * gym_beam_rider_deterministic-v0_random\r\n  * gym_beam_rider_deterministic-v4_random\r\n  * gym_beam_rider_no_frameskip-v0_random\r\n  * gym_beam_rider_no_frameskip-v4_random\r\n  * gym_berzerk-v0_random\r\n  * gym_berzerk-v4_random\r\n  * gym_berzerk_deterministic-v0_random\r\n  * gym_berzerk_deterministic-v4_random\r\n  * gym_berzerk_no_frameskip-v0_random\r\n  * gym_berzerk_no_frameskip-v4_random\r\n  * gym_bowling-v0_random\r\n  * gym_bowling-v4_random\r\n  * gym_bowling_deterministic-v0_random\r\n  * gym_bowling_deterministic-v4_random\r\n  * gym_bowling_no_frameskip-v0_random\r\n  * gym_bowling_no_frameskip-v4_random\r\n  * gym_boxing-v0_random\r\n  * gym_boxing-v4_random\r\n  * gym_boxing_deterministic-v0_random\r\n  * gym_boxing_deterministic-v4_random\r\n  * gym_boxing_no_frameskip-v0_random\r\n  * gym_boxing_no_frameskip-v4_random\r\n  * gym_breakout-v0_random\r\n  * gym_breakout-v4_random\r\n  * gym_breakout_deterministic-v0_random\r\n  * gym_breakout_deterministic-v4_random\r\n  * gym_breakout_no_frameskip-v0_random\r\n  * gym_breakout_no_frameskip-v4_random\r\n  * gym_carnival-v0_random\r\n  * gym_carnival-v4_random\r\n  * gym_carnival_deterministic-v0_random\r\n  * gym_carnival_deterministic-v4_random\r\n  * gym_carnival_no_frameskip-v0_random\r\n  * gym_carnival_no_frameskip-v4_random\r\n  * gym_centipede-v0_random\r\n  * gym_centipede-v4_random\r\n  * gym_centipede_deterministic-v0_random\r\n  * gym_centipede_deterministic-v4_random\r\n  * gym_centipede_no_frameskip-v0_random\r\n  * gym_centipede_no_frameskip-v4_random\r\n  * gym_chopper_command-v0_random\r\n  * gym_chopper_command-v4_random\r\n  * gym_chopper_command_deterministic-v0_random\r\n  * gym_chopper_command_deterministic-v4_random\r\n  * gym_chopper_command_no_frameskip-v0_random\r\n  * gym_chopper_command_no_frameskip-v4_random\r\n  * gym_crazy_climber-v0_random\r\n  * gym_crazy_climber-v4_random\r\n  * gym_crazy_climber_deterministic-v0_random\r\n  * gym_crazy_climber_deterministic-v4_random\r\n  * gym_crazy_climber_no_frameskip-v0_random\r\n  * gym_crazy_climber_no_frameskip-v4_random\r\n  * gym_demon_attack-v0_random\r\n  * gym_demon_attack-v4_random\r\n  * gym_demon_attack_deterministic-v0_random\r\n  * gym_demon_attack_deterministic-v4_random\r\n  * gym_demon_attack_no_frameskip-v0_random\r\n  * gym_demon_attack_no_frameskip-v4_random\r\n  * gym_double_dunk-v0_random\r\n  * gym_double_dunk-v4_random\r\n  * gym_double_dunk_deterministic-v0_random\r\n  * gym_double_dunk_deterministic-v4_random\r\n  * gym_double_dunk_no_frameskip-v0_random\r\n  * gym_double_dunk_no_frameskip-v4_random\r\n  * gym_elevator_action-v0_random\r\n  * gym_elevator_action-v4_random\r\n  * gym_elevator_action_deterministic-v0_random\r\n  * gym_elevator_action_deterministic-v4_random\r\n  * gym_elevator_action_no_frameskip-v0_random\r\n  * gym_elevator_action_no_frameskip-v4_random\r\n  * gym_enduro-v0_random\r\n  * gym_enduro-v4_random\r\n  * gym_enduro_deterministic-v0_random\r\n  * gym_enduro_deterministic-v4_random\r\n  * gym_enduro_no_frameskip-v0_random\r\n  * gym_enduro_no_frameskip-v4_random\r\n  * gym_fishing_derby-v0_random\r\n  * gym_fishing_derby-v4_random\r\n  * gym_fishing_derby_deterministic-v0_random\r\n  * gym_fishing_derby_deterministic-v4_random\r\n  * gym_fishing_derby_no_frameskip-v0_random\r\n  * gym_fishing_derby_no_frameskip-v4_random\r\n  * gym_freeway-v0_random\r\n  * gym_freeway-v4_random\r\n  * gym_freeway_deterministic-v0_random\r\n  * gym_freeway_deterministic-v4_random\r\n  * gym_freeway_no_frameskip-v0_random\r\n  * gym_freeway_no_frameskip-v4_random\r\n  * gym_frostbite-v0_random\r\n  * gym_frostbite-v4_random\r\n  * gym_frostbite_deterministic-v0_random\r\n  * gym_frostbite_deterministic-v4_random\r\n  * gym_frostbite_no_frameskip-v0_random\r\n  * gym_frostbite_no_frameskip-v4_random\r\n  * gym_gopher-v0_random\r\n  * gym_gopher-v4_random\r\n  * gym_gopher_deterministic-v0_random\r\n  * gym_gopher_deterministic-v4_random\r\n  * gym_gopher_no_frameskip-v0_random\r\n  * gym_gopher_no_frameskip-v4_random\r\n  * gym_gravitar-v0_random\r\n  * gym_gravitar-v4_random\r\n  * gym_gravitar_deterministic-v0_random\r\n  * gym_gravitar_deterministic-v4_random\r\n  * gym_gravitar_no_frameskip-v0_random\r\n  * gym_gravitar_no_frameskip-v4_random\r\n  * gym_hero-v0_random\r\n  * gym_hero-v4_random\r\n  * gym_hero_deterministic-v0_random\r\n  * gym_hero_deterministic-v4_random\r\n  * gym_hero_no_frameskip-v0_random\r\n  * gym_hero_no_frameskip-v4_random\r\n  * gym_ice_hockey-v0_random\r\n  * gym_ice_hockey-v4_random\r\n  * gym_ice_hockey_deterministic-v0_random\r\n  * gym_ice_hockey_deterministic-v4_random\r\n  * gym_ice_hockey_no_frameskip-v0_random\r\n  * gym_ice_hockey_no_frameskip-v4_random\r\n  * gym_jamesbond-v0_random\r\n  * gym_jamesbond-v4_random\r\n  * gym_jamesbond_deterministic-v0_random\r\n  * gym_jamesbond_deterministic-v4_random\r\n  * gym_jamesbond_no_frameskip-v0_random\r\n  * gym_jamesbond_no_frameskip-v4_random\r\n  * gym_journey_escape-v0_random\r\n  * gym_journey_escape-v4_random\r\n  * gym_journey_escape_deterministic-v0_random\r\n  * gym_journey_escape_deterministic-v4_random\r\n  * gym_journey_escape_no_frameskip-v0_random\r\n  * gym_journey_escape_no_frameskip-v4_random\r\n  * gym_kangaroo-v0_random\r\n  * gym_kangaroo-v4_random\r\n  * gym_kangaroo_deterministic-v0_random\r\n  * gym_kangaroo_deterministic-v4_random\r\n  * gym_kangaroo_no_frameskip-v0_random\r\n  * gym_kangaroo_no_frameskip-v4_random\r\n  * gym_krull-v0_random\r\n  * gym_krull-v4_random\r\n  * gym_krull_deterministic-v0_random\r\n  * gym_krull_deterministic-v4_random\r\n  * gym_krull_no_frameskip-v0_random\r\n  * gym_krull_no_frameskip-v4_random\r\n  * gym_kung_fu_master-v0_random\r\n  * gym_kung_fu_master-v4_random\r\n  * gym_kung_fu_master_deterministic-v0_random\r\n  * gym_kung_fu_master_deterministic-v4_random\r\n  * gym_kung_fu_master_no_frameskip-v0_random\r\n  * gym_kung_fu_master_no_frameskip-v4_random\r\n  * gym_montezuma_revenge-v0_random\r\n  * gym_montezuma_revenge-v4_random\r\n  * gym_montezuma_revenge_deterministic-v0_random\r\n  * gym_montezuma_revenge_deterministic-v4_random\r\n  * gym_montezuma_revenge_no_frameskip-v0_random\r\n  * gym_montezuma_revenge_no_frameskip-v4_random\r\n  * gym_ms_pacman-v0_random\r\n  * gym_ms_pacman-v4_random\r\n  * gym_ms_pacman_deterministic-v0_random\r\n  * gym_ms_pacman_deterministic-v4_random\r\n  * gym_ms_pacman_no_frameskip-v0_random\r\n  * gym_ms_pacman_no_frameskip-v4_random\r\n  * gym_name_this_game-v0_random\r\n  * gym_name_this_game-v4_random\r\n  * gym_name_this_game_deterministic-v0_random\r\n  * gym_name_this_game_deterministic-v4_random\r\n  * gym_name_this_game_no_frameskip-v0_random\r\n  * gym_name_this_game_no_frameskip-v4_random\r\n  * gym_phoenix-v0_random\r\n  * gym_phoenix-v4_random\r\n  * gym_phoenix_deterministic-v0_random\r\n  * gym_phoenix_deterministic-v4_random\r\n  * gym_phoenix_no_frameskip-v0_random\r\n  * gym_phoenix_no_frameskip-v4_random\r\n  * gym_pitfall-v0_random\r\n  * gym_pitfall-v4_random\r\n  * gym_pitfall_deterministic-v0_random\r\n  * gym_pitfall_deterministic-v4_random\r\n  * gym_pitfall_no_frameskip-v0_random\r\n  * gym_pitfall_no_frameskip-v4_random\r\n  * gym_pong-v0_random\r\n  * gym_pong-v4_random\r\n  * gym_pong_deterministic-v0_random\r\n  * gym_pong_deterministic-v4_random\r\n  * gym_pong_no_frameskip-v0_random\r\n  * gym_pong_no_frameskip-v4_random\r\n  * gym_pooyan-v0_random\r\n  * gym_pooyan-v4_random\r\n  * gym_pooyan_deterministic-v0_random\r\n  * gym_pooyan_deterministic-v4_random\r\n  * gym_pooyan_no_frameskip-v0_random\r\n  * gym_pooyan_no_frameskip-v4_random\r\n  * gym_private_eye-v0_random\r\n  * gym_private_eye-v4_random\r\n  * gym_private_eye_deterministic-v0_random\r\n  * gym_private_eye_deterministic-v4_random\r\n  * gym_private_eye_no_frameskip-v0_random\r\n  * gym_private_eye_no_frameskip-v4_random\r\n  * gym_qbert-v0_random\r\n  * gym_qbert-v4_random\r\n  * gym_qbert_deterministic-v0_random\r\n  * gym_qbert_deterministic-v4_random\r\n  * gym_qbert_no_frameskip-v0_random\r\n  * gym_qbert_no_frameskip-v4_random\r\n  * gym_riverraid-v0_random\r\n  * gym_riverraid-v4_random\r\n  * gym_riverraid_deterministic-v0_random\r\n  * gym_riverraid_deterministic-v4_random\r\n  * gym_riverraid_no_frameskip-v0_random\r\n  * gym_riverraid_no_frameskip-v4_random\r\n  * gym_road_runner-v0_random\r\n  * gym_road_runner-v4_random\r\n  * gym_road_runner_deterministic-v0_random\r\n  * gym_road_runner_deterministic-v4_random\r\n  * gym_road_runner_no_frameskip-v0_random\r\n  * gym_road_runner_no_frameskip-v4_random\r\n  * gym_robotank-v0_random\r\n  * gym_robotank-v4_random\r\n  * gym_robotank_deterministic-v0_random\r\n  * gym_robotank_deterministic-v4_random\r\n  * gym_robotank_no_frameskip-v0_random\r\n  * gym_robotank_no_frameskip-v4_random\r\n  * gym_seaquest-v0_random\r\n  * gym_seaquest-v4_random\r\n  * gym_seaquest_deterministic-v0_random\r\n  * gym_seaquest_deterministic-v4_random\r\n  * gym_seaquest_no_frameskip-v0_random\r\n  * gym_seaquest_no_frameskip-v4_random\r\n  * gym_skiing-v0_random\r\n  * gym_skiing-v4_random\r\n  * gym_skiing_deterministic-v0_random\r\n  * gym_skiing_deterministic-v4_random\r\n  * gym_skiing_no_frameskip-v0_random\r\n  * gym_skiing_no_frameskip-v4_random\r\n  * gym_solaris-v0_random\r\n  * gym_solaris-v4_random\r\n  * gym_solaris_deterministic-v0_random\r\n  * gym_solaris_deterministic-v4_random\r\n  * gym_solaris_no_frameskip-v0_random\r\n  * gym_solaris_no_frameskip-v4_random\r\n  * gym_space_invaders-v0_random\r\n  * gym_space_invaders-v4_random\r\n  * gym_space_invaders_deterministic-v0_random\r\n  * gym_space_invaders_deterministic-v4_random\r\n  * gym_space_invaders_no_frameskip-v0_random\r\n  * gym_space_invaders_no_frameskip-v4_random\r\n  * gym_star_gunner-v0_random\r\n  * gym_star_gunner-v4_random\r\n  * gym_star_gunner_deterministic-v0_random\r\n  * gym_star_gunner_deterministic-v4_random\r\n  * gym_star_gunner_no_frameskip-v0_random\r\n  * gym_star_gunner_no_frameskip-v4_random\r\n  * gym_tennis-v0_random\r\n  * gym_tennis-v4_random\r\n  * gym_tennis_deterministic-v0_random\r\n  * gym_tennis_deterministic-v4_random\r\n  * gym_tennis_no_frameskip-v0_random\r\n  * gym_tennis_no_frameskip-v4_random\r\n  * gym_time_pilot-v0_random\r\n  * gym_time_pilot-v4_random\r\n  * gym_time_pilot_deterministic-v0_random\r\n  * gym_time_pilot_deterministic-v4_random\r\n  * gym_time_pilot_no_frameskip-v0_random\r\n  * gym_time_pilot_no_frameskip-v4_random\r\n  * gym_tutankham-v0_random\r\n  * gym_tutankham-v4_random\r\n  * gym_tutankham_deterministic-v0_random\r\n  * gym_tutankham_deterministic-v4_random\r\n  * gym_tutankham_no_frameskip-v0_random\r\n  * gym_tutankham_no_frameskip-v4_random\r\n  * gym_up_n_down-v0_random\r\n  * gym_up_n_down-v4_random\r\n  * gym_up_n_down_deterministic-v0_random\r\n  * gym_up_n_down_deterministic-v4_random\r\n  * gym_up_n_down_no_frameskip-v0_random\r\n  * gym_up_n_down_no_frameskip-v4_random\r\n  * gym_venture-v0_random\r\n  * gym_venture-v4_random\r\n  * gym_venture_deterministic-v0_random\r\n  * gym_venture_deterministic-v4_random\r\n  * gym_venture_no_frameskip-v0_random\r\n  * gym_venture_no_frameskip-v4_random\r\n  * gym_video_pinball-v0_random\r\n  * gym_video_pinball-v4_random\r\n  * gym_video_pinball_deterministic-v0_random\r\n  * gym_video_pinball_deterministic-v4_random\r\n  * gym_video_pinball_no_frameskip-v0_random\r\n  * gym_video_pinball_no_frameskip-v4_random\r\n  * gym_wizard_of_wor-v0_random\r\n  * gym_wizard_of_wor-v4_random\r\n  * gym_wizard_of_wor_deterministic-v0_random\r\n  * gym_wizard_of_wor_deterministic-v4_random\r\n  * gym_wizard_of_wor_no_frameskip-v0_random\r\n  * gym_wizard_of_wor_no_frameskip-v4_random\r\n  * gym_yars_revenge-v0_random\r\n  * gym_yars_revenge-v4_random\r\n  * gym_yars_revenge_deterministic-v0_random\r\n  * gym_yars_revenge_deterministic-v4_random\r\n  * gym_yars_revenge_no_frameskip-v0_random\r\n  * gym_yars_revenge_no_frameskip-v4_random\r\n  * gym_zaxxon-v0_random\r\n  * gym_zaxxon-v4_random\r\n  * gym_zaxxon_deterministic-v0_random\r\n  * gym_zaxxon_deterministic-v4_random\r\n  * gym_zaxxon_no_frameskip-v0_random\r\n  * gym_zaxxon_no_frameskip-v4_random\r\n  * image_celeba\r\n  * image_celeba32\r\n  * image_celeba64\r\n  * image_celeba_multi_resolution\r\n  * image_celebahq128\r\n  * image_celebahq128_dmol\r\n  * image_celebahq256\r\n  * image_celebahq256_dmol\r\n  * image_cifar10\r\n  * image_cifar100\r\n  * image_cifar100_plain\r\n  * image_cifar100_plain8\r\n  * image_cifar100_plain_gen\r\n  * image_cifar100_tune\r\n  * image_cifar10_plain\r\n  * image_cifar10_plain8\r\n  * image_cifar10_plain_gen\r\n  * image_cifar10_plain_gen_dmol\r\n  * image_cifar10_plain_random_shift\r\n  * image_cifar10_tune\r\n  * image_cifar20\r\n  * image_cifar20_plain\r\n  * image_cifar20_plain8\r\n  * image_cifar20_plain_gen\r\n  * image_cifar20_tune\r\n  * image_fashion_mnist\r\n  * image_fsns\r\n  * image_imagenet\r\n  * image_imagenet224\r\n  * image_imagenet32\r\n  * image_imagenet32_gen\r\n  * image_imagenet32_small\r\n  * image_imagenet64\r\n  * image_imagenet64_gen\r\n  * image_imagenet_multi_resolution_gen\r\n  * image_lsun_bedrooms\r\n  * image_mnist\r\n  * image_mnist_tune\r\n  * image_ms_coco_characters\r\n  * image_ms_coco_tokens32k\r\n  * image_text_ms_coco\r\n  * image_text_ms_coco_multi_resolution\r\n  * image_vqav2_rcnn_feature_tokens10k_labels3k\r\n  * image_vqav2_tokens10k_labels3k\r\n  * img2img_allen_brain\r\n  * img2img_allen_brain_dim16to16_paint1\r\n  * img2img_allen_brain_dim48to64\r\n  * img2img_allen_brain_dim8to32\r\n  * img2img_celeba\r\n  * img2img_celeba64\r\n  * img2img_cifar10\r\n  * img2img_cifar100\r\n  * img2img_imagenet\r\n  * lambada_lm\r\n  * lambada_lm_control\r\n  * lambada_rc\r\n  * lambada_rc_control\r\n  * languagemodel_de_en_fr_ro_wiki64k\r\n  * languagemodel_de_wiki32k\r\n  * languagemodel_de_wiki64k\r\n  * languagemodel_en_wiki32k\r\n  * languagemodel_en_wiki64k\r\n  * languagemodel_en_wiki64k_shorter\r\n  * languagemodel_en_wiki_lm_multi_nli_subwords\r\n  * languagemodel_en_wiki_lm_multi_nli_subwords64k\r\n  * languagemodel_en_wiki_lm_short_multi_nli_subwords64k\r\n  * languagemodel_en_wiki_lm_summarize_cnndm_subwords\r\n  * languagemodel_en_wiki_lm_summarize_cnndm_subwords64k\r\n  * languagemodel_fr_wiki32k\r\n  * languagemodel_fr_wiki64k\r\n  * languagemodel_lm1b32k\r\n  * languagemodel_lm1b32k_packed\r\n  * languagemodel_lm1b8k\r\n  * languagemodel_lm1b8k_packed\r\n  * languagemodel_lm1b_characters\r\n  * languagemodel_lm1b_characters_packed\r\n  * languagemodel_lm1b_multi_nli\r\n  * languagemodel_lm1b_multi_nli_subwords\r\n  * languagemodel_lm1b_sentiment_imdb\r\n  * languagemodel_multi_wiki_translate_fr\r\n  * languagemodel_ptb10k\r\n  * languagemodel_ptb_characters\r\n  * languagemodel_ro_wiki32k\r\n  * languagemodel_ro_wiki64k\r\n  * languagemodel_wiki_noref_v128k_l1k\r\n  * languagemodel_wiki_noref_v32k_l16k\r\n  * languagemodel_wiki_noref_v32k_l1k\r\n  * languagemodel_wiki_noref_v8k_l16k\r\n  * languagemodel_wiki_noref_v8k_l1k\r\n  * languagemodel_wiki_scramble_l128\r\n  * languagemodel_wiki_scramble_l1k\r\n  * languagemodel_wiki_xml_v8k_l1k\r\n  * languagemodel_wiki_xml_v8k_l4k\r\n  * languagemodel_wikitext103\r\n  * languagemodel_wikitext103_characters\r\n  * librispeech\r\n  * librispeech_clean\r\n  * librispeech_clean_small\r\n  * librispeech_noisy\r\n  * librispeech_train_full_test_clean\r\n  * msr_paraphrase_corpus\r\n  * msr_paraphrase_corpus_characters\r\n  * multi_nli\r\n  * multi_nli_characters\r\n  * multi_nli_shared_vocab\r\n  * multi_nli_wiki_lm_shared_vocab\r\n  * multi_nli_wiki_lm_shared_vocab64k\r\n  * ocr_test\r\n  * paraphrase_generation_ms_coco_problem1d\r\n  * paraphrase_generation_ms_coco_problem1d_characters\r\n  * paraphrase_generation_ms_coco_problem2d\r\n  * paraphrase_generation_ms_coco_problem2d_characters\r\n  * parsing_english_ptb16k\r\n  * parsing_english_ptb8k\r\n  * parsing_icelandic16k\r\n  * program_search_algolisp\r\n  * programming_desc2code_cpp\r\n  * programming_desc2code_py\r\n  * question_nli\r\n  * question_nli_characters\r\n  * quora_question_pairs\r\n  * quora_question_pairs_characters\r\n  * rte\r\n  * rte_characters\r\n  * sci_tail\r\n  * sci_tail_characters\r\n  * sci_tail_shared_vocab\r\n  * sentiment_imdb\r\n  * sentiment_imdb_characters\r\n  * sentiment_sst_binary\r\n  * sentiment_sst_binary_characters\r\n  * squad\r\n  * squad_concat\r\n  * squad_concat_positioned\r\n  * stanford_nli\r\n  * stanford_nli_characters\r\n  * stanford_nli_shared_vocab\r\n  * stanford_nli_wiki_lm_shared_vocab\r\n  * stanford_nli_wiki_lm_shared_vocab64k\r\n  * style_transfer_modern_to_shakespeare\r\n  * style_transfer_modern_to_shakespeare_characters\r\n  * style_transfer_shakespeare_to_modern\r\n  * style_transfer_shakespeare_to_modern_characters\r\n  * summarize_cnn_dailymail32k\r\n  * summarize_cnn_dailymail_wiki_lm_shared_vocab\r\n  * summarize_cnn_dailymail_wiki_lm_shared_vocab64k\r\n  * sva_language_modeling\r\n  * sva_number_prediction\r\n  * text2text_copyable_tokens\r\n  * text2text_tmpdir\r\n  * text2text_tmpdir_tokens\r\n  * timeseries_synthetic_data_series10_samples100k\r\n  * timeseries_toy_problem\r\n  * timeseries_toy_problem_no_inputs\r\n  * tiny_algo\r\n  * translate_encs_wmt32k\r\n  * translate_encs_wmt_characters\r\n  * translate_ende_wmt32k\r\n  * translate_ende_wmt32k_packed\r\n  * translate_ende_wmt8k\r\n  * translate_ende_wmt8k_packed\r\n  * translate_ende_wmt_bpe32k\r\n  * translate_ende_wmt_characters\r\n  * translate_enet_wmt32k\r\n  * translate_enet_wmt_characters\r\n  * translate_enfr_wmt32k\r\n  * translate_enfr_wmt32k_packed\r\n  * translate_enfr_wmt32k_with_backtranslate_en\r\n  * translate_enfr_wmt32k_with_backtranslate_fr\r\n  * translate_enfr_wmt8k\r\n  * translate_enfr_wmt_characters\r\n  * translate_enfr_wmt_multi64k\r\n  * translate_enfr_wmt_small32k\r\n  * translate_enfr_wmt_small8k\r\n  * translate_enfr_wmt_small_characters\r\n  * translate_enid_iwslt32k\r\n  * translate_enmk_setimes32k\r\n  * translate_enmk_setimes_characters\r\n  * translate_envi_iwslt32k\r\n  * translate_enzh_wmt32k\r\n  * translate_enzh_wmt8k\r\n  * video_bair_robot_pushing\r\n  * video_bair_robot_pushing_with_actions\r\n  * video_google_robot_pushing\r\n  * video_stochastic_shapes10k\r\n  * video_twentybn\r\n  * wiki_revision\r\n  * wiki_revision_packed1k\r\n  * wiki_revision_packed256\r\n  * wikisum_commoncrawl\r\n  * wikisum_commoncrawl_lead_section\r\n  * wikisum_web\r\n  * wikisum_web_lead_section\r\n  * winograd_nli\r\n  * winograd_nli_characters\r\n  * wsj_parsing\r\n```\r\n\r\nTraining the model using the custom problem worked just fine by running t2t-trainer with the t2t_usr_dir flag set to my directory with the custom problem, however I am unable to properly register the problem in the notebook.\r\n\r\nAm I doing something wrong? Or is this not supported in the AttentionVIsualizer?", "comments": []}, {"number": 28661, "title": "TF2.0.0-alpha bad performance (compared to TF1.13.1) with model.fit() for 1-layer tf.keras.Sequential model, Linear Regression", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Nope, this only concerns performance of model.fit for a tf.keras.Sequential model, comparing versions 2.0.0-alpha to 1.13.1.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tested on Windows 10, 64-bit (local machine), and on google colab with similar outcome\r\n- TensorFlow installed from (source or binary): pip install tensorflow / pip install tensorflow==2.0.0-alpha0\r\n- TensorFlow version (use command below): 2.0.0-alpha vs. 1.13.1\r\n- Python version: Python 3.7.3\r\n\r\n\r\n**Describe the current behavior**\r\nMuch higher (mse) loss with tensorflow 2.0.0-alpha, running 500 epochs of 'sgd' using model.fit() of a 1-layer tf.keras.Sequential model, implementing a simple Linear Regression (6 data points), when running the same code first with tensorflow 1.13.1 (performance well/as expected) and then with 2.0.0-alpha.\r\n\r\nResults running on google colabs shown below (CPU only), similar performance difference on my local machine, on which I used the specified Python version (Windows 10, 64-bit, i5-7200U CPU) - https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%202%20-%20Lesson%202%20-%20Notebook.ipynb#scrollTo=btF2CSFH2iEX\r\n\r\n1.13.1\r\n...\r\nEpoch 500/500\r\n6/6 [==============================] - 0s 238us/sample - loss: 2.0710e-05\r\n\r\n2.0.0-alpha\r\n...\r\nEpoch 500/500\r\n6/6 [==============================] - 0s 542us/sample - loss: 0.2409\r\n\r\nAs you can see, the (mse) loss is several orders of magnitudes worse for 2.0.0-alpha.\r\n\r\n\r\n**Describe the expected behavior**\r\nWith what I understand about tensorflow 2.0 is that this performance should be the same / similar for this code (see next item for the code).\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nhttps://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%202%20-%20Lesson%202%20-%20Notebook.ipynb#scrollTo=btF2CSFH2iEX\r\n\r\n( !pip install tensorflow==2.0.0-alpha0 )\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow import keras\r\ntf.version\r\nmodel = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\r\nmodel.compile(optimizer='sgd', loss='mean_squared_error')\r\nxs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\r\nys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\r\nmodel.fit(xs, ys, epochs=500)\r\nprint(model.predict([10.0]))\r\n\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@FunkyKingston Able to reproduce the issue with the provided code in 2.0.0-alpha vs. 1.13.1\r\n2.0.0-alpha vs. 1.13.1\r\n1.13.1\r\nEpoch 500/500\r\n6/6 [==============================] - 0s 488us/sample - loss: 5.4758e-05\r\n[[18.97841]]\r\n\r\n2.0.0-alpha\r\nEpoch 500/500\r\n6/6 [==============================] - 0s 501us/sample - loss: 0.6405\r\n[[16.559488]]", "Thanks for the report! I'm able to reproduce on `tensorflow==2.0.0-alpha`, but on `tf-nightly-2.0-preview` I see the expected behavior. So presumably the issue has been resolved since the 2.0 alpha was cut.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28661\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28661\">No</a>\n"]}, {"number": 28660, "title": "ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /home/xsx/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)", "body": "- centos7_DVD(The latest version)\r\n- python: 3.7.3\r\n- tensorflow:  1.13.1\r\n- anaconda: Anaconda3-2019.03-Linux-x86_64\r\n\r\nAfter the installation of tensorflow(cpu version) via pip command, I just used import tensorflow as tf which leads to the following error message\uff1b\r\n\r\n```\r\n### >>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"/home/xsx/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/xsx/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/xsx/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/xsx/.conda/envs/tensorflow/lib/python3.7/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/xsx/.conda/envs/tensorflow/lib/python3.7/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /home/xsx/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n```\r\n\r\nI try to update GLIBC_2.23,But the whole system crashed\uff1b\r\n\r\nThis problem has been bothering me for a week and my system has crashed three times.\r\n\r\n**Is it a version support issue for tensorflow?**", "comments": ["Today, I tried to downgrade the python version to 3.6.8, and all the problems were gone.\r\nSurprise\uff01\r\nHope to help you.", "Thanks! \r\nDowngrading python did the job for me too, out of curiosity what made you choose to downgrade to this specific version\r\n", "> Thanks!\r\n> Downgrading python did the job for me too, out of curiosity what made you choose to downgrade to this specific version\r\n\r\nThis is my first question on GITHUB.\r\nI am very happy to help you solve this problem, and congratulations on your successful installation.\r\nI forgot which blog I saw about the version, so I tried it and just tried it.", "Had same problem.  Super annoying.\r\n\r\nWhen I used:\r\n`$ conda create -n tf_cpu pip python=3.7`\r\n\r\nI got this error when trying to import tensorflow.\r\n\r\nBut when I did this instead:\r\n`$ conda create -n tf-cpu tensorflow`\r\n\r\nIt installed tensorflow version 1.13.1 with Python 3.7.3 and it works!", "Creating this new environment worked on mine too", "Hello, 3.7.3 did not work for me, I still got the same error, but with 3.6.8 it worked:\r\n\r\n    conda create -n tf-cpu tensorflow python=3.6.8", "A solution that worked for me in centos 7 with miniconda installed\r\nCreate an environment for tensorflow with the python version=3.6.8\r\n`conda create -n tfgpu tensorflow python=3.6.8\r\n`\r\nNow install the tensorflow with version 1.13.1\r\n`conda install tensorflow-gpu==1.13.1\r\n`\r\n\r\n\r\n", "If you have set up a conda enviroment like me but wanna install tensorflow1.14 (rather than tensorflow2) with CUDA10.1, you could try to install tensorflow with `conda install`. https://github.com/tensorflow/tensorflow/issues/26289#issuecomment-515494697", "It work for me. \r\n`conda create -n tf-cpu tensorflow==1.13.1`\r\ncan install python3.7.9 and tensorflow 1.13.1\r\n\r\nIt also work in tensorflow-gpu version.\r\nhttps://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/#install-tensorflow"]}]