[{"number": 31127, "title": "Update README.md", "body": "libtensorflow-core.a can only be compiled with r14b and below.\r\n\r\n", "comments": ["Is this exactly the same one as #31066?", "> Is this exactly the same one as #31066?\r\n\r\n@ilhamfp just saw #31066 , I had a discussion on Reddit regarding this change, maybe someone raised with the same wording.", "@mihaimaruseac can you please tell me where the build is failing as in logs I can see, there is a Time out while running test cases. "]}, {"number": 31126, "title": " fatal error C1083: Cannot open include file: 'ab sl/strings/string_view.h': No such file or directory", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (win10):\r\n- TensorFlow installed from (source):\r\n- TensorFlow version:1.14.\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):0.22\r\n- GCC/Compiler version (if compiling from source):cmake3.13.5+MSbuild\r\n\r\n\r\n\r\n**Describe the problem**\r\nI want to build .dll and .lib of TF_C++ API on WIN10.    an error :cannot find absl. And\uff0c I have no idea to fix it.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\ncmake .. -Thost=x64 -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=D:/swigwin-4.0.0/swig.exe -DPYTHON_EXECUTABLE=D:/Anaconda3/envs/tfcc36/python.exe -DPYTHON_LIBRARIES=D:/Anaconda3/envs/tfcc36/libs/python36.lib -Dtensorflow_BUILD_ALL_KERNELS=ON -Dtensorflow_BUILD_CC_EXAMPLE=ON -Dtensorflow_BUILD_CC_TESTS=OFF -Dtensorflow_BUILD_CONTRIB_KERNELS=ON -Dtensorflow_BUILD_MORE_PYTHON_TESTS=OFF -Dtensorflow_BUILD_PYTHON_BINDINGS=ON -Dtensorflow_BUILD_PYTHON_TESTS=OFF -Dtensorflow_BUILD_SHARED_LIB=ON -Dtensorflow_DISABLE_EIGEN_FORCEINLINE=OFF -Dtensorflow_ENABLE_GPU=OFF -Dtensorflow_ENABLE_GRPC_SUPPORT=OFF -Dtensorflow_ENABLE_HDFS_SUPPORT=OFF -Dtensorflow_ENABLE_MKLDNN_SUPPORT=OFF -Dtensorflow_ENABLE_MKL_SUPPORT=OFF -Dtensorflow_ENABLE_POSITION_INDEPENDENT_CODE=ON -Dtensorflow_ENABLE_SNAPPY_SUPPORT=ON -Dtensorflow_ENABLE_SSL_SUPPORT=OFF -Dtensorflow_OPTIMIZE_FOR_NATIVE_ARCH=ON -Dtensorflow_VERBOSE=OFF\r\nMSBuild /p:Configuration=Release ALL_BUILD.vcxproj\r\n**Any other info / logs**\r\n\r\n\u201cD:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\ALL_BUILD.vcxproj\u201d(\u9ed8\u8ba4\u76ee\u6807) (1) ->\r\n\u201cD:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\_beam_search_ops.vcxproj\u201d(\u9ed8\u8ba4\u76ee\u6807) (2) ->\r\n\u201cD:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.vcxproj\u201d(\u9ed8\u8ba4\u76ee\u6807) (3) ->\r\n\u201cD:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal_static.vcxproj\u201d(\u9ed8\u8ba4\u76ee\u6807) (4) ->\r\n\u201cD:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_c.vcxproj\u201d(\u9ed8\u8ba4\u76ee\u6807) (5) ->\r\n\u201cD:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_cc_framework.vcxproj\u201d(\u9ed8\u8ba4\u76ee\u6807) (6) ->\r\n\u201cD:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_framework.vcxproj\u201d(\u9ed8\u8ba4\u76ee\u6807) (7) ->\r\n\u201cD:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\proto_text.vcxproj\u201d(\u9ed8\u8ba4\u76ee\u6807) (8) ->\r\n\u201cD:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj\u201d(\u9ed8\u8ba4\u76ee\u6807) (9) ->\r\n(ClCompile \u76ee\u6807) ->\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\core\\coding.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\gif\\gif_io.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\core\\status.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\core\\threadpool.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\hash\\crc32c.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\db\\sqlite.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/gtl/array_slice.h(19): fatal error C1083: Cannot open include file: 'abs\r\nl/types/span.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\lib\\histogra\r\nm\\histogram.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\hash\\hash.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\block_builder.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\path.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\inputbuffer.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\block.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\buffered_inputstream.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\format.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\iterator.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\inputstream_interface.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\record_writer.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\random_inputstream.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\record_reader.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\snappy\\snappy_inputbuffer.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\snappy\\snappy_outputbuffer.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\table.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\table_builder.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\two_level_iterator.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\zlib_inputstream.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\jpeg\\jpeg_mem.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/gtl/array_slice.h(19): fatal error C1083: Cannot open include file: 'abs\r\nl/types/span.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\lib\\random\\d\r\nistribution_sampler.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\io\\zlib_outputbuffer.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\lib\\png\\png_io.cc(27): fatal error C1083: Cannot open include file: 'absl/ba\r\nse/casts.h': No such file or directory [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/gtl/array_slice.h(19): fatal error C1083: Cannot open include file: 'abs\r\nl/types/span.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\lib\\random\\r\r\nandom_distributions.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\strings\\numbers.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\strings\\ordered_code.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/strings/proto_text_util.h(19): fatal error C1083: Cannot open include fi\r\nle: 'absl/strings/str_cat.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\r\n\\lib\\strings\\proto_text_util.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\monitoring\\collection_registry.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\monitoring\\sampler.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\strings\\scanner.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/strings/str_util.h(22): fatal error C1083: Cannot open include file: 'ab\r\nsl/base/macros.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\lib\\string\r\ns\\str_util.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\strings\\base64.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\li\r\nb\\strings\\strcat.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\lib\\wav\\wav_io.cc(22): fatal error C1083: Cannot open include file: 'absl/ba\r\nse/casts.h': No such file or directory [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\fr\r\namework\\resource_handle.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\lib\\strings\\proto_serialization.cc(19): fatal error C1083: Cannot open inclu\r\nde file: 'absl/memory/memory.h': No such file or directory [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_\r\ncore_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\pl\r\natform\\default\\human_readable_json.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\pl\r\natform\\file_system.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\pl\r\natform\\file_system_helper.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\pl\r\natform\\platform_strings.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\pl\r\natform\\tensor_coding.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n  D:\\tfVS\\tensorflow-r1.14\\tensorflow/core/lib/core/stringpiece.h(29): fatal error C1083: Cannot open include file: 'ab\r\nsl/strings/string_view.h': No such file or directory (compiling source file D:\\tfVS\\tensorflow-r1.14\\tensorflow\\core\\pl\r\natform\\windows\\windows_file_system.cc) [D:\\tfVS\\tensorflow-r1.14\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]\r\n\r\n    105 \u4e2a\u8b66\u544a\r\n    48 \u4e2a\u9519\u8bef\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@penghao1990,\r\nThe TensorFlow team does not officially support cmake, sorry. Please try out building from [source with Bazel](https://www.tensorflow.org/install/source_windows). Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 31125, "title": "tf_core_lib", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 31124, "title": "Error 'int8x8_t' does not name a type when building with bazel", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ARMv8 aarch64 CentOS Linux release 7.6.1810\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 1.14\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): gcc4.8.5\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nHello,\r\nI encountered the following error while trying to build tensorflow on an ARM machine:\r\n\r\n```\r\n/<install folder>/tensorflow/lite/kernels/BUILD:374:1: C++ compilation of rule '//tensorflow/lite/kernels:builtin_op_kernels' failed (Exit 1)\r\ncc1plus: warning: command line option '-std=gnu99' is valid for C/ObjC but not for C++ [enabled by default]\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:22:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:22,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:29:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h: In static member function 'static void tflite::optimized_ops::depthwise_conv::WorkspacePrefetchWrite<(tflite::DepthwiseConvImplementation)3>::Run(int8, int, int8*)':\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5775:11: error: 'int8x8_t' does not name a type\r\n     const int8x8_t fill_data_vec_int8 = vdup_n_s8(fill_data);\r\n           ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5776:11: error: 'uint32x2_t' does not name a type\r\n     const uint32x2_t fill_data_vec = vreinterpret_u32_s8(fill_data_vec_int8);\r\n           ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5780:55: error: 'fill_data_vec' was not declared in this scope\r\n       vst1_lane_u32(reinterpret_cast<uint32_t*>(ptr), fill_data_vec, 0);\r\n                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5780:71: error: 'vst1_lane_u32' was not declared in this scope\r\n       vst1_lane_u32(reinterpret_cast<uint32_t*>(ptr), fill_data_vec, 0);\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5783:19: error: 'fill_data_vec' was not declared in this scope\r\n                   fill_data_vec, 0);\r\n                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5783:35: error: 'vst1_lane_u32' was not declared in this scope\r\n                   fill_data_vec, 0);\r\n                                   ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 26.504s, Critical Path: 10.13s\r\nINFO: 23 processes: 23 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1. Add the following code to the top of `<install folder>/tensorflow/WORKSPACE`, as suggested [here](https://github.com/tensorflow/tensorflow/issues/28824#issuecomment-493675905):\r\n\r\n```\r\nhttp_archive(\r\n    name = \"build_bazel_rules_nodejs\",\r\n    # Replace with a real SHA256 checksum\r\n    sha256 = \"{SHA256}\"\r\n    # Replace with a real commit SHA\r\n    strip_prefix = \"rules_nodejs-{HEAD}\",\r\n    urls = [\"https://github.com/bazelbuild/rules_nodejs/archive/{HEAD}.tar.gz\"],\r\n)\r\n```\r\n2. Run `./configure` with all option set to n\r\n3. Build tensorflow `bazel build --host_copt=\"-std=gnu99\" --copt=\"-std=gnu99\" --conlyopt=\"-std=gnu99\" //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nSee above\r\n\r\n\r\nAny help would be appreciated.\r\n", "comments": ["@hsinpaohuang, Just to verify, did you install tensorflow lite following the instructions mentioned in the [Tensorflow](https://www.tensorflow.org/lite/guide/build_arm64) website on ARM. Thanks! ", "> @hsinpaohuang, Just to verify, did you install tensorflow lite following the instructions mentioned in the [Tensorflow](https://www.tensorflow.org/lite/guide/build_arm64) website on ARM. Thanks!\r\n\r\n@gadagashwini, I followed the instructions on how to build tensorflow (not lite) from source from the [official website](https://www.tensorflow.org/install/source).", "@hsinpaohuang The [official website](https://www.tensorflow.org/install/source_windows) provides the instructions to build Tensorflow on Linux or MacOS platform. Looks like you are building Tensorflow on ARM. Please let me know if my understanding is bad. Thanks!", "> @hsinpaohuang The [official website](https://www.tensorflow.org/install/source_windows) provides the instructions to build Tensorflow on Linux or MacOS platform. Looks like you are building Tensorflow on ARM. Please let me know if my understanding is bad. Thanks!\r\n\r\n@gadagashwini You're right. I found a precompiled .whl for aarch64 [here](https://github.com/lhelontra/tensorflow-on-arm) and it worked. Thank you. Closing this issue.", "Are you satisfied with the resolution of your issue?<br> [Yes](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31124)<br> [No](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31124)\r\n"]}, {"number": 31123, "title": "how can I feed multi inputs with tf2.0", "body": "how can i feed value to actions in loss functions  error  like this\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,4]\r\n```\r\n\r\nmy code here\r\n```\r\nfrom tensorflow import keras\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nclass DQN:\r\n    def __init__(self, actions, state_shape):\r\n        self.actions = actions\r\n        self.state_shape = state_shape\r\n        self.create_model()\r\n\r\n    def loss_func(self, actions):\r\n        def nested_func(label, logits):\r\n            print(label, logits)\r\n            return tf.losses.mean_squared_error(tf.reduce_sum(tf.multiply(actions, logits), axis=-1), label)\r\n\r\n        return nested_func\r\n\r\n    def create_model(self):\r\n        def loss_func(actions):\r\n            def nested_func(label, logits):\r\n                return tf.losses.mean_squared_error(tf.reduce_sum(tf.multiply(actions, logits), axis=-1),\r\n                                                    tf.reduce_sum(label, axis=-1))\r\n\r\n            return nested_func\r\n\r\n        actions = keras.Input((self.actions))\r\n        self.model = keras.models.Sequential([\r\n            keras.layers.Conv2D(filters=32, kernel_size=8, strides=4, padding='same', activation='relu'),\r\n            keras.layers.MaxPool2D(pool_size=(2, 2), strides=1, padding='same'),\r\n            keras.layers.Conv2D(filters=64, kernel_size=4, strides=2, padding='same', activation='relu'),\r\n            keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\r\n            keras.layers.Flatten(),\r\n            keras.layers.Dense(512, activation='relu'),\r\n            keras.layers.Dense(self.actions, activation=None),\r\n        ])\r\n        self.model.compile(optimizer=tf.train.AdamOptimizer(1e-3), loss=loss_func(actions))\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n    model = DQN(4, (80, 80, 4))\r\n    states = np.random.rand(100, 80, 80, 4)\r\n    actions = np.random.randint(0, 4, (100, 4))\r\n    label = np.random.randint(0, 4, (100, 4))\r\n    model.model.fit(states, label)\r\n```\r\n\r\n", "comments": ["Hi,\r\n\r\nThe issue here is that you define an input tensor for actions, but do not make it part of your model's inputs. A work-around to your problem is to define a `tf.keras.Model` instance with both a `states` input tensor and the `actions` one, whose output will be the processing of `states` by the sequential stack you defined. Then, your built model will expect to be called on lists of two elements, one to be fed as states, the other as actions.\r\n\r\nThe updated code using this solution:\r\n```python\r\nfrom tensorflow import keras\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nclass DQN:\r\n    def __init__(self, actions, state_shape):\r\n        self.actions = actions\r\n        self.state_shape = state_shape\r\n        self.create_model()\r\n\r\n    def loss_func(self, actions):\r\n        def nested_func(label, logits):\r\n            print(label, logits)\r\n            return tf.losses.mean_squared_error(tf.reduce_sum(tf.multiply(actions, logits), axis=-1), label)\r\n\r\n        return nested_func\r\n\r\n    def create_model(self):\r\n        def loss_func(actions):\r\n            def nested_func(label, logits):\r\n                return tf.losses.mean_squared_error(tf.reduce_sum(tf.multiply(actions, logits), axis=-1),\r\n                                                    tf.reduce_sum(label, axis=-1))\r\n\r\n            return nested_func\r\n\r\n        # Define both Input tensors.\r\n        states = keras.Input(self.state_shape)\r\n        actions = keras.Input((self.actions))\r\n        # Define the sequential stack of layers to process states.\r\n        model = keras.models.Sequential([\r\n            keras.layers.Conv2D(filters=32, kernel_size=8, strides=4, padding='same', activation='relu'),\r\n            keras.layers.MaxPool2D(pool_size=(2, 2), strides=1, padding='same'),\r\n            keras.layers.Conv2D(filters=64, kernel_size=4, strides=2, padding='same', activation='relu'),\r\n            keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\r\n            keras.layers.Flatten(),\r\n            keras.layers.Dense(512, activation='relu'),\r\n            keras.layers.Dense(self.actions, activation=None),\r\n        ])\r\n        # Define a model that goes from (states, actions) to sequential(states).\r\n        # Although at this stage actions is not used, it is thus feedable.\r\n        self.model = keras.Model([states, actions], model(states))\r\n        # Compile the model (unchanged code) ; the fed actions will be used in practice.\r\n        self.model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=loss_func(actions))\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n    model = DQN(4, (80, 80, 4))\r\n    states = np.random.rand(100, 80, 80, 4)\r\n    actions = np.random.randint(0, 4, (100, 4))\r\n    label = np.random.randint(0, 4, (100, 4))\r\n    # feed both states and actions to the model\r\n    model.model.fit([states, actions], label)\r\n```\r\n\r\nIt is unrelated, but I changed `tf.train.AdamOptimizer` to `tf.keras.optimizers.Adam` as the former is removed in version 2.0.", "@LieJiang Did @pandrey-fr solution answer your question?", "@pandrey-fr   but when i use model   to predict , i must pass useless actions  like this :\r\n```\r\nmodel.model.predict([states,np.empty([100,4])])\r\n```", "@LieJang I am unfamiliar with the model you are trying to set up; are `actions` always empty/random? If that is the case, you could replace the inputs mechanism with an automated Tensor generation within the model..."]}, {"number": 31122, "title": "Corrected typo in evaluate() method", "body": "Instead of \"Do not specify the batch_size IS your data is\", it should be \"Do not specify the batch_size IF your data is", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F31122) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 31121, "title": "How to use Tensorboard logging in tf2.0 step loop of the @tf.function", "body": "Hello,\r\n\r\nI have been trying to figure out how to log to tensorboard from the gradienttape loop function\r\n\r\nthanks,\r\ntejavoo", "comments": ["I had the same issue, whats the solution to this ?\r\n"]}, {"number": 31120, "title": "The aip of instance normaalization", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):tf2.0\r\n- Are you willing to contribute it (Yes/No):yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\ntensorflow/python/keras/layers/normalization.py\r\n**Will this change the current api? How?**\r\n\u201dtensorflow/python/keras/layers/normalization.py\u201c add a instance normalizatiom layer class\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["@zhaoyingjun Normalization.py already exists in ['tensorflow/python/keras/layers/'](https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/keras/layers).Can you please be specific what feature request are you talking about? Thanks!", "there is no Instance Normalization in Normalization.py \uff0c\bmy request is \"add a instance normalizatiom layer class in Normalization.py \"", "@zhaoyingjun Hi, `InstanceNormalization` has appeared in [tensorflow/addons](https://github.com/tensorflow/addons).\r\nhttps://github.com/tensorflow/addons/blob/master/tensorflow_addons/layers/normalizations.py#L277", "OK\uff0cthanks"]}, {"number": 31119, "title": "How to create a tensorflow lite plugin for Unity", "body": "I'm trying to use tensorflow lite in unity.\r\nI need plugins to run my project.\r\nEspecially a **plugin for IOS** [tensorflowlite_c]\r\n\r\nThank you!", "comments": ["@Deepak-HpyAda ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Hi. Any updates on this? Thx", "Hi. Is it possible to build the tensorflowlite_c.a static library for use in iOS? The readme only listed the bazel command for Android and linux but not for iOS.", "Hi, a simple way is importing pre-build `TensorFlowLiteC.framework` from CocoaPods\r\n\r\nJust make the blank Xcode project with Podfile and copy it.\r\n```\r\npod 'TensorFlowLiteObjC', '0.0.1-nightly'\r\n```\r\n\r\nand need to modify `[DllImport (TensorFlowLibrary)]` to  `[DllImport (__Internal)]`\r\nof use my PR #34450"]}, {"number": 31118, "title": "Tensorflowlite 1.14: bazel windows build is broken", "body": "Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template\r\n\r\nSystem information\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10\r\n\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nn/a\r\n\r\nTensorFlow installed from (source or binary):\r\nBuild from source\r\n\r\nTensorFlow version:\r\nr1.14, 456fbc0e498e3d10604973de9f46ca48d62267cc\r\n\r\nPython version:\r\n2.7.15\r\n\r\nInstalled using virtualenv? pip? conda?:\r\nn/a\r\n\r\nBazel version (if compiling from source):\r\n0.21.0\r\n\r\nGCC/Compiler version (if compiling from source):\r\nMSVC 2017\r\n\r\nCUDA/cuDNN version:\r\nn/a\r\n\r\nGPU model and memory:\r\nn/a\r\n\r\nDescribe the problem\r\nWindows build of tensorflow lite fails.\r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem\r\n\r\n```\r\n$ bazel --output_user_root=D:\\test\\tensorflow_1.14.windows build  --jobs 1 -c opt --cxxopt=--std=c++11 //tensorflow/lite:libtensorflowlite.so\r\n\r\nINFO: Repository 'flatbuffers' used the following cache hits instead of downloading the corresponding file.              \r\n* Hash '3f4a286642094f45b1b77228656fbd7ea123964f19502f9ecfd29933fd23a50b' for http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.11.0.tar.gz                                                                                \r\nIf the definition of 'flatbuffers' was updated, verify that the hashes were also updated.                               \r\nERROR: An error occurred during the fetch of repository 'flatbuffers':                                                     \r\njava.io.IOException: Could not create symlink from \r\nD:/test/tensorflow/third_party/flatbuffers/build_defs.bzl to \r\nD:/test/tensorflow_1.14.windows/s5ozolul/external/flatbuffers/build_defs.bzl: \r\nD:/test/tensorflow_1.14.windows/s5ozolul/external/flatbuffers/build_defs.bzl (File exists)                                                                             \r\nERROR: D:/test/tensorflow/tensorflow/lite/BUILD:149:1: //tensorflow/lite:framework depends on \r\n//tensorflow/lite/schema:schema_fbs in repository @ which failed to fetch. no such package \r\n'@flatbuffers//': java.io.IOException: Could not create symlink from \r\nD:/test/tensorflow/third_party/flatbuffers/build_defs.bzl to \r\nD:/test/tensorflow_1.14.windows/s5ozolul/external/flatbuffers/build_defs.bzl: \r\nD:/test/tensorflow_1.14.windows/s5ozolul/external/flatbuffers/build_defs.bzl (File exists)                                                                                                                     \r\nERROR: Analysis of target '//tensorflow/lite:libtensorflowlite.so' failed; build aborted: no such package \r\n'@flatbuffers//': java.io.IOException: Could not create symlink from \r\nD:/test/tensorflow/third_party/flatbuffers/build_defs.bzl to \r\nD:/test/tensorflow_1.14.windows/s5ozolul/external/flatbuffers/build_defs.bzl: \r\nD:/test/tensorflow_1.14.windows/s5ozolul/external/flatbuffers/build_defs.bzl (File exists)                                                                            \r\nINFO: Elapsed time: 96.770s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (22 packages loaded, 98 targets configured)                                    \r\ncurrently loading: tensorflow/lite/schema\r\n```", "comments": ["@ElderOrb ,\r\nCan you please follow the instructions mentioned in [this link](https://github.com/bazelbuild/bazel/issues/4148#issuecomment-469237002) and let us know if it helps.", "I've tried that but it didn't help. Please note that I'm not doing windows => android cross-compilation. What I'm trying to get is windows build (dll or whatever). \r\n\r\nAlso, not sure why, maybe due to the latest changes in 1.14 branch now I see this error: \r\n\r\n\"D:\\Test\\tensorflow_1.14>bazel-0.20.0-windows-x86_64.exe --output_user_root D:\\test\\tensorflow_1.14-windows build --jobs 1 -c opt --cxxopt --std                                                                    WARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:                                                                   d:\\test\\tensorflow_1.14/.bazelrc                                                                                                                                                                                   Extracting Bazel installation...                                                                                                                                                                                   Starting local Bazel server and connecting to it...                                                                                                                                                                INFO: Invocation ID: 3928ae41-cf2a-4404-8fff-f3faa653acfd                                                                                                                                                          ERROR: D:/test/tensorflow_1.14-windows/sricgeud/external/io_bazel_rules_closure/closure/protobuf/closure_proto_library.bzl:66:21: name 'ProtoInfo' is not defined (did you mean 'protos'?)                         ERROR: error loading package '': in D:/test/tensorflow_1.14-windows/sricgeud/external/io_bazel_rules_closure/closure/defs.bzl: Extension 'closure/protobuf/closure_proto_library.bzl' has errors                   ERROR: error loading package '': in D:/test/tensorflow_1.14-windows/sricgeud/external/io_bazel_rules_closure/closure/defs.bzl: Extension 'closure/protobuf/closure_proto_library.bzl' has errors\r\nINFO: Elapsed time: 10.338s                                                                                                                                                                                        INFO: 0 processes.                                                                                                                                                                                                 FAILED: Build did NOT complete successfully (0 packages loaded)\r\n\"\r\n\r\nIs there any working guide on bazel build for tensorflowlite 1.14 for windows? ", "@ElderOrb Have you implemented. / configure yet?", "No, I stopped wasting time on this and still hope the issue will be fixed. ", "I think you're using a bazel that is too old", "@ElderOrb I mean to execute the \u201c. / configure\u201d instruction first and then continue compiling\uff0cand I didn't report this mistake after I implemented it.", "@mihaimaruseac \r\nwhich bazel version is recommended to use with windows?\r\n\r\n@Huangswust182\r\nOkay, I'll try with ./configure then (although on linux it builds with no need in configuring)", "`./configure` set-ups several bazel config options as well as checking out that you have a bazel version that is in the range of those we tested with.\r\n\r\nSee https://www.tensorflow.org/install/source_windows#tested_build_configurations for the exact configurations we have used when building.", "@mihaimaruseac I followed link and found this:\r\n\r\n> Install Bazel 0.24.1\r\n\r\n... and then after couple lines: \r\n\r\n> Ensure you install Bazel 0.23.0 or lower.\r\n\r\nSo what is the right version?", "Anyway, just tried with 0.24.1 and 'configure.py': \r\n\r\nD:\\Test\\tf_1.14>bazel --output_user_root=../tf_1.14-windows-build build --jobs 1 -c opt --cxxopt=--std=c++11 //tensorflow/lite:libtensorflowlite.so\r\n\r\n`                                                                Extracting Bazel installation...                                                                                                                                                                                   Starting local Bazel server and connecting to it...                                                                                                                                                                INFO: Repository 'flatbuffers' used the following cache hits instead of downloading the corresponding file.                                                                                                         * Hash '3f4a286642094f45b1b77228656fbd7ea123964f19502f9ecfd29933fd23a50b' for http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.11.0.tar.gz                                                   If the definition of 'flatbuffers' was updated, verify that the hashes were also updated.                                                                                                                          ERROR: D:/test/tf_1.14/tensorflow/lite/kernels/BUILD:286:1: no such package '@flatbuffers//': java.io.IOException: Could not create symlink from D:/test/tf_1.14/third_party/flatbuffers/build_defs.bzl to D:/test/tf_1.14-windows-build/dutqtkj7/external/flatbuffers/build_defs.bzl: D:/test/tf_1.14-windows-build/dutqtkj7/external/flatbuffers/build_defs.bzl (File exists) and referenced by '//tensorflow/lite/kernels:builtin_op_kernels'                                                                                                                                                                                                         ERROR: Analysis of target '//tensorflow/lite:libtensorflowlite.so' failed; build aborted: no such package '@flatbuffers//': java.io.IOException: Could not create symlink from D:/test/tf_1.14/third_party/flatbuffers/build_defs.bzl to D:/test/tf_1.14-windows-build/dutqtkj7/external/flatbuffers/build_defs.bzl: D:/test/tf_1.14-windows-build/dutqtkj7/external/flatbuffers/build_defs.bzl (File exists)                         INFO: Elapsed time: 43.454s                                                                                                                                                                                        INFO: 0 processes.                                                                                                                                                                                                 FAILED: Build did NOT complete successfully (18 packages loaded, 81 targets configured)                                                                                                                                currently loading: tensorflow/lite/schema`", "Also tried with bazel 0.25.2 (latest supported based on configure.py output) and got this: \r\n\r\nD:\\Test\\tf_1.14>configure.py\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.25.2 installed.\r\nPlease specify the location of python. [Default is C:\\Python37\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Python37\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Python37\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]:\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=noignite       # Disable Apache Ignite support.\r\n        --config=nokafka        # Disable Apache Kafka support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\n\r\nD:\\Test\\tf_1.14>bazel --output_user_root=../tf_1.14-windows-build build --jobs 1 -c opt --cxxopt=--std=c++11 //tensorflow/lite:libtensorflowlite.so\r\nExtracting Bazel installation...\r\nStarting local Bazel server and connecting to it...\r\nINFO: An error occurred during the fetch of repository 'local_config_cc'\r\nINFO: Call stack for the definition of repository 'local_config_cc':\r\n - D:/test/tf_1.14-windows-build/dutqtkj7/external/bazel_tools/tools/cpp/cc_configure.bzl:97:5\r\n - /DEFAULT.WORKSPACE.SUFFIX:246:1\r\nERROR: no such package '@local_config_cc//': Traceback (most recent call last):\r\n        File \"D:/test/tf_1.14-windows-build/dutqtkj7/external/bazel_tools/tools/cpp/cc_configure.bzl\", line 52\r\n                configure_windows_toolchain(repository_ctx)\r\n        File \"D:/test/tf_1.14-windows-build/dutqtkj7/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 349, in configure_windows_toolchain\r\n                _find_missing_vc_tools(repository_ctx, vc_path)\r\n        File \"D:/test/tf_1.14-windows-build/dutqtkj7/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 248, in _find_missing_vc_tools\r\n                _find_vcvarsall_bat_script(repository_ctx, vc_path)\r\n        File \"D:/test/tf_1.14-windows-build/dutqtkj7/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 191, in _find_vcvarsall_bat_script\r\n                repository_ctx.path(vcvarsall).exists\r\nIllegal char <*> at index 64: D:/test/tf_1.14-windows-build/dutqtkj7/external/local_config_cc/**********************************************************************\r\n** Visual Studio 2017 Developer Command Prompt v15.9.12\r\n** Copyright (c) 2017 Microsoft Corporation\r\n**********************************************************************\r\n[ERROR:typescript.bat] TypeScript was not added to PATH since a valid installation was not found\r\n[ERROR:VsDevCmd.bat] *** VsDevCmd.bat encountered errors. Environment may be incomplete and/or incorrect. ***\r\n[ERROR:VsDevCmd.bat] In an uninitialized command prompt, please 'set VSCMD_DEBUG=[value]' and then re-run\r\n[ERROR:VsDevCmd.bat] vsdevcmd.bat [args] for additional details.\r\n[ERROR:VsDevCmd.bat] Where [value] is:\r\n[ERROR:VsDevCmd.bat]    1 : basic debug logging\r\n[ERROR:VsDevCmd.bat]    2 : detailed debug logging\r\n[ERROR:VsDevCmd.bat]    3 : trace level logging. Redirection of output to a file when using this level is recommended.\r\n[ERROR:VsDevCmd.bat] Example: set VSCMD_DEBUG=3\r\n[ERROR:VsDevCmd.bat]          vsdevcmd.bat > vsdevcmd.trace.txt 2>&1\r\nC:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Auxiliary/Build/VCVARSALL.BAT\r\nERROR: Analysis of target '//tensorflow/lite:libtensorflowlite.so' failed; build aborted: no such package '@local_config_cc//': Traceback (most recent call last):\r\n        File \"D:/test/tf_1.14-windows-build/dutqtkj7/external/bazel_tools/tools/cpp/cc_configure.bzl\", line 52\r\n                configure_windows_toolchain(repository_ctx)\r\n        File \"D:/test/tf_1.14-windows-build/dutqtkj7/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 349, in configure_windows_toolchain\r\n                _find_missing_vc_tools(repository_ctx, vc_path)\r\n        File \"D:/test/tf_1.14-windows-build/dutqtkj7/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 248, in _find_missing_vc_tools\r\n                _find_vcvarsall_bat_script(repository_ctx, vc_path)\r\n        File \"D:/test/tf_1.14-windows-build/dutqtkj7/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 191, in _find_vcvarsall_bat_script\r\n                repository_ctx.path(vcvarsall).exists\r\nIllegal char <*> at index 64: D:/test/tf_1.14-windows-build/dutqtkj7/external/local_config_cc/**********************************************************************\r\n** Visual Studio 2017 Developer Command Prompt v15.9.12\r\n** Copyright (c) 2017 Microsoft Corporation\r\n**********************************************************************\r\n[ERROR:typescript.bat] TypeScript was not added to PATH since a valid installation was not found\r\n[ERROR:VsDevCmd.bat] *** VsDevCmd.bat encountered errors. Environment may be incomplete and/or incorrect. ***\r\n[ERROR:VsDevCmd.bat] In an uninitialized command prompt, please 'set VSCMD_DEBUG=[value]' and then re-run\r\n[ERROR:VsDevCmd.bat] vsdevcmd.bat [args] for additional details.\r\n[ERROR:VsDevCmd.bat] Where [value] is:\r\n[ERROR:VsDevCmd.bat]    1 : basic debug logging\r\n[ERROR:VsDevCmd.bat]    2 : detailed debug logging\r\n[ERROR:VsDevCmd.bat]    3 : trace level logging. Redirection of output to a file when using this level is recommended.\r\n[ERROR:VsDevCmd.bat] Example: set VSCMD_DEBUG=3\r\n[ERROR:VsDevCmd.bat]          vsdevcmd.bat > vsdevcmd.trace.txt 2>&1\r\nC:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Auxiliary/Build/VCVARSALL.BAT\r\nINFO: Elapsed time: 37.323s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (7 packages loaded, 25 targets configured)", "any progress here?", "Can you try with master instead of 1.14?\r\n\r\nSeems 1.14 is badly broken", "On the latest master (c022a5870282bf7b7771bc1418671e5d9c1f6fcc) I see this:\r\n\r\n\r\n```\r\n**********************************************************************\r\n** Visual Studio 2017 Developer Command Prompt v15.9.12\r\n** Copyright (c) 2017 Microsoft Corporation\r\n**********************************************************************\r\n[vcvarsall.bat] Environment initialized for: 'x64'\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community>D:\r\n\r\nD:\\>cd test\\tensorflow\r\n\r\nD:\\test\\tensorflow>python configure.py\r\nCannot find bazel. Please install bazel.\r\n\r\nD:\\test\\tensorflow>bazel version\r\nStarting local Bazel server and connecting to it...\r\nBuild label: 0.24.1\r\nBuild target: bazel-out/x64_windows-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Tue Apr 2 16:30:30 2019 (1554222630)\r\nBuild timestamp: 1554222630\r\nBuild timestamp as int: 1554222630\r\n\r\nD:\\test\\tensorflow>python configure.py\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.24.1 installed.\r\nPlease specify the location of python. [Default is C:\\Python27\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Python27\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Python27\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]:\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=noignite       # Disable Apache Ignite support.\r\n        --config=nokafka        # Disable Apache Kafka support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\n\r\nD:\\test\\tensorflow>bazel --output_user_root=D:\\test\\tensorflow.windows build --jobs 1 -c opt --cxxopt=--std=c++11 //tensorflow/lite:libtensorflowlite.so\r\nExtracting Bazel installation...\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=C:/Python27/python.exe\r\nINFO: Reading rc options for 'build' from d:\\test\\tensorflow\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include\r\nINFO: Reading rc options for 'build' from d:\\test\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=C:/Python27/python.exe --action_env PYTHON_LIB_PATH=C:/Python27/lib/site-packages --python_path=C:/Python27/python.exe --config monolithic --copt=-w --host_copt=-w --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --verbose_failures --distinct_host_configuration=false --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:monolithic in file d:\\test\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):\r\n        File \"D:/test/tensorflow.windows/s5ozolul/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 164\r\n                _clone_or_update(ctx)\r\n        File \"D:/test/tensorflow.windows/s5ozolul/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 74, in _clone_or_update\r\n                fail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning io_bazel_rules_docker:\r\n+ cd D:/test/tensorflow.windows/s5ozolul/external\r\n+ rm -rf D:/test/tensorflow.windows/s5ozolul/external/io_bazel_rules_docker D:/test/tensorflow.windows/s5ozolul/external/io_bazel_rules_docker\r\n/usr/bin/bash: line 5: rm: command not found\r\nERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):\r\n        File \"D:/test/tensorflow.windows/s5ozolul/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 164\r\n                _clone_or_update(ctx)\r\n        File \"D:/test/tensorflow.windows/s5ozolul/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 74, in _clone_or_update\r\n                fail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning io_bazel_rules_docker:\r\n+ cd D:/test/tensorflow.windows/s5ozolul/external\r\n+ rm -rf D:/test/tensorflow.windows/s5ozolul/external/io_bazel_rules_docker D:/test/tensorflow.windows/s5ozolul/external/io_bazel_rules_docker\r\n/usr/bin/bash: line 5: rm: command not found\r\nINFO: Elapsed time: 16.367s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n```", "Is it possible to add tensorflowlite for windows to CI? ", "No solution still?", "I have same problem!", "Please watch #31601, most likely after that PR is merged this issue can be solved.\r\n\r\nI estimate one more week at most until solution.", "I constantly run accross the bug. It's really annoying. It has nothing to do with my code since usually after several docker restarting or code recompiling, it works again.", "@mihaimaruseac I guess the issue still here? Any ETA on fixing it finally?", "I have same problem!I'm so tired!!!", "As TF 1.14 is in a very bad state, I would recommend trying 1.15 or 2.0 or 2.1", "D:\\test\\tensorflow-r1.15>bazel --output_user_root=..\\tensorflow_1.15.windows build  --jobs 1 -c opt --cxxopt=--std=c++11 //tensorflow/lite:libtensorflowlite.so                                                    Extracting Bazel installation...                                                                                                                                                                                   Starting local Bazel server and connecting to it...                                                                                                                                                                INFO: Options provided by the client:                                                                                                                                                                                Inherited 'common' options: --isatty=1 --terminal_columns=211                                                                                                                                                    INFO: Options provided by the client:                                                                                                                                                                                'build' options: --python_path=C:/Python27/python.exe                                                                                                                                                            INFO: Reading rc options for 'build' from d:\\test\\tensorflow-r1.15\\.bazelrc:                                                                                                                                         'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include                                         ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):                File \"D:/test/tensorflow_1.15.windows/pmsk6zot/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 164                                                                                                               _clone_or_update(ctx)                                                                                                                                                                                      File \"D:/test/tensorflow_1.15.windows/pmsk6zot/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 74, in _clone_or_update                                                                                           fail((\"error cloning %s:\\n%s\" % (ctx....)))                                                                                                                                                        error cloning io_bazel_rules_docker:                                                                                                                                                                               + cd D:/test/tensorflow_1.15.windows/pmsk6zot/external                                                                                                                                                             + rm -rf D:/test/tensorflow_1.15.windows/pmsk6zot/external/io_bazel_rules_docker D:/test/tensorflow_1.15.windows/pmsk6zot/external/io_bazel_rules_docker                                                           /usr/bin/bash: line 5: rm: command not found                                                                                                                                                                       ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):                File \"D:/test/tensorflow_1.15.windows/pmsk6zot/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 164                                                                                                               _clone_or_update(ctx)                                                                                                                                                                                      File \"D:/test/tensorflow_1.15.windows/pmsk6zot/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 74, in _clone_or_update                                                                                           fail((\"error cloning %s:\\n%s\" % (ctx....)))                                                                                                                                                        error cloning io_bazel_rules_docker:                                                                                                                                                                               + cd D:/test/tensorflow_1.15.windows/pmsk6zot/external                                                                                                                                                             + rm -rf D:/test/tensorflow_1.15.windows/pmsk6zot/external/io_bazel_rules_docker D:/test/tensorflow_1.15.windows/pmsk6zot/external/io_bazel_rules_docker                                                           /usr/bin/bash: line 5: rm: command not found                                                                                                                                                                       INFO: Elapsed time: 16.173s                                                                                                                                                                                        INFO: 0 processes.                                                                                                                                                                                                 FAILED: Build did NOT complete successfully (0 packages loaded)", "Error is `rm: command not found`. `rm` is a Linux command, available under Windows via WSL, MinGW or other similar approaches.\r\n\r\nDin you run `configure.py`?\r\n\r\nAlso, please use ` ``` ` around code blocks and errors so that they are readable.", "Run configure.cmd (which calls configure.py), the error is pretty the same: \r\n\r\n```\r\nMicrosoft` Windows [Version 10.0.18363.535]\r\n(c) 2019 Microsoft Corporation. All rights reserved.\r\n\r\nD:\\test\\tensorflow-r1.15>configure\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.24.1 installed.\r\nPlease specify the location of python. [Default is C:\\Python27\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Python27\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Python27\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]:\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=noignite       # Disable Apache Ignite support.\r\n        --config=nokafka        # Disable Apache Kafka support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\nD:\\test\\tensorflow-r1.15>bazel --output_user_root=..\\tensorflow_1.15.windows.build build --jobs 1 -c opt --cxxopt=--std=c++11 //tensorflow/lite:libtensorflowlite.so\r\nExtracting Bazel installation...\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=C:/Python27/python.exe\r\nINFO: Reading rc options for 'build' from d:\\test\\tensorflow-r1.15\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include\r\nINFO: Reading rc options for 'build' from d:\\test\\tensorflow-r1.15\\.tf_configure.bazelrc:\r\n  'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=C:/Python27/python.exe --action_env PYTHON_LIB_PATH=C:/Python27/lib/site-packages --python_path=C:/Python27/python.exe --config monolithic --copt=-w --host_copt=-w --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --verbose_failures --distinct_host_configuration=false --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:monolithic in file d:\\test\\tensorflow-r1.15\\.bazelrc: --define framework_shared_object=false\r\nERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):\r\n        File \"D:/test/tensorflow_1.15.windows.build/pmsk6zot/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 164\r\n                _clone_or_update(ctx)\r\n        File \"D:/test/tensorflow_1.15.windows.build/pmsk6zot/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 74, in _clone_or_update\r\n                fail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning io_bazel_rules_docker:\r\n+ cd D:/test/tensorflow_1.15.windows.build/pmsk6zot/external\r\n+ rm -rf D:/test/tensorflow_1.15.windows.build/pmsk6zot/external/io_bazel_rules_docker D:/test/tensorflow_1.15.windows.build/pmsk6zot/external/io_bazel_rules_docker\r\n/usr/bin/bash: line 5: rm: command not found\r\nERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):\r\n        File \"D:/test/tensorflow_1.15.windows.build/pmsk6zot/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 164\r\n                _clone_or_update(ctx)\r\n        File \"D:/test/tensorflow_1.15.windows.build/pmsk6zot/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 74, in _clone_or_update\r\n                fail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning io_bazel_rules_docker:\r\n+ cd D:/test/tensorflow_1.15.windows.build/pmsk6zot/external\r\n+ rm -rf D:/test/tensorflow_1.15.windows.build/pmsk6zot/external/io_bazel_rules_docker D:/test/tensorflow_1.15.windows.build/pmsk6zot/external/io_bazel_rules_docker\r\n/usr/bin/bash: line 5: rm: command not found\r\nINFO: Elapsed time: 16.673s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n\r\nD:\\test\\tensorflow-r1.15>\r\n```", "Does it mean I should you wsl for building for windows?", "Or MSYS2. See https://www.tensorflow.org/install/source_windows", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31118\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31118\">No</a>\n"]}, {"number": 31117, "title": "Model does not converge during training with distribute strategy and tf.py_function in dataset.map", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution:Windows 10 Pro\r\n- TensorFlow installed from:binary(pip)\r\n- TensorFlow version:2.0.0-beta1\r\n- Python version:3.6.8\r\n- CUDA/cuDNN version:10.0\r\n- GPU model and memory:Tesla K80\r\n\r\n**Describe the current behavior**\r\nModel does not converge and training is extremely slow with distribute strategy, if tf.py_function called in dataset.map. \r\nWorks fine without distribute strategy or implementing map function without tf.py_function.\r\n\r\n**Describe the expected behavior**\r\nSuccesful training with distribute strategy when tf.py_function called in dataset.map.\r\n\r\n**Code to reproduce the issue**\r\nReproducible in Colaboratory with TF 1.14.0\r\nhttps://colab.research.google.com/drive/1J98yNqa4gslsTe1SiCrhomhNB6UREkLC\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n\r\ndef get_keys():\r\n    return list(range(-1000, 1000))\r\n\r\n# generate positive feature and label\r\ndef generate_positive():\r\n    x = tf.random.uniform(shape=(), minval=0.0, maxval=20.0)\r\n    y = tf.random.uniform(shape=(), minval=0.0, maxval=20.0)\r\n    label = tf.constant(1)\r\n    return x, y, label\r\n\r\n\r\n# generate negative feature and label\r\ndef generate_negative():\r\n    x = tf.random.uniform(shape=(), minval=40.0, maxval=100.0)\r\n    y = tf.random.uniform(shape=(), minval=40.0, maxval=100.0)\r\n    label = tf.constant(0)\r\n    return x, y, label\r\n\r\n\r\n# generate pos/neg feature and label\r\ndef generate_pf(key):\r\n    if key > -1:\r\n        x = tf.random.uniform(shape=(), minval=0.0, maxval=20.0)\r\n        y = tf.random.uniform(shape=(), minval=0.0, maxval=20.0)\r\n        label = tf.constant(1)\r\n    else:\r\n        x = tf.random.uniform(shape=(), minval=40.0, maxval=100.0)\r\n        y = tf.random.uniform(shape=(), minval=40.0, maxval=100.0)\r\n        label = tf.constant(0)\r\n\r\n    x = tf.math.sign(tf.random.uniform(shape=(), minval=-1.0, maxval=1.0)) * tf.abs(x)\r\n    y = tf.math.sign(tf.random.uniform(shape=(), minval=-1.0, maxval=1.0)) * tf.abs(y)\r\n    feature = tf.stack([x, y])\r\n    return feature, label\r\n\r\n\r\n# dataset map function: works with or without distribute strategy\r\ndef map_tf(key):\r\n    x, y, label = tf.cond(tf.greater(key, -1), generate_positive, generate_negative)\r\n    x = tf.math.sign(tf.random.uniform(shape=(), minval=-1.0, maxval=1.0)) * tf.abs(x)\r\n    y = tf.math.sign(tf.random.uniform(shape=(), minval=-1.0, maxval=1.0)) * tf.abs(y)\r\n    feature = tf.stack([x, y])\r\n    return feature, label\r\n\r\n\r\n# dataset map function: works without distribute strategy\r\ndef map_py_func(key):\r\n    feature, label = tf.py_function(func=generate_pf,\r\n                                    inp=[key],\r\n                                    Tout=[tf.float32, tf.int32])\r\n    # TODO: skip shape setting if training without distribute strategy\r\n    feature.set_shape([2])\r\n    label.set_shape([1])\r\n    return feature, label\r\n\r\n\r\ndef get_dataset():\r\n    keys = get_keys()\r\n    dataset = tf.data.Dataset.from_tensor_slices(keys)\r\n    dataset = dataset.repeat()\r\n    dataset = dataset.shuffle(buffer_size=len(keys))\r\n    # replace 'map_py_func' with 'map_tf' to have successful training\r\n    dataset = dataset.map(lambda key: map_py_func(key), \r\n                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n    dataset = dataset.batch(100)\r\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n    return dataset\r\n\r\n\r\ndef get_model():\r\n    x = inputs = keras.Input([2])\r\n    x = keras.layers.Dense(units=4, activation='relu')(inputs=x)\r\n    x = keras.layers.Dense(units=4, activation='relu')(inputs=x)\r\n    x = keras.layers.Dense(units=1, activation='sigmoid')(inputs=x)\r\n    return keras.Model(inputs=inputs, outputs=x)\r\n\r\n\r\n# server = tf.distribute.Server.create_local_server()\r\ntrain_dataset = get_dataset()\r\nval_dataset = get_dataset()\r\n\r\nstrategy = tf.distribute.OneDeviceStrategy('/gpu:0')\r\n# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"],\r\n#                                           cross_device_ops=tf.distribute.ReductionToOneDevice())\r\nwith strategy.scope():\r\n    model = get_model()\r\n    optimizer = keras.optimizers.Adam(learning_rate=1e-2)\r\n    model.compile(optimizer=optimizer,\r\n                  loss=keras.losses.BinaryCrossentropy(name='loss'),\r\n                  metrics=[keras.metrics.BinaryAccuracy(name='accuracy')],\r\n                  run_eagerly=False)\r\n\r\nmodel.fit(train_dataset,\r\n          initial_epoch=0,\r\n          epochs=20,\r\n          steps_per_epoch=50,\r\n          validation_data=val_dataset,\r\n          validation_steps=1,\r\n          validation_freq=1)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n  1/100 [..............................] - ETA: 11:27 - loss: 15.6796 - accuracy: 0.5120\r\n  2/100 [..............................] - ETA: 6:00 - loss: 18.0561 - accuracy: 0.4938 \r\n  3/100 [..............................] - ETA: 4:10 - loss: 19.7856 - accuracy: 0.4705\r\n  4/100 [>.............................] - ETA: 3:14 - loss: 18.6577 - accuracy: 0.4707\r\n  5/100 [>.............................] - ETA: 2:42 - loss: 17.9387 - accuracy: 0.4689\r\n  6/100 [>.............................] - ETA: 2:19 - loss: 17.1595 - accuracy: 0.4741\r\n  7/100 [=>............................] - ETA: 2:04 - loss: 16.9366 - accuracy: 0.4744\r\n  8/100 [=>............................] - ETA: 1:53 - loss: 16.6326 - accuracy: 0.4814\r\n  9/100 [=>............................] - ETA: 1:44 - loss: 16.1086 - accuracy: 0.4825\r\n 10/100 [==>...........................] - ETA: 1:36 - loss: 15.7002 - accuracy: 0.4848\r\n```", "comments": ["@makercob I tried executing the Colab link provided, Please confirm us is this expected behavior. Please look at the colab [gist](https://colab.research.google.com/drive/1vmljazkzTyE7Xyo7vruf7oyUYk1Q78y9). Thanks! ", "@gadagashwini Thanks! Issue is reproduced in the gist: Without discarding distribute strategy or replacing 'map_py_func' with 'map_tf', accuracy will always oscillate around 50%.", "I tried reproducing this but I think I am getting the same behavior with and without strategy - the accuracy hovers around 50% in either case.. can you send a version that does work? ", "I tried reproducing but even without distribution strategy, I am seeing the same behavior (accuracy hovers around 50%). Can you share a working example?  \r\n\r\n![Screen Shot 2019-07-31 at 2 18 05 PM](https://user-images.githubusercontent.com/14104855/62248998-4a0bc200-b39e-11e9-9371-1ae1495a17d4.png)\r\n", "@guptapriya oops, my bad. In Colab(TF 1.14), eager mode must be enabled to achieve successful training.\r\n\r\nhttps://colab.research.google.com/drive/1J98yNqa4gslsTe1SiCrhomhNB6UREkLC\r\n\r\nhere  in TensorFlow2.0.0b, accuracy will grow to 1.00:\r\n\r\n<img width=\"985\" alt=\"Screen Shot 2019-08-01 at 09 25 12\" src=\"https://user-images.githubusercontent.com/6904036/62258773-5cd5d380-b43e-11e9-971e-7d24cce1f27e.png\">\r\n\r\nBTW, according to the doc: [https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/py_function](url)\r\n\r\n> The operation must run in the same address space as the Python program that calls tf.py_function(). If you are using distributed TensorFlow, you must run a tf.distribute.Server in the same process as the program that calls tf.py_function() and you must pin the created operation to a device in that server (e.g. using with tf.device():).\r\n\r\nCould you please elaborate on how to pin operation when distribute strategy is involved? Thanks!", "@guptapriya feature.set_shape([2]) is the culprit. I think this issue could be closed. Thank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31117\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31117\">No</a>\n"]}, {"number": 31116, "title": "Cannot open include file: 'absl/strings/string_view.h", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@penghao1990 ,\r\nCan you please fill details in the above mentioned template.\r\nAlso In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. \r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 31115, "title": "Convert to TFLite Unexpected value for attribute 'data_format'. Expected 'NHWC'", "body": "I'm trying to convert a frozen Tensorflow graph. See model [here](https://drive.google.com/open?id=15g1aNF3WdJ7Yw8GRPVEWzBbkaZPIvCGC). I found a lot related bug reports on that issue but non of them was actually solved: [#30411](https://github.com/tensorflow/tensorflow/issues/30411), [#7967](https://github.com/tensorflow/tensorflow/issues/7967),[#24491](https://github.com/tensorflow/tensorflow/issues/24491). \r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 19.04 64bit\r\n- TensorFlow installed from (source or binary): binary  (CPU)\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc9 1.14.0\r\n- Python version: 3.7.3\r\n\r\n**Describe the current behavior**\r\nRunning in Jupyter I get following error:\r\n```\r\nConverterError: TOCO failed. See console for info.\r\n2019-07-28 21:08:26.912035: F tensorflow/lite/toco/import_tensorflow.cc:2619] Check failed: status.ok() Unexpected value for attribute 'data_format'. Expected 'NHWC'\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fc8ee681740 (most recent call first):\r\n  File \"/home/paul/anaconda3/envs/openvino/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n  File \"/home/paul/.local/lib/python3.7/site-packages/absl/app.py\", line 251 in _run_main\r\n  File \"/home/paul/.local/lib/python3.7/site-packages/absl/app.py\", line 300 in run\r\n  File \"/home/paul/anaconda3/envs/openvino/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/home/paul/anaconda3/envs/openvino/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n  File \"/home/paul/anaconda3/envs/openvino/bin/toco_from_protos\", line 10 in <module>\r\nAborted (core dumped)\r\n```\r\n\r\nRunning over shell:\r\n```\r\nTraceback (most recent call last):\r\n  File \"tensorflow_issue_tflite.py\", line 10, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/paul/anaconda3/envs/openvino/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 898, in convert\r\n    **converter_kwargs)\r\n  File \"/home/paul/anaconda3/envs/openvino/lib/python3.7/site-packages/tensorflow/lite/python/convert.py\", line 404, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/home/paul/anaconda3/envs/openvino/lib/python3.7/site-packages/tensorflow/lite/python/convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-07-28 21:35:22.220584: F tensorflow/lite/toco/import_tensorflow.cc:2619] Check failed: status.ok() Unexpected value for attribute 'data_format'. Expected 'NHWC'\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fae1bce0740 (most recent call first):\r\n  File \"/home/paul/anaconda3/envs/openvino/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n  File \"/home/paul/.local/lib/python3.7/site-packages/absl/app.py\", line 251 in _run_main\r\n  File \"/home/paul/.local/lib/python3.7/site-packages/absl/app.py\", line 300 in run\r\n  File \"/home/paul/anaconda3/envs/openvino/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/home/paul/anaconda3/envs/openvino/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n  File \"/home/paul/anaconda3/envs/openvino/bin/toco_from_protos\", line 10 in <module>\r\nAborted (core dumped)\r\n```\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = \"model_lcnn_29v2_cpu.pb\"\r\n\r\ninput_arrays = [\"0\"]\r\noutput_arrays = [\"MatMul\"]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n  graph_def_file, input_arrays, output_arrays)\r\ntflite_model = converter.convert()\r\nopen(\"model_lcnn_29v2.tflite\", \"wb\").write(tflite_model)\r\n\r\n```\r\n[](url)", "comments": ["TF Lite's Conv/MaxPool/AvgPool operator only supports NHWC data format right now. I think your model uses NCHW format in those ops. Could you try switch your data format to 'NHWC'?", "I would like to switch the data_format, but that is actually not so easy because the model was build in Pytorch->convert to ONNX->convert to frozen graph. And I cannot change the data format of a node without rebuilding the entire graph. Is there some tool from Tensorflow to do that?", "There isn't such tool that I'm aware of to convert data format from a graphdef. One way to do this is to manually insert transpose nodes before each of those ops in your graphdef(which could be tricky).", "@haozha111 Ok, [modifying the GraphDef](https://github.com/paulbauriegel/tensorflow-tools/blob/master/convert-model-to-NWHC.py) and adding Transpose nodes before and after the convolutional operations let me convert the model. Thanks for the hint \ud83d\udc4d", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31115\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31115\">No</a>\n", "Awesome! We are going to support 'nchw' in the future, so hopefully won't need to do this all on your own. Thanks!", "Dear,\r\nhow to set the four parameters\r\n--mean_values\r\n--std_dev_values\r\n--default_ranges_min\r\n--default_ranges_max\r\n\r\nthx\r\n#32611", "> Awesome! We are going to support 'nchw' in the future, so hopefully won't need to do this all on your own. Thanks!\r\n\r\nHey, i am really excited for this. When is it going to happen?", "> Awesome! We are going to support 'nchw' in the future, so hopefully won't need to do this all on your own. Thanks!\r\n\r\nAny idea when that's happening?", "> Awesome! We are going to support 'nchw' in the future, so hopefully won't need to do this all on your own. Thanks!\r\n \r\nHey y'all, any updates on this?", "> > Awesome! We are going to support 'nchw' in the future, so hopefully won't need to do this all on your own. Thanks!\r\n> \r\n> Hey y'all, any updates on this?\r\n\r\nhi, currently we don't have concrete plans to support it on our roadmap. Sorry about that. If you can share some common scripts that could help walk-around this issue, that will be great. thanks!", "> @haozha111 Ok, [modifying the GraphDef](https://github.com/paulbauriegel/tensorflow-tools/blob/master/convert-model-to-NWHC.py) and adding Transpose nodes before and after the convolutional operations let me convert the model. Thanks for the hint +1\r\n \r\n@paulbauriegel Could you please elaborate on how to do that? I have the exact same issue, but I am not sure where to put the transpose and how to modify the GraphDef. Thank you very much!\r\n", "@xsankar Have a look at the python script I linked in that comment, did it work for you?", "@paulbauriegel probably you meant @xserraalza", "Thanks for the quick response! I hadn't noticed the link (it points to the wrong url!), I have now tried it, and it gives me an error on the first node processed:\r\n\r\n\r\n_(1, 224, 112, 16)  \r\n(1, 16, 112, 112)  \r\n(1, 16, 224, 112)  \r\nTraceback (most recent call last):\\\r\n  File \"quantize_tf_model.py\", line 42, in <module>\\\r\n    assert out_trans.shape == sess.graph.get_tensor_by_name(n_org.name+':0').shape\\\r\nAssertionError_\r\n\r\n\r\nDo you have any idea on why this may happen?\r\nThanks!", "@xserraalza I'm happy to help, but open an issue here: https://github.com/paulbauriegel/tensorflow-tools/issues I don't think here is the perfect place to discuss why the script fails.", "I managed to make it work changing the order of the strides. Thank you for your work :)", "> I managed to make it work changing the order of the strides. Thank you for your work :)\r\n\r\nCould you please share your experience? You probably work with pytorch as I am?", "> > I managed to make it work changing the order of the strides. Thank you for your work :)\r\n> \r\n> Could you please share your experience? You probably work with pytorch as I am?\r\n\r\nI used @paulbauriegel code, and I added the following line after line 29:\r\n`atts[\"strides\"].list.i[-1], atts[\"strides\"].list.i[1] = atts[\"strides\"].list.i[1], atts[\"strides\"].list.i[-1]`\r\n\r\nIt seemed that the order of the strides channels was not the right one for me. After this change, I managed to convert to NHWC with no problem.\r\n\r\nHope it helps!", "> > > I managed to make it work changing the order of the strides. Thank you for your work :)\r\n> > \r\n> > \r\n> > Could you please share your experience? You probably work with pytorch as I am?\r\n> \r\n> I used @paulbauriegel code, and I added the following line after line 29:\r\n> `atts[\"strides\"].list.i[-1], atts[\"strides\"].list.i[1] = atts[\"strides\"].list.i[1], atts[\"strides\"].list.i[-1]`\r\n> \r\n> It seemed that the order of the strides channels was not the right one for me. After this change, I managed to convert to NHWC with no problem.\r\n> \r\n> Hope it helps!\r\n\r\nHa ha I just figure out something like that right now even not reading your post)))\r\nDid you convert you model to TFlite. I cant do it even with resnet18 got something like\r\n`Here is a list of operators for which you will need custom implementations: Dilation2D`\r\nWhich is completly weird because resnet18 does not have any dilations in convs", "@MaratZakirov Yes, forgot to transfer the attributes for the Conv2D layer. I added the fix to the script. As for the `Dilation2D` error look at the solution from https://github.com/tensorflow/tensorflow/issues/38102 maybe that helps:\r\n````\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n````", "> > > > I managed to make it work changing the order of the strides. Thank you for your work :)\r\n> > > \r\n> > > \r\n> > > Could you please share your experience? You probably work with pytorch as I am?\r\n> > \r\n> > \r\n> > I used @paulbauriegel code, and I added the following line after line 29:\r\n> > `atts[\"strides\"].list.i[-1], atts[\"strides\"].list.i[1] = atts[\"strides\"].list.i[1], atts[\"strides\"].list.i[-1]`\r\n> > It seemed that the order of the strides channels was not the right one for me. After this change, I managed to convert to NHWC with no problem.\r\n> > Hope it helps!\r\n> \r\n> Ha ha I just figure out something like that right now even not reading your post)))\r\n> Did you convert you model to TFlite. I cant do it even with resnet18 got something like\r\n> `Here is a list of operators for which you will need custom implementations: Dilation2D`\r\n> Which is completly weird because resnet18 does not have any dilations in convs\r\n\r\n[This issue](https://github.com/onnx/onnx-tensorflow/issues/595) leading to [this fix](https://github.com/onnx/onnx-tensorflow/pull/613) might help you, It's an issue when converting to TFlite,  as ONNX -> Frozen pb graph incorporates Dilation2D layer, even when dilations are 1 (by default dilations are 1 in Conv layers)", "> @MaratZakirov Yes, forgot to transfer the attributes for the Conv2D layer. I added the fix to the script. As for the `Dilation2D` error look at the solution from #38102 maybe that helps:\r\n> \r\n> ```\r\n> converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n>                                        tf.lite.OpsSet.SELECT_TF_OPS]\r\n> ```\r\n\r\nI use your script and get a pb file,but i convert pb to tflite file get a error like this:\r\nF tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1305] Check failed: block_shape_array_shape.dims(0) == 2 (3 vs. 2)\r\nDo you have any idea on why this may happen?\r\nThanks!", "@yusuyuan123 Hard to say without having a closer look at your model. You can open a issue in my Repo and we can continue the discussion there."]}, {"number": 31114, "title": "TFLite No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int)", "body": "**System information**\r\n- OS Platform and Distribution: Android 5.1.1, API 22\r\n- Mobile device: Xiaomi Redmi 3\r\n- TensorFlow installed from: official binary\r\n- TensorFlow version : tensorflow-lite:1.14.0\r\n\r\n**Describe the current behavior**\r\nTensorflow-lite 1.13.1 works fine on all devices I tested. Whereas tensorflow-lite 1.14.0 is broken for Xiaomi Redmi 3 (Android 5.1.1, API 22), other devices are ok.\r\nI get a runtime error when `Interpreter` is created.\r\n\r\n**Describe the expected behavior**\r\nNo error.\r\n\r\n**Code to reproduce the issue**\r\n```\r\ninterpreter = new Interpreter(tfliteModel, null);\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nW/linker: /data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so: unused DT entry: type 0x6ffffffe arg 0x2020\r\n    /data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so: unused DT entry: type 0x6fffffff arg 0x3\r\nE/art: dlopen(\"/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so\", RTLD_LAZY) failed: dlopen failed: cannot locate symbol \"__register_atfork\" referenced by \"/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so\"...\r\nW/System.err: TensorFlowLite: failed to load native library: dlopen failed: cannot locate symbol \"__register_atfork\" referenced by \"/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so\"...\r\nW/linker: /data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so: unused DT entry: type 0x6ffffffe arg 0x2020\r\n    /data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so: unused DT entry: type 0x6fffffff arg 0x3\r\nE/art: dlopen(\"/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so\", RTLD_LAZY) failed: dlopen failed: cannot locate symbol \"__register_atfork\" referenced by \"/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so\"...\r\nW/System.err: TensorFlowLite: failed to load native library: dlopen failed: cannot locate symbol \"__register_atfork\" referenced by \"/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so\"...\r\nE/art: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)\r\nD/AndroidRuntime: Shutting down VM\r\nE/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: eu.yesse.readerdemo.debug, PID: 12710\r\n    java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:58)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:224)\r\n        at eu.yesse.reader.commons.internal.detector.BlockingCornersClassSingleDetector.<init>(BlockingCornersClassSingleDetector.java:76)\r\n        at eu.yesse.reader.commons.internal.detector.BlockingCornersClassMultiDetector.<init>(BlockingCornersClassMultiDetector.java:25)\r\n        at eu.yesse.reader.commons.shared.detector.AsyncCornersClassMultiDetectorImpl.<init>(AsyncCornersClassMultiDetectorImpl.java:36)\r\n        at eu.yesse.reader.tempregdoc.internal.TempRegDocReaderManager.createDetector(TempRegDocReaderManager.java:79)\r\n        at eu.yesse.reader.tempregdoc.internal.TempRegDocReaderManager.<init>(TempRegDocReaderManager.java:48)\r\n        at eu.yesse.reader.TempRegDocReader.getReader(TempRegDocReader.java:20)\r\n        at eu.yesse.readerdemo.activities.TempRegDocActivity.onCreate(TempRegDocActivity.java:24)\r\n        at android.app.Activity.performCreate(Activity.java:6093)\r\n        at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1106)\r\n        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2295)\r\n        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2404)\r\n        at android.app.ActivityThread.access$900(ActivityThread.java:154)\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1315)\r\n        at android.os.Handler.dispatchMessage(Handler.java:102)\r\n        at android.os.Looper.loop(Looper.java:135)\r\n        at android.app.ActivityThread.main(ActivityThread.java:5296)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at java.lang.reflect.Method.invoke(Method.java:372)\r\n        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:912)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:707)\r\n```\r\n", "comments": ["Did you solve it?\r\n\r\nFirebase crashlytics reports this issue for Android 5 users of my app\r\n\r\nI added Tensorflow like this:\r\n\r\n    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'\r\n\r\n`Fatal Exception: java.lang.UnsatisfiedLinkError\r\nNo implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)`", ">Did you solve it?\r\n\r\n@anonym24 nope :( I guess we can't do much about it without a fix in tf. BTW I guess you should not put both `org.tensorflow:tensorflow-lite` and `org.tensorflow:tensorflow-lite-gpu` in your gradle file at the same time (?). But that's not the issue here anyway... \r\nFrom crashlitics: does the crash affects only Android 5.*.* and all of them?", "@wosiu yes, we need them both: https://www.tensorflow.org/lite/performance/gpu\r\n\r\n![image](https://user-images.githubusercontent.com/8851301/62043870-2fa0df80-b20a-11e9-9c14-d56096189366.png)\r\n", "@wosiu \r\nin my case, yes (only Android 5):\r\n\r\n![image](https://user-images.githubusercontent.com/8851301/62052901-29692e00-b21f-11e9-8b3a-fee666ab05f1.png)\r\n\r\n", "@liyunlu0618 are there any updates on that?", "I also encounter this problem, I resolve this by reconfigure my ndk abifilter settings. My project originally was only built for 'armeabi' architecture. When I add any other abi options, it works like a charm. However, I'm still confused because on the tutorial page of Tensorflow Lite, it says that the library support all kinds of architecture(which should include armeabi). Or is it because arm support was removed in ndk r17? Hope someone can help me to find a workaround for tflite to run on armeabi devices.", "Did anyone find solution for this? I am also facing the same issue.\r\nI tested in Oneplus3.\r\n2019-09-06 08:28:18.799 15233-15233/ai.fritz.tflitedemo E/ritz.tflitedem: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)\r\n2019-09-06 08:28:18.802 15233-15233/ai.fritz.tflitedemo E/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: ai.fritz.tflitedemo, PID: 15233\r\n    java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(Native Method)\r\n\r\nGradle:\r\n   implementation 'org.tensorflow:tensorflow-lite:0.1.2-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite:0.1'\r\n    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'", "Any update on this? I'm also facing the same issue on 1.14.0", "I'm also got this crash", "I had a similar issue from NDK, namely that arm64 Android 5.x devices failed to load the shared library libtensorflowlite.so because of __register_atfork being missing.\r\n\r\nThe problem is that for at least arm64, __register_atfork usage is somehow generated in the shared library, but [this function is introduced in Android 6](https://android.googlesource.com/platform/bionic/+/master/android-changes-for-ndk-developers.md). As suggested in the link, I tried compiling with lower NDK target API level, but this didn't seem to help. I also tried searching for \"atfork\" in tensorflow lite's source code, but couldn't find any.\r\n\r\n**Workaround for at least NDK users:** Disassembling libtensorflowlite.so left an impression that __register_atfork is only called while reporting errors, so at least theoretically it shouldn't be called in production anyway. The workaround was thus to introduce fake __register_atfork() declaration and definition in cpp and h files, so that linker wouldn't complain anymore. So I put\r\n\r\n```\r\nextern \"C\" {\r\n    int __register_atfork(void (*prepare) (void), void (*parent) (void), void (*child) (void), void *__dso_handle);\r\n}\r\n```\r\n\r\ninto tensorflow/lite/util.h, and\r\n\r\n```\r\n#include <cassert>\r\nextern \"C\" {\r\n    int __register_atfork(void (*prepare) (void), void (*parent) (void), void (*child) (void), void *__dso_handle) {\r\n        assert(0 && \"Using dummy __register_atfork(). This is dangerous, so asserting.\");\r\n        return 0; // Avoid warning\r\n    }\r\n}\r\n```\r\n\r\ninto tensorflow/lite/util.cc (the exact files aren't important, the definition just has to be compiled and linked to libtensorflowlite.so) and recompiled. After that neural networks seem to work fine on all devices. I guess something similar should work for JNI users as well.", "I had the same issue. I fixed it by adding \r\n```\r\nndk {\r\n            abiFilters \"armeabi-v7a\", \"x86\"\r\n        }\r\n```\r\nto the `defaultConfig` in `app/build.gradle` file. ", "@kongaskristjan and @FunmiKesa - big thanks for investigating and sharing that! Said that, I feel propsed changes are more like workarounds and not solutions. It still would be nice to have a fix inside the tensorflow lib.", "Any updates on this? It's still happening on 1.15.0! This seems like a critical bug to me, tflite instantly crashes on some devices.\r\n\r\nI will bump my minApi to 23 for a while, and later revert to 21 when this gets fixed :)\r\n\r\nEDIT: Excluding 64bit architectures as some of you are doing is not a viable solution, Google Play store enforces all apps to support 64bit since 1st of August 2019: https://android-developers.googleblog.com/2019/01/get-your-apps-ready-for-64-bit.html", "Hi all, apologies for the delayed response, just now seeing this issue.\r\n\r\nWe set our Android NDK API level to 18 when building, but it's possible there's something wrong with the config and it's assuming API 23. I'll take a look.\r\n\r\n", "This is fixed in the latest nightly, and we'll try to pull the fix in to the 2.1 release (https://github.com/tensorflow/tensorflow/pull/34419). Thanks again for your patience.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31114\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31114\">No</a>\n", "Hi @jdduke , thanks for the fix. Just to understand how we can resolve this issue on android, would we be able to pull in the nightly build of TFL in gradle and have this fixed\r\n\r\n```\r\ndependencies: {\r\n     implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n}\r\n```\r\n\r\nor do we have to also reconvert our models to TFL using the nightly build?", "@jdduke are you going to backport the fix to 1.* version?", "There won't be any backport, however, you can safely use the latest 2.x or nightly version with both 1.X and 2.X TF models.", "Hello @jdduke, please show me what I need to put in gradle.build to use latest fix", "@runnableapps \r\nAnswer:\r\n```\r\ndependencies: {\r\n     implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n}\r\n```\r\nor wait for `2.1` release.", "  implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\ndoes not fix crash", "You might need to [clear your gradle cache](https://stackoverflow.com/questions/23025433/how-to-clear-gradle-cache). I've manually inspected the [nightly build](https://bintray.com/google/tensorflow/tensorflow-lite#files/org%2Ftensorflow%2Ftensorflow-lite%2F0.0.0-nightly) and verified that `__register_atfork` is no longer referenced. There might be another issue with your usage, in which case please attach the log from adb.", "Got the same problem with org.tensorflow:tensorflow-lite:2.0.0\r\nDevice T8-PLUS, Android 5.1", "@alexeyvasilyev the fix did not make it into 2.0, but it will be in the upcoming 2.1 release (expected to be finalized soon). In the meantime, please try the nightly build.", "@jdduke Thanks. Lets hope nightly build can sort out this issue in android 5.", "The 2.1 release is now available (`org.tensorflow:tensorflow-lite:2.1.0`), please give it a try.", "I confirm - 2.1.0 works on the device I originally issued the problem with :) Big thanks to all contributors! \ud83e\udd47 "]}, {"number": 31113, "title": "MAE and MAPE and ACC makes no sense", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\nDebian 9 VM on GCP with TPU v3-8\r\nTensorflow 1.13.1 Keras 2.2.4 \r\n\r\n**Describe the current behavior**\r\n\r\ntraining a model using dataset scaled to range 0..1 I am getting improbable metrics consistently\r\n\r\n```\r\nloss: 0.3452 - mean_absolute_error: 76.0366 - mean_absolute_percentage_error: 76.0319 - acc: 76.0429 \r\nval_loss: 0.0146 - val_mean_absolute_error: 7.6565 - val_mean_absolute_percentage_error: 7.6635 - val_acc: 7.6594\r\n```\r\n\r\nI don't understand these metrics.\r\n\r\n1. If accuracy is about the same as MAE then what does it mean? its not accurate at all?\r\n\r\n2. If MAPE about the same as MAE - how percentage can be equal to absolute value of error?\r\n\r\n3. The data is scaled to 0..1 range. How absolute error can be 76?\r\n\r\n**Describe the expected behavior**\r\n\r\nmeaningful metrics\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nmodel = tf.keras.Sequential()\r\nmodel.add(layers.Conv1D(filters=128, kernel_size=2, activation=activation, input_shape=(window_size // subseq_size, subseq_size)))\r\nmodel.add(layers.Conv1D(filters=64, kernel_size=2, activation=activation))\r\nmodel.add(layers.Conv1D(filters=32, kernel_size=2, activation=activation))\r\nmodel.add(layers.MaxPooling1D(pool_size=2))\r\nmodel.add(layers.TimeDistributed(Flatten()))\r\nmodel.add(layers.LSTM(500))\r\nmodel.add(layers.Dense(100))\r\nmodel.add(layers.Dense(1))\r\n\r\nopt = tf.train.AdamOptimizer(learning_rate)\r\n\r\ntpu_model = tf.contrib.tpu.keras_to_tpu_model(model, \r\n        strategy=tf.contrib.tpu.TPUDistributionStrategy(\r\n            tf.contrib.cluster_resolver.TPUClusterResolver(tpu = [TPU_ADDRESS1])))\r\n\r\ntpu_model.compile(optimizer=opt, loss='mse', metrics=['mae', 'mape', 'acc'])\r\n\r\nH = tpu_model.fit(X, y, validation_split=0.15, epochs=epochs_n, batch_size = window_size // subseq_size)\r\n```\r\n", "comments": ["Is your question regarding mae, mape and accuracy metrics in general? or it is, that you are suspicious of those values in your specific use case?\r\nFor the latter I cannot reproduce the behavior since the code snippet provided is incomplete.", "Ok I think what I really wanted to ask is this - are these numbers make sense to you (generally)? if not then probably something is wrong with TF outputting them (generally) [my assumption here - whatever the case - model is learning or not learning or invalid altogether - the metrics should somehow be relevant - and if they aren't I assume this is a bug]. \r\n\r\nI am going to try my best to make you a gist so you can replicate it..", "Well, usage of these metrics depends more on the task at hand. For instance ```mape``` is most commonly used in assessing forecasting models.\r\nI found this documentation useful to understand more about the pros and cons of using these metrics.\r\nSee https://towardsdatascience.com/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-2-regression-metrics-d4a1a9ba3d74\r\nWe can always select appropriate ```metrics``` argument as per our use case from ```compile``` method. Therefore not necessarily a bug on TF end."]}, {"number": 31112, "title": "NotFoundError: No registered 'ReadFile' OpKernel for GPU devices compatible with node {{node ReadFile}}", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): installed via pip\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: \r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2018 NVIDIA Corporation\r\nBuilt on Sat_Aug_25_21:08:04_Central_Daylight_Time_2018\r\nCuda compilation tools, release 10.0, V10.0.130\r\n- GPU model and memory: NVIDIA GeForce GTX 1060 3GB\r\n\r\n**Describe the current behavior**\r\n\r\nI am running the following code (it runs well on Google Colab GPU):\r\n```python\r\ndef build_dataset(boxes_img_dataframe, data_directory, augment=True, shuffle=False):\r\n    filenames_ds = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['image_name'].apply(lambda path: os.path.join(data_directory, path)))\r\n    images_ds    = filenames_ds.map(\r\n        lambda path: (tf.image.decode_jpeg(tf.io.read_file(path)) / 255) * 2 - 1\r\n    )\r\n    x1_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['x_1'])\r\n    x2_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['x_2'])\r\n    y1_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['y_1'])\r\n    y2_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['y_2'])\r\n    tmp_ds       = tf.data.Dataset.zip((images_ds, x1_ds, x2_ds, y1_ds, y2_ds))\r\n    #\"\"\"\r\n    images_ds    = tmp_ds.map(\r\n        lambda image, x1, x2, y1, y2: tf.image.resize_images(\r\n            tf.image.crop_to_bounding_box(\r\n                image,\r\n                tf.cast(x1, tf.int32),\r\n                tf.cast(y1, tf.int32),\r\n                tf.cast(x2 - x1, tf.int32),\r\n                tf.cast(y2 - y1, tf.int32)\r\n            ),\r\n            (96, 96)\r\n        )\r\n    )\r\n    if augment:\r\n        images_color_augmented_hue = images_ds.map(\r\n            lambda image: tf.image.random_hue(image, 0.08)\r\n        )\r\n        images_color_augmented_sat = images_ds.map(\r\n            lambda image: tf.image.random_saturation(image, 0.6, 1.6)\r\n        )\r\n        images_color_augmented_bri = images_ds.map(\r\n            lambda image: tf.image.random_brightness(image, 0.05)\r\n        )\r\n        images_color_augmented_con = images_ds.map(\r\n            lambda image: tf.image.random_contrast(image, 0.7, 1.3)\r\n        )\r\n        images_augmented_flipped   = images_ds.map(\r\n            lambda image: tf.image.flip_left_right(image)\r\n        )\r\n        images_augmented_rotation  = images_ds.map(\r\n            lambda image: tf.image.rot90(image, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\r\n        )\r\n        images_ds = images_ds.concatenate(images_color_augmented_hue)\r\n        images_ds = images_ds.concatenate(images_color_augmented_sat)\r\n        images_ds = images_ds.concatenate(images_color_augmented_bri)\r\n        images_ds = images_ds.concatenate(images_color_augmented_con)\r\n        images_ds = images_ds.concatenate(images_augmented_flipped)\r\n        images_ds = images_ds.concatenate(images_augmented_rotation)\r\n        images_ds = images_ds.map(lambda image: tf.clip_by_value(image, -1, 1))\r\n    ds = tf.data.Dataset.zip((images_ds, images_ds))\r\n    ds = ds.apply(tf.data.experimental.ignore_errors())\r\n    if shuffle:\r\n        ds = ds.shuffle(1000)\r\n    return ds\r\n```\r\n\r\nThis basically builds my dataset, and I call it in the model like that:\r\n\r\n```python\r\nwith tf.device('/gpu:0'):\r\n        autoencoder.fit(\r\n            dataset.batch(32),\r\n            epochs=epochs,\r\n            steps_per_epoch=steps,\r\n            shuffle=True,\r\n        )\r\n```\r\n\r\nSo actually pretty straighforward I guess.\r\n\r\nAnd when it runs, I get the following error:\r\n\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0728 11:28:51.089698 10264 deprecation_wrapper.py:119] From main.py:80: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\r\n\r\nW0728 11:28:51.129585 10264 deprecation.py:506] From C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\n2019-07-28 11:28:52.388036: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-07-28 11:28:52.403659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll\r\n2019-07-28 11:28:52.546637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce GTX 1060 3GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085\r\npciBusID: 0000:01:00.0\r\n2019-07-28 11:28:52.551575: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-07-28 11:28:52.554530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-07-28 11:28:53.229349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-28 11:28:53.233344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\r\n2019-07-28 11:28:53.235723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\r\n2019-07-28 11:28:53.237899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2112 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2019-07-28 11:29:01.339772: E tensorflow/core/common_runtime/executor.cc:641] Executor failed to create kernel. Not found: No registered 'ReadFile' OpKernel for GPU devices compatible with node {{node ReadFile}}\r\n        .  Registered:  device='CPU'\r\n\r\n         [[ReadFile]]\r\n2019-07-28 11:29:01.376815: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at iterator_ops.cc:601 : Not found: No registered 'ReadFile' OpKernel for GPU devices compatible with node {{node ReadFile}}\r\n        .  Registered:  device='CPU'\r\n\r\n         [[ReadFile]]\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1356, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1341, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1429, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'ReadFile' OpKernel for GPU devices compatible with node {{node ReadFile}}\r\n        .  Registered:  device='CPU'\r\n\r\n         [[ReadFile]]\r\n         [[MakeIterator]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 144, in <module>\r\n    main()\r\n  File \"main.py\", line 140, in main\r\n    model.train_model(latent_model, dataset, epochs, steps_per_epoch)\r\n  File \"C:\\Users\\Julien\\Documents\\Travail\\NarcisseTechnologies\\narcisse.latent\\trainer\\model.py\", line 201, in train_model\r\n    shuffle=True,\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 780, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 142, in model_iteration\r\n    input_iterator = _get_iterator(inputs, model._distribution_strategy)\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 517, in _get_iterator\r\n    return training_utils.get_iterator(inputs)\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\", line 1315, in get_iterator\r\n    initialize_iterator(iterator)\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\", line 1322, in initialize_iterator\r\n    K.get_session((init_op,)).run(init_op)\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 950, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1173, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1350, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\Julien\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1370, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'ReadFile' OpKernel for GPU devices compatible with node {{node ReadFile}}\r\n        .  Registered:  device='CPU'\r\n\r\n         [[ReadFile]]\r\n         [[MakeIterator]]\r\n```\r\n\r\nIt seems that the tf.io.read_file operation is running on the GPU, and my GPU does not support this kind of operation.\r\n\r\nThis is what I understand from the error.\r\n\r\nWhat can I do to fix this please? Is it a bug in the driver, a compatibility problem... ?", "comments": ["@asimshankar I saw that you answered similar questions. Maybe you can help with this one?", "@Bornlex \r\nIn order to expedite the trouble-shooting process, please provide complete code snippet to reproduce the issue reported here. Thanks!", "Yes of course.\r\n\r\n```python\r\nclass SampleLayer(Layer):\r\n    '''\r\n    Keras Layer to grab a random sample from a distribution (by multiplication)\r\n    Computes \"(normal)*logvar + mean\" for the vae sampling operation\r\n    (written for tf backend)\r\n\r\n    Additionally,\r\n        Applies regularization to the latent space representation.\r\n        Can perform standard regularization or B-VAE regularization.\r\n\r\n    call:\r\n        pass in mean then logvar layers to sample from the distribution\r\n        ex.\r\n            sample = SampleLayer('bvae', 16)([mean, logvar])\r\n    '''\r\n    def __init__(self, latent_regularizer='bvae', beta=100., **kwargs):\r\n        '''\r\n        args:\r\n        ------\r\n        latent_regularizer : str\r\n            Either 'bvae', 'vae', or 'no'\r\n            Determines whether regularization is applied\r\n                to the latent space representation.\r\n        beta : float\r\n            beta > 1, used for 'bvae' latent_regularizer,\r\n            (Unused if 'bvae' not selected)\r\n        ------\r\n        ex.\r\n            sample = SampleLayer('bvae', 16)([mean, logvar])\r\n        '''\r\n        if latent_regularizer.lower() in ['bvae', 'vae']:\r\n            self.reg = latent_regularizer\r\n        else:\r\n            self.reg = None\r\n    \r\n        if self.reg == 'bvae':\r\n            self.beta = beta\r\n        elif self.reg == 'vae':\r\n            self.beta = 1.\r\n\r\n        super(SampleLayer, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        # save the shape for distribution sampling\r\n        super(SampleLayer, self).build(input_shape) # needed for layers\r\n\r\n    def call(self, x, training=None):\r\n        if len(x) != 2:\r\n            raise Exception('input layers must be a list: mean and logvar')\r\n        if len(x[0].shape) != 2 or len(x[1].shape) != 2:\r\n            raise Exception('input shape is not a vector [batchSize, latentSize]')\r\n\r\n        mean = x[0]\r\n        logvar = x[1]\r\n\r\n        # trick to allow setting batch at train/eval time\r\n        if mean.shape[0].value == None or  logvar.shape[0].value == None:\r\n            return mean + 0*logvar # Keras needs the *0 so the gradinent is not None\r\n\r\n        if self.reg is not None:\r\n            # kl divergence:\r\n            latent_loss = -0.5 * (1 + logvar\r\n                                - K.square(mean)\r\n                                - K.exp(logvar))\r\n            latent_loss = K.sum(latent_loss, axis=-1) # sum over latent dimension\r\n            latent_loss = K.mean(latent_loss, axis=0) # avg over batch\r\n\r\n            # use beta to force less usage of vector space:\r\n            latent_loss = self.beta * latent_loss\r\n            self.add_loss(latent_loss, x)\r\n\r\n        def reparameterization_trick():\r\n            epsilon = K.random_normal(shape=logvar.shape,\r\n                              mean=0., logvar=1.)\r\n            stddev = K.exp(logvar*0.5)\r\n            return mean + stddev * epsilon * inf\r\n\r\n        return K.in_train_phase(reparameterization_trick, mean + 0*logvar, training=training)\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape[0]\r\n\r\nclass CustomAutoEncoder(object):\r\n    def __init__(self, latent_size, beta):\r\n        self.shape       = (96, 96, 3)\r\n        self.latent_size = 50\r\n        self.beta        = 1\r\n        self.encoder = self.build_encoder()\r\n        self.decoder = self.build_decoder()\r\n        self.ae      = Model(self.encoder.inputs, self.decoder(self.encoder.outputs))\r\n        self.batch   = 32\r\n    \r\n    def build_encoder(self):\r\n        encoder_input = Input((self.shape))\r\n        x = Conv2D(64, (5, 5), strides=(3, 3), padding='same', kernel_initializer='glorot_uniform')(encoder_input)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2D(128, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2D(256, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2D(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2D(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        mean   = Conv2D(self.latent_size, (1, 1), padding='same')(x)\r\n        mean   = GlobalAveragePooling2D()(mean)\r\n        logvar = Conv2D(self.latent_size, (1, 1), padding='same')(x)\r\n        logvar = GlobalAveragePooling2D()(logvar)\r\n        x = SampleLayer('bvae', self.beta)([mean, logvar])\r\n        return Model(encoder_input, x)\r\n    \r\n    def build_decoder(self):\r\n        encoder_input = Input((self.latent_size,))\r\n        x = Reshape((1, 1, self.latent_size))(encoder_input)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(64, (5, 5), strides=(3, 3), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        \r\n        x = Conv2D(self.shape[-1], (1, 1), 1, padding='same', activation='tanh')(x)\r\n        return Model(encoder_input, x)\r\n\r\ndef build_model(latent_size, beta):\r\n    bvae = CustomAutoEncoder(latent_size, beta)\r\n    encoder = bvae.encoder\r\n    decoder = bvae.decoder\r\n    autoencoder = bvae.ae\r\n    autoencoder.compile(\r\n        optimizer=optimizers.Adam(),\r\n        loss='mean_absolute_error'\r\n    )\r\n    return autoencoder\r\n\r\ndef train_model(autoencoder, dataset, epochs, steps):\r\n    with tf.device('/gpu:0'):\r\n        autoencoder.fit(\r\n            dataset.batch(32),\r\n            epochs=epochs,\r\n            steps_per_epoch=steps,\r\n            shuffle=True,\r\n        )\r\n\r\ndef build_dataset(boxes_img_dataframe, data_directory, augment=True, shuffle=False):\r\n    filenames_ds = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['image_name'].apply(lambda path: os.path.join(data_directory, path)))\r\n    images_ds    = filenames_ds.map(\r\n        lambda path: (tf.image.decode_jpeg(tf.io.read_file(path)) / 255) * 2 - 1\r\n    )\r\n    x1_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['x_1'])\r\n    x2_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['x_2'])\r\n    y1_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['y_1'])\r\n    y2_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['y_2'])\r\n    tmp_ds       = tf.data.Dataset.zip((images_ds, x1_ds, x2_ds, y1_ds, y2_ds))\r\n    #\"\"\"\r\n    images_ds    = tmp_ds.map(\r\n        lambda image, x1, x2, y1, y2: tf.image.resize_images(\r\n            tf.image.crop_to_bounding_box(\r\n                image,\r\n                tf.cast(x1, tf.int32),\r\n                tf.cast(y1, tf.int32),\r\n                tf.cast(x2 - x1, tf.int32),\r\n                tf.cast(y2 - y1, tf.int32)\r\n            ),\r\n            (96, 96)\r\n        )\r\n    )\r\n    if augment:\r\n        images_color_augmented_hue = images_ds.map(\r\n            lambda image: tf.image.random_hue(image, 0.08)\r\n        )\r\n        images_color_augmented_sat = images_ds.map(\r\n            lambda image: tf.image.random_saturation(image, 0.6, 1.6)\r\n        )\r\n        images_color_augmented_bri = images_ds.map(\r\n            lambda image: tf.image.random_brightness(image, 0.05)\r\n        )\r\n        images_color_augmented_con = images_ds.map(\r\n            lambda image: tf.image.random_contrast(image, 0.7, 1.3)\r\n        )\r\n        images_augmented_flipped   = images_ds.map(\r\n            lambda image: tf.image.flip_left_right(image)\r\n        )\r\n        images_augmented_rotation  = images_ds.map(\r\n            lambda image: tf.image.rot90(image, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\r\n        )\r\n        images_ds = images_ds.concatenate(images_color_augmented_hue)\r\n        images_ds = images_ds.concatenate(images_color_augmented_sat)\r\n        images_ds = images_ds.concatenate(images_color_augmented_bri)\r\n        images_ds = images_ds.concatenate(images_color_augmented_con)\r\n        images_ds = images_ds.concatenate(images_augmented_flipped)\r\n        images_ds = images_ds.concatenate(images_augmented_rotation)\r\n        images_ds = images_ds.map(lambda image: tf.clip_by_value(image, -1, 1))\r\n    ds = tf.data.Dataset.zip((images_ds, images_ds))\r\n    ds = ds.apply(tf.data.experimental.ignore_errors())\r\n    if shuffle:\r\n        ds = ds.shuffle(1000)\r\n    return ds\r\n\r\n\r\nboxes_img = pd.read_csv(os.path.join(args.data_dir, 'list_bbox.txt'), sep='\\s+', skiprows=1, dtype={\r\n        'image_name': str,\r\n        'x_1': np.int32,\r\n        'x_2': np.int32,\r\n        'y_1': np.int32,\r\n        'y_2': np.int32,\r\n    })\r\n\r\n    tf.keras.callbacks.TensorBoard(log_dir=os.path.join(args.save_path, args.log_dir), histogram_freq=0, write_graph=True, write_images=True)\r\n\r\n    epochs = args.epochs\r\n    steps_per_epoch = args.steps_per_epoch\r\n    dataset = build_dataset(boxes_img, args.data_dir, augment=args.augment)\r\n    dataset = dataset.repeat(epochs)\r\n    latent_model = build_model(args.latent_size, args.beta)\r\n    train_model(latent_model, dataset, epochs, steps_per_epoch)\r\n```", "@ravikyram is it enough?", "@Bornlex \r\nI tried to reproduce the issue .I am getting the  error `NameError: name 'args' is not defined`.\r\nPlease, help me with the reproducible code and the  list_bbox.txt file.Thanks!", "```python\r\nimport os\r\nimport sys\r\nimport cv2\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom PIL import Image\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n\r\nfrom IPython import display\r\n\r\nfrom tensorflow.keras.applications.resnet50 import ResNet50\r\nfrom tensorflow.keras.layers import (\r\n    Dense,\r\n    Dropout,\r\n    Flatten,\r\n    GlobalAveragePooling2D,\r\n    Conv2D,\r\n    Input,\r\n    MaxPooling2D,\r\n    UpSampling2D,\r\n    Reshape,\r\n    BatchNormalization,\r\n    LeakyReLU,\r\n    Add,\r\n    Conv2DTranspose,\r\n    Activation\r\n)\r\nfrom tensorflow.keras import optimizers\r\nfrom tensorflow.keras import regularizers\r\nfrom tensorflow.keras.models import Model, Sequential, load_model\r\nfrom tensorflow.keras.callbacks import TensorBoard\r\nfrom tensorflow.python.keras.layers import Layer\r\nfrom tensorflow.python.keras import backend as K\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\n\r\n\r\nclass SampleLayer(Layer):\r\n    '''\r\n    Keras Layer to grab a random sample from a distribution (by multiplication)\r\n    Computes \"(normal)*logvar + mean\" for the vae sampling operation\r\n    (written for tf backend)\r\n\r\n    Additionally,\r\n        Applies regularization to the latent space representation.\r\n        Can perform standard regularization or B-VAE regularization.\r\n\r\n    call:\r\n        pass in mean then logvar layers to sample from the distribution\r\n        ex.\r\n            sample = SampleLayer('bvae', 16)([mean, logvar])\r\n    '''\r\n    def __init__(self, latent_regularizer='bvae', beta=100., **kwargs):\r\n        '''\r\n        args:\r\n        ------\r\n        latent_regularizer : str\r\n            Either 'bvae', 'vae', or 'no'\r\n            Determines whether regularization is applied\r\n                to the latent space representation.\r\n        beta : float\r\n            beta > 1, used for 'bvae' latent_regularizer,\r\n            (Unused if 'bvae' not selected)\r\n        ------\r\n        ex.\r\n            sample = SampleLayer('bvae', 16)([mean, logvar])\r\n        '''\r\n        if latent_regularizer.lower() in ['bvae', 'vae']:\r\n            self.reg = latent_regularizer\r\n        else:\r\n            self.reg = None\r\n    \r\n        if self.reg == 'bvae':\r\n            self.beta = beta\r\n        elif self.reg == 'vae':\r\n            self.beta = 1.\r\n\r\n        super(SampleLayer, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        # save the shape for distribution sampling\r\n        super(SampleLayer, self).build(input_shape) # needed for layers\r\n\r\n    def call(self, x, training=None):\r\n        if len(x) != 2:\r\n            raise Exception('input layers must be a list: mean and logvar')\r\n        if len(x[0].shape) != 2 or len(x[1].shape) != 2:\r\n            raise Exception('input shape is not a vector [batchSize, latentSize]')\r\n\r\n        mean = x[0]\r\n        logvar = x[1]\r\n\r\n        # trick to allow setting batch at train/eval time\r\n        if mean.shape[0].value == None or  logvar.shape[0].value == None:\r\n            return mean + 0*logvar # Keras needs the *0 so the gradinent is not None\r\n\r\n        if self.reg is not None:\r\n            # kl divergence:\r\n            latent_loss = -0.5 * (1 + logvar\r\n                                - K.square(mean)\r\n                                - K.exp(logvar))\r\n            latent_loss = K.sum(latent_loss, axis=-1) # sum over latent dimension\r\n            latent_loss = K.mean(latent_loss, axis=0) # avg over batch\r\n\r\n            # use beta to force less usage of vector space:\r\n            latent_loss = self.beta * latent_loss\r\n            self.add_loss(latent_loss, x)\r\n\r\n        def reparameterization_trick():\r\n            epsilon = K.random_normal(shape=logvar.shape,\r\n                              mean=0., logvar=1.)\r\n            stddev = K.exp(logvar*0.5)\r\n            return mean + stddev * epsilon * inf\r\n\r\n        return K.in_train_phase(reparameterization_trick, mean + 0*logvar, training=training)\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape[0]\r\n\r\nclass CustomAutoEncoder(object):\r\n    def __init__(self, latent_size, beta):\r\n        self.shape       = (96, 96, 3)\r\n        self.latent_size = 50\r\n        self.beta        = 1\r\n        self.encoder = self.build_encoder()\r\n        self.decoder = self.build_decoder()\r\n        self.ae      = Model(self.encoder.inputs, self.decoder(self.encoder.outputs))\r\n        self.batch   = 32\r\n    \r\n    def build_encoder(self):\r\n        encoder_input = Input((self.shape))\r\n        x = Conv2D(64, (5, 5), strides=(3, 3), padding='same', kernel_initializer='glorot_uniform')(encoder_input)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2D(128, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2D(256, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2D(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2D(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        mean   = Conv2D(self.latent_size, (1, 1), padding='same')(x)\r\n        mean   = GlobalAveragePooling2D()(mean)\r\n        logvar = Conv2D(self.latent_size, (1, 1), padding='same')(x)\r\n        logvar = GlobalAveragePooling2D()(logvar)\r\n        x = SampleLayer('bvae', self.beta)([mean, logvar])\r\n        return Model(encoder_input, x)\r\n    \r\n    def build_decoder(self):\r\n        encoder_input = Input((self.latent_size,))\r\n        x = Reshape((1, 1, self.latent_size))(encoder_input)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(64, (5, 5), strides=(3, 3), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        x = BatchNormalization(momentum=0.5)(x)\r\n        x = Activation('relu')(x)\r\n        \r\n        x = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(x)\r\n        \r\n        x = Conv2D(self.shape[-1], (1, 1), 1, padding='same', activation='tanh')(x)\r\n        return Model(encoder_input, x)\r\n\r\ndef build_model(latent_size, beta):\r\n    bvae = CustomAutoEncoder(latent_size, beta)\r\n    encoder = bvae.encoder\r\n    decoder = bvae.decoder\r\n    autoencoder = bvae.ae\r\n    autoencoder.compile(\r\n        optimizer=optimizers.Adam(),\r\n        loss='mean_absolute_error'\r\n    )\r\n    return autoencoder\r\n\r\ndef train_model(autoencoder, dataset, epochs, steps):\r\n    with tf.device('/gpu:0'):\r\n        autoencoder.fit(\r\n            dataset.batch(32),\r\n            epochs=epochs,\r\n            steps_per_epoch=steps,\r\n            shuffle=True,\r\n        )\r\n\r\ndef build_dataset(boxes_img_dataframe, data_directory, augment=True, shuffle=False):\r\n    filenames_ds = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['image_name'].apply(lambda path: os.path.join(data_directory, path)))\r\n    images_ds    = filenames_ds.map(\r\n        lambda path: (tf.image.decode_jpeg(tf.io.read_file(path)) / 255) * 2 - 1\r\n    )\r\n    x1_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['x_1'])\r\n    x2_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['x_2'])\r\n    y1_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['y_1'])\r\n    y2_ds        = tf.data.Dataset.from_tensor_slices(boxes_img_dataframe['y_2'])\r\n    tmp_ds       = tf.data.Dataset.zip((images_ds, x1_ds, x2_ds, y1_ds, y2_ds))\r\n    #\"\"\"\r\n    images_ds    = tmp_ds.map(\r\n        lambda image, x1, x2, y1, y2: tf.image.resize_images(\r\n            tf.image.crop_to_bounding_box(\r\n                image,\r\n                tf.cast(x1, tf.int32),\r\n                tf.cast(y1, tf.int32),\r\n                tf.cast(x2 - x1, tf.int32),\r\n                tf.cast(y2 - y1, tf.int32)\r\n            ),\r\n            (96, 96)\r\n        )\r\n    )\r\n    if augment:\r\n        images_color_augmented_hue = images_ds.map(\r\n            lambda image: tf.image.random_hue(image, 0.08)\r\n        )\r\n        images_color_augmented_sat = images_ds.map(\r\n            lambda image: tf.image.random_saturation(image, 0.6, 1.6)\r\n        )\r\n        images_color_augmented_bri = images_ds.map(\r\n            lambda image: tf.image.random_brightness(image, 0.05)\r\n        )\r\n        images_color_augmented_con = images_ds.map(\r\n            lambda image: tf.image.random_contrast(image, 0.7, 1.3)\r\n        )\r\n        images_augmented_flipped   = images_ds.map(\r\n            lambda image: tf.image.flip_left_right(image)\r\n        )\r\n        images_augmented_rotation  = images_ds.map(\r\n            lambda image: tf.image.rot90(image, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\r\n        )\r\n        images_ds = images_ds.concatenate(images_color_augmented_hue)\r\n        images_ds = images_ds.concatenate(images_color_augmented_sat)\r\n        images_ds = images_ds.concatenate(images_color_augmented_bri)\r\n        images_ds = images_ds.concatenate(images_color_augmented_con)\r\n        images_ds = images_ds.concatenate(images_augmented_flipped)\r\n        images_ds = images_ds.concatenate(images_augmented_rotation)\r\n        images_ds = images_ds.map(lambda image: tf.clip_by_value(image, -1, 1))\r\n    ds = tf.data.Dataset.zip((images_ds, images_ds))\r\n    ds = ds.apply(tf.data.experimental.ignore_errors())\r\n    if shuffle:\r\n        ds = ds.shuffle(1000)\r\n    return ds\r\n\r\n\r\nboxes_img = pd.read_csv(os.path.join(\"/path/to/data\", 'list_bbox.txt'), sep='\\s+', skiprows=1, dtype={\r\n        'image_name': str,\r\n        'x_1': np.int32,\r\n        'x_2': np.int32,\r\n        'y_1': np.int32,\r\n        'y_2': np.int32,\r\n    })\r\n\r\n    epochs = 100\r\n    steps_per_epoch = 1000\r\n    dataset = build_dataset(boxes_img, \"/path/to/data\")\r\n    dataset = dataset.repeat(epochs)\r\n    latent_model = build_model(100, 10)\r\n    train_model(latent_model, dataset, epochs, steps_per_epoch)\r\n```\r\n\r\nThe dataset I use is the DeepFashion dataset (in Img folder here, the img.zip).\r\nThe list_bbox.txt file is located in the Anno folder, same link.\r\n\r\nhttps://drive.google.com/drive/folders/0B7EVK8r0v71pWGplNFhjc01NbzQ\r\n\r\n\r\n@ravikyram sorry, I was trying to give you the minimum amount of code necessary so you have an idea of the problem without having to read a big bunch of code.", "@jvishnuvardhan Hello. Do you have a rough idea of what is the cause of this?\r\nIs it a bad installation, bad version, not compatible hardware, bad code?", "@Bornlex Sorry for the late response. Could you simple standalone code with smaller dataset. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31112\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31112\">No</a>\n"]}, {"number": 31111, "title": "absl", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new/choose). Please provide all the information it asks. Thank you.\r\n"]}, {"number": 31110, "title": "keras model fit() crash with large batch_size and 0 validation_split", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-gpu 1.13.1\r\n- Python version: 3.6.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10/7.4.1\r\n- GPU model and memory: GTX 1080Ti, 10G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nRaise an error when fitting tf.keras model when the training dataset size less then batch_size and validation_split is 0.0.\r\nIf using a batch_size less then dataset size or setting validation_split, the fitting is good.\r\nUsing original keras, fitting is good in any case.\r\nError is :\r\n```\r\nTraceback (most recent call last):\r\n  File \"crf_tf.py\", line 123, in <module>\r\n    model.fit(x, y, batch_size=16, epochs=50, validation_split=0.0)\r\n  File \"/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 880, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 329, in model_iteration\r\n    batch_outs = f(ins_batch)\r\n  File \"/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3076, in __call__\r\n    run_metadata=self.run_metadata)\r\n  File \"/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\r\n    run_metadata_ptr)\r\n  File \"/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[0], expected a dimension of 1, got 2\r\n         [[{{node metrics/crf_accuracy/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_bool_Squeeze}}]]\r\n         [[{{node crf/cond/Maximum}}]]\r\n```\r\n**Describe the expected behavior**\r\nFit successfully.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import backend as K\r\n# import keras\r\n# from keras import backend as K\r\nimport numpy as np\r\n\r\n\r\nclass CRF(keras.layers.Layer):\r\n\r\n    def __init__(self, num_tags, **kwargs):\r\n        super(CRF, self).__init__(**kwargs)\r\n        self.num_tags = num_tags\r\n        self.input_spec = keras.layers.InputSpec(min_ndim=3)\r\n        self.supports_masking = True\r\n\r\n    def get_config(self):\r\n        config = {\r\n            'num_tags': self.num_tags,\r\n        }\r\n        base_config = super(CRF, self).get_config()\r\n        return dict(list(base_config.items()) + list(config.items()))\r\n\r\n    def build(self, input_shape):\r\n        assert len(input_shape) == 3\r\n        if input_shape[-1] is None:\r\n            raise ValueError('The last dimension of the inputs to `CRF` '\r\n                             'should be defined. Found `None`.')\r\n        if input_shape[-1] != self.num_tags:\r\n            raise ValueError('The last dimension of the input shape must be equal to output'\r\n                             ' shape. Use a linear layer if needed.')\r\n        self.transitions = self.add_weight(name='transitions',\r\n                                           shape=[self.num_tags,\r\n                                                  self.num_tags],\r\n                                           initializer=\"glorot_uniform\",\r\n                                           trainable=True)\r\n        self.built = True\r\n\r\n    def call(self, inputs, mask=None):\r\n        seq_lens = get_seq_lens(inputs, mask)\r\n        viterbi_sequence, _ = tf.contrib.crf.crf_decode(inputs,\r\n                                                        self.transitions,\r\n                                                        seq_lens)\r\n        outputs = K.one_hot(viterbi_sequence, self.num_tags)\r\n        return K.in_train_phase(inputs, outputs)\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape[:2] + (self.num_tags,)\r\n\r\n    def compute_mask(self, inputs, mask=None):\r\n        if mask is not None:\r\n            return K.any(mask, axis=1)\r\n        return mask\r\n\r\n\r\ndef get_seq_lens(inputs, mask=None):\r\n    if mask is not None:\r\n        return K.sum(K.cast(mask, dtype='int32'), axis=-1)\r\n    else:\r\n        shape = K.int_shape(inputs)\r\n        return K.ones(shape[:-1], dtype='int32') * shape[-1]\r\n\r\n\r\ndef crf_loss(y_true, y_pred):\r\n    crf, idx = y_pred._keras_history[:2]\r\n    inputs = crf.get_input_at(idx)\r\n    mask = crf.get_input_mask_at(idx)\r\n    seq_lens = get_seq_lens(inputs, mask)\r\n    y_true = K.cast(K.argmax(y_true, axis=-1), dtype='int32')\r\n    log_likelihood, crf.transitions = \\\r\n        tf.contrib.crf.crf_log_likelihood(y_pred,\r\n                                          y_true,\r\n                                          seq_lens,\r\n                                          transition_params=crf.transitions)\r\n    return K.mean(-log_likelihood)\r\n\r\n\r\ndef crf_accuracy(y_true, y_pred):\r\n    crf, idx = y_pred._keras_history[:2]\r\n    inputs = crf.get_input_at(idx)\r\n    mask = crf.get_input_mask_at(idx)\r\n    seq_lens = get_seq_lens(inputs, mask)\r\n    viterbi_sequence, _ = tf.contrib.crf.crf_decode(inputs,\r\n                                                    crf.transitions,\r\n                                                    seq_lens)\r\n    y_true = K.cast(K.argmax(y_true, -1), dtype='int32')\r\n    judge = K.cast(K.equal(viterbi_sequence, y_true), K.floatx())\r\n    if mask is None:\r\n        return K.mean(judge)\r\n    else:\r\n        mask = K.cast(mask, K.floatx())\r\n        return K.sum(judge * mask) / K.sum(mask)\r\n\r\n\r\nnum_words = 20\r\nnum_features = 100\r\nnum_tags = 5\r\n\r\ninputs = keras.layers.Input(shape=(None,))\r\nembedding = keras.layers.Embedding(10, num_features, mask_zero=True)(inputs)\r\nscores = keras.layers.TimeDistributed(keras.layers.Dense(num_tags))(embedding)\r\ncrf = CRF(num_tags)\r\noutputs = crf(scores)\r\nmodel = keras.models.Model(inputs, outputs)\r\n\r\nmodel.summary()\r\n\r\nx = np.array([[1, 2, 3, 4, 0, 0], [4, 5, 6, 0, 0, 0]])\r\ny = np.array([[1, 3, 4, 2, 0, 0], [2, 1, 3, 0, 0, 0]])\r\ny = np.eye(num_tags)[y]\r\n\r\nprint(x)\r\nprint(x.shape)\r\nprint(y)\r\nprint(y.shape)\r\n\r\nmodel.compile(optimizer=\"adam\",\r\n              loss=crf_loss,\r\n              metrics=[crf_accuracy])\r\n\r\nmodel.fit(x, y, batch_size=16, epochs=50, validation_split=0.0)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Issue replicating with TF version-gpu 1.13, please find the gist of [Colab](https://colab.sandbox.google.com/drive/1JHRJCgGmImIasATBbxnxaMFZuXCrysLv#scrollTo=Qw6wX1NdWhB8). Thanks!", "> Issue replicating with TF version-gpu 1.13, please find the gist of [Colab](https://colab.sandbox.google.com/drive/1JHRJCgGmImIasATBbxnxaMFZuXCrysLv#scrollTo=Qw6wX1NdWhB8). Thanks!\r\n\r\n@anush-o Thanks, but your gist is private access only(", "Please find updated [Gist](https://colab.sandbox.google.com/gist/ymodak/c1d83748736e87fdacb7c1da4c0632c3/github31110.ipynb) using TF 1.15", "@linhx13 Thank you for the issue. From the gist it looks like the issue is independent of validation_split=0, batch_size. I removed your custom loss and metric to make sure that the model works first and there are errors in the model. It would be great if you can provide a minimal repro, if there is still an issue here. Closing for now, please feel free to reopen if required.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31110\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31110\">No</a>\n"]}, {"number": 31109, "title": "dilated tf.keras.layers.Conv2D can't estimate output shape", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nwhen creating tf.keras.Model with functional api, dilated convolution of tf.keras.layers can't estimate the output shape.\r\n\r\n**Describe the expected behavior**\r\n\r\nthe dilated convolution can estimate the output shape as convolution op does.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ninput= tf.keras.Input([100,100,3])\r\nresults = tf.keras.layers.Conv2D(filters = 10, kernel_size = (3,3), padding = 'same', dilation_rate = 2)(input)\r\nprint(results.shape)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I have tried on colab with TF version 2.0 beta1 and was able to reproduce the issue.Please, find the [gist](https://colab.research.google.com/drive/10utd0A3GuBGAvIf8RnMQVFRp2QjAbFPC) here.Thanks!", "This is fixed in latest 2.0 nightly build version' 2.0.0-dev20190729'. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31109\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31109\">No</a>\n"]}, {"number": 31108, "title": "Bulld tensorflow from source for Raspberry PI (Python 3.7)", "body": "I successfully have built tensorflow 2.0.0b1 for raspberry PI using the guideline\r\nhttps://www.tensorflow.org/install/source_rpi and command\r\n\r\nsudo CI_DOCKER_EXTRA_PARAMS=\"-e CI_BUILD_PYTHON=python3 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.7\" tensorflow/tools/ci_build/ci_build.sh PI-PYTHON3 tensorflow/tools/ci_build/pi/build_raspberry_pi.sh\r\n\r\nHowever, generated wheel file is called tensorflow-2.0.0b1-cp34-none-linux_armv7l.whl so I suppose it is for python 3.4\r\n\r\nIs there a way to tell installer to use python 3.7 during wheel generation?\r\n\r\n\r\n", "comments": ["Hello, how did you do to make it work with Python 3.7?", "Look at these releases\r\nhttps://github.com/lhelontra/tensorflow-on-arm/releases", "Please check this.\r\n\r\nhttps://www.tensorflow.org/install/source_rpi#python-3.7"]}, {"number": 31107, "title": "Model failed to serialize as JSON. Ignoring 'Not JSON Serializable:'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- Ubuntu 18.04:\r\n- TensorFlow installed from binary:\r\n- TensorFlow version (1.14):\r\n- Python version: (3.6)\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GTX 1080Ti\r\n\r\n\r\n**Describe the current behavior**\r\n```\r\nW0728 12:29:27.513279 140257532127040 summary_ops_v2.py:1110] Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', b'\\nNreplica_1/Fast_SCNN/tf_op_layer_Relu/replica_0/Fast_SCNN/tf_op_layer_Relu/Relu\\x12\\x04Relu\\x1a\\x1ebatch_normalization/cond/Merge*\\x07\\n\\x01T\\x12\\x020\\x01')\r\n```\r\n**Describe the expected behavior**\r\nRunning without issue\r\n\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\ndef conv_block(inputs, conv_type, filter_count, kernel_size, strides, padding='same', relu=True):\r\n\r\n  if(conv_type == 'ds'):\r\n    x = tf.keras.layers.SeparableConv2D(filter_count, kernel_size, padding=padding, strides = strides)(inputs)\r\n  else:\r\n    x = tf.keras.layers.Conv2D(filter_count, kernel_size, padding=padding, strides = strides)(inputs)\r\n\r\n  x = tf.keras.layers.BatchNormalization()(x)\r\n\r\n  if (relu):\r\n    x = tf.keras.activations.relu(x)\r\n\r\n  return x\r\n\r\n\r\ndef _res_bottleneck(inputs, filters, kernel, t, s, r=False):\r\n\r\n\r\n    tchannel = tf.keras.backend.int_shape(inputs)[-1] * t\r\n\r\n    x = conv_block(inputs, 'conv', tchannel, (1, 1), strides=(1, 1))\r\n\r\n    x = tf.keras.layers.DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\r\n    x = tf.keras.layers.BatchNormalization()(x)\r\n    x = tf.keras.activations.relu(x)\r\n\r\n    x = conv_block(x, 'conv', filters, (1, 1), strides=(1, 1), padding='same', relu=False)\r\n\r\n    if r:\r\n        x = tf.keras.layers.add([x, inputs])\r\n    return x\r\n\r\n\r\ndef bottleneck_block(inputs, filters, kernel, t, strides, n):\r\n    x = _res_bottleneck(inputs, filters, kernel, t, strides)\r\n\r\n    for i in range(1, n):\r\n        x = _res_bottleneck(x, filters, kernel, t, 1, True)\r\n\r\n    return x\r\n\r\ndef pyramid_pooling_block(input_tensor, bin_sizes,input_height, input_width):\r\n    # concat_list = []\r\n    width = input_width//32\r\n    height = input_height//32\r\n    # x = tf.keras.layers.Lambda(lambda x: tf.image.resize(x, (height, width)))(input_tensor)\r\n    concat_list=[input_tensor]\r\n    for bin_size in bin_sizes:\r\n        x = tf.keras.layers.AveragePooling2D(pool_size=(height // bin_size, width // bin_size),\r\n                                             strides=(height // bin_size, width // bin_size))(input_tensor)\r\n        x = tf.keras.layers.Conv2D(128, 3, 2, padding='same')(x)\r\n        x = tf.keras.layers.Lambda(lambda x: tf.image.resize(x, (height, width)))(x)\r\n\r\n        concat_list.append(x)\r\n    \r\n    return tf.keras.layers.concatenate(concat_list)\r\n\r\n\r\n\r\ndef buildFastScnn(input_height, input_width, input_channel, n_classes, weights_path=None):\r\n\r\n    input_layer = tf.keras.layers.Input(shape=(input_height, input_width, input_channel), name ='input_layer')\r\n\r\n    lds_layer = conv_block(input_layer, 'conv', 32, (3, 3), strides = (2, 2))\r\n    lds_layer = conv_block(lds_layer, 'ds', 48, (3, 3), strides = (2, 2))\r\n    lds_layer = conv_block(lds_layer, 'ds', 64, (3, 3), strides = (2, 2))\r\n\r\n \r\n    gfe_layer = bottleneck_block(lds_layer, 64, (3, 3), t=6, strides=2, n=3)\r\n    gfe_layer = bottleneck_block(gfe_layer, 96, (3, 3), t=6, strides=2, n=3)\r\n    gfe_layer = bottleneck_block(gfe_layer, 128, (3, 3), t=6, strides=1, n=3)\r\n    gfe_layer = pyramid_pooling_block(gfe_layer, [2,4,6,8],input_height, input_width)\r\n\r\n\r\n    ff_layer1 = conv_block(lds_layer, 'conv', 128, (1,1), padding='same', strides= (1,1), relu=False)\r\n\r\n    ff_layer2 = tf.keras.layers.UpSampling2D((4, 4))(gfe_layer)\r\n    ff_layer2 = tf.keras.layers.DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same')(ff_layer2)\r\n    ff_layer2 = tf.keras.layers.BatchNormalization()(ff_layer2)\r\n    ff_layer2 = tf.keras.activations.relu(ff_layer2)\r\n    ff_layer2 = tf.keras.layers.Conv2D(128, 1, 1, padding='same', activation=None)(ff_layer2)\r\n\r\n    ff_final = tf.keras.layers.add([ff_layer1, ff_layer2])\r\n    ff_final = tf.keras.layers.BatchNormalization()(ff_final)\r\n    ff_final = tf.keras.activations.relu(ff_final)\r\n\r\n\r\n    classifier = tf.keras.layers.SeparableConv2D(128, (3, 3), padding='same', strides = (1, 1), name = 'DSConv1_classifier')(ff_final)\r\n    classifier = tf.keras.layers.BatchNormalization()(classifier)\r\n    classifier = tf.keras.activations.relu(classifier)\r\n\r\n    classifier = tf.keras.layers.SeparableConv2D(128, (3, 3), padding='same', strides = (1, 1), name = 'DSConv2_classifier')(classifier)\r\n    classifier = tf.keras.layers.BatchNormalization()(classifier)\r\n    classifier = tf.keras.activations.relu(classifier)\r\n\r\n\r\n    classifier = tf.keras.layers.Conv2D(n_classes, (1, 1), padding='same', strides=(1, 1),name = 'Conv2_classifier')(classifier)\r\n    classifier = tf.keras.layers.BatchNormalization()(classifier)\r\n    classifier = tf.keras.activations.relu(classifier)\r\n    \r\n    classifier = tf.keras.layers.Dropout(0.3)(classifier)\r\n    classifier = tf.keras.layers.UpSampling2D((8, 8))(classifier)\r\n    classifier = tf.keras.activations.softmax(classifier)\r\n    \r\n\r\n    fast_scnn = tf.keras.Model(inputs = input_layer , outputs = classifier, name = 'Fast_SCNN')\r\n    if weights_path is not None:\r\n        fast_scnn.load_weights(weights_path, by_name=True)\r\n    return fast_scnn\r\n    \r\n    \r\nnet=buildFastScnn(800, 1600, 3, 20, weights_path=None)\r\ncheckpoint = ModelCheckpoint('output_il/weights.{epoch:03d}-{categorical_accuracy:.3f}.h5',\r\n                             monitor='categorical_accuracy',\r\n                             mode='max',\r\n                             verbose=1,save_weights_only=True)\r\ntensorboard = TensorBoard(batch_size=opt.batch_size)\r\noptimizer = tf.keras.optimizers.SGD(momentum=0.9, lr=0.045)\r\nnet.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\r\nnet.fit_generator(train_generator, steps_per_epoch=None, epochs=opt.n_epochs, callbacks=[checkpoint, tensorboard],\r\n                    validation_data=val_generator, validation_steps=None, workers=12,\r\n                    use_multiprocessing=True, shuffle=True, max_queue_size=12, initial_epoch=opt.epoch)\r\n```\r\n**Other info / logs**\r\nchecked these\r\n[1](https://stackoverflow.com/questions/56804384/tf-keras-model-save-throws-not-json-serializable-when-dtype-of-input-is-uint8)\r\n[2](https://github.com/keras-team/keras/issues/9342)\r\n[3](https://github.com/keras-team/keras/issues/11110)\r\n[4](https://github.com/tensorflow/tensorflow/issues/27112)\r\n", "comments": ["I believe this is fixed by https://github.com/tensorflow/tensorflow/commit/7cc180f107f142432358ac33787466de90afd776#diff-8eb7e20502209f082d0cb15119a50413.\r\n\r\nIf you don't like using nightly, you can use Python 2 or wrap everything in Lambda layers.", "> I believe this is fixed by [7cc180f#diff-8eb7e20502209f082d0cb15119a50413](https://github.com/tensorflow/tensorflow/commit/7cc180f107f142432358ac33787466de90afd776#diff-8eb7e20502209f082d0cb15119a50413).\r\n> \r\n> If you don't like using nightly, you can use Python 2 or wrap everything in Lambda layers.\r\n\r\nHow can I apply this on 1.14, like a patch?\r\nor just need to edit `tensorflow/python/keras/engine/base_layer.py` and apply this `https://github.com/tensorflow/tensorflow/commit/7cc180f107f142432358ac33787466de90afd776#diff-8eb7e20502209f082d0cb15119a50413`", "You can use nightly: https://pypi.org/project/tf-nightly/ or https://pypi.org/project/tf-nightly-2.0-preview/. There are corresponding gpu versions, too.", "```pip install tf-nightly-gpu``` since you are using TF 1.X", "> I believe this is fixed by [7cc180f#diff-8eb7e20502209f082d0cb15119a50413](https://github.com/tensorflow/tensorflow/commit/7cc180f107f142432358ac33787466de90afd776#diff-8eb7e20502209f082d0cb15119a50413).\r\n> \r\n> If you don't like using nightly, you can use Python 2 or wrap everything in Lambda layers.\r\n\r\nThis commit seems to have introduced https://github.com/tensorflow/tensorflow/issues/31272 .", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "This problem is closely related to #31272 \u2026 I don't think it should be closed yet.\r\nThe serialization code needs to be changed, e.g. by using base64-encoding; which however would introduce non-backward-compatibility to currently saved models, I guess; someone who can do architecture decisions should look into this \u2026", "The options provided are quite frustrating. Using python 2 or weaker versions might not be the best option, but fixing the bug in the current version"]}, {"number": 31106, "title": "speedup reduce op grads when keep_dims=True", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F31106) for more info**.\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F31106) for more info**.\n\n<!-- ok -->", "I signed it!", "We need to roll this back because of the TF forward compatibility policy.", "@alextp What is this incompatible with?", "Some graph rewriting packages were not expecting broadcast_to and crashed;\nso we need to add an if with forward compatibility and do the new thing and\notherwise do the old thing.\n\nOn Tue, Aug 20, 2019 at 9:05 PM Eric Junyuan Xie <notifications@github.com>\nwrote:\n\n> @alextp <https://github.com/alextp> What is this incompatible with?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/31106?email_source=notifications&email_token=AAABHRMPXEKMVMA7QWORA63QFS5KBA5CNFSM4IHLZ27KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4YLGZQ#issuecomment-523285350>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRMAV5VAX7LZ7KIBBKTQFS5KBANCNFSM4IHLZ27A>\n> .\n>\n\n\n-- \n - Alex\n", "@piiswrong commit https://github.com/tensorflow/tensorflow/commit/0d9b07979d180d0a04e334b2ea3f3b4ca7790eba should roll this forward"]}, {"number": 31105, "title": "Refactor the test style & add tests for IsStateful", "body": "This PR refactors the test style for the dataset ops to reduce the repeat code and add the tests for `IsStateful()` API.\r\n\r\ncc: @jsimsa ", "comments": ["@jsimsa Before, we create a `TEST_P`/`TEST_F` for each dataset API, but these tests have the repeat code of making datasets and iterators. As these APIs don't affect each other's behaviors, this PR is trying to make each API test share the code of making dataset and iterator by combing these tests into a single `TEST_P` and moving the API evaluation code to `DatasetOpsTestBase` as functions. \r\n\r\nThis change brings three benefits:\r\n1. avoid the repeat code of making datasets/iterators in different API tests;\r\n2. avoid the repeat code of evaluating the API outputs among different dataset op tests;\r\n2. make it easier to add the tests when new APIs are added to `DatasetBase`/`IteratorBase`: just need to add the evaluation function to `DatasetOpsTestBase` and add the expected output to `TestCase`.", "@jsimsa Thanks for your review! The comments are addressed here (https://github.com/tensorflow/tensorflow/pull/31105/commits/27f5f642d360aacb7963dccdeeac806b316457c7). Could you please take a look when you get a chance?", "@jsimsa Thanks for your detailed review and suggestions! The TestCase part is revised to be more modular. Could you please take a look at the change (https://github.com/tensorflow/tensorflow/commit/52043fdca1c080b793ec3e3e74b10c95fcd6ad76) when you have time?  ", "@jsimsa The utility function `CreateTensors()` is added and the test cases are moved to be just before the unit tests. Please take another look at the change (https://github.com/tensorflow/tensorflow/pull/31105/commits/8ef3e83a314b1a60587750e5e515774bb22dc359) when you get a chance!\r\n\r\nAlso, as `CreateTensor()` is moved out of `DatasetOpsTestBase`, some related files are updated accordingly. Will apply `CreateTensors()` to the other expected_outputs in the next PR when refactoring these tests with the new style. ", "Internal tests failed with `error: 'tensorflow::data::DatasetParams' has virtual functions but non-virtual destructor [-Werror,-Wnon-virtual-dtor]`", "@jsimsa Thanks for checking the internal failures! The virtual deconstructor is added here (https://github.com/tensorflow/tensorflow/pull/31105/commits/59b95d24ee63f83334a0848e535f09b5d6408896). Please take a look at the change!"]}, {"number": 31104, "title": "W tensorflow/core/framework/op_kernel.cc:1431] OP_REQUIRES failed at iterator_ops.cc:988 : Invalid argument: Input shape axis 0 must equal 4, got shape [3] ", "body": "Epoch: [93/10] step: [186/2] time: 0.2719242572784424s, mse: 0.03679807484149933\r\n2019-07-28 12:23:43.405599: W tensorflow/core/framework/op_kernel.cc:1431] OP_REQUIRES failed at iterator_ops.cc:988 : Invalid argument: Input shape axis 0 must equal 4, got shape [3]\r\n[[{{node crop_to_bounding_box_1/unstack}}]]\r\nTraceback (most recent call last):\r\nFile \"train.py\", line 380, in\r\ntrain()\r\nFile \"train.py\", line 178, in train\r\nfor step, (lr_patchs, hr_patchs) in enumerate(train_ds):\r\nFile \"/home/xyh/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 556, in next\r\nreturn self.next()\r\nFile \"/home/xyh/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 585, in next\r\nreturn self._next_internal()\r\nFile \"/home/xyh/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 577, in _next_internal\r\noutput_shapes=self._flat_output_shapes)\r\nFile \"/home/xyh/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1954, in iterator_get_next_sync\r\n_six.raise_from(_core._status_to_exception(e.code, message), None)\r\nFile \"\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input shape axis 0 must equal 4, got shape [3]\r\n[[{{node crop_to_bounding_box_1/unstack}}]] [Op:IteratorGetNextSync]\r\n2019-07-28 12:23:43.507127: W tensorflow/core/kernels/data/generator_dataset_op.cc:79] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\r\n[[{{node PyFunc}}]]\r\n", "comments": ["@YonghuiXu ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 31103, "title": "pip install tensorflow-lite PLEASE!", "body": "I'm finding very, very difficult-to-understand information online for how to install TF-lite.  Most of it involves cross-compilation and 10+ hours of waiting.  Tensorflow installation is easy.  Could you please make it so we can install TF-lite by just typing \"pip install tensorflow-lite?\"\r\n\r\nThanks!", "comments": ["Just kidding: you should try to build the Android Open Source Project as a practice first.", "Please go through the [link](https://www.tensorflow.org/lite/guide/build_arm64) to build tensorflow-lite.Thanks!", "Hi Ravikyram.  I've been stuck on those instructions for the last 3 days.  I'm finding them very, very difficult to follow.", "There are many precompiled binaries for various platforms. See the full guide\r\nhttps://www.tensorflow.org/lite/guide/\r\n\r\nHowever, here's more links\r\n\r\nIf you just want to run it on raspberry pi or linux, then you can already do a pip install\r\nhttps://www.tensorflow.org/lite/guide/python\r\nwhich can be built by using  from the source tree with these instructions\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/pip_package/README.md\r\n\r\nIf you want to use it on android you can use the precompiled aar.\r\nhttps://www.tensorflow.org/lite/guide/android\r\n\r\nIf you want to use it on ios you can use a cocoapod\r\nhttps://www.tensorflow.org/lite/guide/ios\r\n\r\n"]}, {"number": 31102, "title": "DepthwiseConv2D initializer version problem", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 1903\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N\r\n- TensorFlow installed from (source or binary):Pip\r\n- TensorFlow version (use command below):1.14\r\n- Python version:3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.0.130\r\n- GPU model and memory:7.5.0\r\n\r\n**Describe the current behavior**\r\nVarianceScaling throws an warning\r\n**Describe the expected behavior**\r\nNo warning\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.Session(config=config)\r\n\r\nfrom tensorflow.python.keras import backend as K\r\nfrom tensorflow.python.keras import datasets as ds\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.layers import *\r\nfrom tensorflow.python.keras.initializers import GlorotUniformV2\r\n\r\nBATCH_SIZE = 128\r\nEPOCHS = 5\r\nINPUT_SHAPE = (28, 28, 1)\r\nNUM_TRAIN = 60000\r\nNUM_TEST = 10000\r\nKERNEL_INIT = GlorotUniformV2()\r\n\r\n(train_x, train_y), (val_x, val_y) = ds.mnist.load_data()\r\ntrain_x, val_x = train_x / 255.0, val_x / 255.0\r\ntrain_x = train_x.reshape((NUM_TRAIN, *INPUT_SHAPE))\r\nval_x = val_x.reshape((NUM_TEST, *INPUT_SHAPE))\r\n\r\n\r\nx_in = Input(shape=INPUT_SHAPE)\r\nx = x_in\r\nx = DepthwiseConv2D(3, 2, depthwise_initializer=KERNEL_INIT)(x)\r\nx = Flatten()(x)\r\nx = Dense(128, activation='relu', kernel_initializer=KERNEL_INIT)(x)\r\nx = Dropout(0.5)(x)\r\nx = Dense(10, activation='softmax', kernel_initializer=KERNEL_INIT)(x)\r\nmodel = Model(x_in, x)\r\n\r\nmodel.compile(\r\n  optimizer='adam',\r\n  loss='sparse_categorical_crossentropy',\r\n  metrics=['accuracy']\r\n)\r\n\r\nmodel.fit(\r\n  train_x,\r\n  train_y,\r\n  batch_size=BATCH_SIZE,\r\n  epochs=EPOCHS,\r\n)\r\n\r\nmodel.evaluate(\r\n  val_x,\r\n  val_y\r\n)\r\n```\r\n\r\n\r\n\r\n\r\n**logs**\r\nFirst Log:\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0728 12:30:00.214958 16060 deprecation_wrapper.py:119] From x:\\Suger\\hat\\unpush\\dwconv.py:4: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\r\n\r\nW0728 12:30:00.216953 16060 deprecation_wrapper.py:119] From x:\\Suger\\hat\\unpush\\dwconv.py:6: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\n2019-07-28 12:30:00.238369: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-07-28 12:30:00.257704: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll\r\n2019-07-28 12:30:01.156168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:01:00.0\r\n2019-07-28 12:30:01.172584: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-07-28 12:30:01.190335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-07-28 12:30:01.966452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-28 12:30:01.975391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2019-07-28 12:30:01.982825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n2019-07-28 12:30:01.987863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3000 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nW0728 12:30:02.522783 16060 deprecation.py:506] From X:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\n2019-07-28 12:30:03.177402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:01:00.0\r\n2019-07-28 12:30:03.197705: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.        \r\n2019-07-28 12:30:03.217384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-07-28 12:30:03.222728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-28 12:30:03.232990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\r\n2019-07-28 12:30:03.237410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\r\n2019-07-28 12:30:03.249019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3000 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nEpoch 1/5\r\n60000/60000 [==============================] - 3s 54us/sample - loss: 0.6449 - acc: 0.8029\r\nEpoch 2/5\r\n60000/60000 [==============================] - 2s 31us/sample - loss: 0.2886 - acc: 0.9142\r\nEpoch 3/5\r\n60000/60000 [==============================] - 2s 31us/sample - loss: 0.2315 - acc: 0.9330\r\nEpoch 4/5\r\n60000/60000 [==============================] - 2s 38us/sample - loss: 0.2015 - acc: 0.9410\r\nEpoch 5/5\r\n60000/60000 [==============================] - 2s 34us/sample - loss: 0.1849 - acc: 0.9455\r\n10000/10000 [==============================] - 1s 78us/sample - loss: 0.1072 - acc: 0.9671\r\n```\r\nNotice:\r\n```\r\nW0728 12:30:02.522783 16060 deprecation.py:506] From X:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\n```\r\nAnd then I read the its source code and found that DepthwiseConv2D inherits Conv2D.\r\n```\r\nclass DepthwiseConv2D(Conv2D):\r\n  def __init__(self,\r\n               kernel_size,\r\n               strides=(1, 1),\r\n               padding='valid',\r\n               depth_multiplier=1,\r\n               data_format=None,\r\n               activation=None,\r\n               use_bias=True,\r\n               depthwise_initializer='glorot_uniform',\r\n               bias_initializer='zeros',\r\n               depthwise_regularizer=None,\r\n               bias_regularizer=None,\r\n               activity_regularizer=None,\r\n               depthwise_constraint=None,\r\n               bias_constraint=None,\r\n               **kwargs):\r\n    super(DepthwiseConv2D, self).__init__(\r\n        filters=None,\r\n        kernel_size=kernel_size,\r\n        strides=strides,\r\n        padding=padding,\r\n        data_format=data_format,\r\n        activation=activation,\r\n        use_bias=use_bias,\r\n        bias_regularizer=bias_regularizer,\r\n        activity_regularizer=activity_regularizer,\r\n        bias_constraint=bias_constraint,\r\n        **kwargs)\r\n    self.depth_multiplier = depth_multiplier\r\n    self.depthwise_initializer = initializers.get(depthwise_initializer)\r\n    self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\r\n    self.depthwise_constraint = constraints.get(depthwise_constraint)\r\n    self.bias_initializer = initializers.get(bias_initializer)\r\n########\r\nclass Conv2D(Conv):\r\n  def __init__(self,\r\n               filters,\r\n               kernel_size,\r\n               strides=(1, 1),\r\n               padding='valid',\r\n               data_format=None,\r\n               dilation_rate=(1, 1),\r\n               activation=None,\r\n               use_bias=True,\r\n               kernel_initializer='glorot_uniform',\r\n               bias_initializer='zeros',\r\n               kernel_regularizer=None,\r\n               bias_regularizer=None,\r\n               activity_regularizer=None,\r\n               kernel_constraint=None,\r\n               bias_constraint=None,\r\n               **kwargs):\r\n    super(Conv2D, self).__init__(\r\n        rank=2,\r\n        filters=filters,\r\n        kernel_size=kernel_size,\r\n        strides=strides,\r\n        padding=padding,\r\n        data_format=data_format,\r\n        dilation_rate=dilation_rate,\r\n        activation=activations.get(activation),\r\n        use_bias=use_bias,\r\n        kernel_initializer=initializers.get(kernel_initializer),\r\n        bias_initializer=initializers.get(bias_initializer),\r\n        kernel_regularizer=regularizers.get(kernel_regularizer),\r\n        bias_regularizer=regularizers.get(bias_regularizer),\r\n        activity_regularizer=regularizers.get(activity_regularizer),\r\n        kernel_constraint=constraints.get(kernel_constraint),\r\n        bias_constraint=constraints.get(bias_constraint),\r\n        **kwargs)\r\n```\r\nObviously, when DepthwiseConv2D inherits Conv2D, there is no `kernel_initializer` parameter incoming, so Conv2D uses the default parameter `'glorot_uniform'`, resulting in a warning.\r\n\r\nThen, I changed my code:\r\n```\r\nx = DepthwiseConv2D(3, 2, depthwise_initializer=KERNEL_INIT, kernel_initializer=KERNEL_INIT)(x)\r\n```\r\n**Log**\r\nSecond log:\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0728 12:39:05.557960  7540 deprecation_wrapper.py:119] From x:\\Suger\\hat\\unpush\\dwconv.py:4: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\r\n\r\nW0728 12:39:05.568932  7540 deprecation_wrapper.py:119] From x:\\Suger\\hat\\unpush\\dwconv.py:6: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\n2019-07-28 12:39:05.586014: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-07-28 12:39:05.601795: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll\r\n2019-07-28 12:39:06.511195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:01:00.0\r\n2019-07-28 12:39:06.537446: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-07-28 12:39:06.565361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-07-28 12:39:07.398542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-28 12:39:07.412458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2019-07-28 12:39:07.420821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n2019-07-28 12:39:07.435578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3000 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2019-07-28 12:39:08.630786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:01:00.0\r\n2019-07-28 12:39:08.651080: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.        \r\n2019-07-28 12:39:08.666536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-07-28 12:39:08.680031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-28 12:39:08.687696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\r\n2019-07-28 12:39:08.702410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\r\n2019-07-28 12:39:08.718322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3000 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nEpoch 1/5\r\n60000/60000 [==============================] - 3s 52us/sample - loss: 0.6964 - acc: 0.7821\r\nEpoch 2/5\r\n60000/60000 [==============================] - 2s 32us/sample - loss: 0.2977 - acc: 0.9111\r\nEpoch 3/5\r\n60000/60000 [==============================] - 2s 31us/sample - loss: 0.2382 - acc: 0.9298\r\nEpoch 4/5\r\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.2097 - acc: 0.9378\r\nEpoch 5/5\r\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.1888 - acc: 0.9438\r\n10000/10000 [==============================] - 1s 79us/sample - loss: 0.1104 - acc: 0.9666\r\n```\r\nThere's no warning.\r\n", "comments": ["@Suger131 Looks like you found workaround. Please let us know if you are happy to close if no issue persists. Thanks!"]}, {"number": 31101, "title": "when will the weights be updated for the sparse tensor in the optimizer", "body": "I notice there are both [SparseApplyAdadeltaOp](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/training_ops.cc#L798) and [ApplyAdadeltaOp](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/training_ops.cc#L642) in the [/tensorflow/core/kernels/training_ops.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/training_ops.cc). \r\n\r\nApparently, when the weights for the dense feature is optimized using Adadelta, the class of `ApplyAdadeltaOp` will be called, while when the weights for the categorical feature is optimized, `SparseApplyAdadeltaOp` will be called.\r\n\r\nMy question is when the `SparseApplyAdadeltaOp`  is called, for which part of the weights will be updated seems to not be in the code annotation, on earth the wights that are not zero will be updated or the weights whose gradients that are not zero will be updated?", "comments": ["@ymodak hi, is there any answer for this problem :)", "@oanush hi, but who should I turn to help for this problem?", "@gadagashwini sos", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\n"]}, {"number": 31100, "title": "When I used tf.keras.backend.clip in my code, I got the error: TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed", "body": "When I implemented the code below with TensorFlow 1.12.0, I got some errors. However, the code can be implemented well with TensorFlow 1.11.0. I am confused by the problem. Actually, I am not sure whether it is the problem of the TensorFlow version. Hope someone can give me some advice.\r\n\r\nThe code:\r\n\r\n```\r\ndef lightconstraint(temp):\r\n    # add constraint for the output W\r\n    # 1-norm of W less than min{I_DC-I_L, I_U-I_DC}\r\n    # for simplicity, only clip [0, I_DC]\r\n    W, I_DC= temp\r\n    norms = tf.norm(W, ord=1, axis=2, keepdims=True)\r\n    desired = K.clip(norms, 0, I_DC[0])\r\n    return W * (desired / (K.epsilon() + norms))\r\n\r\n\r\n# function test code\r\noo1 = tf.convert_to_tensor(np.array([[[1, 0], [1, 1]],\r\n                                    [[0, 0], [1, 2]]]).astype('float32'))\r\noo2 = tf.convert_to_tensor(np.array([1]).astype('float32'))\r\nwith tf.Session() as sess:\r\n    print(sess.run(lightconstraint([oo1, oo2])))\r\n```\r\nThe error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-47-3851ab5448f3> in <module>()\r\n     14 oo2 = tf.convert_to_tensor(np.array([1]).astype('float32'))\r\n     15 with tf.Session() as sess:\r\n---> 16     print(sess.run(lightconstraint([oo1, oo2])))\r\n\r\n<ipython-input-47-3851ab5448f3> in lightconstraint(temp)\r\n      5     W, I_DC= temp\r\n      6     norms = tf.norm(W, ord=1, axis=2, keepdims=True)\r\n----> 7     desired = K.clip(norms, 0, I_DC[0])\r\n      8     return W * (desired / (K.epsilon() + norms))\r\n      9 \r\n\r\nC:\\YYY\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py in clip(x, min_value, max_value)\r\n   1941       A tensor.\r\n   1942   \"\"\"\r\n-> 1943   if max_value is not None and max_value < min_value:\r\n   1944     max_value = min_value\r\n   1945   if max_value is None:\r\n\r\nC:\\YYY\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in __bool__(self)\r\n    669       `TypeError`.\r\n    670     \"\"\"\r\n--> 671     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\r\n    672                     \"Use `if t is not None:` instead of `if t:` to test if a \"\r\n    673                     \"tensor is defined, and use TensorFlow ops such as \"\r\n\r\nTypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.\r\n```", "comments": ["I guess that maybe it is the problem of the usage of K.clip. I am not sure whether tensor can be the third parameters of the K.clip function. Actually, sometimes, the code can run without error, but, it outputs errors in majority conditions.", "I have tried on colab with TF version 1.12.0 and 1.11.0 beta and was able to reproduce the issue.Please, find the [gist ](https://colab.research.google.com/drive/1fuHtPEGXy3xJQdwGDwvON0Uoi-pxEV46)here. Thanks!", "@bugzhu I was able to reproduce the issue with tf-nightly. [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/83a39f17991e14fc1dfb27fb7263e29d/tf-nightly_31100.ipynb) is the gist.\r\n\r\nHowever, it ran without an issue when TF2.0 was used. Here is the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/ecedfcce76930129a03a41d889dad523/tf-20_31100.ipynb) with TF2.0b1. Would you like to install TF2.0 as it has better performance than older TF1.x versions. Thanks!", "Thank you for your comments. With TF2.0, it ran perfectly without error! Maybe in my future work, I will try TF2.0. It is a good idea.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31100\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31100\">No</a>\n"]}, {"number": 31099, "title": "Improve fps Resnet model", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):1.14.1\r\n- Python version:3.6.8\r\n- CUDA/cuDNN version:9.0/7.4\r\n- GPU model and memory: Nvidia GeForce 840m\r\n\r\nI have trained a Resnet Model from scratch to detect eye region in real-time.\r\nThe trained model gives me some results but the values fps <10.\r\nI have opened the webcam and load Tensorflow model using a python script and OpenCV library.\r\nI tried many solutions ( decrease the width and height of the input image, set the batch size to 1 ...) but any of those methods working.\r\nI want to know if there is a solution to increase the value of fps?\r\n\r\n\r\n", "comments": ["Hi abdou31,\r\nyou could try the tensorflow slim models. \r\n[Here](https://github.com/tensorflow/models/tree/master/research/slim) is an overview how to use them. There is even a pretrained model that might be a good start to try out the performance before training your own network.", "I just want to tell you that I have used a Github Repository [link](https://github.com/yinguobing/cnn-facial-landmark) that use a CNN to create a Resnet model to detect 68 facial landmarks.\r\nNB: The output of the CNN is Regression, not a classification.\r\nSo I have used this CNN to train my own dataset to detect 40 eye region landmarks, I tried to use the pre-trained model that he gives but it doesn't work because of the number of landmarks ( units of logits layers ) and the width and height of the input image tensor are differents.\r\nFor that reason, I should use Transfer learning ( that I didn't how can I start using this technique ).\r\nThe models that you give are many and are different, I would like to know:\r\n+ How can I choose a pre-trained model that can be compatible with my CNN?\r\n+ How can I use transfer learning to adjust some parameters in the CNN?\r\nThanks", "Since the project of the github repository you linked seems to be specific, I would consider converting the network you have trained to a tf lite network and try the performance then.", "I have converted to tflite and I don't know how can I use tflite model for prediction ", "Sorry, I mixed something up there. Tf lite is just for embedded devices, but I guess you are trying to run the model on your pc. \r\nYou can have a look at https://www.tensorflow.org/guide/performance/overview \r\nIf this does not help you, you might consider opening a question on stackoverflow since this is not an issue with tf. ", "The link that you post doesn't meet for what I need and what I want.\r\nThe performance should be good on the phone because the SDK that I want should be performant and the value of fps should be heigher.\r\nI know that this is related to the GPU or CPU of the phone you test on it.\r\nBut there many application that use machine learning SDK work perfectly and fast like BinaryFace SDK ... \r\nI know just gpu delegate on.the phone that can improve the performance but I don't know how to use it.\r\nWhat can improve the performance ? ", "See step by step tutorial for GPU delegate on android https://www.youtube.com/watch?reload=9&v=Xkhgre8r5G0&feature=youtu.be", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31099\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31099\">No</a>\n"]}, {"number": 31098, "title": "conda install tensorflow-mkl version raise error: could not create a dilated convolution forward descriptor", "body": "keras vesion: 2.2.4, tenssoflow version: 1.13.1\r\nCPU: i3-330\r\n\r\nexception stack:\r\n\r\n\r\n\r\nEpoch 1/5\r\n\r\n---------------------------------------------------------------------------\r\nAbortedError                              Traceback (most recent call last)\r\n<ipython-input-7-ddf42c6880a1> in <module>\r\n     13                               validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),\r\n     14                               steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),\r\n---> 15                               callbacks=[checkpoint, early, tb, csv_logger])\r\n\r\nD:\\soft\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py in wrapper(*args, **kwargs)\r\n     89                 warnings.warn('Update your `' + object_name + '` call to the ' +\r\n     90                               'Keras 2 API: ' + signature, stacklevel=2)\r\n---> 91             return func(*args, **kwargs)\r\n     92         wrapper._original_function = func\r\n     93         return wrapper\r\n\r\nD:\\soft\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1416             use_multiprocessing=use_multiprocessing,\r\n   1417             shuffle=shuffle,\r\n-> 1418             initial_epoch=initial_epoch)\r\n   1419 \r\n   1420     @interfaces.legacy_generator_methods_support\r\n\r\nD:\\soft\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n    215                 outs = model.train_on_batch(x, y,\r\n    216                                             sample_weight=sample_weight,\r\n--> 217                                             class_weight=class_weight)\r\n    218 \r\n    219                 outs = to_list(outs)\r\n\r\nD:\\soft\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in train_on_batch(self, x, y, sample_weight, class_weight)\r\n   1215             ins = x + y + sample_weights\r\n   1216         self._make_train_function()\r\n-> 1217         outputs = self.train_function(ins)\r\n   1218         return unpack_singleton(outputs)\r\n   1219 \r\n\r\nD:\\soft\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in __call__(self, inputs)\r\n   2713                 return self._legacy_call(inputs)\r\n   2714 \r\n-> 2715             return self._call(inputs)\r\n   2716         else:\r\n   2717             if py_any(is_tensor(x) for x in inputs):\r\n\r\nD:\\soft\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in _call(self, inputs)\r\n   2673             fetched = self._callable_fn(*array_vals, run_metadata=self.run_metadata)\r\n   2674         else:\r\n-> 2675             fetched = self._callable_fn(*array_vals)\r\n   2676         return fetched[:len(self.outputs)]\r\n   2677 \r\n\r\nD:\\soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py in __call__(self, *args, **kwargs)\r\n   1437           ret = tf_session.TF_SessionRunCallable(\r\n   1438               self._session._session, self._handle, args, status,\r\n-> 1439               run_metadata_ptr)\r\n   1440         if run_metadata:\r\n   1441           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nD:\\soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\r\n    526             None, None,\r\n    527             compat.as_text(c_api.TF_Message(self.status.status)),\r\n--> 528             c_api.TF_GetCode(self.status.status))\r\n    529     # Delete the underlying status object from memory otherwise it stays alive\r\n    530     # as there is a reference to status from this from the traceback due to\r\n\r\nAbortedError: Operation received an exception:Status: 3, message: could not create a dilated convolution forward descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:1111\r\n\t [[{{node conv1_1/convolution}}]]\r\n\r\n--------------------------------------------------------------------------------------\r\nthe code work well with version without MKL.", "comments": ["@eriklu ,\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "@eriklu In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "```python\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras.applications.mobilenet import preprocess_input, decode_predictions\r\n\r\nWIDTH=224\r\nHEIGHT=224\r\nBATCH_SIZE=64\r\ntest_dir = '../Dataset/test/'\r\ntrain_dir = '../Dataset/train/'\r\nval_dir = '../Dataset/val/'\r\n\r\n#Train DataSet Generator with Augmentation\r\nprint(\"\\nTraining Data Set\")\r\ntrain_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\r\ntrain_flow = train_generator.flow_from_directory(\r\n    train_dir,\r\n    target_size=(HEIGHT, WIDTH),\r\n    batch_size = BATCH_SIZE\r\n)\r\n\r\n#Validation DataSet Generator with Augmentation\r\nprint(\"\\nValidation Data Set\")\r\nval_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\r\nval_flow = val_generator.flow_from_directory(\r\n    val_dir,\r\n    target_size=(HEIGHT, WIDTH),\r\n    batch_size = BATCH_SIZE\r\n)\r\n\r\n#Test DataSet Generator with Augmentation\r\nprint(\"\\nTest Data Set\")\r\ntest_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\r\ntest_flow = test_generator.flow_from_directory(\r\n    test_dir,\r\n    target_size=(HEIGHT, WIDTH),\r\n    batch_size = BATCH_SIZE\r\n)\r\n\r\n\r\n\r\n\r\nfrom keras.models import Sequential, Model, load_model\r\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\r\nfrom keras import optimizers, models\r\nfrom keras.layers import Dense, Dropout, GlobalAveragePooling2D\r\nfrom keras import applications\r\nfrom keras import backend as K\r\nimport tensorflow as tf\r\nimport os\r\n\r\nNUM_PARALLEL_EXEC_UNITS = 0\r\n\r\n\r\n#Set Performance Parameters for MKL and Tensorflow using Keras backend\r\n#TensorFlow\r\nconfig = tf.ConfigProto(\r\n    intra_op_parallelism_threads=NUM_PARALLEL_EXEC_UNITS,\r\n    inter_op_parallelism_threads=1\r\n)\r\n\r\nsession = tf.Session(config=config)\r\nK.set_session(session)\r\n\r\n#MKL and OpenMP\r\nos.environ[\"OMP_NUM_THREADS\"] = str(NUM_PARALLEL_EXEC_UNITS)\r\nos.environ[\"KMP_BLOCKTIME\"] = \"1\"\r\nos.environ[\"KMP_SETTINGS\"] = \"1\"\r\nos.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\r\n\r\n\r\n\r\n# Initialize mobilenet with transfer learning\r\nbase_model = applications.MobileNet(weights='imagenet', \r\n                                include_top=False, \r\n                                input_shape=(WIDTH, HEIGHT,3))\r\n\r\n# add a global spatial average pooling layer\r\nx = base_model.output\r\n\r\nx = GlobalAveragePooling2D()(x)\r\n# and a dense layer\r\nx = Dense(1024, activation='relu')(x)\r\npredictions = Dense(len(train_flow.class_indices), activation='softmax')(x)\r\n\r\n# this is the model we will train\r\nmodel = Model(inputs=base_model.input, outputs=predictions)\r\n\r\n# first: train only the top layers (which were randomly initialized)\r\n# i.e. freeze all convolutional InceptionV3 layers\r\nfor layer in base_model.layers:\r\n    layer.trainable = False\r\n\r\n# compile the model (should be done *after* setting layers to non-trainable)\r\nmodel.compile(optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy', 'top_k_categorical_accuracy'], loss='categorical_crossentropy')\r\nmodel.summary()\r\n\r\n\r\n\r\nimport math\r\ntop_layers_file_path=\"top_layers.mn.hdf5\"\r\n\r\ncheckpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\r\ntb = TensorBoard(log_dir='./logs', batch_size=val_flow.batch_size, write_graph=True, update_freq='batch')\r\nearly = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=5)\r\ncsv_logger = CSVLogger('./logs/mn-log.csv', append=True)\r\n\r\nhistory = model.fit_generator(train_flow, \r\n                              epochs=5, \r\n                              verbose=1,\r\n                              validation_data=val_flow,\r\n                              validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),\r\n                              steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),\r\n                              callbacks=[checkpoint, early, tb, csv_logger])\r\n```\r\n-----------------------------------------------------------------------------------------------\r\nthe exception throw at the last line fit_generator function.\r\nthe code come from Intel AIDC. It's a Demo. I can't offer test data here.\r\nyou can download the complete zip file from\uff1a\r\nhttps://pan.baidu.com/s/1XvLocaijuZ2RnVu_onzrwQ  the code: 0jwj \r\n\r\nYou need run Part1-Exploratory_Data_Analysis.ipynb notebook to prepare training data before** you run the Optional-Training_MobileNet.ipynb notebook\r\n\r\nI run the code on non-mkl version tensorflow v1.13, it works.  when I want to speed the training , I install the mkl version with \"conda install tensorflow-mkl\", I encounter the error.\r\n\r\nI think maybe it occurs because of my poor CUP: i3-330M (the first i-serial CPU) or I need install some lib.\r\n\r\nThe CPU-Z shows: Instructions sets\tMMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, EM64T, VT-x", "Are you able to install TF with mkl flag and import tensorflow successfully?\r\nThe above given code snippet works for you in TF without mkl but fails with TF-MKL? Is my understanding correct here?", "Yes\uff0c it's right.  \r\non normal TF : \r\nI get below info:\r\n\r\n-----------------------------------------------------------------------------------------\r\nWARNING:tensorflow:From D:\\soft\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nEpoch 1/5\r\n  3/319 [..............................] - ETA: 38:33 - loss: 2.7897 - acc: 0.1042 - top_k_categorical_accuracy: 0.5417   \r\n---------------------------------------------------------------------\r\nthe triaining start and run slowly.\r\n\r\nI read that mkl version is faster 10x, but I failed with the error.\r\n\r\nI have encounter a error about Instructions set when use TF normal version, so I install from a .whl file  \r\ncompiled with the  Instructions set supported by my poor CPU.\r\n\r\nI think the conda and pip install the lib without care CPU\u3002\r\n", "@eriklu Downgrade to TF 1.12.0 : `conda install tensorflow-mkl=1.12.0`", "it works and the speed raise almost 20% than normal tf version\uff0c thanks u!\r\n```\r\nEpoch 1/5\r\n 11/319 [>.............................] - ETA: 21:14 - loss: 3.6482 - acc: 0.1477 - top_k_categorical_accuracy: 0.5739\r\n```\r\n\r\ncan you explain the reason for me?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31098\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31098\">No</a>\n", "Hi, since we have already upgraded TF. Could you please check the latest Intel distribution? Thank you.", "(py36) C:\\Users\\Erik>conda update tensorflow-mkl\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: done\r\n..........\r\n\r\nThe following packages will be UPDATED:\r\n\r\n  ipython                              7.7.0-py36h39e3cac_0 --> 7.8.0-py36h39e3cac_0\r\n  mkl-service                          2.0.2-py36he774522_0 --> 2.3.0-py36hb782905_0\r\n  notebook                                     6.0.0-py36_0 --> 6.0.1-py36_0\r\n  numpy                               1.16.4-py36h19fb1c0_0 --> 1.16.5-py36h19fb1c0_0\r\n  numpy-base                          1.16.4-py36hc3f5095_0 --> 1.16.5-py36hc3f5095_0\r\n  openssl                                 1.1.1c-he774522_1 --> 1.1.1d-he774522_0\r\n  qtconsole                                      4.5.3-py_0 --> 4.5.5-py_0\r\n  tensorboard                         1.12.2-py36h33f27b4_0 --> 1.14.0-py36he3c9ec2_0\r\n  tensorflow                      1.12.0-mkl_py36h4f00353_0 --> 1.14.0-mkl_py36hb88db5b_0\r\n  tensorflow-base                 1.12.0-mkl_py36h81393da_0 --> 1.14.0-mkl_py36ha978198_0\r\n  tensorflow-mkl                          1.12.0-h4fcabd2_0 --> 1.14.0-h4fcabd2_0\r\n  vs2015_runtime                     14.15.26706-h3a45250_4 --> 14.16.27012-hf0eaf9b_0\r\nProceed ([y]/n)?\r\n\r\n......\r\n\r\n(py36) E:\\test\\jupyter>conda list\r\n# packages in environment at D:\\soft\\Anaconda3\\envs\\py36:\r\n#\r\n# Name                    Version                   Build  Channel\r\n........\r\ntensorboard               1.14.0           py36he3c9ec2_0\r\ntensorflow                1.14.0          mkl_py36hb88db5b_0\r\ntensorflow-base           1.14.0          mkl_py36ha978198_0\r\ntensorflow-estimator      1.14.0                     py_0\r\ntensorflow-mkl            1.14.0               h4fcabd2_0\r\ntermcolor                 1.1.0                    py36_1\r\nterminado                 0.8.2                    py36_0\r\ntestpath                  0.4.2                    py36_0\r\ntk                        8.6.8                hfa6e2cd_0\r\ntornado                   6.0.3            py36he774522_0\r\ntraitlets                 4.3.2            py36h096827d_0\r\n......\r\n\r\nbefore update:    keras vesion: 2.2.4, tenssoflow version: 1.12.0\r\nafter    update:  keras vesion: 2.2.4, tenssoflow version: 1.14.0\r\n\r\n\r\n\r\nthe code works well.  but i feel the training speed slow down a little (two minute more from 21:14 to 23:46). \r\n\r\nEpoch 1/5\r\n 11/319 [>.............................] - ETA: 23:46 - loss: 3.5137 - acc: 0.1534 - top_k_categorical_accuracy: 0.6023\r\n\r\n\r\nthanks your greate work,"]}]